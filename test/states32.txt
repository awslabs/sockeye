ssh://ec2-user@ec2-52-214-115-94.eu-west-1.compute.amazonaws.com:22/home/ec2-user/.pyenv/versions/3.5.4-trt/bin/python -u /home/ec2-user/kellen/sockeye/test/translate.py
/home/ec2-user/kellen/sockeye/sockeye/__init__.py
/home/ec2-user/danchenk/incubator-mxnet/python/mxnet/__init__.py
[INFO:sockeye.vocab] Vocabulary (22309 words) loaded from "/home/ec2-user/kellen/sockeye/test/wmt_model/vocab.src.json"
[INFO:sockeye.vocab] Vocabulary (16743 words) loaded from "/home/ec2-user/kellen/sockeye/test/wmt_model/vocab.trg.json"
[INFO:sockeye.inference] Model version: 1.16.2
[INFO:sockeye.model] ModelConfig loaded from "/home/ec2-user/kellen/sockeye/test/wmt_model/config"
[INFO:sockeye.model] Config[_frozen=True, config_data=Config[_frozen=True, data_statistics=Config[_frozen=True, average_len_target_per_bucket=[5.6599009900989845, 14.83566261975379, 23.622827780137886, 32.348828135886386, 40.9103269172012, 49.4851570964248], buckets=[(10, 10), (20, 20), (30, 30), (40, 40), (50, 50), (60, 60)], length_ratio_mean=0.9875086015461053, length_ratio_std=0.4514233014884626, max_observed_len_source=60, max_observed_len_target=60, num_discarded=6631, num_sents=193369, num_sents_per_bucket=[32320, 46867, 49431, 35883, 19638, 9230], num_tokens_source=4563547, num_tokens_target=4466849, num_unks_source=0, num_unks_target=0, size_vocab_source=22309, size_vocab_target=16743], max_seq_len_source=60, max_seq_len_target=60, num_shards=1, shared_vocab=False, source=/home/ec2-user/kellen/data/training/corpus.tc.BPE.de.200K, target=/home/ec2-user/kellen/data/training/corpus.tc.BPE.en.200K, vocab_source=None, vocab_target=None], config_decoder=Config[_frozen=True, attention_config=Config[_frozen=True, config_coverage=None, input_previous_word=False, layer_normalization=False, num_heads=None, num_hidden=512, query_num_hidden=512, source_num_hidden=512, type=dot], attention_in_upper_layers=False, context_gating=False, dtype=<class 'numpy.float32'>, hidden_dropout=0.0, layer_normalization=False, max_seq_len_source=60, rnn_config=Config[_frozen=True, cell_type=lstm, dropout_inputs=0.0, dropout_recurrent=0.0, dropout_states=0.0, first_residual_layer=2, forget_bias=0.0, num_hidden=512, num_layers=1, residual=False], state_init=last, use_fp16=False], config_embed_source=Config[_frozen=True, dropout=0.0, num_embed=256, vocab_size=22309], config_embed_target=Config[_frozen=True, dropout=0.0, num_embed=256, vocab_size=16743], config_encoder=Config[_frozen=True, conv_config=None, dtype=<class 'numpy.float32'>, reverse_input=False, rnn_config=Config[_frozen=True, cell_type=lstm, dropout_inputs=0.0, dropout_recurrent=0.0, dropout_states=0.0, first_residual_layer=2, forget_bias=0.0, num_hidden=512, num_layers=1, residual=False], use_fp16=False], config_loss=Config[_frozen=True, label_smoothing=0.0, name=cross-entropy, normalization_type=valid, vocab_size=16743], max_seq_len_source=60, max_seq_len_target=60, vocab_source_size=22309, vocab_target_size=16743, weight_normalization=False, weight_tying=False, weight_tying_type=None]
[INFO:sockeye.encoder] Encoder EncoderSequence dtype float32
[INFO:sockeye.encoder] Encoder BatchMajor2TimeMajor dtype float32
[INFO:sockeye.encoder] Encoder BiDirectionalRNNEncoder dtype float32
[INFO:sockeye.encoder] Encoder RecurrentEncoder dtype float32
[INFO:sockeye.encoder] Encoder RecurrentEncoder dtype float32
[INFO:sockeye.decoder] Decoder RecurrentDecoder dtype float32
[INFO:sockeye.model] Encoder EncoderSequence dtype: float32
[INFO:sockeye.model] Decoder RecurrentDecoder dtype: float32
[INFO:sockeye.encoder] Encoder Embedding dtype float32
[INFO:sockeye.encoder] Encoder Embedding dtype float32
[WARNING:sockeye.inference] Model was only trained with sentences up to a length of 60, but a max_input_len of 256 is used.
[14:32:27] /home/ec2-user/danchenk/incubator-mxnet/src/engine/engine.cc:55: MXNet start using engine: NaiveEngine
[INFO:sockeye.model] Loaded params from "/home/ec2-user/kellen/sockeye/test/wmt_model/params.best"
[INFO:sockeye.inference] Translator (1 model(s) beam_size=20 ensemble_mode=None batch_size=1 buckets_source=[10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, 120, 130, 140, 150, 160, 170, 180, 190, 200, 210, 220, 230, 240, 250, 256])
After layer source_embed_embed_0 (1, 10, 256) <class 'numpy.float32'> [[[-0.00175095 -0.0164032  -0.0703125  ...,  0.00574493 -0.01233673
    0.0269928 ]
  [-0.06872559 -0.00477982 -0.00354767 ..., -0.06140137 -0.04299927
    0.03726196]
  [ 0.06011963  0.00928497  0.03005981 ...,  0.06628418  0.02203369
   -0.06420898]
  ...,
  [ 0.06011963  0.00928497  0.03005981 ...,  0.06628418  0.02203369
   -0.06420898]
  [ 0.06011963  0.00928497  0.03005981 ...,  0.06628418  0.02203369
   -0.06420898]
  [ 0.06011963  0.00928497  0.03005981 ...,  0.06628418  0.02203369
   -0.06420898]]]
After layer swapaxes10_output (10, 1, 256) <class 'numpy.float32'> [[[-0.00175095 -0.0164032  -0.0703125  ...,  0.00574493 -0.01233673
    0.0269928 ]]

 [[-0.06872559 -0.00477982 -0.00354767 ..., -0.06140137 -0.04299927
    0.03726196]]

 [[ 0.06011963  0.00928497  0.03005981 ...,  0.06628418  0.02203369
   -0.06420898]]

 ...,
 [[ 0.06011963  0.00928497  0.03005981 ...,  0.06628418  0.02203369
   -0.06420898]]

 [[ 0.06011963  0.00928497  0.03005981 ...,  0.06628418  0.02203369
   -0.06420898]]

 [[ 0.06011963  0.00928497  0.03005981 ...,  0.06628418  0.02203369
   -0.06420898]]]
After layer split4_output0 (1, 256) <class 'numpy.float32'> [[ -1.75094604e-03  -1.64031982e-02  -7.03125000e-02   3.06243896e-02
   -5.19409180e-02  -2.61383057e-02  -1.62506104e-02  -4.49218750e-02
   -7.18593597e-04   2.31018066e-02   5.72814941e-02  -7.00073242e-02
    8.66088867e-02  -6.09436035e-02   4.63867188e-02  -8.91723633e-02
   -3.99169922e-02   4.47692871e-02   6.22863770e-02   3.35388184e-02
    4.08935547e-02  -1.47018433e-02  -5.96618652e-02  -4.84924316e-02
   -1.29013062e-02   4.08325195e-02  -7.45239258e-02  -4.81262207e-02
    1.84936523e-02   6.60400391e-02  -8.18634033e-03  -8.49609375e-02
    7.13500977e-02   2.64892578e-02  -5.14221191e-02   8.77685547e-02
   -3.56292725e-03   4.24804688e-02   4.79507446e-03   8.68530273e-02
    5.55419922e-02  -5.71899414e-02  -6.66379929e-05  -5.02014160e-02
   -6.50024414e-02  -7.35473633e-02  -6.50024414e-02   6.91604614e-03
   -4.83703613e-02   3.69567871e-02   3.84826660e-02  -8.99658203e-02
   -7.94677734e-02  -2.89154053e-02   1.76086426e-02  -2.56958008e-02
   -8.03222656e-02  -8.96930695e-04  -2.29644775e-02   6.87255859e-02
    7.87353516e-02   8.48388672e-02  -8.77075195e-02   3.80859375e-02
    4.70275879e-02   1.64794922e-02   4.80041504e-02   5.49621582e-02
    1.05895996e-02   3.70483398e-02  -2.94036865e-02   1.57165527e-02
    8.14056396e-03   2.80456543e-02  -9.49707031e-02   4.28161621e-02
   -3.33557129e-02   3.94287109e-02   2.30865479e-02  -6.39343262e-03
    6.87789917e-03  -6.32324219e-02   4.43115234e-02   5.30700684e-02
    7.01293945e-02   9.04541016e-02   5.86853027e-02  -2.09197998e-02
   -5.39245605e-02  -9.89913940e-04  -1.98669434e-02  -4.91638184e-02
    8.55712891e-02  -7.08007812e-02   4.53186035e-02   2.46276855e-02
   -3.30505371e-02   6.35375977e-02   9.27734375e-02   6.46972656e-02
    4.85534668e-02   2.13165283e-02  -7.03735352e-02   3.72314453e-02
   -9.88769531e-03  -5.31921387e-02  -3.93390656e-05   6.41479492e-02
    2.13012695e-02  -9.07592773e-02   7.87963867e-02  -9.22851562e-02
   -1.34811401e-02   9.36889648e-02  -4.03747559e-02   3.54919434e-02
    2.44140625e-02   3.03497314e-02  -9.39941406e-02  -3.61633301e-02
   -7.84301758e-02  -6.00433350e-03  -8.94775391e-02  -7.80029297e-02
    6.12792969e-02   6.24084473e-02  -5.09948730e-02   7.50732422e-02
   -1.14898682e-02   5.39855957e-02   1.90429688e-02  -1.08413696e-02
    1.87683105e-02   5.22155762e-02   3.15246582e-02  -6.48193359e-02
    8.28857422e-02  -9.52148438e-02  -2.36511230e-02  -6.02111816e-02
    6.54296875e-02   2.20794678e-02   5.34362793e-02   9.44824219e-02
    4.73937988e-02   6.45141602e-02  -5.77697754e-02   2.14233398e-02
   -2.18963623e-02   6.32934570e-02   3.09143066e-02  -6.65283203e-02
   -2.84881592e-02   7.99560547e-02  -2.42004395e-02  -9.03320312e-02
   -4.91027832e-02  -4.82788086e-02  -5.17272949e-02  -8.64257812e-02
   -7.20596313e-03  -3.64685059e-02  -7.72857666e-03  -1.00860596e-02
   -9.68170166e-03  -7.68432617e-02   8.88671875e-02  -4.43420410e-02
   -3.70788574e-02   1.91192627e-02  -2.69317627e-02  -7.25708008e-02
   -1.19781494e-03   5.15747070e-02  -9.18579102e-02   2.07977295e-02
    3.40576172e-02  -7.94677734e-02   3.50952148e-02   7.12890625e-02
   -3.65295410e-02   8.11157227e-02   5.85937500e-02  -1.91040039e-02
    7.52639771e-03  -5.55725098e-02   6.59561157e-03   8.09936523e-02
    1.13449097e-02   3.52783203e-02  -2.69622803e-02  -7.88574219e-02
    9.19342041e-03   4.10461426e-02  -1.50489807e-03   6.55746460e-03
    1.35345459e-02  -9.20410156e-02   1.93328857e-02  -8.72802734e-02
    7.85522461e-02  -7.56835938e-02  -3.75671387e-02   7.18383789e-02
   -6.65283203e-02  -1.42364502e-02  -4.59289551e-03  -2.31323242e-02
   -7.43865967e-03   1.91879272e-03  -2.13165283e-02   9.43756104e-03
    9.24072266e-02   3.81774902e-02  -1.27105713e-02   5.32836914e-02
    3.09906006e-02  -5.84716797e-02   5.46569824e-02   6.27441406e-02
   -2.81066895e-02  -8.21533203e-02   7.26928711e-02  -1.46560669e-02
   -7.08618164e-02  -6.82373047e-02   6.75659180e-02  -7.94677734e-02
    5.14831543e-02   1.47018433e-02   6.58569336e-02  -7.11059570e-02
   -4.29687500e-02   4.22973633e-02  -1.16195679e-02   6.43310547e-02
    6.09130859e-02  -6.90078735e-03  -6.05163574e-02   2.84881592e-02
   -6.09130859e-02  -6.51855469e-02  -3.97949219e-02   3.13415527e-02
    2.64892578e-02   1.49688721e-02  -3.68118286e-03  -5.97534180e-02
    4.87518311e-03  -9.42993164e-02   4.44335938e-02  -8.22143555e-02
    3.35083008e-02   5.74493408e-03  -1.23367310e-02   2.69927979e-02]]
After layer split4_output1 (1, 256) <class 'numpy.float32'> [[-0.06872559 -0.00477982 -0.00354767 -0.01820374 -0.01612854  0.08428955
  -0.06951904  0.00264549 -0.06427002  0.05566406  0.03616333  0.06744385
   0.01268768  0.02503967 -0.00322533  0.00941467 -0.03817749 -0.01480103
  -0.06390381 -0.00082541 -0.04299927  0.05258179 -0.03115845 -0.04760742
  -0.01341248  0.00824738 -0.03616333  0.05459595 -0.00548172 -0.08770752
  -0.0380249   0.02459717 -0.05517578 -0.06402588  0.06884766  0.07977295
   0.03912354  0.04818726  0.09075928  0.02204895 -0.09381104 -0.05026245
  -0.06982422  0.02409363 -0.0067482  -0.00616837 -0.02383423  0.05352783
   0.08691406 -0.06396484  0.04638672  0.08349609 -0.03488159 -0.09228516
   0.08404541  0.07086182 -0.04742432  0.02374268 -0.08935547  0.07965088
  -0.07897949  0.03561401  0.06286621  0.06707764  0.015625   -0.04220581
  -0.03765869 -0.01841736  0.00150776 -0.01802063 -0.09423828  0.07720947
   0.03140259 -0.0836792  -0.0725708  -0.04382324  0.00515366 -0.00694656
  -0.05938721  0.03411865  0.09222412  0.04168701  0.03198242 -0.00574875
   0.02363586  0.07275391 -0.0791626   0.0692749  -0.04470825 -0.06378174
   0.07495117 -0.0425415   0.09332275  0.08538818 -0.06231689  0.05157471
   0.04559326 -0.07385254 -0.03271484 -0.040802   -0.05093384  0.03372192
   0.0453186   0.01898193  0.02832031  0.02198792 -0.05975342  0.02789307
  -0.06890869  0.07781982 -0.0451355   0.06726074  0.01552582  0.02284241
   0.0793457   0.09033203  0.05105591  0.06140137  0.00379372  0.02333069
   0.078125    0.01802063  0.04208374  0.05169678  0.08758545 -0.04968262
   0.06512451  0.0064621   0.02359009  0.01506805 -0.03088379  0.0725708
   0.00184059  0.07592773  0.04055786  0.07019043  0.01560211  0.06787109
  -0.00635147  0.01701355 -0.00484848 -0.06152344  0.08978271  0.06109619
  -0.08135986  0.07098389 -0.08624268  0.07788086 -0.02548218 -0.02539062
  -0.04089355 -0.03823853  0.07440186  0.04370117 -0.01373291  0.02972412
   0.03491211 -0.03488159  0.07348633  0.02772522 -0.07122803  0.04489136
   0.03134155  0.06896973  0.00819397 -0.05523682 -0.03001404 -0.08703613
   0.08984375 -0.02163696  0.07391357  0.08508301 -0.06445312 -0.05703735
  -0.01725769  0.02288818  0.09173584  0.0064621   0.05944824  0.07824707
  -0.03109741 -0.05822754 -0.04455566 -0.07830811 -0.03317261 -0.07208252
  -0.04022217  0.0355835   0.06433105 -0.06378174 -0.0163269   0.03146362
  -0.04788208 -0.08764648 -0.06896973  0.06286621 -0.09527588 -0.08459473
  -0.05029297 -0.09246826  0.03024292 -0.03356934  0.05667114 -0.00226593
   0.08392334  0.02262878 -0.0247345  -0.0089798   0.05606079 -0.07501221
  -0.04611206 -0.04418945  0.05441284  0.00803375  0.09259033 -0.03710938
  -0.08795166 -0.04641724  0.01368713  0.02748108  0.03753662  0.06182861
  -0.07946777 -0.02145386 -0.02024841  0.03305054 -0.00712204  0.07513428
  -0.07617188 -0.00623322 -0.02082825 -0.00763702 -0.03875732 -0.00661469
  -0.03726196 -0.07226562  0.08209229  0.00625992  0.04260254  0.09307861
  -0.07598877  0.05856323 -0.05401611  0.09051514 -0.02059937  0.02522278
  -0.07348633 -0.07568359  0.03039551 -0.06561279  0.02690125  0.06768799
   0.07397461 -0.06140137 -0.04299927  0.03726196]]
After layer split4_output2 (1, 256) <class 'numpy.float32'> [[ 0.06011963  0.00928497  0.03005981 -0.03009033 -0.03494263  0.00979614
   0.04443359  0.0892334  -0.0647583   0.06057739 -0.03366089 -0.0413208
   0.05426025  0.00199127 -0.04977417 -0.01615906  0.02236938  0.04937744
  -0.07427979  0.01543427  0.03674316 -0.07714844  0.00384521  0.04898071
   0.04669189  0.0435791   0.05166626 -0.03117371  0.00643921 -0.0916748
  -0.06555176  0.04605103  0.03308105 -0.02362061 -0.05386353  0.05136108
  -0.05328369  0.00138664  0.0087204   0.0222168  -0.08197021  0.01593018
  -0.09448242 -0.01968384 -0.05157471 -0.02156067  0.09191895 -0.0456543
  -0.01366425  0.02568054  0.05508423 -0.06210327 -0.06109619  0.09179688
   0.034729    0.00032783  0.08184814 -0.00460052 -0.06396484 -0.07873535
  -0.07684326  0.03585815  0.03106689 -0.02568054 -0.09423828  0.09216309
   0.05581665 -0.07940674 -0.00190926  0.01980591 -0.01357269 -0.07611084
  -0.03887939 -0.06494141 -0.03253174  0.00991821  0.06130981  0.06057739
  -0.02391052 -0.05252075  0.05300903 -0.06097412  0.06945801  0.03237915
   0.07281494 -0.03497314  0.01681519 -0.01838684  0.03123474  0.05499268
   0.03588867 -0.06677246  0.01105499  0.08728027  0.07897949 -0.04669189
   0.01126862  0.08270264  0.07562256 -0.08111572 -0.07165527  0.0562439
   0.09436035  0.03012085  0.07299805  0.05389404 -0.06439209  0.03515625
   0.09405518  0.03613281 -0.04663086 -0.00576401 -0.03102112  0.0838623
  -0.04074097 -0.05682373 -0.0304718  -0.04257202  0.06616211  0.08886719
  -0.08056641 -0.00977325  0.0760498  -0.06884766 -0.05273438  0.04104614
   0.0186615   0.05349731 -0.05892944  0.05801392  0.07830811  0.00614548
  -0.06091309  0.04446411  0.00978851  0.00144386 -0.07788086  0.08276367
   0.07202148  0.08605957 -0.04882812  0.00289917  0.03555298  0.07757568
  -0.07965088  0.03540039 -0.0254364  -0.05508423  0.05841064 -0.03363037
   0.07727051  0.02099609  0.07696533 -0.0352478  -0.06634521 -0.01145172
  -0.05770874  0.02613831  0.06896973  0.02345276 -0.03134155 -0.03076172
  -0.0869751  -0.05670166 -0.04318237  0.01870728  0.06878662  0.08166504
   0.05862427  0.06976318  0.01977539 -0.0680542   0.07312012  0.04721069
   0.04644775  0.06045532 -0.07788086 -0.02279663  0.00743866  0.01916504
   0.05877686 -0.05581665  0.02497864  0.08215332 -0.04962158 -0.04550171
  -0.07220459  0.02761841 -0.00298882 -0.01675415  0.06939697 -0.08612061
   0.09387207  0.06481934  0.00206184  0.08013916 -0.00548172  0.01785278
   0.04898071 -0.06671143 -0.00177479 -0.04730225  0.02372742  0.05212402
  -0.06420898 -0.0300293  -0.04797363 -0.05340576 -0.06292725 -0.07714844
   0.0657959  -0.03717041 -0.0149765   0.06335449 -0.04147339 -0.05319214
   0.00527573  0.01927185  0.01180267  0.0838623   0.00623322 -0.00313187
   0.09326172  0.03146362  0.00914001  0.09161377  0.06488037 -0.06155396
   0.02760315 -0.06207275 -0.06124878 -0.01649475  0.06549072 -0.01605225
  -0.0793457  -0.02545166 -0.08441162 -0.04592896 -0.06707764  0.06787109
  -0.00608063  0.02279663 -0.0328064   0.04278564 -0.05740356 -0.04873657
   0.06732178 -0.05264282 -0.06866455  0.07745361 -0.03759766 -0.0319519
  -0.05053711  0.06628418  0.02203369 -0.06420898]]
After layer split4_output3 (1, 256) <class 'numpy.float32'> [[ 0.06011963  0.00928497  0.03005981 -0.03009033 -0.03494263  0.00979614
   0.04443359  0.0892334  -0.0647583   0.06057739 -0.03366089 -0.0413208
   0.05426025  0.00199127 -0.04977417 -0.01615906  0.02236938  0.04937744
  -0.07427979  0.01543427  0.03674316 -0.07714844  0.00384521  0.04898071
   0.04669189  0.0435791   0.05166626 -0.03117371  0.00643921 -0.0916748
  -0.06555176  0.04605103  0.03308105 -0.02362061 -0.05386353  0.05136108
  -0.05328369  0.00138664  0.0087204   0.0222168  -0.08197021  0.01593018
  -0.09448242 -0.01968384 -0.05157471 -0.02156067  0.09191895 -0.0456543
  -0.01366425  0.02568054  0.05508423 -0.06210327 -0.06109619  0.09179688
   0.034729    0.00032783  0.08184814 -0.00460052 -0.06396484 -0.07873535
  -0.07684326  0.03585815  0.03106689 -0.02568054 -0.09423828  0.09216309
   0.05581665 -0.07940674 -0.00190926  0.01980591 -0.01357269 -0.07611084
  -0.03887939 -0.06494141 -0.03253174  0.00991821  0.06130981  0.06057739
  -0.02391052 -0.05252075  0.05300903 -0.06097412  0.06945801  0.03237915
   0.07281494 -0.03497314  0.01681519 -0.01838684  0.03123474  0.05499268
   0.03588867 -0.06677246  0.01105499  0.08728027  0.07897949 -0.04669189
   0.01126862  0.08270264  0.07562256 -0.08111572 -0.07165527  0.0562439
   0.09436035  0.03012085  0.07299805  0.05389404 -0.06439209  0.03515625
   0.09405518  0.03613281 -0.04663086 -0.00576401 -0.03102112  0.0838623
  -0.04074097 -0.05682373 -0.0304718  -0.04257202  0.06616211  0.08886719
  -0.08056641 -0.00977325  0.0760498  -0.06884766 -0.05273438  0.04104614
   0.0186615   0.05349731 -0.05892944  0.05801392  0.07830811  0.00614548
  -0.06091309  0.04446411  0.00978851  0.00144386 -0.07788086  0.08276367
   0.07202148  0.08605957 -0.04882812  0.00289917  0.03555298  0.07757568
  -0.07965088  0.03540039 -0.0254364  -0.05508423  0.05841064 -0.03363037
   0.07727051  0.02099609  0.07696533 -0.0352478  -0.06634521 -0.01145172
  -0.05770874  0.02613831  0.06896973  0.02345276 -0.03134155 -0.03076172
  -0.0869751  -0.05670166 -0.04318237  0.01870728  0.06878662  0.08166504
   0.05862427  0.06976318  0.01977539 -0.0680542   0.07312012  0.04721069
   0.04644775  0.06045532 -0.07788086 -0.02279663  0.00743866  0.01916504
   0.05877686 -0.05581665  0.02497864  0.08215332 -0.04962158 -0.04550171
  -0.07220459  0.02761841 -0.00298882 -0.01675415  0.06939697 -0.08612061
   0.09387207  0.06481934  0.00206184  0.08013916 -0.00548172  0.01785278
   0.04898071 -0.06671143 -0.00177479 -0.04730225  0.02372742  0.05212402
  -0.06420898 -0.0300293  -0.04797363 -0.05340576 -0.06292725 -0.07714844
   0.0657959  -0.03717041 -0.0149765   0.06335449 -0.04147339 -0.05319214
   0.00527573  0.01927185  0.01180267  0.0838623   0.00623322 -0.00313187
   0.09326172  0.03146362  0.00914001  0.09161377  0.06488037 -0.06155396
   0.02760315 -0.06207275 -0.06124878 -0.01649475  0.06549072 -0.01605225
  -0.0793457  -0.02545166 -0.08441162 -0.04592896 -0.06707764  0.06787109
  -0.00608063  0.02279663 -0.0328064   0.04278564 -0.05740356 -0.04873657
   0.06732178 -0.05264282 -0.06866455  0.07745361 -0.03759766 -0.0319519
  -0.05053711  0.06628418  0.02203369 -0.06420898]]
After layer split4_output4 (1, 256) <class 'numpy.float32'> [[ 0.06011963  0.00928497  0.03005981 -0.03009033 -0.03494263  0.00979614
   0.04443359  0.0892334  -0.0647583   0.06057739 -0.03366089 -0.0413208
   0.05426025  0.00199127 -0.04977417 -0.01615906  0.02236938  0.04937744
  -0.07427979  0.01543427  0.03674316 -0.07714844  0.00384521  0.04898071
   0.04669189  0.0435791   0.05166626 -0.03117371  0.00643921 -0.0916748
  -0.06555176  0.04605103  0.03308105 -0.02362061 -0.05386353  0.05136108
  -0.05328369  0.00138664  0.0087204   0.0222168  -0.08197021  0.01593018
  -0.09448242 -0.01968384 -0.05157471 -0.02156067  0.09191895 -0.0456543
  -0.01366425  0.02568054  0.05508423 -0.06210327 -0.06109619  0.09179688
   0.034729    0.00032783  0.08184814 -0.00460052 -0.06396484 -0.07873535
  -0.07684326  0.03585815  0.03106689 -0.02568054 -0.09423828  0.09216309
   0.05581665 -0.07940674 -0.00190926  0.01980591 -0.01357269 -0.07611084
  -0.03887939 -0.06494141 -0.03253174  0.00991821  0.06130981  0.06057739
  -0.02391052 -0.05252075  0.05300903 -0.06097412  0.06945801  0.03237915
   0.07281494 -0.03497314  0.01681519 -0.01838684  0.03123474  0.05499268
   0.03588867 -0.06677246  0.01105499  0.08728027  0.07897949 -0.04669189
   0.01126862  0.08270264  0.07562256 -0.08111572 -0.07165527  0.0562439
   0.09436035  0.03012085  0.07299805  0.05389404 -0.06439209  0.03515625
   0.09405518  0.03613281 -0.04663086 -0.00576401 -0.03102112  0.0838623
  -0.04074097 -0.05682373 -0.0304718  -0.04257202  0.06616211  0.08886719
  -0.08056641 -0.00977325  0.0760498  -0.06884766 -0.05273438  0.04104614
   0.0186615   0.05349731 -0.05892944  0.05801392  0.07830811  0.00614548
  -0.06091309  0.04446411  0.00978851  0.00144386 -0.07788086  0.08276367
   0.07202148  0.08605957 -0.04882812  0.00289917  0.03555298  0.07757568
  -0.07965088  0.03540039 -0.0254364  -0.05508423  0.05841064 -0.03363037
   0.07727051  0.02099609  0.07696533 -0.0352478  -0.06634521 -0.01145172
  -0.05770874  0.02613831  0.06896973  0.02345276 -0.03134155 -0.03076172
  -0.0869751  -0.05670166 -0.04318237  0.01870728  0.06878662  0.08166504
   0.05862427  0.06976318  0.01977539 -0.0680542   0.07312012  0.04721069
   0.04644775  0.06045532 -0.07788086 -0.02279663  0.00743866  0.01916504
   0.05877686 -0.05581665  0.02497864  0.08215332 -0.04962158 -0.04550171
  -0.07220459  0.02761841 -0.00298882 -0.01675415  0.06939697 -0.08612061
   0.09387207  0.06481934  0.00206184  0.08013916 -0.00548172  0.01785278
   0.04898071 -0.06671143 -0.00177479 -0.04730225  0.02372742  0.05212402
  -0.06420898 -0.0300293  -0.04797363 -0.05340576 -0.06292725 -0.07714844
   0.0657959  -0.03717041 -0.0149765   0.06335449 -0.04147339 -0.05319214
   0.00527573  0.01927185  0.01180267  0.0838623   0.00623322 -0.00313187
   0.09326172  0.03146362  0.00914001  0.09161377  0.06488037 -0.06155396
   0.02760315 -0.06207275 -0.06124878 -0.01649475  0.06549072 -0.01605225
  -0.0793457  -0.02545166 -0.08441162 -0.04592896 -0.06707764  0.06787109
  -0.00608063  0.02279663 -0.0328064   0.04278564 -0.05740356 -0.04873657
   0.06732178 -0.05264282 -0.06866455  0.07745361 -0.03759766 -0.0319519
  -0.05053711  0.06628418  0.02203369 -0.06420898]]
After layer split4_output5 (1, 256) <class 'numpy.float32'> [[ 0.06011963  0.00928497  0.03005981 -0.03009033 -0.03494263  0.00979614
   0.04443359  0.0892334  -0.0647583   0.06057739 -0.03366089 -0.0413208
   0.05426025  0.00199127 -0.04977417 -0.01615906  0.02236938  0.04937744
  -0.07427979  0.01543427  0.03674316 -0.07714844  0.00384521  0.04898071
   0.04669189  0.0435791   0.05166626 -0.03117371  0.00643921 -0.0916748
  -0.06555176  0.04605103  0.03308105 -0.02362061 -0.05386353  0.05136108
  -0.05328369  0.00138664  0.0087204   0.0222168  -0.08197021  0.01593018
  -0.09448242 -0.01968384 -0.05157471 -0.02156067  0.09191895 -0.0456543
  -0.01366425  0.02568054  0.05508423 -0.06210327 -0.06109619  0.09179688
   0.034729    0.00032783  0.08184814 -0.00460052 -0.06396484 -0.07873535
  -0.07684326  0.03585815  0.03106689 -0.02568054 -0.09423828  0.09216309
   0.05581665 -0.07940674 -0.00190926  0.01980591 -0.01357269 -0.07611084
  -0.03887939 -0.06494141 -0.03253174  0.00991821  0.06130981  0.06057739
  -0.02391052 -0.05252075  0.05300903 -0.06097412  0.06945801  0.03237915
   0.07281494 -0.03497314  0.01681519 -0.01838684  0.03123474  0.05499268
   0.03588867 -0.06677246  0.01105499  0.08728027  0.07897949 -0.04669189
   0.01126862  0.08270264  0.07562256 -0.08111572 -0.07165527  0.0562439
   0.09436035  0.03012085  0.07299805  0.05389404 -0.06439209  0.03515625
   0.09405518  0.03613281 -0.04663086 -0.00576401 -0.03102112  0.0838623
  -0.04074097 -0.05682373 -0.0304718  -0.04257202  0.06616211  0.08886719
  -0.08056641 -0.00977325  0.0760498  -0.06884766 -0.05273438  0.04104614
   0.0186615   0.05349731 -0.05892944  0.05801392  0.07830811  0.00614548
  -0.06091309  0.04446411  0.00978851  0.00144386 -0.07788086  0.08276367
   0.07202148  0.08605957 -0.04882812  0.00289917  0.03555298  0.07757568
  -0.07965088  0.03540039 -0.0254364  -0.05508423  0.05841064 -0.03363037
   0.07727051  0.02099609  0.07696533 -0.0352478  -0.06634521 -0.01145172
  -0.05770874  0.02613831  0.06896973  0.02345276 -0.03134155 -0.03076172
  -0.0869751  -0.05670166 -0.04318237  0.01870728  0.06878662  0.08166504
   0.05862427  0.06976318  0.01977539 -0.0680542   0.07312012  0.04721069
   0.04644775  0.06045532 -0.07788086 -0.02279663  0.00743866  0.01916504
   0.05877686 -0.05581665  0.02497864  0.08215332 -0.04962158 -0.04550171
  -0.07220459  0.02761841 -0.00298882 -0.01675415  0.06939697 -0.08612061
   0.09387207  0.06481934  0.00206184  0.08013916 -0.00548172  0.01785278
   0.04898071 -0.06671143 -0.00177479 -0.04730225  0.02372742  0.05212402
  -0.06420898 -0.0300293  -0.04797363 -0.05340576 -0.06292725 -0.07714844
   0.0657959  -0.03717041 -0.0149765   0.06335449 -0.04147339 -0.05319214
   0.00527573  0.01927185  0.01180267  0.0838623   0.00623322 -0.00313187
   0.09326172  0.03146362  0.00914001  0.09161377  0.06488037 -0.06155396
   0.02760315 -0.06207275 -0.06124878 -0.01649475  0.06549072 -0.01605225
  -0.0793457  -0.02545166 -0.08441162 -0.04592896 -0.06707764  0.06787109
  -0.00608063  0.02279663 -0.0328064   0.04278564 -0.05740356 -0.04873657
   0.06732178 -0.05264282 -0.06866455  0.07745361 -0.03759766 -0.0319519
  -0.05053711  0.06628418  0.02203369 -0.06420898]]
After layer split4_output6 (1, 256) <class 'numpy.float32'> [[ 0.06011963  0.00928497  0.03005981 -0.03009033 -0.03494263  0.00979614
   0.04443359  0.0892334  -0.0647583   0.06057739 -0.03366089 -0.0413208
   0.05426025  0.00199127 -0.04977417 -0.01615906  0.02236938  0.04937744
  -0.07427979  0.01543427  0.03674316 -0.07714844  0.00384521  0.04898071
   0.04669189  0.0435791   0.05166626 -0.03117371  0.00643921 -0.0916748
  -0.06555176  0.04605103  0.03308105 -0.02362061 -0.05386353  0.05136108
  -0.05328369  0.00138664  0.0087204   0.0222168  -0.08197021  0.01593018
  -0.09448242 -0.01968384 -0.05157471 -0.02156067  0.09191895 -0.0456543
  -0.01366425  0.02568054  0.05508423 -0.06210327 -0.06109619  0.09179688
   0.034729    0.00032783  0.08184814 -0.00460052 -0.06396484 -0.07873535
  -0.07684326  0.03585815  0.03106689 -0.02568054 -0.09423828  0.09216309
   0.05581665 -0.07940674 -0.00190926  0.01980591 -0.01357269 -0.07611084
  -0.03887939 -0.06494141 -0.03253174  0.00991821  0.06130981  0.06057739
  -0.02391052 -0.05252075  0.05300903 -0.06097412  0.06945801  0.03237915
   0.07281494 -0.03497314  0.01681519 -0.01838684  0.03123474  0.05499268
   0.03588867 -0.06677246  0.01105499  0.08728027  0.07897949 -0.04669189
   0.01126862  0.08270264  0.07562256 -0.08111572 -0.07165527  0.0562439
   0.09436035  0.03012085  0.07299805  0.05389404 -0.06439209  0.03515625
   0.09405518  0.03613281 -0.04663086 -0.00576401 -0.03102112  0.0838623
  -0.04074097 -0.05682373 -0.0304718  -0.04257202  0.06616211  0.08886719
  -0.08056641 -0.00977325  0.0760498  -0.06884766 -0.05273438  0.04104614
   0.0186615   0.05349731 -0.05892944  0.05801392  0.07830811  0.00614548
  -0.06091309  0.04446411  0.00978851  0.00144386 -0.07788086  0.08276367
   0.07202148  0.08605957 -0.04882812  0.00289917  0.03555298  0.07757568
  -0.07965088  0.03540039 -0.0254364  -0.05508423  0.05841064 -0.03363037
   0.07727051  0.02099609  0.07696533 -0.0352478  -0.06634521 -0.01145172
  -0.05770874  0.02613831  0.06896973  0.02345276 -0.03134155 -0.03076172
  -0.0869751  -0.05670166 -0.04318237  0.01870728  0.06878662  0.08166504
   0.05862427  0.06976318  0.01977539 -0.0680542   0.07312012  0.04721069
   0.04644775  0.06045532 -0.07788086 -0.02279663  0.00743866  0.01916504
   0.05877686 -0.05581665  0.02497864  0.08215332 -0.04962158 -0.04550171
  -0.07220459  0.02761841 -0.00298882 -0.01675415  0.06939697 -0.08612061
   0.09387207  0.06481934  0.00206184  0.08013916 -0.00548172  0.01785278
   0.04898071 -0.06671143 -0.00177479 -0.04730225  0.02372742  0.05212402
  -0.06420898 -0.0300293  -0.04797363 -0.05340576 -0.06292725 -0.07714844
   0.0657959  -0.03717041 -0.0149765   0.06335449 -0.04147339 -0.05319214
   0.00527573  0.01927185  0.01180267  0.0838623   0.00623322 -0.00313187
   0.09326172  0.03146362  0.00914001  0.09161377  0.06488037 -0.06155396
   0.02760315 -0.06207275 -0.06124878 -0.01649475  0.06549072 -0.01605225
  -0.0793457  -0.02545166 -0.08441162 -0.04592896 -0.06707764  0.06787109
  -0.00608063  0.02279663 -0.0328064   0.04278564 -0.05740356 -0.04873657
   0.06732178 -0.05264282 -0.06866455  0.07745361 -0.03759766 -0.0319519
  -0.05053711  0.06628418  0.02203369 -0.06420898]]
After layer split4_output7 (1, 256) <class 'numpy.float32'> [[ 0.06011963  0.00928497  0.03005981 -0.03009033 -0.03494263  0.00979614
   0.04443359  0.0892334  -0.0647583   0.06057739 -0.03366089 -0.0413208
   0.05426025  0.00199127 -0.04977417 -0.01615906  0.02236938  0.04937744
  -0.07427979  0.01543427  0.03674316 -0.07714844  0.00384521  0.04898071
   0.04669189  0.0435791   0.05166626 -0.03117371  0.00643921 -0.0916748
  -0.06555176  0.04605103  0.03308105 -0.02362061 -0.05386353  0.05136108
  -0.05328369  0.00138664  0.0087204   0.0222168  -0.08197021  0.01593018
  -0.09448242 -0.01968384 -0.05157471 -0.02156067  0.09191895 -0.0456543
  -0.01366425  0.02568054  0.05508423 -0.06210327 -0.06109619  0.09179688
   0.034729    0.00032783  0.08184814 -0.00460052 -0.06396484 -0.07873535
  -0.07684326  0.03585815  0.03106689 -0.02568054 -0.09423828  0.09216309
   0.05581665 -0.07940674 -0.00190926  0.01980591 -0.01357269 -0.07611084
  -0.03887939 -0.06494141 -0.03253174  0.00991821  0.06130981  0.06057739
  -0.02391052 -0.05252075  0.05300903 -0.06097412  0.06945801  0.03237915
   0.07281494 -0.03497314  0.01681519 -0.01838684  0.03123474  0.05499268
   0.03588867 -0.06677246  0.01105499  0.08728027  0.07897949 -0.04669189
   0.01126862  0.08270264  0.07562256 -0.08111572 -0.07165527  0.0562439
   0.09436035  0.03012085  0.07299805  0.05389404 -0.06439209  0.03515625
   0.09405518  0.03613281 -0.04663086 -0.00576401 -0.03102112  0.0838623
  -0.04074097 -0.05682373 -0.0304718  -0.04257202  0.06616211  0.08886719
  -0.08056641 -0.00977325  0.0760498  -0.06884766 -0.05273438  0.04104614
   0.0186615   0.05349731 -0.05892944  0.05801392  0.07830811  0.00614548
  -0.06091309  0.04446411  0.00978851  0.00144386 -0.07788086  0.08276367
   0.07202148  0.08605957 -0.04882812  0.00289917  0.03555298  0.07757568
  -0.07965088  0.03540039 -0.0254364  -0.05508423  0.05841064 -0.03363037
   0.07727051  0.02099609  0.07696533 -0.0352478  -0.06634521 -0.01145172
  -0.05770874  0.02613831  0.06896973  0.02345276 -0.03134155 -0.03076172
  -0.0869751  -0.05670166 -0.04318237  0.01870728  0.06878662  0.08166504
   0.05862427  0.06976318  0.01977539 -0.0680542   0.07312012  0.04721069
   0.04644775  0.06045532 -0.07788086 -0.02279663  0.00743866  0.01916504
   0.05877686 -0.05581665  0.02497864  0.08215332 -0.04962158 -0.04550171
  -0.07220459  0.02761841 -0.00298882 -0.01675415  0.06939697 -0.08612061
   0.09387207  0.06481934  0.00206184  0.08013916 -0.00548172  0.01785278
   0.04898071 -0.06671143 -0.00177479 -0.04730225  0.02372742  0.05212402
  -0.06420898 -0.0300293  -0.04797363 -0.05340576 -0.06292725 -0.07714844
   0.0657959  -0.03717041 -0.0149765   0.06335449 -0.04147339 -0.05319214
   0.00527573  0.01927185  0.01180267  0.0838623   0.00623322 -0.00313187
   0.09326172  0.03146362  0.00914001  0.09161377  0.06488037 -0.06155396
   0.02760315 -0.06207275 -0.06124878 -0.01649475  0.06549072 -0.01605225
  -0.0793457  -0.02545166 -0.08441162 -0.04592896 -0.06707764  0.06787109
  -0.00608063  0.02279663 -0.0328064   0.04278564 -0.05740356 -0.04873657
   0.06732178 -0.05264282 -0.06866455  0.07745361 -0.03759766 -0.0319519
  -0.05053711  0.06628418  0.02203369 -0.06420898]]
After layer split4_output8 (1, 256) <class 'numpy.float32'> [[ 0.06011963  0.00928497  0.03005981 -0.03009033 -0.03494263  0.00979614
   0.04443359  0.0892334  -0.0647583   0.06057739 -0.03366089 -0.0413208
   0.05426025  0.00199127 -0.04977417 -0.01615906  0.02236938  0.04937744
  -0.07427979  0.01543427  0.03674316 -0.07714844  0.00384521  0.04898071
   0.04669189  0.0435791   0.05166626 -0.03117371  0.00643921 -0.0916748
  -0.06555176  0.04605103  0.03308105 -0.02362061 -0.05386353  0.05136108
  -0.05328369  0.00138664  0.0087204   0.0222168  -0.08197021  0.01593018
  -0.09448242 -0.01968384 -0.05157471 -0.02156067  0.09191895 -0.0456543
  -0.01366425  0.02568054  0.05508423 -0.06210327 -0.06109619  0.09179688
   0.034729    0.00032783  0.08184814 -0.00460052 -0.06396484 -0.07873535
  -0.07684326  0.03585815  0.03106689 -0.02568054 -0.09423828  0.09216309
   0.05581665 -0.07940674 -0.00190926  0.01980591 -0.01357269 -0.07611084
  -0.03887939 -0.06494141 -0.03253174  0.00991821  0.06130981  0.06057739
  -0.02391052 -0.05252075  0.05300903 -0.06097412  0.06945801  0.03237915
   0.07281494 -0.03497314  0.01681519 -0.01838684  0.03123474  0.05499268
   0.03588867 -0.06677246  0.01105499  0.08728027  0.07897949 -0.04669189
   0.01126862  0.08270264  0.07562256 -0.08111572 -0.07165527  0.0562439
   0.09436035  0.03012085  0.07299805  0.05389404 -0.06439209  0.03515625
   0.09405518  0.03613281 -0.04663086 -0.00576401 -0.03102112  0.0838623
  -0.04074097 -0.05682373 -0.0304718  -0.04257202  0.06616211  0.08886719
  -0.08056641 -0.00977325  0.0760498  -0.06884766 -0.05273438  0.04104614
   0.0186615   0.05349731 -0.05892944  0.05801392  0.07830811  0.00614548
  -0.06091309  0.04446411  0.00978851  0.00144386 -0.07788086  0.08276367
   0.07202148  0.08605957 -0.04882812  0.00289917  0.03555298  0.07757568
  -0.07965088  0.03540039 -0.0254364  -0.05508423  0.05841064 -0.03363037
   0.07727051  0.02099609  0.07696533 -0.0352478  -0.06634521 -0.01145172
  -0.05770874  0.02613831  0.06896973  0.02345276 -0.03134155 -0.03076172
  -0.0869751  -0.05670166 -0.04318237  0.01870728  0.06878662  0.08166504
   0.05862427  0.06976318  0.01977539 -0.0680542   0.07312012  0.04721069
   0.04644775  0.06045532 -0.07788086 -0.02279663  0.00743866  0.01916504
   0.05877686 -0.05581665  0.02497864  0.08215332 -0.04962158 -0.04550171
  -0.07220459  0.02761841 -0.00298882 -0.01675415  0.06939697 -0.08612061
   0.09387207  0.06481934  0.00206184  0.08013916 -0.00548172  0.01785278
   0.04898071 -0.06671143 -0.00177479 -0.04730225  0.02372742  0.05212402
  -0.06420898 -0.0300293  -0.04797363 -0.05340576 -0.06292725 -0.07714844
   0.0657959  -0.03717041 -0.0149765   0.06335449 -0.04147339 -0.05319214
   0.00527573  0.01927185  0.01180267  0.0838623   0.00623322 -0.00313187
   0.09326172  0.03146362  0.00914001  0.09161377  0.06488037 -0.06155396
   0.02760315 -0.06207275 -0.06124878 -0.01649475  0.06549072 -0.01605225
  -0.0793457  -0.02545166 -0.08441162 -0.04592896 -0.06707764  0.06787109
  -0.00608063  0.02279663 -0.0328064   0.04278564 -0.05740356 -0.04873657
   0.06732178 -0.05264282 -0.06866455  0.07745361 -0.03759766 -0.0319519
  -0.05053711  0.06628418  0.02203369 -0.06420898]]
After layer split4_output9 (1, 256) <class 'numpy.float32'> [[ 0.06011963  0.00928497  0.03005981 -0.03009033 -0.03494263  0.00979614
   0.04443359  0.0892334  -0.0647583   0.06057739 -0.03366089 -0.0413208
   0.05426025  0.00199127 -0.04977417 -0.01615906  0.02236938  0.04937744
  -0.07427979  0.01543427  0.03674316 -0.07714844  0.00384521  0.04898071
   0.04669189  0.0435791   0.05166626 -0.03117371  0.00643921 -0.0916748
  -0.06555176  0.04605103  0.03308105 -0.02362061 -0.05386353  0.05136108
  -0.05328369  0.00138664  0.0087204   0.0222168  -0.08197021  0.01593018
  -0.09448242 -0.01968384 -0.05157471 -0.02156067  0.09191895 -0.0456543
  -0.01366425  0.02568054  0.05508423 -0.06210327 -0.06109619  0.09179688
   0.034729    0.00032783  0.08184814 -0.00460052 -0.06396484 -0.07873535
  -0.07684326  0.03585815  0.03106689 -0.02568054 -0.09423828  0.09216309
   0.05581665 -0.07940674 -0.00190926  0.01980591 -0.01357269 -0.07611084
  -0.03887939 -0.06494141 -0.03253174  0.00991821  0.06130981  0.06057739
  -0.02391052 -0.05252075  0.05300903 -0.06097412  0.06945801  0.03237915
   0.07281494 -0.03497314  0.01681519 -0.01838684  0.03123474  0.05499268
   0.03588867 -0.06677246  0.01105499  0.08728027  0.07897949 -0.04669189
   0.01126862  0.08270264  0.07562256 -0.08111572 -0.07165527  0.0562439
   0.09436035  0.03012085  0.07299805  0.05389404 -0.06439209  0.03515625
   0.09405518  0.03613281 -0.04663086 -0.00576401 -0.03102112  0.0838623
  -0.04074097 -0.05682373 -0.0304718  -0.04257202  0.06616211  0.08886719
  -0.08056641 -0.00977325  0.0760498  -0.06884766 -0.05273438  0.04104614
   0.0186615   0.05349731 -0.05892944  0.05801392  0.07830811  0.00614548
  -0.06091309  0.04446411  0.00978851  0.00144386 -0.07788086  0.08276367
   0.07202148  0.08605957 -0.04882812  0.00289917  0.03555298  0.07757568
  -0.07965088  0.03540039 -0.0254364  -0.05508423  0.05841064 -0.03363037
   0.07727051  0.02099609  0.07696533 -0.0352478  -0.06634521 -0.01145172
  -0.05770874  0.02613831  0.06896973  0.02345276 -0.03134155 -0.03076172
  -0.0869751  -0.05670166 -0.04318237  0.01870728  0.06878662  0.08166504
   0.05862427  0.06976318  0.01977539 -0.0680542   0.07312012  0.04721069
   0.04644775  0.06045532 -0.07788086 -0.02279663  0.00743866  0.01916504
   0.05877686 -0.05581665  0.02497864  0.08215332 -0.04962158 -0.04550171
  -0.07220459  0.02761841 -0.00298882 -0.01675415  0.06939697 -0.08612061
   0.09387207  0.06481934  0.00206184  0.08013916 -0.00548172  0.01785278
   0.04898071 -0.06671143 -0.00177479 -0.04730225  0.02372742  0.05212402
  -0.06420898 -0.0300293  -0.04797363 -0.05340576 -0.06292725 -0.07714844
   0.0657959  -0.03717041 -0.0149765   0.06335449 -0.04147339 -0.05319214
   0.00527573  0.01927185  0.01180267  0.0838623   0.00623322 -0.00313187
   0.09326172  0.03146362  0.00914001  0.09161377  0.06488037 -0.06155396
   0.02760315 -0.06207275 -0.06124878 -0.01649475  0.06549072 -0.01605225
  -0.0793457  -0.02545166 -0.08441162 -0.04592896 -0.06707764  0.06787109
  -0.00608063  0.02279663 -0.0328064   0.04278564 -0.05740356 -0.04873657
   0.06732178 -0.05264282 -0.06866455  0.07745361 -0.03759766 -0.0319519
  -0.05053711  0.06628418  0.02203369 -0.06420898]]
After layer encoder_birnn_forward_l0_t0_i2h_output (1, 1024) <class 'numpy.float32'> [[-0.07534768 -0.03747175 -0.05188336 ...,  0.05627933 -0.06602892
  -0.01455931]]
After layer encoder_birnn_forward_l0_begin_state_0_0 (1, 256) <class 'numpy.float32'> [[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
   0.  0.  0.  0.]]
After layer encoder_birnn_forward_l0_t0_h2h_output (1, 1024) <class 'numpy.float32'> [[ 0.01966858  0.00881195  0.05056763 ...,  0.0147934   0.02441406
   0.02816772]]
After layer _plus1026_0 (1, 1024) <class 'numpy.float32'> [[-0.0556791  -0.0286598  -0.00131574 ...,  0.07107273 -0.04161486
   0.01360841]]
After layer encoder_birnn_forward_l0_t0_slice_output0 (1, 256) <class 'numpy.float32'> [[-0.0556791  -0.0286598  -0.00131574 -0.01140913  0.11776476  0.08399388
   0.04196896  0.05859178 -0.04454242  0.00779697  0.08002147  0.03112211
   0.0207901  -0.04673263  0.13967043  0.12729041  0.00675085  0.02030327
   0.03594784  0.0559453   0.00546577  0.11212671  0.03221136 -0.0264401
   0.05218098  0.11914564  0.05534595  0.00810954  0.04232707  0.10029479
  -0.00124552 -0.01301795  0.07366932  0.1554848   0.1642397   0.03785751
   0.02353834  0.09435764  0.09613167  0.02987294 -0.04027504  0.04886877
   0.08343968  0.01071632  0.13995831  0.00971136 -0.01033353  0.03428957
   0.03480783 -0.08046521  0.05013857 -0.02684003  0.15781102  0.03770631
   0.02261463  0.03953432  0.02093019 -0.03355839  0.03625828  0.00696502
   0.13679767  0.02038462  0.05147359  0.05483426  0.09786423  0.03291215
   0.03474918  0.07510623  0.10216177  0.10064299 -0.01073425  0.12115736
   0.097083    0.04596271  0.13071586  0.04585212  0.06937732  0.07783112
   0.12689099  0.12231851  0.01598007  0.04749111  0.2388522   0.03596598
   0.04659692 -0.00308827  0.03198355 -0.00961334  0.24068478  0.12751099
   0.04720712 -0.01601657  0.00221969  0.02880651  0.00375498  0.05689866
   0.07328016  0.07642028  0.0506499   0.05753985  0.09231592 -0.01473569
   0.06882901 -0.00919659  0.01703406  0.07665586  0.00618024  0.06275605
   0.10945137  0.05229514  0.04208701 -0.01029145  0.18270282  0.1861005
  -0.01978602  0.04427882  0.06623856  0.04428472 -0.01856891  0.13361366
   0.04160494  0.1131047   0.05581445  0.07910872  0.12558505  0.06046853
   0.12997353  0.07009324  0.04020599  0.12673005  0.06760967  0.04129472
   0.02813324  0.03571163  0.06325914  0.11525127  0.07534748  0.07158422
   0.18537118  0.08127423  0.09524005  0.05176918  0.08217099  0.0833088
  -0.01234468  0.02456478  0.08507371  0.05143853  0.21110831  0.0307523
   0.05893184  0.00662626  0.13182256 -0.01193079  0.01095331 -0.00077945
   0.06956959 -0.01678957  0.05540776 -0.06315314  0.08546367  0.05627788
   0.04094958 -0.04288967  0.05185365  0.01765546  0.01649307  0.06978213
   0.09958436  0.05183931  0.0860578   0.16941115 -0.02833702 -0.00757372
   0.02728825  0.08181061  0.07352169 -0.03591149  0.07436466 -0.04838338
   0.07174205  0.08615039  0.03309757  0.08467898  0.06792907  0.0153846
   0.04508459  0.1259995   0.00389738  0.02066788 -0.00936782 -0.02211023
   0.00370872  0.05214266 -0.02412929  0.09283058  0.14196298  0.0490464
   0.10419524  0.02261299  0.07553954  0.07265025  0.11870893  0.07205074
  -0.04553016  0.11226476  0.02250671  0.01912555  0.13300347 -0.0426501
   0.00366768  0.14034641  0.01664553  0.12652567  0.01716773 -0.0054732
  -0.0374583   0.09430987  0.04394905 -0.00582765  0.00295788  0.03055829
   0.18573655  0.01236359  0.02748045  0.14321882  0.04377722 -0.00500796
   0.01652432 -0.00650034  0.05054776  0.07455771  0.01442519  0.03301093
  -0.02776115 -0.10907149  0.01569781  0.03295617 -0.00508699  0.12297335
   0.05323039  0.08041926  0.17490067  0.0740828   0.03141984  0.15509103
   0.0393949  -0.06283318  0.01483885  0.00749964  0.05917566 -0.03774747
  -0.07074462 -0.00213026  0.06272147  0.11571452]]
After layer encoder_birnn_forward_l0_t0_slice_output1 (1, 256) <class 'numpy.float32'> [[  5.61110191e-02   6.37755077e-03   3.42057645e-02   4.00999188e-02
   -4.04495448e-02   2.70763151e-02   7.83020034e-02   1.11989453e-01
    4.46947664e-02   8.68665725e-02  -6.58906251e-03  -2.57066563e-02
    6.01813085e-02  -7.79956952e-02   7.59920031e-02   4.59819548e-02
   -8.07516426e-02   9.04760212e-02   6.31720275e-02   7.74100050e-02
    2.22442560e-02   1.20127574e-01   5.09440079e-02   2.43004840e-02
    1.09425753e-01   2.33720336e-02   8.94675404e-02  -1.20902341e-02
    6.28443956e-02   6.86112791e-02  -5.06067574e-02   3.79262045e-02
    5.49830943e-02   7.68160820e-02   7.60075226e-02   4.43452932e-02
    1.52174626e-02   3.76139134e-02   5.20625114e-02   3.34733203e-02
    2.61111818e-02   9.69301164e-03   8.23262781e-02   1.22250589e-02
    8.36035758e-02   2.01929733e-03   8.73695761e-02   5.37451543e-02
    2.27873418e-02   5.29728569e-02   1.78013127e-02   1.47373360e-02
    9.72535610e-02  -7.60580972e-03   2.87142396e-02   5.55205308e-02
    1.09048463e-01  -9.24761593e-03   1.06584765e-01   1.31066546e-01
    1.82599649e-02  -1.92279778e-02  -1.24055184e-02   1.80540085e-01
    9.04749930e-02  -1.73901804e-02   1.34527441e-02   7.99269006e-02
    2.22788490e-02   1.26480907e-01   4.32729684e-02   4.02070954e-03
   -1.04753673e-02   3.07151824e-02   7.04749078e-02   1.16730161e-01
    1.16217807e-01   9.97294635e-02   1.35390416e-01   5.42838648e-02
    5.02293557e-02   2.60037482e-02   2.27661639e-01  -9.10887122e-03
    1.10146128e-01  -3.77247185e-02   2.67801471e-02   5.47650307e-02
    2.31051445e-01  -1.32427476e-02   9.23863053e-03   8.48726183e-02
    9.79124084e-02   1.13330074e-02   4.13126498e-03   3.55914123e-02
    6.63987696e-02  -4.56715375e-03   6.34214580e-02   5.88571429e-02
    5.53045794e-02  -5.72304353e-02   4.09897529e-02   1.02627501e-02
    3.97044420e-02   4.50782403e-02   3.58995423e-03  -4.02609855e-02
   -1.48401111e-02  -2.48886794e-02   9.06062126e-03   4.58842255e-02
    9.92669985e-02   1.01442538e-01  -2.76455656e-02   1.32421367e-02
   -6.17773086e-03   1.24534898e-01   5.84688783e-02   2.98721176e-02
    8.96492042e-03   3.28334086e-02   1.03087261e-01  -1.37618259e-02
    1.87591054e-02  -9.63995606e-03   4.23466489e-02  -1.29437670e-02
    1.09766703e-02   1.17592141e-01   5.50252646e-02  -3.15230340e-03
    7.71716610e-03   5.83510846e-03  -5.32421470e-03   9.10174400e-02
    2.78278366e-02   5.03451899e-02   3.66156437e-02  -5.84717840e-04
    2.77385470e-02   4.91731726e-02   1.31565005e-01  -9.98169184e-03
   -2.55237073e-02   5.57810739e-02  -4.09002304e-02   5.27806729e-02
    2.26922333e-03   4.51287404e-02   4.95684408e-02   6.21718578e-02
    1.02287456e-01   9.17063653e-02  -3.93676460e-02  -4.00854349e-02
   -2.46675685e-02   3.87556776e-02  -1.11990981e-02   8.02735761e-02
    1.37204349e-01   6.68849498e-02  -7.19017684e-02   3.42538022e-02
    3.10161188e-02  -7.28189722e-02   2.37877052e-02   5.67808338e-02
    2.31303666e-02   4.85822484e-02  -2.51331702e-02   1.26748934e-01
   -4.48168591e-02   5.50540760e-02   1.94648597e-02   5.29774427e-02
    3.18505503e-02   1.23363018e-01  -4.92374972e-02   1.54509954e-02
    5.21820746e-02   3.07692587e-03   4.05182615e-02   4.32072878e-02
   -1.71128213e-02  -1.81237385e-02   5.12528829e-02   8.52809548e-02
    2.16558222e-02  -1.35593824e-02   1.80191211e-02   6.47565871e-02
   -4.44882736e-03   4.00045328e-02   3.19468528e-02   8.98767710e-02
    2.15557024e-01   1.07305646e-02  -4.90181968e-02   5.19604385e-02
    9.71216261e-02   1.55404031e-01   1.05239265e-01   1.00094229e-02
    4.27453443e-02  -8.88194703e-03   1.47083431e-01   4.90457788e-02
   -2.26425007e-04   3.03096473e-02   2.21908931e-02   3.34060900e-02
   -1.68165714e-02   1.20235428e-01   1.52530983e-01  -6.46141320e-02
   -1.31490342e-02  -1.66928470e-02   7.11613335e-03  -2.57671475e-02
    3.59986722e-03   6.22699857e-02   5.81031032e-02   1.23694956e-01
    8.06296691e-02   9.21138525e-02   7.22490922e-02   3.59555818e-02
    7.95457512e-04  -2.44277716e-02   9.98631865e-02   5.92526235e-02
    2.56842431e-02   4.35525812e-02   7.04263151e-02   7.65143037e-02
    1.60361417e-02   3.44417356e-02   5.96034005e-02   7.33873844e-02
    5.49913123e-02   5.35337515e-02   1.74535915e-01   8.95608217e-02
    2.34404840e-02   2.18618624e-02   3.62521186e-02  -1.16855502e-01
    7.73267895e-02   9.21044201e-02   4.31365259e-02  -5.47422692e-02
    1.51009560e-02  -1.30211450e-02   3.48694585e-02   7.47899041e-02]]
After layer encoder_birnn_forward_l0_t0_slice_output2 (1, 256) <class 'numpy.float32'> [[ 0.01442602  0.08985765 -0.0246505  -0.03507829  0.11306231 -0.02542904
   0.04425748 -0.14561167  0.05860169  0.01550213  0.06542625  0.02282303
   0.08802076 -0.043451    0.10362687 -0.0308244  -0.01739854  0.01676793
  -0.0342481  -0.0188802   0.02928035 -0.11079343 -0.13330805  0.11473554
   0.00827667 -0.06242526 -0.04937554 -0.05295309 -0.04921974  0.03727511
   0.05161566 -0.05962642  0.0370824  -0.02697257  0.07586336  0.03282876
   0.03683729 -0.02924652 -0.05002219 -0.030706   -0.05464294  0.10080744
  -0.02065526  0.07163978 -0.08450627 -0.08241037  0.01336752  0.08482074
   0.05986856 -0.01903027 -0.00867793 -0.07187478  0.0821258  -0.09993796
   0.03093864  0.12793995  0.03556035 -0.06538852  0.0841925  -0.05203005
   0.07277381 -0.0671747   0.01243305  0.0193432  -0.01136849 -0.02234524
   0.02035894  0.07079621 -0.00396366 -0.0702822  -0.00141762 -0.09488408
  -0.13112879  0.07611851  0.14895065 -0.00501571  0.1395281  -0.14169297
   0.12393317 -0.04819426  0.09007523 -0.04652194  0.15475266  0.02531408
   0.0192247  -0.03921976  0.05933269 -0.12328334 -0.0639659   0.07962449
  -0.03005466  0.06768202 -0.09096234 -0.05229282 -0.08491163  0.04601749
   0.01956183 -0.14977083  0.07440074  0.10164    -0.11818871 -0.01776227
   0.00152223  0.01720612  0.04752515 -0.08167391  0.01747449  0.11662669
   0.08667141  0.05661745  0.02546565 -0.08592106  0.15001477  0.17119391
  -0.06569439 -0.00920434  0.06058142  0.15645511  0.02040492  0.03935065
   0.01340695 -0.10714617  0.12316614 -0.12399849  0.09482633 -0.02589716
   0.04701348  0.09404151  0.00591205 -0.15929069  0.00097291  0.02815237
   0.06861836 -0.04415073  0.0707082   0.0926857   0.0574676   0.12782735
  -0.10034446  0.00831586 -0.06230689  0.14154989 -0.10665889 -0.07932595
   0.11227385  0.09523433  0.05529264 -0.06473298  0.14029457 -0.06915127
  -0.01551467  0.01283517  0.08929989  0.10239127  0.06839874 -0.0946169
   0.0805897   0.04460294  0.0595786   0.01994812  0.01613168  0.05278022
  -0.00961735  0.02337065 -0.06285959  0.06140839 -0.1477779  -0.01480053
  -0.1128663  -0.05438219  0.00635818 -0.01024275 -0.0144705  -0.01146167
   0.01985861 -0.03893396  0.16394943  0.0035176  -0.0509786   0.00872859
   0.05753176  0.07594449  0.06535967  0.00309033  0.02244098 -0.08091915
   0.00780442  0.0272444   0.04348342  0.02085236  0.02977085 -0.03537236
  -0.14854546  0.18553321  0.00329152 -0.16616543 -0.08740495 -0.08986379
   0.06722424  0.10512165  0.10763257 -0.11114688 -0.00277185 -0.0133023
  -0.08464622 -0.00842679  0.02971943  0.07436685  0.05216786 -0.00242724
   0.01423646  0.07963008  0.09354582 -0.03056005  0.00087474 -0.00289244
  -0.06584343 -0.09074649 -0.07341715  0.01015343 -0.05037348  0.03938083
   0.0329879  -0.16465253  0.08697417 -0.03754794 -0.12598655 -0.02463608
   0.01454054 -0.06445926 -0.04676479 -0.04871688  0.06716578  0.04980624
  -0.06558447 -0.02021191  0.05035466  0.10038774 -0.03604236 -0.00259098
   0.041525    0.08972299 -0.00609495 -0.09359732  0.05655799 -0.08912382
   0.05279034 -0.05394557 -0.08524659  0.02639305 -0.07754316  0.01173801
   0.02206894 -0.11622756  0.06993619  0.0010551 ]]
After layer encoder_birnn_forward_l0_t0_slice_output3 (1, 256) <class 'numpy.float32'> [[-0.03274529  0.06784149  0.13342172  0.02437791  0.01905258  0.02928729
   0.07070694 -0.03636044  0.10885561  0.02334932  0.13109148  0.06089649
   0.01716607  0.16004524  0.12521142  0.09552448  0.02117382  0.05606945
   0.16312361  0.05069569  0.06977333  0.06972693  0.01492807  0.028483
   0.04944843  0.0396544   0.05126788  0.08035094  0.00241544  0.02744813
   0.07026626  0.0330458   0.03365315  0.06756796  0.05001155  0.11550131
   0.01583691  0.08562165  0.03345282  0.02437513  0.10899965  0.1475895
   0.04288308  0.01568142  0.13824826  0.06620941  0.03387198  0.0040899
   0.06619941  0.01453029  0.05177356  0.05136227  0.08463069  0.04285615
   0.02245756  0.04110967  0.03642733  0.1348404   0.01041026 -0.00161963
  -0.00173647 -0.02001195  0.01525144  0.04489954 -0.06211288 -0.05163948
   0.01176254  0.09941902  0.02848792  0.0333976   0.02224533 -0.0120686
   0.07352036  0.10691497  0.1138609   0.1231463   0.01569626  0.09963541
   0.16579857  0.13978091  0.1082851   0.04287031  0.217161    0.04841728
   0.09736304  0.08856192 -0.00583322  0.06206135  0.18020301  0.098503
   0.00366318  0.1087933  -0.00156898  0.08199897  0.05560887  0.10995704
   0.05150251  0.0538755   0.00581207  0.1161383   0.04801283 -0.00257935
   0.05485086  0.12797882  0.06118177  0.02739297  0.05917792  0.02765096
   0.11891595  0.0218874   0.07014744  0.10143635  0.22608863  0.13754122
  -0.03459713 -0.02703489  0.09914078  0.05799561 -0.01395732  0.03846706
  -0.00939881  0.10226639  0.08793671  0.08007357  0.05060132  0.10337217
   0.10481924  0.12271839 -0.01061966  0.19100618  0.03400265 -0.02172374
   0.055766    0.01683035  0.00961478  0.07173359  0.11474179 -0.04210618
   0.11722015  0.02579113  0.03736414  0.03358707  0.08063815 -0.01782093
  -0.00276922  0.05376037  0.01741675  0.1044172   0.05543021  0.05632442
   0.0982296   0.04854123  0.01056137  0.06860995 -0.02246547  0.04440694
   0.00602906  0.00531707 -0.0218057  -0.06217971  0.11952615 -0.01488678
  -0.00390243  0.16934654  0.04399204  0.05408711  0.08231309  0.0791523
   0.13832673  0.08088652  0.00336391  0.11646936 -0.06763145  0.10869931
   0.09207979 -0.00539912  0.05135006  0.06480247  0.02512966  0.07778203
   0.11021176  0.10484104  0.05387038  0.10264448 -0.01756044 -0.02394738
   0.01231269  0.05421443 -0.0031321  -0.01345544  0.1278114   0.01409923
   0.11627661  0.10694186 -0.01634409  0.12464692  0.1240107  -0.00405114
   0.12044656  0.1141134   0.07275654  0.03445178  0.06085895  0.06240714
  -0.04940309  0.08258291  0.04253967  0.11245546  0.17056505  0.05383268
   0.01404369  0.02171224  0.04941658  0.0950118   0.16115534 -0.00792173
   0.01325233  0.12612528 -0.08773308  0.06402726  0.01158555  0.02942474
   0.001637    0.05094798  0.08118829  0.07412296  0.02609978 -0.00747393
  -0.02454234  0.03494563  0.03861347  0.04913292  0.09832885  0.00824627
  -0.00203139  0.13993435  0.08295287 -0.08391299  0.02569679  0.13505806
   0.02049297 -0.05336072  0.19465867  0.08977111 -0.01876258  0.01312573
  -0.05175149 -0.06426501  0.01678206  0.02587216  0.01238002  0.08202513
   0.02094716  0.07107273 -0.04161486  0.01360841]]
After layer encoder_birnn_forward_l0_t0_o_output (1, 256) <class 'numpy.float32'> [[ 0.4918144   0.51695389  0.533306    0.50609416  0.50476301  0.5073213
   0.51766938  0.49091092  0.52718705  0.50583708  0.53272599  0.51521945
   0.50429142  0.53992617  0.53126204  0.52386296  0.50529325  0.51401371
   0.54069072  0.51267123  0.51743627  0.5174247   0.50373197  0.50712025
   0.51235962  0.50991231  0.51281416  0.52007693  0.50060385  0.50686157
   0.51755935  0.50826073  0.50841248  0.51688558  0.51250029  0.52884328
   0.50395918  0.52139235  0.50836241  0.5060935   0.52722299  0.5368306
   0.51071912  0.50392032  0.5345071   0.51654631  0.5084672   0.50102246
   0.51654381  0.50363255  0.51294053  0.51283777  0.52114505  0.51071239
   0.50561416  0.51027596  0.5091058   0.5336591   0.50260258  0.49959508
   0.49956587  0.49499717  0.50381279  0.51122302  0.48447675  0.48709297
   0.5029406   0.52483433  0.5071215   0.50834864  0.50556111  0.4969829
   0.51837182  0.52670336  0.52843451  0.53074771  0.50392401  0.52488828
   0.54135495  0.53488845  0.52704483  0.51071596  0.55407792  0.51210195
   0.52432156  0.52212602  0.49854168  0.51551038  0.54492927  0.52460587
   0.50091583  0.52717155  0.49960774  0.52048826  0.51389861  0.52746159
   0.51287282  0.51346564  0.50145304  0.52900201  0.51200092  0.4993552
   0.51370931  0.53195107  0.51529068  0.5068478   0.51479018  0.50691229
   0.52969396  0.50547165  0.51752967  0.52533734  0.55628258  0.5343312
   0.4913516   0.4932417   0.5247649   0.51449484  0.49651071  0.5096156
   0.49765027  0.52554435  0.52197003  0.52000767  0.51264763  0.52582002
   0.52618086  0.53064114  0.49734509  0.54760689  0.50849986  0.49456927
   0.51393789  0.50420749  0.50240368  0.51792574  0.52865404  0.48947501
   0.52927154  0.50644743  0.50933993  0.50839597  0.52014863  0.49554491
   0.49930769  0.51343685  0.50435412  0.52608061  0.51385403  0.51407737
   0.52453768  0.51213288  0.50264031  0.51714575  0.49438384  0.51109987
   0.50150728  0.5013293   0.4945488   0.48446006  0.52984601  0.49627841
   0.49902439  0.54223573  0.51099622  0.51351851  0.52056664  0.51977777
   0.53452665  0.52021062  0.50084096  0.5290845   0.4830986   0.52714813
   0.5230037   0.49865022  0.51283473  0.51619494  0.50628209  0.5194357
   0.52752507  0.52618629  0.51346439  0.52563864  0.49561003  0.49401343
   0.5030781   0.51355028  0.49921694  0.49663618  0.53190941  0.50352472
   0.52903646  0.52671003  0.49591404  0.53112149  0.530963    0.49898723
   0.53007531  0.5284974   0.51818109  0.5086121   0.51521009  0.51559669
   0.48765171  0.520634    0.51063329  0.52808428  0.54253817  0.51345491
   0.50351089  0.50542784  0.51235163  0.52373511  0.5402019   0.49801958
   0.50331306  0.53148961  0.47808078  0.51600134  0.50289637  0.50735569
   0.50040925  0.51273423  0.52028596  0.51852226  0.50652456  0.49813148
   0.49386469  0.50873554  0.5096522   0.51228076  0.52456242  0.50206161
   0.49949214  0.53492659  0.52072638  0.47903401  0.50642383  0.53371328
   0.50512308  0.48666298  0.54851156  0.52242768  0.49530947  0.50328141
   0.48706502  0.48393926  0.50419545  0.5064677   0.50309497  0.52049482
   0.50523663  0.51776069  0.4895978   0.50340205]]
After layer encoder_birnn_forward_l0_t0_f_output (1, 256) <class 'numpy.float32'> [[ 0.51402408  0.50159442  0.50855064  0.51002365  0.48988897  0.5067687
   0.51956552  0.52796811  0.51117182  0.521703    0.49835274  0.49357367
   0.51504081  0.48051092  0.51898885  0.51149344  0.47982305  0.52260357
   0.51578778  0.51934284  0.50556082  0.52999586  0.51273322  0.50607479
   0.52732915  0.50584275  0.52235198  0.49697748  0.51570594  0.51714611
   0.487351    0.50948042  0.51374233  0.51919454  0.51899272  0.5110845
   0.50380427  0.50940239  0.51301271  0.50836754  0.50652742  0.50242323
   0.52056998  0.50305629  0.52088875  0.50050485  0.52182853  0.51343304
   0.50569659  0.5132401   0.50445026  0.50368428  0.5242942   0.49809855
   0.50717807  0.51387656  0.52723509  0.49768806  0.52662098  0.53271985
   0.50456488  0.49519318  0.49689868  0.54501283  0.52260333  0.49565256
   0.50336313  0.51997107  0.50556946  0.53157812  0.51081657  0.50100517
   0.49738118  0.50767821  0.51761144  0.52914947  0.5290218   0.5249117
   0.53379595  0.51356769  0.51255471  0.5065006   0.55667084  0.4977228
   0.52750868  0.49056989  0.50669461  0.51368785  0.55750728  0.49668932
   0.50230962  0.52120543  0.52445859  0.50283325  0.50103283  0.50889695
   0.51659358  0.49885821  0.51585007  0.51471007  0.51382267  0.48569629
   0.51024604  0.50256568  0.50992483  0.51126766  0.50089747  0.48993614
   0.49629006  0.4937782   0.50226516  0.51146907  0.52479643  0.52533895
   0.49308902  0.5033105   0.49845555  0.53109354  0.51461309  0.50746751
   0.50224125  0.50820762  0.52574903  0.49655962  0.50468963  0.49759007
   0.51058507  0.49676409  0.50274414  0.52936423  0.51375288  0.49921197
   0.50192928  0.50145876  0.49866894  0.5227387   0.50695658  0.51258367
   0.50915283  0.49985376  0.50693417  0.51229084  0.53284389  0.49750459
   0.49361941  0.51394165  0.4897764   0.51319212  0.50056732  0.51128024
   0.5123896   0.51553798  0.52554959  0.52291054  0.4901593   0.48997998
   0.49383342  0.50968772  0.49720028  0.52005768  0.5342474   0.51671505
   0.48203233  0.50856262  0.50775343  0.4818033   0.50594664  0.51419139
   0.50578237  0.51214319  0.49371704  0.53164488  0.48879763  0.51376003
   0.50486606  0.51324123  0.50796199  0.53080171  0.4876931   0.50386268
   0.51304257  0.50076926  0.5101282   0.51080012  0.49572191  0.49546915
   0.51281041  0.52130735  0.50541377  0.49661016  0.50450468  0.5161835
   0.49888775  0.50999981  0.50798601  0.52245408  0.55368155  0.50268263
   0.48774788  0.5129872   0.52426136  0.538773    0.52628559  0.50250238
   0.51068473  0.49777949  0.53670472  0.51225901  0.49994338  0.50757688
   0.50554746  0.50835073  0.49579597  0.53002274  0.538059    0.48385212
   0.4967128   0.49582693  0.50177902  0.49355856  0.50089997  0.51556247
   0.51452166  0.53088439  0.52014655  0.52301216  0.51805443  0.5089879
   0.50019884  0.49389336  0.52494508  0.51480883  0.50642073  0.51088643
   0.51759934  0.51911926  0.50400895  0.50860959  0.51489639  0.51833862
   0.51374435  0.51338029  0.54352355  0.52237529  0.50585985  0.50546521
   0.50906199  0.47081929  0.5193221   0.52300984  0.51078248  0.48631787
   0.50377518  0.49674475  0.50871652  0.51868874]]
After layer encoder_birnn_forward_l0_begin_state_1_0 (1, 256) <class 'numpy.float32'> [[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
   0.  0.  0.  0.]]
After layer _mul2052_0 (1, 256) <class 'numpy.float32'> [[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
   0.  0.  0.  0.]]
After layer encoder_birnn_forward_l0_t0_i_output (1, 256) <class 'numpy.float32'> [[ 0.48608381  0.49283555  0.49967107  0.49714777  0.52940726  0.52098614
   0.51049072  0.51464379  0.48886621  0.50194925  0.51999474  0.5077799
   0.50519735  0.48831898  0.53486091  0.53177971  0.50168771  0.50507563
   0.508986    0.51398265  0.50136644  0.52800238  0.50805217  0.49339035
   0.51304233  0.52975124  0.51383299  0.50202739  0.51058018  0.52505267
   0.4996886   0.49674556  0.51840901  0.53879309  0.54096788  0.50946325
   0.50588429  0.52357197  0.52401441  0.50746769  0.48993257  0.51221478
   0.52084786  0.50267911  0.53493255  0.50242782  0.49741662  0.50857157
   0.50870109  0.47989452  0.51253206  0.49329036  0.53937113  0.50942546
   0.50565338  0.50988227  0.50523233  0.49161121  0.50906354  0.50174123
   0.53414619  0.50509602  0.51286554  0.51370513  0.52444655  0.50822729
   0.50868642  0.51876771  0.52551824  0.52513957  0.49731642  0.53025234
   0.5242517   0.51148868  0.53263247  0.51146102  0.51733738  0.51944798
   0.53168023  0.53054154  0.50399494  0.51187056  0.55943072  0.50899053
   0.51164711  0.49922794  0.50799519  0.49759665  0.5598824   0.53183466
   0.51179957  0.49599597  0.50055492  0.50720114  0.50093877  0.51422083
   0.51831186  0.51909578  0.51265979  0.51438099  0.52306259  0.49631611
   0.51720047  0.49770081  0.50425839  0.51915461  0.50154507  0.51568389
   0.52733552  0.51307082  0.51052022  0.4974272   0.54554909  0.54639131
   0.49505365  0.51106787  0.51655358  0.51106936  0.49535793  0.53335381
   0.51039976  0.5282461   0.51394999  0.51976687  0.53135508  0.51511252
   0.53244776  0.51751614  0.51005012  0.53164017  0.51689601  0.51032221
   0.50703287  0.50892699  0.51580954  0.528781    0.51882797  0.51788843
   0.54621053  0.52030736  0.52379203  0.51293939  0.52053118  0.52081519
   0.49691388  0.50614089  0.52125561  0.51285678  0.55258191  0.50768745
   0.51472872  0.50165659  0.53290796  0.49701735  0.5027383   0.49980518
   0.51738542  0.4958027   0.51384842  0.48421699  0.52135289  0.51406574
   0.51023597  0.48927921  0.51296049  0.50441372  0.50412321  0.51743847
   0.52487552  0.51295692  0.52150118  0.54225177  0.49291623  0.4981066
   0.50682163  0.52044123  0.51837212  0.49102309  0.51858264  0.48790652
   0.51792783  0.52152425  0.50827366  0.52115715  0.51697576  0.50384611
   0.51126921  0.53145826  0.50097436  0.50516683  0.49765807  0.49447265
   0.50092721  0.51303273  0.49396801  0.52319098  0.53543127  0.51225913
   0.52602524  0.50565296  0.51887596  0.51815462  0.5296424   0.51800489
   0.48861939  0.52803671  0.50562644  0.50478125  0.53320193  0.48933905
   0.50091696  0.53502911  0.5041613   0.53158933  0.50429183  0.49863172
   0.49063653  0.52356005  0.51098549  0.49854311  0.50073946  0.50763899
   0.54630113  0.50309086  0.50686967  0.53574365  0.51094258  0.49874797
   0.50413096  0.49837488  0.51263428  0.5186308   0.50360626  0.50825197
   0.49306017  0.47275916  0.50392437  0.50823832  0.49872825  0.53070468
   0.51330447  0.52009398  0.54361403  0.51851225  0.50785434  0.53869522
   0.50984746  0.48429689  0.50370961  0.50187492  0.51478958  0.49056429
   0.48232123  0.49946746  0.51567525  0.52889639]]
After layer encoder_birnn_forward_l0_t0_c_output (1, 256) <class 'numpy.float32'> [[ 0.01442502  0.08961658 -0.02464551 -0.03506391  0.112583   -0.02542356
   0.04422861 -0.14459121  0.0585347   0.01550089  0.06533305  0.02281907
   0.08779414 -0.04342368  0.10325752 -0.03081464 -0.01739678  0.01676636
  -0.03423471 -0.01887796  0.02927198 -0.11034232 -0.13252395  0.11423471
   0.00827649 -0.0623443  -0.04933546 -0.05290366 -0.04918003  0.03725785
   0.05156987 -0.05955586  0.03706542 -0.02696603  0.07571816  0.03281698
   0.03682064 -0.02923818 -0.04998051 -0.03069635 -0.05458862  0.10046735
  -0.02065232  0.07151747 -0.08430569 -0.08222431  0.01336672  0.08461791
   0.05979714 -0.01902797 -0.00867771 -0.07175127  0.08194166 -0.09960657
   0.03092877  0.12724644  0.03554536 -0.06529548  0.08399414 -0.05198315
   0.07264562 -0.06707384  0.01243241  0.01934079 -0.011368   -0.02234153
   0.02035613  0.07067817 -0.00396364 -0.07016671 -0.00141762 -0.09460036
  -0.13038234  0.07597184  0.1478588  -0.00501567  0.13862965 -0.14075227
   0.12330253 -0.04815698  0.08983241 -0.04648841  0.15352902  0.02530867
   0.01922233 -0.03919966  0.05926317 -0.12266254 -0.0638788   0.07945664
  -0.03004561  0.06757886 -0.09071229 -0.0522452  -0.08470815  0.04598504
   0.01955933 -0.14866094  0.07426376  0.10129144 -0.11764146 -0.01776041
   0.00152223  0.01720443  0.0474894  -0.08149279  0.01747272  0.11610078
   0.08645504  0.05655703  0.02546015 -0.08571024  0.14889948  0.16954088
  -0.06560005 -0.00920408  0.06050741  0.15519091  0.02040209  0.03933035
   0.01340615 -0.10673802  0.1225471  -0.12336686  0.09454312 -0.02589138
   0.04697888  0.09376527  0.00591198 -0.15795697  0.00097291  0.02814493
   0.06851087 -0.04412206  0.0705906   0.0924212   0.05740442  0.12713565
  -0.10000903  0.00831567 -0.06222639  0.14061202 -0.10625627 -0.07915998
   0.11180447  0.09494746  0.05523637 -0.06464272  0.1393813  -0.06904126
  -0.01551343  0.01283446  0.08906327  0.10203495  0.06829228 -0.09433556
   0.08041569  0.04457339  0.0595082   0.01994547  0.01613029  0.05273126
  -0.00961705  0.0233664  -0.06277693  0.06133132 -0.14671148 -0.01479945
  -0.11238947 -0.05432864  0.0063581  -0.01024239 -0.01446949 -0.01146117
   0.019856   -0.03891429  0.1624961   0.00351758 -0.05093449  0.00872836
   0.05746837  0.07579882  0.06526677  0.00309032  0.02243721 -0.08074299
   0.00780426  0.02723766  0.04345604  0.02084934  0.02976206 -0.03535762
  -0.14746243  0.18343328  0.00329151 -0.16465281 -0.08718305 -0.08962268
   0.06712316  0.10473614  0.10721885 -0.11069145 -0.00277185 -0.01330152
  -0.08444464 -0.00842659  0.02971068  0.07423006  0.05212059 -0.00242723
   0.0142355   0.0794622   0.0932739  -0.03055054  0.00087474 -0.00289243
  -0.06574844 -0.09049822 -0.07328553  0.01015308 -0.05033091  0.03936048
   0.03297594 -0.16318056  0.08675552 -0.0375303  -0.12532417 -0.02463109
   0.01453951 -0.06437014 -0.04673073 -0.04867838  0.06706497  0.0497651
  -0.0654906  -0.02020916  0.05031215  0.10005186 -0.03602676 -0.00259098
   0.04150115  0.089483   -0.00609488 -0.09332496  0.05649777 -0.0888886
   0.05274136 -0.0538933  -0.08504069  0.02638693 -0.07738812  0.01173747
   0.02206536 -0.11570701  0.06982239  0.0010551 ]]
After layer _mul2053_0 (1, 256) <class 'numpy.float32'> [[ 0.00701177  0.04416624 -0.01231465 -0.01743195  0.05960226 -0.01324532
   0.02257829 -0.07441297  0.02861564  0.00778066  0.03397284  0.01158706
   0.04435337 -0.02120461  0.05522841 -0.0163866  -0.00872775  0.00846828
  -0.01742499 -0.00970294  0.01467599 -0.05826101 -0.06732908  0.0563623
   0.00424619 -0.03302697 -0.02535019 -0.02655908 -0.02511035  0.01956233
   0.02576887 -0.02958411  0.01921505 -0.01452911  0.04096109  0.01671904
   0.01862698 -0.01530829 -0.02619051 -0.01557741 -0.02674474  0.05146086
  -0.01075672  0.03595034 -0.04509786 -0.04131178  0.00664883  0.04303426
   0.03041887 -0.00913142 -0.00444761 -0.03539421  0.04419696 -0.05074212
   0.01563924  0.06488071  0.01795867 -0.03209999  0.04275835 -0.02608209
   0.03880338 -0.03387873  0.00637616  0.00993546 -0.00596191 -0.01135457
   0.01035489  0.03666555 -0.00208296 -0.03684732 -0.00070501 -0.05016206
  -0.06835317  0.03885874  0.0787544  -0.00256532  0.0717183  -0.07311349
   0.06555752 -0.02554928  0.04527508 -0.02379605  0.08588885  0.01288187
   0.00983505 -0.01956957  0.0301054  -0.06103647 -0.03576462  0.0422578
  -0.01537733  0.03351884 -0.04540649 -0.02649883 -0.04243359  0.02364646
   0.01013783 -0.07716927  0.03807204  0.05210239 -0.06153385 -0.00881478
   0.0007873   0.00856266  0.02394693 -0.04230736  0.00876335  0.0598713
   0.04559081  0.02901776  0.01299792 -0.04263461  0.08123197  0.09263566
  -0.03247554 -0.00470391  0.03125532  0.07931332  0.01010634  0.02097699
   0.0068425  -0.05638395  0.06298308 -0.06412201  0.05023597 -0.01333697
   0.0250138   0.04852504  0.00301541 -0.08397627  0.00050289  0.01436298
   0.03473726 -0.02245491  0.0364113   0.04887057  0.02978302  0.06584208
  -0.05462598  0.0043267  -0.03259369  0.07212544 -0.0553097  -0.04122772
   0.05555719  0.04805679  0.02879227 -0.03315246  0.07701959 -0.03505138
  -0.00798521  0.00643849  0.04746253  0.05071314  0.03433314 -0.0471494
   0.0416059   0.0220996   0.0305782   0.00965794  0.00840957  0.02710734
  -0.00490697  0.01143269 -0.03220208  0.03093636 -0.07396066 -0.00765781
  -0.05899048 -0.02786825  0.00331575 -0.00555396 -0.00713225 -0.00570888
   0.01006345 -0.0202526   0.08423345  0.00172721 -0.02641374  0.00425863
   0.02976447  0.03953093  0.03317338  0.00161054  0.0115995  -0.04068204
   0.00399008  0.01447568  0.02177036  0.01053239  0.01481133 -0.01748337
  -0.07386794  0.09410728  0.0016259  -0.08614486 -0.04668053 -0.04591003
   0.03530848  0.05296014  0.05563328 -0.05735529 -0.00146809 -0.00689025
  -0.04126129 -0.00444955  0.01502251  0.03746994  0.0277908  -0.00118774
   0.0071308   0.04251459  0.04702509 -0.01624034  0.00044112 -0.00144226
  -0.03225859 -0.04738125 -0.03744784  0.00506175 -0.02520267  0.01998091
   0.01801479 -0.08209465  0.04397374 -0.02010662 -0.06403346 -0.01228471
   0.00732982 -0.03208046 -0.02395577 -0.0252461   0.03377434  0.02529321
  -0.03229081 -0.00955407  0.02535352  0.05085019 -0.01796756 -0.00137504
   0.02130273  0.04653957 -0.00331326 -0.04839014  0.02869264 -0.04788386
   0.02689005 -0.02610036 -0.04283581  0.01324294 -0.0398386   0.00575798
   0.01064259 -0.05779188  0.03600568  0.00055804]]
After layer encoder_birnn_forward_l0_t0_state_0 (1, 256) <class 'numpy.float32'> [[ 0.00701177  0.04416624 -0.01231465 -0.01743195  0.05960226 -0.01324532
   0.02257829 -0.07441297  0.02861564  0.00778066  0.03397284  0.01158706
   0.04435337 -0.02120461  0.05522841 -0.0163866  -0.00872775  0.00846828
  -0.01742499 -0.00970294  0.01467599 -0.05826101 -0.06732908  0.0563623
   0.00424619 -0.03302697 -0.02535019 -0.02655908 -0.02511035  0.01956233
   0.02576887 -0.02958411  0.01921505 -0.01452911  0.04096109  0.01671904
   0.01862698 -0.01530829 -0.02619051 -0.01557741 -0.02674474  0.05146086
  -0.01075672  0.03595034 -0.04509786 -0.04131178  0.00664883  0.04303426
   0.03041887 -0.00913142 -0.00444761 -0.03539421  0.04419696 -0.05074212
   0.01563924  0.06488071  0.01795867 -0.03209999  0.04275835 -0.02608209
   0.03880338 -0.03387873  0.00637616  0.00993546 -0.00596191 -0.01135457
   0.01035489  0.03666555 -0.00208296 -0.03684732 -0.00070501 -0.05016206
  -0.06835317  0.03885874  0.0787544  -0.00256532  0.0717183  -0.07311349
   0.06555752 -0.02554928  0.04527508 -0.02379605  0.08588885  0.01288187
   0.00983505 -0.01956957  0.0301054  -0.06103647 -0.03576462  0.0422578
  -0.01537733  0.03351884 -0.04540649 -0.02649883 -0.04243359  0.02364646
   0.01013783 -0.07716927  0.03807204  0.05210239 -0.06153385 -0.00881478
   0.0007873   0.00856266  0.02394693 -0.04230736  0.00876335  0.0598713
   0.04559081  0.02901776  0.01299792 -0.04263461  0.08123197  0.09263566
  -0.03247554 -0.00470391  0.03125532  0.07931332  0.01010634  0.02097699
   0.0068425  -0.05638395  0.06298308 -0.06412201  0.05023597 -0.01333697
   0.0250138   0.04852504  0.00301541 -0.08397627  0.00050289  0.01436298
   0.03473726 -0.02245491  0.0364113   0.04887057  0.02978302  0.06584208
  -0.05462598  0.0043267  -0.03259369  0.07212544 -0.0553097  -0.04122772
   0.05555719  0.04805679  0.02879227 -0.03315246  0.07701959 -0.03505138
  -0.00798521  0.00643849  0.04746253  0.05071314  0.03433314 -0.0471494
   0.0416059   0.0220996   0.0305782   0.00965794  0.00840957  0.02710734
  -0.00490697  0.01143269 -0.03220208  0.03093636 -0.07396066 -0.00765781
  -0.05899048 -0.02786825  0.00331575 -0.00555396 -0.00713225 -0.00570888
   0.01006345 -0.0202526   0.08423345  0.00172721 -0.02641374  0.00425863
   0.02976447  0.03953093  0.03317338  0.00161054  0.0115995  -0.04068204
   0.00399008  0.01447568  0.02177036  0.01053239  0.01481133 -0.01748337
  -0.07386794  0.09410728  0.0016259  -0.08614486 -0.04668053 -0.04591003
   0.03530848  0.05296014  0.05563328 -0.05735529 -0.00146809 -0.00689025
  -0.04126129 -0.00444955  0.01502251  0.03746994  0.0277908  -0.00118774
   0.0071308   0.04251459  0.04702509 -0.01624034  0.00044112 -0.00144226
  -0.03225859 -0.04738125 -0.03744784  0.00506175 -0.02520267  0.01998091
   0.01801479 -0.08209465  0.04397374 -0.02010662 -0.06403346 -0.01228471
   0.00732982 -0.03208046 -0.02395577 -0.0252461   0.03377434  0.02529321
  -0.03229081 -0.00955407  0.02535352  0.05085019 -0.01796756 -0.00137504
   0.02130273  0.04653957 -0.00331326 -0.04839014  0.02869264 -0.04788386
   0.02689005 -0.02610036 -0.04283581  0.01324294 -0.0398386   0.00575798
   0.01064259 -0.05779188  0.03600568  0.00055804]]
After layer activation1026_output (1, 256) <class 'numpy.float32'> [[ 0.00701165  0.04413754 -0.01231403 -0.01743018  0.05953179 -0.01324455
   0.02257446 -0.07427593  0.02860783  0.0077805   0.03395978  0.01158654
   0.0443243  -0.02120143  0.05517233 -0.01638514 -0.00872753  0.00846808
  -0.01742322 -0.00970264  0.01467494 -0.05819518 -0.06722753  0.0563027
   0.00424616 -0.03301497 -0.02534476 -0.02655284 -0.02510507  0.01955984
   0.02576317 -0.02957548  0.01921268 -0.01452809  0.0409382   0.01671749
   0.01862483 -0.0153071  -0.02618452 -0.01557615 -0.02673837  0.05141548
  -0.0107563   0.03593486 -0.04506731 -0.0412883   0.00664873  0.04300772
   0.03040949 -0.00913116 -0.00444758 -0.03537944  0.04416821 -0.05069862
   0.01563796  0.06478982  0.01795674 -0.03208897  0.04273231 -0.02607618
   0.03878392 -0.03386578  0.00637607  0.00993514 -0.00596184 -0.01135409
   0.01035452  0.03664913 -0.00208296 -0.03683065 -0.00070501 -0.05012003
  -0.06824692  0.03883919  0.07859198 -0.00256531  0.07159559 -0.07298349
   0.06546376 -0.02554372  0.04524417 -0.02379156  0.08567827  0.01288116
   0.00983473 -0.01956707  0.03009631 -0.06096078 -0.03574938  0.04223266
  -0.01537612  0.0335063  -0.04537531 -0.02649263 -0.04240814  0.02364206
   0.01013749 -0.07701645  0.03805366  0.0520553  -0.0614563  -0.00881455
   0.0007873   0.00856245  0.02394236 -0.04228213  0.00876313  0.05979986
   0.04555925  0.02900962  0.01299719 -0.04260879  0.08105377  0.09237159
  -0.03246413 -0.00470388  0.03124515  0.07914744  0.01010599  0.02097392
   0.00684239 -0.05632427  0.06289993 -0.06403427  0.05019375 -0.01333618
   0.02500858  0.04848699  0.0030154  -0.08377942  0.00050289  0.014362
   0.0347233  -0.02245113  0.03639522  0.04883171  0.02977422  0.0657471
  -0.05457171  0.00432668 -0.03258215  0.07200064 -0.05525337 -0.04120438
   0.0555001   0.04801983  0.02878431 -0.03314032  0.07686765 -0.03503703
  -0.00798504  0.0064384   0.04742692  0.05066971  0.03431966 -0.0471145
   0.04158191  0.02209601  0.03056867  0.00965764  0.00840937  0.0271007
  -0.00490693  0.0114322  -0.03219096  0.0309265  -0.0738261  -0.00765766
  -0.05892215 -0.02786104  0.00331574 -0.0055539  -0.00713213 -0.00570882
   0.01006311 -0.02024983  0.08403479  0.00172721 -0.0264076   0.0042586
   0.02975568  0.03951035  0.03316122  0.00161054  0.01159898 -0.04065961
   0.00399006  0.01447467  0.02176692  0.010532    0.01481025 -0.01748159
  -0.07373388  0.09383045  0.0016259  -0.0859324  -0.04664665 -0.04587781
   0.03529381  0.05291068  0.05557596 -0.05729248 -0.00146809 -0.00689014
  -0.04123789 -0.00444952  0.01502138  0.03745241  0.02778365 -0.00118774
   0.00713068  0.042489    0.04699046 -0.01623891  0.00044112 -0.00144226
  -0.0322474  -0.04734583 -0.03743035  0.0050617  -0.02519734  0.01997826
   0.01801284 -0.08191071  0.04394542 -0.02010391 -0.06394608 -0.01228409
   0.00732969 -0.03206946 -0.02395119 -0.02524074  0.0337615   0.02528782
  -0.03227959 -0.00955378  0.02534809  0.05080641 -0.01796563 -0.00137504
   0.02129951  0.046506   -0.00331325 -0.0483524   0.02868477 -0.0478473
   0.02688357 -0.02609443 -0.04280963  0.01324216 -0.03981753  0.00575792
   0.01064219 -0.05772763  0.03599013  0.00055804]]
After layer encoder_birnn_forward_l0_t0_out_0 (1, 256) <class 'numpy.float32'> [[ 0.00344843  0.02281707 -0.00656714 -0.00882131  0.03004944 -0.00671924
   0.01168611 -0.03646286  0.01508168  0.00393567  0.01809126  0.00596961
   0.02235237 -0.01144721  0.02931096 -0.00858357 -0.00440996  0.00435271
  -0.00942058 -0.00497426  0.00759334 -0.03011162 -0.03386465  0.02855224
   0.00217556 -0.01683474 -0.01299715 -0.01380952 -0.0125677   0.00991413
   0.01333397 -0.01503206  0.00976797 -0.00750936  0.02098084  0.00884093
   0.00938615 -0.007981   -0.01331123 -0.00788299 -0.01409708  0.02760141
  -0.00549345  0.0181083  -0.0240888  -0.02132732  0.00338066  0.02154783
   0.01570783 -0.00459875 -0.00228134 -0.01814391  0.02301804 -0.02589241
   0.00790678  0.03306069  0.00914188 -0.01712457  0.02147737 -0.01302753
   0.01937512 -0.01676346  0.00321234  0.00507907 -0.00288837 -0.0055305
   0.00520771  0.01923472 -0.00105631 -0.01872281 -0.00035642 -0.0249088
  -0.03537728  0.02045673  0.04153071 -0.00136153  0.03607874 -0.03830818
   0.03543913 -0.01366304  0.02384571 -0.01215073  0.04747244  0.00659647
   0.00515656 -0.01021648  0.01500427 -0.03142592 -0.01948088  0.0221555
  -0.00770214  0.01766357 -0.02266985 -0.0137891  -0.02179348  0.01247028
   0.00519924 -0.0395453   0.01908212  0.02753736 -0.03146568 -0.00440159
   0.00040444  0.0045548   0.01233727 -0.02143061  0.00451117  0.03031329
   0.02413246  0.01466354  0.00672643 -0.02238399  0.0450888   0.04935702
  -0.0159513  -0.00232015  0.01639635  0.04072095  0.00501773  0.01068863
   0.00340512 -0.0296009   0.03283188 -0.03329831  0.02573171 -0.00701243
   0.01315904  0.02572919  0.00149969 -0.04587819  0.00025572  0.007103
   0.01784562 -0.01132003  0.01828509  0.0252912   0.01574026  0.03218156
  -0.02888326  0.00219123 -0.01659539  0.03660483 -0.02873997 -0.02041862
   0.02771163  0.02465515  0.01451749 -0.01743448  0.03949875 -0.01801175
  -0.00418845  0.00329732  0.02383868  0.02620363  0.01696708 -0.02408021
   0.02085363  0.01107738  0.0151177   0.00467874  0.00445567  0.01344949
  -0.00244868  0.00619894 -0.01644946  0.01588133 -0.0384314  -0.00398028
  -0.03149546 -0.01449361  0.00166066 -0.00293848 -0.00344552 -0.00300939
   0.00526304 -0.01009758  0.04309596  0.00089158 -0.01336969  0.00221207
   0.01569687  0.0207898   0.0170271   0.00084656  0.00574857 -0.02008639
   0.00200731  0.00743347  0.01086642  0.00523057  0.00787771 -0.00880241
  -0.03900791  0.04942144  0.00080631 -0.04564055 -0.02476765 -0.02289244
   0.01870838  0.02796316  0.02879841 -0.02913965 -0.00075637 -0.00355253
  -0.02010973 -0.00231657  0.00767042  0.01977803  0.01507369 -0.00060985
   0.00359038  0.02147512  0.02407564 -0.00850489  0.00023829 -0.00071827
  -0.01623054 -0.02516382 -0.01789473  0.00261185 -0.01267165  0.01013608
   0.00901379 -0.04199843  0.02286419 -0.01042433 -0.03239026 -0.00611909
   0.00361987 -0.01631487 -0.01220678 -0.01293035  0.01771002  0.01269604
  -0.0161234  -0.00511057  0.01319942  0.024338   -0.00909822 -0.00073388
   0.01075887  0.02263275 -0.00181736 -0.02526063  0.01420784 -0.02408066
   0.01309405 -0.01262812 -0.02158442  0.00670673 -0.020032    0.00299697
   0.00537682 -0.0298891   0.01762069  0.00028092]]
After layer expand_dims1032_0 (1, 1, 256) <class 'numpy.float32'> [[[ 0.00344843  0.02281707 -0.00656714 -0.00882131  0.03004944 -0.00671924
    0.01168611 -0.03646286  0.01508168  0.00393567  0.01809126  0.00596961
    0.02235237 -0.01144721  0.02931096 -0.00858357 -0.00440996  0.00435271
   -0.00942058 -0.00497426  0.00759334 -0.03011162 -0.03386465  0.02855224
    0.00217556 -0.01683474 -0.01299715 -0.01380952 -0.0125677   0.00991413
    0.01333397 -0.01503206  0.00976797 -0.00750936  0.02098084  0.00884093
    0.00938615 -0.007981   -0.01331123 -0.00788299 -0.01409708  0.02760141
   -0.00549345  0.0181083  -0.0240888  -0.02132732  0.00338066  0.02154783
    0.01570783 -0.00459875 -0.00228134 -0.01814391  0.02301804 -0.02589241
    0.00790678  0.03306069  0.00914188 -0.01712457  0.02147737 -0.01302753
    0.01937512 -0.01676346  0.00321234  0.00507907 -0.00288837 -0.0055305
    0.00520771  0.01923472 -0.00105631 -0.01872281 -0.00035642 -0.0249088
   -0.03537728  0.02045673  0.04153071 -0.00136153  0.03607874 -0.03830818
    0.03543913 -0.01366304  0.02384571 -0.01215073  0.04747244  0.00659647
    0.00515656 -0.01021648  0.01500427 -0.03142592 -0.01948088  0.0221555
   -0.00770214  0.01766357 -0.02266985 -0.0137891  -0.02179348  0.01247028
    0.00519924 -0.0395453   0.01908212  0.02753736 -0.03146568 -0.00440159
    0.00040444  0.0045548   0.01233727 -0.02143061  0.00451117  0.03031329
    0.02413246  0.01466354  0.00672643 -0.02238399  0.0450888   0.04935702
   -0.0159513  -0.00232015  0.01639635  0.04072095  0.00501773  0.01068863
    0.00340512 -0.0296009   0.03283188 -0.03329831  0.02573171 -0.00701243
    0.01315904  0.02572919  0.00149969 -0.04587819  0.00025572  0.007103
    0.01784562 -0.01132003  0.01828509  0.0252912   0.01574026  0.03218156
   -0.02888326  0.00219123 -0.01659539  0.03660483 -0.02873997 -0.02041862
    0.02771163  0.02465515  0.01451749 -0.01743448  0.03949875 -0.01801175
   -0.00418845  0.00329732  0.02383868  0.02620363  0.01696708 -0.02408021
    0.02085363  0.01107738  0.0151177   0.00467874  0.00445567  0.01344949
   -0.00244868  0.00619894 -0.01644946  0.01588133 -0.0384314  -0.00398028
   -0.03149546 -0.01449361  0.00166066 -0.00293848 -0.00344552 -0.00300939
    0.00526304 -0.01009758  0.04309596  0.00089158 -0.01336969  0.00221207
    0.01569687  0.0207898   0.0170271   0.00084656  0.00574857 -0.02008639
    0.00200731  0.00743347  0.01086642  0.00523057  0.00787771 -0.00880241
   -0.03900791  0.04942144  0.00080631 -0.04564055 -0.02476765 -0.02289244
    0.01870838  0.02796316  0.02879841 -0.02913965 -0.00075637 -0.00355253
   -0.02010973 -0.00231657  0.00767042  0.01977803  0.01507369 -0.00060985
    0.00359038  0.02147512  0.02407564 -0.00850489  0.00023829 -0.00071827
   -0.01623054 -0.02516382 -0.01789473  0.00261185 -0.01267165  0.01013608
    0.00901379 -0.04199843  0.02286419 -0.01042433 -0.03239026 -0.00611909
    0.00361987 -0.01631487 -0.01220678 -0.01293035  0.01771002  0.01269604
   -0.0161234  -0.00511057  0.01319942  0.024338   -0.00909822 -0.00073388
    0.01075887  0.02263275 -0.00181736 -0.02526063  0.01420784 -0.02408066
    0.01309405 -0.01262812 -0.02158442  0.00670673 -0.020032    0.00299697
    0.00537682 -0.0298891   0.01762069  0.00028092]]]
After layer encoder_birnn_forward_l0_t1_i2h_output (1, 1024) <class 'numpy.float32'> [[ 0.08165702 -0.05381364  0.08985929 ...,  0.03199084  0.08803809
   0.01552574]]
After layer encoder_birnn_forward_l0_t1_h2h_output (1, 1024) <class 'numpy.float32'> [[ 0.04410346  0.03952393  0.08904912 ...,  0.06186322  0.07280186
   0.07780308]]
After layer _plus1027_0 (1, 1024) <class 'numpy.float32'> [[ 0.12576048 -0.01428971  0.17890841 ...,  0.09385406  0.16083995
   0.09332882]]
After layer encoder_birnn_forward_l0_t1_slice_output0 (1, 256) <class 'numpy.float32'> [[ 0.12576048 -0.01428971  0.17890841  0.13847896  0.09555878  0.06347033
   0.07903248  0.07181778  0.03106494  0.07289127  0.14371872  0.12562738
   0.01246645  0.09478198 -0.01832888  0.06472786 -0.01805694  0.15737766
   0.12475678  0.0847446  -0.0067496   0.05703275  0.21902402  0.01187308
   0.03710521  0.0268079   0.15546611 -0.00126563  0.05294354  0.05237579
   0.02942411  0.16136441  0.14121684  0.01181817  0.10246842  0.05997389
   0.03323976  0.24902828  0.16985808  0.00348715  0.08672531  0.09499891
   0.20551114  0.02437822  0.08787826  0.09629304  0.1544424   0.06076475
   0.0928136   0.05385287  0.07269599 -0.04815552  0.29722047  0.04597545
   0.14068413  0.06889026  0.04722367  0.06390263  0.0789168  -0.04971496
   0.04012302  0.16023208  0.11999759  0.28744918  0.13846606 -0.03781169
   0.23738854  0.05785671  0.00227483  0.11254194  0.02897874  0.01980188
   0.24484053  0.0212096   0.05902568  0.09416126  0.14814419  0.19395858
   0.10960494  0.05387888  0.12405431  0.0742133   0.26824409  0.0057846
   0.14030114  0.13666636  0.11579327  0.19461736  0.30295193 -0.01563685
   0.04353574  0.02513218  0.01046108  0.16077237  0.05246145  0.1221102
   0.07550699  0.23857222  0.12159593  0.10222846  0.07348297 -0.04322895
   0.11361812  0.07845898  0.13838184  0.01557373  0.12016908  0.05912037
   0.0482551   0.10362333  0.24030872  0.17913225  0.11422477  0.14309354
   0.09249599  0.03294476  0.1656002   0.0829031   0.01407486  0.18706068
  -0.01097339  0.19183715  0.18669406  0.04220931  0.22093377  0.06331141
   0.07751338  0.07271793  0.1082878   0.28783679  0.06776141  0.14853629
   0.05649757  0.06011837  0.18074253  0.10356638 -0.01244772  0.0564255
   0.17741667  0.12140808 -0.04486194  0.06394524  0.11774531  0.11581098
   0.02843792 -0.05736029  0.08119403 -0.03539886  0.0612196   0.03646854
   0.21183139  0.11693475  0.14850524  0.14312699  0.03784548  0.16190021
   0.02987339  0.10288443  0.13555819  0.12041969  0.21472105 -0.03305934
   0.07992981  0.07749683  0.09863974  0.03630781  0.0657129   0.06388287
   0.16310945  0.01947979  0.01130977  0.39832112  0.18833201  0.18970805
   0.13751253 -0.00450427  0.02538302  0.01577937  0.02263378  0.05651584
   0.13787961  0.04649125  0.08219317  0.05635374 -0.07599648  0.02886552
   0.11978286  0.0754985   0.15095603  0.14547145  0.05506034  0.10605712
   0.12462077  0.14444259  0.04237542  0.05311094  0.33375627  0.10994783
   0.18860532  0.08433045  0.16119388  0.12051533  0.07781723 -0.02631517
   0.13749765 -0.01939655  0.1399852   0.02902849  0.04488335  0.0480326
   0.11303937  0.06264278  0.09910075  0.07902618  0.26636314  0.12569609
   0.06485273  0.2359238  -0.00055902  0.09902899  0.08814544  0.12102283
   0.07060024  0.11480268  0.12171577  0.29288536  0.12474678 -0.03093694
   0.11515138 -0.00591537 -0.0061904   0.30729657  0.0301111   0.10349295
   0.06693202  0.04928605  0.07807259  0.06178688  0.05273216  0.27539831
   0.00288156  0.07496211  0.31452629  0.05861955  0.13720387  0.05751937
   0.07500694  0.03383904  0.09851598  0.14855494  0.15585697 -0.03222331
   0.17523238 -0.0234576   0.00557342  0.19192219]]
After layer encoder_birnn_forward_l0_t1_slice_output1 (1, 256) <class 'numpy.float32'> [[ 0.17144048  0.06420718  0.09485573  0.03514691  0.15247214  0.08164407
   0.06332734  0.00700094  0.20243536  0.1232466   0.21317703  0.13944128
   0.06264792  0.13439751 -0.08884605  0.10229185  0.07376289  0.11319963
   0.25604326  0.07392278  0.04464182  0.06324937  0.15504524  0.07755954
   0.07107159 -0.05262137  0.10315939  0.00734363 -0.00641952  0.06067109
   0.14409527  0.12548144  0.08499192  0.10725503  0.19395986 -0.0262102
   0.09923239  0.08426436  0.06367907  0.02776298  0.03316358  0.14776444
   0.17879003  0.01780764  0.05138753  0.11821348  0.13973853  0.10500577
   0.10097192  0.06093213  0.0422012   0.0803867   0.28936845  0.04163926
   0.03459907  0.05361611  0.1568858   0.05705315  0.00297564  0.15126935
   0.02110731 -0.02536997  0.01704711  0.18885575  0.12259427  0.1731534
   0.13727584  0.07203475  0.00846087  0.07658843  0.10380132  0.06957678
   0.09291932  0.11325747  0.04952455  0.2278647   0.14525096  0.32006401
   0.07961854 -0.05956023  0.18937367  0.01469114  0.35538304  0.14613992
   0.10459674 -0.0094446   0.06405862  0.12964408  0.28058887  0.06398095
   0.0155313  -0.02723372 -0.02040294  0.02394882  0.03841719  0.10541083
   0.03297945  0.13437408  0.11134271  0.12117627  0.03353     0.09570986
   0.08055685  0.15496676  0.11257227 -0.01382573  0.0424637   0.02879076
   0.1377847   0.16050023  0.1197726   0.15078963  0.23925288  0.14212811
   0.05814301  0.08163886  0.17850211  0.2216589   0.08059625  0.10750749
   0.00482123  0.20267949  0.17571849  0.03821865  0.17876413  0.11976918
   0.10080098  0.13436022  0.06035726  0.23659514  0.03533761  0.15298192
   0.05751012  0.054496    0.01720349  0.03298638  0.10815531 -0.02741434
   0.24686688  0.03354893  0.06130434  0.20770575  0.0583709   0.06674521
   0.0755819   0.16137907  0.09913012  0.01351489  0.08108774  0.03913385
   0.1203773   0.06987439  0.01293941  0.06738938  0.10965866  0.1467175
   0.07699056  0.05949905  0.14872086  0.11503346  0.13359442  0.11270201
   0.10527427  0.11545566  0.10559937 -0.01453577  0.03213089  0.09325787
   0.07749692  0.03033382 -0.00418316  0.22444557  0.0693204   0.13493739
   0.01474402  0.03065977  0.08883093  0.08981644  0.00199896  0.07977581
   0.18092173 -0.01427419  0.181953    0.13442944 -0.03551323  0.0695372
   0.08941701  0.12937465  0.11708937  0.1194981   0.01916243 -0.0221193
   0.13820279  0.11138085 -0.06969874  0.09143072  0.50459969  0.02405308
   0.01308713 -0.02168676  0.15042204  0.07124494  0.12086748  0.12205184
   0.12868506  0.08730559  0.10918309 -0.00577892 -0.01761729  0.10153317
   0.14841019  0.04790139  0.11551452  0.00540963  0.33003443  0.04674707
   0.06458544  0.10860391  0.03161238 -0.03500633  0.0613229   0.08468893
  -0.03457583  0.12961     0.03194921  0.21676891  0.05835885  0.01980247
   0.14454661  0.06749551  0.10799807  0.15627758  0.12625906  0.08909276
   0.14750791  0.14192003  0.1086053  -0.00918158  0.05813952  0.16701119
   0.06519173  0.16699484  0.46855903  0.02189216  0.0764827   0.07467794
   0.05428274  0.01997275  0.19001609  0.10952625  0.15381655 -0.02008497
   0.16778383  0.0351294   0.11678799  0.10290164]]
After layer encoder_birnn_forward_l0_t1_slice_output2 (1, 256) <class 'numpy.float32'> [[  9.32417437e-02   1.50699928e-01  -1.76128924e-01  -4.32734042e-02
    1.57478765e-01  -1.16951525e-01   1.08591586e-01  -5.32742292e-02
    5.22545725e-02  -7.61003792e-02   1.40860304e-02   9.75711495e-02
    1.24880746e-01  -1.76228777e-01   5.62984496e-02  -1.14225909e-01
    5.16672432e-02   1.74230158e-01  -3.21136303e-02   9.65108424e-02
   -1.73672616e-01  -1.01476267e-01  -1.72541797e-01   7.62017369e-02
    1.02131516e-02  -1.12412125e-02  -2.71728873e-01  -1.01717070e-01
   -7.43922144e-02   9.35713649e-02   3.90658490e-02  -1.69122279e-01
    2.11932838e-01  -6.40746951e-03   1.55392006e-01   1.56788290e-01
    9.20919925e-02  -1.69804230e-01  -1.82293653e-01   7.80572891e-02
   -1.23914674e-01   9.32287127e-02  -1.56311527e-01   7.13763982e-02
   -4.82064933e-02  -1.52834393e-02   6.92724884e-02   1.27235383e-01
    1.29448175e-01   1.27722025e-02   2.60620490e-02   1.22567624e-01
    7.05835000e-02  -3.53748277e-02   2.12218612e-01   1.15419723e-01
   -9.71969143e-02  -3.18692401e-02   1.60103843e-01  -9.02266949e-02
    1.05232373e-01  -5.14260978e-02   1.35810241e-01   2.22736299e-01
   -1.51299343e-01   8.47756416e-02   3.32823396e-02   1.95251063e-01
    8.88542384e-02  -2.06878960e-01   5.89077845e-02  -7.59810358e-02
   -2.67073900e-01   8.05966556e-02   8.29582959e-02   1.22081667e-01
    1.14973560e-01  -2.81032979e-01   1.32766649e-01  -1.98045984e-01
    1.33817241e-01  -1.76937431e-01   9.08652395e-02   5.96285015e-02
   -1.04231626e-01  -2.04105794e-01   8.80271792e-02  -1.92894593e-01
    5.47970273e-02   1.03326984e-01   1.18793517e-01   1.10582307e-01
   -9.77917463e-02  -7.22171813e-02  -1.94388032e-01  -8.25184025e-03
   -1.54352188e-02  -2.44722739e-01   6.05260432e-02   1.52433395e-01
   -4.91927192e-02  -2.87368745e-02  -5.66580221e-02   1.73768565e-01
   -9.78092030e-02  -1.20437682e-01   5.17582409e-02   1.47393629e-01
    8.22628364e-02   2.06296086e-01  -1.25295550e-01  -1.49136797e-01
    1.67855948e-01   1.61886692e-01  -2.00985074e-02   1.83183402e-01
    1.05959594e-01   6.93894252e-02   1.43939465e-01  -3.29326466e-02
    2.48391293e-02  -1.97931260e-01   1.66526526e-01  -4.35720012e-02
    2.84070730e-01  -2.41711698e-02   1.53969854e-01   9.17461962e-02
   -1.77258372e-01  -2.54690707e-01  -2.20785849e-02   1.14988506e-01
    5.75198233e-02  -4.98022288e-02   1.93000376e-01   1.70942694e-01
   -5.40492758e-02   1.15736082e-01  -2.24851206e-01  -8.62555429e-02
   -5.39740436e-02   1.60237104e-01  -1.66289583e-01  -2.57664397e-02
    1.65915281e-01   5.51294610e-02   1.46041512e-01  -6.21767528e-02
    1.23048693e-01  -9.78187323e-02   1.45432338e-01  -1.53114974e-01
    1.52899146e-01   2.79841483e-01   9.56135392e-02  -2.04758674e-01
    1.55368224e-01  -5.67390472e-02   8.44321251e-02   7.06439614e-02
    2.70423502e-01   1.06777355e-01   2.18583047e-01   1.36344492e-01
   -1.12419687e-01   8.31446201e-02  -6.37512654e-02   1.32926852e-01
   -1.43950120e-01  -1.14849687e-01   1.03884026e-01   2.33129770e-01
   -1.18121698e-01   1.51363418e-01  -1.02878317e-01  -9.28500146e-02
    8.77561569e-02   1.77070647e-01  -1.66671842e-01  -4.23874632e-02
    2.02071607e-01   1.39980346e-01   9.18664932e-02   1.32353619e-01
   -8.18211064e-02  -1.34708390e-01  -1.05515316e-01   2.49861509e-01
    6.73430115e-02  -6.29900098e-02   6.61205426e-02  -1.63711011e-01
   -1.80390924e-01   1.64142266e-01   8.25863183e-02  -1.20236725e-01
    4.93577383e-02  -1.93506747e-01   1.34893090e-01  -1.16363168e-04
    1.10080868e-01  -1.63067713e-01  -1.11697592e-01  -3.67215276e-02
   -1.26627505e-01   1.39757141e-01   2.88920254e-02   4.05080393e-02
    7.03409910e-02   1.81244627e-01  -9.90150645e-02   2.07132071e-01
    1.07872121e-01   2.76338868e-02   2.16349021e-01  -1.94727063e-01
   -1.06444493e-01  -1.82501450e-01  -4.26606685e-02   2.36124173e-02
   -9.68844742e-02   8.00348967e-02   1.83300570e-01  -2.16079324e-01
    9.17046815e-02  -3.35811436e-01  -2.49973014e-01  -1.94323778e-01
    5.57392426e-02  -3.45840715e-02  -8.68209302e-02  -1.59673691e-01
   -5.67508191e-02   2.65820086e-01  -7.42358640e-02  -2.38656551e-02
    2.60730892e-01   2.02618584e-01  -3.74571532e-02   2.18556240e-01
    1.04612783e-01   9.66300368e-02  -2.48367950e-01  -1.27304390e-01
    1.75173223e-01  -1.07189678e-01   7.21335411e-04  -1.08319752e-01
   -1.80600971e-01   1.50393680e-01  -1.34102151e-01  -6.01972491e-02
   -1.48501128e-01  -1.02807797e-01  -1.34179462e-02   1.77134275e-01]]
After layer encoder_birnn_forward_l0_t1_slice_output3 (1, 256) <class 'numpy.float32'> [[ 0.07576629  0.09534562  0.04188716  0.08033836  0.09128739  0.12216613
   0.1858893   0.04424877  0.15666737  0.11922611  0.0737364   0.08174238
   0.09602019  0.15557428 -0.01519001 -0.00163826  0.10543948  0.02686468
   0.25297436  0.10145502  0.09763227  0.00900339  0.22937958  0.11432964
   0.1486934   0.16769111  0.20304441  0.08686364  0.05878137  0.15726012
   0.13340363  0.17399442  0.07425293  0.1546751   0.1840806   0.06044569
   0.12274093  0.08911209  0.02645063  0.15574747  0.19595912  0.10872778
   0.02393114  0.13692178  0.11797371  0.16458759  0.16191126  0.05573892
   0.16963044  0.0855522  -0.0291797   0.10998444  0.36850566  0.0447823
   0.0753223   0.00386897  0.1767164   0.03665584  0.14610317  0.19052528
   0.06480456  0.12757419  0.0086682   0.30958152  0.12455859  0.15990591
   0.2066837   0.11465178  0.08031432  0.1310457   0.17901877  0.16833177
   0.1311779   0.08067671  0.09276327  0.23887023  0.06468423  0.231369
   0.19451711  0.09216298  0.12794846 -0.05532604  0.39751917  0.11437076
   0.19366261  0.15235892  0.10524339  0.09363985  0.27730119  0.06861468
   0.05689754  0.06446955  0.09440662  0.2213396   0.13446493  0.18282494
   0.10635     0.2241535   0.14472635  0.30227435  0.07323787  0.02483983
   0.156387    0.18091822  0.1224779   0.00210871  0.15220572  0.20409259
   0.16422068  0.13540678  0.12708136  0.17422208  0.1607925   0.24009427
   0.14584605  0.05861449  0.10910143  0.16862005  0.11725215  0.23138738
   0.10849968  0.28269508  0.08076705  0.13915092  0.10676225  0.08062264
   0.06417906  0.03722137  0.05328944  0.20355502  0.10803392  0.16998735
   0.05892018  0.14242485  0.05795499  0.05591989  0.0254039   0.1114035
   0.09981817  0.17150119  0.1210395  -0.00341545  0.14865157  0.09070945
   0.07644239  0.04038642 -0.02240765  0.13566114  0.02661012  0.07925803
   0.12783369  0.09227595  0.16391531  0.11633807  0.13423298  0.08732972
   0.16309431  0.16535196  0.18378934  0.08674794  0.12002513  0.12349346
   0.0626851   0.16935411  0.1761021   0.0319273   0.15708044  0.0997391
   0.08312561 -0.0103374   0.19232304  0.34148118  0.14353612  0.25607258
  -0.01776051  0.09382842  0.09127584  0.09438393  0.01946347  0.04691093
   0.07815364  0.14715551  0.17094205  0.1069809  -0.01642482  0.12201225
   0.10197566  0.09696175  0.13196434  0.13279614 -0.07640439  0.0446622
   0.20372945  0.15609866  0.043721    0.14099348  0.5141921   0.03791754
   0.18827555  0.01341378  0.03323595  0.0137649   0.17787126  0.08022045
   0.17530915  0.17783308  0.04377048 -0.03224816 -0.02875167  0.19191007
   0.18834326  0.03969479  0.15889183  0.2371873   0.18274626  0.20302159
   0.19886363  0.06807961  0.14106989  0.03801162  0.08640657  0.21774612
   0.07507682  0.01702254  0.15971625  0.09439285  0.04773761  0.14409329
   0.05297889  0.07824915  0.11469369  0.06813996  0.08136589  0.0643573
   0.13362512  0.06500526  0.03682145  0.09050647  0.01581085  0.1458143
   0.04659291  0.26717019  0.38502583  0.07091407  0.09779277  0.08252329
   0.11280466  0.05336217  0.15445407  0.056608    0.14727628  0.12810229
   0.18371777  0.09385406  0.16083995  0.09332882]]
After layer encoder_birnn_forward_l0_t1_o_output (1, 256) <class 'numpy.float32'> [[ 0.51893258  0.52381837  0.51047027  0.52007383  0.52280599  0.53050363
   0.54633898  0.51106036  0.53908694  0.52977127  0.51842576  0.52042425
   0.52398664  0.53881532  0.49620256  0.49959043  0.52633554  0.50671577
   0.56290847  0.52534205  0.52438867  0.50225085  0.55709481  0.52855128
   0.53710502  0.54182482  0.55058742  0.52170229  0.51469111  0.53923422
   0.53330153  0.5433892   0.51855475  0.53859186  0.54589063  0.51510686
   0.5306468   0.52226329  0.50661224  0.53885835  0.54883361  0.52715522
   0.50598252  0.53417706  0.52945924  0.54105425  0.54038966  0.51393116
   0.54230624  0.521375    0.49270558  0.52746844  0.59109789  0.51119369
   0.51882172  0.50096726  0.54406446  0.50916296  0.536461    0.54748774
   0.51619548  0.5318504   0.50216705  0.57678312  0.5310995   0.53989148
   0.5514878   0.52863163  0.52006781  0.53271461  0.54463553  0.54198384
   0.53274751  0.52015823  0.52317417  0.55943519  0.51616544  0.5575856
   0.54847652  0.52302444  0.53194356  0.48617199  0.59809142  0.52856153
   0.54826492  0.5380162   0.5262866   0.52339286  0.56888443  0.51714694
   0.51422054  0.51611185  0.52358419  0.5551101   0.53356564  0.54557937
   0.52656251  0.55580491  0.53611857  0.57499838  0.51830131  0.50620961
   0.53901726  0.54510659  0.53058124  0.50052714  0.53797811  0.55084682
   0.54096317  0.53380007  0.53172767  0.54344571  0.54011178  0.55973685
   0.53639704  0.51464939  0.52724832  0.54205543  0.52927953  0.55759013
   0.52709836  0.57020682  0.52018076  0.53473169  0.52666521  0.52014476
   0.51603925  0.50930429  0.51331919  0.55071378  0.52698225  0.54239482
   0.5147258   0.53554612  0.5144847   0.51397634  0.50635064  0.52782208
   0.52493382  0.5427705   0.53022301  0.49914613  0.53709459  0.52266186
   0.51910132  0.51009524  0.4943983   0.53386337  0.50665212  0.51980412
   0.53191501  0.52305263  0.5408873   0.52905178  0.53350794  0.52181858
   0.54068339  0.54124409  0.54581845  0.52167338  0.52997035  0.5308342
   0.51566613  0.54223764  0.54391211  0.50798112  0.53918958  0.52491415
   0.52076948  0.49741569  0.5479331   0.58455026  0.53582257  0.56367064
   0.49556002  0.52343988  0.52280313  0.52357846  0.50486571  0.5117256
   0.51952845  0.5367226   0.54263175  0.52671975  0.49589387  0.5304653
   0.52547187  0.52422148  0.53294331  0.53315032  0.48090816  0.51116371
   0.55075699  0.53894562  0.51092851  0.53519011  0.62578869  0.50947821
   0.54693037  0.50335342  0.50830823  0.50344121  0.54435092  0.52004439
   0.54371542  0.54434144  0.51094091  0.49193868  0.49281254  0.54783082
   0.54694712  0.50992239  0.53963959  0.55902034  0.54555988  0.55058181
   0.54955274  0.51701337  0.53520912  0.50950176  0.52158821  0.55422246
   0.51876038  0.50425559  0.53984445  0.52358073  0.51193213  0.53596115
   0.51324165  0.51955235  0.528642    0.51702839  0.52033025  0.51608378
   0.53335667  0.5162456   0.50920433  0.5226112   0.50395262  0.53638911
   0.51164609  0.56639808  0.59508473  0.51772112  0.52442873  0.52061915
   0.5281713   0.51333737  0.53853697  0.51414824  0.5367527   0.53198183
   0.54580069  0.52344632  0.54012352  0.52331531]]
After layer encoder_birnn_forward_l0_t1_f_output (1, 256) <class 'numpy.float32'> [[ 0.54275548  0.51604629  0.52369618  0.50878584  0.53804433  0.52039969
   0.51582658  0.50175023  0.55043668  0.53077269  0.55309331  0.53480393
   0.51565689  0.53354889  0.47780314  0.52555072  0.51843238  0.52826971
   0.56366342  0.51847231  0.51115859  0.51580709  0.53868383  0.51938015
   0.5177604   0.4868477   0.52576697  0.50183594  0.49839512  0.51516312
   0.53596163  0.53132921  0.52123517  0.52678806  0.54833853  0.49344781
   0.52478778  0.52105361  0.51591438  0.50694031  0.50829011  0.53687406
   0.54457885  0.50445181  0.51284409  0.52951896  0.5348779   0.52622736
   0.52522153  0.51522833  0.51054877  0.52008587  0.57184154  0.51040828
   0.50864887  0.51340079  0.53914118  0.5142594   0.50074393  0.53774542
   0.50527662  0.49365789  0.50426167  0.54707414  0.5306102   0.54318053
   0.53426516  0.5180009   0.50211519  0.51913774  0.52592707  0.51738721
   0.52321315  0.52828413  0.51237863  0.55672097  0.53624904  0.57933986
   0.51989412  0.48511431  0.54720247  0.50367272  0.58792239  0.53647012
   0.52612537  0.49763882  0.51600915  0.53236574  0.56969059  0.51598978
   0.50388277  0.49319199  0.49489945  0.50598693  0.50960314  0.52632833
   0.50824416  0.53354305  0.52780694  0.53025705  0.50838166  0.52390921
   0.52012831  0.53866434  0.52811337  0.49654362  0.51061434  0.5071972
   0.53439176  0.54003918  0.52990741  0.53762615  0.55952954  0.53547233
   0.51453167  0.52039844  0.54450738  0.55518895  0.5201382   0.526851
   0.50120533  0.55049711  0.54381692  0.50955349  0.54457235  0.52990651
   0.52517891  0.53353959  0.51508474  0.55887443  0.50883347  0.53817105
   0.5143736   0.51362067  0.50430077  0.50824583  0.52701253  0.4931469
   0.56140518  0.50838643  0.51532125  0.55174053  0.51458859  0.51668012
   0.51888651  0.54025745  0.52476227  0.50337863  0.52026087  0.5097822
   0.53005803  0.51746154  0.5032348   0.51684099  0.5273872   0.53661376
   0.51923817  0.51487041  0.53711182  0.5287267   0.53334898  0.52814573
   0.52629429  0.5288319   0.52637535  0.49636617  0.50803208  0.52329761
   0.51936454  0.5075829   0.49895424  0.55587703  0.51732314  0.53368324
   0.50368595  0.50766432  0.52219313  0.522439    0.50049973  0.5199334
   0.54510748  0.4964315   0.54536319  0.53355682  0.4911226   0.51737732
   0.52233934  0.53229862  0.52923894  0.52983904  0.50479048  0.49447039
   0.53449583  0.52781647  0.48258239  0.52284175  0.62353969  0.50601298
   0.50327176  0.49457854  0.53753477  0.51780373  0.53018016  0.53047514
   0.53212696  0.52181256  0.52726871  0.49855524  0.49559578  0.52536154
   0.53703457  0.51197308  0.52884656  0.50135243  0.58176774  0.51168466
   0.51614076  0.52712435  0.50790244  0.49124932  0.51532596  0.52115959
   0.49135688  0.53235722  0.50798661  0.55398107  0.51458555  0.50495046
   0.53607386  0.51686746  0.52697331  0.53899008  0.53152287  0.52225846
   0.53681022  0.5354206   0.52712464  0.4977046   0.51453078  0.54165602
   0.51629215  0.54165196  0.61504263  0.50547284  0.51911134  0.51866084
   0.51356733  0.50499302  0.54736161  0.52735424  0.53837854  0.49497893
   0.54184783  0.50878143  0.52916384  0.52570271]]
After layer _mul2054_0 (1, 256) <class 'numpy.float32'> [[ 0.00380568  0.02279182 -0.00644913 -0.00886913  0.03206866 -0.00689286
   0.01164648 -0.03733673  0.0157511   0.00412976  0.01879015  0.00619681
   0.02287112 -0.01131369  0.02638831 -0.00861199 -0.00452475  0.00447353
  -0.00982183 -0.00503071  0.00750176 -0.03005144 -0.03626909  0.02927346
   0.00219851 -0.01607911 -0.01332829 -0.0133283  -0.01251488  0.01007779
   0.01381113 -0.0157189   0.01001556 -0.00765376  0.02246054  0.00824998
   0.00977521 -0.00797644 -0.01351206 -0.00789681 -0.01359409  0.027628
  -0.00585788  0.01813521 -0.02312817 -0.02187537  0.00355631  0.02264581
   0.01597665 -0.00470477 -0.00227072 -0.01840803  0.02527366 -0.0258992
   0.00795488  0.03330981  0.00968226 -0.01650772  0.02141098 -0.01402552
   0.01960644 -0.0167245   0.00321525  0.00543543 -0.00316345 -0.00616758
   0.00553226  0.01899279 -0.00104589 -0.01912883 -0.00037078 -0.02595321
  -0.03576327  0.02052845  0.04035207 -0.00142817  0.03845887 -0.04235756
   0.03408297 -0.01239432  0.02477464 -0.01198542  0.05049598  0.00691074
   0.00517447 -0.00973858  0.01553466 -0.03249373 -0.02037477  0.02180459
  -0.00774837  0.01653123 -0.02247165 -0.01340806 -0.02162429  0.0124458
   0.0051525  -0.04117313  0.02009469  0.02762766 -0.03128268 -0.00461814
   0.0004095   0.0046124   0.01264669 -0.02100745  0.00447469  0.03036656
   0.02436336  0.01567073  0.00688769 -0.02292148  0.04545169  0.04960383
  -0.01670969 -0.00244791  0.01701875  0.04403388  0.00525669  0.01105175
   0.0034295  -0.0310392   0.03425127 -0.03267359  0.02735712 -0.00706735
   0.01313672  0.02589003  0.00155319 -0.04693219  0.00025589  0.00772974
   0.01786793 -0.01153331  0.01836225  0.02483827  0.01569603  0.03246982
  -0.03066731  0.00219964 -0.01679622  0.03979453 -0.02846174 -0.02130154
   0.02882788  0.02596304  0.01510909 -0.01668824  0.04007028 -0.01786857
  -0.00423262  0.00333167  0.0238848   0.02621063  0.01810686 -0.02530102
   0.02160337  0.01137843  0.01642391  0.00510641  0.00448524  0.01431662
  -0.00258251  0.00604597 -0.01695038  0.01535576 -0.03757439 -0.00400731
  -0.03063756 -0.01414545  0.00165441 -0.00308732 -0.00368968 -0.00304673
   0.00506882 -0.01028152  0.04398613  0.00090236 -0.01322007  0.0022142
   0.01622484  0.0196244   0.01809154  0.00085932  0.00569677 -0.02104797
   0.00208417  0.00770538  0.01152172  0.00558047  0.00747662 -0.00864501
  -0.03948211  0.04967137  0.00078463 -0.04504013 -0.02910716 -0.02323107
   0.01776976  0.02619295  0.02990483 -0.02969878 -0.00077835 -0.00365511
  -0.02195624 -0.00232183  0.0079209   0.01868084  0.013773   -0.00062399
   0.00382949  0.02176633  0.02486906 -0.00814213  0.00025663 -0.00073798
  -0.01664997 -0.02497581 -0.01901985  0.00248658 -0.01298759  0.01041325
   0.00885169 -0.04370368  0.02233807 -0.01113869 -0.03295069 -0.00620317
   0.00392932 -0.01658135 -0.01262405 -0.0136074   0.01795183  0.01320959
  -0.01733404 -0.00511544  0.01336446  0.02530837 -0.00924486 -0.0007448
   0.01099843  0.02520825 -0.0020378  -0.0244599   0.01489467 -0.02483549
   0.01380985 -0.0131805  -0.02344668  0.00698372 -0.02144825  0.00285008
   0.00576666 -0.02940344  0.0190529   0.00029336]]
After layer encoder_birnn_forward_l0_t1_i_output (1, 256) <class 'numpy.float32'> [[ 0.53139877  0.49642763  0.54460818  0.53456455  0.52387154  0.51586229
   0.51974785  0.51794672  0.50776565  0.51821476  0.53586799  0.53136563
   0.50311655  0.52367777  0.49541789  0.51617634  0.4954859   0.53926343
   0.53114879  0.52117348  0.49831259  0.51425433  0.55453819  0.50296825
   0.50927526  0.50670159  0.53878844  0.49968359  0.51323283  0.51309097
   0.50735551  0.54025376  0.53524566  0.50295448  0.52559471  0.51498896
   0.50830919  0.56193733  0.54236269  0.50087178  0.52166778  0.52373189
   0.55119771  0.50609428  0.52195543  0.52405465  0.53853405  0.51518655
   0.52318674  0.51345998  0.51816601  0.48796344  0.57376289  0.51149184
   0.53511316  0.51721573  0.51180375  0.51597023  0.51971895  0.4875738
   0.51002938  0.53997254  0.52996343  0.57137156  0.53456134  0.49054822
   0.55906999  0.51446015  0.50056869  0.5281058   0.50724417  0.50495028
   0.56090617  0.50530219  0.51475215  0.52352291  0.53696847  0.54833823
   0.52737385  0.51346648  0.53097391  0.51854485  0.56666178  0.50144613
   0.53501785  0.53411353  0.528916    0.54850137  0.57516396  0.49609089
   0.5108822   0.50628275  0.50261527  0.54010677  0.51311237  0.53048968
   0.51886779  0.55936176  0.53036159  0.52553487  0.51836246  0.48919442
   0.52837402  0.51960468  0.53454036  0.50389338  0.53000617  0.51477575
   0.51206142  0.52588266  0.55978972  0.54466373  0.52852517  0.53571248
   0.52310753  0.50823545  0.54130572  0.52071393  0.5035187   0.54662931
   0.4972567   0.54781276  0.54653841  0.51055074  0.5550099   0.51582259
   0.51936865  0.51817149  0.52704555  0.57146651  0.51693392  0.53706592
   0.51412064  0.51502508  0.54506302  0.52586848  0.4968881   0.51410264
   0.54423821  0.5303148   0.48878634  0.51598084  0.52940238  0.52892041
   0.50710905  0.48566389  0.52028739  0.49115118  0.51530015  0.50911611
   0.55276072  0.52920043  0.53705823  0.53572083  0.50946021  0.54038686
   0.50746781  0.52569842  0.53383774  0.53006858  0.55347496  0.49173594
   0.51997185  0.51936454  0.52463996  0.50907594  0.51642233  0.51596528
   0.5406872   0.50486982  0.50282741  0.59828424  0.54694432  0.54728526
   0.53432405  0.49887392  0.50634545  0.50394475  0.50565821  0.51412523
   0.53441542  0.5116207   0.52053678  0.5140847   0.48101002  0.50721586
   0.52990997  0.51886564  0.53766751  0.53630388  0.51376158  0.52648944
   0.53111494  0.536048    0.51059228  0.51327461  0.58267307  0.52745932
   0.54701203  0.52107012  0.5402115   0.53009242  0.51944453  0.49342158
   0.53432035  0.49515095  0.53493923  0.50725663  0.51121897  0.51200587
   0.52822977  0.51565558  0.52475494  0.51974624  0.56619984  0.53138274
   0.51620746  0.55870885  0.4998602   0.52473706  0.52202207  0.53021884
   0.51764274  0.52866924  0.53039145  0.57270241  0.53114629  0.49226639
   0.52875608  0.49852118  0.4984524   0.57622528  0.50752723  0.52585018
   0.51672673  0.51231903  0.51950824  0.51544178  0.51318002  0.56841773
   0.50072038  0.51873171  0.5779897   0.5146507   0.53424728  0.51437587
   0.51874298  0.50845897  0.52460915  0.53707063  0.53888559  0.49194485
   0.54369634  0.49413583  0.50139338  0.5478338 ]]
After layer encoder_birnn_forward_l0_t1_c_output (1, 256) <class 'numpy.float32'> [[  9.29724649e-02   1.49569377e-01  -1.74329996e-01  -4.32464145e-02
    1.56189755e-01  -1.16421223e-01   1.08166754e-01  -5.32238856e-02
    5.22070639e-02  -7.59538114e-02   1.40850991e-02   9.72626954e-02
    1.24235593e-01  -1.74426809e-01   5.62390462e-02  -1.13731705e-01
    5.16213179e-02   1.72488332e-01  -3.21025960e-02   9.62123126e-02
   -1.71947315e-01  -1.01129383e-01  -1.70849726e-01   7.60545880e-02
    1.02127967e-02  -1.12407394e-02  -2.65232801e-01  -1.01367719e-01
   -7.42552876e-02   9.32992324e-02   3.90459895e-02  -1.67528093e-01
    2.08815813e-01  -6.40738197e-03   1.54153243e-01   1.55516058e-01
    9.18325335e-02  -1.68190822e-01  -1.80300876e-01   7.78991431e-02
   -1.23284318e-01   9.29595456e-02  -1.55050784e-01   7.12554380e-02
   -4.81691882e-02  -1.52822491e-02   6.91618994e-02   1.26553208e-01
    1.28729939e-01   1.27715077e-02   2.60561500e-02   1.21957526e-01
    7.04665184e-02  -3.53600793e-02   2.09089100e-01   1.14909917e-01
   -9.68919918e-02  -3.18584554e-02   1.58749744e-01  -8.99826512e-02
    1.04845643e-01  -5.13808131e-02   1.34981379e-01   2.19124541e-01
   -1.50155336e-01   8.45731348e-02   3.32700573e-02   1.92807138e-01
    8.86211395e-02  -2.03977227e-01   5.88397421e-02  -7.58351609e-02
   -2.60899991e-01   8.04225951e-02   8.27685148e-02   1.21478766e-01
    1.14469618e-01  -2.73860842e-01   1.31992027e-01  -1.95496708e-01
    1.33024171e-01  -1.75113812e-01   9.06159878e-02   5.95579334e-02
   -1.03855796e-01  -2.01317951e-01   8.78005177e-02  -1.90537244e-01
    5.47422469e-02   1.02960825e-01   1.18237861e-01   1.10133752e-01
   -9.74811986e-02  -7.20918998e-02  -1.91976056e-01  -8.25165305e-03
   -1.54339932e-02  -2.39951581e-01   6.04522415e-02   1.51263624e-01
   -4.91530783e-02  -2.87289675e-02  -5.65974750e-02   1.72040433e-01
   -9.74984914e-02  -1.19858719e-01   5.17120734e-02   1.46335453e-01
    8.20777789e-02   2.03418538e-01  -1.24643974e-01  -1.48040861e-01
    1.66297033e-01   1.60487160e-01  -2.00958010e-02   1.81161568e-01
    1.05564818e-01   6.92782700e-02   1.42953560e-01  -3.29207443e-02
    2.48340219e-02  -1.95386365e-01   1.65004104e-01  -4.35444489e-02
    2.76668429e-01  -2.41664629e-02   1.52764589e-01   9.14896429e-02
   -1.75424904e-01  -2.49322906e-01  -2.20749974e-02   1.14484370e-01
    5.74564710e-02  -4.97610942e-02   1.90639183e-01   1.69296876e-01
   -5.39967045e-02   1.15222082e-01  -2.21136957e-01  -8.60422626e-02
   -5.39216921e-02   1.58879638e-01  -1.64773598e-01  -2.57607400e-02
    1.64409429e-01   5.50736785e-02   1.45012036e-01  -6.20967522e-02
    1.22431412e-01  -9.75079313e-02   1.44415617e-01  -1.51929542e-01
    1.51718691e-01   2.72758365e-01   9.53232348e-02  -2.01944292e-01
    1.54130027e-01  -5.66782393e-02   8.42320621e-02   7.05266818e-02
    2.64018863e-01   1.06373399e-01   2.15167120e-01   1.35505855e-01
   -1.11948483e-01   8.29535574e-02  -6.36650398e-02   1.32149428e-01
   -1.42964005e-01  -1.14347368e-01   1.03511937e-01   2.28996113e-01
   -1.17575377e-01   1.50217965e-01  -1.02516897e-01  -9.25841108e-02
    8.75315741e-02   1.75242946e-01  -1.65145457e-01  -4.23620977e-02
    1.99365407e-01   1.39073178e-01   9.16089341e-02   1.31586164e-01
   -8.16390067e-02  -1.33899450e-01  -1.05125472e-01   2.44788468e-01
    6.72413930e-02  -6.29068315e-02   6.60243556e-02  -1.62263975e-01
   -1.78459376e-01   1.62683845e-01   8.23990703e-02  -1.19660646e-01
    4.93176952e-02  -1.91127107e-01   1.34080827e-01  -1.16363168e-04
    1.09638371e-01  -1.61637545e-01  -1.11235373e-01  -3.67050320e-02
   -1.25955015e-01   1.38854280e-01   2.88839880e-02   4.04858962e-02
    7.02252090e-02   1.79285765e-01  -9.86927524e-02   2.04219803e-01
    1.07455648e-01   2.76268553e-02   2.13035509e-01  -1.92302570e-01
   -1.06044292e-01  -1.80501908e-01  -4.26348075e-02   2.36080308e-02
   -9.65824723e-02   7.98644423e-02   1.81274891e-01  -2.12778032e-01
    9.14484710e-02  -3.23732883e-01  -2.44893298e-01  -1.91914171e-01
    5.56815900e-02  -3.45702916e-02  -8.66034403e-02  -1.58330396e-01
   -5.66899739e-02   2.59731144e-01  -7.40997940e-02  -2.38611251e-02
    2.54979044e-01   1.99890584e-01  -3.74396443e-02   2.15141565e-01
    1.04232825e-01   9.63304043e-02  -2.43383899e-01  -1.26621112e-01
    1.73403189e-01  -1.06781036e-01   7.21335295e-04  -1.07898086e-01
   -1.78662717e-01   1.49269968e-01  -1.33304030e-01  -6.01246431e-02
   -1.47419065e-01  -1.02447115e-01  -1.34171406e-02   1.75304621e-01]]
After layer _mul2055_0 (1, 256) <class 'numpy.float32'> [[  4.94054556e-02   7.42503703e-02  -9.49415416e-02  -2.31180005e-02
    8.18233639e-02  -6.00573197e-02   5.62194400e-02  -2.75671370e-02
    2.65089534e-02  -3.93603854e-02   7.54775386e-03   5.16820550e-02
    6.25049844e-02  -9.13434401e-02   2.78618298e-02  -5.87056167e-02
    2.55776346e-02   9.30166468e-02  -1.70512553e-02   5.01433052e-02
   -8.56835097e-02  -5.20062223e-02  -9.47427005e-02   3.82530428e-02
    5.20112459e-03  -5.69570065e-03  -1.42904371e-01  -5.06517850e-02
   -3.81102525e-02   4.78709936e-02   1.98101979e-02  -9.05076787e-02
    1.11767754e-01  -3.22262151e-03   8.10221285e-02   8.00890550e-02
    4.66793217e-02  -9.45127010e-02  -9.77884680e-02   3.90174836e-02
   -6.43134564e-02   4.86858785e-02  -8.54636356e-02   3.60619687e-02
   -2.51421686e-02  -8.00873339e-03   3.72460373e-02   6.51985109e-02
    6.73497990e-02   6.55765831e-03   1.35014113e-02   5.95108122e-02
    4.04310748e-02  -1.80863924e-02   1.11886330e-01   5.94332181e-02
   -4.95896861e-02  -1.64380148e-02   8.25052485e-02  -4.38731834e-02
    5.34743592e-02  -2.77442280e-02   7.15351924e-02   1.25201523e-01
   -8.02672356e-02   4.14872020e-02   1.86002906e-02   9.91915911e-02
    4.43609692e-02  -1.07721552e-01   2.98461169e-02  -3.82929854e-02
   -1.46340415e-01   4.06377129e-02   4.26052697e-02   6.35969192e-02
    6.14665747e-02  -1.50168374e-01   6.96091428e-02  -1.00381009e-01
    7.06323609e-02  -9.08043683e-02   5.13486154e-02   2.98650954e-02
   -5.55647053e-02  -1.07526638e-01   4.64391001e-02  -1.04509942e-01
    3.14857662e-02   5.10779284e-02   6.04056194e-02   5.57588190e-02
   -4.89955395e-02  -3.89373228e-02  -9.85052884e-02  -4.37741680e-03
   -8.00820161e-03  -1.34219736e-01   3.20615470e-02   7.94943124e-02
   -2.54791100e-02  -1.40540507e-02  -2.99046356e-02   8.93930122e-02
   -5.21168783e-02  -6.03960156e-02   2.74077188e-02   7.53299445e-02
    4.20288630e-02   1.06974281e-01  -6.97744116e-02  -8.06324854e-02
    8.78921673e-02   8.59749764e-02  -1.05122644e-02   9.20727327e-02
    5.71428388e-02   3.60741615e-02   7.19797909e-02  -1.79954432e-02
    1.23488838e-02  -1.07035145e-01   9.01810825e-02  -2.22316496e-02
    1.53553724e-01  -1.24656074e-02   7.93411359e-02   4.74073254e-02
   -9.24569145e-02  -1.42479688e-01  -1.14113148e-02   6.14856519e-02
    2.95395572e-02  -2.56282110e-02   1.03910372e-01   8.90278891e-02
   -2.68303193e-02   5.92359751e-02  -1.20351180e-01  -4.56294864e-02
   -2.63561867e-02   8.19788501e-02  -8.72315317e-02  -1.36253815e-02
    8.33735093e-02   2.67472975e-02   7.54479319e-02  -3.04988939e-02
    6.30889237e-02  -4.96428572e-02   7.98272789e-02  -8.04011822e-02
    8.14817697e-02   1.46122336e-01   4.85633947e-02  -1.09128043e-01
    7.82160237e-02  -2.97956616e-02   4.49662544e-02   3.73839773e-02
    1.46127835e-01   5.23076244e-02   1.11880846e-01   7.03769326e-02
   -5.87326474e-02   4.22296599e-02  -3.28780487e-02   6.81845173e-02
   -7.72988051e-02  -5.77305369e-02   5.20486385e-02   1.37004763e-01
   -6.43071830e-02   8.22120756e-02  -5.47772422e-02  -4.61877994e-02
    4.43212129e-02   8.83127600e-02  -8.35071579e-02  -2.17794236e-02
    1.06543951e-01   7.11527169e-02   4.76858206e-02   6.76464364e-02
   -3.92691791e-02  -6.79159239e-02  -5.57070337e-02   1.27012327e-01
    3.61535139e-02  -3.37371789e-02   3.39207761e-02  -8.54302719e-02
   -9.47824419e-02   8.72063488e-02   4.20723297e-02  -6.14187717e-02
    2.87360922e-02  -1.00811772e-01   7.33438283e-02  -6.06333706e-05
    5.92279099e-02  -8.56828392e-02  -5.77806048e-02  -1.81110557e-02
   -6.73003271e-02   6.87538311e-02   1.54511780e-02   2.05367394e-02
    3.59004587e-02   9.17953625e-02  -5.21324500e-02   1.05307080e-01
    5.63878827e-02   1.43589545e-02   1.20620668e-01  -1.02186270e-01
   -5.47408536e-02  -1.00848012e-01  -2.13114433e-02   1.23880086e-02
   -5.04181832e-02   4.23456319e-02   9.38356295e-02  -1.12489201e-01
    4.85034883e-02  -1.85402602e-01  -1.30074173e-01  -9.44728926e-02
    2.94419788e-02  -1.72340218e-02  -4.31676917e-02  -9.12339762e-02
   -2.87717059e-02   1.36579663e-01  -3.82893458e-02  -1.22245084e-02
    1.32463709e-01   1.03031956e-01  -1.92132778e-02   1.22290276e-01
    5.21914996e-02   4.99696359e-02  -1.40673384e-01  -6.51656464e-02
    9.26401839e-02  -5.49255870e-02   3.74187628e-04  -5.48617505e-02
   -9.37280953e-02   8.01685154e-02  -7.18356222e-02  -2.95780078e-02
   -8.01512077e-02  -5.06227911e-02  -6.72726566e-03   9.60377976e-02]]
After layer encoder_birnn_forward_l0_t1_state_0 (1, 256) <class 'numpy.float32'> [[ 0.05321113  0.0970422  -0.10139067 -0.03198713  0.11389202 -0.06695018
   0.06786592 -0.06490386  0.04226005 -0.03523063  0.02633791  0.05787886
   0.0853761  -0.10265713  0.05425014 -0.06731761  0.02105289  0.09749018
  -0.02687308  0.0451126  -0.07818175 -0.08205766 -0.13101178  0.0675265
   0.00739963 -0.02177481 -0.15623266 -0.06398009 -0.05062513  0.05794879
   0.03362133 -0.10622658  0.12178331 -0.01087638  0.10348267  0.08833903
   0.05645453 -0.10248914 -0.11130053  0.03112067 -0.07790755  0.07631388
  -0.09132151  0.05419718 -0.04827034 -0.02988411  0.04080235  0.08784432
   0.08332644  0.00185289  0.01123069  0.04110278  0.06570473 -0.04398559
   0.11984121  0.09274302 -0.03990743 -0.03294574  0.10391624 -0.05789871
   0.0730808  -0.04446873  0.07475045  0.13063696 -0.08343069  0.03531962
   0.02413255  0.11818438  0.04331508 -0.12685038  0.02947534 -0.06424619
  -0.18210369  0.06116617  0.08295734  0.06216875  0.09992544 -0.19252592
   0.10369211 -0.11277533  0.09540699 -0.10278979  0.10184459  0.03677583
  -0.05039024 -0.11726521  0.06197377 -0.13700366  0.011111    0.07288252
   0.05265725  0.07229005 -0.07146718 -0.05234538 -0.12012959  0.00806839
  -0.00285571 -0.17539287  0.05215623  0.10712197 -0.05676179 -0.01867219
  -0.02949514  0.09400541 -0.03947018 -0.08140346  0.03188241  0.1056965
   0.06639222  0.12264501 -0.06288671 -0.10355397  0.13334386  0.13557881
  -0.02722196  0.08962482  0.07416159  0.08010805  0.07723648 -0.00694369
   0.01577838 -0.13807434  0.12443235 -0.05490524  0.18091084 -0.01953296
   0.09247786  0.07329735 -0.09090372 -0.18941188 -0.01115543  0.06921539
   0.04740749 -0.03716151  0.12227262  0.11386615 -0.01113429  0.0917058
  -0.15101849 -0.04342985 -0.04315241  0.12177338 -0.11569327 -0.03492692
   0.11220139  0.05271034  0.09055702 -0.04718713  0.1031592  -0.06751142
   0.07559466 -0.07706951  0.10536657  0.17233297  0.06667025 -0.13442907
   0.0998194  -0.01841723  0.06139017  0.04249039  0.15061307  0.06662425
   0.10929834  0.07642291 -0.07568303  0.05758542 -0.07045244  0.06417721
  -0.10793637 -0.07187599  0.05370305  0.13391745 -0.06799686  0.07916534
  -0.04970842 -0.05646932  0.08830734  0.08921512 -0.09672723 -0.01956522
   0.12276879  0.09077711  0.06577736  0.06850576 -0.03357241 -0.08896389
  -0.05362286  0.13471772  0.04767524 -0.02815671  0.0413974  -0.09407528
  -0.13426454  0.13687772  0.04285696 -0.1064589  -0.00037107 -0.12404285
   0.09111359  0.02613232  0.08913273 -0.11538162 -0.05855896 -0.02176616
  -0.08925657  0.066432    0.02337208  0.03921758  0.04967346  0.09117137
  -0.04830296  0.12707341  0.08125694  0.00621682  0.1208773  -0.10292425
  -0.07139082 -0.12582383 -0.04033129  0.01487459 -0.06340577  0.05275888
   0.10268732 -0.15619288  0.07084157 -0.19654129 -0.16302487 -0.10067606
   0.0333713  -0.03381537 -0.05579174 -0.10484137 -0.01081987  0.14978926
  -0.05562338 -0.01733995  0.14582817  0.12834033 -0.02845814  0.12154547
   0.06318993  0.07517789 -0.14271118 -0.08962554  0.10753486 -0.07976107
   0.01418404 -0.06804225 -0.11717477  0.08715224 -0.09328387 -0.02672793
  -0.07438454 -0.08002623  0.01232564  0.09633116]]
After layer activation1027_output (1, 256) <class 'numpy.float32'> [[ 0.05316097  0.09673872 -0.10104466 -0.03197622  0.11340212 -0.06685033
   0.06776192 -0.06481288  0.04223491 -0.03521606  0.02633182  0.05781432
   0.08516926 -0.10229803  0.05419698 -0.06721611  0.02104978  0.0971825
  -0.02686662  0.04508202 -0.07802285 -0.08187398 -0.13026734  0.06742406
   0.0073995  -0.02177137 -0.1549738  -0.06389293 -0.05058192  0.05788401
   0.03360866 -0.10582882  0.1211848  -0.01087596  0.10311487  0.08810996
   0.05639463 -0.1021318  -0.1108432   0.03111063 -0.07775031  0.07616609
  -0.0910685   0.05414418 -0.04823288 -0.02987521  0.04077972  0.08761907
   0.08313413  0.00185289  0.01123022  0.04107965  0.06561035 -0.04395724
   0.11927077  0.09247804 -0.03988626 -0.03293382  0.1035438  -0.0578341
   0.07295097 -0.04443944  0.07461153  0.12989885 -0.08323765  0.03530494
   0.02412786  0.11763719  0.04328801 -0.12617435  0.0294668  -0.06415795
  -0.18011709  0.06109     0.08276756  0.06208879  0.09959418 -0.19018194
   0.10332207 -0.11229964  0.09511857 -0.1024293   0.10149393  0.03675926
  -0.05034763 -0.11673065  0.06189455 -0.13615286  0.01111054  0.07275374
   0.05260863  0.07216439 -0.07134576 -0.05229762 -0.11955504  0.00806821
  -0.0028557  -0.17361622  0.05210899  0.10671411 -0.05670091 -0.01867002
  -0.02948659  0.09372948 -0.0394497  -0.08122414  0.03187161  0.10530465
   0.06629484  0.12203376 -0.06280395 -0.1031854   0.13255914  0.13475417
  -0.02721524  0.08938562  0.07402593  0.07993713  0.07708327 -0.00694358
   0.01577707 -0.13720354  0.12379409 -0.05485014  0.17896269 -0.01953047
   0.09221513  0.07316637 -0.09065416 -0.18717876 -0.01115496  0.06910507
   0.047372   -0.03714442  0.12166689  0.11337658 -0.01113383  0.09144958
  -0.1498808  -0.04340256 -0.04312564  0.12117501 -0.11517984 -0.03491273
   0.11173291  0.05266158  0.0903103  -0.04715214  0.10279483 -0.06740905
   0.07545099 -0.07691728  0.10497836  0.17064698  0.06657165 -0.13362512
   0.09948919 -0.01841515  0.06131316  0.04246483  0.14948447  0.06652585
   0.10886519  0.07627448 -0.07553886  0.05752185 -0.0703361   0.06408925
  -0.10751915 -0.07175247  0.05365148  0.13312261 -0.06789226  0.07900038
  -0.04966752 -0.05640937  0.08807851  0.08897918 -0.09642669 -0.01956272
   0.12215569  0.09052859  0.06568266  0.06839879 -0.0335598  -0.08872993
  -0.05357153  0.1339086   0.04763915 -0.02814927  0.04137376 -0.09379874
  -0.13346353  0.13602926  0.04283074 -0.10605854 -0.00037107 -0.12341054
   0.0908623   0.02612637  0.08889744 -0.11487231 -0.05849211 -0.02176272
  -0.0890203   0.06633445  0.02336782  0.03919748  0.04963265  0.0909196
  -0.04826543  0.12639382  0.08107857  0.00621674  0.12029199 -0.10256235
  -0.07126979 -0.125164   -0.04030944  0.01487349 -0.06332094  0.05270998
   0.10232791 -0.15493499  0.0707233  -0.19404911 -0.16159582 -0.1003373
   0.03335892 -0.03380249 -0.05573393 -0.10445893 -0.01081945  0.14867896
  -0.05556609 -0.01733821  0.14480318  0.12764031 -0.02845046  0.12095045
   0.06310596  0.07503658 -0.14175017 -0.08938634  0.10712226 -0.07959236
   0.01418309 -0.06793744 -0.11664144  0.08693225 -0.09301423 -0.02672157
  -0.07424765 -0.07985584  0.01232501  0.09603429]]
After layer encoder_birnn_forward_l0_t1_out_0 (1, 256) <class 'numpy.float32'> [[ 0.02758696  0.05067352 -0.05158029 -0.01663     0.05928731 -0.03546434
   0.03702098 -0.0331233   0.02276829 -0.01865645  0.01365109  0.03008797
   0.04462755 -0.05511975  0.02689268 -0.03358052  0.01107924  0.0492439
  -0.01512345  0.02368348 -0.0409143  -0.04112128 -0.07257126  0.03563707
   0.00397431 -0.01179627 -0.08532663 -0.03333309 -0.02603407  0.03121304
   0.01792355 -0.05750624  0.06284095 -0.0058577   0.05628944  0.04538604
   0.02992563 -0.05333969 -0.05615452  0.01676422 -0.04267198  0.04015135
  -0.04607907  0.02892258 -0.02553735 -0.01616411  0.02203694  0.04503017
   0.04508416  0.00096605  0.00553319  0.02166822  0.03878214 -0.02247067
   0.06188027  0.04632847 -0.0217007  -0.01676868  0.05554721 -0.03166346
   0.03765696 -0.02363514  0.03746745  0.07492346 -0.04420747  0.01906084
   0.01330622  0.06218674  0.0225127  -0.06721491  0.01604867 -0.03477257
  -0.09595693  0.03177647  0.04330185  0.03473465  0.05140708 -0.10604271
   0.05666973 -0.05873546  0.05059771 -0.04979826  0.06070265  0.01942953
  -0.02760384 -0.06280298  0.03257427 -0.07126144  0.00632061  0.03762437
   0.02705244  0.03724489 -0.03735551 -0.02903094 -0.06379046  0.00440185
  -0.0015037  -0.09649675  0.0279366   0.06136044 -0.02938816 -0.00945095
  -0.01589378  0.05109256 -0.02093127 -0.04065489  0.01714623  0.05800673
   0.03586307  0.06514163 -0.0333946  -0.05607566  0.07159675  0.07542687
  -0.01459817  0.04600225  0.03903005  0.04333036  0.0407986  -0.00387167
   0.00831607 -0.0782344   0.06439531 -0.02933011  0.09425342 -0.01015867
   0.04758663  0.03726394 -0.04653452 -0.10308192 -0.00587847  0.03748224
   0.02438359 -0.01989255  0.06259575  0.05827288 -0.00563762  0.04826911
  -0.0786775  -0.02355763 -0.02286621  0.06048404 -0.06186247 -0.01824755
   0.0580007   0.02686242  0.04464926 -0.0251728   0.05208122 -0.0350395
   0.04013351 -0.04023178  0.05678146  0.09028109  0.0355165  -0.06972807
   0.05379215 -0.00996709  0.03346585  0.02215277  0.07922234  0.03531419
   0.05613809  0.04135889 -0.0410865   0.02922001 -0.03792449  0.03364135
  -0.05599269 -0.03569081  0.02939742  0.07781686 -0.0363782   0.04453019
  -0.02461324 -0.02952692  0.04604772  0.04658758 -0.04868253 -0.01001075
   0.06346335  0.04858874  0.0356415   0.03602699 -0.0166421  -0.04706815
  -0.02815033  0.07019776  0.02538897 -0.01500779  0.01989698 -0.04794651
  -0.07350598  0.07331237  0.02188345 -0.05676148 -0.00023221 -0.06287498
   0.04969535  0.0131508   0.0451873  -0.05783146 -0.03184023 -0.01131758
  -0.04840171  0.03610859  0.01193958  0.01928276  0.02445959  0.04980856
  -0.02639864  0.06445104  0.04375321  0.00347528  0.06562649 -0.05646896
  -0.03916651 -0.06471146 -0.02157398  0.00757807 -0.03302746  0.02921305
   0.05308366 -0.07812683  0.03817958 -0.10160037 -0.08272609 -0.05377689
   0.01712119 -0.01756216 -0.02946329 -0.05400823 -0.00562969  0.0767308
  -0.02963654 -0.00895078  0.07373441  0.06670626 -0.01433768  0.0648765
   0.03228792  0.04250057 -0.08435337 -0.0462772   0.05617799 -0.04143731
   0.0074911  -0.03487483 -0.06281573  0.04469606 -0.04992564 -0.01421539
  -0.04052442 -0.04180025  0.00665703  0.05025622]]
After layer expand_dims1033_0 (1, 1, 256) <class 'numpy.float32'> [[[ 0.02758696  0.05067352 -0.05158029 -0.01663     0.05928731 -0.03546434
    0.03702098 -0.0331233   0.02276829 -0.01865645  0.01365109  0.03008797
    0.04462755 -0.05511975  0.02689268 -0.03358052  0.01107924  0.0492439
   -0.01512345  0.02368348 -0.0409143  -0.04112128 -0.07257126  0.03563707
    0.00397431 -0.01179627 -0.08532663 -0.03333309 -0.02603407  0.03121304
    0.01792355 -0.05750624  0.06284095 -0.0058577   0.05628944  0.04538604
    0.02992563 -0.05333969 -0.05615452  0.01676422 -0.04267198  0.04015135
   -0.04607907  0.02892258 -0.02553735 -0.01616411  0.02203694  0.04503017
    0.04508416  0.00096605  0.00553319  0.02166822  0.03878214 -0.02247067
    0.06188027  0.04632847 -0.0217007  -0.01676868  0.05554721 -0.03166346
    0.03765696 -0.02363514  0.03746745  0.07492346 -0.04420747  0.01906084
    0.01330622  0.06218674  0.0225127  -0.06721491  0.01604867 -0.03477257
   -0.09595693  0.03177647  0.04330185  0.03473465  0.05140708 -0.10604271
    0.05666973 -0.05873546  0.05059771 -0.04979826  0.06070265  0.01942953
   -0.02760384 -0.06280298  0.03257427 -0.07126144  0.00632061  0.03762437
    0.02705244  0.03724489 -0.03735551 -0.02903094 -0.06379046  0.00440185
   -0.0015037  -0.09649675  0.0279366   0.06136044 -0.02938816 -0.00945095
   -0.01589378  0.05109256 -0.02093127 -0.04065489  0.01714623  0.05800673
    0.03586307  0.06514163 -0.0333946  -0.05607566  0.07159675  0.07542687
   -0.01459817  0.04600225  0.03903005  0.04333036  0.0407986  -0.00387167
    0.00831607 -0.0782344   0.06439531 -0.02933011  0.09425342 -0.01015867
    0.04758663  0.03726394 -0.04653452 -0.10308192 -0.00587847  0.03748224
    0.02438359 -0.01989255  0.06259575  0.05827288 -0.00563762  0.04826911
   -0.0786775  -0.02355763 -0.02286621  0.06048404 -0.06186247 -0.01824755
    0.0580007   0.02686242  0.04464926 -0.0251728   0.05208122 -0.0350395
    0.04013351 -0.04023178  0.05678146  0.09028109  0.0355165  -0.06972807
    0.05379215 -0.00996709  0.03346585  0.02215277  0.07922234  0.03531419
    0.05613809  0.04135889 -0.0410865   0.02922001 -0.03792449  0.03364135
   -0.05599269 -0.03569081  0.02939742  0.07781686 -0.0363782   0.04453019
   -0.02461324 -0.02952692  0.04604772  0.04658758 -0.04868253 -0.01001075
    0.06346335  0.04858874  0.0356415   0.03602699 -0.0166421  -0.04706815
   -0.02815033  0.07019776  0.02538897 -0.01500779  0.01989698 -0.04794651
   -0.07350598  0.07331237  0.02188345 -0.05676148 -0.00023221 -0.06287498
    0.04969535  0.0131508   0.0451873  -0.05783146 -0.03184023 -0.01131758
   -0.04840171  0.03610859  0.01193958  0.01928276  0.02445959  0.04980856
   -0.02639864  0.06445104  0.04375321  0.00347528  0.06562649 -0.05646896
   -0.03916651 -0.06471146 -0.02157398  0.00757807 -0.03302746  0.02921305
    0.05308366 -0.07812683  0.03817958 -0.10160037 -0.08272609 -0.05377689
    0.01712119 -0.01756216 -0.02946329 -0.05400823 -0.00562969  0.0767308
   -0.02963654 -0.00895078  0.07373441  0.06670626 -0.01433768  0.0648765
    0.03228792  0.04250057 -0.08435337 -0.0462772   0.05617799 -0.04143731
    0.0074911  -0.03487483 -0.06281573  0.04469606 -0.04992564 -0.01421539
   -0.04052442 -0.04180025  0.00665703  0.05025622]]]
After layer encoder_birnn_forward_l0_t2_i2h_output (1, 1024) <class 'numpy.float32'> [[ 0.07376467 -0.04585483  0.06153381 ...,  0.03591035  0.03396329
   0.02903319]]
After layer encoder_birnn_forward_l0_t2_h2h_output (1, 1024) <class 'numpy.float32'> [[ 0.10194565  0.08575457  0.11172991 ...,  0.18630293  0.12884799
   0.16601799]]
After layer _plus1028_0 (1, 1024) <class 'numpy.float32'> [[ 0.17571032  0.03989974  0.17326373 ...,  0.22221327  0.16281128
   0.19505119]]
After layer encoder_birnn_forward_l0_t2_slice_output0 (1, 256) <class 'numpy.float32'> [[ 0.17571032  0.03989974  0.17326373  0.02682822  0.18292725  0.12830706
   0.23952536  0.06833819 -0.01951725  0.13535321  0.1176993   0.19699331
   0.00774227  0.26973599  0.0312825   0.09597382  0.06451693  0.09065056
   0.23055375  0.09005845  0.03748284 -0.02943915  0.12034161  0.12016416
   0.14277165  0.0717058   0.24755356  0.03381845  0.2060415   0.15876785
   0.07973643  0.16378587  0.33705068  0.02213117  0.32104033  0.08141077
   0.0718917   0.40507808  0.26938084 -0.01687578  0.00249204  0.18662176
   0.17621395  0.09345959  0.28277999  0.11589587  0.16933027  0.20948502
   0.13688621 -0.02923118 -0.04136229 -0.02249858  0.61267459  0.15566197
   0.32298893  0.14805984  0.18118918 -0.02962263  0.08126643 -0.11535526
   0.15141514  0.13901632  0.08370117  0.26723489  0.09642532  0.08566242
   0.20679775  0.25932452  0.18249838  0.20428416 -0.02771186 -0.04394097
   0.30436811  0.08877673  0.23349479  0.33300903  0.21402921  0.54041725
   0.15692894  0.06522889  0.14820421  0.18053396  0.2473796   0.07577662
   0.26905844  0.16913211  0.03710267  0.33067751  0.29352474  0.0190308
   0.07814194  0.01449872 -0.03691202  0.13025661  0.05825903 -0.02731467
   0.24957585  0.28983152  0.20802858  0.1804513   0.03378522 -0.05413354
   0.14884892  0.23908171  0.2548413   0.13002698  0.0572008   0.14588097
   0.00516309  0.10537609  0.32385373  0.20917675  0.4668777   0.51631576
   0.24594785  0.18733528  0.18944067  0.24031189  0.00923248  0.09953062
  -0.0081925   0.23695904  0.30398625  0.09396651  0.43827409  0.03173887
   0.16902083  0.11561615  0.17051814  0.43342531 -0.05465633  0.1753259
   0.04835948 -0.05990379  0.27766603  0.12058927  0.11521674 -0.03464864
   0.23447169 -0.01540846  0.05824938  0.25237256  0.1882073   0.05020274
   0.1286362  -0.11299     0.06630903 -0.12237029  0.18334886 -0.00378369
   0.3338632   0.22629707  0.38707316  0.25355428  0.10924622  0.17320724
   0.12321568 -0.05202267  0.19835845  0.14309035  0.41088942  0.00568774
   0.18463621  0.19148302  0.20680754  0.0662055   0.06503911  0.12735723
   0.00780515  0.14824125 -0.0504697   0.69021165  0.04840028  0.31622511
   0.19133581  0.03256958 -0.01384658 -0.11184011  0.03112977  0.06878258
   0.3241961   0.12119331  0.19431353  0.10475083 -0.03130532  0.13477144
   0.00813131  0.25480056  0.09390216  0.1350697  -0.04198407  0.12268744
   0.28842863  0.10727535  0.12308142  0.28507861  0.67995673  0.31282377
   0.11688712  0.12922715  0.07328137  0.20529585  0.14102407  0.00200257
   0.14555474  0.01604355  0.12612823 -0.0807414   0.01946352  0.10623069
   0.14945245  0.05512606  0.17219746  0.11582661  0.37602574  0.15350164
   0.10065342  0.26027003  0.09915502 -0.12236811  0.05666155  0.05917748
   0.24381241  0.16854119  0.21521443  0.480656    0.12585329  0.09078173
   0.07439461  0.04363386 -0.07229599  0.50789028  0.01551358  0.28055167
   0.10747256  0.05419406  0.15395702 -0.03203567  0.09763016  0.24063143
   0.10576962  0.24307758  0.73182273  0.13198306  0.25771183  0.16133204
   0.10045811  0.11200121  0.20901579  0.07412261  0.41242817 -0.0902576
   0.20589483  0.10595608 -0.04154208  0.11557003]]
After layer encoder_birnn_forward_l0_t2_slice_output1 (1, 256) <class 'numpy.float32'> [[  2.68316180e-01  -3.27762142e-02   8.21234956e-02   1.48640305e-01
    9.03178900e-02   1.67208791e-01   1.69326007e-01   1.12284645e-01
    3.10427010e-01   8.86065364e-02   1.95819467e-01   6.96267411e-02
    1.49009794e-01   9.93323401e-02   6.50174320e-02   1.03453368e-01
    1.47149339e-03   9.52256396e-02   2.91156530e-01   1.51795924e-01
    1.18282914e-01   4.26431000e-02   2.83456326e-01   9.77389216e-02
    1.60393387e-01   1.29354909e-01   2.06616342e-01   1.21472955e-01
    2.17564017e-01   1.77240521e-02   1.28950104e-01   1.08226404e-01
    1.67726994e-01   1.41089693e-01   2.85480052e-01   2.08238184e-01
    1.28211930e-01   1.46193653e-02   2.58181661e-01   1.05074756e-02
    2.46259749e-01   1.19813167e-01   2.64626741e-01  -1.68294366e-02
    6.45060688e-02  -4.92374599e-02   1.91987276e-01   7.88618773e-02
    1.19002134e-01  -8.91300291e-02  -4.51818518e-02   7.90201575e-02
    6.47902012e-01  -2.17808858e-02   2.16249630e-01   5.15645444e-02
    9.79216471e-02   6.99237362e-02   9.53417122e-02   2.03728557e-01
   -2.45952215e-02   3.98711190e-02   1.51556313e-01   2.46211499e-01
    2.94586867e-02   8.30234513e-02   1.30596608e-01   2.46617794e-01
    1.24243379e-01   2.68993437e-01  -9.61745977e-02   1.32315800e-01
    3.50940168e-01   1.20603040e-01   5.91580719e-02   5.21786690e-01
    1.47089511e-01   4.03324664e-01   2.07996830e-01  -4.07906510e-02
    2.00083494e-01  -1.20554417e-01   5.80413222e-01   1.13978691e-01
    2.09418386e-01   6.59025088e-02   1.00504868e-02   3.07168812e-01
    5.37009239e-01   1.62000805e-01   8.09446797e-02   1.31806642e-01
   -3.37409936e-02   9.19260755e-02  -1.38977803e-02   2.67437752e-02
    1.82704046e-01   1.74679860e-01   2.45889097e-01   1.39242455e-01
    3.64188999e-02  -8.78827348e-02   6.05525412e-02   1.75177693e-01
    1.56647533e-01   7.15245157e-02   1.84816331e-01   1.42809883e-01
    1.33403212e-01   1.26391619e-01   1.80741906e-01   2.26976752e-01
    3.38053256e-01   4.47635084e-01   1.95302948e-01   1.14416935e-01
    2.49616668e-01   2.03136712e-01   1.16885811e-01   7.53731579e-02
    1.25103980e-01   3.33867788e-01   7.77966455e-02   1.51302278e-01
    2.91773796e-01   1.69185087e-01  -4.01628613e-02   1.06897831e-01
    8.39974955e-02   2.56471068e-01   2.14031264e-02   1.69137985e-01
    8.26065913e-02   5.90796620e-02   1.10739559e-01   2.49081179e-01
    7.08600655e-02  -7.45576993e-02   3.75799268e-01   1.52197704e-01
    1.45324126e-01   1.40904173e-01   1.92256495e-01   1.45627037e-01
    2.61456594e-02   2.31137872e-01   9.10621285e-02   1.05230302e-01
    1.58077508e-01   1.08271629e-01   2.56993443e-01   1.16520092e-01
    2.30736762e-01   2.20075250e-02   1.11356325e-01   7.98982903e-02
    2.18636781e-01   3.58191133e-02   2.25342035e-01   7.93036148e-02
    3.11684906e-01   1.26541480e-01   2.56013453e-01   1.86385065e-01
    1.92560956e-01   7.23115355e-03   4.58730832e-02   8.73851180e-02
   -2.05693878e-02   8.84796232e-02  -1.45709850e-02   4.76644576e-01
    1.42829657e-01   2.77516931e-01  -1.28171630e-02   1.18901588e-01
    5.41928113e-02   1.52440831e-01  -1.18010759e-01   1.97737306e-01
    1.42311871e-01  -6.65739179e-04   1.89387515e-01   1.16175026e-01
    9.43166912e-02   1.77791357e-01   2.87569582e-01   1.75120115e-01
    3.53302956e-02   1.62645295e-01  -2.27651931e-02   1.65999800e-01
    1.27461001e-01   1.04849309e-01   7.47786909e-02   1.60925925e-01
    8.70844781e-01  -8.36774856e-02   1.38397872e-01   1.87676288e-02
    1.71634197e-01   9.67219397e-02   6.67713284e-02   2.71031022e-01
    1.91951588e-01   1.21885099e-01   1.69884846e-01  -1.23006836e-01
    4.54752818e-02   1.30648375e-01   2.03519106e-01   8.28236192e-02
    1.36800572e-01   1.69793248e-01   3.33051026e-01   2.29460180e-01
    2.98827514e-03   2.17906415e-01   8.80788118e-02   7.64925927e-02
    4.52347845e-03   2.35865146e-01  -4.18715551e-02   1.74561024e-01
    1.01717845e-01   3.24531853e-01   1.68901570e-02   3.20832059e-02
    1.51219279e-01   4.40973714e-02   1.16287075e-01   3.80752593e-01
    2.82145143e-02   2.04225272e-01   1.89545095e-01   1.77728578e-01
   -2.01764479e-02   6.82134703e-02   1.39774829e-02   2.90780187e-01
    3.38500291e-02   2.16923386e-01   6.63432539e-01   1.96436346e-02
    3.94265130e-02   8.58365372e-03   1.11710280e-01   1.21711016e-01
    1.12416521e-01   2.15782821e-01   3.37733418e-01  -7.35596865e-02
    2.28670746e-01   2.12851375e-01   8.92104506e-02   1.65517345e-01]]
After layer encoder_birnn_forward_l0_t2_slice_output2 (1, 256) <class 'numpy.float32'> [[ 0.08832572  0.19574852 -0.29638225 -0.18115997  0.37807178 -0.00522289
   0.30512112 -0.09742908 -0.03406491 -0.09668571  0.17068841  0.19784033
   0.01151153 -0.28559768  0.07506871 -0.01490773  0.16873775  0.26823503
  -0.05244948  0.11534174 -0.14046234 -0.46182638 -0.30309543  0.14746784
  -0.1504253  -0.09636668 -0.31057161 -0.07440911 -0.22435461  0.15582265
   0.14898634 -0.07766338  0.35091791 -0.08844049  0.41272473  0.08826197
   0.14452292 -0.43351692 -0.28583789  0.13319413 -0.0984719   0.23118615
  -0.12250806  0.27595341 -0.46121639 -0.14715579  0.0284923   0.2333996
   0.15209101  0.10068136  0.06654628  0.05027555 -0.01009277 -0.24771318
   0.3535839   0.31592304 -0.32796478 -0.08341381  0.07933047 -0.02533264
   0.2416721  -0.09204382  0.08775169  0.60935116 -0.18202414  0.02571932
   0.12819107  0.41194928  0.1024044  -0.17928368  0.17306897 -0.0473333
  -0.39012197  0.19447131  0.22296211  0.31396812  0.27761713 -0.56245041
   0.15931219 -0.43962273  0.34680021 -0.29214939  0.01690049  0.1283766
  -0.17154607 -0.24111906  0.01642833 -0.34729236  0.07521595 -0.02067687
   0.11644698  0.13990739 -0.37711865 -0.14150459 -0.34840786 -0.00143313
  -0.22103994 -0.33241251  0.18372339  0.11024152 -0.15843105 -0.00857438
  -0.06107441  0.23061556 -0.2626985  -0.24843144  0.26811334  0.23678979
   0.23150006  0.17750213 -0.29750475 -0.20379983  0.48678797  0.3860119
  -0.20610857  0.2972509   0.16222455  0.11275292  0.16354069  0.09023759
   0.00588911 -0.26447347  0.28270599 -0.1423589   0.53925705  0.06113328
   0.4102903   0.20344418 -0.32460916 -0.3040331   0.08855547  0.30174422
   0.09834609 -0.08281111  0.30898839  0.35786411  0.03427301  0.20134211
  -0.4102869  -0.05729914 -0.06191679  0.40910274 -0.33408096 -0.09870507
   0.2709865   0.05024747  0.22641736 -0.08887935  0.35714346 -0.12197166
   0.36799863 -0.27622557  0.49598598  0.12144829  0.12588105 -0.36013705
   0.42256898 -0.08620934  0.18472132  0.17441246  0.49550673  0.19457319
   0.14569861  0.28836587 -0.15793942  0.16682991 -0.04452412  0.35908353
  -0.2478427  -0.27121633  0.10277818  0.61998713 -0.15488304  0.36381888
  -0.22004086 -0.34268287  0.0835107   0.06631384 -0.1398942  -0.04352771
   0.41243699  0.26421431  0.14996684  0.25506496 -0.03947992 -0.26981953
  -0.13223152  0.26090544  0.12306336 -0.16412947  0.29984355 -0.27109927
  -0.24344376  0.2760312   0.09497719 -0.37074286  0.03431    -0.32247066
   0.2658191   0.00881875  0.12366121 -0.33228582 -0.35603428 -0.23405245
  -0.15545681 -0.04569753  0.26789573  0.10162152  0.12903336  0.11648819
  -0.1340128   0.20621379  0.11767814  0.15295675  0.45000511 -0.29990441
  -0.19843075 -0.3018221  -0.09950922 -0.15658194 -0.09818722  0.23286842
   0.30536187 -0.42917153  0.09035453 -0.52355409 -0.29671681 -0.15939149
   0.16555145 -0.06180042 -0.11203756 -0.46950495 -0.15388548  0.31905171
  -0.23452915  0.04533777  0.38333607  0.19129199 -0.16128774  0.45726472
   0.18837142  0.34316692 -0.46159303 -0.29482085  0.31175813 -0.20915198
   0.13023856 -0.13712841 -0.25732303  0.13705876 -0.43634111 -0.05350464
  -0.2016094  -0.23093264  0.03659148  0.20283893]]
After layer encoder_birnn_forward_l0_t2_slice_output3 (1, 256) <class 'numpy.float32'> [[ 0.2630001   0.18202278  0.18851244  0.28391215  0.13170865  0.23488861
   0.32933491  0.189127    0.27278236  0.22212809  0.15493661  0.14344335
   0.16705953  0.14493692  0.0384381   0.1336595   0.13120592  0.2043829
   0.43027514  0.23471662  0.02250053  0.02807876  0.31369004  0.23727137
   0.21568744  0.10836463  0.28002933  0.23834044  0.00737489  0.16709717
   0.18184309  0.27260879  0.11811486  0.1260879   0.16442016  0.15787955
   0.21207017  0.12889373 -0.08099983  0.09043115  0.15926662  0.18506314
   0.08176992  0.14064099  0.14389583  0.19842702  0.34015808  0.16631791
   0.16157614  0.04272807 -0.00347143  0.17907467  0.64326024  0.04615867
   0.18542784 -0.05754281  0.12314672  0.08139124  0.15034971  0.1725435
   0.04622076  0.21179089  0.03011395  0.28841659  0.14566398  0.15519351
   0.30324405  0.14376327  0.12389983  0.17693074  0.22075978  0.19134103
   0.36851668  0.09831086  0.14751583  0.55871266  0.20225038  0.56517708
   0.34455097  0.13094892  0.25172865  0.00376396  0.57300717  0.12438735
   0.23963214  0.15850902  0.06482551  0.27019349  0.49155796  0.14661244
   0.12026335  0.05840495 -0.05289065  0.24908963  0.08353199  0.32803321
   0.29140615  0.23016088  0.28943616  0.33391681  0.10123658  0.13953415
   0.12144344  0.27351007  0.2139343  -0.01452952  0.11872266  0.31410149
   0.24106897  0.10608613  0.2836116   0.15829979  0.48973161  0.46556634
   0.26039103  0.10207766  0.17799713  0.33842665  0.17161109  0.18588774
   0.11687315  0.34476605  0.2133233   0.1442467   0.13110717  0.201326
   0.13100541  0.00622124  0.10580096  0.46356961  0.24076445  0.349392
   0.08847157  0.16768399  0.10559291  0.07073563  0.23303047  0.12396798
   0.31694871  0.2113401   0.10803275  0.24413921  0.18740635  0.16843906
   0.11497369  0.14679016  0.13395765  0.14119774  0.07751656  0.18755822
   0.39872819  0.14925298  0.15975754  0.00870147  0.15734753  0.02492162
   0.07226931  0.14925818  0.26130515  0.24537402  0.21518518  0.18379712
   0.15522622  0.18684267  0.27248973  0.07091413  0.16204956  0.06800417
  -0.00891959  0.1419746   0.04526731  0.74609506  0.23122586  0.38845962
  -0.01497358  0.17676185  0.17209285  0.18646444  0.10814629  0.28205526
   0.19809306 -0.00628881  0.11188184  0.23938999  0.07501838  0.22704118
   0.2047227   0.07976975  0.05438378  0.18229041 -0.01110457  0.10361022
   0.34324965  0.21209869  0.07412715  0.22344515  0.75323141  0.25762168
   0.20470524  0.19806701  0.08587256  0.05294933  0.24368441  0.14382932
   0.17371365  0.26410705  0.32551813  0.00092147 -0.09606597  0.242336
   0.20661797  0.05274329  0.18641827  0.20950627  0.48706973  0.44224885
   0.16664553  0.34532702  0.21378863  0.11337227  0.07817374  0.24771132
   0.0185346   0.18605128  0.12402584  0.18770523  0.12735543  0.11777602
   0.21948649  0.06775169  0.00559714  0.31217572  0.14104931  0.17805539
   0.23713163  0.08323879  0.00591333  0.0293383   0.09231357  0.29396385
   0.12320949  0.28458765  0.76398408 -0.08548836  0.20295574  0.13580464
   0.18841049  0.17008626  0.20102656  0.27510333  0.26113418  0.11982958
   0.30200118  0.22221327  0.16281128  0.19505119]]
After layer encoder_birnn_forward_l0_t2_o_output (1, 256) <class 'numpy.float32'> [[ 0.56537366  0.54538047  0.54698902  0.57050508  0.53287959  0.55845362
   0.58159751  0.54714131  0.56777585  0.55530483  0.53865689  0.53579944
   0.54166806  0.53617096  0.50960833  0.53336519  0.53275448  0.55091864
   0.60593939  0.55841124  0.50562489  0.50701922  0.57778567  0.55904114
   0.5537138   0.52706468  0.56955338  0.55930465  0.50184375  0.54167736
   0.54533595  0.56773323  0.52949446  0.53148031  0.5410127   0.53938812
   0.55281973  0.53217888  0.47976112  0.52259237  0.53973269  0.54613417
   0.5204311   0.53510243  0.53591198  0.54944462  0.58422893  0.54148388
   0.54030639  0.51068044  0.49913213  0.54464942  0.6554901   0.51153761
   0.54622459  0.48561826  0.53074783  0.52033657  0.53751677  0.54302913
   0.51155317  0.55275071  0.50752795  0.57160848  0.53635174  0.53872073
   0.57523537  0.53587908  0.53093541  0.54411763  0.55496687  0.54768986
   0.59110051  0.52455795  0.53681225  0.63615465  0.55039096  0.6376496
   0.58529562  0.53269053  0.56260192  0.50094104  0.63945681  0.53105676
   0.559623    0.53954452  0.51620066  0.5671404   0.62047338  0.5365876
   0.53002965  0.51459712  0.48678041  0.56195241  0.52087086  0.58128077
   0.57234031  0.55728751  0.57185811  0.58271211  0.52528757  0.53482705
   0.53032362  0.56795442  0.55328053  0.49636769  0.52964586  0.57788604
   0.55997711  0.52649671  0.57043147  0.53949249  0.62004322  0.61433381
   0.56473243  0.52549732  0.54438215  0.5838083   0.5427978   0.54633856
   0.52918506  0.58534777  0.55312949  0.53599924  0.53272992  0.5501622
   0.53270459  0.50155532  0.5264256   0.61386061  0.55990201  0.58647013
   0.52210343  0.54182303  0.52637374  0.51767653  0.55799544  0.53095239
   0.5785805   0.55263925  0.52698195  0.56073344  0.5467149   0.54201049
   0.5287118   0.53663182  0.5334394   0.53524089  0.51936942  0.54675257
   0.59838206  0.53724414  0.53985471  0.50217533  0.53925592  0.50623006
   0.51805949  0.53724539  0.56495708  0.5610376   0.5535897   0.54582036
   0.53872883  0.54657525  0.56770402  0.51772112  0.54042399  0.51699448
   0.4977701   0.53543413  0.51131493  0.67832726  0.55755025  0.59591186
   0.49625668  0.54407579  0.54291731  0.54648149  0.52701026  0.57005006
   0.549362    0.49842781  0.52794135  0.55956334  0.51874578  0.55651778
   0.55100268  0.51993185  0.5135926   0.54544681  0.49722385  0.52587938
   0.58497971  0.55282676  0.51852334  0.55563003  0.67988241  0.56405157
   0.55099833  0.54935551  0.52145499  0.51323426  0.56062144  0.53589547
   0.54331952  0.56564564  0.58066845  0.50023037  0.47600201  0.56028926
   0.55147153  0.51318276  0.54647005  0.55218583  0.61941588  0.60879475
   0.54156524  0.58548397  0.55324453  0.52831274  0.51953351  0.56161308
   0.50463355  0.54637915  0.53096676  0.54678899  0.53179592  0.52941006
   0.55465239  0.51693147  0.50139928  0.57741624  0.53520399  0.54439664
   0.55900663  0.52079767  0.50147831  0.50733405  0.52306199  0.57296628
   0.53076351  0.5706706   0.68221807  0.47864091  0.55056548  0.53389907
   0.54696381  0.54241937  0.55008811  0.56834537  0.56491506  0.52992159
   0.57493162  0.55532587  0.54061317  0.54860878]]
After layer encoder_birnn_forward_l0_t2_f_output (1, 256) <class 'numpy.float32'> [[ 0.56667948  0.49180669  0.52051938  0.53709179  0.52256411  0.54170507
   0.54223067  0.52804172  0.57698947  0.52213717  0.54879904  0.51739967
   0.53718364  0.5248127   0.51624864  0.52584028  0.50036788  0.52378845
   0.57227927  0.53787631  0.52953631  0.51065916  0.57039338  0.52441531
   0.5400126   0.53229368  0.55147111  0.53033096  0.55417752  0.50443089
   0.53219295  0.52703023  0.5418337   0.53521407  0.57088923  0.55187225
   0.53200912  0.50365478  0.56418926  0.50262684  0.56125569  0.52991754
   0.56577331  0.49579275  0.51612091  0.4876931   0.54784995  0.5197053
   0.52971548  0.47773227  0.4887065   0.51974475  0.65653753  0.494555
   0.55385274  0.51288831  0.52446085  0.51747382  0.52381736  0.55075669
   0.49385151  0.50996649  0.5378167   0.56124377  0.50736415  0.52074397
   0.53260285  0.56134385  0.53102094  0.56684577  0.47597489  0.53303075
   0.58684558  0.53011429  0.51478517  0.62756544  0.53670627  0.59948617
   0.55181253  0.48980373  0.54985464  0.46989781  0.64116246  0.52846384
   0.55216408  0.51646966  0.50251263  0.57619405  0.63111645  0.54041189
   0.52022511  0.53290403  0.49156559  0.52296537  0.49652565  0.50668555
   0.54554939  0.54355925  0.56116444  0.53475446  0.50910372  0.47804344
   0.5151335   0.54368281  0.53908205  0.51787353  0.54607302  0.53564191
   0.53330141  0.53155595  0.54506284  0.55650181  0.58371758  0.61007679
   0.54867113  0.5285731   0.56208211  0.55061024  0.52918822  0.51883441
   0.53123528  0.58270013  0.51943934  0.53775352  0.57243031  0.54219568
   0.48996061  0.52669901  0.52098703  0.56376863  0.50535053  0.542184
   0.5206399   0.51476562  0.52765661  0.56195033  0.51770759  0.48136923
   0.59285957  0.53797615  0.53626722  0.53516787  0.54791665  0.53634256
   0.50653607  0.55752856  0.52274978  0.52628332  0.53943729  0.52704149
   0.56389707  0.52909708  0.55742961  0.50550169  0.52781034  0.51996398
   0.55444252  0.50895381  0.55609834  0.5198155   0.5772965   0.5315932
   0.56365609  0.54646188  0.54799199  0.50180775  0.51146626  0.52183241
   0.49485782  0.52210546  0.49635735  0.61695522  0.53564686  0.56893736
   0.49679574  0.52969044  0.51354492  0.53803658  0.47053149  0.54927391
   0.53551805  0.49983358  0.54720587  0.52901113  0.52356172  0.54433113
   0.571401    0.54366851  0.50883168  0.54057193  0.49430892  0.5414049
   0.5318222   0.52618831  0.51868594  0.54014492  0.70492148  0.47909284
   0.53454435  0.50469178  0.54280353  0.52416164  0.51668662  0.56734604
   0.54784113  0.5304336   0.54236937  0.46928704  0.5113669   0.53261572
   0.5507049   0.52069408  0.5341469   0.54234666  0.58250153  0.55711466
   0.50074708  0.5542621   0.52200544  0.51911384  0.50113088  0.55869442
   0.48953363  0.54352975  0.52540755  0.5804283   0.50422245  0.5080201
   0.53773296  0.51102257  0.52903903  0.59405458  0.5070532   0.5508796
   0.54724491  0.54431552  0.49495605  0.51704675  0.50349432  0.57218713
   0.50846171  0.55401915  0.66003108  0.50491077  0.50985533  0.50214595
   0.52789855  0.53039026  0.52807456  0.55373734  0.5836398   0.48161834
   0.55691987  0.55301285  0.52228785  0.54128516]]
After layer _mul2056_0 (1, 256) <class 'numpy.float32'> [[ 0.03015366  0.047726   -0.05277581 -0.01718002  0.05951588 -0.03626725
   0.03679898 -0.03427195  0.0243836  -0.01839522  0.01445422  0.0299465
   0.04586264 -0.05387577  0.02800656 -0.03539831  0.01053419  0.05106423
  -0.01537891  0.024265   -0.04140007 -0.0419035  -0.07472826  0.03541193
   0.00399589 -0.01159059 -0.0861578  -0.03393062 -0.02805531  0.02923116
   0.01789303 -0.05598462  0.0659863  -0.00582119  0.05907714  0.04875186
   0.03003433 -0.05161915 -0.06279456  0.01564208 -0.04372605  0.04044006
  -0.05166727  0.02687057 -0.02491333 -0.01457427  0.02235357  0.04565316
   0.04413931  0.00088519  0.00548851  0.02136295  0.04313762 -0.02175329
   0.06637438  0.04756681 -0.02092988 -0.01704856  0.05443313 -0.0318881
   0.03609106 -0.02267756  0.04020204  0.07331918 -0.04232974  0.01839248
   0.01285306  0.06634208  0.02300122 -0.0719046   0.01402952 -0.0342452
  -0.10686675  0.03242506  0.04270521  0.03901496  0.05363061 -0.11541663
   0.05721861 -0.05523777  0.05245998 -0.0483007   0.06529893  0.0194347
  -0.02782368 -0.06056392  0.0311426  -0.0789407   0.00701233  0.03938658
   0.02739362  0.03852366 -0.03513081 -0.02737482 -0.05964742  0.00408813
  -0.00155793 -0.09533641  0.02926822  0.05728395 -0.02889764 -0.00892612
  -0.01519393  0.05110913 -0.02127767 -0.0421567   0.01741013  0.05661548
   0.03540707  0.06519268 -0.03427721 -0.05762797  0.07783516  0.08271348
  -0.0149359   0.04737327  0.0416849   0.04410831  0.04087264 -0.00360263
   0.00838203 -0.08045594  0.06463505 -0.02952549  0.10355885 -0.01059068
   0.04531051  0.03860564 -0.04735966 -0.10678448 -0.0056374   0.03752748
   0.02468223 -0.01912947  0.06451795  0.06398712 -0.00576431  0.04414435
  -0.08953276 -0.02336422 -0.02314122  0.0651692  -0.06339027 -0.0187328
   0.05683405  0.02938752  0.04733866 -0.0248338   0.05564792 -0.03558132
   0.04262761 -0.04077725  0.05873444  0.08711461  0.03518925 -0.06989827
   0.05534412 -0.00937352  0.03413897  0.02208716  0.08694839  0.035417
   0.06160668  0.04176221 -0.04147369  0.02889681 -0.03603404  0.03348975
  -0.05341316 -0.03752685  0.0266559   0.08262107 -0.0364223   0.04504012
  -0.02469493 -0.02991126  0.04534978  0.048001   -0.04551321 -0.01074667
   0.0657449   0.04537345  0.03599376  0.03624031 -0.01757723 -0.04842582
  -0.03064016  0.07324178  0.02425867 -0.01522072  0.0204631  -0.05093282
  -0.07140487  0.07202345  0.0222293  -0.05750323 -0.00026158 -0.05942804
   0.04870426  0.01318876  0.04838156 -0.06047862 -0.03025663 -0.01234895
  -0.04889842  0.03523776  0.0126763   0.0184043   0.02540136  0.0485593
  -0.02660068  0.06616637  0.04340314  0.00337167  0.07041121 -0.05734061
  -0.03574875 -0.06973938 -0.02105315  0.0077216  -0.03177459  0.02947609
   0.0502689  -0.08489548  0.03722069 -0.11407813 -0.0822008  -0.05114546
   0.01794485 -0.01728042 -0.02951601 -0.0622815  -0.00548625  0.08251584
  -0.03043961 -0.0094384   0.07217854  0.06635796 -0.01432851  0.06954675
   0.03212966  0.04164999 -0.09419382 -0.0452529   0.05482722 -0.0400517
   0.00748773 -0.03608895 -0.06187702  0.04825945 -0.05444418 -0.01287266
  -0.04142623 -0.04425554  0.00643753  0.05214262]]
After layer encoder_birnn_forward_l0_t2_i_output (1, 256) <class 'numpy.float32'> [[ 0.5438149   0.50997359  0.54320788  0.50670666  0.54560471  0.53203285
   0.55959666  0.51707792  0.49512079  0.53378671  0.52939087  0.54908967
   0.50193554  0.56702811  0.50782001  0.52397507  0.51612365  0.52264714
   0.55738449  0.52249944  0.50936961  0.49264076  0.53004915  0.53000498
   0.53563243  0.51791877  0.56157428  0.50845379  0.5513289   0.53960878
   0.51992357  0.54085517  0.58347392  0.50553256  0.57957774  0.52034146
   0.5179652   0.5999071   0.5669409   0.49578115  0.50062305  0.54652053
   0.54393989  0.52334791  0.57022762  0.52894157  0.54223174  0.55218059
   0.53416818  0.49269274  0.48966089  0.49437556  0.64855069  0.53883713
   0.5800525   0.53694749  0.54517382  0.49259487  0.52030545  0.47119313
   0.5377816   0.53469819  0.52091306  0.566414    0.52408767  0.52140254
   0.551516    0.56447023  0.54549843  0.5508942   0.49307245  0.48901653
   0.57550997  0.52217966  0.55810994  0.58249134  0.55330402  0.63190943
   0.53915191  0.51630145  0.53698337  0.54501128  0.56153142  0.51893514
   0.56686175  0.54218251  0.5092746   0.5819242   0.57285881  0.50475752
   0.51952559  0.50362462  0.49077305  0.53251821  0.51456064  0.49317175
   0.5620721   0.57195491  0.5518204   0.54499084  0.5084455   0.48646995
   0.53714365  0.55948734  0.56336778  0.53246099  0.51429629  0.53640568
   0.5012908   0.52631968  0.58026314  0.55210435  0.61464453  0.62628585
   0.56117886  0.54669732  0.54721904  0.55979049  0.50230813  0.52486211
   0.49795189  0.55896413  0.57541674  0.52347434  0.60784769  0.50793403
   0.54215491  0.52887189  0.54252654  0.6066913   0.4863393   0.54371953
   0.51208752  0.48502851  0.56897396  0.53011084  0.52877241  0.4913387
   0.55835086  0.49614796  0.5145582   0.56276041  0.54691344  0.51254803
   0.5321148   0.47178251  0.51657122  0.46944556  0.54570925  0.49905407
   0.58269906  0.55633408  0.59557796  0.5630511   0.52728444  0.54319388
   0.530765    0.48699728  0.54942769  0.53571165  0.60130113  0.50142199
   0.54602838  0.54772502  0.55151838  0.51654536  0.51625407  0.5317964
   0.50195128  0.53699255  0.48738527  0.66601402  0.51209772  0.57840401
   0.54768854  0.5081417   0.49653846  0.47206911  0.5077818   0.51718885
   0.58034652  0.53026134  0.54842609  0.52616376  0.4921743   0.53364193
   0.50203282  0.56335771  0.5234583   0.53371614  0.4895055   0.53063345
   0.5716114   0.52679318  0.53073156  0.57079089  0.66372907  0.57757437
   0.52918857  0.53226191  0.51831216  0.55114448  0.53519768  0.50050062
   0.53632462  0.5040108   0.53149033  0.47982562  0.50486577  0.52653277
   0.53729373  0.51377803  0.54294336  0.52892435  0.59291422  0.53830022
   0.52514213  0.56470269  0.52476847  0.46944612  0.51416159  0.51479006
   0.56065291  0.54203582  0.55359685  0.61790276  0.5314219   0.52267987
   0.51859009  0.5109067   0.48193383  0.6243118   0.50387836  0.56968147
   0.52684236  0.51354522  0.53841341  0.49199176  0.52438819  0.55986923
   0.52641779  0.56047195  0.67520511  0.53294796  0.56407374  0.54024577
   0.52509344  0.52797109  0.55206454  0.51852214  0.60166997  0.47745091
   0.55129266  0.52646428  0.48961598  0.52886039]]
After layer encoder_birnn_forward_l0_t2_c_output (1, 256) <class 'numpy.float32'> [[ 0.08809675  0.19328606 -0.28799838 -0.17920382  0.36103174 -0.00522284
   0.29599211 -0.09712197 -0.03405174 -0.09638555  0.16904986  0.19529891
   0.01151102 -0.2780779   0.07492802 -0.01490663  0.16715433  0.26198176
  -0.05240144  0.11483296 -0.13954581 -0.4315716  -0.29414278  0.14640808
  -0.14930089 -0.09606948 -0.30095702 -0.07427209 -0.22066459  0.15457362
   0.1478937  -0.07750762  0.33718932 -0.08821062  0.39078379  0.08803349
   0.14352505 -0.40825626 -0.27829951  0.13241203 -0.09815485  0.2271536
  -0.12189885  0.26915574 -0.4310751  -0.14610271  0.02848459  0.22925179
   0.15092906  0.10034255  0.06644822  0.05023323 -0.01009242 -0.24276781
   0.33955008  0.30581585 -0.31669086 -0.08322088  0.07916448 -0.02532722
   0.23707449 -0.09178476  0.08752714  0.54367018 -0.18004011  0.02571365
   0.12749347  0.39012656  0.10204794 -0.17738718  0.17136146 -0.04729798
  -0.37146538  0.19205627  0.21933949  0.30404273  0.27069825 -0.50979328
   0.15797794 -0.41333169  0.33353475 -0.28411192  0.01689888  0.12767598
  -0.16988289 -0.23655246  0.01642685 -0.33397207  0.07507443 -0.02067392
   0.11592349  0.13900164 -0.36020255 -0.14056762 -0.33496279 -0.00143313
  -0.21750903 -0.32068685  0.18168378  0.10979709 -0.15711868 -0.00857417
  -0.06099858  0.22661237 -0.25681779 -0.24344362  0.26186842  0.23246129
   0.22745129  0.17566115 -0.28902745 -0.20102437  0.45166337  0.36791703
  -0.20323879  0.28879479  0.1608163   0.11227752  0.16209814  0.08999345
   0.00588904 -0.25847495  0.27540767 -0.14140496  0.49242535  0.06105724
   0.38871914  0.20068307 -0.31366858 -0.29499909  0.08832471  0.29290798
   0.09803025 -0.08262233  0.2995165   0.34333131  0.0342596   0.1986648
  -0.38871628 -0.05723651 -0.06183779  0.38771057 -0.32218292 -0.09838577
   0.26454252  0.05020523  0.22262602 -0.08864605  0.34269544 -0.12137038
   0.35223988 -0.26940817  0.45895448  0.12085469  0.12522033 -0.34533474
   0.39909247 -0.0859964   0.1826486   0.17266519  0.45857611  0.19215439
   0.14467633  0.28063005 -0.15663914  0.16529921 -0.04449473  0.34440652
  -0.2428897  -0.26475626  0.10241781  0.55111909 -0.15365633  0.34857336
  -0.21655701 -0.32987043  0.0833171   0.0662168  -0.1389887  -0.04350024
   0.39053994  0.25823307  0.14885262  0.24967386 -0.03945941 -0.26345688
  -0.13146618  0.25514221  0.12244586 -0.16267139  0.29116943 -0.26464739
  -0.23874587  0.26922789  0.09469263 -0.35464132  0.03429654 -0.31173918
   0.25973022  0.00881852  0.12303469 -0.32057318 -0.34171614 -0.22987023
  -0.15421651 -0.04566575  0.26166573  0.10127315  0.12832198  0.11596414
  -0.13321626  0.20333965  0.11713792  0.15177497  0.42190322 -0.29122511
  -0.19586673 -0.29297918 -0.09918208 -0.15531468 -0.0978729   0.22874846
   0.29621175 -0.40462872  0.09010945 -0.48043838 -0.28830516 -0.15805526
   0.16405542 -0.06172187 -0.11157113 -0.43779925 -0.15268219  0.30864921
  -0.23032169  0.04530673  0.36560115  0.18899235 -0.15990359  0.42785227
   0.18617456  0.33030173 -0.4313817  -0.28656584  0.30203569 -0.20615467
   0.12950715 -0.13627531 -0.25178996  0.13620695 -0.41060701 -0.05345364
  -0.19892153 -0.22691315  0.03657516  0.20010212]]
After layer _mul2057_0 (1, 256) <class 'numpy.float32'> [[ 0.04790832  0.09857079 -0.15644298 -0.09080377  0.19698061 -0.00277872
   0.1656362  -0.05021963 -0.01685972 -0.05144933  0.08949345  0.10723662
   0.00577779 -0.15767798  0.03804994 -0.0078107   0.0862723   0.13692401
  -0.02920775  0.06000016 -0.07108039 -0.21260977 -0.15591013  0.07759701
  -0.0799704  -0.04975619 -0.16900973 -0.03776392 -0.12165876  0.08340928
   0.07689342 -0.04192039  0.19674118 -0.04459334  0.22648959  0.04580747
   0.07434098 -0.24491583 -0.15777938  0.06564739 -0.04913858  0.12414411
  -0.06630564  0.14086209 -0.24581093 -0.0772798   0.01544525  0.12658839
   0.0806215   0.04943804  0.0325371   0.02483408 -0.00654545 -0.13081232
   0.19695687  0.16420706 -0.17265157 -0.04099418  0.04118971 -0.01193401
   0.12749431 -0.04907715  0.04559403  0.30794239 -0.0943568   0.01340716
   0.07031469  0.22021483  0.05566699 -0.09772157  0.08449361 -0.0231295
  -0.21378203  0.10028788  0.12241555  0.17710225  0.14977843 -0.32214317
   0.08517411 -0.21340375  0.17910261 -0.15484419  0.00948925  0.06625555
  -0.09630012 -0.12825461  0.00836578 -0.19434643  0.04300705 -0.01043532
   0.06022522  0.07000465 -0.17677771 -0.07485481 -0.17235866 -0.00070678
  -0.12225576 -0.18341841  0.10025682  0.05983841 -0.07988629 -0.00417108
  -0.032765    0.12678675 -0.14468287 -0.12962423  0.13467796  0.12469356
   0.11401924  0.09245392 -0.16771197 -0.11098643  0.27761242  0.23042123
  -0.11405331  0.15788333  0.08800174  0.06285189  0.08142322  0.04723416
   0.00293246 -0.14447822  0.15847419 -0.07402187  0.29931962  0.03101305
   0.21074599  0.10613564 -0.17017353 -0.17897338  0.04295578  0.1592598
   0.05020007 -0.04007419  0.17041709  0.18200365  0.01811553  0.0976117
  -0.21704008 -0.02839778 -0.03181914  0.21818817 -0.17620617 -0.05042743
   0.14076699  0.02368595  0.11500219 -0.0416145   0.18701208 -0.06057039
   0.20524985 -0.14988095  0.27334318  0.06804737  0.06602673 -0.18758371
   0.21182431 -0.04188002  0.1003522   0.09249876  0.27574232  0.09635044
   0.07899738  0.1537081  -0.08638937  0.08538454 -0.02297058  0.18315415
  -0.1219188  -0.14217214  0.04991693  0.36705303 -0.07868706  0.20161623
  -0.11860579 -0.16762093  0.04137015  0.03125891 -0.07057594 -0.02249784
   0.22664849  0.13693102  0.08163466  0.13136934 -0.01942091 -0.14059164
  -0.06600033  0.14373633  0.0640953  -0.08682034  0.14252904 -0.14043076
  -0.13646986  0.14182742  0.05025636 -0.20242603  0.02276361 -0.18005256
   0.13744627  0.00469376  0.06377038 -0.17668214 -0.18288568 -0.11505019
  -0.08271011 -0.02301603  0.13907281  0.04859345  0.06478537  0.06105892
  -0.07157626  0.10447145  0.06359926  0.08027748  0.25015241 -0.15676653
  -0.10285787 -0.16544613 -0.05204763 -0.07291187 -0.05032248  0.11775743
   0.16607198 -0.21932326  0.04988431 -0.29686421 -0.15321168 -0.08261231
   0.08507752 -0.03153411 -0.0537699  -0.27332324 -0.07693325  0.17583174
  -0.12134323  0.02326705  0.19684456  0.09298268 -0.08385155  0.23954132
   0.0980056   0.18512486 -0.29127112 -0.15272468  0.1703704  -0.11137419
   0.06800336 -0.07194942 -0.13900431  0.07062632 -0.24704991 -0.02552149
  -0.10966398 -0.11946167  0.01790778  0.10582609]]
After layer encoder_birnn_forward_l0_t2_state_0 (1, 256) <class 'numpy.float32'> [[ 0.07806198  0.14629678 -0.2092188  -0.1079838   0.25649649 -0.03904597
   0.20243518 -0.08449157  0.00752388 -0.06984454  0.10394767  0.13718311
   0.05164044 -0.21155375  0.0660565  -0.04320901  0.09680649  0.18798825
  -0.04458666  0.08426516 -0.11248047 -0.25451326 -0.23063838  0.11300895
  -0.0759745  -0.06134678 -0.25516754 -0.07169455 -0.14971408  0.11264044
   0.09478645 -0.09790501  0.26272747 -0.05041454  0.28556675  0.09455933
   0.1043753  -0.29653499 -0.22057393  0.08128947 -0.09286463  0.16458417
  -0.11797292  0.16773266 -0.27072427 -0.09185407  0.03779881  0.17224154
   0.12476081  0.05032323  0.03802561  0.04619704  0.03659218 -0.15256561
   0.26333126  0.21177387 -0.19358146 -0.05804274  0.09562284 -0.04382211
   0.16358536 -0.07175471  0.08579607  0.38126159 -0.13668653  0.03179964
   0.08316775  0.2865569   0.07866821 -0.16962618  0.09852313 -0.05737469
  -0.32064879  0.13271293  0.16512075  0.21611722  0.20340905 -0.43755978
   0.14239271 -0.26864153  0.23156258 -0.20314489  0.07478818  0.08569025
  -0.1241238  -0.18881853  0.03950838 -0.27328712  0.05001938  0.02895126
   0.08761884  0.10852831 -0.21190852 -0.10222963 -0.23200607  0.00338135
  -0.12381369 -0.27875483  0.12952504  0.11712236 -0.10878393 -0.0130972
  -0.04795893  0.17789587 -0.16596054 -0.17178093  0.15208809  0.18130903
   0.14942631  0.1576466  -0.20198919 -0.16861439  0.35544759  0.31313473
  -0.12898922  0.2052566   0.12968665  0.10696021  0.12229586  0.04363153
   0.01131449 -0.22493416  0.22310925 -0.10354736  0.40287846  0.02042236
   0.25605649  0.14474128 -0.21753319 -0.28575784  0.03731838  0.19678727
   0.0748823  -0.05920366  0.23493505  0.24599077  0.01235122  0.14175606
  -0.30657282 -0.051762   -0.05496036  0.28335738 -0.23959644 -0.06916022
   0.19760105  0.05307347  0.16234085 -0.0664483   0.24266    -0.09615171
   0.24787745 -0.1906582   0.33207762  0.15516198  0.10121598 -0.25748199
   0.26716843 -0.05125353  0.13449118  0.11458592  0.36269072  0.13176744
   0.14060405  0.1954703  -0.12786306  0.11428135 -0.05900463  0.2166439
  -0.17533195 -0.17969899  0.07657284  0.4496741  -0.11510936  0.24665634
  -0.14330073 -0.19753219  0.08671993  0.0792599  -0.11608915 -0.03324451
   0.29239339  0.18230447  0.11762841  0.16760965 -0.03699814 -0.18901744
  -0.09664049  0.2169781   0.08835398 -0.10204107  0.16299215 -0.19136359
  -0.20787472  0.21385087  0.07248567 -0.25992927  0.02250203 -0.2394806
   0.18615052  0.01788253  0.11215194 -0.23716077 -0.21314231 -0.12739913
  -0.13160853  0.01222173  0.1517491   0.06699775  0.09018673  0.10961823
  -0.09817694  0.17063782  0.10700241  0.08364915  0.32056361 -0.21410714
  -0.13860662 -0.2351855  -0.07310078 -0.06519027 -0.08209708  0.14723352
   0.21634087 -0.30421874  0.08710501 -0.41094235 -0.23541248 -0.13375777
   0.10302237 -0.04881453 -0.08328591 -0.33560473 -0.0824195   0.25834757
  -0.15178284  0.01382865  0.26902309  0.15934063 -0.09818007  0.30908808
   0.13013527  0.22677484 -0.38546494 -0.19797759  0.22519761 -0.1514259
   0.07549109 -0.10803837 -0.20088132  0.11888577 -0.30149409 -0.03839415
  -0.1510902  -0.16371721  0.02434531  0.15796871]]
After layer activation1028_output (1, 256) <class 'numpy.float32'> [[ 0.07790381  0.14526193 -0.20621864 -0.10756604  0.25101566 -0.03902614
   0.19971451 -0.08429109  0.00752374 -0.06973119  0.10357489  0.136329
   0.05159458 -0.20845322  0.06596059 -0.04318214  0.09650522  0.18580465
  -0.04455714  0.08406628 -0.1120085  -0.24915648 -0.22663404  0.11253031
  -0.07582866 -0.06126994 -0.24977005 -0.07157196 -0.14860545  0.11216646
   0.0945036  -0.09759339  0.25684485 -0.05037187  0.27804935  0.09427851
   0.10399792 -0.28813845 -0.21706502  0.08111089 -0.0925986   0.16311403
  -0.11742865  0.16617715 -0.26429862 -0.09159662  0.03778083  0.17055821
   0.1241175   0.0502808   0.03800729  0.0461642   0.03657585 -0.15139282
   0.25740871  0.20866376 -0.19119909 -0.05797765  0.09533245 -0.04379408
   0.16214164 -0.07163181  0.08558618  0.36380258 -0.13584161  0.03178893
   0.08297653  0.2789627   0.07850633 -0.1680178   0.09820559 -0.05731182
  -0.31009343  0.13193925  0.16363628  0.21281421  0.20064935 -0.41161972
   0.14143808 -0.26236033  0.22751059 -0.20039582  0.07464906  0.08548113
  -0.12349026 -0.18660614  0.03948784 -0.26668084  0.0499777   0.02894317
   0.08739531  0.10810421 -0.20879255 -0.10187498 -0.22793107  0.00338134
  -0.12318487 -0.27175224  0.12880553  0.11658974 -0.10835684 -0.01309645
  -0.0479222   0.17604272 -0.16445346 -0.17011097  0.1509262   0.1793481
   0.14832401  0.15635349 -0.19928627 -0.16703442  0.34119785  0.30328616
  -0.12827857  0.20242186  0.12896447  0.10655417  0.12168979  0.04360386
   0.01131401 -0.22121586  0.21947955 -0.10317886  0.38240919  0.02041952
   0.25060335  0.14373891 -0.21416564 -0.27822566  0.03730106  0.19428581
   0.07474265 -0.05913458  0.23070602  0.24114624  0.01235059  0.14081411
  -0.29731604 -0.05171582 -0.05490509  0.27600956 -0.23511453 -0.06905017
   0.19506875  0.05302369  0.16092959 -0.06635068  0.23800665 -0.09585649
   0.2429224  -0.18838114  0.32038635  0.15392867  0.10087175 -0.25193885
   0.26098809 -0.0512087   0.13368611  0.11408705  0.34758189  0.13101009
   0.13968477  0.19301823 -0.12717079  0.11378642 -0.05893625  0.21331698
  -0.17355713 -0.17778939  0.07642353  0.4216311  -0.11460364  0.24177301
  -0.14232783 -0.19500251  0.08650319  0.07909434 -0.11557045 -0.03323226
   0.28433618  0.18031135  0.11708888  0.16605754 -0.03698127 -0.18679811
  -0.09634076  0.21363595  0.08812478 -0.10168838  0.16156396 -0.1890614
  -0.20493136  0.21064946  0.07235899 -0.25422937  0.02249824 -0.2350051
   0.18402976  0.01788062  0.11168408 -0.2328122  -0.20997225 -0.12671433
  -0.13085391  0.01222112  0.15059492  0.06689769  0.08994301  0.10918127
  -0.09786272  0.16900072  0.1065959   0.08345459  0.31001645 -0.21089435
  -0.13772577 -0.23094313 -0.07297084 -0.06509808 -0.08191313  0.14617877
   0.21302773 -0.29516858  0.08688538 -0.38927254 -0.23115799 -0.13296574
   0.10265943 -0.04877579 -0.08309387 -0.32354784 -0.08223338  0.25274929
  -0.1506279   0.01382777  0.26271558  0.15800567 -0.09786582  0.29960725
   0.12940559  0.22296575 -0.36744401 -0.19543092  0.22146639 -0.15027903
   0.07534801 -0.10761997 -0.19822216  0.11832882 -0.29267931 -0.0383753
  -0.14995091 -0.16227001  0.0243405   0.15666771]]
After layer encoder_birnn_forward_l0_t2_out_0 (1, 256) <class 'numpy.float32'> [[ 0.04404476  0.07922302 -0.11279934 -0.06136697  0.13376112 -0.02179429
   0.11615346 -0.04611914  0.0042718  -0.03872207  0.05579133  0.073045
   0.02794714 -0.11176656  0.03361407 -0.02303185  0.05141359  0.10236324
  -0.02699892  0.04694356 -0.05663428 -0.12632713 -0.13094591  0.06290907
  -0.04198738 -0.03229322 -0.14225738 -0.04003053 -0.07457671  0.06075803
   0.05153621 -0.05540701  0.13599792 -0.02677166  0.15042824  0.0508527
   0.0574921  -0.1533412  -0.10413936  0.04238793 -0.04997849  0.08908214
  -0.06111352  0.0889218  -0.1416408  -0.05032727  0.02207265  0.09235452
   0.06706148  0.02567742  0.01897066  0.02514331  0.02397511 -0.07744312
   0.14060296  0.10133094 -0.1014785  -0.03016789  0.05124279 -0.02378146
   0.08294407 -0.03959453  0.04343738  0.20795265 -0.07285888  0.01712536
   0.04773104  0.14949028  0.04168179 -0.09142145  0.05450085 -0.0313891
  -0.18329638  0.06920978  0.08784196  0.13538276  0.11043559 -0.26246914
   0.08278309 -0.13975686  0.12799789 -0.10038649  0.04773485  0.04539533
  -0.06910799 -0.10068232  0.02038365 -0.15124547  0.03100984  0.01553055
   0.04632211  0.05563012 -0.10163613 -0.05724889 -0.11872265  0.00196551
  -0.07050367 -0.15144412  0.07365849  0.06793825 -0.0569185  -0.00700433
  -0.02541427  0.09998424 -0.0909889  -0.08443759  0.07993744  0.10364276
   0.08305805  0.08231959 -0.11367916 -0.09011381  0.21155742  0.18631895
  -0.07244307  0.10637214  0.07020596  0.06220721  0.06605295  0.02382247
   0.0059872  -0.12948821  0.12140061 -0.05530379  0.20372082  0.01123405
   0.13349755  0.07209302 -0.11274227 -0.17079177  0.02088494  0.11394282
   0.0390234  -0.03204048  0.12143759  0.12483574  0.00689158  0.07476559
  -0.17202127 -0.02858019 -0.02893399  0.1547678  -0.12854062 -0.03742592
   0.10313515  0.0284542   0.08584619 -0.03551359  0.12361338 -0.05240978
   0.1453604  -0.10120666  0.17296208  0.07729918  0.05439569 -0.12753902
   0.13520736 -0.02751164  0.07552692  0.06400712  0.19241776  0.07150797
   0.07525221  0.10549898 -0.07219537  0.05890963 -0.03185056  0.1102837
  -0.08639155 -0.0951945   0.03907649  0.28600386 -0.06389729  0.14407541
  -0.07063114 -0.10609614  0.04696408  0.04322359 -0.06090681 -0.01894405
   0.15620349  0.08987219  0.06181606  0.09291971 -0.01918388 -0.10395647
  -0.05308402  0.11107614  0.04526024 -0.0554656   0.08033346 -0.09942349
  -0.11988069  0.11645266  0.03751982 -0.14125746  0.01529616 -0.13255499
   0.10140009  0.00982282  0.05823822 -0.1194872  -0.11771494 -0.06790563
  -0.07109548  0.00691283  0.08744572  0.03346426  0.04281305  0.06117309
  -0.0539685   0.08672825  0.05825146  0.04608244  0.19202912 -0.12839137
  -0.07458749 -0.13521349 -0.04037072 -0.03439214 -0.04255662  0.08209591
   0.10750094 -0.16127396  0.04613325 -0.21284994 -0.12292887 -0.07039341
   0.0569403  -0.02521374 -0.04166321 -0.18682177 -0.04401163  0.13759586
  -0.08420199  0.00720147  0.13174616  0.08016165 -0.05118989  0.17166485
   0.06868377  0.12724    -0.25067693 -0.09354123  0.12193175 -0.08023383
   0.04121264 -0.05837516 -0.10903965  0.06725164 -0.16533895 -0.0203359
  -0.08621152 -0.09011273  0.0131588   0.08594928]]
After layer expand_dims1034_0 (1, 1, 256) <class 'numpy.float32'> [[[ 0.04404476  0.07922302 -0.11279934 -0.06136697  0.13376112 -0.02179429
    0.11615346 -0.04611914  0.0042718  -0.03872207  0.05579133  0.073045
    0.02794714 -0.11176656  0.03361407 -0.02303185  0.05141359  0.10236324
   -0.02699892  0.04694356 -0.05663428 -0.12632713 -0.13094591  0.06290907
   -0.04198738 -0.03229322 -0.14225738 -0.04003053 -0.07457671  0.06075803
    0.05153621 -0.05540701  0.13599792 -0.02677166  0.15042824  0.0508527
    0.0574921  -0.1533412  -0.10413936  0.04238793 -0.04997849  0.08908214
   -0.06111352  0.0889218  -0.1416408  -0.05032727  0.02207265  0.09235452
    0.06706148  0.02567742  0.01897066  0.02514331  0.02397511 -0.07744312
    0.14060296  0.10133094 -0.1014785  -0.03016789  0.05124279 -0.02378146
    0.08294407 -0.03959453  0.04343738  0.20795265 -0.07285888  0.01712536
    0.04773104  0.14949028  0.04168179 -0.09142145  0.05450085 -0.0313891
   -0.18329638  0.06920978  0.08784196  0.13538276  0.11043559 -0.26246914
    0.08278309 -0.13975686  0.12799789 -0.10038649  0.04773485  0.04539533
   -0.06910799 -0.10068232  0.02038365 -0.15124547  0.03100984  0.01553055
    0.04632211  0.05563012 -0.10163613 -0.05724889 -0.11872265  0.00196551
   -0.07050367 -0.15144412  0.07365849  0.06793825 -0.0569185  -0.00700433
   -0.02541427  0.09998424 -0.0909889  -0.08443759  0.07993744  0.10364276
    0.08305805  0.08231959 -0.11367916 -0.09011381  0.21155742  0.18631895
   -0.07244307  0.10637214  0.07020596  0.06220721  0.06605295  0.02382247
    0.0059872  -0.12948821  0.12140061 -0.05530379  0.20372082  0.01123405
    0.13349755  0.07209302 -0.11274227 -0.17079177  0.02088494  0.11394282
    0.0390234  -0.03204048  0.12143759  0.12483574  0.00689158  0.07476559
   -0.17202127 -0.02858019 -0.02893399  0.1547678  -0.12854062 -0.03742592
    0.10313515  0.0284542   0.08584619 -0.03551359  0.12361338 -0.05240978
    0.1453604  -0.10120666  0.17296208  0.07729918  0.05439569 -0.12753902
    0.13520736 -0.02751164  0.07552692  0.06400712  0.19241776  0.07150797
    0.07525221  0.10549898 -0.07219537  0.05890963 -0.03185056  0.1102837
   -0.08639155 -0.0951945   0.03907649  0.28600386 -0.06389729  0.14407541
   -0.07063114 -0.10609614  0.04696408  0.04322359 -0.06090681 -0.01894405
    0.15620349  0.08987219  0.06181606  0.09291971 -0.01918388 -0.10395647
   -0.05308402  0.11107614  0.04526024 -0.0554656   0.08033346 -0.09942349
   -0.11988069  0.11645266  0.03751982 -0.14125746  0.01529616 -0.13255499
    0.10140009  0.00982282  0.05823822 -0.1194872  -0.11771494 -0.06790563
   -0.07109548  0.00691283  0.08744572  0.03346426  0.04281305  0.06117309
   -0.0539685   0.08672825  0.05825146  0.04608244  0.19202912 -0.12839137
   -0.07458749 -0.13521349 -0.04037072 -0.03439214 -0.04255662  0.08209591
    0.10750094 -0.16127396  0.04613325 -0.21284994 -0.12292887 -0.07039341
    0.0569403  -0.02521374 -0.04166321 -0.18682177 -0.04401163  0.13759586
   -0.08420199  0.00720147  0.13174616  0.08016165 -0.05118989  0.17166485
    0.06868377  0.12724    -0.25067693 -0.09354123  0.12193175 -0.08023383
    0.04121264 -0.05837516 -0.10903965  0.06725164 -0.16533895 -0.0203359
   -0.08621152 -0.09011273  0.0131588   0.08594928]]]
After layer encoder_birnn_forward_l0_t3_i2h_output (1, 1024) <class 'numpy.float32'> [[ 0.07376467 -0.04585483  0.06153381 ...,  0.03591035  0.03396329
   0.02903319]]
After layer encoder_birnn_forward_l0_t3_h2h_output (1, 1024) <class 'numpy.float32'> [[ 0.18180765  0.1777689   0.14502844 ...,  0.38282531  0.23510456
   0.3309114 ]]
After layer _plus1029_0 (1, 1024) <class 'numpy.float32'> [[ 0.25557232  0.13191406  0.20656225 ...,  0.41873565  0.26906785
   0.35994458]]
After layer encoder_birnn_forward_l0_t3_slice_output0 (1, 256) <class 'numpy.float32'> [[  2.55572319e-01   1.31914064e-01   2.06562251e-01   9.26668122e-02
    3.29632431e-01   2.65383393e-01   4.77994055e-01   7.98606798e-02
   -9.34543014e-02   2.12179825e-01   1.69136047e-01   2.86203742e-01
    2.69477954e-03   4.04471308e-01  -4.84590232e-02   1.18132621e-01
    1.28401771e-01   2.03925595e-01   3.60502273e-01   1.59398600e-01
    2.53976695e-02  -1.96112692e-01   2.18063086e-01   1.80741593e-01
    1.54448867e-01   9.18770134e-02   3.90493751e-01   5.14379889e-02
    3.14568102e-01   2.50673175e-01   2.09568024e-01   2.82034159e-01
    4.92089868e-01   1.27128154e-01   6.06274128e-01   6.22394420e-02
    1.22520931e-01   7.02262878e-01   4.64768678e-01  -1.01130508e-01
   -3.95133607e-02   2.62535155e-01   3.36539537e-01   1.35781556e-01
    5.49737155e-01   2.06953645e-01   2.05270082e-01   3.13197941e-01
    1.46885633e-01  -4.55401316e-02  -9.74349231e-02  -7.89594352e-02
    1.12643981e+00   1.87104926e-01   5.01543880e-01   1.51035115e-01
    3.58582050e-01  -4.16346192e-02   1.39013276e-01  -2.91328073e-01
    1.92285612e-01   2.12354004e-01   6.33551627e-02   4.50774640e-01
    9.98796225e-02   7.93153197e-02   3.06097537e-01   5.02116919e-01
    2.77978718e-01   3.96307915e-01  -5.45268878e-02  -2.22886920e-01
    6.16676748e-01   2.07044154e-01   3.09188306e-01   6.18534863e-01
    3.27764332e-01   9.27640796e-01   2.22817123e-01  -2.82944739e-03
    3.28197509e-01   2.55480587e-01   3.69021744e-01   3.04054096e-02
    4.45668399e-01   2.91674167e-01   1.07431948e-01   5.56468666e-01
    4.90625888e-01  -3.71142700e-02   1.61404401e-01  -4.34153713e-02
   -7.72168636e-02   2.23489881e-01  -4.66040894e-02  -1.52794272e-01
    4.44327891e-01   4.90622878e-01   3.76537740e-01   2.70937085e-01
    7.79419467e-02  -9.57481042e-02   2.03301445e-01   4.56685245e-01
    4.02006745e-01   1.86142802e-01   5.99329844e-02   1.85978740e-01
    2.77760923e-02   1.46812662e-01   5.07518768e-01   3.76765311e-01
    8.18570137e-01   9.54073668e-01   3.54633123e-01   3.48298222e-01
    2.69177973e-01   4.08332348e-01   6.17778674e-02   6.04969412e-02
   -5.11780493e-02   4.01803225e-01   6.05642438e-01   1.42882973e-01
    7.17533529e-01   8.10197815e-02   2.09100723e-01   1.85647890e-01
    2.00497925e-01   7.45813549e-01  -1.14840090e-01   3.15314472e-01
    1.00472778e-01   1.88062191e-02   4.11614388e-01   2.25911066e-01
    2.55779028e-01  -1.64526165e-01   3.46112311e-01  -3.55344638e-02
    4.73120138e-02   4.35859770e-01   3.12154770e-01   5.77858202e-02
    2.31645077e-01  -2.12832451e-01   5.28694354e-02  -1.94729671e-01
    3.40823621e-01  -3.14690806e-02   6.04143798e-01   3.36674780e-01
    6.16855681e-01   4.44814980e-01   1.02395289e-01   3.68669391e-01
    2.49494269e-01  -1.14712268e-01   3.95016521e-01   3.08186054e-01
    7.17465937e-01  -2.26766020e-02   3.26114178e-01   3.34690452e-01
    3.01780462e-01   7.07145631e-02   7.73100555e-02   2.21109062e-01
    6.51776604e-03   1.90322250e-01  -1.26160607e-01   1.30685449e+00
    1.34424463e-01   5.43259621e-01   3.02813411e-01   9.58951190e-02
   -4.14207727e-02  -1.86035231e-01  -7.55898654e-04   1.33651391e-01
    5.28888762e-01   2.11784452e-01   2.57329106e-01   1.52031869e-01
   -8.21164101e-02   2.26186648e-01   1.40652247e-02   4.53821540e-01
    2.29978830e-01   2.48521134e-01  -1.36253655e-01   1.45924896e-01
    5.40918827e-01   1.67665929e-01   1.99621454e-01   4.45360005e-01
    1.19191277e+00   5.02557278e-01   2.37173274e-01   1.33492559e-01
    1.39765218e-01   3.72323722e-01   2.24629804e-01   1.02055371e-01
    2.43294403e-01   6.97851460e-03   2.85479158e-01  -1.23327799e-01
   -2.68508941e-02   1.82510376e-01   2.64711320e-01   1.30029082e-01
    3.41716945e-01   1.84152752e-01   7.19398558e-01   3.10664743e-01
    1.42772168e-01   4.72599149e-01   1.92149073e-01  -1.84167385e-01
    8.59288871e-02   1.35182247e-01   3.31862986e-01   2.75695801e-01
    2.84459472e-01   9.53385174e-01   2.63110459e-01   6.27300292e-02
    8.89728591e-02   5.00763431e-02  -1.69121608e-01   9.12177861e-01
    1.08797304e-01   4.81884837e-01   2.04713464e-01   2.70751491e-02
    2.16184273e-01  -9.30089876e-02   1.39833868e-01   4.98120904e-01
    1.38595700e-01   3.73548031e-01   1.42124152e+00   2.18082204e-01
    4.31288451e-01   2.84454942e-01   1.46488458e-01   1.47668019e-01
    3.17446649e-01   1.47171721e-01   6.35439992e-01  -1.78367749e-01
    3.94960463e-01   2.07589850e-01  -9.56090689e-02   1.83318853e-01]]
After layer encoder_birnn_forward_l0_t3_slice_output1 (1, 256) <class 'numpy.float32'> [[ 0.47143668 -0.00405221  0.12061357  0.23348351  0.15419036  0.22322145
   0.39949191  0.18132155  0.63297081  0.14720583  0.40075389  0.17112932
   0.30808979  0.2567454   0.02272879  0.20872504  0.08723788  0.17068906
   0.48954815  0.25799227  0.13711669  0.00505523  0.46320599  0.15181586
   0.28252444  0.23256284  0.3268559   0.18295012  0.40121064  0.06231022
   0.31477797  0.25439385  0.23996276  0.26649505  0.50220448  0.2627992
   0.14800875  0.13343033  0.49141246  0.04061426  0.35740906  0.18907955
   0.46728301 -0.03518057  0.0540311  -0.08861184  0.44487134  0.18451275
   0.16691004 -0.10730788 -0.07851556  0.14438604  1.05658376 -0.05744203
   0.39502832 -0.0056055   0.15736793  0.16269672  0.21868226  0.31572202
  -0.00263821  0.14519797  0.16372776  0.38144031  0.0761445   0.16051149
   0.26758623  0.40995935  0.19535187  0.50980401 -0.09411112  0.21956789
   0.56551695  0.22354682  0.08458145  0.9063735   0.23552471  0.78673345
   0.3588686  -0.14685555  0.36083296 -0.18049122  0.94524515  0.24527031
   0.36683127  0.17068061  0.0101348   0.54348755  0.94507313  0.23258626
   0.11137804  0.2245231  -0.00916416  0.19579205 -0.05402977  0.03611486
   0.3826701   0.35378167  0.42045408  0.31797078  0.06769717 -0.12749478
   0.06486274  0.33455563  0.3165417   0.12059228  0.28329077  0.25521764
   0.22100376  0.17949446  0.33665311  0.45546108  0.60018307  0.7657963
   0.3032558   0.21465707  0.45360929  0.42761639  0.20679893  0.1775111
   0.22629142  0.53798127  0.20506921  0.21019733  0.45444763  0.25804088
  -0.10277797  0.18978634  0.16223878  0.60822153  0.12547503  0.29375723
   0.10962053  0.09407215  0.18684284  0.42724258  0.21053761 -0.16706912
   0.56998324  0.29664207  0.20645173  0.2328424   0.32915145  0.24743937
   0.17874816  0.41721109  0.13486993  0.20655751  0.36915612  0.2415413
   0.39981902  0.13052456  0.3109147   0.14794955  0.16517651  0.11475214
   0.4004772   0.08609955  0.46833962  0.21169826  0.50273377  0.20855981
   0.41046476  0.34654856  0.35839123  0.06845488  0.09986424  0.16506466
  -0.04072933  0.12354483 -0.06214049  0.78767943  0.22829179  0.52565235
   0.00779191  0.12409042  0.11611669  0.30170006 -0.12184727  0.37348223
   0.18146448 -0.03687962  0.36593071  0.23766865  0.16648807  0.26674953
   0.42638963  0.31656611  0.17219536  0.30329743 -0.11460134  0.25279611
   0.33431193  0.24005252  0.03872692  0.20470881  1.54878557 -0.09310158
   0.24880314 -0.00328758  0.26208416  0.22470316  0.1462671   0.49935013
   0.28342649  0.16696231  0.36276394 -0.19673561  0.04524774  0.26528537
   0.35094562  0.1851768   0.27711391  0.26803437  0.66091013  0.4335269
   0.06714339  0.36420453  0.10352001  0.07848238  0.0314031   0.36128736
  -0.0601483   0.29651254  0.17022859  0.57600927 -0.05556145  0.10193429
   0.28361014  0.12240547  0.18341711  0.66637266  0.11978377  0.31410891
   0.36977762  0.29389399  0.00632173  0.09716955  0.08373267  0.56602502
   0.08386603  0.39312047  1.32542181 -0.01827285  0.12285344 -0.0145883
   0.15612414  0.18261951  0.25209731  0.34626845  0.59165192 -0.06164499
   0.44423836  0.28684321  0.15558781  0.28602672]]
After layer encoder_birnn_forward_l0_t3_slice_output2 (1, 256) <class 'numpy.float32'> [[ 0.1391457   0.28165522 -0.46595597 -0.23323154  0.63136882 -0.05862387
   0.52604234 -0.07356465 -0.11973689 -0.09649131  0.32869112  0.3674795
   0.06493888 -0.47505865  0.09992541 -0.00647261  0.2882781   0.45596915
  -0.07976976  0.20514604 -0.19295466 -0.85915303 -0.62463665  0.2687529
  -0.1683041  -0.10782915 -0.54394412 -0.07412134 -0.44041985  0.28433913
   0.24843936 -0.1419363   0.53125483 -0.15453862  0.78444886  0.1999118
   0.2392004  -0.80930465 -0.54583365  0.11078024 -0.09138351  0.5294106
  -0.138722    0.48934907 -0.91902244 -0.26243693 -0.00120965  0.3462899
   0.2844021   0.18302803  0.04136907  0.02536649 -0.18432608 -0.34290925
   0.65162522  0.48859739 -0.66037077 -0.1188097   0.24751659 -0.02987181
   0.45118639 -0.12795146  0.1112207   1.15417194 -0.35580459  0.06434302
   0.27216589  0.67352688  0.19388837 -0.41791144  0.29849008  0.00163984
  -0.75702786  0.25626644  0.39341992  0.61367542  0.51387519 -1.05969286
   0.32263857 -0.72773671  0.66266888 -0.44734877 -0.02514624  0.14202186
  -0.25756848 -0.475761    0.05991394 -0.64403892  0.11423247 -0.04429559
   0.2714957   0.22417705 -0.63633853 -0.20911583 -0.7932626  -0.16929261
  -0.36456525 -0.70652747  0.32737261  0.1449658  -0.32607818 -0.03819365
  -0.04820217  0.38839948 -0.38251168 -0.47811478  0.37236738  0.31810194
   0.32404763  0.30600423 -0.55966991 -0.46174324  0.94482583  0.79994667
  -0.23159647  0.53542602  0.27902472  0.13559437  0.24851416  0.11739254
   0.02558144 -0.44347185  0.51266623 -0.22960314  1.00340521 -0.00451822
   0.73891836  0.33854556 -0.58609116 -0.69128799  0.14656569  0.46218768
   0.18379937 -0.12946302  0.55918646  0.6497125   0.1413012   0.37488469
  -0.73978221 -0.16013876 -0.05410025  0.74584186 -0.64076573 -0.11642569
   0.5283013   0.01318853  0.40644461 -0.07934295  0.72681201 -0.15235849
   0.72235501 -0.42568684  0.89640683  0.32849085  0.16746287 -0.6877504
   0.77096248 -0.09878071  0.38397196  0.38158876  1.03416312  0.17456521
   0.20874408  0.53227782 -0.17278309  0.20434083 -0.03640908  0.63709575
  -0.3922984  -0.39093104  0.14463361  1.16176915 -0.22557662  0.77628487
  -0.39710563 -0.66424537  0.09923925  0.09488384 -0.27010512 -0.08709043
   0.73078758  0.50470376  0.27259865  0.38283753 -0.03307293 -0.45082971
  -0.23697688  0.56409311  0.25084046 -0.28286523  0.62985134 -0.44991463
  -0.45527884  0.56678426  0.16186391 -0.69442785 -0.04516413 -0.59984773
   0.4491815  -0.04936761  0.09368477 -0.52560353 -0.70804149 -0.34420949
  -0.18212706 -0.10104553  0.54126525  0.1097174   0.20067349  0.12323193
  -0.19129193  0.32832012  0.24511108  0.23635836  0.87490052 -0.55365545
  -0.33039117 -0.59913969 -0.1817496  -0.25350323 -0.18978268  0.35432416
   0.5420025  -0.78544295  0.17260787 -0.96642298 -0.54404545 -0.2229851
   0.25474727 -0.03669626 -0.2103253  -0.8169657  -0.21301755  0.62253797
  -0.38086641  0.01939629  0.63905579  0.31051761 -0.16101819  0.96602005
   0.40254134  0.56427574 -1.00677681 -0.60236907  0.58629709 -0.35701141
   0.21640256 -0.18071306 -0.46505791  0.28592733 -0.7152642  -0.10585424
  -0.32282844 -0.34790689  0.00199825  0.26152003]]
After layer encoder_birnn_forward_l0_t3_slice_output3 (1, 256) <class 'numpy.float32'> [[  4.31098133e-01   2.84430832e-01   3.40550125e-01   4.24633890e-01
    2.61948884e-01   3.85206431e-01   6.47938609e-01   2.74893016e-01
    3.88451666e-01   3.59323353e-01   2.64649153e-01   3.07043403e-01
    2.57815242e-01   3.86071712e-01  -3.89649719e-03   1.63807377e-01
    3.21436912e-01   2.40315124e-01   7.02936053e-01   4.03161287e-01
    1.18831232e-01   2.13924926e-02   5.77935815e-01   4.02224928e-01
    3.26256692e-01   1.59201205e-01   5.07100344e-01   3.74909312e-01
    4.81788181e-02   2.60561019e-01   3.54665637e-01   4.53177094e-01
    1.22048691e-01   2.38086835e-01   2.67437458e-01   2.23156571e-01
    3.46446514e-01   1.55177057e-01  -1.71104848e-01   1.77933022e-01
    2.67806858e-01   2.84547269e-01   1.88653022e-01   2.64452457e-01
    2.64342606e-01   3.31491560e-01   6.73034251e-01   3.28502148e-01
    2.72134572e-01   7.90867507e-02  -6.88772202e-02   3.26610893e-01
    1.16445267e+00   2.14610286e-02   3.35379422e-01  -6.67010099e-02
    1.92898929e-01   2.07759380e-01   3.02498639e-01   2.99599499e-01
    1.95182115e-02   3.12571108e-01   4.58724760e-02   4.75276560e-01
    1.90481335e-01   2.85714060e-01   4.83744085e-01   2.18821779e-01
    2.58795053e-01   2.55260855e-01   3.76941949e-01   3.34869415e-01
    6.53151989e-01   2.31360525e-01   2.37314656e-01   9.96767521e-01
    3.28191549e-01   1.02823627e+00   5.44653237e-01   1.63907707e-01
    4.82990921e-01  -3.36040780e-02   1.12457669e+00   2.53057033e-01
    4.57144797e-01   2.36618280e-01   1.33111745e-01   4.12280500e-01
    8.37896526e-01   3.26159626e-01   2.21652746e-01   1.78754359e-01
   -1.28959745e-01   4.71108526e-01   9.75878686e-02   5.22626519e-01
    4.30763602e-01   4.15226609e-01   4.51482952e-01   5.79870582e-01
    1.54431283e-01   2.33790874e-01   1.53754234e-01   5.15209258e-01
    4.08059776e-01   4.95343953e-02   2.31563076e-01   4.81973052e-01
    4.21821296e-01   1.55690640e-01   5.06569266e-01   2.86911279e-01
    8.44650209e-01   7.76254416e-01   4.23062354e-01   2.61806488e-01
    3.29902470e-01   6.22531712e-01   3.17802221e-01   3.56868953e-01
    2.47542590e-01   6.12208247e-01   3.48354101e-01   2.66211271e-01
    3.36098880e-01   3.81904542e-01   1.28514394e-01   1.35785639e-02
    2.11202130e-01   8.62147093e-01   3.90636563e-01   5.96605420e-01
    1.84732825e-01   2.86829412e-01   1.87334344e-01   1.29273564e-01
    3.96006197e-01   2.37877876e-01   5.46095371e-01   3.21647346e-01
    1.61586717e-01   3.49584490e-01   3.08490068e-01   3.11517984e-01
    1.92610621e-01   3.01093757e-01   2.24047005e-01   2.33076870e-01
    8.32924992e-02   2.42776304e-01   6.97926521e-01   1.92552388e-01
    3.23498845e-01  -1.07345339e-02   1.92277610e-01   3.77332047e-03
    1.54002070e-01   2.45303348e-01   5.28601766e-01   3.77651364e-01
    3.40383530e-01   3.35214436e-01   1.81138486e-01   3.46731246e-01
    5.10827065e-01   1.33055538e-01   3.01201016e-01   1.41707018e-01
   -3.49418893e-02   2.05077887e-01   1.49576753e-01   1.32603204e+00
    4.00451928e-01   6.23855770e-01  -1.63048506e-02   1.93255275e-01
    2.82791764e-01   3.47715020e-01   1.89647093e-01   4.59846586e-01
    2.98627317e-01  -3.81127298e-02   2.76590616e-01   4.02357489e-01
    1.66543141e-01   3.75510156e-01   3.23522896e-01   1.52699500e-01
    2.41169497e-01   4.15612906e-01  -1.79709867e-02   2.40437716e-01
    5.92351615e-01   3.36617976e-01   9.51455086e-02   3.84111911e-01
    1.37814283e+00   3.44894946e-01   3.43527973e-01   3.37298721e-01
    1.56348020e-01   7.56590441e-02   3.95732492e-01   3.73960048e-01
    3.39173019e-01   4.54500109e-01   5.28174162e-01   3.63105536e-02
   -1.68596610e-01   3.65588605e-01   3.63992810e-01   1.38276160e-01
    4.03152615e-01   3.84816140e-01   9.00132835e-01   6.80269420e-01
    2.56780088e-01   5.91867864e-01   3.94728690e-01   2.00693339e-01
    2.01641545e-01   4.18663323e-01   2.40239799e-02   2.38977268e-01
    2.97033012e-01   2.43781373e-01   2.77139574e-01   2.60648668e-01
    3.63072932e-01   1.24154128e-01   6.62457198e-02   5.57355046e-01
    2.96516836e-01   3.50017965e-01   4.19181734e-01   1.66944176e-01
    2.72524171e-02  -2.93411314e-04   2.17881620e-01   6.20151043e-01
    1.46033615e-01   4.71308112e-01   1.51938176e+00  -3.88090983e-02
    3.15207720e-01   1.73837632e-01   3.27777594e-01   3.04240227e-01
    4.21593189e-01   4.61947501e-01   5.16416788e-01   1.75708771e-01
    5.33653796e-01   4.18735653e-01   2.69067854e-01   3.59944582e-01]]
After layer encoder_birnn_forward_l0_t3_o_output (1, 256) <class 'numpy.float32'> [[ 0.6061359   0.57063216  0.58432418  0.60459161  0.56511533  0.59512818
   0.65654576  0.56829375  0.59590995  0.58887666  0.56577885  0.57616341
   0.56409913  0.59533668  0.49902588  0.54086053  0.57967442  0.55979127
   0.66883838  0.59944695  0.52967286  0.50534797  0.64059228  0.59922212
   0.58084828  0.53971648  0.62412649  0.59264469  0.5120424   0.56477422
   0.58774853  0.61139435  0.53047436  0.55924213  0.56646371  0.5555588
   0.58575565  0.53871661  0.45732787  0.54436624  0.56655443  0.57066065
   0.54702389  0.56573045  0.56570351  0.58212227  0.66218221  0.58139485
   0.56761688  0.51976138  0.48278746  0.58093452  0.76214081  0.50536507
   0.58306772  0.48333091  0.54807574  0.55175382  0.57505322  0.57434464
   0.50487942  0.57751274  0.51146615  0.61663187  0.54747689  0.57094651
   0.6186316   0.55448818  0.56434005  0.5634709   0.59313536  0.58294374
   0.65772039  0.55758351  0.55905181  0.73042256  0.58131927  0.73657382
   0.63289422  0.54088545  0.61845392  0.4915998   0.75483668  0.5629288
   0.61233664  0.55888009  0.53322887  0.60163462  0.69802201  0.58082467
   0.55518746  0.54456997  0.46780467  0.61564612  0.52437764  0.62776172
   0.60605603  0.60234046  0.61099178  0.64103764  0.5385313   0.55818295
   0.53836304  0.62602681  0.60062253  0.51238108  0.55763346  0.61821365
   0.60391903  0.53884423  0.62400192  0.57123983  0.6994437   0.68487233
   0.6042158   0.56508029  0.58173561  0.65079415  0.57878852  0.58828229
   0.5615716   0.64844435  0.58621836  0.56616253  0.5832426   0.5943324
   0.53208447  0.5033946   0.55260515  0.70310909  0.59643596  0.64487928
   0.54605234  0.57121974  0.54669714  0.53227341  0.59772772  0.55919063
   0.63322926  0.57972568  0.54030901  0.5865168   0.57651669  0.57725579
   0.54800433  0.57470989  0.55577862  0.55800688  0.52081108  0.56039774
   0.66772789  0.5479899   0.58017671  0.49731642  0.54792184  0.50094336
   0.53842461  0.56102014  0.62915695  0.59330654  0.58428365  0.5830276
   0.54516119  0.58582473  0.6250003   0.53321487  0.57473612  0.53536761
   0.49126545  0.55109054  0.53732467  0.79018354  0.59879619  0.65109497
   0.49592388  0.54816401  0.57023054  0.58606339  0.54727018  0.61297774
   0.57410693  0.49047294  0.56871015  0.59925395  0.54153985  0.59278977
   0.58018255  0.5381009   0.56000185  0.60243297  0.49550739  0.55982155
   0.64390451  0.58336872  0.52376842  0.59486449  0.79869258  0.58537906
   0.5850473   0.58353418  0.5390076   0.51890576  0.59766191  0.59241551
   0.58398962  0.61170864  0.62905717  0.50907665  0.45795038  0.59039259
   0.59000665  0.53451407  0.59944493  0.59503418  0.71097684  0.66379887
   0.56384456  0.64379364  0.59742045  0.55000561  0.55024028  0.60316336
   0.5060057   0.55946159  0.573717    0.56064528  0.56884485  0.56479573
   0.58978415  0.53099871  0.51655537  0.63584036  0.57359082  0.58662194
   0.60328746  0.54163939  0.50681269  0.49992669  0.5542559   0.65025288
   0.53644365  0.61569333  0.82044744  0.49029896  0.57815588  0.54335028
   0.58121854  0.57547879  0.60386443  0.6134761   0.62630951  0.54381454
   0.63033491  0.60318071  0.56686401  0.58902699]]
After layer encoder_birnn_forward_l0_t3_f_output (1, 256) <class 'numpy.float32'> [[ 0.61572373  0.49898699  0.53011692  0.55810714  0.5384714   0.55557477
   0.59856558  0.54520661  0.65316278  0.53673518  0.59886879  0.54267824
   0.57641894  0.5638361   0.50568193  0.55199265  0.52179563  0.54256898
   0.62        0.5641427   0.53422558  0.5012638   0.61377448  0.53788126
   0.57016504  0.55788004  0.58099419  0.54561037  0.59897852  0.51557249
   0.57805109  0.56325769  0.55970448  0.56623226  0.62297726  0.56532425
   0.53693473  0.53330815  0.62043911  0.51015222  0.58841312  0.54712957
   0.61474049  0.49120578  0.51350451  0.47786149  0.60941911  0.54599774
   0.54163092  0.47319874  0.48038116  0.53603393  0.74203718  0.48564342
   0.59749258  0.49859864  0.53926098  0.54058468  0.55445373  0.57828134
   0.49934044  0.53623587  0.54084074  0.59422046  0.51902694  0.54004198
   0.56650025  0.60107815  0.54868323  0.62476051  0.47648954  0.55467248
   0.6377281   0.55565512  0.52113277  0.7122575   0.5586105   0.68712956
   0.58876657  0.46335194  0.58924204  0.4549993   0.72015792  0.56101209
   0.59069312  0.5425669   0.50253367  0.63262331  0.72012329  0.55788583
   0.52781576  0.55589616  0.49770898  0.54879224  0.48649579  0.50902772
   0.59451693  0.58753431  0.60359192  0.57882965  0.51691782  0.46816942
   0.51621002  0.58286738  0.5784812   0.53011161  0.57035285  0.56346035
   0.55502713  0.54475349  0.5833773   0.61193687  0.64569819  0.68261081
   0.57523823  0.55345917  0.61149704  0.60530436  0.55151629  0.54426163
   0.55633271  0.63134271  0.55108839  0.55235672  0.61169618  0.56415462
   0.4743281   0.54730469  0.54047096  0.64753497  0.53132766  0.57291573
   0.52737772  0.52350074  0.54657531  0.60521501  0.55244088  0.45832956
   0.63875932  0.57362145  0.55143034  0.55794901  0.58155292  0.56154615
   0.54456842  0.60281569  0.53366643  0.55145651  0.59125507  0.56009346
   0.5986442   0.53258485  0.5771085   0.53692007  0.54120052  0.5286566
   0.59880227  0.52151161  0.61499065  0.55272776  0.62310153  0.55195177
   0.60119939  0.58578038  0.58865094  0.51710701  0.52494538  0.54117274
   0.48981908  0.53084695  0.48446989  0.68733287  0.55682635  0.62846851
   0.501948    0.53098285  0.52899659  0.57485807  0.46957585  0.59230012
   0.54524207  0.49078116  0.59047532  0.55913907  0.54152614  0.56629473
   0.60501122  0.57848722  0.54294276  0.57524842  0.47138101  0.5628646
   0.58280814  0.5597266   0.50968051  0.55099922  0.8247382   0.4767414
   0.5618819   0.49917808  0.56514853  0.55594063  0.53650171  0.62230659
   0.57038611  0.54164392  0.58970934  0.45097414  0.51130998  0.56593508
   0.58684689  0.54616237  0.56883854  0.56661028  0.65946484  0.60671556
   0.51677954  0.59005785  0.52585691  0.51961052  0.50785011  0.58935201
   0.48496744  0.57358974  0.54245466  0.64014864  0.48611322  0.52546155
   0.57043111  0.53056324  0.54572618  0.66069043  0.52991021  0.57788789
   0.59140527  0.57294917  0.50158042  0.52427328  0.52092099  0.63784546
   0.52095419  0.59703362  0.7900824   0.49543193  0.53067482  0.496353
   0.53895193  0.54552841  0.56269264  0.58571237  0.64374411  0.4845936
   0.60926849  0.57122314  0.53881866  0.57102317]]
After layer _mul2058_0 (1, 256) <class 'numpy.float32'> [[ 0.04806462  0.07300019 -0.11091042 -0.06026653  0.13811602 -0.02169296
   0.12117073 -0.04606536  0.00491432 -0.03748802  0.06225102  0.07444629
   0.02976653 -0.11928164  0.03340358 -0.02385106  0.0505132   0.10199659
  -0.02764373  0.04753757 -0.06008995 -0.12757829 -0.14155996  0.06078539
  -0.043318   -0.03422415 -0.14825086 -0.03911729 -0.08967552  0.05807431
   0.05479141 -0.05514575  0.14704974 -0.02854634  0.1779016   0.05345668
   0.05604273 -0.15814452 -0.1368527   0.04147    -0.05464277  0.09004887
  -0.07252273  0.08239125 -0.13901813 -0.04389352  0.02303532  0.09404349
   0.06757431  0.02381289  0.01826679  0.02476318  0.02715276 -0.07409249
   0.15733847  0.10559016 -0.10439093 -0.03137701  0.05301844 -0.02534151
   0.08168479 -0.03847745  0.04640201  0.22655344 -0.070944    0.01717314
   0.04711455  0.17224309  0.04316393 -0.10597574  0.04694524 -0.03182416
  -0.20448674  0.07374262  0.08604983  0.15393111  0.11362643 -0.30066025
   0.08383607 -0.12447558  0.13644642 -0.09243079  0.0538593   0.04807327
  -0.07331907 -0.10244668  0.01985429 -0.1728878   0.03602012  0.0161515
   0.04624661  0.06033047 -0.10546877 -0.05610283 -0.11286998  0.0017212
  -0.07360934 -0.16377802  0.07818027  0.06779389 -0.05623235 -0.00613171
  -0.02475688  0.1036897  -0.09600505 -0.09106307  0.08674388  0.10216045
   0.08293565  0.08587854 -0.11783591 -0.10318136  0.22951187  0.21374916
  -0.07419953  0.11360115  0.079303    0.06474348  0.06744815  0.02374697
   0.00629462 -0.14201054  0.12295292 -0.05719508  0.24643922  0.01152137
   0.12145479  0.07921758 -0.11757037 -0.18503819  0.01982829  0.11274252
   0.03949125 -0.03099316  0.1284097   0.14887731  0.00682332  0.06497099
  -0.19582625 -0.02969179 -0.03030681  0.15809897 -0.13933802 -0.03883666
   0.10760729  0.03199352  0.08663587 -0.03664335  0.14347395 -0.05385394
   0.1483904  -0.10154167  0.19164482  0.08330958  0.05477814 -0.13611956
   0.15998106 -0.02672931  0.08271082  0.06333482  0.22599314  0.07272927
   0.08453107  0.11450267 -0.07526671  0.05909569 -0.03097421  0.11724177
  -0.08588094 -0.09539266  0.03709723  0.3090758  -0.06409593  0.15501575
  -0.07192951 -0.1048862   0.04587455  0.04556319 -0.05451266 -0.01969072
   0.15942517  0.0894716   0.06945667  0.09371711 -0.02003546 -0.10703959
  -0.05846858  0.12551905  0.04797115 -0.05869896  0.0768314  -0.10771179
  -0.12115107  0.11969802  0.03694453 -0.14322083  0.01855829 -0.11417032
   0.10459461  0.00892657  0.0633825  -0.13184731 -0.11435121 -0.07928132
  -0.07506768  0.00661983  0.08948787  0.03021425  0.04611338  0.0620368
  -0.05761483  0.09319595  0.06086709  0.04739647  0.21140043 -0.12990214
  -0.07162907 -0.13877305 -0.03844055 -0.03387355 -0.04169301  0.08677237
   0.10491828 -0.17449676  0.04725052 -0.26306418 -0.11443712 -0.07028457
   0.05876716 -0.02589919 -0.0454513  -0.22173083 -0.04367493  0.14929593
  -0.08976517  0.00792311  0.13493672  0.08353803 -0.05114406  0.19715042
   0.06779452  0.1353922  -0.30454907 -0.09808442  0.1195067  -0.0751607
   0.04068607 -0.058938   -0.11303444  0.06963287 -0.19408505 -0.01860556
  -0.0920545  -0.09351906  0.01311771  0.0902038 ]]
After layer encoder_birnn_forward_l0_t3_i_output (1, 256) <class 'numpy.float32'> [[ 0.56354755  0.53293079  0.55145776  0.52315015  0.58166993  0.56595922
   0.61727411  0.51995456  0.4766534   0.55284685  0.54218352  0.5710665
   0.50067371  0.59976149  0.48788762  0.52949888  0.53205645  0.55080551
   0.58916205  0.53976548  0.50634909  0.45112839  0.55430073  0.54506278
   0.53853565  0.52295309  0.59640157  0.51285666  0.57799989  0.56234217
   0.55220109  0.57004488  0.62059861  0.53173935  0.64709038  0.51555485
   0.53059196  0.66868925  0.61414486  0.4747389   0.49012294  0.5652594
   0.5833497   0.53389335  0.63407463  0.55155456  0.55113804  0.57766569
   0.53665555  0.48861694  0.4756605   0.48027039  0.75518125  0.54664028
   0.62282211  0.53768718  0.5886972   0.48959288  0.53469747  0.42767879
   0.54792386  0.55288988  0.5158335   0.61082345  0.52494919  0.51981848
   0.57593244  0.62295669  0.56905061  0.59780031  0.48637167  0.44450784
   0.6494624   0.55157691  0.5766871   0.64988524  0.58121526  0.71659642
   0.555475    0.49929267  0.5813207   0.56352502  0.59122258  0.50760072
   0.60960883  0.57240593  0.52683222  0.63563508  0.62025386  0.49072245
   0.54026371  0.48914787  0.48070532  0.55564111  0.48835111  0.46187556
   0.60928977  0.62025315  0.59303778  0.56732291  0.51947564  0.47608119
   0.55065101  0.6122275   0.59916973  0.5464018   0.51497877  0.54636115
   0.50694358  0.53663737  0.62422466  0.59309268  0.69393271  0.72193366
   0.58774066  0.58620489  0.56689107  0.60068798  0.51543957  0.51511967
   0.48720828  0.5991208   0.64694613  0.53566009  0.67206365  0.52024388
   0.55208552  0.54627913  0.54995728  0.67826581  0.47132149  0.57818192
   0.52509713  0.50470144  0.60147494  0.55623877  0.56359845  0.45896098
   0.58567452  0.49111733  0.5118258   0.60727203  0.57741112  0.51444238
   0.55765367  0.44699183  0.51321429  0.45147082  0.58439058  0.49213335
   0.64660376  0.58338255  0.64950311  0.60940576  0.52557647  0.59113747
   0.56205201  0.47135338  0.59748977  0.57644242  0.67204875  0.49433109
   0.58081359  0.58290017  0.57487768  0.51767129  0.51931792  0.55505311
   0.50162947  0.54743743  0.46850163  0.78698629  0.53355557  0.63257039
   0.57513016  0.5239554   0.48964626  0.45362487  0.49981099  0.53336322
   0.62922388  0.5527491   0.56397963  0.53793496  0.47948241  0.55630678
   0.50351626  0.61154747  0.55724263  0.56181246  0.46598914  0.53641659
   0.63202614  0.54181856  0.54974031  0.60953552  0.76708299  0.62306011
   0.55901694  0.53332365  0.53488451  0.59202039  0.55592251  0.52549171
   0.56052536  0.50174463  0.570889    0.46920708  0.49328771  0.54550141
   0.56579411  0.53246152  0.58460748  0.54590851  0.67247456  0.57704753
   0.53563255  0.6159988   0.54789001  0.45408782  0.521469    0.53374422
   0.58221263  0.56849068  0.57063919  0.72179544  0.56540078  0.51567733
   0.52222854  0.5125165   0.45782009  0.7134456   0.52717257  0.61819291
   0.55100042  0.50676841  0.55383658  0.47676447  0.53490156  0.62201762
   0.53459358  0.59231603  0.80553299  0.55430549  0.60618126  0.57063806
   0.53655678  0.53685009  0.57870185  0.53672665  0.65372193  0.4555259
   0.59747624  0.55171186  0.47611591  0.5457018 ]]
After layer encoder_birnn_forward_l0_t3_c_output (1, 256) <class 'numpy.float32'> [[ 0.13825458  0.27443632 -0.43492603 -0.22909255  0.558994   -0.0585568
   0.48235002 -0.07343223 -0.11916794 -0.09619296  0.31734419  0.35178509
   0.06484775 -0.44227755  0.09959415 -0.00647252  0.2805492   0.42679328
  -0.079601    0.20231584 -0.19059514 -0.69582105 -0.55434811  0.26246402
  -0.16673276 -0.10741318 -0.49596772 -0.0739859  -0.4139924   0.27691627
   0.24345107 -0.14099078  0.48633969 -0.15332003  0.65525281  0.19729057
   0.23474035 -0.6692065  -0.4973911   0.11032928 -0.09112998  0.4849304
  -0.13783896  0.45369965 -0.72543466 -0.25657344 -0.00120965  0.33308113
   0.27697441  0.18101129  0.04134548  0.02536106 -0.18226652 -0.33007216
   0.57276309  0.4531025  -0.57861006 -0.11825381  0.2425828  -0.02986293
   0.42287374 -0.12725775  0.11076436  0.81913143 -0.34151325  0.06425437
   0.26563904  0.58729506  0.19149476 -0.3951695   0.28993022  0.00163984
  -0.639323    0.2508001   0.37430477  0.54670912  0.47295904 -0.7855463
   0.31189078 -0.62167871  0.58013678 -0.41971728 -0.02514094  0.14107464
  -0.25201985 -0.44284233  0.05984235 -0.56764334  0.11373817 -0.04426664
   0.26501602  0.22049567 -0.56240141 -0.20612006 -0.66025335 -0.16769364
  -0.34922886 -0.6084947   0.31615797  0.14395878 -0.31499246 -0.03817509
  -0.04816487  0.36997962 -0.36488673 -0.44473255  0.35606068  0.30778968
   0.31316221  0.29679763 -0.50773251 -0.43150395  0.73743165  0.66400695
  -0.22754271  0.48951781  0.27200219  0.13476944  0.24352144  0.11685624
   0.02557586 -0.41651812  0.47201997 -0.22565174  0.76302058 -0.00451819
   0.62849122  0.32617831 -0.52707851 -0.59880877  0.14552516  0.43186557
   0.18175726 -0.12874454  0.50737357  0.5714764   0.14036825  0.35825691
  -0.62901354 -0.15878376 -0.05404752  0.6326617  -0.56542069 -0.11590248
   0.48408151  0.01318777  0.38544968 -0.07917687  0.62111109 -0.15119043
   0.61836594 -0.40171045  0.71454382  0.31716409  0.1659148  -0.59653485
   0.64748877 -0.09846067  0.3661519   0.36408642  0.77557266  0.17281339
   0.20576407  0.48712033 -0.17108396  0.20154345 -0.036393    0.5629189
  -0.37333998 -0.37216258  0.14363346  0.82161558 -0.22182679  0.6505692
  -0.37746972 -0.58118176  0.09891474  0.09460013 -0.26372266 -0.08687092
   0.62354696  0.46580836  0.26604122  0.36516917 -0.03306088 -0.42258081
  -0.23263825  0.51100802  0.24570854 -0.27555484  0.55794978 -0.42182884
  -0.42622855  0.51299369  0.16046497 -0.60081899 -0.04513345 -0.53694117
   0.42122597 -0.04932755  0.09341165 -0.48201323 -0.60944724 -0.33123025
  -0.18013969 -0.10070304  0.49394512  0.10927925  0.19802248  0.1226119
  -0.18899229  0.31701052  0.24031752  0.23205313  0.7038554  -0.50325489
  -0.31887221 -0.53643715 -0.17977446 -0.24820891 -0.18753654  0.34020483
   0.49450228 -0.65581977  0.17091386 -0.74712819 -0.4960441  -0.21936138
   0.24937595 -0.0366798  -0.20727785 -0.67341495 -0.20985299  0.55289268
  -0.36345965  0.01939386  0.56425631  0.30090791 -0.15964091  0.74695015
   0.38212132  0.51114297 -0.76442558 -0.53873312  0.52722722 -0.34257889
   0.21308662 -0.17877123 -0.43419757  0.27838203 -0.6139673  -0.10546064
  -0.31206217 -0.33451796  0.00199825  0.25571671]]
After layer _mul2059_0 (1, 256) <class 'numpy.float32'> [[ 0.07791303  0.14625557 -0.23984334 -0.1198498   0.32514998 -0.03314076
   0.29774219 -0.03818142 -0.0568018  -0.05317997  0.17205879  0.20089269
   0.03246757 -0.26526105  0.04859075 -0.00342719  0.14926802  0.23508009
  -0.04689789  0.10920311 -0.09650768 -0.31390464 -0.30727556  0.14305937
  -0.08979154 -0.05617205 -0.29579592 -0.03794416 -0.23928757  0.15572169
   0.13443395 -0.08037107  0.30182174 -0.08152629  0.4240078   0.10171411
   0.12455134 -0.4474912  -0.3054702   0.0523776  -0.04466489  0.27411145
  -0.08040832  0.24222723 -0.45997971 -0.14151426 -0.00066668  0.19240953
   0.14863986  0.08844519  0.01966641  0.01218016 -0.13764426 -0.18043074
   0.35672951  0.2436274  -0.34062612 -0.05789622  0.12970841 -0.01277174
   0.23170261 -0.07035952  0.05713597  0.50034469 -0.17927711  0.03340061
   0.15299013  0.36585939  0.10897021 -0.23623244  0.14101385  0.00072892
  -0.41521624  0.13833554  0.21585673  0.35529819  0.27489102 -0.56291968
   0.17324753 -0.31039962  0.33724552 -0.23652118 -0.01486389  0.07160959
  -0.15363352 -0.25348559  0.03152688 -0.36081403  0.07054654 -0.02172264
   0.14317854  0.10785498 -0.27034935 -0.11452878 -0.32243544 -0.0774536
  -0.21278156 -0.37742075  0.18749362  0.08167111 -0.1636309  -0.01817445
  -0.02652204  0.2265117  -0.21862908 -0.24300267  0.18336369  0.16816433
   0.15875557  0.1592727  -0.31693915 -0.25592184  0.51172793  0.47936895
  -0.1337361   0.28695774  0.15419561  0.08095438  0.12552059  0.06019495
   0.01246077 -0.24954467  0.30537149 -0.12087263  0.51279837 -0.00235056
   0.3469809   0.1781844  -0.28987065 -0.4061515   0.06858914  0.24969687
   0.09544022 -0.06497756  0.3051725   0.31787732  0.07911133  0.16442594
  -0.36839721 -0.07798146 -0.02766292  0.38419774 -0.32648018 -0.05962515
   0.26994982  0.00589482  0.19781828 -0.03574605  0.36297148 -0.07440585
   0.39983773 -0.23435086  0.46409842  0.19328162  0.08720092 -0.3526341
   0.36392236 -0.04640977  0.21877201  0.20987485  0.52122265  0.08542703
   0.11951057  0.28394252 -0.09835235  0.10433326 -0.01889954  0.3124499
  -0.18727833 -0.20373572  0.0672925   0.64660019 -0.11835692  0.41153082
  -0.21709423 -0.30451334  0.04843323  0.04291297 -0.13181148 -0.04633375
   0.39235064  0.25747514  0.15004183  0.19643725 -0.01585211 -0.23508456
  -0.11713714  0.31250566  0.13691927 -0.15481015  0.25999853 -0.22627598
  -0.26938757  0.27794951  0.08821406 -0.3662205  -0.0346211  -0.33454663
   0.23547246 -0.02630755  0.04996444 -0.28536165 -0.33880544 -0.17405875
  -0.10097286 -0.05052721  0.28198785  0.0512746   0.09768206  0.06688496
  -0.10693073  0.1687959   0.14049143  0.12667978  0.47332484 -0.290402
  -0.17079833 -0.33044463 -0.09849663 -0.11270864 -0.09779449  0.18158236
   0.28790545 -0.37282744  0.09753015 -0.53927374 -0.28046373 -0.11311969
   0.13023125 -0.018799   -0.09489597 -0.48044494 -0.11062874  0.34179434
  -0.20026642  0.0098282   0.31250578  0.1434622  -0.08539217  0.46461615
   0.2042796   0.30275819 -0.61577004 -0.29862273  0.31959528 -0.19548856
   0.11433307 -0.09597335 -0.25127095  0.14941506 -0.40136388 -0.04804005
  -0.18644974 -0.18455753  0.0009514   0.13954507]]
After layer encoder_birnn_forward_l0_t3_state_0 (1, 256) <class 'numpy.float32'> [[ 0.12597765  0.21925576 -0.35075375 -0.18011633  0.46326602 -0.05483372
   0.41891292 -0.08424678 -0.05188748 -0.09066799  0.23430981  0.27533898
   0.06223409 -0.3845427   0.08199432 -0.02727825  0.19978122  0.33707669
  -0.07454161  0.15674068 -0.15659761 -0.44148293 -0.44883552  0.20384477
  -0.13310954 -0.0903962  -0.4440468  -0.07706144 -0.3289631   0.213796
   0.18922536 -0.13551682  0.44887149 -0.11007263  0.6019094   0.1551708
   0.18059407 -0.6056357  -0.44232291  0.0938476  -0.09930766  0.36416033
  -0.15293105  0.32461846 -0.59899783 -0.18540779  0.02236864  0.28645301
   0.21621417  0.11225808  0.0379332   0.03694334 -0.11049151 -0.25452322
   0.51406801  0.34921756 -0.44501704 -0.08927324  0.18272685 -0.03811325
   0.31338739 -0.10883696  0.10353798  0.72689813 -0.2502211   0.05057375
   0.20010468  0.53810251  0.15213414 -0.34220818  0.18795909 -0.03109524
  -0.61970299  0.21207815  0.30190656  0.5092293   0.38851744 -0.86357993
   0.25708359 -0.43487519  0.47369194 -0.32895195  0.03899541  0.11968286
  -0.22695258 -0.35593227  0.05138117 -0.53370184  0.10656665 -0.00557114
   0.18942514  0.16818546 -0.37581813 -0.17063162 -0.43530542 -0.0757324
  -0.2863909  -0.54119879  0.26567388  0.14946499 -0.21986325 -0.02430615
  -0.05127892  0.33020139 -0.31463414 -0.33406574  0.27010757  0.27032477
   0.24169123  0.24515124 -0.43477505 -0.3591032   0.74123979  0.6931181
  -0.20793563  0.40055889  0.2334986   0.14569786  0.19296874  0.08394191
   0.01875539 -0.39155519  0.4283244  -0.17806771  0.75923759  0.00917081
   0.4684357   0.257402   -0.40744102 -0.59118968  0.08841743  0.36243939
   0.13493147 -0.09597072  0.43358219  0.46675462  0.08593465  0.22939694
  -0.56422347 -0.10767325 -0.05796973  0.54229671 -0.4658182  -0.09846181
   0.3775571   0.03788834  0.28445414 -0.07238939  0.50644541 -0.12825979
   0.54822814 -0.33589253  0.65574324  0.27659118  0.14197905 -0.48875368
   0.52390343 -0.07313908  0.30148283  0.27320969  0.74721581  0.15815631
   0.20404163  0.39844519 -0.17361906  0.16342895 -0.04987374  0.42969167
  -0.27315927 -0.29912838  0.10438974  0.95567596 -0.18245286  0.56654656
  -0.28902376 -0.40939954  0.09430778  0.08847617 -0.18632415 -0.06602447
   0.55177581  0.34694675  0.21949852  0.29015437 -0.03588757 -0.34212416
  -0.17560571  0.4380247   0.18489042 -0.21350911  0.33682993 -0.33398777
  -0.39053863  0.39764753  0.12515859 -0.50944132 -0.01606281 -0.44871694
   0.34006706 -0.01738098  0.11334694 -0.41720897 -0.45315665 -0.25334007
  -0.17604053 -0.04390738  0.3714757   0.08148885  0.14379543  0.12892176
  -0.16454557  0.26199186  0.20135853  0.17407624  0.68472528 -0.42030412
  -0.24242741 -0.46921769 -0.13693717 -0.14658219 -0.1394875   0.26835471
   0.39282373 -0.54732418  0.14478067 -0.80233788 -0.39490086 -0.18340427
   0.1889984  -0.04469819 -0.14034727 -0.70217574 -0.15430367  0.49109027
  -0.29003158  0.01775131  0.4474425   0.22700024 -0.13653623  0.66176659
   0.2720741   0.43815041 -0.92031908 -0.39670715  0.43910199 -0.27064925
   0.15501913 -0.15491134 -0.36430538  0.21904793 -0.59544891 -0.06664561
  -0.27850425 -0.27807659  0.01406911  0.22974887]]
After layer activation1029_output (1, 256) <class 'numpy.float32'> [[ 0.12531543  0.2158086  -0.33704382 -0.17819351  0.43274236 -0.05477883
   0.39601424 -0.08404803 -0.05184097 -0.09042036  0.23011397  0.26858574
   0.06215387 -0.36664602  0.08181107 -0.02727148  0.19716506  0.32486507
  -0.07440386  0.1554696  -0.15532999 -0.41487291 -0.42094135  0.20106749
  -0.13232893 -0.09015077 -0.4169932  -0.07690927 -0.31758875  0.21059704
   0.18699877 -0.13469329  0.42097095 -0.10963023  0.53840685  0.15393728
   0.17865604 -0.54104769 -0.41556805  0.09357306 -0.09898248  0.34887329
  -0.15174986  0.31367695 -0.53633606 -0.18331207  0.02236491  0.27886689
   0.21290676  0.11178889  0.03791502  0.03692655 -0.11004405 -0.24916582
   0.47310871  0.33568144 -0.41779444 -0.08903683  0.18071996 -0.03809481
   0.30351558 -0.10840925  0.10316958  0.62116396 -0.24512649  0.05053068
   0.19747593  0.4915503   0.1509712  -0.32944733  0.18577649 -0.03108522
  -0.5509212   0.20895478  0.2930564   0.46934447  0.37008142 -0.69809759
   0.25156569 -0.40938753  0.44117752 -0.31757873  0.03897565  0.11911467
  -0.22313464 -0.34162605  0.051336   -0.4882057   0.10616507 -0.00557108
   0.18719156  0.16661742 -0.35907024 -0.16899469 -0.40974557 -0.07558794
  -0.27880961 -0.49389488  0.2595948   0.14836185 -0.21638772 -0.02430137
  -0.05123402  0.31870171 -0.30464706 -0.32216927  0.26372492  0.26392701
   0.23709255  0.24035537 -0.40930417 -0.34442386  0.62989366  0.59998137
  -0.20498972  0.38042706  0.22934557  0.1446756   0.19060871  0.08374531
   0.0187532  -0.37270018  0.40392005 -0.17620923  0.64062768  0.00917055
   0.43693453  0.25186393 -0.38629773 -0.53075075  0.08818774  0.34736091
   0.13411853 -0.09567716  0.40831065  0.4355734   0.08572374  0.22545603
  -0.51110435 -0.10725907 -0.05790488  0.49472451 -0.43481433 -0.09814485
   0.36058408  0.03787022  0.27702245 -0.07226321  0.46717101 -0.12756108
   0.49919108 -0.32380548  0.57552361  0.2697472   0.14103268 -0.45322669
   0.48070705 -0.07300895  0.292669    0.26660892  0.63348502  0.1568507
   0.20125639  0.37861782 -0.17189535  0.16198932 -0.04983243  0.40506363
  -0.26656207 -0.29051474  0.10401221  0.74234188 -0.18045491  0.51281857
  -0.28123602 -0.38796273  0.09402918  0.08824603 -0.1841975  -0.06592871
   0.50184995  0.33366498  0.21604003  0.28227687 -0.03587217 -0.32937244
  -0.17382264  0.41200581  0.18281205 -0.21032286  0.32464436 -0.32209939
  -0.3718245   0.37793431  0.12450914 -0.46950978 -0.01606143 -0.42084378
   0.32753724 -0.01737923  0.11286402 -0.39457655 -0.42449033 -0.24805579
  -0.17424428 -0.04387919  0.3552818   0.08130895  0.14281248  0.12821223
  -0.16307645  0.25615764  0.19868058  0.17233899  0.5945828  -0.39718661
  -0.23778722 -0.43756703 -0.13608761 -0.1455413  -0.13858984  0.26209322
   0.37379199 -0.49851206  0.14377747 -0.66534173 -0.37557751 -0.18137518
   0.18677974 -0.04466845 -0.139433   -0.60574698 -0.1530906   0.45508134
  -0.28216386  0.01774944  0.4197945   0.22317992 -0.13569407  0.57953787
   0.26555374  0.41211015 -0.72604835 -0.37712795  0.41289982 -0.26422885
   0.15378921 -0.15368396 -0.34900066  0.21561044 -0.53380322 -0.06654712
  -0.27152017 -0.27112398  0.01406818  0.22579004]]
After layer encoder_birnn_forward_l0_t3_out_0 (1, 256) <class 'numpy.float32'> [[ 0.07595818  0.12314733 -0.19694285 -0.1077343   0.24454933 -0.03260043
   0.26000148 -0.04776397 -0.03089255 -0.05324644  0.13019362  0.15474927
   0.03506095 -0.21827783  0.04082584 -0.01475007  0.11429154  0.18185663
  -0.04976416  0.09319577 -0.08227408 -0.20965518 -0.26965177  0.12048409
  -0.07686303 -0.04865586 -0.2602565  -0.04557987 -0.16261891  0.11893978
   0.10990825 -0.08235072  0.2233143  -0.06130984  0.30498794  0.08552121
   0.10464878 -0.29147139 -0.19005086  0.05093801 -0.05607896  0.19908826
  -0.0830108   0.1774566  -0.30340719 -0.10671004  0.01480964  0.16213177
   0.12084948  0.05810355  0.0183049   0.02145191 -0.08386906 -0.1259197
   0.27585441  0.16224521 -0.228983   -0.04912641  0.10392359 -0.02187955
   0.15323877 -0.06260772  0.05276775  0.38302949 -0.13420108  0.02885032
   0.12216485  0.27255884  0.0851991  -0.18563399  0.1101906  -0.01812094
  -0.3623521   0.11650974  0.16383371  0.34281978  0.21513547 -0.51420039
   0.15921447 -0.22143176  0.27284795 -0.15612164  0.02942025  0.06705308
  -0.13663352 -0.190928    0.02737384 -0.29372144  0.07410556 -0.00323582
   0.10392641  0.09073485 -0.16797474 -0.10404093 -0.21486142 -0.04745122
  -0.16897425 -0.29749286  0.15861028  0.09510553 -0.11653156 -0.01356461
  -0.0275825   0.19951582 -0.18297789 -0.16507344  0.14706184  0.16316329
   0.14318471  0.1295141  -0.25540659 -0.19674863  0.44057515  0.41091064
  -0.12385803  0.21497184  0.13341849  0.09415403  0.11032213  0.04926588
   0.01053126 -0.24167533  0.23678535 -0.09976306  0.37364134  0.00545036
   0.23248607  0.12678695 -0.21347012 -0.37317568  0.05259834  0.22400585
   0.07323574 -0.05465268  0.22322227  0.23184414  0.05123946  0.1260729
  -0.32364622 -0.06218084 -0.03128653  0.29016423 -0.2506777  -0.05665468
   0.19760163  0.02176439  0.15396316 -0.04032337  0.24330784 -0.07148494
   0.33332381 -0.17744213  0.3339054   0.13414972  0.07727489 -0.2270409
   0.2588245  -0.04095949  0.18413474  0.15818082  0.37013495  0.09144828
   0.10971718  0.22180368 -0.10743465  0.08637511 -0.0286405   0.21685794
  -0.13095273 -0.16009992  0.05588832  0.58658636 -0.10805571  0.3338936
  -0.13947167 -0.21266721  0.05361831  0.05171777 -0.1008058  -0.04041283
   0.28811553  0.16365364  0.12286416  0.16915552 -0.01942621 -0.1952486
  -0.10084886  0.2217007   0.10237508 -0.12670542  0.16086368 -0.18031818
  -0.23941948  0.22047505  0.06521396 -0.2792947  -0.01282815 -0.24635313
   0.19162478 -0.01014138  0.06083456 -0.20474805 -0.25370172 -0.14695209
  -0.10175686 -0.02684128  0.22349256  0.04139249  0.06540103  0.07569555
  -0.09621619  0.13691986  0.11909807  0.10254759  0.42273459 -0.26365203
  -0.13407503 -0.28170288 -0.08130153 -0.08004853 -0.07625771  0.15808502
   0.18914089 -0.27889836  0.08248758 -0.37302071 -0.21364534 -0.10243993
   0.11015972 -0.02371889 -0.07202486 -0.38515839 -0.08781136  0.26696071
  -0.17022592  0.0096138   0.21275719  0.1115736  -0.07520924  0.37684616
   0.14245462  0.25373346 -0.59568453 -0.18490544  0.23872046 -0.14356881
   0.08938514 -0.08844186 -0.21074909  0.13227186 -0.33432603 -0.03618929
  -0.17114864 -0.16353676  0.00797474  0.13299643]]
After layer expand_dims1035_0 (1, 1, 256) <class 'numpy.float32'> [[[ 0.07595818  0.12314733 -0.19694285 -0.1077343   0.24454933 -0.03260043
    0.26000148 -0.04776397 -0.03089255 -0.05324644  0.13019362  0.15474927
    0.03506095 -0.21827783  0.04082584 -0.01475007  0.11429154  0.18185663
   -0.04976416  0.09319577 -0.08227408 -0.20965518 -0.26965177  0.12048409
   -0.07686303 -0.04865586 -0.2602565  -0.04557987 -0.16261891  0.11893978
    0.10990825 -0.08235072  0.2233143  -0.06130984  0.30498794  0.08552121
    0.10464878 -0.29147139 -0.19005086  0.05093801 -0.05607896  0.19908826
   -0.0830108   0.1774566  -0.30340719 -0.10671004  0.01480964  0.16213177
    0.12084948  0.05810355  0.0183049   0.02145191 -0.08386906 -0.1259197
    0.27585441  0.16224521 -0.228983   -0.04912641  0.10392359 -0.02187955
    0.15323877 -0.06260772  0.05276775  0.38302949 -0.13420108  0.02885032
    0.12216485  0.27255884  0.0851991  -0.18563399  0.1101906  -0.01812094
   -0.3623521   0.11650974  0.16383371  0.34281978  0.21513547 -0.51420039
    0.15921447 -0.22143176  0.27284795 -0.15612164  0.02942025  0.06705308
   -0.13663352 -0.190928    0.02737384 -0.29372144  0.07410556 -0.00323582
    0.10392641  0.09073485 -0.16797474 -0.10404093 -0.21486142 -0.04745122
   -0.16897425 -0.29749286  0.15861028  0.09510553 -0.11653156 -0.01356461
   -0.0275825   0.19951582 -0.18297789 -0.16507344  0.14706184  0.16316329
    0.14318471  0.1295141  -0.25540659 -0.19674863  0.44057515  0.41091064
   -0.12385803  0.21497184  0.13341849  0.09415403  0.11032213  0.04926588
    0.01053126 -0.24167533  0.23678535 -0.09976306  0.37364134  0.00545036
    0.23248607  0.12678695 -0.21347012 -0.37317568  0.05259834  0.22400585
    0.07323574 -0.05465268  0.22322227  0.23184414  0.05123946  0.1260729
   -0.32364622 -0.06218084 -0.03128653  0.29016423 -0.2506777  -0.05665468
    0.19760163  0.02176439  0.15396316 -0.04032337  0.24330784 -0.07148494
    0.33332381 -0.17744213  0.3339054   0.13414972  0.07727489 -0.2270409
    0.2588245  -0.04095949  0.18413474  0.15818082  0.37013495  0.09144828
    0.10971718  0.22180368 -0.10743465  0.08637511 -0.0286405   0.21685794
   -0.13095273 -0.16009992  0.05588832  0.58658636 -0.10805571  0.3338936
   -0.13947167 -0.21266721  0.05361831  0.05171777 -0.1008058  -0.04041283
    0.28811553  0.16365364  0.12286416  0.16915552 -0.01942621 -0.1952486
   -0.10084886  0.2217007   0.10237508 -0.12670542  0.16086368 -0.18031818
   -0.23941948  0.22047505  0.06521396 -0.2792947  -0.01282815 -0.24635313
    0.19162478 -0.01014138  0.06083456 -0.20474805 -0.25370172 -0.14695209
   -0.10175686 -0.02684128  0.22349256  0.04139249  0.06540103  0.07569555
   -0.09621619  0.13691986  0.11909807  0.10254759  0.42273459 -0.26365203
   -0.13407503 -0.28170288 -0.08130153 -0.08004853 -0.07625771  0.15808502
    0.18914089 -0.27889836  0.08248758 -0.37302071 -0.21364534 -0.10243993
    0.11015972 -0.02371889 -0.07202486 -0.38515839 -0.08781136  0.26696071
   -0.17022592  0.0096138   0.21275719  0.1115736  -0.07520924  0.37684616
    0.14245462  0.25373346 -0.59568453 -0.18490544  0.23872046 -0.14356881
    0.08938514 -0.08844186 -0.21074909  0.13227186 -0.33432603 -0.03618929
   -0.17114864 -0.16353676  0.00797474  0.13299643]]]
After layer encoder_birnn_forward_l0_t4_i2h_output (1, 1024) <class 'numpy.float32'> [[ 0.07376467 -0.04585483  0.06153381 ...,  0.03591035  0.03396329
   0.02903319]]
After layer encoder_birnn_forward_l0_t4_h2h_output (1, 1024) <class 'numpy.float32'> [[ 0.30962789  0.32780135  0.20324004 ...,  0.69398254  0.38610384
   0.59891701]]
After layer _plus1030_0 (1, 1024) <class 'numpy.float32'> [[ 0.38339257  0.28194651  0.26477385 ...,  0.72989291  0.42006713
   0.62795019]]
After layer encoder_birnn_forward_l0_t4_slice_output0 (1, 256) <class 'numpy.float32'> [[  3.83392572e-01   2.81946510e-01   2.64773846e-01   2.12005645e-01
    5.43327868e-01   4.96792614e-01   8.70877147e-01   8.28156322e-02
   -2.09214568e-01   3.42497855e-01   2.68586546e-01   4.73835588e-01
   -1.24633312e-02   6.35437846e-01  -1.84095323e-01   1.58184990e-01
    2.47525781e-01   3.86462718e-01   5.42619109e-01   2.69431204e-01
    1.30311586e-03  -4.87712085e-01   3.73839438e-01   2.89139599e-01
    1.94501698e-01   1.37664482e-01   6.20396614e-01   5.74745983e-02
    4.89234716e-01   4.20837820e-01   4.25307781e-01   4.56803322e-01
    7.32908607e-01   3.38311076e-01   1.07472551e+00   5.15247360e-02
    2.19627142e-01   1.19196749e+00   7.91433275e-01  -2.94635952e-01
   -1.38324097e-01   3.84977639e-01   6.20397329e-01   1.98286444e-01
    1.00100493e+00   3.75036836e-01   2.68944353e-01   4.66443062e-01
    1.74505457e-01  -9.26032886e-02  -1.90238759e-01  -1.69377387e-01
    1.99648011e+00   2.51485646e-01   8.11550558e-01   1.36285812e-01
    6.54019296e-01  -3.57175991e-02   2.50065565e-01  -5.87493896e-01
    2.77932823e-01   3.18810523e-01  -2.23367661e-03   7.58427382e-01
    7.12477788e-02   1.07187793e-01   5.09282708e-01   9.07897770e-01
    4.64569867e-01   7.34088302e-01  -1.05790049e-01  -5.18658042e-01
    1.12986529e+00   3.77379686e-01   4.06953275e-01   1.13817835e+00
    5.28962374e-01   1.61190188e+00   3.61322790e-01  -1.47539094e-01
    6.32306218e-01   3.74401331e-01   5.28966546e-01  -5.08575290e-02
    7.21166968e-01   5.00284255e-01   2.16200352e-01   9.44972038e-01
    7.91647375e-01  -1.33249670e-01   3.15174878e-01  -1.16228178e-01
   -1.35945380e-01   3.59615743e-01  -2.24438399e-01  -3.73319149e-01
    7.42534757e-01   8.04004610e-01   6.52712047e-01   4.00839418e-01
    1.42870307e-01  -1.78612992e-01   2.94604540e-01   8.32030356e-01
    6.18791342e-01   2.38333285e-01   7.70098567e-02   2.39597589e-01
    3.61877456e-02   2.08925918e-01   8.12514186e-01   6.64136589e-01
    1.41335857e+00   1.70409751e+00   5.30028462e-01   6.12176061e-01
    3.98000032e-01   6.71830237e-01   1.46768436e-01  -4.67819273e-02
   -1.29744738e-01   7.04242468e-01   1.11662710e+00   2.44097888e-01
    1.19034302e+00   1.76851645e-01   2.84560591e-01   2.81626880e-01
    2.43422717e-01   1.28714192e+00  -2.28679895e-01   5.57937443e-01
    2.27791578e-01   1.15903616e-01   6.40307307e-01   4.06663120e-01
    4.64740962e-01  -3.63840818e-01   5.40113389e-01  -6.36110604e-02
    3.54908928e-02   7.55971551e-01   5.19821405e-01   5.27853854e-02
    3.93877536e-01  -3.91935050e-01   3.08599956e-02  -3.09126019e-01
    6.16093814e-01  -6.91550970e-02   1.04587770e+00   5.42721927e-01
    1.02284431e+00   7.69948602e-01   7.83418864e-02   6.59660459e-01
    4.42936420e-01  -2.11232528e-01   7.00280428e-01   5.68590820e-01
    1.24256587e+00  -8.71095136e-02   5.46960354e-01   5.85665464e-01
    4.68783140e-01   6.71885088e-02   1.07339352e-01   3.65667373e-01
   -3.04572470e-02   2.85185099e-01  -2.64303476e-01   2.38007784e+00
    2.70451158e-01   9.08599734e-01   4.62004662e-01   2.02626616e-01
   -9.46719050e-02  -3.17945361e-01  -5.17055914e-02   2.40369812e-01
    8.71149421e-01   3.34288955e-01   3.90216351e-01   2.21875235e-01
   -1.61095113e-01   3.99397373e-01   3.89399007e-02   7.42845416e-01
    4.41478223e-01   4.24800575e-01  -3.01018506e-01   1.62978888e-01
    9.61195230e-01   2.71531582e-01   3.30905706e-01   7.14979410e-01
    2.02375174e+00   8.12293231e-01   4.42177534e-01   1.48061827e-01
    2.29843318e-01   6.25958383e-01   3.74175012e-01   3.17942649e-01
    3.98008496e-01  -8.67040642e-03   5.40180564e-01  -2.14358866e-01
   -1.39286980e-01   3.00215483e-01   4.49658811e-01   2.37671971e-01
    6.23724461e-01   3.01549911e-01   1.29613316e+00   6.16030931e-01
    2.21819550e-01   8.32379282e-01   3.53177339e-01  -2.71713823e-01
    1.48303583e-01   2.45963424e-01   4.34541672e-01   4.71870720e-01
    4.11643982e-01   1.76276159e+00   4.82151121e-01   1.30922198e-02
    7.70568401e-02   6.98690340e-02  -3.57730687e-01   1.61071181e+00
    2.35181749e-01   8.06735098e-01   3.71502727e-01  -1.03658531e-02
    3.37770343e-01  -1.86522365e-01   1.83758706e-01   9.18874145e-01
    1.87137276e-01   5.96620619e-01   2.61736202e+00   3.47136587e-01
    7.23550498e-01   4.79117930e-01   2.58728147e-01   2.11756840e-01
    5.21303773e-01   2.84253955e-01   1.02602005e+00  -3.21988612e-01
    7.00005531e-01   3.92475843e-01  -2.31932297e-01   2.83338159e-01]]
After layer encoder_birnn_forward_l0_t4_slice_output1 (1, 256) <class 'numpy.float32'> [[  7.59190679e-01   3.36166099e-02   1.62143916e-01   3.58218014e-01
    2.51378477e-01   3.17335755e-01   7.77890205e-01   2.70711184e-01
    1.16130233e+00   2.27945715e-01   7.59021640e-01   3.40533316e-01
    5.50519407e-01   5.11486709e-01  -4.86860946e-02   3.46672475e-01
    2.25587770e-01   2.64935046e-01   7.74796426e-01   4.24244672e-01
    1.58926606e-01  -6.67895377e-02   7.86629319e-01   2.12988943e-01
    4.83100712e-01   4.05599117e-01   5.10373235e-01   2.62867630e-01
    6.87461972e-01   1.36890262e-01   6.19481981e-01   5.16390443e-01
    3.72040987e-01   4.69194829e-01   8.72296810e-01   3.61604869e-01
    1.83306217e-01   3.34733129e-01   8.94369960e-01   8.39213878e-02
    5.47451735e-01   3.17155302e-01   7.97454000e-01  -8.00946355e-02
    6.57675415e-02  -1.55434251e-01   8.31804156e-01   3.64826858e-01
    2.34658718e-01  -1.42881423e-01  -1.52689591e-01   2.60636002e-01
    1.74528205e+00  -1.15885720e-01   6.90847337e-01  -1.08224578e-01
    2.34291211e-01   3.25589925e-01   4.06765372e-01   4.97821122e-01
    2.53292620e-02   3.04811120e-01   1.74552530e-01   5.95238030e-01
    1.45939872e-01   2.94116795e-01   5.00128210e-01   6.63411140e-01
    3.28258634e-01   8.95343661e-01  -9.64534879e-02   3.46942663e-01
    9.53659296e-01   3.68877441e-01   1.05767071e-01   1.58183134e+00
    3.31926435e-01   1.45361900e+00   5.70977569e-01  -3.21083874e-01
    6.16435409e-01  -3.06060195e-01   1.49753463e+00   4.78912413e-01
    6.25274003e-01   3.70794892e-01   1.72905112e-03   9.48438108e-01
    1.59567595e+00   3.25724930e-01   1.89930052e-01   3.86782527e-01
    5.63750416e-03   3.74963582e-01  -1.15937926e-01   6.74404725e-02
    7.17510700e-01   6.49302721e-01   7.15242326e-01   6.49612784e-01
    1.23841487e-01  -1.89396083e-01   6.50679618e-02   6.09208345e-01
    5.61619639e-01   1.81358978e-01   4.39242214e-01   4.53106761e-01
    3.45289022e-01   2.68585443e-01   6.19715691e-01   8.34096313e-01
    1.03483295e+00   1.29154670e+00   4.72292662e-01   3.83363903e-01
    7.55993545e-01   7.76270032e-01   3.68393600e-01   3.19837809e-01
    3.95236939e-01   8.86313915e-01   4.36775625e-01   3.20871234e-01
    7.37257361e-01   4.21604007e-01  -2.06653193e-01   3.16342711e-01
    3.03520828e-01   1.19658852e+00   2.80773193e-01   5.15868425e-01
    1.53243124e-01   1.65698141e-01   3.31795871e-01   6.96214676e-01
    4.59731251e-01  -3.10965836e-01   9.30412591e-01   5.37782669e-01
    3.20440173e-01   4.00891274e-01   5.49779177e-01   4.42980170e-01
    4.23535049e-01   7.06857860e-01   2.10881829e-01   3.86342257e-01
    7.02879786e-01   4.50070351e-01   6.45233631e-01   1.74813926e-01
    4.65823352e-01   3.72414708e-01   2.75798202e-01   1.85511500e-01
    7.04380035e-01   1.81535289e-01   8.62497807e-01   4.22484577e-01
    8.30740809e-01   3.63618910e-01   6.65788293e-01   5.90288818e-01
    6.19554222e-01   1.75955400e-01   1.92809731e-01   2.73584515e-01
   -8.41885805e-02   1.78279161e-01  -1.34555459e-01   1.32892907e+00
    3.70517135e-01   9.42906797e-01   3.44068445e-02   1.49767280e-01
    2.31643096e-01   5.59203625e-01  -1.32841170e-01   6.92846775e-01
    2.53136039e-01  -8.80134180e-02   6.64452314e-01   4.58634943e-01
    2.76364923e-01   4.30835903e-01   6.75820351e-01   5.44484079e-01
    3.99643421e-01   5.66301465e-01  -2.68161148e-01   3.92339736e-01
    7.02066481e-01   4.75884557e-01  -1.30059049e-02   2.80045569e-01
    2.66016936e+00  -1.38480455e-01   4.26035643e-01  -4.05149832e-02
    3.91850382e-01   4.36053425e-01   2.99020052e-01   8.87438655e-01
    4.39760804e-01   2.34400064e-01   6.94531441e-01  -3.11762512e-01
    4.97431420e-02   5.22485137e-01   5.90971231e-01   3.41185033e-01
    5.29655218e-01   4.25296575e-01   1.21656823e+00   7.92641759e-01
    1.48574442e-01   6.24763608e-01   1.00685850e-01   7.81595111e-02
    1.10950917e-01   5.69579363e-01  -9.58653912e-02   5.28812408e-01
    2.90015608e-01   9.56793368e-01  -1.94424868e-01   2.38041013e-01
    4.86816525e-01   2.53546357e-01   2.87257910e-01   1.13799787e+00
    2.52793014e-01   4.97499466e-01   6.54499173e-01   4.84541625e-01
    6.74012974e-02   1.52247295e-01   1.76330447e-01   1.01117206e+00
    1.65555716e-01   6.90348566e-01   2.46699405e+00  -6.70705885e-02
    2.49353886e-01  -7.66685531e-02   2.17577368e-01   3.06137770e-01
    4.74174678e-01   5.80338478e-01   1.00592113e+00  -8.26081038e-02
    8.02869201e-01   3.95770341e-01   2.68165797e-01   4.81495649e-01]]
After layer encoder_birnn_forward_l0_t4_slice_output2 (1, 256) <class 'numpy.float32'> [[ 0.21018988  0.4360216  -0.76442862 -0.31195667  1.05003989 -0.13135277
   0.90420687 -0.01563217 -0.28664982 -0.0840991   0.57835978  0.63662994
   0.16073963 -0.80115741  0.11823346  0.01107053  0.45528692  0.7639237
  -0.06908974  0.34570146 -0.23746984 -1.48597419 -1.19126415  0.46796322
  -0.19690818 -0.12293655 -0.94356376 -0.055641   -0.78286022  0.53775823
   0.41993445 -0.25314069  0.81510848 -0.31066337  1.42628849  0.37502816
   0.41145548 -1.43717861 -1.00248194  0.06671118 -0.0765112   1.05009949
  -0.15054908  0.86111635 -1.68883693 -0.44531882 -0.05892331  0.51253998
   0.48628789  0.32053056 -0.01734006 -0.00632258 -0.50113231 -0.53683567
   1.13377249  0.75705296 -1.21337628 -0.15958607  0.55779326 -0.00214399
   0.82311112 -0.1546402   0.16154359  2.06918931 -0.63209021  0.09783825
   0.52821052  1.10399973  0.34431234 -0.84046656  0.50532055  0.0829675
  -1.37723577  0.36553901  0.6510691   1.12687385  0.91132057 -1.89097464
   0.58340287 -1.22077584  1.21166801 -0.69750863 -0.12108287  0.14709732
  -0.39294177 -0.89883208  0.15667218 -1.18297434  0.15043537 -0.09895612
   0.53536075  0.35146675 -1.06563306 -0.36309987 -1.5114255  -0.42897046
  -0.60639662 -1.320122    0.56911606  0.19154799 -0.60943407 -0.07818232
  -0.01311447  0.63490444 -0.55049598 -0.8750428   0.52266532  0.44629198
   0.46205583  0.5053156  -0.99962169 -0.86618781  1.70352888  1.49274147
  -0.24789736  0.93627566  0.46225095  0.15866397  0.39471343  0.12827118
   0.0880274  -0.75926274  0.91325969 -0.38677058  1.75479722 -0.11466037
   1.31091833  0.56161493 -1.05735588 -1.34459841  0.23183946  0.71692204
   0.31594622 -0.19875082  0.96321028  1.14353156  0.31145149  0.70990968
  -1.31477869 -0.34271097 -0.01224137  1.31610394 -1.13120699 -0.1294914
   0.98165858 -0.014009    0.70966291 -0.03624884  1.31818807 -0.18850699
   1.34136331 -0.66755903  1.57873833  0.69969773  0.27163357 -1.24426568
   1.3627671  -0.08005269  0.71115524  0.72947305  1.92473865  0.14173567
   0.30205035  0.91325778 -0.20152014  0.25033712 -0.0336909   1.06417787
  -0.60780197 -0.59830552  0.21908271  2.0840776  -0.3521854   1.45745695
  -0.68496591 -1.20374024  0.13711415  0.13984311 -0.46619421 -0.15468936
   1.28215313  0.90516281  0.45162958  0.59845489 -0.01584929 -0.74737012
  -0.40456468  1.06245422  0.44693321 -0.48372906  1.14830899 -0.7473228
  -0.82454222  1.04849279  0.26417857 -1.23634481 -0.19675481 -1.05099118
   0.76154482 -0.15410908  0.0516867  -0.85080832 -1.31032515 -0.55608827
  -0.22485578 -0.20915902  0.99304807  0.11313394  0.32827273  0.10861714
  -0.2974577   0.52723265  0.4521634   0.36513466  1.58451331 -0.99309379
  -0.56290764 -1.08266592 -0.33780804 -0.42722666 -0.31249148  0.54332006
   0.94169253 -1.40101671  0.28291154 -1.7358954  -0.95377839 -0.33036703
   0.35226417 -0.02205667 -0.34320626 -1.39843023 -0.29001087  1.15519726
  -0.59642613 -0.02004756  1.06464708  0.52150708 -0.15504888  1.85837889
   0.76750541  0.93693501 -1.93874645 -1.12160468  1.04361749 -0.61751568
   0.37019059 -0.26434606 -0.80636984  0.53305668 -1.19293821 -0.16366762
  -0.51354772 -0.5391171  -0.06873446  0.35912028]]
After layer encoder_birnn_forward_l0_t4_slice_output3 (1, 256) <class 'numpy.float32'> [[  7.19868064e-01   4.53827679e-01   5.38397968e-01   6.67648494e-01
    4.63074267e-01   6.45001709e-01   1.20950484e+00   4.11588818e-01
    6.04767323e-01   5.70807934e-01   4.75557208e-01   5.65959752e-01
    4.16808754e-01   7.90330887e-01  -4.01933193e-02   2.20878780e-01
    5.84505141e-01   3.24258447e-01   1.15743315e+00   6.92176044e-01
    2.82212496e-01   9.00299661e-03   1.02647269e+00   6.91990852e-01
    4.87565011e-01   2.45845050e-01   8.79601479e-01   6.11680090e-01
    1.03397757e-01   4.61353242e-01   6.54408574e-01   7.31973708e-01
    1.14131972e-01   4.27232653e-01   4.31873858e-01   2.93590605e-01
    5.86089790e-01   2.14233220e-01  -3.55943739e-01   3.24343860e-01
    4.32323813e-01   4.70262945e-01   3.83369923e-01   4.67797756e-01
    4.66367424e-01   5.49776077e-01   1.22806299e+00   5.89474440e-01
    4.60858941e-01   1.32664323e-01  -1.92663833e-01   5.71066260e-01
    2.04749227e+00  -3.54917049e-02   5.61609328e-01  -8.31722021e-02
    2.82119244e-01   4.03940409e-01   5.62913775e-01   4.58541632e-01
    9.77970660e-04   4.55313742e-01   7.16499686e-02   8.01687598e-01
    2.82616794e-01   4.88005042e-01   7.84315109e-01   3.47972155e-01
    4.53567207e-01   3.98049980e-01   6.44795001e-01   5.60744286e-01
    1.14233077e+00   4.60932165e-01   3.88374984e-01   1.77010214e+00
    5.34440041e-01   1.77222466e+00   8.91796708e-01   2.03235492e-01
    9.09801424e-01  -1.08639002e-01   2.06210899e+00   4.58822459e-01
    8.03735256e-01   3.85337412e-01   2.69906849e-01   6.53099716e-01
    1.41082466e+00   6.16070509e-01   3.92908931e-01   3.98564249e-01
   -2.63113111e-01   8.39075685e-01   1.54578745e-01   8.12795162e-01
    6.76138163e-01   7.17845142e-01   7.21013606e-01   9.88284588e-01
    2.26628065e-01   3.95557106e-01   1.94515795e-01   9.11636353e-01
    7.11090147e-01   1.58038318e-01   4.42849636e-01   7.55672514e-01
    7.21009612e-01   2.07699671e-01   8.99799645e-01   5.09755909e-01
    1.40966249e+00   1.29354739e+00   6.99721694e-01   5.12618303e-01
    5.60377777e-01   1.08579063e+00   5.35443068e-01   6.34021342e-01
    4.57375854e-01   1.08013105e+00   5.78149319e-01   4.81294692e-01
    6.42289519e-01   7.01125622e-01   1.29995987e-01   4.42122892e-02
    3.70533794e-01   1.53063118e+00   6.32326961e-01   1.00684774e+00
    3.44171882e-01   4.96782184e-01   3.11327100e-01   2.40749061e-01
    6.98717237e-01   4.25498188e-01   9.02330339e-01   5.26773512e-01
    2.69228846e-01   5.44720232e-01   5.16038060e-01   5.58706641e-01
    3.18328649e-01   5.75451076e-01   3.87813300e-01   3.86434019e-01
    9.15136188e-02   3.19593072e-01   1.19437599e+00   2.81455308e-01
    5.92910588e-01   3.63193825e-03   2.73470879e-01  -4.27161343e-02
    2.83235699e-01   4.02957737e-01   1.00506425e+00   5.96058369e-01
    5.47486663e-01   5.94184637e-01   2.34869093e-01   6.31400168e-01
    9.08316731e-01   2.36926630e-01   5.33204079e-01   2.38347694e-01
   -9.73793790e-02   2.98634708e-01   3.28774214e-01   2.30440760e+00
    6.69926286e-01   1.01075578e+00  -2.25661211e-02   2.38485128e-01
    4.65505838e-01   5.94083488e-01   3.16866547e-01   7.65534580e-01
    4.81893718e-01  -8.81777629e-02   5.60877800e-01   6.56457782e-01
    3.06613177e-01   6.34881437e-01   5.29928207e-01   2.65810251e-01
    5.29440165e-01   7.87946820e-01  -3.65114585e-02   4.60141391e-01
    1.04665279e+00   5.49528062e-01   1.40800849e-01   6.55135274e-01
    2.38894439e+00   4.88189310e-01   5.64203978e-01   5.80338836e-01
    2.68587619e-01   1.13020457e-01   6.51247442e-01   7.86741078e-01
    6.21765852e-01   7.63759017e-01   8.77261758e-01   9.08718109e-02
   -2.89051950e-01   5.57457566e-01   6.29094124e-01   2.73460388e-01
    7.86705673e-01   6.94434583e-01   1.57925379e+00   1.07439780e+00
    3.85398328e-01   1.00218320e+00   6.97670519e-01   3.64255518e-01
    3.87571067e-01   6.90487623e-01   2.87072025e-02   3.21830153e-01
    5.90213120e-01   3.87125552e-01   5.32703578e-01   4.72169429e-01
    6.02324903e-01   2.27654278e-01   1.68932930e-01   9.58482742e-01
    5.72640598e-01   6.13028646e-01   7.25944996e-01   3.06491941e-01
    5.72176017e-02  -6.99327886e-02   4.29795206e-01   1.16395414e+00
    1.41806930e-01   8.13948691e-01   2.80489922e+00   3.28582674e-02
    4.93185103e-01   2.14407206e-01   5.39286494e-01   5.51264107e-01
    8.06047738e-01   7.84164488e-01   9.38164353e-01   2.72570223e-01
    9.29478526e-01   7.29892910e-01   4.20067132e-01   6.27950191e-01]]
After layer encoder_birnn_forward_l0_t4_o_output (1, 256) <class 'numpy.float32'> [[ 0.67257798  0.6115489   0.63143969  0.66097647  0.61374325  0.65588319
   0.77021134  0.6014688   0.64674628  0.63894957  0.61669821  0.63783044
   0.60271937  0.68790233  0.48995301  0.55499631  0.64210337  0.58036172
   0.76086605  0.66645086  0.57008857  0.50225073  0.73623145  0.66640967
   0.61953264  0.56115353  0.70673966  0.64832395  0.52582645  0.61333513
   0.65800321  0.67523825  0.52850211  0.60521263  0.60632104  0.57287496
   0.6424675   0.55335438  0.41194183  0.58038253  0.60642844  0.61544603
   0.59468561  0.61486238  0.61452359  0.63408363  0.77347934  0.64324456
   0.61321795  0.53311753  0.4519825   0.63900918  0.88569397  0.49112803
   0.63682479  0.4792189   0.57006568  0.59963405  0.63712651  0.61266816
   0.5002445   0.61190188  0.51790482  0.69033533  0.57018763  0.61963636
   0.68660939  0.58612573  0.61148703  0.59821904  0.65583658  0.63662475
   0.75810736  0.61323529  0.59589148  0.85447037  0.63051808  0.85473418
   0.70926082  0.55063468  0.71295953  0.47286692  0.88716543  0.61273479
   0.69077289  0.59515977  0.56707001  0.65770864  0.80389601  0.6493243
   0.59698272  0.59834266  0.43459859  0.6982705   0.5385679   0.6927048
   0.66287625  0.67213231  0.67283016  0.72874898  0.55641574  0.59761977
   0.54847622  0.71333492  0.67064202  0.53942758  0.6089378   0.68041348
   0.67282927  0.55173904  0.71090829  0.62474924  0.80371267  0.784747
   0.66812605  0.62542009  0.63653994  0.74758828  0.63075173  0.65340072
   0.61239147  0.74651879  0.64064145  0.61805356  0.65527081  0.6684373
   0.5324533   0.51105124  0.5915879   0.82209861  0.65301687  0.7324028
   0.58520359  0.62170285  0.57720912  0.5598982   0.6679033   0.60479814
   0.71142817  0.6287303   0.56690359  0.63290977  0.62622088  0.63615322
   0.57891691  0.64002001  0.59575617  0.595424    0.52286243  0.57922512
   0.76752275  0.56990296  0.64403266  0.50090802  0.56794482  0.4893226
   0.57033932  0.59939808  0.7320531   0.64475399  0.63355225  0.64432472
   0.55844885  0.65280694  0.7126556   0.55895615  0.63023013  0.55930644
   0.47567439  0.57410872  0.58146113  0.90924144  0.66148669  0.73316801
   0.49435872  0.5593403   0.6143195   0.64430159  0.57856041  0.68255413
   0.61819494  0.47796986  0.63665563  0.65846425  0.57605839  0.65359551
   0.62946635  0.566064    0.62935251  0.68739027  0.49087316  0.61304772
   0.74013162  0.63402611  0.53514218  0.65816677  0.9159804   0.61967981
   0.63742471  0.64114541  0.56674612  0.52822506  0.65729153  0.68713111
   0.65062004  0.68216932  0.70625448  0.52270234  0.42823595  0.63586408
   0.65228409  0.56794226  0.68712354  0.66695267  0.82909882  0.74543232
   0.59517449  0.73148763  0.66767114  0.59007019  0.59569788  0.66607541
   0.50717634  0.57977021  0.64341408  0.59559053  0.63011348  0.61589712
   0.64618808  0.556669    0.54213309  0.7228179   0.63937229  0.64863133
   0.67391479  0.57602876  0.51430053  0.48252392  0.60582477  0.76205045
   0.53539246  0.69295031  0.94294     0.50821382  0.62085646  0.55339742
   0.63164639  0.6344288   0.69126666  0.68657696  0.71872872  0.56772375
   0.71696949  0.6747818   0.60349929  0.65202457]]
After layer encoder_birnn_forward_l0_t4_f_output (1, 256) <class 'numpy.float32'> [[ 0.68117797  0.50840336  0.54044741  0.58860898  0.56251574  0.57867485
   0.68522525  0.56726748  0.76156926  0.556741    0.68114132  0.58432007
   0.63425612  0.62515497  0.48783088  0.58581042  0.55615902  0.56584907
   0.68455756  0.60449851  0.53964829  0.48330885  0.68710715  0.55304682
   0.61847979  0.60003215  0.62489396  0.56534111  0.66540205  0.5341692
   0.65010071  0.62630332  0.59195203  0.61519319  0.70522338  0.5894289
   0.5456987   0.5829106   0.70979118  0.52096808  0.63354421  0.57863086
   0.68942964  0.479987    0.51643598  0.46121946  0.69673628  0.59020835
   0.558397    0.46434027  0.46190161  0.56479263  0.85135674  0.47106093
   0.66615534  0.47297025  0.55830628  0.58068597  0.60031205  0.62194717
   0.50633198  0.57561821  0.54352766  0.64456606  0.53642035  0.57300371
   0.62248945  0.66002625  0.5813356   0.70999169  0.47590533  0.58587605
   0.72185051  0.59118766  0.52641714  0.82946372  0.58222806  0.81055474
   0.63898873  0.42041165  0.64940739  0.42407668  0.81720644  0.61749101
   0.65141708  0.59165102  0.50043225  0.72080094  0.83141315  0.58071887
   0.54734027  0.59550792  0.50140935  0.5926578   0.47104794  0.51685375
   0.67205864  0.65685332  0.6715585   0.65692317  0.53092086  0.45279202
   0.51626128  0.64776021  0.63682723  0.5452159   0.60807848  0.61137766
   0.58547473  0.56674558  0.65015388  0.69722039  0.7378518   0.78440887
   0.61592627  0.59468418  0.68048322  0.68487567  0.59107077  0.57928473
   0.59754276  0.70812893  0.60749048  0.57953656  0.67639583  0.60386705
   0.44851977  0.57843268  0.57530302  0.76791739  0.56973577  0.62618113
   0.53823596  0.54133004  0.5821963   0.66734797  0.61295044  0.42287901
   0.71715897  0.63129646  0.57943153  0.59890181  0.6340844   0.60896891
   0.60432887  0.66970646  0.55252594  0.59540188  0.66882598  0.61065596
   0.65593559  0.54359251  0.61439472  0.59204233  0.56851578  0.54624534
   0.66915816  0.54525965  0.70318228  0.6040777   0.69651151  0.58991623
   0.66055942  0.64343137  0.65011716  0.54387569  0.54805368  0.56797272
   0.47896531  0.54445213  0.46641177  0.79066348  0.59158391  0.71968645
   0.50860083  0.53737199  0.55765319  0.63626826  0.46683851  0.66659993
   0.56294823  0.4780108   0.66025984  0.61269033  0.56865478  0.60607326
   0.6628052   0.63285488  0.598602    0.63790929  0.43335858  0.59684581
   0.6686458   0.61677557  0.49674857  0.56955743  0.93463498  0.46543512
   0.60492659  0.4898726   0.59672809  0.60731822  0.57420295  0.70836133
   0.60820204  0.55833322  0.66697419  0.42268455  0.51243323  0.62772864
   0.64358795  0.58447832  0.6294027   0.60474998  0.77145904  0.6883983
   0.53707546  0.65130115  0.52515024  0.51952994  0.52770931  0.63866609
   0.47605202  0.62920606  0.57199997  0.72247934  0.45154631  0.55923086
   0.61935622  0.5630492   0.57132471  0.75731188  0.56286383  0.62187153
   0.65802366  0.61881977  0.51684397  0.53798848  0.54396874  0.73324943
   0.54129469  0.66604447  0.92179537  0.4832387   0.56201744  0.48084223
   0.5541808   0.57594222  0.61637139  0.64114529  0.73222113  0.47935966
   0.69058794  0.59767103  0.56664252  0.61810094]]
After layer _mul2060_0 (1, 256) <class 'numpy.float32'> [[ 0.0858132   0.11147036 -0.18956396 -0.10601809  0.26059443 -0.03173089
   0.28704971 -0.04779046 -0.03951591 -0.05047859  0.1595981   0.16088609
   0.03947235 -0.24039878  0.03999936 -0.01597988  0.11111013  0.19073454
  -0.05102802  0.09474951 -0.08450764 -0.2133726  -0.3083981   0.1127357
  -0.08232556 -0.05424063 -0.27748215 -0.043566   -0.21889272  0.11420324
   0.12301554 -0.08487464  0.26571038 -0.06771593  0.42448059  0.09146215
   0.09854995 -0.35303146 -0.31395692  0.0488916  -0.06291579  0.2107144
  -0.1054352   0.15581264 -0.30934402 -0.08551368  0.01558504  0.16906695
   0.12073334  0.05212595  0.01752141  0.02086533 -0.09406769 -0.11989594
   0.34244916  0.16516952 -0.24845581 -0.05183972  0.10969312 -0.02370443
   0.15867805 -0.06264853  0.05627576  0.46853387 -0.13422368  0.02897895
   0.12456305  0.35516179  0.08844099 -0.24296497  0.08945073 -0.01821796
  -0.44733292  0.12537798  0.15892878  0.42238724  0.22620575 -0.69997883
   0.16427352 -0.18282659  0.30761904 -0.13950086  0.0318673   0.07390309
  -0.14784078 -0.2105877   0.0257128  -0.38469279  0.08860092 -0.00323527
   0.10368001  0.10015577 -0.18843873 -0.10112616 -0.20504972 -0.03914257
  -0.19247147 -0.35548821  0.17841555  0.09818702 -0.11672999 -0.01100563
  -0.02647332  0.21389133 -0.20036758 -0.18213795  0.1642466   0.16527052
   0.14150411  0.13893838 -0.28267068 -0.25037408  0.54692513  0.543688
  -0.12807302  0.23820603  0.15889189  0.09978492  0.11405818  0.04862627
   0.01120715 -0.27727157  0.260203   -0.10319675  0.51354516  0.00553795
   0.21010268  0.14888974 -0.23440205 -0.45398483  0.05037457  0.2269527
   0.07262497 -0.05195183  0.25242993  0.31148773  0.05267368  0.09700715
  -0.40463793 -0.06797374 -0.03358949  0.32478249 -0.29536805 -0.05996018
   0.22816865  0.02537407  0.15716828 -0.04310078  0.33872384 -0.0783226
   0.35960236 -0.18258867  0.4028852   0.16375369  0.08071733 -0.26697943
   0.35057425 -0.03987979  0.21199737  0.16503988  0.52044439  0.09329897
   0.13478161  0.25637212 -0.11287273  0.08888503 -0.02733349  0.24405316
  -0.13083382 -0.16286108  0.04868861  0.7556181  -0.10793617  0.40773588
  -0.14699772 -0.21999985  0.05259103  0.05629458 -0.08698329 -0.04401191
   0.3106212   0.16584429  0.14492606  0.17777477 -0.02040764 -0.20735231
  -0.11639238  0.27720606  0.11067577 -0.13619944  0.14596814 -0.1993392
  -0.261132    0.24525928  0.06217235 -0.2901561  -0.01501287 -0.20884863
   0.20571561 -0.00851447  0.0676373  -0.2533786  -0.2602039  -0.17945631
  -0.10706821 -0.02451495  0.24776471  0.03444408  0.07368556  0.08092789
  -0.10589954  0.15312856  0.1267356   0.10527261  0.52823752 -0.28933665
  -0.13020182 -0.30560201 -0.07191259 -0.07615384 -0.07360885  0.17138906
   0.18700452 -0.34437969  0.08281454 -0.57967257 -0.17831603 -0.10256533
   0.11705733 -0.02516728 -0.08018386 -0.53176606 -0.08685195  0.30539507
  -0.19084764  0.01098486  0.23125796  0.12212351 -0.07427144  0.48523998
   0.14727227  0.29182765 -0.84834588 -0.19170424  0.24678297 -0.13013959
   0.08590863 -0.08921998 -0.22454742  0.14044155 -0.43600026 -0.03194722
  -0.19233167 -0.16619833  0.00797215  0.14200799]]
After layer encoder_birnn_forward_l0_t4_i_output (1, 256) <class 'numpy.float32'> [[ 0.5946911   0.57002342  0.56580943  0.55280375  0.63258618  0.62170529
   0.70492816  0.52069211  0.44788632  0.5847972   0.56674594  0.61629117
   0.49688423  0.65372145  0.45410573  0.539464    0.56156743  0.59543091
   0.63242149  0.5669533   0.5003258   0.3804327   0.59238642  0.57178551
   0.5484727   0.53436184  0.65030873  0.51436466  0.61992615  0.60368371
   0.60475266  0.61225557  0.67544323  0.58378023  0.74549454  0.5128783
   0.55468714  0.76709276  0.68813902  0.42686927  0.46547398  0.5950731
   0.65030891  0.54940981  0.73125613  0.59267551  0.56683373  0.61454153
   0.54351598  0.47686574  0.45258319  0.45775661  0.880427    0.56254214
   0.69243985  0.53401881  0.65791565  0.49107155  0.56219262  0.35721007
   0.5690394   0.57903433  0.49944153  0.68101221  0.51780444  0.52677131
   0.62463832  0.71256977  0.61409771  0.6757018   0.47357711  0.37316608
   0.75581408  0.59324098  0.60035712  0.75734502  0.62924111  0.83367527
   0.58936065  0.46318197  0.65301222  0.59252208  0.629242    0.48728833
   0.6728639   0.62252611  0.55384052  0.72010285  0.68818498  0.46673679
   0.57814789  0.47097561  0.46606588  0.58894742  0.4441247   0.40773922
   0.67754984  0.69083047  0.65762132  0.59888935  0.53565693  0.45546508
   0.57312304  0.69678408  0.64994365  0.55930287  0.51924294  0.55961448
   0.50904596  0.55204231  0.69264495  0.66018903  0.80429518  0.84606916
   0.62948972  0.64843702  0.59820706  0.66191286  0.5366264   0.48830664
   0.4676092   0.6691277   0.7533626   0.56072325  0.76680237  0.54409802
   0.57066399  0.56994504  0.56055695  0.78366303  0.44307786  0.63597518
   0.55670291  0.52894348  0.65482295  0.6002875   0.61413825  0.41003013
   0.6318388   0.48410264  0.50887179  0.68047845  0.62710601  0.51319325
   0.59721583  0.40325156  0.50771439  0.42332807  0.64932966  0.48271814
   0.73998255  0.63244539  0.73552626  0.68350977  0.51957548  0.6591841
   0.60895848  0.44738737  0.66824996  0.63843793  0.77601033  0.47823635
   0.63343006  0.64236999  0.61509567  0.51679087  0.5268091   0.59041166
   0.49238628  0.57081699  0.43430611  0.91529548  0.56720364  0.71271354
   0.61348963  0.55048406  0.47634971  0.42117655  0.48707646  0.5598048
   0.70498484  0.58280253  0.59633476  0.55524236  0.45981312  0.59854287
   0.50973374  0.67761779  0.60861123  0.60463142  0.4253085   0.54065478
   0.72336102  0.56746888  0.58197975  0.6715005   0.88326836  0.69259799
   0.60877776  0.53694797  0.55720919  0.65157247  0.59246743  0.57882279
   0.59820908  0.49783245  0.63185441  0.44661459  0.4652344   0.5744952
   0.61055809  0.55913991  0.65106517  0.57482135  0.78518349  0.6493153
   0.55522859  0.69685775  0.58738786  0.43248639  0.53700811  0.56118274
   0.60695761  0.61582643  0.60148203  0.8535552   0.61825567  0.50327301
   0.51925468  0.51746017  0.41150901  0.83351016  0.55852592  0.69141334
   0.59182203  0.49740854  0.5836488   0.45350417  0.54581088  0.71481264
   0.54664826  0.6448828   0.93197066  0.58592302  0.67338842  0.61753958
   0.5643236   0.5527423   0.62745255  0.57058889  0.73614359  0.4201912
   0.66818905  0.59687859  0.44227546  0.57036448]]
After layer encoder_birnn_forward_l0_t4_c_output (1, 256) <class 'numpy.float32'> [[ 0.20714824  0.41034135 -0.64367807 -0.30221608  0.78182185 -0.13060251
   0.7183401  -0.01563089 -0.27904838 -0.08390139  0.52147233  0.56260049
   0.15936944 -0.66468334  0.11768559  0.01107007  0.42623517  0.64338231
  -0.06898002  0.33255786 -0.23310448 -0.90258127 -0.83097053  0.43655217
  -0.19440214 -0.12232094 -0.73685533 -0.05558365 -0.65434527  0.49128914
   0.39687523 -0.24786867  0.67239869 -0.30104047  0.89090347  0.35838193
   0.38970783 -0.89312834 -0.76263452  0.06661239 -0.07636226  0.78184503
  -0.1494219   0.69683242 -0.93399894 -0.41804349 -0.05885521  0.47192186
   0.45126522  0.30998656 -0.01733832 -0.0063225  -0.46300718 -0.49058893
   0.81230646  0.63933778 -0.8376894  -0.15824497  0.5063383  -0.00214399
   0.6767596  -0.15341921  0.16015288  0.96860337 -0.55948973  0.09752727
   0.48401201  0.80193114  0.33132181 -0.68605614  0.46629119  0.08277766
  -0.8803308   0.35008359  0.57238925  0.80994666  0.72176552 -0.9554581
   0.52513433 -0.83988285  0.83717912 -0.60278404 -0.12049459  0.14604548
  -0.37389353 -0.7157287   0.15540275 -0.8283872   0.14931074 -0.09863438
   0.48946819  0.33767569 -0.78781033 -0.34794155 -0.90719169 -0.40446055
  -0.54158556 -0.86681426  0.51470983  0.1892392  -0.54372859 -0.07802342
  -0.01311372  0.56142008 -0.50089192 -0.70392716  0.47975448  0.41884625
   0.43175831  0.46628731 -0.76143521 -0.69943208  0.93584877  0.90382791
  -0.24294113  0.73350644  0.43191704  0.15734583  0.37541652  0.12757228
   0.08780073 -0.64064252  0.72269309 -0.36857283  0.94191909 -0.11416052
   0.86450756  0.5091747  -0.78464973 -0.87277234  0.22777312  0.61499912
   0.30583689 -0.19617452  0.74570537  0.81559986  0.30175698  0.61062014
  -0.86547959 -0.32989547 -0.01224076  0.86581177 -0.81143194 -0.12877245
   0.75378299 -0.01400808  0.61046541 -0.03623297  0.86633265 -0.18630542
   0.87199932 -0.58337194  0.91840464  0.60417593  0.2651442  -0.84666783
   0.87703329 -0.07988212  0.61140072  0.62274289  0.95830595  0.14079413
   0.29318783  0.72269225 -0.19883581  0.24523553 -0.03367816  0.78725761
  -0.54257798 -0.53584278  0.2156436   0.96951044 -0.33831224  0.89715755
  -0.59473825 -0.8347919   0.13626131  0.13893859 -0.43511921 -0.15346721
   0.85705751  0.71880245  0.42323762  0.53594917 -0.01584797 -0.63357735
  -0.38384789  0.78660136  0.41937485 -0.44922513  0.81719309 -0.63354903
  -0.67753458  0.78121972  0.25819972 -0.84440988 -0.19425458 -0.7821914
   0.64198601 -0.15290055  0.05164072 -0.69149148 -0.86435765 -0.50506932
  -0.22114131 -0.20616141  0.75865906  0.11265372  0.31696787  0.108192
  -0.28898433  0.48326287  0.42367572  0.34972873  0.91930383 -0.75867844
  -0.5101316  -0.79418564 -0.32551908 -0.40300101 -0.30270198  0.49549702
   0.73599887 -0.88557124  0.27559763 -0.93974876 -0.74148881 -0.31885052
   0.33838198 -0.02205309 -0.33033678 -0.88501185 -0.28214481  0.8194685
  -0.53450161 -0.02004488  0.78743595  0.47886232 -0.15381825  0.95252883
   0.64547658  0.73381084 -0.95943451 -0.80812633  0.77931261 -0.54939592
   0.3541584  -0.25835603 -0.66758287  0.48771414 -0.83148789 -0.16222173
  -0.47270477 -0.49231935 -0.06862642  0.34443891]]
After layer _mul2061_0 (1, 256) <class 'numpy.float32'> [[  1.23189211e-01   2.33904183e-01  -3.64199132e-01  -1.67066187e-01
    4.94569689e-01  -8.11962709e-02   5.06378174e-01  -8.13888293e-03
   -1.24981955e-01  -4.90652993e-02   2.95542330e-01   3.46725702e-01
    7.91881606e-02  -4.34517771e-01   5.34417033e-02   5.97190671e-03
    2.39359781e-01   3.83089721e-01  -4.36244495e-02   1.88544780e-01
   -1.16628185e-01  -3.43371421e-01  -4.92255658e-01   2.49614209e-01
   -1.06624268e-01  -6.53636456e-02  -4.79183465e-01  -2.85902657e-02
   -4.05645758e-01   2.96583235e-01   2.40011349e-01  -1.51758969e-01
    4.54167128e-01  -1.75741479e-01   6.64163649e-01   1.83806315e-01
    2.16165930e-01  -6.85112298e-01  -5.24798572e-01   2.84347832e-02
   -3.55446450e-02   4.65254962e-01  -9.71703902e-02   3.82846564e-01
   -6.82992458e-01  -2.47764140e-01  -3.33611183e-02   2.90015578e-01
    2.45269850e-01   1.47821978e-01  -7.84703344e-03  -2.89416476e-03
   -4.07644033e-01  -2.75976956e-01   5.62473357e-01   3.41418415e-01
   -5.51128983e-01  -7.77096003e-02   2.84659654e-01  -7.65853736e-04
    3.85102868e-01  -8.88349935e-02   7.99870044e-02   6.59630716e-01
   -2.89706260e-01   5.13745658e-02   3.02332461e-01   5.71431875e-01
    2.03463957e-01  -4.63569373e-01   2.20824838e-01   3.08898147e-02
   -6.65366411e-01   2.07683936e-01   3.43637943e-01   6.13409042e-01
    4.54164535e-01  -7.96541810e-01   3.09493512e-01  -3.89018595e-01
    5.46688199e-01  -3.57162863e-01  -7.58202597e-02   7.11662546e-02
   -2.51579463e-01  -4.45559800e-01   8.60683396e-02  -5.96524000e-01
    1.02753408e-01  -4.60362919e-02   2.82985002e-01   1.59037009e-01
   -3.67171526e-01  -2.04919279e-01  -4.02906239e-01  -1.64914429e-01
   -3.66951197e-01  -5.98821700e-01   3.38484168e-01   1.13333344e-01
   -2.91251987e-01  -3.55369411e-02  -7.51577690e-03   3.91188562e-01
   -3.25551540e-01  -3.93708467e-01   2.49109119e-01   2.34392419e-01
    2.19784826e-01   2.57410318e-01  -5.27404249e-01  -4.61757392e-01
    7.52698660e-01   7.64700890e-01  -1.52928948e-01   4.75632727e-01
    2.58375823e-01   1.04149230e-01   2.01458409e-01   6.22943938e-02
    4.10564318e-02  -4.28671658e-01   5.44449925e-01  -2.06667349e-01
    7.22265780e-01  -6.21145144e-02   4.93343323e-01   2.90201604e-01
   -4.39840853e-01  -6.83959424e-01   1.00921229e-01   3.91124189e-01
    1.70260280e-01  -1.03765234e-01   4.88304973e-01   4.89594400e-01
    1.85320497e-01   2.50372648e-01  -5.46843588e-01  -1.59703270e-01
   -6.22897875e-03   5.89166224e-01  -5.08853853e-01  -6.60851523e-02
    4.50171143e-01  -5.64878201e-03   3.09942067e-01  -1.53384339e-02
    5.62535465e-01  -8.99330080e-02   6.45264268e-01  -3.68950903e-01
    6.75510705e-01   4.12960142e-01   1.37762427e-01  -5.58109939e-01
    5.34076869e-01  -3.57382521e-02   4.08568501e-01   3.97582680e-01
    7.43655324e-01   6.73328713e-02   1.85713977e-01   4.64235812e-01
   -1.22303046e-01   1.26735479e-01  -1.77419633e-02   4.64806080e-01
   -2.67157942e-01  -3.05868149e-01   9.36553329e-02   8.87388527e-01
   -1.91891938e-01   6.39416337e-01  -3.64865750e-01  -4.59539622e-01
    6.49080351e-02   5.85176758e-02  -2.11936325e-01  -8.59116763e-02
    6.04212582e-01   4.18919891e-01   2.52391309e-01   2.97581673e-01
   -7.28710275e-03  -3.79223198e-01  -1.95660219e-01   5.33015072e-01
    2.55236238e-01  -2.71615624e-01   3.47559154e-01  -3.42531323e-01
   -4.90102112e-01   4.43317890e-01   1.50267005e-01  -5.67021668e-01
   -1.71578914e-01  -5.41744173e-01   3.90826821e-01  -8.20996389e-02
    2.87746862e-02  -4.50556815e-01  -5.12103736e-01  -2.92345643e-01
   -1.32288739e-01  -1.02633841e-01   4.79362071e-01   5.03127985e-02
    1.47464365e-01   6.21557869e-02  -1.76441714e-01   2.70211548e-01
    2.75840491e-01   2.01031551e-01   7.21822202e-01  -4.92621511e-01
   -2.83239663e-01  -5.53434432e-01  -1.91205963e-01  -1.74292445e-01
   -1.62553415e-01   2.78064370e-01   4.46720123e-01  -5.45358181e-01
    1.65767029e-01  -8.02127421e-01  -4.58429664e-01  -1.60468861e-01
    1.75706431e-01  -1.14115970e-02  -1.35936558e-01  -7.37666368e-01
   -1.57585189e-01   5.66591442e-01  -3.16329837e-01  -9.97049361e-03
    4.59586054e-01   2.17166066e-01  -8.39556754e-02   6.80879653e-01
    3.52848649e-01   4.73221987e-01  -8.94164801e-01  -4.73499805e-01
    5.24780095e-01  -3.39273721e-01   1.99859947e-01  -1.42804310e-01
   -4.18876588e-01   2.78284281e-01  -6.12094462e-01  -6.81641400e-02
   -3.15856159e-01  -2.93854862e-01  -3.03517804e-02   1.96455717e-01]]
After layer encoder_birnn_forward_l0_t4_state_0 (1, 256) <class 'numpy.float32'> [[  2.09002405e-01   3.45374554e-01  -5.53763092e-01  -2.73084283e-01
    7.55164146e-01  -1.12927169e-01   7.93427885e-01  -5.59293441e-02
   -1.64497867e-01  -9.95438844e-02   4.55140412e-01   5.07611811e-01
    1.18660510e-01  -6.74916565e-01   9.34410691e-02  -1.00079756e-02
    3.50469917e-01   5.73824286e-01  -9.46524739e-02   2.83294290e-01
   -2.01135814e-01  -5.56744039e-01  -8.00653756e-01   3.62349927e-01
   -1.88949823e-01  -1.19604275e-01  -7.56665587e-01  -7.21562654e-02
   -6.24538481e-01   4.10786480e-01   3.63026887e-01  -2.36633599e-01
    7.19877481e-01  -2.43457407e-01   1.08864427e+00   2.75268465e-01
    3.14715862e-01  -1.03814375e+00  -8.38755488e-01   7.73263872e-02
   -9.84604359e-02   6.75969362e-01  -2.02605590e-01   5.38659215e-01
   -9.92336512e-01  -3.33277822e-01  -1.77760795e-02   4.59082544e-01
    3.66003186e-01   1.99947923e-01   9.67437215e-03   1.79711636e-02
   -5.01711726e-01  -3.95872891e-01   9.04922485e-01   5.06587923e-01
   -7.99584806e-01  -1.29549325e-01   3.94352794e-01  -2.44702827e-02
    5.43780923e-01  -1.51483536e-01   1.36262760e-01   1.12816453e+00
   -4.23929930e-01   8.03535134e-02   4.26895499e-01   9.26593661e-01
    2.91904956e-01  -7.06534326e-01   3.10275555e-01   1.26718581e-02
   -1.11269927e+00   3.33061934e-01   5.02566695e-01   1.03579628e+00
    6.80370271e-01  -1.49652064e+00   4.73767042e-01  -5.71845174e-01
    8.54307234e-01  -4.96663719e-01  -4.39529605e-02   1.45069346e-01
   -3.99420261e-01  -6.56147480e-01   1.11781135e-01  -9.81216788e-01
    1.91354334e-01  -4.92715575e-02   3.86665016e-01   2.59192765e-01
   -5.55610240e-01  -3.06045443e-01  -6.07955933e-01  -2.04057008e-01
   -5.59422672e-01  -9.54309940e-01   5.16899705e-01   2.11520374e-01
   -4.07981992e-01  -4.65425737e-02  -3.39890979e-02   6.05079889e-01
   -5.25919139e-01  -5.75846434e-01   4.13355708e-01   3.99662942e-01
    3.61288935e-01   3.96348715e-01  -8.10074925e-01  -7.12131500e-01
    1.29962373e+00   1.30838895e+00  -2.81001985e-01   7.13838756e-01
    4.17267710e-01   2.03934148e-01   3.15516591e-01   1.10920668e-01
    5.22635803e-02  -7.05943227e-01   8.04652929e-01  -3.09864104e-01
    1.23581100e+00  -5.65765649e-02   7.03446031e-01   4.39091325e-01
   -6.74242914e-01  -1.13794422e+00   1.51295796e-01   6.18076921e-01
    2.42885262e-01  -1.55717075e-01   7.40734935e-01   8.01082134e-01
    2.37994179e-01   3.47379804e-01  -9.51481521e-01  -2.27677017e-01
   -3.98184694e-02   9.13948715e-01  -8.04221869e-01  -1.26045331e-01
    6.78339779e-01   1.97252873e-02   4.67110336e-01  -5.84392175e-02
    9.01259303e-01  -1.68255612e-01   1.00486660e+00  -5.51539540e-01
    1.07839584e+00   5.76713800e-01   2.18479753e-01  -8.25089335e-01
    8.84651124e-01  -7.56180435e-02   6.20565891e-01   5.62622547e-01
    1.26409972e+00   1.60631835e-01   3.20495605e-01   7.20607936e-01
   -2.35175788e-01   2.15620518e-01  -4.50754501e-02   7.08859205e-01
   -3.97991776e-01  -4.68729228e-01   1.42343938e-01   1.64300656e+00
   -2.99828112e-01   1.04715228e+00  -5.11863470e-01  -6.79539442e-01
    1.17499068e-01   1.14812255e-01  -2.98919618e-01  -1.29923582e-01
    9.14833784e-01   5.84764183e-01   3.97317350e-01   4.75356460e-01
   -2.76947394e-02  -5.86575508e-01  -3.12052608e-01   8.10221136e-01
    3.65912020e-01  -4.07815069e-01   4.93527293e-01  -5.41870534e-01
   -7.51234114e-01   6.88577175e-01   2.12439358e-01  -8.57177734e-01
   -1.86591774e-01  -7.50592828e-01   5.96542418e-01  -9.06141102e-02
    9.64119881e-02  -7.03935385e-01  -7.72307634e-01  -4.71801937e-01
   -2.39356950e-01  -1.27148792e-01   7.27126777e-01   8.47568810e-02
    2.21149921e-01   1.43083677e-01  -2.82341242e-01   4.23340112e-01
    4.02576089e-01   3.06304157e-01   1.25005972e+00  -7.81958163e-01
   -4.13441479e-01  -8.59036446e-01  -2.63118565e-01  -2.50446290e-01
   -2.36162275e-01   4.49453413e-01   6.33724630e-01  -8.89737844e-01
    2.48581558e-01  -1.38179994e+00  -6.36745691e-01  -2.63034195e-01
    2.92763770e-01  -3.65788788e-02  -2.16120422e-01  -1.26943243e+00
   -2.44437143e-01   8.71986508e-01  -5.07177472e-01   1.01436675e-03
    6.90843999e-01   3.39289576e-01  -1.58227116e-01   1.16611958e+00
    5.00120938e-01   7.65049636e-01  -1.74251068e+00  -6.65204048e-01
    7.71563053e-01  -4.69413310e-01   2.85768569e-01  -2.32024282e-01
   -6.43424034e-01   4.18725848e-01  -1.04809475e+00  -1.00111358e-01
   -5.08187830e-01  -4.60053205e-01  -2.23796256e-02   3.38463724e-01]]
After layer activation1030_output (1, 256) <class 'numpy.float32'> [[ 0.20601144  0.33226708 -0.50333524 -0.26649243  0.63821971 -0.11244957
   0.66034651 -0.0558711  -0.16303001 -0.09921639  0.42611527  0.46808234
   0.11810671 -0.58820474  0.09317007 -0.01000764  0.33679223  0.51816231
  -0.09437082  0.27595127 -0.19846664 -0.50555766 -0.66440213  0.34728223
  -0.18673286 -0.1190372  -0.63910872 -0.0720313  -0.55428004  0.38914028
   0.34787741 -0.23231353  0.61683339 -0.23875874  0.79638278  0.2685203
   0.30472118 -0.77715397 -0.68514931  0.07717264 -0.0981435   0.58889282
  -0.19987811  0.49197236 -0.75835687 -0.32146296 -0.01777421  0.42933619
   0.35049081  0.19732527  0.00967407  0.01796923 -0.46346226 -0.37641212
   0.71868622  0.46728241 -0.66380459 -0.12882942  0.37510666 -0.0244654
   0.49584463 -0.15033537  0.13542563  0.81039011 -0.40023604  0.08018102
   0.40272358  0.72900176  0.28388718 -0.60849893  0.30068776  0.01267118
  -0.80501449  0.32126936  0.46413332  0.77622265  0.59176004 -0.90451753
   0.44123799 -0.51671308  0.693313   -0.45948929 -0.04392468  0.14406018
  -0.37945282 -0.57579386  0.11131789 -0.75359213  0.18905248 -0.04923172
   0.36848161  0.25354034 -0.50471318 -0.29683521 -0.54268658 -0.20127115
  -0.50754893 -0.74172807  0.47530365  0.20842129 -0.38675788 -0.046509
  -0.03397601  0.54065442 -0.48225546 -0.51963997  0.39131826  0.37966052
   0.34634885  0.37682045 -0.6696316  -0.61201167  0.86162627  0.86386716
  -0.27383217  0.61307836  0.39462614  0.20115326  0.30544737  0.110468
   0.05221605 -0.60812664  0.66662997 -0.30031344  0.84425664 -0.05651628
   0.60655057  0.41289097 -0.58776391 -0.8137207   0.15015186  0.54978764
   0.23821914 -0.15447056  0.62958896  0.66464132  0.23360027  0.33404976
  -0.740453   -0.22382289 -0.03979744  0.7230221  -0.66639042 -0.12538204
   0.59043896  0.01972273  0.43586159 -0.05837278  0.71691048 -0.16668563
   0.76363045 -0.50167322  0.79260349  0.52027285  0.21506861 -0.67783034
   0.70874178 -0.07547424  0.55152196  0.50992066  0.85219043  0.15926439
   0.30995497  0.61728573 -0.23093393  0.21233995 -0.04504495  0.60996103
  -0.37822935 -0.437172    0.14139029  0.92789173 -0.29115528  0.78069675
  -0.47139585 -0.5912199   0.11696131  0.11431043 -0.29032359 -0.12919745
   0.72344422  0.52611947  0.37765124  0.44251707 -0.02768766 -0.52742827
  -0.30230325  0.66971219  0.35041082 -0.3866159   0.45701152 -0.49440259
  -0.63588464  0.59706712  0.20930019 -0.69480073 -0.18445604 -0.63550246
   0.53458464 -0.09036691  0.09611437 -0.6068598  -0.6482693  -0.43965411
  -0.23488827 -0.126468    0.62130439  0.08455451  0.2176138   0.14211516
  -0.27507055  0.39974058  0.38215101  0.29707113  0.8483004  -0.65382922
  -0.39139089 -0.69576085 -0.25721011 -0.24533813 -0.2318676   0.42144963
   0.56061161 -0.71126425  0.24358484 -0.88135368 -0.56267965 -0.25713131
   0.28467658 -0.03656257 -0.21281727 -0.85364377 -0.23968241  0.70238203
  -0.4677431   0.00101437  0.59852391  0.32684299 -0.15691976  0.82302421
   0.46221226  0.64404172 -0.94051713 -0.58181632  0.6478374  -0.43772516
   0.27823555 -0.22794834 -0.56722641  0.3958565  -0.78106451 -0.09977825
  -0.46853203 -0.43012759 -0.02237589  0.32610518]]
After layer encoder_birnn_forward_l0_t4_out_0 (1, 256) <class 'numpy.float32'> [[  1.38558760e-01   2.03197569e-01  -3.17825854e-01  -1.76145226e-01
    3.91703039e-01  -7.37537816e-02   5.08606374e-01  -3.36047225e-02
   -1.05439052e-01  -6.33942708e-02   2.62784511e-01   2.98557162e-01
    7.11852014e-02  -4.04627413e-01   4.56489548e-02  -5.55420388e-03
    2.16255426e-01   3.00721586e-01  -7.18035549e-02   1.83907956e-01
   -1.13143563e-01  -2.53916711e-01  -4.89153743e-01   2.31432244e-01
   -1.15687102e-01  -6.67981505e-02  -4.51683491e-01  -4.66996133e-02
   -2.91455120e-01   2.38673404e-01   2.28904456e-01  -1.56866983e-01
    3.25997740e-01  -1.44499809e-01   4.82863635e-01   1.53828561e-01
    1.95773453e-01  -4.30041552e-01  -2.82241672e-01   4.47896495e-02
   -5.95170073e-02   3.62431735e-01  -1.18864641e-01   3.02495301e-01
   -4.66028184e-01  -2.03834400e-01  -1.37479827e-02   2.76168168e-01
    2.14927256e-01   1.05197564e-01   4.37251059e-03   1.14825014e-02
   -4.10485744e-01  -1.84866548e-01   4.57677215e-01   2.23930568e-01
   -3.78412217e-01  -7.72505105e-02   2.38990396e-01  -1.49891712e-02
    2.48043552e-01  -9.19904932e-02   7.01375827e-02   5.59440911e-01
   -2.28209645e-01   4.96830791e-02   2.76513785e-01   4.27286685e-01
    1.73593327e-01  -3.64015639e-01   1.97202027e-01   8.06678645e-03
   -6.10287428e-01   1.97013706e-01   2.76573092e-01   6.63259268e-01
    3.73115391e-01  -7.73122072e-01   3.12952816e-01  -2.84520149e-01
    4.94304121e-01  -2.17277288e-01  -3.89684550e-02   8.82706866e-02
   -2.62115717e-01  -3.42689335e-01   6.31250367e-02  -4.95644063e-01
    1.51978537e-01  -3.19673531e-02   2.19977155e-01   1.51703998e-01
   -2.19347641e-01  -2.07271278e-01  -2.92273581e-01  -1.39421493e-01
   -3.36442143e-01  -4.98539388e-01   3.19798619e-01   1.51886806e-01
   -2.15198174e-01  -2.77946964e-02  -1.86350364e-02   3.85667682e-01
   -3.23420763e-01  -2.80308127e-01   2.38288477e-01   2.58326143e-01
    2.33033642e-01   2.07906544e-01  -4.76046652e-01  -3.82353842e-01
    6.92499936e-01   6.77917182e-01  -1.82954401e-01   3.83431524e-01
    2.51195312e-01   1.50379822e-01   1.92661449e-01   7.21798688e-02
    3.19766626e-02  -4.53977972e-01   4.27070796e-01  -1.85609788e-01
    5.53216755e-01  -3.77775878e-02   3.22959840e-01   2.11008444e-01
   -3.47714007e-01  -6.68958664e-01   9.80516970e-02   4.02666003e-01
    1.39406696e-01  -9.60347876e-02   3.63404483e-01   3.72131467e-01
    1.56022400e-01   2.02032670e-01  -5.26779115e-01  -1.40724227e-01
   -2.25613117e-02   4.57607746e-01  -4.17307585e-01  -7.97621831e-02
    3.41815084e-01   1.26229422e-02   2.59667218e-01  -3.47565562e-02
    3.74845564e-01  -9.65485051e-02   5.86103737e-01  -2.85905063e-01
    5.10462523e-01   2.60608852e-01   1.22147106e-01  -3.31677705e-01
    4.04223323e-01  -4.52391133e-02   4.03743356e-01   3.28773379e-01
    5.39907157e-01   1.02617979e-01   1.73094004e-01   4.02968407e-01
   -1.64576367e-01   1.18688725e-01  -2.83886828e-02   3.41155142e-01
   -1.79914013e-01  -2.50984251e-01   8.22129622e-02   8.43677640e-01
   -1.92595333e-01   5.72381854e-01  -2.33038649e-01  -3.30693126e-01
    7.18516111e-02   7.36503899e-02  -1.67969733e-01  -8.81842524e-02
    4.47229564e-01   2.51469254e-01   2.40433797e-01   2.91381687e-01
   -1.59497093e-02  -3.44724745e-01  -1.90289721e-01   3.79099965e-01
    2.20531926e-01  -2.65756011e-01   2.24334687e-01  -3.03092390e-01
   -4.70638335e-01   3.78556132e-01   1.12005360e-01  -4.57294762e-01
   -1.68958113e-01  -3.93808037e-01   3.40757459e-01  -5.79383336e-02
    5.44724502e-02  -3.20558548e-01  -4.26101923e-01  -3.02100003e-01
   -1.52823016e-01  -8.62725899e-02   4.38799024e-01   4.41968404e-02
    9.31900516e-02   9.03659239e-02  -1.79424137e-01   2.27029562e-01
    2.62584955e-01   1.98132381e-01   7.03324854e-01  -4.87385422e-01
   -2.32945874e-01  -5.08940458e-01  -1.71731770e-01  -1.44766718e-01
   -1.38123035e-01   2.80717224e-01   2.84328938e-01  -4.12369817e-01
    1.56725913e-01  -5.24925888e-01  -3.54552031e-01  -1.58366427e-01
    1.83954611e-01  -2.03532502e-02  -1.15375280e-01  -6.17029011e-01
   -1.53246284e-01   4.55587000e-01  -3.15218985e-01   5.84304216e-04
    3.07821155e-01   1.57709569e-01  -9.50658768e-02   6.27186000e-01
    2.47464970e-01   4.46288913e-01  -8.86851192e-01  -2.95687079e-01
    4.02214050e-01  -2.42235973e-01   1.75746486e-01  -1.44616991e-01
   -3.92104715e-01   2.71785945e-01  -5.61373472e-01  -5.66464812e-02
   -3.35923165e-01  -2.90242285e-01  -1.35038346e-02   2.12628588e-01]]
After layer expand_dims1036_0 (1, 1, 256) <class 'numpy.float32'> [[[  1.38558760e-01   2.03197569e-01  -3.17825854e-01  -1.76145226e-01
     3.91703039e-01  -7.37537816e-02   5.08606374e-01  -3.36047225e-02
    -1.05439052e-01  -6.33942708e-02   2.62784511e-01   2.98557162e-01
     7.11852014e-02  -4.04627413e-01   4.56489548e-02  -5.55420388e-03
     2.16255426e-01   3.00721586e-01  -7.18035549e-02   1.83907956e-01
    -1.13143563e-01  -2.53916711e-01  -4.89153743e-01   2.31432244e-01
    -1.15687102e-01  -6.67981505e-02  -4.51683491e-01  -4.66996133e-02
    -2.91455120e-01   2.38673404e-01   2.28904456e-01  -1.56866983e-01
     3.25997740e-01  -1.44499809e-01   4.82863635e-01   1.53828561e-01
     1.95773453e-01  -4.30041552e-01  -2.82241672e-01   4.47896495e-02
    -5.95170073e-02   3.62431735e-01  -1.18864641e-01   3.02495301e-01
    -4.66028184e-01  -2.03834400e-01  -1.37479827e-02   2.76168168e-01
     2.14927256e-01   1.05197564e-01   4.37251059e-03   1.14825014e-02
    -4.10485744e-01  -1.84866548e-01   4.57677215e-01   2.23930568e-01
    -3.78412217e-01  -7.72505105e-02   2.38990396e-01  -1.49891712e-02
     2.48043552e-01  -9.19904932e-02   7.01375827e-02   5.59440911e-01
    -2.28209645e-01   4.96830791e-02   2.76513785e-01   4.27286685e-01
     1.73593327e-01  -3.64015639e-01   1.97202027e-01   8.06678645e-03
    -6.10287428e-01   1.97013706e-01   2.76573092e-01   6.63259268e-01
     3.73115391e-01  -7.73122072e-01   3.12952816e-01  -2.84520149e-01
     4.94304121e-01  -2.17277288e-01  -3.89684550e-02   8.82706866e-02
    -2.62115717e-01  -3.42689335e-01   6.31250367e-02  -4.95644063e-01
     1.51978537e-01  -3.19673531e-02   2.19977155e-01   1.51703998e-01
    -2.19347641e-01  -2.07271278e-01  -2.92273581e-01  -1.39421493e-01
    -3.36442143e-01  -4.98539388e-01   3.19798619e-01   1.51886806e-01
    -2.15198174e-01  -2.77946964e-02  -1.86350364e-02   3.85667682e-01
    -3.23420763e-01  -2.80308127e-01   2.38288477e-01   2.58326143e-01
     2.33033642e-01   2.07906544e-01  -4.76046652e-01  -3.82353842e-01
     6.92499936e-01   6.77917182e-01  -1.82954401e-01   3.83431524e-01
     2.51195312e-01   1.50379822e-01   1.92661449e-01   7.21798688e-02
     3.19766626e-02  -4.53977972e-01   4.27070796e-01  -1.85609788e-01
     5.53216755e-01  -3.77775878e-02   3.22959840e-01   2.11008444e-01
    -3.47714007e-01  -6.68958664e-01   9.80516970e-02   4.02666003e-01
     1.39406696e-01  -9.60347876e-02   3.63404483e-01   3.72131467e-01
     1.56022400e-01   2.02032670e-01  -5.26779115e-01  -1.40724227e-01
    -2.25613117e-02   4.57607746e-01  -4.17307585e-01  -7.97621831e-02
     3.41815084e-01   1.26229422e-02   2.59667218e-01  -3.47565562e-02
     3.74845564e-01  -9.65485051e-02   5.86103737e-01  -2.85905063e-01
     5.10462523e-01   2.60608852e-01   1.22147106e-01  -3.31677705e-01
     4.04223323e-01  -4.52391133e-02   4.03743356e-01   3.28773379e-01
     5.39907157e-01   1.02617979e-01   1.73094004e-01   4.02968407e-01
    -1.64576367e-01   1.18688725e-01  -2.83886828e-02   3.41155142e-01
    -1.79914013e-01  -2.50984251e-01   8.22129622e-02   8.43677640e-01
    -1.92595333e-01   5.72381854e-01  -2.33038649e-01  -3.30693126e-01
     7.18516111e-02   7.36503899e-02  -1.67969733e-01  -8.81842524e-02
     4.47229564e-01   2.51469254e-01   2.40433797e-01   2.91381687e-01
    -1.59497093e-02  -3.44724745e-01  -1.90289721e-01   3.79099965e-01
     2.20531926e-01  -2.65756011e-01   2.24334687e-01  -3.03092390e-01
    -4.70638335e-01   3.78556132e-01   1.12005360e-01  -4.57294762e-01
    -1.68958113e-01  -3.93808037e-01   3.40757459e-01  -5.79383336e-02
     5.44724502e-02  -3.20558548e-01  -4.26101923e-01  -3.02100003e-01
    -1.52823016e-01  -8.62725899e-02   4.38799024e-01   4.41968404e-02
     9.31900516e-02   9.03659239e-02  -1.79424137e-01   2.27029562e-01
     2.62584955e-01   1.98132381e-01   7.03324854e-01  -4.87385422e-01
    -2.32945874e-01  -5.08940458e-01  -1.71731770e-01  -1.44766718e-01
    -1.38123035e-01   2.80717224e-01   2.84328938e-01  -4.12369817e-01
     1.56725913e-01  -5.24925888e-01  -3.54552031e-01  -1.58366427e-01
     1.83954611e-01  -2.03532502e-02  -1.15375280e-01  -6.17029011e-01
    -1.53246284e-01   4.55587000e-01  -3.15218985e-01   5.84304216e-04
     3.07821155e-01   1.57709569e-01  -9.50658768e-02   6.27186000e-01
     2.47464970e-01   4.46288913e-01  -8.86851192e-01  -2.95687079e-01
     4.02214050e-01  -2.42235973e-01   1.75746486e-01  -1.44616991e-01
    -3.92104715e-01   2.71785945e-01  -5.61373472e-01  -5.66464812e-02
    -3.35923165e-01  -2.90242285e-01  -1.35038346e-02   2.12628588e-01]]]
After layer encoder_birnn_forward_l0_t5_i2h_output (1, 1024) <class 'numpy.float32'> [[ 0.07376467 -0.04585483  0.06153381 ...,  0.03591035  0.03396329
   0.02903319]]
After layer encoder_birnn_forward_l0_t5_h2h_output (1, 1024) <class 'numpy.float32'> [[ 0.50746268  0.53273994  0.32371843 ...,  1.11504459  0.57411981
   0.93146837]]
After layer _plus1031_0 (1, 1024) <class 'numpy.float32'> [[ 0.58122736  0.4868851   0.38525224 ...,  1.15095496  0.60808307
   0.96050155]]
After layer encoder_birnn_forward_l0_t5_slice_output0 (1, 256) <class 'numpy.float32'> [[ 0.58122736  0.4868851   0.38525224  0.36721113  0.82388639  0.79916012
   1.42220283  0.07305812 -0.39833552  0.53462297  0.43720531  0.77675366
  -0.06076245  0.97251803 -0.38469049  0.22341961  0.39295825  0.62484503
   0.78223652  0.42740858 -0.02965048 -0.87777722  0.55641794  0.41831204
   0.25886378  0.2170151   0.9156279   0.03169684  0.73728287  0.70117986
   0.68794078  0.64008182  1.07432425  0.64230549  1.7587595   0.07343084
   0.34743845  1.85573769  1.26383972 -0.62608421 -0.29981434  0.56838274
   1.07621765  0.23715675  1.66047442  0.57736945  0.37346032  0.66987979
   0.23956065 -0.16927063 -0.28383529 -0.2870805   3.2597425   0.35304469
   1.27548194  0.11102313  1.07260025  0.01966185  0.42126352 -0.99054337
   0.42129803  0.42392683 -0.10481499  1.2125988   0.03917576  0.16000631
   0.83536142  1.46103871  0.73639554  1.21237457 -0.18932284 -0.93565089
   1.86420047  0.6051715   0.53275871  1.89397001  0.81153017  2.60939789
   0.58727574 -0.41953033  1.0748812   0.54003698  0.73742688 -0.14764725
   1.11728299  0.78650218  0.35609484  1.52439821  1.21041131 -0.24685791
   0.56619239 -0.18862462 -0.21243128  0.5539642  -0.46142909 -0.7291888
   1.13778365  1.25701594  1.03393471  0.57093811  0.24850333 -0.31191605
   0.441374    1.35811198  0.89298964  0.28397086  0.11074259  0.30047855
  -0.0211664   0.24242692  1.24153471  1.05038261  2.25112057  2.7683444
   0.78241587  0.96855223  0.55205363  1.02545726  0.26367038 -0.22061801
  -0.2409427   1.16573298  1.8450917   0.40536532  1.83069348  0.27478632
   0.43808356  0.45344394  0.31140643  2.02430701 -0.38898084  0.92374456
   0.45019352  0.23629656  0.98431808  0.69025868  0.72517836 -0.61255497
   0.83476406 -0.08561334  0.06274228  1.23538959  0.81606394  0.04274033
   0.636518   -0.64950037  0.03199301 -0.41371423  1.03446233 -0.12647471
   1.66372156  0.86585796  1.63960147  1.24680078  0.08030295  1.05128193
   0.70344025 -0.31211847  1.10569537  0.91151214  1.95025659 -0.18328792
   0.84252685  0.95458341  0.7380206   0.04101412  0.15783525  0.5756228
  -0.10615537  0.42627296 -0.45451382  3.90000391  0.45595896  1.39883184
   0.68879241  0.31873351 -0.18627758 -0.4992789  -0.08294503  0.40352717
   1.37391114  0.48081142  0.56439149  0.31168815 -0.26855975  0.64148349
   0.09320848  1.12649107  0.74267966  0.64846152 -0.52383596  0.19437456
   1.52388704  0.41288942  0.50439513  1.10709453  3.19415092  1.26529062
   0.73281938  0.182144    0.31971949  0.94197029  0.60352445  0.66662395
   0.61096925 -0.01733683  0.89054596 -0.36677164 -0.3378976   0.45587075
   0.72346485  0.3939763   1.08399427  0.4841828   2.09656119  1.08431649
   0.35257226  1.3718642   0.58929485 -0.41211596  0.25870514  0.40149659
   0.56411994  0.75244427  0.62233806  2.91482329  0.7666887  -0.06920129
   0.03290863  0.05794297 -0.59389353  2.57377863  0.4042823   1.27577329
   0.65186661 -0.06516115  0.48835588 -0.32170698  0.18727484  1.53692377
   0.28736788  0.88175011  4.30579472  0.5570392   1.11811733  0.73483247
   0.42403924  0.30213985  0.83375984  0.46730012  1.5903126  -0.56062949
   1.09384859  0.63822532 -0.40076181  0.41937485]]
After layer encoder_birnn_forward_l0_t5_slice_output1 (1, 256) <class 'numpy.float32'> [[  1.15348446e+00   7.49254897e-02   2.11930752e-01   5.19749343e-01
    3.78195107e-01   4.54014570e-01   1.32414865e+00   3.75661671e-01
    1.88771856e+00   3.34518820e-01   1.27339137e+00   5.58761537e-01
    8.84582102e-01   8.49430084e-01  -1.52015924e-01   5.03003120e-01
    4.32189345e-01   3.80824268e-01   1.14457321e+00   6.65009320e-01
    1.72991380e-01  -1.74006909e-01   1.25165379e+00   2.67686248e-01
    7.35116601e-01   6.40752375e-01   7.70214617e-01   3.84915590e-01
    1.04415095e+00   2.49604106e-01   1.04379773e+00   8.76849890e-01
    5.48983097e-01   7.17625022e-01   1.42222297e+00   4.64782953e-01
    2.26948887e-01   6.08835340e-01   1.49002016e+00   8.57934877e-02
    8.28520417e-01   5.14547288e-01   1.27945137e+00  -1.55956745e-01
    1.14336565e-01  -2.78357029e-01   1.35236192e+00   6.46948516e-01
    3.00333351e-01  -2.09888503e-01  -2.72111058e-01   4.52491760e-01
    2.71835423e+00  -2.18039259e-01   1.09966838e+00  -2.85103798e-01
    3.29371780e-01   5.68858206e-01   6.53727114e-01   7.75237560e-01
    2.89685577e-02   4.88785148e-01   1.97286218e-01   9.27510679e-01
    2.52050936e-01   5.01276255e-01   8.34245145e-01   9.75759447e-01
    5.10057271e-01   1.43653738e+00  -8.76949877e-02   5.61361969e-01
    1.53629208e+00   5.68185329e-01   1.37178868e-01   2.55815434e+00
    4.36850309e-01   2.40817666e+00   8.51789415e-01  -5.53803563e-01
    1.02099466e+00  -4.89653587e-01   2.20305896e+00   8.22177529e-01
    9.96888876e-01   6.89302921e-01   9.70915426e-04   1.49753737e+00
    2.51350594e+00   4.20406133e-01   2.87204981e-01   6.41904175e-01
   -1.36018582e-02   6.30989969e-01  -1.90193921e-01   9.40220580e-02
    1.18711674e+00   1.08228433e+00   1.11100650e+00   1.13585806e+00
    2.18129039e-01  -2.70680666e-01   6.89855069e-02   1.01497090e+00
    9.16379929e-01   2.67582327e-01   6.50894880e-01   7.33975470e-01
    5.24995148e-01   4.12385106e-01   1.01511538e+00   1.35605574e+00
    1.67766023e+00   2.00483489e+00   7.39181101e-01   5.88703513e-01
    1.11389244e+00   1.22639894e+00   5.78849852e-01   4.82972741e-01
    6.35689616e-01   1.39857471e+00   7.53288925e-01   4.94444370e-01
    1.14162922e+00   6.82584643e-01  -3.84511113e-01   4.94314820e-01
    5.21884799e-01   1.98145843e+00   4.80503559e-01   8.39726031e-01
    2.23128840e-01   2.94094205e-01   5.22966146e-01   1.00793231e+00
    8.68765175e-01  -4.99060631e-01   1.45746911e+00   8.93073320e-01
    4.95870769e-01   6.64704859e-01   8.46165180e-01   7.35464752e-01
    7.75069356e-01   1.07271397e+00   3.31100643e-01   6.58199131e-01
    1.17886448e+00   6.92467272e-01   1.00852835e+00   2.73823261e-01
    6.88769758e-01   7.07015812e-01   4.71914202e-01   3.27059984e-01
    1.14821875e+00   3.40002686e-01   1.37605369e+00   7.00124502e-01
    1.31253600e+00   6.18760824e-01   1.02483988e+00   9.00620759e-01
    9.82332528e-01   3.19296360e-01   3.54861736e-01   4.42703307e-01
   -1.81818962e-01   2.61695147e-01  -2.49049664e-01   2.08158493e+00
    5.65923214e-01   1.50829518e+00   7.96674490e-02   2.16590226e-01
    4.19411778e-01   9.31065321e-01  -1.46783128e-01   1.19002604e+00
    3.87128651e-01  -1.53804809e-01   1.06563675e+00   7.70885229e-01
    4.79263306e-01   6.70276105e-01   1.04030907e+00   8.29068482e-01
    6.92774177e-01   9.46519494e-01  -4.90910262e-01   6.00982010e-01
    1.23228312e+00   7.85595298e-01  -7.49768838e-02   4.05294418e-01
    4.18519402e+00  -1.87635064e-01   6.89694405e-01  -8.68256912e-02
    5.24635434e-01   7.42005944e-01   5.00696838e-01   1.44962406e+00
    6.62500083e-01   3.43623698e-01   1.16135311e+00  -4.50185984e-01
    6.04441762e-03   9.25856054e-01   9.22539353e-01   5.52590847e-01
    8.82928491e-01   6.59626126e-01   2.00376368e+00   1.33440006e+00
    2.49268800e-01   1.01204038e+00   6.41320646e-02   6.69135749e-02
    2.59982556e-01   8.56852949e-01  -1.31804213e-01   8.67873788e-01
    5.15518010e-01   1.48596334e+00  -4.23991293e-01   4.32076931e-01
    7.38208652e-01   4.51171190e-01   4.19655353e-01   1.80275893e+00
    3.81619871e-01   7.62587786e-01   1.07941175e+00   7.39840031e-01
    2.16647059e-01   2.16037005e-01   3.28102827e-01   1.64331901e+00
    2.69213885e-01   1.11808884e+00   4.09219837e+00  -1.44505262e-01
    4.62791771e-01  -1.80329680e-01   2.99225450e-01   5.16122401e-01
    7.57100284e-01   8.99432600e-01   1.57356215e+00  -1.52197585e-01
    1.29866099e+00   5.81772089e-01   4.32592452e-01   7.42710173e-01]]
After layer encoder_birnn_forward_l0_t5_slice_output2 (1, 256) <class 'numpy.float32'> [[  3.19149315e-01   6.23915911e-01  -1.22628701e+00  -4.54154134e-01
    1.65861523e+00  -1.74465820e-01   1.45346963e+00   4.63766381e-02
   -5.03251195e-01  -9.56080183e-02   9.20335948e-01   1.00194633e+00
    2.69285530e-01  -1.26790738e+00   1.51664540e-01   2.28269100e-02
    6.63428009e-01   1.18200374e+00  -1.07139170e-01   5.52790105e-01
   -2.69183010e-01  -2.32117367e+00  -1.99188626e+00   7.53100574e-01
   -2.44594023e-01  -1.79164633e-01  -1.55519009e+00  -4.24552858e-02
   -1.31018686e+00   8.88013244e-01   6.73138499e-01  -3.93241763e-01
    1.22497356e+00  -5.28623581e-01   2.34584165e+00   6.00699544e-01
    6.31038487e-01  -2.31582713e+00  -1.65907598e+00  -2.50379741e-02
   -7.54853934e-02   1.79778898e+00  -1.90109700e-01   1.39742804e+00
   -2.76013327e+00  -6.83811903e-01  -1.06575012e-01   7.34646201e-01
    7.88574576e-01   4.86456394e-01  -5.78846633e-02   2.49396265e-03
   -9.37011778e-01  -8.28790545e-01   1.80580759e+00   1.09770417e+00
   -2.02308869e+00  -2.17119694e-01   1.01718819e+00   4.74014319e-02
    1.35747015e+00  -1.50525153e-01   2.60809839e-01   3.38490510e+00
   -1.02293825e+00   1.26684561e-01   9.16659892e-01   1.70290959e+00
    5.08701563e-01  -1.45859861e+00   7.46766925e-01   1.44844800e-01
   -2.24183249e+00   5.29612064e-01   9.76605594e-01   1.82525241e+00
    1.50408661e+00  -3.07406855e+00   9.48400199e-01  -1.93479252e+00
    2.02840400e+00  -1.03072309e+00  -1.92958653e-01   2.08292589e-01
   -6.06129110e-01  -1.52848732e+00   3.00269365e-01  -1.97667277e+00
    1.91480666e-01  -1.65256083e-01   9.05619562e-01   5.46078444e-01
   -1.68083453e+00  -5.91315687e-01  -2.50044250e+00  -7.12417901e-01
   -9.48578835e-01  -2.15901709e+00   9.08494234e-01   2.56010056e-01
   -1.03101301e+00  -1.25159889e-01   3.02422419e-03   9.78375912e-01
   -7.71386683e-01  -1.46528196e+00   6.84101701e-01   6.54454410e-01
    6.23461664e-01   8.04657936e-01  -1.66580534e+00  -1.39305449e+00
    2.75745630e+00   2.47304249e+00  -2.74209887e-01   1.51616144e+00
    7.10483789e-01   2.41105944e-01   5.87376714e-01   1.50758624e-01
    1.94957644e-01  -1.21936858e+00   1.48231065e+00  -6.27424717e-01
    2.80022907e+00  -3.07579935e-01   2.11512136e+00   8.81130159e-01
   -1.73444033e+00  -2.24334550e+00   3.53607595e-01   1.06618857e+00
    4.98416990e-01  -3.15151185e-01   1.54427230e+00   1.85127819e+00
    5.73395312e-01   1.25286233e+00  -2.16153908e+00  -5.86975694e-01
    1.16462111e-02   2.13720012e+00  -1.81533456e+00  -1.81234419e-01
    1.62060869e+00  -6.43681921e-03   1.16640472e+00   2.70880461e-02
    2.12982702e+00  -2.47035637e-01   2.24711061e+00  -9.99340832e-01
    2.54451108e+00   1.24555445e+00   4.45126295e-01  -2.03314376e+00
    2.15734553e+00  -5.96284717e-02   1.18521035e+00   1.20304465e+00
    3.16604543e+00   8.50675106e-02   4.66470599e-01   1.44809783e+00
   -2.65003264e-01   3.10747117e-01  -6.83430731e-02   1.60933757e+00
   -9.02413607e-01  -8.97379220e-01   3.30158621e-01   3.34980035e+00
   -5.56171954e-01   2.39700580e+00  -1.12142813e+00  -1.99389398e+00
    2.43235946e-01   1.86423197e-01  -7.59634376e-01  -2.51626134e-01
    2.07535028e+00   1.45709133e+00   6.91979706e-01   9.32363629e-01
   -1.50588378e-02  -1.14363325e+00  -6.27997994e-01   1.79547012e+00
    7.54721045e-01  -7.77091742e-01   1.84025991e+00  -1.17612660e+00
   -1.36287379e+00   1.72239363e+00   4.00305420e-01  -2.00564694e+00
   -3.66195798e-01  -1.69105685e+00   1.21800494e+00  -2.94339180e-01
    2.04048753e-02  -1.34188390e+00  -2.21043205e+00  -8.89193177e-01
   -3.18731904e-01  -2.92954981e-01   1.64342320e+00   9.55668986e-02
    5.03489852e-01   1.44897759e-01  -4.65590239e-01   7.97505498e-01
    7.24421382e-01   5.33004582e-01   2.58046246e+00  -1.62478769e+00
   -9.15983319e-01  -1.80219364e+00  -5.65613687e-01  -7.20167935e-01
   -4.86452669e-01   8.08197677e-01   1.52099490e+00  -2.30004668e+00
    4.39572722e-01  -2.86284566e+00  -1.54330206e+00  -4.95417953e-01
    4.73421633e-01  -3.57135683e-02  -5.33565819e-01  -2.23366785e+00
   -3.71896178e-01   1.94191980e+00  -8.69267583e-01  -4.70958613e-02
    1.64200234e+00   8.48480046e-01  -1.84431180e-01   3.10637403e+00
    1.30623543e+00   1.45219755e+00  -3.24889135e+00  -1.83043015e+00
    1.71076167e+00  -1.00159132e+00   5.29182434e-01  -4.06739563e-01
   -1.24049866e+00   8.95883918e-01  -1.87596369e+00  -2.03620732e-01
   -8.17365646e-01  -7.83800721e-01  -1.19762026e-01   5.30028522e-01]]
After layer encoder_birnn_forward_l0_t5_slice_output3 (1, 256) <class 'numpy.float32'> [[  1.14939678e+00   6.89533651e-01   7.72507548e-01   1.03687239e+00
    7.16677845e-01   1.02997041e+00   2.03668284e+00   6.13387227e-01
    9.38523591e-01   8.28543305e-01   8.08819652e-01   8.89950931e-01
    6.55440331e-01   1.35043323e+00  -8.17072317e-02   2.88791209e-01
    9.04637992e-01   4.78185952e-01   1.84273565e+00   1.07135379e+00
    5.28260231e-01  -2.93270666e-02   1.63485599e+00   1.11125147e+00
    6.75511003e-01   4.32800651e-01   1.39137316e+00   9.35187101e-01
    1.65175170e-01   7.90895700e-01   1.09943008e+00   1.09027398e+00
    1.08196989e-01   6.79056108e-01   6.59827292e-01   3.90936673e-01
    9.36721683e-01   3.25190842e-01  -6.38313413e-01   5.23083389e-01
    6.12315953e-01   7.48676538e-01   6.68997228e-01   7.47344732e-01
    7.47692108e-01   8.67264807e-01   1.95619059e+00   9.67547655e-01
    7.15531290e-01   1.92090288e-01  -3.73910755e-01   9.25651550e-01
    3.30991507e+00  -1.25814974e-01   9.04037893e-01  -1.15773074e-01
    4.29700851e-01   6.59071922e-01   9.41784382e-01   6.51555061e-01
    2.20960900e-02   5.92821479e-01   1.43100053e-01   1.28947949e+00
    4.44574475e-01   7.60171711e-01   1.21355414e+00   5.44635534e-01
    7.33731985e-01   6.02341890e-01   1.00433993e+00   8.87559652e-01
    1.81208658e+00   7.80430675e-01   6.04812026e-01   2.90221524e+00
    8.37018132e-01   2.76734829e+00   1.35738564e+00   2.30749965e-01
    1.52790713e+00  -2.04748854e-01   3.35089993e+00   7.31168032e-01
    1.25383520e+00   5.92857480e-01   4.75249022e-01   9.89507318e-01
    2.19027114e+00   1.01900709e+00   6.30932808e-01   7.45008588e-01
   -4.66465324e-01   1.34473693e+00   2.58661747e-01   1.14435410e+00
    1.03388035e+00   1.11601985e+00   1.07421267e+00   1.57521594e+00
    3.36948693e-01   6.16612196e-01   2.51511008e-01   1.49582398e+00
    1.11853206e+00   3.13725680e-01   7.61861920e-01   1.12931228e+00
    1.17036176e+00   2.60847986e-01   1.45895970e+00   8.52068245e-01
    2.20472550e+00   2.00852609e+00   1.09132421e+00   8.26547146e-01
    8.74869347e-01   1.74017572e+00   8.44335854e-01   9.96462345e-01
    7.17276573e-01   1.77679920e+00   9.50320482e-01   7.82962263e-01
    1.04280913e+00   1.16092420e+00   1.23170294e-01   1.12044372e-01
    6.06924236e-01   2.47517872e+00   9.95881677e-01   1.60485435e+00
    5.80148995e-01   7.87407458e-01   4.74566013e-01   4.15844470e-01
    1.13519621e+00   6.46204174e-01   1.36369753e+00   8.57208788e-01
    4.43038851e-01   8.55492711e-01   7.98235655e-01   9.07270551e-01
    5.03431439e-01   1.01052570e+00   6.65470481e-01   6.18694961e-01
    1.15081213e-01   4.24104631e-01   1.94140828e+00   4.33742702e-01
    9.47516561e-01   7.03142434e-02   4.02876645e-01  -6.90490603e-02
    4.80124027e-01   6.76221907e-01   1.70150316e+00   9.05500531e-01
    8.28326166e-01   9.91829634e-01   2.91975647e-01   1.05545831e+00
    1.50686407e+00   3.62330794e-01   8.53179336e-01   3.47895384e-01
   -1.89406022e-01   4.45973217e-01   5.59672296e-01   3.67735529e+00
    1.03356481e+00   1.53870118e+00  -1.83433294e-04   3.33072603e-01
    7.40177155e-01   9.33504641e-01   4.99963582e-01   1.24621964e+00
    7.56942511e-01  -1.09663434e-01   9.65087831e-01   1.03035426e+00
    4.76657718e-01   9.94004548e-01   8.20940495e-01   4.50297534e-01
    9.16770875e-01   1.28909779e+00  -1.00216031e-01   7.53288090e-01
    1.72509611e+00   8.17850053e-01   2.23337039e-01   1.01768076e+00
    3.74476409e+00   6.83894873e-01   8.80316615e-01   9.31297123e-01
    4.04716164e-01   2.07168221e-01   1.00955820e+00   1.36848617e+00
    1.02564812e+00   1.17419326e+00   1.36863065e+00   1.29697412e-01
   -4.66454595e-01   8.20116818e-01   1.00301695e+00   4.58802849e-01
    1.34776902e+00   1.13255477e+00   2.54690528e+00   1.65186274e+00
    5.44420302e-01   1.58268988e+00   1.11105192e+00   5.92414677e-01
    6.37074828e-01   1.06774676e+00   6.72796369e-03   4.17351514e-01
    1.02101624e+00   6.22386038e-01   8.81347299e-01   7.65643895e-01
    9.20441329e-01   4.22942638e-01   3.35879385e-01   1.52239978e+00
    9.69237506e-01   9.68998492e-01   1.14942789e+00   5.48401833e-01
    1.11036658e-01  -1.50415242e-01   7.06715047e-01   1.92358649e+00
    1.24110848e-01   1.31032073e+00   4.64365005e+00   1.39081240e-01
    7.46095002e-01   2.43674040e-01   8.36048841e-01   9.06247675e-01
    1.37194991e+00   1.21717608e+00   1.52022600e+00   4.28313494e-01
    1.51070547e+00   1.15095496e+00   6.08083069e-01   9.60501552e-01]]
After layer encoder_birnn_forward_l0_t5_o_output (1, 256) <class 'numpy.float32'> [[ 0.75940073  0.66586316  0.68406308  0.73824614  0.671875    0.73691016
   0.8845951   0.64871305  0.71880138  0.69604683  0.69185793  0.70888007
   0.65823537  0.79420042  0.47958454  0.57170016  0.71190166  0.61731941
   0.86327189  0.74485433  0.62907726  0.49266878  0.83683383  0.75236237
   0.66273606  0.60654223  0.80081135  0.71812642  0.54120016  0.68802363
   0.7501533   0.74843329  0.5270229   0.66352803  0.65922159  0.5965082
   0.71843696  0.58058876  0.3456279   0.62786847  0.64846891  0.67889023
   0.66127861  0.67859989  0.67867565  0.70417625  0.87612009  0.72463042
   0.67162222  0.54787546  0.40759638  0.71619225  0.9647674   0.4685877
   0.71177858  0.47108898  0.60580224  0.65905195  0.71945995  0.65736079
   0.5055238   0.64401227  0.53571409  0.78405905  0.60934848  0.681391
   0.77092719  0.63289011  0.67562371  0.64619195  0.731911    0.7083863
   0.85961384  0.68577296  0.64675641  0.94795585  0.69783682  0.94088566
   0.79533446  0.55743289  0.82169992  0.44899088  0.96613431  0.67506158
   0.7779631   0.6440205   0.61662537  0.72899061  0.89937246  0.73477918
   0.65270096  0.6780901   0.38545316  0.79326791  0.56430733  0.75847816
   0.7376675   0.7532497   0.74539721  0.82852596  0.58344913  0.64944768
   0.5625484   0.81695086  0.75371635  0.57779437  0.68175781  0.75571191
   0.76321042  0.56484473  0.81137347  0.70100087  0.90067309  0.88168937
   0.748631    0.69562435  0.70575792  0.85070938  0.6993776   0.73036247
   0.67200702  0.8553012   0.72117966  0.68631822  0.73939168  0.76150054
   0.53075373  0.52798182  0.64723885  0.92238337  0.73024809  0.83269578
   0.64110172  0.6872744   0.6164639   0.60248846  0.7567966   0.65615457
   0.79636002  0.70207715  0.60898292  0.70171809  0.68959701  0.71244133
   0.62326539  0.73312306  0.66048819  0.64992166  0.52873862  0.60446501
   0.87450677  0.60676706  0.72061545  0.51757133  0.59937859  0.48274457
   0.61777717  0.66289496  0.8457309   0.71207857  0.69600093  0.72944909
   0.57247972  0.74182171  0.81859595  0.58960456  0.70123369  0.58610713
   0.45278957  0.60968143  0.63637668  0.97533405  0.73760647  0.82327586
   0.4999541   0.58250678  0.67703462  0.71778578  0.62245077  0.77664477
   0.68068957  0.47261158  0.72413933  0.73698455  0.61695832  0.72987819
   0.69443595  0.61070997  0.71438372  0.78399444  0.47496694  0.67989475
   0.84878409  0.69377977  0.55560333  0.73452061  0.97690475  0.66460741
   0.70688784  0.71733838  0.59982026  0.55160761  0.7329337   0.79713547
   0.73607129  0.76390213  0.7971589   0.53237897  0.38545573  0.69426113
   0.73165137  0.61273015  0.79376465  0.75631011  0.9273653   0.83914268
   0.6328401   0.82958513  0.75232518  0.64391899  0.65409195  0.74416822
   0.50168204  0.6028493   0.73517048  0.65076107  0.70710135  0.68257785
   0.715132    0.60418719  0.58318925  0.82089156  0.72496754  0.72491986
   0.75940639  0.63376474  0.5277307   0.46246693  0.66967493  0.87253791
   0.53098792  0.78756678  0.99046928  0.5347144   0.6783272   0.56061888
   0.69763237  0.7122317   0.79769504  0.77156621  0.82057172  0.6054709
   0.81916577  0.75968534  0.64750344  0.7232222 ]]
After layer encoder_birnn_forward_l0_t5_f_output (1, 256) <class 'numpy.float32'> [[ 0.76014686  0.51872265  0.55278528  0.62708914  0.59343773  0.61159331
   0.7898711   0.59282637  0.86849517  0.58285844  0.78132278  0.63616592
   0.70777088  0.70044762  0.46206903  0.62316483  0.60639632  0.59407187
   0.75851834  0.66038483  0.54314035  0.45660767  0.77758598  0.5665248
   0.6759271   0.6549235   0.68356729  0.59505808  0.73965019  0.56207901
   0.73958212  0.70616901  0.63389963  0.6720838   0.80568665  0.6141482
   0.55649495  0.6476751   0.81608129  0.5214352   0.69604194  0.62587184
   0.78235638  0.46108967  0.52855301  0.43085665  0.79451555  0.65632248
   0.57452404  0.44771966  0.43238893  0.61123151  0.93810099  0.44570512
   0.75019801  0.42920297  0.58160651  0.63849968  0.65784985  0.68465281
   0.50724167  0.61982018  0.54916221  0.71656996  0.5626812   0.62275922
   0.6972518   0.72626603  0.62481987  0.80791789  0.47809026  0.63676757
   0.82292503  0.63834435  0.53424102  0.92811942  0.6075083   0.9174487
   0.7009424   0.3649824   0.73516631  0.37997517  0.9005239   0.69469839
   0.73044646  0.66581184  0.50024271  0.81720686  0.92508316  0.60358042
   0.57131171  0.65518379  0.49659958  0.65271384  0.45259434  0.52348822
   0.76622498  0.74692601  0.75231671  0.75691831  0.55431712  0.43274
   0.51723957  0.73399186  0.71430391  0.56649929  0.65721208  0.67567706
   0.62831509  0.6016596   0.73402005  0.79511786  0.84259444  0.88130379
   0.67681676  0.6430676   0.75285405  0.7731877   0.64080274  0.61844957
   0.65377849  0.80195761  0.67989492  0.62115288  0.75797862  0.66431534
   0.40503934  0.62112236  0.62758845  0.87883651  0.61786675  0.69840753
   0.55555195  0.57299817  0.62784111  0.73261529  0.70448869  0.37776142
   0.81114525  0.70952404  0.62148851  0.66031653  0.69976211  0.67600334
   0.68461651  0.74511266  0.58202714  0.65885574  0.76474357  0.66651553
   0.73273206  0.56803125  0.66569322  0.66974145  0.61583674  0.58104384
   0.75918543  0.5841912   0.79835647  0.66821539  0.78793722  0.64993668
   0.73591429  0.71107703  0.72757077  0.57915276  0.58779603  0.60890299
   0.45467007  0.56505299  0.43805742  0.88910037  0.63782191  0.81880844
   0.51990634  0.5539369   0.60334247  0.71729141  0.46336991  0.76674575
   0.59559131  0.46162444  0.74376625  0.68371236  0.61757392  0.66156495
   0.73890966  0.69615787  0.66658378  0.7204147   0.37967917  0.64588094
   0.77421796  0.68688482  0.4812645   0.59995902  0.98500896  0.45322835
   0.66589892  0.47830719  0.62823105  0.67743438  0.62262309  0.80994058
   0.65982175  0.58507049  0.7615785   0.38931653  0.5015111   0.71623385
   0.71555918  0.63473648  0.70742875  0.65917641  0.88119167  0.7915675
   0.56199646  0.7334193   0.51602751  0.51672214  0.564632    0.7020027
   0.46709657  0.70430309  0.62609917  0.81547159  0.39556205  0.6063695
   0.67660397  0.61091763  0.60340077  0.85848445  0.59426373  0.68191534
   0.74638265  0.67696089  0.55395091  0.55380017  0.5812977   0.83798605
   0.5668999   0.75363404  0.98357195  0.46393636  0.61367625  0.45503932
   0.5742532   0.62624061  0.68072391  0.71083289  0.82829082  0.46202388
   0.78560954  0.64147508  0.60649252  0.67758822]]
After layer _mul2062_0 (1, 256) <class 'numpy.float32'> [[  1.58872515e-01   1.79153606e-01  -3.06112081e-01  -1.71248183e-01
    4.48142886e-01  -6.90655038e-02   6.26705766e-01  -3.31563912e-02
   -1.42865598e-01  -5.80199920e-02   3.55611563e-01   3.22925329e-01
    8.39844570e-02  -4.72743690e-01   4.31762263e-02  -6.23661838e-03
    2.12523669e-01   3.40892851e-01  -7.17956349e-02   1.87083259e-01
   -1.09244980e-01  -2.54213601e-01  -6.22577131e-01   2.05280215e-01
   -1.27716303e-01  -7.83316493e-02  -5.17231822e-01  -4.29371707e-02
   -4.61940020e-01   2.30894461e-01   2.68488199e-01  -1.67103320e-01
    4.56330061e-01  -1.63623780e-01   8.77106130e-01   1.69055626e-01
    1.75137788e-01  -6.72379851e-01  -6.84492648e-01   4.03207019e-02
   -6.85325935e-02   4.23070192e-01  -1.58509776e-01   2.48370200e-01
   -5.24502456e-01  -1.43594965e-01  -1.41233718e-02   3.01306188e-01
    2.10277632e-01   8.95206183e-02   4.18309122e-03   1.09845418e-02
   -4.70656276e-01  -1.76442578e-01   6.78871036e-01   2.17429042e-01
   -4.65043724e-01  -8.27172026e-02   2.59424925e-01  -1.67536475e-02
    2.75828332e-01  -9.38925520e-02   7.48303607e-02   8.08408797e-01
   -2.38537401e-01   5.00408933e-02   2.97653645e-01   6.72953486e-01
    1.82388023e-01  -5.70821702e-01   1.48339719e-01   8.06902815e-03
   -9.15668070e-01   2.12608203e-01   2.68491745e-01   9.61342633e-01
    4.13330585e-01  -1.37298095e+00   3.32083404e-01  -2.08713427e-01
    6.28057897e-01  -1.88719884e-01  -3.95806916e-02   1.00779444e-01
   -2.91755110e-01  -4.36870754e-01   5.59176989e-02  -8.01857114e-01
    1.77018672e-01  -2.97393464e-02   2.20906258e-01   1.69818893e-01
   -2.75915802e-01  -1.99760094e-01  -2.75157422e-01  -1.06821440e-01
   -4.28643614e-01  -7.12798893e-01   3.88872296e-01   1.60103649e-01
   -2.26151407e-01  -2.01408342e-02  -1.75805073e-02   4.44123715e-01
   -3.75666112e-01  -3.26216608e-01   2.71662354e-01   2.70043075e-01
    2.27003291e-01   2.38467008e-01  -5.94611228e-01  -5.66228449e-01
    1.09505570e+00   1.15308809e+00  -1.90186858e-01   4.59046572e-01
    3.14141691e-01   1.57679379e-01   2.02183902e-01   6.85988367e-02
    3.41688059e-02  -5.66136539e-01   5.47079444e-01  -1.92472979e-01
    9.36718285e-01  -3.75846811e-02   2.84923315e-01   2.72729427e-01
   -4.23147053e-01  -1.00006688e+00   9.34806392e-02   4.31669563e-01
    1.34935379e-01  -8.92255977e-02   4.65063840e-01   5.86885035e-01
    1.67664215e-01   1.31226689e-01  -7.71789730e-01  -1.61542311e-01
   -2.47467216e-02   6.03495419e-01  -5.62763989e-01  -8.52070674e-02
    4.64402616e-01   1.46975610e-02   2.71870881e-01  -3.85030136e-02
    6.89232230e-01  -1.12144977e-01   7.36297965e-01  -3.13291699e-01
    7.17880785e-01   3.86249125e-01   1.34547859e-01  -4.79413062e-01
    6.71614230e-01  -4.41753976e-02   4.95432794e-01   3.75953048e-01
    9.96031225e-01   1.04400523e-01   2.35857293e-01   5.12407780e-01
   -1.71107024e-01   1.24877222e-01  -2.64951698e-02   4.31626499e-01
   -1.80954948e-01  -2.64856845e-01   6.23548180e-02   1.46079779e+00
   -1.91236943e-01   8.57417107e-01  -2.66121060e-01  -3.76421958e-01
    7.08921775e-02   8.23538452e-02  -1.38510361e-01  -9.96183529e-02
    5.44867039e-01   2.69941449e-01   2.95511246e-01   3.25007081e-01
   -1.71035491e-02  -3.88057798e-01  -2.30578691e-01   5.64041793e-01
    2.43911013e-01  -2.93795973e-01   1.87382028e-01  -3.49983841e-01
   -5.81618965e-01   4.72973198e-01   1.02239519e-01  -5.14271498e-01
   -1.83794573e-01  -3.40189964e-01   3.97236943e-01  -4.33413796e-02
    6.05690032e-02  -4.76870030e-01  -4.80856568e-01  -3.82131547e-01
   -1.57932922e-01  -7.43910074e-02   5.53764105e-01   3.29972543e-02
    1.10909142e-01   1.02481373e-01  -2.02031866e-01   2.68709421e-01
    2.84793913e-01   2.01908469e-01   1.10154223e+00  -6.18972659e-01
   -2.32352644e-01  -6.30033910e-01  -1.35776415e-01  -1.29411146e-01
   -1.33344784e-01   3.15517515e-01   2.96010613e-01  -6.26645088e-01
    1.55636713e-01  -1.12681854e+00  -2.51872420e-01  -1.59495905e-01
    1.98085129e-01  -2.23466810e-02  -1.30407229e-01  -1.08978796e+00
   -1.45260125e-01   5.94621003e-01  -3.78548473e-01   6.86686602e-04
    3.82693648e-01   1.87898621e-01  -9.19770598e-02   9.77191925e-01
    2.83518493e-01   5.76567471e-01  -1.71388459e+00  -3.08612347e-01
    4.73489910e-01  -2.13601515e-01   1.64103508e-01  -1.45303026e-01
   -4.37994123e-01   2.97644109e-01  -8.68127286e-01  -4.62538376e-02
   -3.99237216e-01  -2.95112669e-01  -1.35730756e-02   2.29339033e-01]]
After layer encoder_birnn_forward_l0_t5_i_output (1, 256) <class 'numpy.float32'> [[ 0.64134979  0.61937237  0.59513927  0.59078491  0.69506067  0.68979478
   0.80568355  0.51825643  0.40171233  0.6305607   0.60759288  0.68498003
   0.48481408  0.7256211   0.4049961   0.55562371  0.59699464  0.65131968
   0.68616194  0.60525471  0.49258786  0.29363859  0.63562328  0.60307926
   0.56435698  0.55404186  0.71415043  0.50792354  0.67640144  0.66844934
   0.66550869  0.65477192  0.74541843  0.65527439  0.85305429  0.51834947
   0.58599627  0.86479932  0.77968639  0.34839895  0.42560282  0.63838989
   0.74577755  0.55901289  0.84030169  0.64046192  0.59229487  0.66147625
   0.55960542  0.4577831   0.42951375  0.42871878  0.96302164  0.58735567
   0.78167969  0.52772731  0.74509108  0.5049153   0.60378557  0.27080476
   0.60379386  0.60442251  0.47382021  0.77075845  0.50979269  0.53991646
   0.69748735  0.81169152  0.67620713  0.77071887  0.45281017  0.28177968
   0.86578578  0.64683855  0.6301263   0.8692075   0.6924355   0.93146396
   0.64273983  0.39662915  0.74552411  0.63182104  0.67643291  0.46315512
   0.75348437  0.68707979  0.58809483  0.82118517  0.77037168  0.43859699
   0.63788414  0.45298317  0.44709101  0.63505483  0.38664684  0.32537276
   0.75727248  0.77851194  0.73767799  0.63897967  0.56180805  0.42264712
   0.60858643  0.79545265  0.70950681  0.57051945  0.52765739  0.57455951
   0.49470857  0.56031162  0.77583104  0.74084836  0.90474713  0.94094104
   0.68620056  0.72483087  0.63461196  0.73603421  0.56553835  0.44506809
   0.44005406  0.76237285  0.86354977  0.599976    0.8618443   0.56826758
   0.60780233  0.61145771  0.57722849  0.88332564  0.40396267  0.71580452
   0.61068523  0.55880082  0.72796416  0.66602445  0.67374635  0.35147661
   0.69736129  0.47860974  0.51568043  0.77476054  0.6934002   0.51068348
   0.65396595  0.34310213  0.50799757  0.39802185  0.73778003  0.46842343
   0.84073699  0.70388305  0.83748072  0.77674556  0.52006495  0.74102098
   0.66895008  0.42259774  0.75132573  0.71330947  0.87547463  0.45430586
   0.69899714  0.722036    0.67656285  0.51025212  0.53937709  0.64005959
   0.47348604  0.60498333  0.38828811  0.98015976  0.61205512  0.80199844
   0.66569823  0.57901555  0.45356479  0.37771016  0.47927564  0.59953481
   0.7980113   0.61793947  0.63746804  0.57729727  0.43326068  0.65508872
   0.52328527  0.75519079  0.67758155  0.65666366  0.37195569  0.54844123
   0.82111013  0.60178047  0.6234917   0.75158703  0.96061355  0.77993548
   0.67542368  0.54541051  0.57925594  0.71949744  0.64646226  0.66074681
   0.64816189  0.49566591  0.70900279  0.40932131  0.41632023  0.61203414
   0.67336953  0.59723955  0.74724913  0.61873507  0.89056844  0.74730992
   0.58724123  0.79768115  0.64320338  0.39840487  0.56431794  0.59904718
   0.63740528  0.6797111   0.65075016  0.9485743   0.68280417  0.48270658
   0.50822639  0.51448166  0.35574198  0.92915487  0.59971607  0.78172946
   0.65743101  0.4837155   0.61971909  0.42025983  0.54668236  0.82301706
   0.57135165  0.70718479  0.98668939  0.63576722  0.75363934  0.67586482
   0.60444939  0.57496554  0.69714934  0.61474454  0.8306601   0.36340183
   0.74910575  0.65435219  0.40112931  0.60333365]]
After layer encoder_birnn_forward_l0_t5_c_output (1, 256) <class 'numpy.float32'> [[ 0.30873752  0.55384862 -0.84149897 -0.42530772  0.93003041 -0.17271696
   0.89637679  0.04634342 -0.46467021 -0.09531777  0.72605634  0.76241034
   0.2629599  -0.85322946  0.15051228  0.02282295  0.5806402   0.82808238
  -0.1067311   0.50260842 -0.26286444 -0.98091376 -0.96344984  0.63699508
  -0.23983027 -0.17727187 -0.9146378  -0.0424298  -0.86432266  0.71041107
   0.5870406  -0.37415156  0.84111518 -0.48432824  0.98182422  0.53754711
   0.55876684 -0.98071057 -0.93009263 -0.02503274 -0.07534235  0.9465766
  -0.18785204  0.88479447 -0.9920224  -0.59399194 -0.10617334  0.62589967
   0.65760076  0.45139939 -0.0578201   0.00249396 -0.73384631 -0.67982602
   0.94740415  0.79967284 -0.96562302 -0.21377108  0.76871878  0.04736596
   0.87580502 -0.14939851  0.25505283  0.99770683 -0.77106059  0.12601116
   0.72431344  0.93577182  0.4689329  -0.89738005  0.6332162   0.14384028
  -0.97766829  0.48508447  0.75159276  0.94935954  0.90588403 -0.99573421
   0.7390579  -0.95911902  0.96598035 -0.77419817 -0.19059898  0.20533165
  -0.5413965  -0.91016537  0.2915591  -0.9623419   0.18917429 -0.16376798
   0.71902311  0.49757531 -0.93296975 -0.53084123 -0.98662609 -0.61219078
  -0.73913896 -0.97369838  0.72040874  0.25055984 -0.77431428 -0.12451042
   0.00302421  0.75236201 -0.647735   -0.89867359  0.59417945  0.57466102
   0.55353367  0.66663277 -0.93099493 -0.8838411   0.99197972  0.98587805
  -0.26753777  0.9080264   0.61098009  0.23654009  0.52800632  0.14962676
   0.19252461 -0.83946782  0.90189999 -0.55627632  0.99263489 -0.29823387
   0.97131956  0.706985   -0.93957847 -0.97773498  0.33957106  0.78802097
   0.46087128 -0.30511603  0.91283548  0.95186621  0.51784843  0.84908432
  -0.97382897 -0.52771699  0.01164568  0.97254145 -0.94837117 -0.17927589
   0.92471248 -0.00643673  0.82311618  0.02708142  0.97213924 -0.2421301
   0.97790015 -0.76131719  0.98774743  0.84703231  0.41788462 -0.9662959
   0.97361147 -0.0595579   0.8290875   0.8345809   0.99644971  0.08486291
   0.43534324  0.89531612 -0.25896928  0.30111662 -0.06823687  0.92306209
  -0.71747106 -0.71501935  0.3186633   0.99754024 -0.50513166  0.98357761
  -0.80806506 -0.96359366  0.2385499   0.18429318 -0.64086151 -0.24644664
   0.96898186  0.8970862   0.59925228  0.73169398 -0.0150577  -0.81563389
  -0.5566721   0.9463349   0.63795698 -0.65103424  0.95082009 -0.82622635
  -0.87705791  0.93815058  0.38021028 -0.96442437 -0.35065973 -0.93428171
   0.83906472 -0.28612366  0.02040204 -0.87212402 -0.97623801 -0.71099502
  -0.30835983 -0.2848523   0.92794961  0.09527702  0.46485731  0.14389215
  -0.43462944  0.66263992  0.61964053  0.48767444  0.98859262 -0.92531568
  -0.72399163 -0.94703269 -0.51213062 -0.61701334 -0.45139644  0.66859484
   0.90887088 -0.98009825  0.41329023 -0.99349898 -0.91267359 -0.45850599
   0.44095978 -0.03569839 -0.48810208 -0.97730476 -0.35564917  0.95968598
  -0.70100182 -0.04706107  0.92775196  0.6902746  -0.18236811  0.99600059
   0.86331975  0.89612657 -0.99699098 -0.94986814  0.93674093 -0.76226169
   0.48475587 -0.38570079 -0.84559774  0.71428776 -0.95413172 -0.2008525
  -0.67363346 -0.65488279 -0.11919272  0.48540288]]
After layer _mul2063_0 (1, 256) <class 'numpy.float32'> [[ 0.19800875  0.34303853 -0.50080907 -0.25126538  0.64642757 -0.11913925
   0.72219604  0.02401778 -0.18666375 -0.06010364  0.44114667  0.52223587
   0.12748666 -0.61912131  0.06095688  0.01268097  0.3466391   0.53934634
  -0.07323482  0.3042061  -0.12948383 -0.28803414 -0.61239111  0.38415852
  -0.13534988 -0.09821604 -0.653189   -0.02155109 -0.58462912  0.47487381
   0.39068061 -0.24498394  0.62698275 -0.31736788  0.83754933  0.27863726
   0.32743528 -0.84811783 -0.72518057 -0.00872138 -0.03206592  0.60428494
  -0.14009583  0.4946115  -0.83359808 -0.38042921 -0.06288593  0.41401777
   0.36799696  0.20664302 -0.02483453  0.00106921 -0.70670986 -0.39929968
   0.74056655  0.4220092  -0.71947712 -0.10793629  0.46414131  0.01282693
   0.52880567 -0.09029982  0.12084918  0.76899099 -0.39308104  0.0680355
   0.50519949  0.75955808  0.31709576 -0.69162774  0.28672674  0.04053127
  -0.84645128  0.31377134  0.47359836  0.82519042  0.62726629 -0.92749053
   0.47502196 -0.38041458  0.72016162 -0.4891547  -0.12892742  0.09510041
  -0.4079338  -0.62535626  0.1714644  -0.79026091  0.14573452 -0.07182814
   0.45865345  0.22539324 -0.41712239 -0.33711329 -0.38147587 -0.1991902
  -0.55972958 -0.75803584  0.53142965  0.16010264 -0.43501601 -0.05262397
   0.0018405   0.59846836 -0.4595724  -0.51271075  0.31352317  0.33017695
   0.27383786  0.37352207 -0.72229475 -0.65479225  0.8974908   0.92765313
  -0.18358457  0.65816557  0.38773528  0.17410161  0.29860783  0.06659409
   0.08472124 -0.63998747  0.77883554 -0.33375245  0.8554967  -0.16947664
   0.5903703   0.43229142 -0.54235148 -0.86365837  0.13717403  0.56406897
   0.28144729 -0.17049909  0.6645115   0.63396615  0.3488985   0.29843327
  -0.67911065 -0.25257048  0.00600545  0.75348675 -0.65760076 -0.09155323
   0.60473049 -0.00220846  0.41814104  0.010779    0.7172249  -0.11341941
   0.82215685 -0.53587824  0.82721943  0.65792859  0.21732715 -0.71604556
   0.65129745 -0.02516904  0.62291479  0.59531444  0.87236643  0.03855372
   0.30430368  0.64645046 -0.17520899  0.1536454  -0.0368054   0.59081477
  -0.33971253 -0.43257478  0.12373317  0.97774881 -0.30916843  0.78882772
  -0.53792745 -0.55793571  0.10819784  0.06960941 -0.30714932 -0.14775334
   0.77325851  0.55434495  0.38200417  0.42240494 -0.00652391 -0.53431255
  -0.2912983   0.71466339  0.43226787 -0.42751053  0.35366294 -0.45313659
  -0.72016114  0.56456071  0.23705795 -0.72484887 -0.3368485  -0.72867948
   0.56672418 -0.15605485  0.011818   -0.627491   -0.63110101 -0.46978769
  -0.19986708 -0.14119157  0.65791887  0.03899891  0.1935295   0.08806691
  -0.29266623  0.39575475  0.46302584  0.30174127  0.88040936 -0.69149756
  -0.42515773 -0.7554301  -0.32940415 -0.24582112 -0.25473112  0.40051985
   0.57931912 -0.66618365  0.26894867 -0.94240761 -0.62317735 -0.22132386
   0.2241074  -0.01836617 -0.1736384  -0.90806746 -0.21328853  0.75021482
  -0.46086034 -0.02276417  0.57494557  0.29009467 -0.09969743  0.81972545
   0.49325916  0.63372707 -0.98372042 -0.60389501  0.7059648  -0.51518583
   0.29301038 -0.22176467 -0.58950788  0.4391045  -0.79255915 -0.07299016
  -0.5046227  -0.42852399 -0.04781169  0.29285988]]
After layer encoder_birnn_forward_l0_t5_state_0 (1, 256) <class 'numpy.float32'> [[ 0.35688126  0.52219212 -0.80692112 -0.42251354  1.0945704  -0.18820477
   1.34890175 -0.00913862 -0.32952935 -0.11812363  0.79675823  0.8451612
   0.21147111 -1.09186506  0.10413311  0.00644435  0.55916274  0.88023919
  -0.14503045  0.49128938 -0.23872882 -0.54224777 -1.23496819  0.58943874
  -0.26306617 -0.17654769 -1.17042089 -0.06448826 -1.04656911  0.70576829
   0.65916884 -0.41208726  1.08331275 -0.48099166  1.7146554   0.44769287
   0.50257307 -1.52049768 -1.40967321  0.03159932 -0.10059851  1.02735519
  -0.29860562  0.74298167 -1.35810053 -0.52402419 -0.0770093   0.71532393
   0.57827461  0.29616362 -0.02065144  0.01205375 -1.17736614 -0.57574224
   1.41943765  0.63943827 -1.18452084 -0.19065349  0.72356623 -0.00392672
   0.80463398 -0.18419237  0.19567955  1.57739973 -0.63161844  0.11807639
   0.80285311  1.43251157  0.49948376 -1.2624495   0.43506646  0.0486003
  -1.76211929  0.52637953  0.74209011  1.78653312  1.04059684 -2.30047154
   0.80710536 -0.58912802  1.34821951 -0.67787457 -0.16850811  0.19587985
  -0.69968891 -1.06222701  0.22738209 -1.59211802  0.32275319 -0.10156749
   0.67955971  0.39521211 -0.69303823 -0.5368734  -0.65663326 -0.30601165
  -0.98837316 -1.47083473  0.92030191  0.32020628 -0.66116738 -0.07276481
  -0.01574001  1.04259205 -0.83523852 -0.83892739  0.58518553  0.60022002
   0.50084114  0.61198908 -1.31690598 -1.2210207   1.99254656  2.08074117
  -0.37377143  1.11721218  0.701877    0.33178097  0.50079173  0.13519293
   0.11889005 -1.20612407  1.32591498 -0.52622545  1.79221499 -0.20706132
   0.87529361  0.70502084 -0.96549857 -1.86372519  0.23065466  0.99573851
   0.41638267 -0.25972468  1.12957537  1.22085118  0.5165627   0.42965996
  -1.45090032 -0.41411281 -0.01874127  1.35698223 -1.22036481 -0.1767603
   1.06913304  0.0124891   0.69001192 -0.02772402  1.40645719 -0.22556439
   1.55845475 -0.84916997  1.54510021  1.04417777  0.35187501 -1.19545865
   1.32291174 -0.06934443  1.11834764  0.97126746  1.86839771  0.14295425
   0.54016095  1.1588583  -0.34631601  0.27852261 -0.06330057  1.02244127
  -0.52066749 -0.69743162  0.186088    2.43854666 -0.50040537  1.64624476
  -0.80404854 -0.93435764  0.17909002  0.15196326 -0.4456597  -0.2473717
   1.31812549  0.8242864   0.67751539  0.74741203 -0.02362746 -0.92237031
  -0.52187699  1.27870512  0.67617887 -0.7213065   0.54104495 -0.80312043
  -1.3017801   1.03753388  0.33929747 -1.23912036 -0.52064306 -1.06886947
   0.96396112 -0.19939624  0.07238701 -1.10436106 -1.11195755 -0.85191923
  -0.35780001 -0.21558258  1.21168303  0.07199617  0.30443865  0.19054829
  -0.49469811  0.66446418  0.74781978  0.50364971  1.98195159 -1.31047022
  -0.6575104  -1.38546395 -0.46518058 -0.37523228 -0.38807589  0.71603739
   0.87532973 -1.2928288   0.4245854  -2.06922626 -0.87504977 -0.38081977
   0.42219251 -0.04071285 -0.30404562 -1.99785542 -0.35854864  1.34483576
  -0.83940881 -0.02207748  0.95763922  0.47799331 -0.1916745   1.79691744
   0.77677763  1.21029449 -2.69760513 -0.91250736  1.17945468 -0.72878736
   0.45711389 -0.36706769 -1.02750206  0.73674858 -1.66068649 -0.119244
  -0.90385991 -0.72363663 -0.06138477  0.52219892]]
After layer activation1031_output (1, 256) <class 'numpy.float32'> [[ 0.342464    0.47939011 -0.66788828 -0.39904585  0.79854023 -0.18601367
   0.87379384 -0.00913836 -0.3180978  -0.11757728  0.66222054  0.68853313
   0.20837417 -0.79755783  0.10375835  0.00644426  0.50735605  0.70653915
  -0.14402209  0.45523921 -0.23429471 -0.49468756 -0.84401441  0.52949178
  -0.25716117 -0.17473601 -0.82440704 -0.06439901 -0.78046894  0.60801637
   0.57780999 -0.39024353  0.79442441 -0.44703746  0.93721622  0.4200007
   0.46413833 -0.90878433 -0.88742471  0.03158881 -0.10026053  0.77284539
  -0.29003602  0.63094324 -0.87595177 -0.48079988 -0.07685743  0.61400449
   0.52141023  0.28779787 -0.0206485   0.01205316 -0.82661927 -0.51956391
   0.88948154  0.56451696 -0.82887179 -0.18837659  0.61911345 -0.0039267
   0.66661942 -0.18213725  0.19321966  0.91819483 -0.5591656   0.1175307
   0.66562879  0.89218014  0.46171105 -0.85173798  0.40954673  0.04856207
  -0.94273925  0.48260871  0.63040626  0.9453935   0.77812362 -0.980115
   0.66799033 -0.52926821  0.87363237 -0.59013593 -0.16693109  0.19341248
  -0.60417032 -0.7865147   0.22354273 -0.92047346  0.31199422 -0.10121968
   0.59123313  0.37584484 -0.59993029 -0.4906176  -0.57611847 -0.2968044
  -0.75666779 -0.89973658  0.72604024  0.30969343 -0.57913977 -0.07263666
  -0.01573871  0.77890956 -0.6832788  -0.68524051  0.52642417  0.53720605
   0.46277842  0.54552573 -0.86601245 -0.83995503  0.96349716  0.96930939
  -0.35728613  0.80659699  0.6055578   0.32012013  0.46273959  0.13437526
   0.11833303 -0.83551306  0.86824739 -0.48249051  0.94599384 -0.204152
   0.70405376  0.60754508 -0.74671948 -0.95302182  0.22664948  0.75979865
   0.39387867 -0.25403801  0.81087387  0.83990508  0.47504273  0.40503711
  -0.89587075 -0.39195925 -0.01873907  0.87569129 -0.83976173 -0.17494212
   0.78913438  0.01248846  0.59798962 -0.02771692  0.88673943 -0.22181515
   0.91516978 -0.69063556  0.9129734   0.77953249  0.33803734 -0.83226418
   0.86750621 -0.06923349  0.80699337  0.74926078  0.95344865  0.14198835
   0.49310979  0.82066745 -0.33310434  0.27153715 -0.06321616  0.770859
  -0.47821501 -0.60273504  0.18396935  0.98487699 -0.4624359   0.92834049
  -0.66629404 -0.73261911  0.17719962  0.15080422 -0.41832477 -0.24244644
   0.86631703  0.67739618  0.58990175  0.63360244 -0.02362306 -0.72701681
  -0.47914737  0.85613954  0.58902967 -0.61771792  0.49377856 -0.66577768
  -0.86218071  0.77691233  0.32685006 -0.84520453 -0.47819614 -0.7890349
   0.74603856 -0.19679502  0.07226084 -0.80206007 -0.8047533  -0.69207078
  -0.34327474 -0.21230373  0.83718359  0.07187203  0.2953693   0.18827511
  -0.4579373   0.58132666  0.6338464   0.4649826   0.96272999 -0.86439431
  -0.57670426 -0.88216889 -0.43429711 -0.35855982 -0.36970028  0.61444879
   0.70407188 -0.85986561  0.40078637 -0.96860564 -0.70393074 -0.36341918
   0.39877591 -0.04069037 -0.29501051 -0.96387577 -0.34393498  0.87282884
  -0.68549585 -0.0220739   0.743222    0.44463509 -0.18936118  0.94648588
   0.65085328  0.83676779 -0.99096447 -0.72233355  0.82727957 -0.62232292
   0.42772904 -0.35142419 -0.77290452  0.62717676 -0.93030959 -0.11868202
  -0.71817213 -0.61915684 -0.06130779  0.47939533]]
After layer encoder_birnn_forward_l0_t5_out_0 (1, 256) <class 'numpy.float32'> [[ 0.2600674   0.3192082  -0.45687771 -0.29459405  0.53651923 -0.13707536
   0.77295375 -0.00592817 -0.22864914 -0.08183929  0.45816255  0.48808742
   0.13715926 -0.63342077  0.0497609   0.00368419  0.36118761  0.43616033
  -0.12433022  0.33908689 -0.14738947 -0.24371712 -0.70629984  0.3983697
  -0.17042997 -0.10598477 -0.66019452 -0.04624663 -0.42238992  0.41832963
   0.43344608 -0.29207125  0.41867986 -0.29662189  0.6178332   0.25053388
   0.33345413 -0.52762997 -0.30671874  0.01983362 -0.06501584  0.52467716
  -0.19179462  0.42815802 -0.59448713 -0.33856785 -0.06733634  0.44492632
   0.3501907   0.1576774  -0.00841626  0.00863238 -0.79749531 -0.24346125
   0.63311392  0.26593772 -0.50213236 -0.12414996  0.44542733 -0.00258126
   0.336992   -0.11729863  0.10351049  0.71991897 -0.3407267   0.08008436
   0.51315135  0.56465197  0.31194293 -0.55038625  0.29975176  0.03440071
  -0.81039172  0.33096001  0.40771928  0.8961913   0.54300332 -0.92217612
   0.53127575 -0.29503152  0.71786362 -0.26496565 -0.16127786  0.13056533
  -0.47002223 -0.5065316   0.13784212 -0.67101651  0.28059903 -0.07437411
   0.38589844  0.25485665 -0.23124503 -0.38919121 -0.32510787 -0.22511965
  -0.55816925 -0.67772633  0.54118836  0.25658906 -0.33789858 -0.04717371
  -0.00885379  0.63633084 -0.51499838 -0.39592811  0.35889378  0.40597302
   0.35319731  0.30813733 -0.70265955 -0.58880919  0.86779594  0.85462976
  -0.26747546  0.5610885   0.42737722  0.27232918  0.32362971  0.09814265
   0.07952063 -0.71461535  0.62616235 -0.33114204  0.69945997 -0.15546186
   0.37367916  0.32077277 -0.48330587 -0.87905151  0.16551036  0.63268113
   0.2525163  -0.17459382  0.49987447  0.50603312  0.35951072  0.26576695
  -0.71343565 -0.27518564 -0.01141178  0.61448842 -0.57909715 -0.12463599
   0.49184015  0.00915558  0.39496508 -0.01801382  0.46885338 -0.1340795
   0.80032218 -0.4190549   0.65790272  0.40346366  0.20261234 -0.40177101
   0.53592551 -0.04589453  0.68249923  0.53353256  0.66360116  0.10357328
   0.28229535  0.60878891 -0.27267787  0.16009955 -0.0443293   0.45180595
  -0.21653077 -0.36747637  0.1170738   0.96058404 -0.34109572  0.76428032
  -0.33311644 -0.42675561  0.11997028  0.10824513 -0.26038659 -0.18829475
   0.58969295  0.32014528  0.42717105  0.46695521 -0.01457444 -0.53063369
  -0.33273718  0.52285296  0.42079321 -0.48428741  0.2345285  -0.45265874
  -0.73180526  0.53900605  0.18159898 -0.62082016 -0.46715209 -0.52439845
   0.52736557 -0.14116862  0.04334352 -0.44242245 -0.58983082 -0.55167419
  -0.25267467 -0.16217928  0.66736835  0.03826316  0.11385179  0.13071209
  -0.33505046  0.35619637  0.50312489  0.35167104  0.89280242 -0.72535014
  -0.36496159 -0.73183417 -0.32673267 -0.23088348 -0.24181798  0.45725325
   0.35322022 -0.51836938  0.29464632 -0.63033086 -0.49775037 -0.24806188
   0.28517741 -0.0245846  -0.17204696 -0.79123747 -0.2493417   0.63273096
  -0.52056992 -0.01398966  0.39222106  0.20562902 -0.12681043  0.82584482
   0.34559524  0.65901053 -0.98151988 -0.38624215  0.56116623 -0.34888598
   0.29839763 -0.25029543 -0.6165421   0.48390839 -0.76338577 -0.07185851
  -0.58830202 -0.47036436 -0.039697    0.34670934]]
After layer expand_dims1037_0 (1, 1, 256) <class 'numpy.float32'> [[[ 0.2600674   0.3192082  -0.45687771 -0.29459405  0.53651923 -0.13707536
    0.77295375 -0.00592817 -0.22864914 -0.08183929  0.45816255  0.48808742
    0.13715926 -0.63342077  0.0497609   0.00368419  0.36118761  0.43616033
   -0.12433022  0.33908689 -0.14738947 -0.24371712 -0.70629984  0.3983697
   -0.17042997 -0.10598477 -0.66019452 -0.04624663 -0.42238992  0.41832963
    0.43344608 -0.29207125  0.41867986 -0.29662189  0.6178332   0.25053388
    0.33345413 -0.52762997 -0.30671874  0.01983362 -0.06501584  0.52467716
   -0.19179462  0.42815802 -0.59448713 -0.33856785 -0.06733634  0.44492632
    0.3501907   0.1576774  -0.00841626  0.00863238 -0.79749531 -0.24346125
    0.63311392  0.26593772 -0.50213236 -0.12414996  0.44542733 -0.00258126
    0.336992   -0.11729863  0.10351049  0.71991897 -0.3407267   0.08008436
    0.51315135  0.56465197  0.31194293 -0.55038625  0.29975176  0.03440071
   -0.81039172  0.33096001  0.40771928  0.8961913   0.54300332 -0.92217612
    0.53127575 -0.29503152  0.71786362 -0.26496565 -0.16127786  0.13056533
   -0.47002223 -0.5065316   0.13784212 -0.67101651  0.28059903 -0.07437411
    0.38589844  0.25485665 -0.23124503 -0.38919121 -0.32510787 -0.22511965
   -0.55816925 -0.67772633  0.54118836  0.25658906 -0.33789858 -0.04717371
   -0.00885379  0.63633084 -0.51499838 -0.39592811  0.35889378  0.40597302
    0.35319731  0.30813733 -0.70265955 -0.58880919  0.86779594  0.85462976
   -0.26747546  0.5610885   0.42737722  0.27232918  0.32362971  0.09814265
    0.07952063 -0.71461535  0.62616235 -0.33114204  0.69945997 -0.15546186
    0.37367916  0.32077277 -0.48330587 -0.87905151  0.16551036  0.63268113
    0.2525163  -0.17459382  0.49987447  0.50603312  0.35951072  0.26576695
   -0.71343565 -0.27518564 -0.01141178  0.61448842 -0.57909715 -0.12463599
    0.49184015  0.00915558  0.39496508 -0.01801382  0.46885338 -0.1340795
    0.80032218 -0.4190549   0.65790272  0.40346366  0.20261234 -0.40177101
    0.53592551 -0.04589453  0.68249923  0.53353256  0.66360116  0.10357328
    0.28229535  0.60878891 -0.27267787  0.16009955 -0.0443293   0.45180595
   -0.21653077 -0.36747637  0.1170738   0.96058404 -0.34109572  0.76428032
   -0.33311644 -0.42675561  0.11997028  0.10824513 -0.26038659 -0.18829475
    0.58969295  0.32014528  0.42717105  0.46695521 -0.01457444 -0.53063369
   -0.33273718  0.52285296  0.42079321 -0.48428741  0.2345285  -0.45265874
   -0.73180526  0.53900605  0.18159898 -0.62082016 -0.46715209 -0.52439845
    0.52736557 -0.14116862  0.04334352 -0.44242245 -0.58983082 -0.55167419
   -0.25267467 -0.16217928  0.66736835  0.03826316  0.11385179  0.13071209
   -0.33505046  0.35619637  0.50312489  0.35167104  0.89280242 -0.72535014
   -0.36496159 -0.73183417 -0.32673267 -0.23088348 -0.24181798  0.45725325
    0.35322022 -0.51836938  0.29464632 -0.63033086 -0.49775037 -0.24806188
    0.28517741 -0.0245846  -0.17204696 -0.79123747 -0.2493417   0.63273096
   -0.52056992 -0.01398966  0.39222106  0.20562902 -0.12681043  0.82584482
    0.34559524  0.65901053 -0.98151988 -0.38624215  0.56116623 -0.34888598
    0.29839763 -0.25029543 -0.6165421   0.48390839 -0.76338577 -0.07185851
   -0.58830202 -0.47036436 -0.039697    0.34670934]]]
After layer encoder_birnn_forward_l0_t6_i2h_output (1, 1024) <class 'numpy.float32'> [[ 0.07376467 -0.04585483  0.06153381 ...,  0.03591035  0.03396329
   0.02903319]]
After layer encoder_birnn_forward_l0_t6_h2h_output (1, 1024) <class 'numpy.float32'> [[ 0.76304376  0.76070094  0.50576538 ...,  1.56631768  0.79991269
   1.27552199]]
After layer _plus1032_0 (1, 1024) <class 'numpy.float32'> [[ 0.83680844  0.71484613  0.56729919 ...,  1.60222805  0.83387595
   1.30455518]]
After layer encoder_birnn_forward_l0_t6_slice_output0 (1, 256) <class 'numpy.float32'> [[ 0.83680844  0.71484613  0.56729919  0.53103155  1.14722264  1.08208716
   2.02953053  0.09046578 -0.65275609  0.73009592  0.65826094  1.13818741
  -0.12105847  1.35358179 -0.6094259   0.29161161  0.48571441  0.88960624
   1.07652521  0.58816075 -0.02480304 -1.26774132  0.72622049  0.52698916
   0.32261336  0.33274329  1.22816885 -0.01644384  1.01637971  1.07369113
   0.93958372  0.78593379  1.48264086  0.94518566  2.5519762   0.13574281
   0.45233747  2.55981946  1.80235636 -1.05209696 -0.4607434   0.79018009
   1.65888059  0.19314221  2.41478777  0.76369506  0.50618368  0.89970767
   0.34881344 -0.26203242 -0.35521954 -0.41918111  4.66219711  0.47247458
   1.80994701  0.06040299  1.55610788  0.11983679  0.6265015  -1.39232779
   0.55277699  0.46533161 -0.20808528  1.74817038  0.06322723  0.21736522
   1.21914053  2.04979968  1.00875866  1.73005259 -0.30199766 -1.35228729
   2.65880752  0.84477717  0.66920567  2.70734906  1.12366831  3.72215319
   0.87126273 -0.77834696  1.59498501  0.72681278  0.99754888 -0.20447437
   1.56547415  1.08757699  0.51931661  2.21351695  1.69243944 -0.33695757
   0.88714486 -0.26463807 -0.29251391  0.80831331 -0.72755694 -1.17261255
   1.5643394   1.82839704  1.45066333  0.77103251  0.40586251 -0.46669057
   0.61302817  1.93756211  1.15895653  0.3638269   0.13986638  0.35455382
  -0.13679919  0.22263582  1.72183442  1.48058975  3.17244864  3.91032529
   1.08332896  1.35681915  0.6917659   1.42071199  0.37378728 -0.39127207
  -0.35076526  1.68919778  2.67249942  0.61940295  2.52183247  0.3515633
   0.65055972  0.70337516  0.41073304  2.77802134 -0.53847402  1.34448063
   0.73093665  0.3533037   1.41314411  1.07062352  0.99804282 -0.89149004
   1.17371798 -0.0858601   0.15336797  1.77554643  1.16463125  0.03907481
   0.91351902 -0.92378038  0.06515244 -0.45875636  1.50669098 -0.20218612
   2.34254837  1.2732774   2.38274097  1.79265726  0.1362388   1.5114516
   0.98046184 -0.38878226  1.50833714  1.27048147  2.69576764 -0.271512
   1.18357062  1.36950326  1.07449746 -0.01675498  0.22017707  0.83130312
  -0.20137349  0.57312191 -0.66730744  5.55109406  0.62768137  1.90458119
   0.9598735   0.38464159 -0.30875772 -0.68048996 -0.04963624  0.60811126
   1.93618667  0.62172401  0.76476455  0.43418309 -0.35489032  0.90102899
   0.17628871  1.57356298  1.08664906  0.90191919 -0.74468756  0.26929867
   2.06490898  0.60017633  0.65840316  1.56509411  4.46316195  1.8074888
   1.06725991  0.22311264  0.42703378  1.29500163  0.86585444  1.04650784
   0.8490206  -0.01101869  1.25534916 -0.56213546 -0.57986665  0.6321215
   1.04594135  0.58171409  1.66741586  0.72572207  2.96785069  1.60318363
   0.52439982  2.01499104  0.81416839 -0.63613844  0.40759468  0.55969614
   0.74540651  1.05337703  0.89181989  4.19318295  1.03032303 -0.16992016
  -0.02275655 -0.00942652 -0.78579468  3.57441282  0.5717296   1.8302474
   1.03525233 -0.10813136  0.60785735 -0.45747557  0.13226855  2.22774935
   0.43450445  1.17386675  6.13038683  0.81291306  1.51294124  1.01443672
   0.59295869  0.40806264  1.21837544  0.62257874  2.23066545 -0.85320884
   1.49256396  0.86263496 -0.51151806  0.57404262]]
After layer encoder_birnn_forward_l0_t6_slice_output1 (1, 256) <class 'numpy.float32'> [[  1.61537719e+00   1.33848429e-01   2.99069256e-01   6.89043999e-01
    5.32481790e-01   6.34537876e-01   1.94801807e+00   5.30367434e-01
    2.65555763e+00   4.81788665e-01   1.84512520e+00   7.76577771e-01
    1.24309123e+00   1.21777010e+00  -2.63475716e-01   6.44480407e-01
    6.60243154e-01   5.21547079e-01   1.53890359e+00   9.71068561e-01
    1.92587942e-01  -3.17128807e-01   1.75112283e+00   3.28991771e-01
    9.67971504e-01   9.05186474e-01   1.10656285e+00   5.64834833e-01
    1.40771973e+00   3.96816254e-01   1.50411189e+00   1.25338268e+00
    7.55300105e-01   9.34470952e-01   2.08259273e+00   5.55113971e-01
    2.78226525e-01   8.72183204e-01   2.13907766e+00   1.97859015e-02
    1.14004934e+00   7.56852090e-01   1.84183788e+00  -2.59045660e-01
    1.84771851e-01  -4.31309521e-01   1.95085430e+00   9.46534991e-01
    3.75389278e-01  -2.86390662e-01  -4.10954922e-01   7.06637621e-01
    3.80396318e+00  -3.79152238e-01   1.55138707e+00  -5.20853102e-01
    4.49297547e-01   8.55187237e-01   9.21148002e-01   1.16691446e+00
   -6.81675225e-03   6.54501379e-01   2.73948908e-01   1.34398139e+00
    3.75923991e-01   7.60066688e-01   1.20792365e+00   1.29051936e+00
    7.00055063e-01   2.02479243e+00  -6.39096946e-02   9.03623998e-01
    2.21294665e+00   8.23999584e-01   2.08838999e-01   3.63367891e+00
    5.70873559e-01   3.45276594e+00   1.17422080e+00  -7.88347065e-01
    1.57159042e+00  -6.80247724e-01   2.92205596e+00   1.20306265e+00
    1.43505311e+00   1.05780649e+00   3.38322967e-02   2.06801391e+00
    3.55550241e+00   5.18137515e-01   3.68346453e-01   9.51344788e-01
   -8.51816237e-02   9.25545692e-01  -2.79005229e-01   7.40168691e-02
    1.72027802e+00   1.57082069e+00   1.52274895e+00   1.65571177e+00
    3.33718628e-01  -3.45038265e-01   6.60184473e-02   1.47093415e+00
    1.34675801e+00   4.02470380e-01   8.65317404e-01   1.05724633e+00
    7.95940220e-01   6.09632552e-01   1.44343257e+00   1.95237172e+00
    2.42358875e+00   2.77156043e+00   1.13313079e+00   7.83988297e-01
    1.43737602e+00   1.72322297e+00   7.74170756e-01   6.52088463e-01
    9.02531743e-01   1.98051012e+00   1.08019316e+00   7.11489081e-01
    1.57549858e+00   9.98117685e-01  -6.51314914e-01   7.20635712e-01
    7.68744349e-01   2.79885411e+00   6.86258674e-01   1.22614694e+00
    3.11249614e-01   4.79389668e-01   6.95796371e-01   1.27492976e+00
    1.40252757e+00  -6.98602140e-01   2.05808640e+00   1.30833101e+00
    7.15368509e-01   9.93598819e-01   1.17859769e+00   1.08400631e+00
    1.18837500e+00   1.45598900e+00   4.92652506e-01   9.87910032e-01
    1.70387673e+00   9.27923858e-01   1.42885530e+00   4.08280551e-01
    9.50480044e-01   1.08642149e+00   7.19650626e-01   5.31117797e-01
    1.67149079e+00   5.62486887e-01   1.90121841e+00   9.88212287e-01
    1.89095855e+00   9.49748099e-01   1.43183196e+00   1.20663893e+00
    1.39206576e+00   4.63642657e-01   5.67965269e-01   6.92040145e-01
   -3.30292851e-01   3.69601101e-01  -3.96441370e-01   2.87902188e+00
    7.61337817e-01   2.09957576e+00   1.50050402e-01   3.55277836e-01
    6.69579446e-01   1.36645043e+00  -1.71309441e-01   1.78733277e+00
    6.24390602e-01  -2.35428423e-01   1.48684406e+00   1.09520888e+00
    7.72791862e-01   9.32253599e-01   1.45746839e+00   1.10190856e+00
    1.00729966e+00   1.34360349e+00  -7.26560533e-01   8.33178401e-01
    1.81960094e+00   1.09262109e+00  -1.01483382e-01   5.80320656e-01
    5.80857372e+00  -2.10025311e-01   9.82407987e-01  -1.39258236e-01
    6.24544322e-01   1.07753170e+00   7.00045347e-01   2.06959724e+00
    9.30001140e-01   4.98410344e-01   1.64517415e+00  -5.95089078e-01
   -1.21330306e-01   1.38837552e+00   1.31235301e+00   7.91093647e-01
    1.25468946e+00   9.43253994e-01   2.85190201e+00   1.95236182e+00
    3.70806932e-01   1.46445596e+00   2.21332684e-02   3.23651731e-03
    4.46239561e-01   1.17267573e+00  -1.11004166e-01   1.25049520e+00
    8.27083111e-01   2.10309935e+00  -7.20464706e-01   6.41039789e-01
    9.82200503e-01   6.70693159e-01   5.80394387e-01   2.54970527e+00
    4.63450789e-01   1.04415596e+00   1.59211087e+00   9.94538069e-01
    4.32968736e-01   2.62361139e-01   5.19041419e-01   2.35630822e+00
    3.57957661e-01   1.59794605e+00   5.85518932e+00  -2.63838977e-01
    7.76224971e-01  -2.79915988e-01   4.03669745e-01   7.72826970e-01
    1.05338001e+00   1.19177616e+00   2.16498709e+00  -2.31404603e-01
    1.82608771e+00   8.18390787e-01   6.50565684e-01   1.03838694e+00]]
After layer encoder_birnn_forward_l0_t6_slice_output2 (1, 256) <class 'numpy.float32'> [[  4.60703284e-01   7.60615885e-01  -1.79902267e+00  -6.71811581e-01
    2.34876204e+00  -1.73831716e-01   2.06005287e+00   2.01419517e-02
   -6.75013006e-01  -1.60348475e-01   1.31792724e+00   1.40401256e+00
    3.73219103e-01  -1.78582919e+00   2.31826723e-01  -2.85710394e-03
    8.93863976e-01   1.63084543e+00  -2.86324799e-01   8.13812912e-01
   -3.09100181e-01  -3.23476624e+00  -2.81646395e+00   1.06919873e+00
   -3.26410592e-01  -3.05233151e-01  -2.27747869e+00  -6.64707273e-02
   -1.96149862e+00   1.23663187e+00   9.80651200e-01  -5.62160969e-01
    1.74471557e+00  -7.25588977e-01   3.37937355e+00   8.48625839e-01
    8.30412388e-01  -3.28409076e+00  -2.38647175e+00  -1.27562284e-01
   -1.13445677e-01   2.61215138e+00  -3.32514942e-01   1.98517895e+00
   -3.91268396e+00  -9.16056275e-01  -7.77879506e-02   9.93784308e-01
    1.14165425e+00   6.59714937e-01  -1.12055205e-02   5.27669005e-02
   -1.34470892e+00  -1.14537287e+00   2.53385520e+00   1.47217906e+00
   -2.92801499e+00  -3.07907760e-01   1.50661933e+00   7.59202540e-02
    1.95211244e+00  -1.56435728e-01   3.95097077e-01   4.84461021e+00
   -1.48573768e+00   1.45170346e-01   1.35183918e+00   2.36780429e+00
    6.35470092e-01  -2.13768101e+00   9.48455334e-01   1.09300107e-01
   -3.18317318e+00   7.44559348e-01   1.31500447e+00   2.53238654e+00
    2.18874121e+00  -4.38063192e+00   1.36526775e+00  -2.76710081e+00
    2.97284150e+00  -1.38423932e+00  -1.56058788e-01   3.74845952e-01
   -9.02783573e-01  -2.19939303e+00   4.28057015e-01  -2.87180638e+00
    2.53339171e-01  -1.92734122e-01   1.30513120e+00   7.88302302e-01
   -2.38405919e+00  -8.27103257e-01  -3.53126073e+00  -8.92587006e-01
   -1.31466389e+00  -3.07596326e+00   1.29456532e+00   3.71804148e-01
   -1.54572511e+00  -1.50469869e-01  -5.63383512e-02   1.39036906e+00
   -1.02970529e+00  -2.15934563e+00   8.67608905e-01   9.48750198e-01
    7.99288571e-01   1.18768346e+00  -2.47576070e+00  -1.92481279e+00
    3.87315941e+00   3.57395244e+00  -3.45495611e-01   2.19831204e+00
    1.03964520e+00   4.09401149e-01   7.61884570e-01   2.26767331e-01
    3.18400174e-01  -1.72038662e+00   2.13039374e+00  -9.03152764e-01
    3.96112180e+00  -5.62683821e-01   2.98825884e+00   1.27448022e+00
   -2.47561955e+00  -3.20179367e+00   4.83387798e-01   1.42731774e+00
    7.02268958e-01  -4.65415388e-01   2.22714162e+00   2.64379525e+00
    8.96150172e-01   1.89640474e+00  -3.11855507e+00  -8.07955980e-01
   -4.46054600e-02   3.05064082e+00  -2.58810616e+00  -3.00657213e-01
    2.30785656e+00   5.25279492e-02   1.73042142e+00   6.16875440e-02
    3.02781749e+00  -3.26221526e-01   3.25983644e+00  -1.41591060e+00
    3.58085108e+00   1.82510042e+00   6.50697827e-01  -2.87900376e+00
    2.97645140e+00  -8.21743459e-02   1.72064829e+00   1.69522846e+00
    4.50556040e+00   4.74495739e-02   7.24091530e-01   2.05259871e+00
   -3.72771204e-01   3.75931978e-01  -1.58751577e-01   2.17530036e+00
   -1.27192569e+00  -1.24918079e+00   4.50743347e-01   4.67804432e+00
   -8.36894333e-01   3.45198131e+00  -1.66432369e+00  -2.92097569e+00
    4.13508475e-01   2.36591145e-01  -1.11478281e+00  -3.64559621e-01
    2.94511414e+00   2.05393147e+00   9.55930471e-01   1.31753826e+00
   -6.09344468e-02  -1.58365858e+00  -8.76738906e-01   2.66749597e+00
    1.16420448e+00  -1.10674775e+00   2.57707095e+00  -1.65416408e+00
   -1.98124731e+00   2.44765067e+00   5.74943662e-01  -2.84985590e+00
   -4.09327477e-01  -2.40450525e+00   1.73393977e+00  -3.95640075e-01
    4.06973772e-02  -1.90844035e+00  -3.22101355e+00  -1.28504169e+00
   -4.91108060e-01  -2.52889276e-01   2.37748814e+00   6.21171445e-02
    6.72584713e-01   2.96499968e-01  -6.67673707e-01   1.12710416e+00
    1.02380371e+00   7.24517345e-01   3.64969730e+00  -2.32589507e+00
   -1.30796480e+00  -2.66808629e+00  -8.09666574e-01  -1.08064663e+00
   -7.03157723e-01   1.10298598e+00   2.21137905e+00  -3.31275296e+00
    6.23415112e-01  -4.15550756e+00  -2.21582246e+00  -6.81686521e-01
    6.46209419e-01  -1.08720213e-01  -7.73248196e-01  -3.18267059e+00
   -4.86592829e-01   2.82348776e+00  -1.15112853e+00  -1.79614387e-02
    2.26772332e+00   1.23680353e+00  -2.81366110e-01   4.40856743e+00
    1.92565572e+00   2.01700306e+00  -4.60325718e+00  -2.57832718e+00
    2.44824243e+00  -1.46577358e+00   6.27280235e-01  -5.72525084e-01
   -1.67966485e+00   1.31396127e+00  -2.66798401e+00  -2.32155144e-01
   -1.20078695e+00  -1.02579939e+00  -7.65458643e-02   7.98366845e-01]]
After layer encoder_birnn_forward_l0_t6_slice_output3 (1, 256) <class 'numpy.float32'> [[ 1.67996478  0.95237988  1.03054941  1.46168065  0.98837423  1.47650766
   2.94054723  0.88376981  1.30807829  1.06983888  1.23195672  1.19890141
   0.97443038  1.94288409 -0.14236739  0.34816527  1.21788824  0.68849695
   2.64046359  1.45097876  0.82913715 -0.11227987  2.27051234  1.59583986
   0.86669832  0.7379812   1.97005248  1.28694868  0.21851867  1.15432155
   1.63279128  1.47058308  0.13258693  0.94058186  0.93640995  0.54384673
   1.34584534  0.48822898 -0.93761557  0.74069971  0.77089357  1.05002451
   0.98195153  1.04684901  1.06550562  1.22087574  2.67011571  1.42658091
   0.99203295  0.25347254 -0.55496693  1.35664618  4.71065521 -0.23375386
   1.32509875 -0.20377737  0.65045589  0.95463413  1.37589717  0.88141483
   0.08350332  0.68758392  0.24155685  1.87243462  0.66848004  1.05792153
   1.70273983  0.7822569   1.10567033  0.8130461   1.37437558  1.27883899
   2.51376891  1.12595105  0.84248888  4.17177105  1.19968045  3.82967901
   1.83626819  0.23081222  2.19990206 -0.30010939  4.73637486  1.00661898
   1.72566521  0.80355108  0.71484059  1.35848844  3.02578712  1.48803079
   0.88796717  1.15837002 -0.71079594  1.89308715  0.37961107  1.42213798
   1.44773972  1.55461395  1.44190001  2.26464009  0.46259287  0.84266466
   0.33685899  2.18582249  1.56668556  0.4729999   1.15212238  1.53851688
   1.70153093  0.33402976  2.06744361  1.26994872  3.08974767  2.77575254
   1.53749156  1.15103102  1.23092294  2.48438931  1.2100538   1.36623561
   0.95612502  2.57338595  1.42933559  1.09030485  1.48347163  1.66691649
   0.09299607  0.2473729   0.89936328  3.5220499   1.41779542  2.28455043
   0.87929481  1.11161971  0.64749837  0.66063607  1.63595033  0.81979424
   1.84733737  1.30439091  0.66539401  1.24903286  1.0925411   1.32626092
   0.70645297  1.56063771  0.99911952  0.90684128  0.16134189  0.55300808
   2.82101679  0.6326164   1.32084131  0.13939323  0.59106481 -0.05790078
   0.69684213  1.05758584  2.49165869  1.26477861  1.10574198  1.46298599
   0.31423977  1.57898068  2.20230818  0.47855708  1.22571552  0.44372803
  -0.3122853   0.62494165  0.74545383  5.15573215  1.41184163  2.12381887
   0.08941197  0.49011141  1.10843837  1.34309113  0.71599615  1.85541987
   1.07936549 -0.0857202   1.41480148  1.4749769   0.65536654  1.37045205
   1.15596485  0.68376803  1.34929252  1.78857088 -0.19855814  1.0707761
   2.48346376  1.0358603   0.34896493  1.38722134  5.19582653  0.91543078
   1.23265934  1.31324673  0.53655577  0.37534097  1.41012359  2.00174546
   1.48147285  1.60674524  1.92959523  0.12108847 -0.68956631  1.1313194
   1.43358731  0.65412194  1.98779941  1.61981928  3.63504243  2.31570387
   0.7413131   2.24806619  1.54475462  0.80905658  0.89517981  1.48748791
  -0.05399047  0.50099874  1.50514364  0.90112454  1.24767041  1.12620604
   1.2673229   0.71288174  0.57968229  2.17401767  1.40512764  1.33807957
   1.62290025  0.87019378  0.20418112 -0.19192684  1.01989436  2.7747798
   0.14801301  1.86868691  6.66736937  0.26867044  1.06741607  0.27185968
   1.18808639  1.31853414  2.03450012  1.66418648  2.12173152  0.62523955
   2.16670609  1.60222805  0.83387595  1.30455518]]
After layer encoder_birnn_forward_l0_t6_o_output (1, 256) <class 'numpy.float32'> [[ 0.84289992  0.72159356  0.73702246  0.81178957  0.72876668  0.81404448
   0.94981486  0.7076028   0.78719145  0.74456626  0.77416086  0.76832932
   0.72600168  0.87466866  0.46446812  0.58617258  0.77169168  0.66563249
   0.93342084  0.81014901  0.69617248  0.4719595   0.90640521  0.83143616
   0.70405823  0.6765542   0.8776167   0.78363031  0.55441332  0.76029938
   0.83655167  0.81314605  0.53309822  0.71921718  0.71837389  0.63270682
   0.79344952  0.61968917  0.28138223  0.67714888  0.68371415  0.74077964
   0.72749531  0.74016935  0.74374127  0.77221763  0.93523997  0.80636805
   0.72948927  0.56303102  0.36471283  0.79521406  0.99108136  0.44182622
   0.79002875  0.44923124  0.65711313  0.7220462   0.79833126  0.70711529
   0.52086371  0.66542923  0.56009728  0.86673975  0.66116273  0.74229312
   0.84589219  0.68616629  0.75132108  0.6927582   0.79808617  0.78225213
   0.92510146  0.75509095  0.69898915  0.98480934  0.7684679   0.97874498
   0.86250675  0.55744821  0.90024072  0.42553073  0.99130589  0.73235792
   0.8488571   0.69073361  0.67146987  0.79551387  0.95372558  0.81578255
   0.70847046  0.76103646  0.32942301  0.86910713  0.59377927  0.80567336
   0.8096503   0.82557911  0.80874866  0.9059059   0.6136291   0.69902617
   0.58342731  0.89896911  0.82731056  0.61609358  0.75989836  0.82324904
   0.8457346   0.58273953  0.88769841  0.780734    0.95646793  0.94135135
   0.82309973  0.75969923  0.77398008  0.92304021  0.77030849  0.79677129
   0.72234535  0.929129    0.80679774  0.74843907  0.81509632  0.84116423
   0.52323228  0.56152976  0.71081865  0.97130865  0.80499262  0.90758938
   0.70667607  0.75243092  0.65644652  0.65940326  0.83698308  0.69419265
   0.86381412  0.78657305  0.66047102  0.77713239  0.74885994  0.79022145
   0.66961694  0.82644486  0.73088545  0.71235341  0.54024822  0.63483322
   0.94380099  0.65308249  0.78932166  0.53479201  0.6436094   0.48552883
   0.66748726  0.74222898  0.92355496  0.77984762  0.75133443  0.81198889
   0.57791984  0.82906014  0.90045661  0.61740714  0.77306777  0.60914695
   0.422557    0.65134162  0.67818731  0.99426681  0.80405629  0.89319682
   0.52233809  0.62013268  0.75183785  0.79299778  0.67172474  0.86476213
   0.74637389  0.47858307  0.80452216  0.81381273  0.6582188   0.79745322
   0.76059878  0.66457915  0.79401392  0.85675204  0.45052287  0.74474448
   0.92297441  0.73805046  0.58636653  0.80014825  0.99449086  0.7141102
   0.77428371  0.78805596  0.63101089  0.59274888  0.80378544  0.88098019
   0.81479496  0.83295906  0.87320465  0.53023517  0.33412957  0.75608236
   0.80745965  0.65793872  0.87951016  0.8347702   0.97429538  0.9101693
   0.67728293  0.90448362  0.82415485  0.69190842  0.70995796  0.81570095
   0.48650566  0.62269402  0.81834042  0.71118057  0.7768963   0.75513804
   0.78028411  0.67103761  0.64099431  0.89789188  0.80299634  0.79217392
   0.83519471  0.704786    0.55086869  0.45216507  0.73495203  0.94129771
   0.53693587  0.86630625  0.99872988  0.5667665   0.74410522  0.56754941
   0.76639867  0.78893775  0.884372    0.84079915  0.8929975   0.65140933
   0.89721966  0.83232957  0.69717389  0.78660065]]
After layer encoder_birnn_forward_l0_t6_f_output (1, 256) <class 'numpy.float32'> [[ 0.83415657  0.53341222  0.57421499  0.6657542   0.63006175  0.65351766
   0.87523037  0.62956882  0.9343527   0.61817014  0.86355376  0.68494207
   0.77610165  0.77167088  0.43450955  0.65576553  0.65931499  0.62750947
   0.82330525  0.7253325   0.54799873  0.42137563  0.85209435  0.58151406
   0.72471499  0.7120142   0.75148773  0.6375705   0.803406    0.5979225
   0.81818694  0.7778849   0.68033248  0.71798146  0.88919973  0.63532126
   0.56911141  0.70519978  0.89464372  0.50494635  0.7576887   0.6806699
   0.86316592  0.43559834  0.54606199  0.3938137   0.87553978  0.7204178
   0.59276056  0.42888772  0.39868316  0.66965777  0.97820342  0.40633142
   0.82511401  0.3726528   0.6104722   0.70165414  0.715276    0.76258689
   0.49829578  0.65802413  0.56806207  0.79314393  0.59288961  0.68136823
   0.76993138  0.78423506  0.66819996  0.8833757   0.48402801  0.71169364
   0.90140611  0.69508469  0.55202085  0.97426116  0.63896471  0.96931356
   0.76390707  0.31252369  0.8280102   0.33620602  0.94892609  0.76906914
   0.80768746  0.74227113  0.5084573   0.88775516  0.97222632  0.62671214
   0.59105939  0.72138554  0.47871745  0.71617073  0.43069768  0.5184958
   0.84816468  0.82790053  0.82094288  0.83966148  0.58266389  0.41458613
   0.51649863  0.81319934  0.79359913  0.59928107  0.70377046  0.74216396
   0.68910539  0.64785701  0.80898559  0.87570506  0.91860849  0.94111955
   0.7564162   0.68653905  0.80804801  0.84854352  0.68442237  0.65748096
   0.71146947  0.87873554  0.74653059  0.67073011  0.82856601  0.73068839
   0.3426933   0.67274702  0.68324924  0.94261384  0.66513413  0.77314347
   0.57719028  0.61760378  0.6672551   0.78158551  0.80258471  0.33212221
   0.8867622   0.78723371  0.67158633  0.72979814  0.76469558  0.74725139
   0.76645035  0.81091839  0.62073106  0.72867495  0.84604037  0.71665388
   0.80672288  0.60067552  0.72121167  0.74770731  0.67253011  0.62974381
   0.84177452  0.63702774  0.87002933  0.72873473  0.86886477  0.72106451
   0.80718666  0.76970369  0.80092186  0.61387795  0.6382935   0.66642058
   0.41816938  0.59136254  0.40216765  0.94679964  0.68164408  0.89086193
   0.53744239  0.58789688  0.66140902  0.79680604  0.45727706  0.85659999
   0.65121651  0.44141322  0.81560409  0.74936128  0.68412453  0.71753228
   0.81114519  0.7506175   0.73249131  0.79308188  0.32594994  0.69702655
   0.86051822  0.74887496  0.47465092  0.64114118  0.99700731  0.44768581
   0.72758573  0.46524158  0.65125144  0.74602658  0.66819787  0.88791281
   0.71707547  0.62208569  0.83823776  0.35546803  0.46970457  0.80033278
   0.78790665  0.68806612  0.77811056  0.71975648  0.94541693  0.87570393
   0.59165394  0.81221324  0.5055331   0.50080913  0.60974479  0.7636283
   0.4722774   0.77738559  0.69573778  0.89120406  0.32729065  0.65498853
   0.72754467  0.66165835  0.64115816  0.92755365  0.61383253  0.73965108
   0.83091289  0.72998333  0.60658234  0.5652166   0.62692356  0.91343433
   0.58854598  0.83173114  0.99714321  0.43442026  0.68486595  0.4304744
   0.59956908  0.6841321   0.74142343  0.76705861  0.89706093  0.44240564
   0.86129504  0.69389468  0.65713793  0.73853868]]
After layer _mul2064_0 (1, 256) <class 'numpy.float32'> [[ 0.29769486  0.27854365 -0.46334621 -0.28129017  0.68964696 -0.12299514
   1.18059981 -0.00575339 -0.30789664 -0.0730205   0.68804359  0.57888645
   0.16412307 -0.84256047  0.04524683  0.00422598  0.36866438  0.55235845
  -0.11940433  0.35634816 -0.13082309 -0.22849    -1.05230939  0.34276691
  -0.190648   -0.12570447 -0.87955695 -0.04111581 -0.8408199   0.42199475
   0.53932333 -0.32055646  0.73701286 -0.34534308  1.52467108  0.28442881
   0.28602007 -1.07225466 -1.26115525  0.01595596 -0.07622236  0.69928974
  -0.25774619  0.3236416  -0.74160707 -0.20636791 -0.06742471  0.5153321
   0.34277838  0.12702094 -0.00823338  0.00807189 -1.1517036  -0.23394217
   1.17119789  0.23828846 -0.72311705 -0.13377281  0.51754957 -0.00299446
   0.40094572 -0.12120303  0.11115813  1.25110507 -0.37448001  0.0804535
   0.61814177  1.12342584  0.33375502 -1.11521721  0.21058436  0.03458852
  -1.58838511  0.36587834  0.40964922  1.7405498   0.66490465 -2.22987819
   0.61655349 -0.18411647  1.11633956 -0.22790551 -0.15990174  0.15064515
  -0.56512994 -0.78846043  0.11561409 -1.41341102  0.31378916 -0.06365358
   0.40166014  0.28510031 -0.3317695  -0.38449302 -0.28281042 -0.15866575
  -0.83830321 -1.21770489  0.75551528  0.26886487 -0.38523835 -0.03016728
  -0.00812969  0.84783518 -0.66284454 -0.50275332  0.4118363   0.44546166
   0.34513232  0.39648142 -1.06535792 -1.06925404  1.83037019  1.9582262
  -0.28272676  0.76700979  0.56715029  0.28153059  0.34275305  0.08888678
   0.08458664 -1.05986404  0.9898361  -0.35295525  1.48496842 -0.1512973
   0.29995725  0.47430068 -0.65967613 -1.75677311  0.15341629  0.7698487
   0.24033204 -0.16040695  0.75371492  0.95419961  0.41458532  0.14269961
  -1.28660357 -0.32600355 -0.01258638  0.99032313 -0.93320757 -0.13208438
   0.81943738  0.01012764  0.42831182 -0.0202018   1.18991959 -0.1616516
   1.25724113 -0.51007563  1.11434436  0.78073937  0.23664653 -0.75283271
   1.11359334 -0.04417432  0.97299528  0.70779634  1.62338495  0.10307923
   0.43601072  0.89197749 -0.27737206  0.17097889 -0.04040435  0.68137592
  -0.2177272  -0.41243494  0.07483857  2.308815   -0.34109837  1.46657681
  -0.43212977 -0.54930598  0.11845176  0.12108525 -0.20378995 -0.2118986
   0.85838509  0.36385092  0.55258435  0.5600816  -0.01616412 -0.66183048
  -0.423318    0.95981842  0.49529514 -0.5720551   0.17635357 -0.55979627
  -1.12020552  0.77698314  0.16104786 -0.79445112 -0.51908493 -0.47851768
   0.70136434 -0.09276742  0.04714214 -0.8238827  -0.74300766 -0.75643003
  -0.25656959 -0.13411084  1.01567852  0.02559234  0.14299622  0.15250205
  -0.38977593  0.45719528  0.58188647  0.36250514  1.87377059 -1.14758396
  -0.38901863 -1.12529218 -0.23516418 -0.18791975 -0.23662725  0.54678643
   0.41339844 -1.00502646  0.29540011 -1.84410286 -0.28639561 -0.24943258
   0.30716392 -0.026938   -0.19494133 -1.85311806 -0.22008882  0.99470925
  -0.69747561 -0.01611619  0.58088702  0.27016976 -0.12016526  1.64136612
   0.45716935  1.0066396  -2.68989873 -0.39641169  0.80776834 -0.31372431
   0.27407137 -0.2511228  -0.76181412  0.56512934 -1.48973691 -0.05275422
  -0.77849007 -0.50212759 -0.04033826  0.38566411]]
After layer encoder_birnn_forward_l0_t6_i_output (1, 256) <class 'numpy.float32'> [[ 0.69779259  0.67147112  0.63813972  0.62972367  0.75900328  0.74688876
   0.88386285  0.52260107  0.34236872  0.67482632  0.65886962  0.75734669
   0.46977228  0.79471457  0.35219017  0.57239062  0.61909634  0.7088089
   0.74583584  0.64294308  0.49379957  0.21964413  0.67397529  0.62878066
   0.579961    0.58242673  0.77349788  0.49588916  0.73426682  0.74529821
   0.7190156   0.6869576   0.81497115  0.72014588  0.92770618  0.53388369
   0.61119485  0.92823046  0.85843551  0.25882262  0.38680947  0.68786997
   0.84008765  0.54813606  0.91794801  0.68215543  0.62391138  0.71088946
   0.58632982  0.43486416  0.41211724  0.39671272  0.99064273  0.6159693
   0.85935551  0.51509619  0.82579416  0.52992338  0.65169573  0.1990364
   0.63477963  0.6142782   0.44816563  0.85172188  0.51580149  0.55412835
   0.77191222  0.88592738  0.73277718  0.84941918  0.42506918  0.20549668
   0.93455178  0.69947034  0.66132528  0.93745887  0.75466853  0.97638911
   0.70500839  0.31467628  0.83131629  0.67410547  0.7305764   0.44905877
   0.82713747  0.74792522  0.62698793  0.90145677  0.84454465  0.41654873
   0.70830059  0.43422389  0.42738855  0.69174993  0.3257311   0.2363831
   0.82697517  0.86157066  0.81010056  0.68374419  0.60009533  0.38539982
   0.64863127  0.87408412  0.76114309  0.58996654  0.53490973  0.58772141
   0.46585345  0.55543023  0.84836495  0.81466168  0.95978421  0.98035949
   0.74712348  0.79524225  0.6663596   0.80545002  0.59237379  0.40341112
   0.41319686  0.84411865  0.93538421  0.65008277  0.92565829  0.58699661
   0.65713656  0.66893566  0.60126364  0.94147658  0.36854261  0.79322582
   0.6750108   0.5874185   0.80426139  0.74471551  0.73067361  0.29080245
   0.76381636  0.47854814  0.53826702  0.85514605  0.76217324  0.50976747
   0.71371973  0.28418824  0.51628238  0.38728088  0.81857032  0.44962496
   0.9123401   0.78130329  0.91550177  0.85725272  0.53400713  0.81927627
   0.72719985  0.40401044  0.81881464  0.7808252   0.9367764   0.43253595
   0.76558918  0.79729986  0.74545127  0.49581131  0.55482298  0.69663042
   0.44982603  0.63948321  0.3391      0.99613178  0.65196359  0.87040913
   0.72309649  0.5949921   0.42341799  0.33615199  0.48759347  0.64750987
   0.8739326   0.65061057  0.68238729  0.60687214  0.41219705  0.7111609
   0.54395837  0.828291    0.74775022  0.71134377  0.32197994  0.5669207
   0.88744539  0.64569664  0.65890157  0.82708311  0.98860544  0.85905814
   0.74407548  0.55554789  0.60516512  0.78499258  0.70388234  0.74010372
   0.70036161  0.49724537  0.77822441  0.3630535   0.35896325  0.65297031
   0.73999476  0.64146173  0.84123099  0.67386585  0.95110047  0.83246291
   0.62817603  0.88236207  0.69299704  0.34611997  0.60051101  0.63638222
   0.678177    0.74142283  0.70926565  0.9851265   0.73697853  0.45762187
   0.49431112  0.49764341  0.31307235  0.97273254  0.63916218  0.86179119
   0.73793292  0.47299352  0.64745188  0.38758487  0.53301901  0.90271389
   0.60694879  0.76384324  0.99782902  0.69272989  0.81949669  0.73388749
   0.64404374  0.60062325  0.77177751  0.65080482  0.90296966  0.29876018
   0.81646276  0.70321089  0.37483776  0.63969547]]
After layer encoder_birnn_forward_l0_t6_c_output (1, 256) <class 'numpy.float32'> [[ 0.43065724  0.64143956 -0.94670469 -0.58617032  0.98192912 -0.17210171
   0.96803361  0.02013923 -0.5882678  -0.15898819  0.86626756  0.88621593
   0.35680422 -0.94531864  0.22776103 -0.0028571   0.71329701  0.92618191
  -0.27874866  0.67168832 -0.29961827 -0.99690491 -0.99286932  0.78915918
  -0.31529185 -0.29609433 -0.97918892 -0.06637301 -0.96120399  0.84449226
   0.75334769 -0.509579    0.9407711  -0.6203593   0.99768132  0.69035089
   0.68069738 -0.99719524 -0.98323089 -0.12687486 -0.11296149  0.98928946
  -0.32077873  0.96296537 -0.99920136 -0.72402638 -0.07763144  0.75897133
   0.81497037  0.57817364 -0.01120505  0.05271798 -0.87279862 -0.8162154
   0.98748517  0.89999235 -0.99429119 -0.29853252  0.90633726  0.07577473
   0.96048337 -0.15517199  0.37574604  0.99987614 -0.90253741  0.14415908
   0.87448668  0.98259854  0.56180733 -0.9725675   0.73908293  0.10886693
  -0.99656904  0.63189197  0.86553621  0.98744857  0.97519755 -0.99968666
   0.87760919 -0.99213237  0.99477941 -0.88189703 -0.15480411  0.35822311
  -0.71765053 -0.97571403  0.40369627 -0.99361408  0.24805495 -0.1903826
   0.8630383   0.65744621 -0.98315048 -0.67891753 -0.99828821 -0.71266913
  -0.86545074 -0.99575031  0.86031753  0.35556877 -0.91307735 -0.14934446
  -0.05627882  0.88325208 -0.77379012 -0.97371542  0.70015728  0.73921669
   0.66363883  0.82985902 -0.98595405 -0.95831203  0.99913573  0.99842823
  -0.33237478  0.97566211  0.77774793  0.3879641   0.64218569  0.22295861
   0.30805963 -0.93790954  0.97217035 -0.71782953  0.99927509 -0.50996602
   0.99493754  0.85500729 -0.98595011 -0.99669427  0.44895267  0.89111561
   0.60580599 -0.43448761  0.97701001  0.98994297  0.71441817  0.95592862
  -0.99609661 -0.66846108 -0.0445759   0.99553001 -0.98876476 -0.29191393
   0.98040366  0.05247969  0.93910569  0.06160942  0.99532175 -0.31512156
   0.99705607 -0.88874269  0.99844974  0.94934452  0.57213956 -0.99370509
   0.9948169  -0.08198988  0.93794107  0.93480992  0.99975592  0.047414
   0.61943734  0.9675613  -0.35641328  0.35916942 -0.15743127  0.9745304
  -0.85431874 -0.84805375  0.42250985  0.99982715 -0.68416059  0.99799442
  -0.93079722 -0.99421048  0.39144763  0.23227337 -0.80574656 -0.34922394
   0.99448258  0.96764624  0.74245614  0.86617041 -0.06085914 -0.91917133
  -0.70478183  0.99040633  0.8224054  -0.80290979  0.98851544 -0.92942679
  -0.96267843  0.98514783  0.51898062 -0.99332845 -0.38790151 -0.98382008
   0.93951976 -0.37621227  0.04067492 -0.95695424 -0.99681872 -0.85782242
  -0.45509544 -0.2476327   0.98292947  0.06203737  0.58667755  0.28810632
  -0.58344758  0.81002587  0.7714113   0.61969972  0.998649   -0.9810915
  -0.86375952 -0.9904176  -0.66940629 -0.79343879 -0.6063683   0.80156898
   0.97628248 -0.99735129  0.55350137 -0.99950856 -0.97648984 -0.59261465
   0.56911266 -0.10829387 -0.6488142  -0.99656558 -0.45150802  0.99296844
  -0.81812757 -0.01795951  0.97878325  0.84454149 -0.27416897  0.99970371
   0.95838082  0.96520936 -0.99979925 -0.98854411  0.98516524 -0.89876813
   0.5561766  -0.51721132 -0.93281806  0.86527431 -0.99041563 -0.22807239
  -0.83389449 -0.77221811 -0.07639671  0.66312277]]
After layer _mul2065_0 (1, 256) <class 'numpy.float32'> [[ 0.30050942  0.43070814 -0.60412985 -0.36912531  0.74528742 -0.12854083
   0.85560894  0.01052478 -0.2014045  -0.10728942  0.57075739  0.67117268
   0.16761674 -0.75125849  0.08021519 -0.00163538  0.44159958  0.65648597
  -0.20790075  0.43185735 -0.14795138 -0.21896431 -0.66916937  0.49620804
  -0.18285698 -0.17245325 -0.75740057 -0.03291366 -0.70578021  0.62939858
   0.54166877 -0.35005918  0.76670128 -0.44674921  0.92555511  0.36856708
   0.41603872 -0.92562699 -0.84404033 -0.03283808 -0.04369457  0.68050253
  -0.26948225  0.52783602 -0.91721487 -0.49389854 -0.04843514  0.5395447
   0.47784144  0.25142699 -0.00461779  0.02091389 -0.86463159 -0.50276363
   0.8486008   0.46358263 -0.82107985 -0.15819936  0.5906561   0.01508193
   0.60969526 -0.09531877  0.16839646  0.85161638 -0.46553013  0.07988263
   0.67502695  0.87051094  0.4116796  -0.82611746  0.31416139  0.02237179
  -0.93134534  0.44198969  0.57240099  0.92569244  0.73595089 -0.97608316
   0.61872184 -0.31220052  0.8269763  -0.5944916  -0.11309623  0.16086324
  -0.59359562 -0.72976112  0.2531127  -0.89570016  0.20949349 -0.07930363
   0.61129051  0.28547886 -0.42018726 -0.46964115 -0.32517353 -0.16846293
  -0.71570629 -0.85790926  0.6969437   0.24311808 -0.54793346 -0.05755733
  -0.03650421  0.77203661 -0.588965   -0.57445949  0.37452093  0.43445346
   0.30915844  0.4609288  -0.83644885 -0.78070009  0.95895469  0.9788186
  -0.24832501  0.77588773  0.51825982  0.31248569  0.38041398  0.08994398
   0.12728928 -0.79170692  0.90935278 -0.46664861  0.92498726 -0.29934832
   0.65380985  0.57194489 -0.59281594 -0.93836433  0.16545819  0.70685589
   0.40892559 -0.25522605  0.78577143  0.73722589  0.52200651  0.27798638
  -0.76083487 -0.3198908  -0.02399374  0.85132354 -0.75361001 -0.14880823
   0.69973344  0.01491411  0.48484373  0.02386015  0.81474084 -0.14168651
   0.90965426 -0.6943776   0.91408253  0.81382817  0.30552661 -0.81411898
   0.72343069 -0.03312477  0.76799989  0.72992313  0.93654776  0.02050826
   0.47423452  0.77143651 -0.26568872  0.17808026 -0.08734649  0.67888755
  -0.38429481 -0.54231614  0.14327309  0.99595958 -0.44604778  0.86866343
  -0.67305619 -0.59154737  0.16574597  0.07807916 -0.39287677 -0.22612596
   0.86911076  0.62956089  0.50664264  0.52565467 -0.02508596 -0.65367872
  -0.38337198  0.82034463  0.61495382 -0.57114488  0.31828213 -0.52691126
  -0.85432452  0.63610667  0.34195715 -0.82156521 -0.38348156 -0.84515864
   0.69907361 -0.20900394  0.02461505 -0.75120199 -0.70164311 -0.63487756
  -0.31873137 -0.12313421  0.76493973  0.02252289  0.21059568  0.18812488
  -0.43174815  0.51960057  0.64893508  0.41759449  0.94981551 -0.81672227
  -0.542593   -0.87390691 -0.46389657 -0.274625   -0.36413085  0.51010424
   0.66209233 -0.73945904  0.3925795  -0.98464239 -0.71965206 -0.27119341
   0.28131872 -0.05389173 -0.20312579 -0.96939176 -0.28858685  0.85573143
  -0.60372329 -0.00849473  0.63371503  0.32733151 -0.14613727  0.90244645
   0.58168811  0.73726863 -0.99762869 -0.68479407  0.80733967 -0.65959471
   0.35820207 -0.31064916 -0.71992803  0.56312472 -0.89431524 -0.06813895
  -0.68084377 -0.54303217 -0.02863637  0.42419663]]
After layer encoder_birnn_forward_l0_t6_state_0 (1, 256) <class 'numpy.float32'> [[  5.98204255e-01   7.09251761e-01  -1.06747603e+00  -6.50415480e-01
    1.43493438e+00  -2.51535952e-01   2.03620863e+00   4.77139466e-03
   -5.09301126e-01  -1.80309922e-01   1.25880098e+00   1.25005913e+00
    3.31739813e-01  -1.59381890e+00   1.25462025e-01   2.59060878e-03
    8.10263991e-01   1.20884442e+00  -3.27305079e-01   7.88205504e-01
   -2.78774470e-01  -4.47454304e-01  -1.72147870e+00   8.38974953e-01
   -3.73504996e-01  -2.98157722e-01  -1.63695753e+00  -7.40294680e-02
   -1.54660010e+00   1.05139327e+00   1.08099210e+00  -6.70615673e-01
    1.50371408e+00  -7.92092323e-01   2.45022631e+00   6.52995884e-01
    7.02058792e-01  -1.99788165e+00  -2.10519552e+00  -1.68821216e-02
   -1.19916931e-01   1.37979221e+00  -5.27228475e-01   8.51477623e-01
   -1.65882194e+00  -7.00266480e-01  -1.15859844e-01   1.05487680e+00
    8.20619822e-01   3.78447950e-01  -1.28511749e-02   2.89857797e-02
   -2.01633525e+00  -7.36705780e-01   2.01979876e+00   7.01871097e-01
   -1.54419684e+00  -2.91972160e-01   1.10820568e+00   1.20874662e-02
    1.01064098e+00  -2.16521800e-01   2.79554576e-01   2.10272145e+00
   -8.40010166e-01   1.60336137e-01   1.29316878e+00   1.99393678e+00
    7.45434642e-01  -1.94133472e+00   5.24745762e-01   5.69603145e-02
   -2.51973057e+00   8.07868004e-01   9.82050180e-01   2.66624212e+00
    1.40085554e+00  -3.20596123e+00   1.23527527e+00  -4.96316969e-01
    1.94331586e+00  -8.22397113e-01  -2.72997975e-01   3.11508387e-01
   -1.15872550e+00  -1.51822162e+00   3.68726790e-01  -2.30911112e+00
    5.23282647e-01  -1.42957211e-01   1.01295066e+00   5.70579171e-01
   -7.51956761e-01  -8.54134202e-01  -6.07983947e-01  -3.27128679e-01
   -1.55400944e+00  -2.07561421e+00   1.45245898e+00   5.11982918e-01
   -9.33171809e-01  -8.77246037e-02  -4.46338989e-02   1.61987185e+00
   -1.25180960e+00  -1.07721281e+00   7.86357224e-01   8.79915118e-01
    6.54290795e-01   8.57410192e-01  -1.90180683e+00  -1.84995413e+00
    2.78932476e+00   2.93704486e+00  -5.31051755e-01   1.54289746e+00
    1.08541012e+00   5.94016314e-01   7.23167062e-01   1.78830758e-01
    2.11875916e-01  -1.85157096e+00   1.89918888e+00  -8.19603860e-01
    2.40995574e+00  -4.50645626e-01   9.53767061e-01   1.04624557e+00
   -1.25249207e+00  -2.69513750e+00   3.18874478e-01   1.47670460e+00
    6.49257660e-01  -4.15632993e-01   1.53948641e+00   1.69142556e+00
    9.36591864e-01   4.20686007e-01  -2.04743838e+00  -6.45894349e-01
   -3.65801156e-02   1.84164667e+00  -1.68681765e+00  -2.80892611e-01
    1.51917076e+00   2.50417553e-02   9.13155556e-01   3.65835242e-03
    2.00466037e+00  -3.03338110e-01   2.16689539e+00  -1.20445323e+00
    2.02842689e+00   1.59456754e+00   5.42173147e-01  -1.56695175e+00
    1.83702397e+00  -7.72990957e-02   1.74099517e+00   1.43771946e+00
    2.55993271e+00   1.23587489e-01   9.10245240e-01   1.66341400e+00
   -5.43060780e-01   3.49059165e-01  -1.27750829e-01   1.36026347e+00
   -6.02021992e-01  -9.54751074e-01   2.18111664e-01   3.30477452e+00
   -7.87146151e-01   2.33524036e+00  -1.10518599e+00  -1.14085340e+00
    2.84197748e-01   1.99164405e-01  -5.96666694e-01  -4.38024551e-01
    1.72749591e+00   9.93411779e-01   1.05922699e+00   1.08573627e+00
   -4.12500836e-02  -1.31550920e+00  -8.06689978e-01   1.78016305e+00
    1.11024892e+00  -1.14319992e+00   4.94635701e-01  -1.08670759e+00
   -1.97452998e+00   1.41308975e+00   5.03005028e-01  -1.61601639e+00
   -9.02566493e-01  -1.32367635e+00   1.40043795e+00  -3.01771343e-01
    7.17571899e-02  -1.57508469e+00  -1.44465077e+00  -1.39130759e+00
   -5.75300932e-01  -2.57245064e-01   1.78061819e+00   4.81152236e-02
    3.53591919e-01   3.40626925e-01  -8.21524084e-01   9.76795852e-01
    1.23082161e+00   7.80099630e-01   2.82358599e+00  -1.96430624e+00
   -9.31611657e-01  -1.99919915e+00  -6.99060738e-01  -4.62544739e-01
   -6.00758076e-01   1.05689073e+00   1.07549071e+00  -1.74448550e+00
    6.87979579e-01  -2.82874537e+00  -1.00604773e+00  -5.20626009e-01
    5.88482618e-01  -8.08297247e-02  -3.98067117e-01  -2.82250977e+00
   -5.08675694e-01   1.85044074e+00  -1.30119896e+00  -2.46109255e-02
    1.21460199e+00   5.97501278e-01  -2.66302526e-01   2.54381251e+00
    1.03885746e+00   1.74390817e+00  -3.68752742e+00  -1.08120573e+00
    1.61510801e+00  -9.73319054e-01   6.32273436e-01  -5.61771989e-01
   -1.48174214e+00   1.12825406e+00  -2.38405228e+00  -1.20893165e-01
   -1.45933390e+00  -1.04515982e+00  -6.89746365e-02   8.09860706e-01]]
After layer activation1032_output (1, 256) <class 'numpy.float32'> [[ 0.53577054  0.61020744 -0.78850842 -0.5719496   0.89267337 -0.24636193
   0.96649843  0.00477136 -0.46940047 -0.17838095  0.85073322  0.84830022
   0.3200832  -0.9207328   0.12480786  0.0025906   0.66973585  0.8363325
  -0.31609717  0.65739125 -0.27177045 -0.41980422 -0.93804085  0.68526578
  -0.35705367 -0.28962576 -0.92704606 -0.07389453 -0.91322279  0.78234744
   0.7935667  -0.58538473  0.90581715 -0.65959275  0.98522353  0.57368332
   0.60567296 -0.96387762 -0.97075289 -0.01688052 -0.11934542  0.88090473
  -0.48325965  0.69184065 -0.93005836 -0.60453689 -0.1153442   0.7836951
   0.67540705  0.36135885 -0.01285047  0.02897766 -0.96516371 -0.62715077
   0.96539998  0.6055541  -0.9128229  -0.28394896  0.80342722  0.01208688
   0.76602697 -0.21320044  0.27249277  0.97060996 -0.68581444  0.15897617
   0.85995418  0.9635967   0.63241744 -0.95963973  0.48135448  0.05689879
  -0.98712891  0.66841245  0.75395203  0.99038237  0.88553643 -0.99672163
   0.84410268 -0.45921573  0.95979607 -0.67637241 -0.26641223  0.30180871
  -0.82062411 -0.90838724  0.35287753 -0.9804523   0.48022959 -0.14199126
   0.76697969  0.5157845  -0.63631487 -0.69322312 -0.54270637 -0.31593841
  -0.91444463 -0.96899801  0.89617801  0.47148874 -0.73206925 -0.08750027
  -0.04460428  0.92460561 -0.84879029 -0.79216325  0.65634048  0.70637679
   0.57455146  0.6949209  -0.95639187 -0.95174164  0.99247313  0.99439305
  -0.48618463  0.91260594  0.79519677  0.53277802  0.61886722  0.17694847
   0.20876136 -0.95189369  0.95616794 -0.67485422  0.98399413 -0.42242959
   0.74148375  0.7803424  -0.84898096 -0.99091995  0.30848885  0.90084875
   0.57116997 -0.3932451   0.91203403  0.93432856  0.73365247  0.3975082
  -0.96723026 -0.56889957 -0.03656381  0.95095295 -0.93374068 -0.27373099
   0.90855306  0.02503652  0.72264338  0.00365834  0.96435535 -0.29436445
   0.97410423 -0.83500791  0.9659819   0.9208467   0.4946312  -0.91653955
   0.95050865 -0.07714551  0.94034195  0.89323771  0.98811734  0.12296209
   0.72124994  0.93067557 -0.49530137  0.33554089 -0.12706037  0.87645417
  -0.53848684 -0.74192643  0.21471752  0.99730873 -0.6567893   0.98143834
  -0.8023541  -0.81470126  0.2767857   0.19657215 -0.53467345 -0.41200566
   0.93875933  0.75881338  0.78536785  0.79531664 -0.0412267  -0.86566275
  -0.66776025  0.9447127   0.80415034 -0.81548882  0.45788798 -0.79567331
  -0.96218324  0.88814843  0.46447715 -0.92404419 -0.71754527 -0.86769527
   0.88544625 -0.29293278  0.07163429 -0.91783077 -0.89463007 -0.88345826
  -0.51924169 -0.25171694  0.94476163  0.04807813  0.33955717  0.32803696
  -0.67589855  0.75167549  0.84281749  0.65276384  0.99296987 -0.96141708
  -0.73134446 -0.96397096 -0.60377121 -0.432156   -0.53758872  0.78447092
   0.79152089 -0.94074464  0.59668243 -0.99304175 -0.76412237 -0.478183
   0.52880347 -0.08065415 -0.3782939  -0.99295473 -0.46891269  0.95178747
  -0.86203146 -0.02460596  0.83805466  0.53526914 -0.26018098  0.98773038
   0.77743649  0.94067824 -0.99874741 -0.7936458   0.92391133 -0.7501592
   0.55961567 -0.50929093 -0.9017939   0.81042087 -0.98315024 -0.12030763
  -0.89752316 -0.77991748 -0.06886546  0.66951346]]
After layer encoder_birnn_forward_l0_t6_out_0 (1, 256) <class 'numpy.float32'> [[ 0.45160094  0.44032174 -0.58114839 -0.46430272  0.6505506  -0.20054956
   0.91799456  0.00337623 -0.36950803 -0.13281643  0.65860438  0.65177393
   0.23238094 -0.80533612  0.05796927  0.00151854  0.51682961  0.5566901
  -0.29505169  0.53258485 -0.1891991  -0.19813059 -0.85024512  0.56975472
  -0.25138658 -0.19594753 -0.81359112 -0.05790599 -0.50630289  0.59481829
   0.66385955 -0.47600329  0.4828895  -0.47439045  0.70775884  0.36297336
   0.48057091 -0.59730452 -0.27315262 -0.01143062 -0.08159816  0.6525563
  -0.35156912  0.51207924 -0.69172281 -0.46683404 -0.10787451  0.63194668
   0.49270219  0.20345624 -0.00468673  0.02304345 -0.95655578 -0.27709165
   0.76269376  0.27203381 -0.59982795 -0.20502427  0.64140105  0.00854682
   0.39899567 -0.1418698   0.15262246  0.84126621 -0.45343494  0.11800691
   0.7274285   0.66118759  0.47514856 -0.66479832  0.38416234  0.0445092
  -0.91319442  0.50471216  0.5270043   0.9753378   0.68050635 -0.97553629
   0.72804427 -0.25598899  0.86404753 -0.28781724 -0.26409602  0.22103201
  -0.69659263 -0.62745363  0.23694663 -0.77996337  0.45800725 -0.11583399
   0.54338247  0.3925308  -0.20961677 -0.60248518 -0.3222478  -0.25454316
  -0.74038035 -0.79998451  0.72478276  0.42712444 -0.44921899 -0.06116498
  -0.02602336  0.8311919  -0.70221317 -0.48804671  0.49875206  0.58152401
   0.48591805  0.40495789 -0.84898752 -0.74305707  0.9492687   0.93607324
  -0.40017843  0.69330603  0.61546648  0.49177554  0.47671866  0.14098746
   0.1507978  -0.88443202  0.77143413 -0.50508726  0.80204999 -0.35533267
   0.38796824  0.43818548 -0.60347152 -0.96248913  0.24833125  0.81760073
   0.40363213 -0.29588977  0.59870154  0.6160993   0.61405468  0.27594727
  -0.83550715 -0.44748107 -0.02414934  0.73901635 -0.69924098 -0.2163081
   0.60838252  0.0206913   0.52816951  0.00260603  0.52099127 -0.18687233
   0.91936052 -0.54532903  0.76247042  0.49246144  0.3183493  -0.44500637
   0.6344524  -0.05725963  0.8684575   0.69658929  0.74240655  0.09984385
   0.41682464  0.771586   -0.44599739  0.20716535 -0.09822628  0.53388941
  -0.22754139 -0.48324755  0.14561869  0.99159098 -0.52809554  0.87661761
  -0.41910011 -0.50522286  0.20809796  0.15588129 -0.35915339 -0.35628688
   0.70066547  0.36315525  0.63184583  0.64723879 -0.02713619 -0.69032556
  -0.50789762  0.62783635  0.63850659 -0.6986717   0.20628901 -0.59257329
  -0.88807052  0.65549839  0.27235386 -0.73937231 -0.71359223 -0.61963004
   0.68558663 -0.23084742  0.04520201 -0.54404318 -0.71909064 -0.77830923
  -0.4230755  -0.2096699   0.82497025  0.02549271  0.11345609  0.24802296
  -0.54576081  0.4945564   0.74126655  0.54490781  0.96744597 -0.87505233
  -0.49532712 -0.87189597 -0.49760097 -0.29901236 -0.38166538  0.63989365
   0.38507938 -0.58579606  0.48828936 -0.70623201 -0.59364384 -0.36109418
   0.41261694 -0.05412197 -0.24248424 -0.89156598 -0.37653518  0.75398123
  -0.71996409 -0.01734193  0.46165806  0.24203001 -0.19122054  0.92974836
   0.41743353  0.81491542 -0.9974789  -0.44981185  0.68748724 -0.4257524
   0.42888871 -0.40179884 -0.79752129  0.68140119 -0.87795073 -0.07836951
  -0.80527544 -0.6491484  -0.0480112   0.5266397 ]]
After layer expand_dims1038_0 (1, 1, 256) <class 'numpy.float32'> [[[ 0.45160094  0.44032174 -0.58114839 -0.46430272  0.6505506  -0.20054956
    0.91799456  0.00337623 -0.36950803 -0.13281643  0.65860438  0.65177393
    0.23238094 -0.80533612  0.05796927  0.00151854  0.51682961  0.5566901
   -0.29505169  0.53258485 -0.1891991  -0.19813059 -0.85024512  0.56975472
   -0.25138658 -0.19594753 -0.81359112 -0.05790599 -0.50630289  0.59481829
    0.66385955 -0.47600329  0.4828895  -0.47439045  0.70775884  0.36297336
    0.48057091 -0.59730452 -0.27315262 -0.01143062 -0.08159816  0.6525563
   -0.35156912  0.51207924 -0.69172281 -0.46683404 -0.10787451  0.63194668
    0.49270219  0.20345624 -0.00468673  0.02304345 -0.95655578 -0.27709165
    0.76269376  0.27203381 -0.59982795 -0.20502427  0.64140105  0.00854682
    0.39899567 -0.1418698   0.15262246  0.84126621 -0.45343494  0.11800691
    0.7274285   0.66118759  0.47514856 -0.66479832  0.38416234  0.0445092
   -0.91319442  0.50471216  0.5270043   0.9753378   0.68050635 -0.97553629
    0.72804427 -0.25598899  0.86404753 -0.28781724 -0.26409602  0.22103201
   -0.69659263 -0.62745363  0.23694663 -0.77996337  0.45800725 -0.11583399
    0.54338247  0.3925308  -0.20961677 -0.60248518 -0.3222478  -0.25454316
   -0.74038035 -0.79998451  0.72478276  0.42712444 -0.44921899 -0.06116498
   -0.02602336  0.8311919  -0.70221317 -0.48804671  0.49875206  0.58152401
    0.48591805  0.40495789 -0.84898752 -0.74305707  0.9492687   0.93607324
   -0.40017843  0.69330603  0.61546648  0.49177554  0.47671866  0.14098746
    0.1507978  -0.88443202  0.77143413 -0.50508726  0.80204999 -0.35533267
    0.38796824  0.43818548 -0.60347152 -0.96248913  0.24833125  0.81760073
    0.40363213 -0.29588977  0.59870154  0.6160993   0.61405468  0.27594727
   -0.83550715 -0.44748107 -0.02414934  0.73901635 -0.69924098 -0.2163081
    0.60838252  0.0206913   0.52816951  0.00260603  0.52099127 -0.18687233
    0.91936052 -0.54532903  0.76247042  0.49246144  0.3183493  -0.44500637
    0.6344524  -0.05725963  0.8684575   0.69658929  0.74240655  0.09984385
    0.41682464  0.771586   -0.44599739  0.20716535 -0.09822628  0.53388941
   -0.22754139 -0.48324755  0.14561869  0.99159098 -0.52809554  0.87661761
   -0.41910011 -0.50522286  0.20809796  0.15588129 -0.35915339 -0.35628688
    0.70066547  0.36315525  0.63184583  0.64723879 -0.02713619 -0.69032556
   -0.50789762  0.62783635  0.63850659 -0.6986717   0.20628901 -0.59257329
   -0.88807052  0.65549839  0.27235386 -0.73937231 -0.71359223 -0.61963004
    0.68558663 -0.23084742  0.04520201 -0.54404318 -0.71909064 -0.77830923
   -0.4230755  -0.2096699   0.82497025  0.02549271  0.11345609  0.24802296
   -0.54576081  0.4945564   0.74126655  0.54490781  0.96744597 -0.87505233
   -0.49532712 -0.87189597 -0.49760097 -0.29901236 -0.38166538  0.63989365
    0.38507938 -0.58579606  0.48828936 -0.70623201 -0.59364384 -0.36109418
    0.41261694 -0.05412197 -0.24248424 -0.89156598 -0.37653518  0.75398123
   -0.71996409 -0.01734193  0.46165806  0.24203001 -0.19122054  0.92974836
    0.41743353  0.81491542 -0.9974789  -0.44981185  0.68748724 -0.4257524
    0.42888871 -0.40179884 -0.79752129  0.68140119 -0.87795073 -0.07836951
   -0.80527544 -0.6491484  -0.0480112   0.5266397 ]]]
After layer encoder_birnn_forward_l0_t7_i2h_output (1, 1024) <class 'numpy.float32'> [[ 0.07376467 -0.04585483  0.06153381 ...,  0.03591035  0.03396329
   0.02903319]]
After layer encoder_birnn_forward_l0_t7_h2h_output (1, 1024) <class 'numpy.float32'> [[ 1.03656387  0.96709329  0.69150096 ...,  1.9814558   1.05076218
   1.61739659]]
After layer _plus1033_0 (1, 1024) <class 'numpy.float32'> [[ 1.11032856  0.92123848  0.75303477 ...,  2.01736617  1.0847255
   1.64642978]]
After layer encoder_birnn_forward_l0_t7_slice_output0 (1, 256) <class 'numpy.float32'> [[ 1.11032856  0.92123848  0.75303477  0.68975747  1.46911633  1.29715657
   2.55366778  0.18196443 -0.94671464  0.87968636  0.87295491  1.44924784
  -0.13608299  1.71997702 -0.77638459  0.33503464  0.4998368   1.1342988
   1.41679454  0.7104094   0.03659446 -1.58638299  0.86809254  0.61903971
   0.37481737  0.46724218  1.52566063 -0.05075681  1.26896226  1.45701206
   1.18794239  0.89937085  1.87744665  1.16637194  3.32048821  0.22953674
   0.51463223  3.18774414  2.31307125 -1.46142364 -0.57438928  1.00355756
   2.22352314  0.09684268  3.08572197  0.92157203  0.63413852  1.12873006
   0.46802852 -0.35751447 -0.417427   -0.5391925   5.88460493  0.58284181
   2.29242396 -0.02452886  2.04429936  0.21890979  0.82530606 -1.70846605
   0.60101342  0.46907765 -0.27103043  2.26440263  0.15445717  0.2507987
   1.55021417  2.57575893  1.21106923  2.17090416 -0.42141819 -1.65565944
   3.30929089  1.04848886  0.79460418  3.38998485  1.41032231  4.69636488
   1.15004337 -1.12586343  2.08340573  0.90883833  1.28596067 -0.20586111
   1.99589097  1.34753096  0.69422001  2.86114907  2.14676142 -0.38701263
   1.17652273 -0.35244021 -0.35791892  1.07913792 -1.01914465 -1.58344126
   1.95275331  2.4236629   1.80335152  0.97940218  0.60785526 -0.62432975
   0.75168139  2.46758223  1.36698294  0.52287167  0.14123163  0.41319019
  -0.21492356  0.20510565  2.19308019  1.90591133  4.0047617   4.87314177
   1.39167047  1.69991338  0.81898946  1.81951296  0.43498319 -0.483729
  -0.41329736  2.12980318  3.44099736  0.8524754   3.17291069  0.43651587
   0.84426796  0.96622664  0.53014547  3.40222549 -0.63587588  1.69467998
   0.97300923  0.41834977  1.8606354   1.45917583  1.25935209 -1.19638193
   1.4765836  -0.0629795   0.27228343  2.25771618  1.4896034   0.04462728
   1.15758574 -1.17922306  0.12008934 -0.48132312  1.89247155 -0.29247057
   2.95467806  1.6717869   3.08880067  2.29978752  0.22237976  1.98019874
   1.23127604 -0.42427105  1.81678617  1.57406998  3.37404513 -0.30328745
   1.53749633  1.76341069  1.41169465 -0.07291899  0.29468775  1.0999496
  -0.29403514  0.6980564  -0.85469067  6.99492598  0.74474084  2.34537864
   1.22012115  0.39437777 -0.42649174 -0.82628745  0.03345839  0.80414504
   2.42350268  0.73957807  0.99198842  0.58667833 -0.38262978  1.13192368
   0.27392188  2.03874302  1.40763152  1.15766597 -0.93092185  0.38954005
   2.45810843  0.80609667  0.74568838  1.98895693  5.57865572  2.31533813
   1.36452341  0.24218383  0.57534128  1.68128717  1.09448147  1.30357492
   1.09042645  0.00998743  1.56611896 -0.76003557 -0.79767925  0.79803205
   1.35207021  0.78214157  2.21395755  0.96791786  3.73204494  2.04547477
   0.7059918   2.61918926  0.95706564 -0.93200558  0.55537164  0.67503524
   0.97897965  1.35368967  1.1691823   5.33488798  1.22966719 -0.23855568
  -0.05227505 -0.0584039  -0.90728343  4.43737841  0.68686271  2.37114191
   1.44469225 -0.11174741  0.69611835 -0.5349468   0.05692507  2.81414223
   0.55395877  1.43647552  7.73374319  1.04571843  1.84330487  1.28409505
   0.73062992  0.50021285  1.59034383  0.71725667  2.83551717 -1.10719717
   1.84077489  0.99506736 -0.54400045  0.72657508]]
After layer encoder_birnn_forward_l0_t7_slice_output1 (1, 256) <class 'numpy.float32'> [[ 2.08994055  0.21563053  0.4362562   0.85143656  0.71377182  0.83768749
   2.51155996  0.74192363  3.3121624   0.69184315  2.362077    0.96546751
   1.53056896  1.57504869 -0.37102228  0.75529486  0.83728069  0.6963746
   1.90860033  1.29621673  0.24444017 -0.48747906  2.18574715  0.43172699
   1.16183424  1.19214618  1.4717505   0.76973999  1.7182076   0.55592418
   1.92216146  1.57064116  0.98488063  1.07511175  2.7191906   0.68213588
   0.36655271  1.06682444  2.66995859 -0.07020721  1.42788112  0.96109128
   2.36557317 -0.37572306  0.25682148 -0.54940307  2.52828765  1.15970862
   0.485392   -0.34777987 -0.54129624  0.99298668  4.80486155 -0.59264177
   1.97330129 -0.74891043  0.58813715  1.13140881  1.16146457  1.62432861
  -0.04773495  0.81864935  0.42970049  1.74537575  0.48209575  1.01350212
   1.55500889  1.61011004  0.86055386  2.51862264 -0.04355973  1.32467914
   2.82139421  1.10152233  0.31209373  4.56115389  0.75285292  4.34611845
   1.50402331 -0.98878407  2.15006185 -0.82893723  3.58577681  1.57304049
   1.86375141  1.3844856   0.11017397  2.54241562  4.53139067  0.67388552
   0.42933279  1.22175264 -0.17623639  1.19885838 -0.40942451  0.01297359
   2.21947789  2.00053239  1.88099837  2.06979465  0.42042661 -0.38899505
   0.05591052  1.89103913  1.77618694  0.58112341  1.04376745  1.36882949
   1.14283061  0.84302419  1.84546387  2.5225904   3.11548018  3.46712041
   1.58200288  0.95330101  1.68855059  2.22753596  0.9226144   0.83698219
   1.13824272  2.50346208  1.35993099  0.92619944  1.94337964  1.28536892
  -0.96088451  0.97257704  0.97403574  3.5332377   0.88236946  1.62094617
   0.43813947  0.70258921  0.83801413  1.50145614  1.93166804 -0.87778747
   2.61924076  1.67347085  0.97596586  1.30447459  1.51175427  1.42898679
   1.58732295  1.83081007  0.6638357   1.30736065  2.15000272  1.16815138
   1.79542148  0.50085908  1.22220778  1.41520178  0.93602264  0.73084396
   2.14953947  0.81836486  2.36877322  1.24988294  2.46272349  1.29553866
   1.83153462  1.45536935  1.7854346   0.59422058  0.76749706  0.9642325
  -0.48073831  0.47430789 -0.55543655  3.54476166  0.93052495  2.63354945
   0.22116545  0.54851532  0.94943446  1.78181458 -0.20116651  2.34457183
   0.92347085 -0.32681149  1.85751224  1.37888014  1.07360435  1.16504097
   1.83436334  1.34032142  1.31300497  1.65090251 -0.91293311  1.02541566
   2.32500267  1.35504079 -0.06065381  0.74874628  7.25587273 -0.21716169
   1.23599231 -0.23146418  0.69447494  1.38239968  0.88196415  2.57785916
   1.20935011  0.68401963  2.02567768 -0.76832241 -0.29406035  1.79206753
   1.69626343  1.02909756  1.57487893  1.23264921  3.58537674  2.47119188
   0.51109594  1.90655577  0.0295015  -0.11905549  0.5994423   1.47163987
  -0.02680054  1.62005985  1.12405324  2.7347827  -1.00823343  0.84400046
   1.1875118   0.84584475  0.76341236  3.26199389  0.53929567  1.26438129
   2.06890297  1.18840241  0.61742973  0.30251497  0.68779463  3.00155449
   0.43533483  2.03518414  7.39126968 -0.39311206  1.13167012 -0.34520027
   0.51529306  1.00051641  1.34424591  1.40691948  2.66049457 -0.27904385
   2.3129344   1.0263052   0.90406603  1.33606911]]
After layer encoder_birnn_forward_l0_t7_slice_output2 (1, 256) <class 'numpy.float32'> [[ 0.60653538  0.83763242 -2.37873316 -0.92773807  2.9624939  -0.17807277
   2.5769999  -0.12182406 -0.73729187 -0.26833263  1.70221412  1.74905562
   0.46034983 -2.2468493   0.3448222  -0.04943324  1.1392802   2.03098702
  -0.57923883  1.08063722 -0.36225012 -4.11045265 -3.46922255  1.33246696
  -0.45063299 -0.45733723 -2.96280146 -0.13591233 -2.57279587  1.5332377
   1.29819536 -0.7636376   2.30479479 -0.83567429  4.32905817  1.1171869
   0.98820955 -4.1417985  -3.04469609 -0.1758315  -0.18327871  3.30693269
  -0.60768235  2.48477149 -4.91418123 -1.09188735  0.05239886  1.27210438
   1.45800686  0.85424805  0.10365854  0.1177426  -1.59293532 -1.40969431
   3.19019365  1.86474872 -3.72397232 -0.38936371  1.89535737  0.04885524
   2.47632408 -0.22621046  0.5074665   6.13421869 -1.95564485  0.1815553
   1.70231724  2.99302197  0.73918366 -2.69348335  1.09243667 -0.02667813
  -4.01209021  0.97942948  1.63232386  3.08947945  2.83413839 -5.51535606
   1.75856328 -3.55572748  3.83998346 -1.70855844 -0.02034543  0.59364069
  -1.24583697 -2.72828674  0.49934375 -3.66515183  0.37157986 -0.14269033
   1.65963423  1.02922523 -3.02977037 -1.01366949 -4.38783407 -0.94005144
  -1.62469149 -3.92256451  1.67669296  0.5386672  -2.04706669 -0.15552756
  -0.20340107  1.79572868 -1.31958723 -2.80712271  1.10109985  1.28240454
   1.01411521  1.5806514  -3.2723608  -2.38044739  4.81931305  4.59651423
  -0.49076587  2.86613107  1.45590496  0.63981032  0.86922449  0.35983318
   0.41268337 -2.16991138  2.74116373 -1.13927484  5.03194189 -0.80299121
   3.75605845  1.69653332 -3.10914302 -4.04245424  0.58911926  1.73737991
   0.89559305 -0.60009575  2.87996364  3.36779881  1.20560801  2.45613194
  -3.97402406 -0.93675792 -0.17849135  3.85461235 -3.31287408 -0.45281661
   2.9160552   0.14197259  2.28375554  0.03788284  3.89568448 -0.41639739
   4.14807749 -1.88550043  4.47786999  2.3165164   0.82937294 -3.5968399
   3.71493173 -0.16445775  2.21579146  2.13502932  5.6822443   0.09496866
   1.02412176  2.63739109 -0.5272488   0.44558087 -0.27944288  2.68783879
  -1.67047358 -1.60799932  0.54072315  5.80972338 -1.15895069  4.46047783
  -2.2092855  -3.77988935  0.58204693  0.30134577 -1.44939065 -0.47176218
   3.70598221  2.57217288  1.21371245  1.66804469 -0.14817071 -1.99955952
  -1.09707165  3.49668074  1.57871425 -1.40142751  3.25930691 -2.0785439
  -2.55291557  3.08074427  0.76610756 -3.5955596  -0.24944922 -3.03853798
   2.20522165 -0.41681647  0.14663626 -2.44193673 -4.09797668 -1.6363529
  -0.71776223 -0.10699005  3.030972    0.03610982  0.78544873  0.53797519
  -0.85192186  1.4979099   1.33358002  0.91405445  4.57411289 -2.93315148
  -1.61734366 -3.50988841 -0.99921292 -1.39974332 -0.91929996  1.36890614
   2.89806986 -4.21054459  0.81837875 -5.34264135 -2.83931088 -0.81278056
   0.86734879 -0.2352961  -1.04600191 -4.06875658 -0.64611256  3.59871149
  -1.44847441  0.0654081   2.83653188  1.61824644 -0.41696978  5.49466515
   2.49161839  2.53662801 -5.67809248 -3.22587991  3.08183527 -1.94141734
   0.69146824 -0.71643585 -2.07241583  1.68756914 -3.43173146 -0.25510967
  -1.59246027 -1.23815441  0.05922768  1.12241256]]
After layer encoder_birnn_forward_l0_t7_slice_output3 (1, 256) <class 'numpy.float32'> [[ 2.22930741  1.21641564  1.29840374  1.82799363  1.2729882   1.89444113
   3.6990521   1.20252085  1.63905776  1.28542578  1.64977407  1.48820376
   1.32976067  2.4352181  -0.20939434  0.42098409  1.51250982  0.90713072
   3.37943149  1.79890406  1.12814701 -0.24526988  2.80283403  2.05552745
   1.06383467  1.06679094  2.53800535  1.62926722  0.24896151  1.43205142
   2.17794275  1.84115756  0.18548089  1.17171466  1.21375048  0.76579142
   1.73671973  0.67141968 -1.16966331  0.92854482  0.92604131  1.30732501
   1.27004993  1.29699695  1.36166859  1.51653826  3.28145003  1.86939979
   1.24477708  0.31943583 -0.68814814  1.77233672  5.95741081 -0.32544869
   1.71571004 -0.34512877  0.91134602  1.27725732  1.78376579  1.14138639
   0.14427418  0.77357411  0.30744919  2.43538189  0.90257955  1.34685302
   2.15608215  1.02157009  1.49362636  0.97369778  1.70158863  1.66906202
   3.1339016   1.45719945  1.06983447  5.27423906  1.54019392  4.79757643
   2.26801109  0.22535871  2.79338193 -0.36953008  5.97294998  1.25496638
   2.1703763   0.98550427  0.94380611  1.69913852  3.78808928  1.9637388
   1.12359464  1.54809058 -0.92643499  2.37972069  0.45150977  1.6569711
   1.8487457   1.97750235  1.77736986  2.92454767  0.5660578   1.03619623
   0.47764188  2.82576966  1.98693871  0.58558559  1.54129553  1.93104696
   2.20199728  0.44244686  2.59781957  1.64914823  3.88169146  3.43826437
   1.97860634  1.47764778  1.5879612   3.18937325  1.57114732  1.7138133
   1.15404904  3.2708621   1.90276253  1.32458889  1.90941346  2.1177814
   0.03437836  0.43985099  1.21138084  4.46331215  1.78571761  2.89643216
   1.17998338  1.43396521  0.80100513  0.92180037  2.12049127  0.94174701
   2.29453921  1.77676308  0.91305006  1.63232827  1.3848089   1.77267992
   0.91371566  2.10719061  1.28006232  1.22291303  0.2263905   0.71776342
   3.63137627  0.83350611  1.64813399  0.17597947  0.83380663 -0.04960931
   0.8805759   1.454566    3.22246718  1.6286658   1.31023097  1.88723421
   0.31707904  2.10815215  2.83622551  0.57844651  1.61829686  0.51123458
  -0.45112294  0.78973937  0.8518303   6.41340733  1.71961951  2.67844915
   0.21801698  0.67050374  1.52122557  1.77910268  0.90360689  2.44552994
   1.36239719 -0.07733164  1.82727981  1.88896155  0.83250165  1.70382702
   1.49070752  0.89106196  1.7678082   2.20021319 -0.29254299  1.38392317
   3.14070249  1.16956842  0.51003408  1.69338727  6.52491331  1.15677404
   1.52041721  1.65353811  0.67664409  0.56780899  1.78714299  2.55812025
   1.89005411  1.98661184  2.45818949  0.09515387 -0.91719979  1.48118484
   1.87135339  0.80538374  2.57893872  2.06239462  4.61161852  2.9198947
   0.98977304  2.87934661  1.94139004  0.94529706  1.12510836  1.88456094
  -0.12351558  0.57088375  1.95003784  1.1405189   1.53725827  1.50108659
   1.61592233  1.01326525  0.86092395  2.80058336  1.79206753  1.63426709
   2.07026339  1.18406534  0.33043054 -0.1666863   1.35653698  3.54819918
   0.24291345  2.38272691  8.44051075  0.39534318  1.3953265   0.31187502
   1.54739046  1.7283963   2.64227867  2.03854966  2.60283518  0.8243292
   2.75590634  2.01736617  1.0847255   1.64642978]]
After layer encoder_birnn_forward_l0_t7_o_output (1, 256) <class 'numpy.float32'> [[ 0.90285063  0.77143216  0.78556621  0.86152256  0.78125387  0.86926115
   0.97585058  0.76897293  0.83740664  0.78337198  0.83886057  0.81580848
   0.79080105  0.91947371  0.44784185  0.60371876  0.81943285  0.71241266
   0.9670555   0.85801548  0.7554968   0.43898812  0.94282877  0.88650495
   0.74342263  0.74398619  0.92676359  0.83606923  0.56192088  0.80722076
   0.89825118  0.86308557  0.54623777  0.76345485  0.77096188  0.6826098
   0.85026991  0.66182095  0.23691584  0.71678001  0.71627152  0.78706515
   0.78075129  0.78532916  0.79603076  0.82002819  0.96378696  0.86638886
   0.77639443  0.57918674  0.33444515  0.85474801  0.99742007  0.41934845
   0.84757543  0.41456416  0.71327549  0.78198254  0.85616124  0.75793403
   0.53600609  0.68429351  0.57626247  0.91948581  0.71147931  0.79361463
   0.89623576  0.73527831  0.81662196  0.72585595  0.84574211  0.84145069
   0.95826972  0.81110394  0.74456543  0.99490428  0.82349294  0.99181771
   0.90619284  0.5561024   0.94231713  0.4086546   0.99745983  0.77815837
   0.89755756  0.72819901  0.71986783  0.84542221  0.97786236  0.87693703
   0.75465488  0.82463777  0.28364852  0.91526783  0.61099815  0.83983099
   0.86397982  0.87841469  0.85537177  0.94904661  0.63785303  0.73811543
   0.6171909   0.94405264  0.87941891  0.64235163  0.82365298  0.87336528
   0.90042871  0.6088419   0.9307211   0.83877593  0.97980052  0.96887928
   0.87853253  0.81421703  0.83032906  0.96043241  0.82794714  0.84733021
   0.76024973  0.96341562  0.87020391  0.78994411  0.87095326  0.89261943
   0.50859374  0.60822356  0.77054322  0.98860723  0.85640144  0.9476698
   0.76494479  0.80751842  0.69018942  0.7154088   0.89287889  0.71945244
   0.90842378  0.85529667  0.71362388  0.83648837  0.79976219  0.85479069
   0.7137599   0.89160013  0.78246045  0.7725758   0.55635715  0.67211431
   0.97420335  0.69709575  0.83863872  0.54388165  0.69715923  0.48760024
   0.70694155  0.81070018  0.96167111  0.83598673  0.78755182  0.86843985
   0.57861227  0.891693    0.94460231  0.64070988  0.83456016  0.62509584
   0.38909385  0.68777537  0.70095092  0.9983632   0.84807986  0.93574297
   0.5542894   0.66161597  0.82071888  0.85558605  0.71169019  0.92023396
   0.79614902  0.48067668  0.86143732  0.86863708  0.69688368  0.84603387
   0.8161844   0.70910925  0.85418487  0.90026867  0.4273814   0.79962033
   0.95854086  0.76306701  0.62481445  0.8446691   0.99853575  0.760746
   0.82059991  0.8393687   0.66298932  0.6382575   0.85657668  0.92811716
   0.86876166  0.87938422  0.92115825  0.52377051  0.28552878  0.81475151
   0.86661482  0.69112498  0.92949378  0.8871941   0.99016201  0.94882119
   0.72904307  0.94681603  0.87450475  0.72016841  0.75493503  0.86813408
   0.46916032  0.6389671   0.87545079  0.75777489  0.82306582  0.81773645
   0.83423197  0.73365867  0.70285368  0.94270736  0.85718054  0.83675337
   0.88797921  0.76567799  0.58186412  0.45842463  0.79519624  0.97202849
   0.56043154  0.91550064  0.99978417  0.59756827  0.80144119  0.57734287
   0.82453656  0.84920722  0.93353349  0.88478547  0.9310438   0.69515455
   0.94024605  0.88260835  0.74738717  0.83840799]]
After layer encoder_birnn_forward_l0_t7_f_output (1, 256) <class 'numpy.float32'> [[ 0.88992155  0.55369973  0.60736662  0.70086843  0.67123407  0.69797802
   0.92494822  0.67741638  0.96484375  0.66637683  0.91388941  0.72421515
   0.82208949  0.82850212  0.40829402  0.68033135  0.69789219  0.66738349
   0.87086183  0.78519756  0.56080759  0.38048765  0.89896226  0.60628599
   0.76166582  0.76712465  0.81332332  0.68346465  0.84789789  0.63550895
   0.87237924  0.82787496  0.72807556  0.7455678   0.93814957  0.66421521
   0.59062576  0.74399251  0.93523049  0.48245537  0.80657095  0.72334027
   0.91416419  0.40715882  0.56385475  0.36600292  0.92610121  0.76127976
   0.61902034  0.41392091  0.3678861   0.72967744  0.99187672  0.35602891
   0.87796527  0.32105875  0.64293766  0.75609881  0.76159877  0.83539122
   0.48806855  0.69394958  0.60580218  0.85136861  0.61824262  0.73370498
   0.82563603  0.83342671  0.70277637  0.92543709  0.48911181  0.78995919
   0.94382107  0.75054526  0.57739627  0.98965806  0.67979997  0.98720878
   0.81817377  0.27115232  0.89567459  0.30386981  0.9730323   0.82821667
   0.86573362  0.79971051  0.52751565  0.92706233  0.98934901  0.66237265
   0.60571432  0.77237177  0.4560546   0.76832163  0.39905012  0.50324339
   0.90198505  0.880853    0.86772579  0.8879326   0.60358536  0.40395924
   0.51397401  0.86887395  0.85522538  0.64132589  0.73957622  0.79719096
   0.75819898  0.69910175  0.86359358  0.92571038  0.9575268   0.96973765
   0.82948798  0.72177857  0.84403348  0.90269518  0.7155745   0.69782925
   0.75735688  0.92438418  0.79574847  0.71630359  0.87472296  0.78336233
   0.27670115  0.72563285  0.72592318  0.97161883  0.707313    0.83492553
   0.60781562  0.66876155  0.6980468   0.81779152  0.87343395  0.29363647
   0.93208963  0.84203804  0.72630703  0.78658706  0.81932104  0.80674338
   0.83023912  0.86185819  0.6601215   0.78707123  0.89566904  0.76281071
   0.85759068  0.62266117  0.77245188  0.80458516  0.71829551  0.67499048
   0.89562571  0.6938892   0.91441488  0.77727956  0.92148691  0.78508323
   0.86194444  0.81082344  0.85636663  0.64433295  0.68297923  0.72396845
   0.38207778  0.61640286  0.36460403  0.97193491  0.71718174  0.93298978
   0.55506712  0.63379103  0.72100145  0.85592073  0.44987729  0.91250181
   0.71574879  0.41901666  0.86500674  0.79881108  0.74528176  0.76224744
   0.86228067  0.79254276  0.7880156   0.83901298  0.28639999  0.73602617
   0.91092664  0.79495257  0.4848412   0.67890543  0.99929452  0.44592196
   0.77486563  0.44239092  0.66696167  0.79937607  0.70722908  0.92942291
   0.77018398  0.66463524  0.88346684  0.31684211  0.42701009  0.85718054
   0.8450461   0.73674095  0.82847798  0.77428192  0.97302181  0.92209744
   0.62506336  0.87063169  0.50737482  0.47027123  0.64552867  0.81330657
   0.49330023  0.8348034   0.75473976  0.93904811  0.26732573  0.69930708
   0.76629579  0.69969475  0.68209416  0.96310169  0.63164854  0.77977943
   0.88784379  0.76645523  0.64963377  0.57505721  0.6654762   0.95264435
   0.60714686  0.88444191  0.99938369  0.40296835  0.75614697  0.41454682
   0.62604648  0.7311601   0.79318732  0.80327964  0.93465489  0.4306882
   0.90994263  0.73619896  0.71178436  0.79184276]]
After layer _mul2066_0 (1, 256) <class 'numpy.float32'> [[  5.32354832e-01   3.92712504e-01  -6.48349285e-01  -4.55855668e-01
    9.63176847e-01  -1.75566569e-01   1.88338757e+00   3.23222089e-03
   -4.91396010e-01  -1.20154351e-01   1.15040493e+00   9.05311763e-01
    2.72719800e-01  -1.32048237e+00   5.12253940e-02   1.76247233e-03
    5.65476894e-01   8.06762815e-01  -2.85037488e-01   6.18897021e-01
   -1.56338841e-01  -1.70250833e-01  -1.54754436e+00   5.08658767e-01
   -2.84485996e-01  -2.28724137e-01  -1.33137572e+00  -5.05965240e-02
   -1.31135893e+00   6.68169856e-01   9.43035066e-01  -5.55185914e-01
    1.09481752e+00  -5.90558529e-01   2.29867887e+00   4.33729798e-01
    4.14654016e-01  -1.48640895e+00  -1.96884310e+00  -8.14487040e-03
   -9.67215151e-02   9.98059273e-01  -4.81973380e-01   3.46686631e-01
   -9.35334623e-01  -2.56299585e-01  -1.07297942e-01   8.03056359e-01
    5.07980347e-01   1.56647518e-01  -4.72776871e-03   2.11502686e-02
   -1.99995601e+00  -2.62288570e-01   1.77331316e+00   2.25341856e-01
   -9.92822289e-01  -2.20759809e-01   8.44008088e-01   1.00977635e-02
    4.93262082e-01  -1.50255218e-01   1.69354767e-01   1.79019105e+00
   -5.19330084e-01   1.17639422e-01   1.06768680e+00   1.66180015e+00
    5.23873866e-01  -1.79658318e+00   2.56659359e-01   4.49963249e-02
   -2.37817478e+00   6.06341481e-01   5.67032099e-01   2.63866806e+00
    9.52301562e-01  -3.16495299e+00   1.01066983e+00  -1.34577498e-01
    1.74057865e+00  -2.49901652e-01  -2.65635848e-01   2.57996440e-01
   -1.00314760e+00  -1.21413779e+00   1.94509149e-01  -2.14068985e+00
    5.17709196e-01  -9.46909487e-02   6.13558710e-01   4.40699250e-01
   -3.42933327e-01  -6.56249762e-01  -2.42616057e-01  -1.64625347e-01
   -1.40169322e+00  -1.82831097e+00   1.26033616e+00   4.54606324e-01
   -5.63248873e-01  -3.54371630e-02  -2.29406636e-02   1.40746450e+00
   -1.07057929e+00  -6.90844476e-01   5.81571102e-01   7.01460361e-01
    4.96082604e-01   5.99416971e-01  -1.64238822e+00  -1.71252179e+00
    2.67085314e+00   2.84816289e+00  -4.40501034e-01   1.11363029e+00
    9.16122496e-01   5.36215663e-01   5.17479897e-01   1.24793336e-01
    1.60465688e-01  -1.71156287e+00   1.51127660e+00  -5.87085187e-01
    2.10804367e+00  -3.53018820e-01   2.63908446e-01   7.59190142e-01
   -9.09213006e-01  -2.61864638e+00   2.25544065e-01   1.23293841e+00
    3.94628942e-01  -2.77959377e-01   1.07463360e+00   1.38323343e+00
    8.18051100e-01   1.23528756e-01  -1.90839612e+00  -5.43867588e-01
   -2.65683960e-02   1.44861543e+00  -1.38204515e+00  -2.26608261e-01
    1.26127493e+00   2.15824414e-02   6.02793634e-01   2.87938397e-03
    1.79551220e+00  -2.31389552e-01   1.85830927e+00  -7.49966264e-01
    1.56686211e+00   1.28296542e+00   3.89440536e-01  -1.05767751e+00
    1.64528584e+00  -5.36370091e-02   1.59199190e+00   1.11750996e+00
    2.35894442e+00   9.70264673e-02   7.84580827e-01   1.34873509e+00
   -4.65059131e-01   2.24910319e-01  -8.72511640e-02   9.84787822e-01
   -2.30019227e-01  -5.88511288e-01   7.95243904e-02   3.21202564e+00
   -5.64526856e-01   2.17875528e+00  -6.13452375e-01  -7.23062634e-01
    2.04906985e-01   1.70468941e-01  -2.68426806e-01  -3.99698198e-01
    1.23645306e+00   4.16256100e-01   9.16238487e-01   8.67298186e-01
   -3.07429340e-02  -1.00274348e+00  -6.95593178e-01   1.41085529e+00
    8.74893486e-01  -9.59159553e-01   1.41663656e-01  -7.99845219e-01
   -1.79865193e+00   1.12333930e+00   2.43877560e-01  -1.09712231e+00
   -9.01929736e-01  -5.90256333e-01   1.08515120e+00  -1.33500904e-01
    4.78592962e-02  -1.25908506e+00  -1.02169907e+00  -1.29311311e+00
   -4.43087548e-01  -1.70974135e-01   1.57311714e+00   1.52449291e-02
    1.50987312e-01   2.91978776e-01  -6.94225729e-01   7.19645500e-01
    1.01970863e+00   6.04017019e-01   2.74741077e+00  -1.81128180e+00
   -5.82316339e-01  -1.74056613e+00  -3.54685813e-01  -2.17521489e-01
   -3.87806565e-01   8.59576166e-01   5.30539811e-01  -1.45630240e+00
    5.19245565e-01  -2.65632796e+00  -2.68942446e-01  -3.64077449e-01
    4.50951755e-01  -5.65561354e-02  -2.71519244e-01  -2.71836400e+00
   -3.21304262e-01   1.44293559e+00  -1.15526140e+00  -1.88631732e-02
    7.89046466e-01   3.43597412e-01  -1.77217990e-01   2.42334867e+00
    6.30739033e-01   1.54238546e+00  -3.68525481e+00  -4.35691684e-01
    1.22125900e+00  -4.03486311e-01   3.95832568e-01  -4.10745263e-01
   -1.17529905e+00   9.06303525e-01  -2.22826624e+00  -5.20672612e-02
   -1.32791007e+00  -7.69445598e-01  -4.90950681e-02   6.41282320e-01]]
After layer encoder_birnn_forward_l0_t7_i_output (1, 256) <class 'numpy.float32'> [[ 0.75219035  0.71529442  0.67983961  0.66591293  0.81292301  0.78535604
   0.92781961  0.54536599  0.27954602  0.70675725  0.70536017  0.80988264
   0.46603164  0.84812587  0.3150996   0.58298385  0.62242097  0.75663131
   0.80483544  0.67049164  0.50914758  0.1698934   0.70434868  0.65000015
   0.59262252  0.61473083  0.82137054  0.48731351  0.78056508  0.81107521
   0.76637286  0.7108202   0.86731756  0.76248854  0.96512502  0.55713356
   0.62589175  0.96037042  0.90995383  0.18824969  0.36022466  0.73175746
   0.90234208  0.52419174  0.95629996  0.71536231  0.6534273   0.75560445
   0.61491698  0.4115614   0.39713261  0.36837545  0.9972257   0.64172107
   0.90824765  0.49386808  0.88537037  0.55450994  0.6953615   0.15336278
   0.64588815  0.61516541  0.43265411  0.90588564  0.53853768  0.56237304
   0.82494462  0.92928505  0.77048808  0.89760607  0.39617744  0.16034554
   0.96474618  0.7404846   0.68881905  0.96739006  0.8038168   0.9909541
   0.75951886  0.24492529  0.88927984  0.71276242  0.7834627   0.44871569
   0.88036501  0.79372567  0.66690499  0.94589221  0.89536572  0.40443665
   0.76432198  0.41279078  0.41146341  0.74633086  0.26519406  0.17030866
   0.87574655  0.91861403  0.85855645  0.72698963  0.6474514   0.34879735
   0.67954493  0.92183775  0.79689229  0.62781906  0.53524935  0.6018526
   0.446475    0.55109745  0.89962643  0.8705591   0.98209769  0.99240875
   0.8008588   0.84552342  0.69402176  0.86050767  0.607063    0.38137195
   0.39812174  0.89376628  0.96896154  0.70108616  0.95980197  0.60742849
   0.69936335  0.72436672  0.62951702  0.96777403  0.3461794   0.84483862
   0.72571892  0.60308832  0.86537099  0.81140661  0.77891451  0.23211947
   0.81405604  0.48426032  0.56765336  0.90531403  0.8160187   0.51115495
   0.76089376  0.23519191  0.52998632  0.38193974  0.86903709  0.42739913
   0.95048416  0.84181386  0.95642841  0.90885943  0.55536693  0.8787024
   0.77404183  0.39549518  0.86018002  0.82836306  0.96688342  0.42475402
   0.82310051  0.85363632  0.80403316  0.48177829  0.57314336  0.75025064
   0.42701626  0.66775668  0.29844981  0.99908435  0.67803168  0.91256624
   0.77208489  0.59733611  0.3949644   0.30443066  0.50836384  0.69086045
   0.91860205  0.67690361  0.7294805   0.64260262  0.40549281  0.7561937
   0.56805545  0.8848052   0.80339211  0.76090831  0.2827377   0.59617198
   0.92115241  0.69127709  0.67823851  0.87963277  0.99623662  0.91013938
   0.79649383  0.56025177  0.63999474  0.84307492  0.74922466  0.78643602
   0.74846202  0.50249684  0.82722962  0.31863856  0.31052217  0.68955332
   0.79446787  0.68614149  0.90149593  0.72470427  0.97661614  0.88548964
   0.66951489  0.93208641  0.72253394  0.28251803  0.63538092  0.66262972
   0.7269057   0.79473215  0.76299721  0.99520266  0.77376032  0.4406423
   0.48693419  0.48540321  0.28755605  0.98831135  0.66526866  0.91460013
   0.80918026  0.47209218  0.66732663  0.36936387  0.51422745  0.94343531
   0.63505358  0.8079083   0.99956232  0.73995185  0.86333913  0.78314608
   0.67494351  0.62250936  0.83066446  0.67200261  0.94456518  0.24839379
   0.86304033  0.73008764  0.36725745  0.67405331]]
After layer encoder_birnn_forward_l0_t7_c_output (1, 256) <class 'numpy.float32'> [[ 0.54168367  0.68455303 -0.98297155 -0.72953761  0.99467057 -0.17621411
   0.98851383 -0.12122495 -0.6275062  -0.26207265  0.93568528  0.94126797
   0.43036929 -0.97788876  0.33177564 -0.04939301  0.81417155  0.96615267
  -0.52211195  0.79343528 -0.34719446 -0.99946219 -0.99806231  0.86985099
  -0.42241919 -0.42791152 -0.99467385 -0.1350816  -0.98841739  0.91097701
   0.86125785 -0.64321458  0.98028445 -0.68351108  0.99965262  0.80658817
   0.75659788 -0.99949485 -0.99547666 -0.17404158 -0.18125375  0.99732029
  -0.54249358  0.98620319 -0.99989218 -0.79756594  0.05235096  0.85436702
   0.89726478  0.69328225  0.10328886  0.1172015  -0.92059815 -0.88742918
   0.99661678  0.95311564 -0.99883538 -0.37081155  0.9558382   0.04881641
   0.98596978 -0.22242935  0.46796885  0.99999058 -0.96075612  0.17958644
   0.93569815  0.9949854   0.62865168 -0.99089003  0.79776573 -0.0266718
  -0.9993453   0.75281882  0.92639184  0.99586338  0.99311614 -0.99996763
   0.94234234 -0.99836993  0.99907643 -0.93647045 -0.02034263  0.53250897
  -0.84711212 -0.99149996  0.4616009  -0.99869013  0.35537282 -0.14172974
   0.93016791  0.77359742 -0.99533993 -0.76727551 -0.99969113 -0.73524588
  -0.92530185 -0.99921697  0.9324311   0.49197841 -0.9672063  -0.15428558
  -0.20064169  0.9463619  -0.86668122 -0.99273539  0.80089372  0.85712427
   0.76745874  0.91870356 -0.99712878 -0.98302937  0.9998697   0.99979651
  -0.45482409  0.99354142  0.89685434  0.56477046  0.70097989  0.34506708
   0.39074874 -0.97425795  0.99171519 -0.81416976  0.99991482 -0.66570568
   0.99890774  0.93497431 -0.99602258 -0.99938387  0.52926189  0.93992203
   0.7141453  -0.53711772  0.99371713  0.99762708  0.83535719  0.98539579
  -0.99929357 -0.73372912 -0.17661968  0.99910307 -0.99735194 -0.42421153
   0.99415338  0.14102635  0.97944587  0.03786473  0.99917376 -0.3938911
   0.99950117 -0.95497876  0.99974203  0.98073691  0.68013918 -0.9984985
   0.99881417 -0.16299096  0.97648841  0.97242361  0.99997681  0.09468418
   0.77154005  0.98981398 -0.48327523  0.41825974 -0.27238935  0.99078709
  -0.93161428 -0.92286384  0.49353516  0.999982   -0.82069761  0.99973291
  -0.97618413 -0.99895859  0.52415156  0.29254368 -0.8955723  -0.43962204
   0.99879277  0.98840308  0.83778965  0.93129271 -0.14709581 -0.96399647
  -0.79944468  0.99816579  0.91840088 -0.88565981  0.99705291 -0.96917635
  -0.98795044  0.99579066  0.64466035 -0.99849463 -0.24440086 -0.99542075
   0.97599208 -0.39424512  0.14559422 -0.98497838 -0.9994486  -0.926961
  -0.61552125 -0.10658368  0.99535108  0.03609413  0.65582299  0.49145374
  -0.69207215  0.90476984  0.8701216   0.72307253  0.99978721 -0.99434936
  -0.92423791 -0.99821353 -0.76126337 -0.88529617 -0.72556603  0.87844265
   0.99393988 -0.99955976  0.67418647 -0.99995422 -0.99318677 -0.67112124
   0.7000246  -0.23104782 -0.78024709 -0.99941546 -0.56904721  0.9985041
  -0.89539081  0.06531498  0.99314892  0.92436939 -0.39437458  0.99996626
   0.98638958  0.98755395 -0.99997663 -0.99684948  0.99579984 -0.95964622
   0.5989244  -0.61469674 -0.96880215  0.93383688 -0.99791163 -0.24971578
  -0.92052567 -0.84492838  0.05915853  0.80840647]]
After layer _mul2067_0 (1, 256) <class 'numpy.float32'> [[ 0.40744925  0.48965696 -0.66826302 -0.48580852  0.80859059 -0.13839082
   0.91716254 -0.06611197 -0.17541686 -0.18522175  0.65999514  0.76231658
   0.20056571 -0.82937276  0.10454237 -0.02879533  0.50675744  0.73102134
  -0.42021421  0.53199172 -0.17677322 -0.16980202 -0.70298386  0.56540328
  -0.25033513 -0.26305041 -0.8169958  -0.06582709 -0.77152407  0.73887086
   0.66004467 -0.45720991  0.85021794 -0.52116936  0.96478975  0.44937733
   0.47354835 -0.9598853  -0.90583783 -0.03276328 -0.06529207  0.72979659
  -0.4895148   0.51695955 -0.95619684 -0.57054859  0.03420755  0.64556354
   0.55174333  0.28532821  0.04101937  0.04317416 -0.91804415 -0.56948203
   0.90517485  0.47071341 -0.88433927 -0.20561869  0.66465306  0.00748662
   0.63682622 -0.13683084  0.20246865  0.90587711 -0.51740336  0.10099457
   0.77189916  0.92462504  0.48436862 -0.88942891  0.31605679 -0.0042767
  -0.96411455  0.55745071  0.63811636  0.96338832  0.79828346 -0.99092203
   0.71572679 -0.24452604  0.88845855 -0.66748095 -0.01593769  0.23894513
  -0.74576789 -0.78697896  0.30784395 -0.94465321  0.31818864 -0.0573207
   0.71094781  0.31933388 -0.40954596 -0.57264137 -0.26511216 -0.12521875
  -0.81032991 -0.91789472  0.80054474  0.35766318 -0.62621909 -0.0538144
  -0.13634504  0.87239212 -0.6906516  -0.62325817  0.42867786  0.51586246
   0.34265113  0.5062952  -0.89704341 -0.85578513  0.98196971  0.99220681
  -0.36424989  0.84006256  0.6224364   0.4859893   0.42553896  0.1315989
   0.15556557 -0.87075889  0.96093386 -0.57080317  0.95972019 -0.40436861
   0.69859946  0.67726427 -0.62701315 -0.96717775  0.18321957  0.79408246
   0.51826876 -0.32392943  0.85993397  0.8094812   0.65067184  0.22872955
  -0.81348097 -0.35531589 -0.10025875  0.90450203 -0.81385785 -0.21683782
   0.75644511  0.03316826  0.51909292  0.01446205  0.86831903 -0.16834871
   0.95001    -0.80391437  0.9561817   0.891352    0.37772682 -0.87738305
   0.77312392 -0.06446214  0.83995581  0.80551982  0.96686101  0.04021749
   0.63505501  0.8449412  -0.38856933  0.20150846 -0.15611815  0.74333864
  -0.39781445 -0.61624849  0.14729548  0.99906635 -0.55645895  0.91232252
  -0.75369704 -0.59671402  0.20702121  0.08905926 -0.45527658 -0.30371749
   0.9174931   0.66905361  0.61115122  0.59845114 -0.0596463  -0.72896808
  -0.45412889  0.88318229  0.737836   -0.67390591  0.28190446 -0.5777958
  -0.91005296  0.68836725  0.43723348 -0.87830859 -0.24348108 -0.90597165
   0.77737164 -0.22087653  0.09317954 -0.83041054 -0.74881154 -0.7289955
  -0.46069428 -0.05355796  0.82338387  0.01150098  0.20364758  0.33888355
  -0.54982907  0.62080014  0.78441107  0.52401376  0.9764083  -0.88048607
  -0.61879104 -0.93042129 -0.55003864 -0.25011212 -0.46101081  0.58208221
   0.72250056 -0.79438227  0.51440239 -0.99515712 -0.76848853 -0.29572439
   0.34086591 -0.11215135 -0.22436477 -0.98773366 -0.37856928  0.91323197
  -0.72453254  0.03083469  0.66275471  0.34142867 -0.20279823  0.94340348
   0.62641025  0.79785305 -0.99953896 -0.73762059  0.85971296 -0.75154316
   0.40424013 -0.38265449 -0.80474949  0.62754083 -0.94259256 -0.06202785
  -0.79445076 -0.61687177  0.02172641  0.54490906]]
After layer encoder_birnn_forward_l0_t7_state_0 (1, 256) <class 'numpy.float32'> [[ 0.93980408  0.88236946 -1.31661224 -0.94166422  1.77176738 -0.31395739
   2.80054998 -0.06287975 -0.6668129  -0.30537611  1.81040001  1.66762829
   0.4732855  -2.14985514  0.15576777 -0.02703286  1.07223439  1.5377841
  -0.70525169  1.15088868 -0.33311206 -0.34005284 -2.25052834  1.07406211
  -0.53482115 -0.49177456 -2.14837146 -0.11642362 -2.08288288  1.40704072
   1.6030798  -1.01239586  1.94503546 -1.11172795  3.26346874  0.88310713
   0.88820237 -2.44629431 -2.874681   -0.04090815 -0.16201359  1.72785592
  -0.97148818  0.86364615 -1.89153147 -0.82684815 -0.0730904   1.44861984
   1.05972362  0.44197571  0.0362916   0.06432442 -2.91800022 -0.8317706
   2.67848802  0.69605529 -1.8771615  -0.42637849  1.50866115  0.01758438
   1.13008833 -0.28708607  0.37182343  2.69606829 -1.03673339  0.21863399
   1.83958602  2.5864253   1.00824249 -2.68601203  0.57271612  0.04071962
  -3.34228945  1.16379213  1.20514846  3.6020565   1.75058508 -4.15587521
   1.72639656 -0.37910354  2.62903714 -0.9173826  -0.28157353  0.49694157
  -1.74891543 -2.00111675  0.50235307 -3.08534312  0.8358978  -0.15201165
   1.32450652  0.76003313 -0.75247931 -1.22889113 -0.50772822 -0.2898441
  -2.21202326 -2.74620581  2.0608809   0.81226951 -1.18946791 -0.08925156
  -0.15928571  2.27985668 -1.76123095 -1.31410265  1.0102489   1.21732283
   0.83873373  1.10571218 -2.53943157 -2.56830692  3.65282297  3.8403697
  -0.80475092  1.95369291  1.53855896  1.022205    0.94301885  0.25639224
   0.31603128 -2.58232164  2.47221041 -1.15788841  3.06776381 -0.7573874
   0.9625079   1.43645442 -1.53622615 -3.58582401  0.40876365  2.02702093
   0.91289771 -0.60188878  1.93456757  2.19271469  1.46872294  0.35225829
  -2.7218771  -0.89918351 -0.12682715  2.35311747 -2.19590306 -0.4434461
   2.01771998  0.0547507   1.12188649  0.01734143  2.66383123 -0.39973825
   2.80831933 -1.55388069  2.52304387  2.17431736  0.76716733 -1.9350605
   2.41840982 -0.11809915  2.43194771  1.92302978  3.32580543  0.13724396
   1.41963577  2.19367623 -0.85362846  0.42641878 -0.24336931  1.72812653
  -0.62783366 -1.20475984  0.22681987  4.211092   -1.12098575  3.0910778
  -1.36714935 -1.31977665  0.41192818  0.25952822 -0.72370338 -0.70341569
   2.15394616  1.08530974  1.52738976  1.46574926 -0.09038923 -1.73171163
  -1.1497221   2.29403758  1.61272955 -1.63306546  0.42356813 -1.37764096
  -2.70870495  1.81170654  0.68111104 -1.97543097 -1.14541078 -1.49622798
   1.86252284 -0.35437745  0.14103884 -2.08949566 -1.77051067 -2.02210855
  -0.90378183 -0.2245321   2.39650106  0.02674591  0.35463488  0.63086236
  -1.24405479  1.34044564  1.80411971  1.12803078  3.72381902 -2.69176793
  -1.20110738 -2.67098737 -0.90472448 -0.46763361 -0.84881735  1.44165838
   1.25304031 -2.25068474  1.03364801 -3.65148497 -1.037431   -0.65980184
   0.79181767 -0.16870749 -0.495884   -3.7060976  -0.69987357  2.35616755
  -1.87979388  0.01197152  1.45180118  0.68502605 -0.38001621  3.36675215
   1.25714922  2.34023857 -4.68479395 -1.17331231  2.08097196 -1.15502954
   0.80007267 -0.79339975 -1.98004854  1.53384435 -3.17085886 -0.11409511
  -2.12236071 -1.38631737 -0.02736866  1.18619132]]
After layer activation1033_output (1, 256) <class 'numpy.float32'> [[ 0.73513222  0.70760441 -0.86593896 -0.73598593  0.94380283 -0.30403298
   0.9926396  -0.06279701 -0.58287948 -0.29622474  0.94787246  0.9312374
   0.44085011 -0.9732185   0.15452005 -0.02702628  0.79030156  0.91174728
  -0.60769063  0.81804824 -0.32131431 -0.32752457 -0.97804904  0.79098672
  -0.48905775 -0.45562375 -0.97314    -0.11590044 -0.96943861  0.88686407
   0.92213082 -0.76675111  0.95993137 -0.80467236  0.99707729  0.70797247
   0.71050471 -0.98510778 -0.99365062 -0.04088534 -0.1606108   0.93880206
  -0.74935758  0.6981315  -0.95550656 -0.67877996 -0.07296052  0.89541966
   0.7855581   0.41528079  0.03627568  0.06423585 -0.99417603 -0.68142557
   0.990614    0.60185802 -0.95423895 -0.40229034  0.90670115  0.01758257
   0.81104946 -0.27945063  0.3555856   0.99093676 -0.77659488  0.21521571
   0.95075542  0.98872715  0.76503408 -0.99075353  0.51735121  0.04069713
  -0.99750304  0.82227188  0.83521825  0.99851406  0.94144207 -0.99950892
   0.93862867 -0.3619287   0.98964328 -0.72465682 -0.27436078  0.45970845
  -0.94125199 -0.96410638  0.46396571 -0.99582911  0.68363011 -0.1508515
   0.86790025  0.64109647 -0.63662577 -0.84225738 -0.46817324 -0.2819913
  -0.97631264 -0.99179798  0.96808571  0.67084038 -0.83041382 -0.08901533
  -0.15795211  0.97928667 -0.9426403  -0.86530983  0.76586497  0.83886266
   0.68513781  0.80254149 -0.9876231  -0.98831356  0.99865741  0.99907714
  -0.66668439  0.96060562  0.91187787  0.77076316  0.73660618  0.25091797
   0.30591398 -0.98863477  0.98585469 -0.82035053  0.99568021 -0.63953549
   0.7453934   0.89298171 -0.91148406 -0.99846506  0.38742241  0.96588773
   0.72252011 -0.53839219  0.95910096  0.97539151  0.89933354  0.33837679
  -0.99139076 -0.71590006 -0.12615149  0.98208445 -0.975546   -0.41649684
   0.96525836  0.05469605  0.80822408  0.01733969  0.99033612 -0.37972498
   0.99275267 -0.91442353  0.98721337  0.97448093  0.64527929 -0.95914048
   0.98426038 -0.11755314  0.98467761  0.95816624  0.99741948  0.1363887
   0.88952291  0.97543818 -0.69296032  0.40232411 -0.23867567  0.93883413
  -0.55655873 -0.83510065  0.22300853  0.99956024 -0.80791152  0.99587655
  -0.87804091 -0.86672837  0.39010864  0.25385422 -0.61919802 -0.60653138
   0.97343385  0.79515988  0.90997684  0.89876348 -0.09014387 -0.93925786
  -0.817662    0.97986001  0.92356235 -0.92649686  0.39993215 -0.88042194
  -0.99116194  0.94800496  0.59224117 -0.96224999 -0.81622803 -0.9044643
   0.95291138 -0.34025195  0.14011104 -0.96983409 -0.94366539 -0.96555674
  -0.71813428 -0.22083344  0.98356116  0.02673954  0.34047955  0.55864567
  -0.84660804  0.8717792   0.94723099  0.81034422  0.99883503 -0.99085885
  -0.83399206 -0.99047279 -0.7185905  -0.43628535 -0.69045115  0.89403105
   0.84913397 -0.97805583  0.77536732 -0.99865383 -0.77687156 -0.57823145
   0.65943754 -0.16712491 -0.45887399 -0.99879307 -0.60428751  0.98219246
  -0.95447379  0.01197094  0.89604843  0.59477711 -0.36272153  0.99762213
   0.85027623  0.98162127 -0.99982947 -0.82533109  0.96932334 -0.81941342
   0.6640774  -0.66033065 -0.96259052  0.91108018 -0.99648362 -0.11360259
  -0.971726   -0.88235801 -0.02736183  0.82939392]]
After layer encoder_birnn_forward_l0_t7_out_0 (1, 256) <class 'numpy.float32'> [[ 0.66371459  0.54586881 -0.68025237 -0.63406849  0.73734963 -0.26428404
   0.96866792 -0.0482892  -0.48810714 -0.23205416  0.79513282  0.75971138
   0.34862474 -0.89484882  0.06920055 -0.01631627  0.64759904  0.64954031
  -0.58767056  0.70189804 -0.24275193 -0.1437794  -0.92213279  0.70121366
  -0.36357659 -0.33897778 -0.90187073 -0.09690079 -0.54474777  0.71589506
   0.82830513 -0.66177183  0.52435076 -0.61433101  0.76870859  0.48326895
   0.60412079 -0.65196496 -0.23541157 -0.0293058  -0.11504094  0.7388984
  -0.58506191  0.54826301 -0.76061261 -0.55661869 -0.07031839  0.77578163
   0.60990292  0.24052513  0.01213222  0.05490547 -0.99161112 -0.28575477
   0.83962005  0.24950877 -0.68063527 -0.31458402  0.77628237  0.01332643
   0.43472746 -0.19122624  0.20491064  0.9111523  -0.55253118  0.17079833
   0.85210103  0.72698963  0.62474364 -0.71914434  0.43754572  0.03424463
  -0.95587695  0.66694796  0.62187463  0.99342591  0.77527088 -0.99133062
   0.85057861 -0.20126942  0.93255782 -0.29613435 -0.27366385  0.35772598
  -0.84482783 -0.7020613   0.333994   -0.84189606  0.66849613 -0.13228726
   0.65496516  0.52867234 -0.18057796 -0.77089107 -0.28605297 -0.23682503
  -0.84351444 -0.87120992  0.8280732   0.63665879 -0.52968198 -0.06570359
  -0.09748661  0.92449814 -0.82897574 -0.55583316  0.63080698  0.73263353
   0.61691773  0.48862088 -0.91920167 -0.82897365  0.97848505  0.96798515
  -0.58570391  0.78214145  0.7571587   0.74026591  0.60987097  0.21261038
   0.23257102 -0.95246619  0.8578946  -0.64803106  0.86719096 -0.57086182
   0.37910241  0.54313248 -0.70233786 -0.98708975  0.33178911  0.91534263
   0.552688   -0.43476161  0.66196132  0.69780368  0.80299592  0.24344601
  -0.90060294 -0.61230695 -0.09002472  0.82150221 -0.78020483 -0.35601762
   0.6889627   0.04876701  0.63240337  0.01339623  0.55098057 -0.2552186
   0.967143   -0.63744074  0.82791537  0.5300023   0.44986242 -0.46767712
   0.69581455 -0.09530035  0.94693601  0.80101424  0.78551954  0.11844539
   0.51468885  0.86979139 -0.65457195  0.25777304 -0.1991892   0.58686131
  -0.21655357 -0.57436168  0.15631804  0.99792415 -0.68517351  0.93188447
  -0.48668876 -0.57344133  0.32016954  0.21719413 -0.44067717 -0.55815077
   0.77499843  0.38221481  0.78388798  0.78069931 -0.06281979 -0.79464394
  -0.66736299  0.6948278   0.78889298 -0.83409607  0.17092356 -0.70400327
  -0.95006919  0.72339129  0.37004083 -0.81278282 -0.8150329  -0.68806762
   0.781959   -0.28559685  0.09289213 -0.61900389 -0.80832177 -0.89614975
  -0.62388754 -0.19419743  0.90601546  0.01400538  0.09721671  0.4551574
  -0.73368305  0.60250837  0.8804453   0.71893263  0.98900849 -0.94014788
  -0.60801613 -0.93779552 -0.62841082 -0.31419891 -0.52124578  0.77613884
   0.39837995 -0.62494552  0.67879593 -0.75675482 -0.63941646 -0.47284093
   0.55012387 -0.12261264 -0.32252127 -0.94156957 -0.5179835   0.82185286
  -0.8475529   0.00916589  0.52137846  0.27266046 -0.2884348   0.96971714
   0.47652161  0.89867491 -0.9996137  -0.49319169  0.77685565 -0.47308248
   0.5475561  -0.56075758 -0.89861047  0.8061105  -0.9277699  -0.07897136
  -0.91366154 -0.77877653 -0.02044988  0.6953705 ]]
After layer expand_dims1039_0 (1, 1, 256) <class 'numpy.float32'> [[[ 0.66371459  0.54586881 -0.68025237 -0.63406849  0.73734963 -0.26428404
    0.96866792 -0.0482892  -0.48810714 -0.23205416  0.79513282  0.75971138
    0.34862474 -0.89484882  0.06920055 -0.01631627  0.64759904  0.64954031
   -0.58767056  0.70189804 -0.24275193 -0.1437794  -0.92213279  0.70121366
   -0.36357659 -0.33897778 -0.90187073 -0.09690079 -0.54474777  0.71589506
    0.82830513 -0.66177183  0.52435076 -0.61433101  0.76870859  0.48326895
    0.60412079 -0.65196496 -0.23541157 -0.0293058  -0.11504094  0.7388984
   -0.58506191  0.54826301 -0.76061261 -0.55661869 -0.07031839  0.77578163
    0.60990292  0.24052513  0.01213222  0.05490547 -0.99161112 -0.28575477
    0.83962005  0.24950877 -0.68063527 -0.31458402  0.77628237  0.01332643
    0.43472746 -0.19122624  0.20491064  0.9111523  -0.55253118  0.17079833
    0.85210103  0.72698963  0.62474364 -0.71914434  0.43754572  0.03424463
   -0.95587695  0.66694796  0.62187463  0.99342591  0.77527088 -0.99133062
    0.85057861 -0.20126942  0.93255782 -0.29613435 -0.27366385  0.35772598
   -0.84482783 -0.7020613   0.333994   -0.84189606  0.66849613 -0.13228726
    0.65496516  0.52867234 -0.18057796 -0.77089107 -0.28605297 -0.23682503
   -0.84351444 -0.87120992  0.8280732   0.63665879 -0.52968198 -0.06570359
   -0.09748661  0.92449814 -0.82897574 -0.55583316  0.63080698  0.73263353
    0.61691773  0.48862088 -0.91920167 -0.82897365  0.97848505  0.96798515
   -0.58570391  0.78214145  0.7571587   0.74026591  0.60987097  0.21261038
    0.23257102 -0.95246619  0.8578946  -0.64803106  0.86719096 -0.57086182
    0.37910241  0.54313248 -0.70233786 -0.98708975  0.33178911  0.91534263
    0.552688   -0.43476161  0.66196132  0.69780368  0.80299592  0.24344601
   -0.90060294 -0.61230695 -0.09002472  0.82150221 -0.78020483 -0.35601762
    0.6889627   0.04876701  0.63240337  0.01339623  0.55098057 -0.2552186
    0.967143   -0.63744074  0.82791537  0.5300023   0.44986242 -0.46767712
    0.69581455 -0.09530035  0.94693601  0.80101424  0.78551954  0.11844539
    0.51468885  0.86979139 -0.65457195  0.25777304 -0.1991892   0.58686131
   -0.21655357 -0.57436168  0.15631804  0.99792415 -0.68517351  0.93188447
   -0.48668876 -0.57344133  0.32016954  0.21719413 -0.44067717 -0.55815077
    0.77499843  0.38221481  0.78388798  0.78069931 -0.06281979 -0.79464394
   -0.66736299  0.6948278   0.78889298 -0.83409607  0.17092356 -0.70400327
   -0.95006919  0.72339129  0.37004083 -0.81278282 -0.8150329  -0.68806762
    0.781959   -0.28559685  0.09289213 -0.61900389 -0.80832177 -0.89614975
   -0.62388754 -0.19419743  0.90601546  0.01400538  0.09721671  0.4551574
   -0.73368305  0.60250837  0.8804453   0.71893263  0.98900849 -0.94014788
   -0.60801613 -0.93779552 -0.62841082 -0.31419891 -0.52124578  0.77613884
    0.39837995 -0.62494552  0.67879593 -0.75675482 -0.63941646 -0.47284093
    0.55012387 -0.12261264 -0.32252127 -0.94156957 -0.5179835   0.82185286
   -0.8475529   0.00916589  0.52137846  0.27266046 -0.2884348   0.96971714
    0.47652161  0.89867491 -0.9996137  -0.49319169  0.77685565 -0.47308248
    0.5475561  -0.56075758 -0.89861047  0.8061105  -0.9277699  -0.07897136
   -0.91366154 -0.77877653 -0.02044988  0.6953705 ]]]
After layer encoder_birnn_forward_l0_t8_i2h_output (1, 1024) <class 'numpy.float32'> [[ 0.07376467 -0.04585483  0.06153381 ...,  0.03591035  0.03396329
   0.02903319]]
After layer encoder_birnn_forward_l0_t8_h2h_output (1, 1024) <class 'numpy.float32'> [[ 1.2797575   1.12693715  0.84548593 ...,  2.32956862  1.29022276
   1.92839503]]
After layer _plus1034_0 (1, 1024) <class 'numpy.float32'> [[ 1.35352218  1.08108234  0.90701973 ...,  2.36547899  1.32418609
   1.95742822]]
After layer encoder_birnn_forward_l0_t8_slice_output0 (1, 256) <class 'numpy.float32'> [[  1.35352218e+00   1.08108234e+00   9.07019734e-01   8.29755306e-01
    1.73488224e+00   1.45636261e+00   2.93351793e+00   3.22564512e-01
   -1.23419929e+00   1.00408959e+00   1.04557920e+00   1.66339648e+00
   -1.01750806e-01   2.03704405e+00  -8.70617509e-01   3.56716573e-01
    4.77346957e-01   1.30172884e+00   1.74440837e+00   7.82748044e-01
    1.09466732e-01  -1.82330990e+00   9.69464540e-01   7.07958817e-01
    4.33789283e-01   6.00956559e-01   1.77391803e+00  -5.83500937e-02
    1.46966314e+00   1.77355266e+00   1.42797720e+00   9.81460154e-01
    2.21570706e+00   1.27858520e+00   3.98413825e+00   3.36784303e-01
    5.54717004e-01   3.67316318e+00   2.76355195e+00  -1.77530611e+00
   -6.46467507e-01   1.16214478e+00   2.67378783e+00   5.17943129e-03
    3.59822297e+00   1.04725969e+00   7.35710621e-01   1.33102345e+00
    5.67734778e-01  -4.35727686e-01  -4.75331426e-01  -6.08535945e-01
    6.80526161e+00   6.60625160e-01   2.67598462e+00  -1.30668879e-01
    2.47662425e+00   2.81793058e-01   9.92541373e-01  -1.91672897e+00
    5.95913172e-01   4.90339935e-01  -2.71132529e-01   2.67920303e+00
    2.66334146e-01   2.52533644e-01   1.78539991e+00   3.00559855e+00
    1.34629619e+00   2.49229670e+00  -5.26764274e-01  -1.85296321e+00
    3.75406718e+00   1.21443772e+00   8.88719022e-01   3.89132094e+00
    1.64052081e+00   5.43159008e+00   1.38734829e+00  -1.41531456e+00
    2.45154905e+00   1.07125473e+00   1.54697645e+00  -1.63960323e-01
    2.36455536e+00   1.57097113e+00   8.56676221e-01   3.36493921e+00
    2.52669501e+00  -4.00010884e-01   1.37713575e+00  -4.32621002e-01
   -4.09677893e-01   1.30681980e+00  -1.29547012e+00  -1.89291346e+00
    2.25787115e+00   2.94957495e+00   2.05316520e+00   1.15827310e+00
    8.12097192e-01  -7.85960197e-01   8.72534633e-01   2.88795114e+00
    1.50641203e+00   7.12776899e-01   1.16538547e-01   4.77928221e-01
   -2.04140604e-01   2.08162442e-01   2.61780143e+00   2.25920439e+00
    4.68268919e+00   5.57613420e+00   1.65141726e+00   1.96081007e+00
    9.27424848e-01   2.19268847e+00   4.62842345e-01  -5.07197857e-01
   -4.21597958e-01   2.44675612e+00   4.04937601e+00   1.04291105e+00
    3.73465323e+00   5.40504277e-01   9.81156647e-01   1.19955719e+00
    6.33443475e-01   3.88112450e+00  -6.73610210e-01   1.94050205e+00
    1.13005006e+00   4.27059025e-01   2.27296853e+00   1.77290547e+00
    1.48228621e+00  -1.48574269e+00   1.70887744e+00  -2.13093385e-02
    3.81618947e-01   2.64242053e+00   1.72621787e+00   5.01740724e-02
    1.34639776e+00  -1.39682925e+00   2.01098546e-01  -5.00416577e-01
    2.15015578e+00  -3.77989918e-01   3.44800019e+00   2.00477004e+00
    3.64000726e+00   2.70650077e+00   3.16892982e-01   2.38271594e+00
    1.44087875e+00  -4.04763341e-01   2.02407932e+00   1.78357732e+00
    3.94194365e+00  -2.73651332e-01   1.84517944e+00   2.09069991e+00
    1.71134329e+00  -9.72088650e-02   3.78529161e-01   1.34746575e+00
   -3.75363290e-01   8.10430288e-01  -9.74633992e-01   8.09221554e+00
    8.34553897e-01   2.71134734e+00   1.43932617e+00   3.92063022e-01
   -5.07655084e-01  -9.37778175e-01   1.15264267e-01   9.47717190e-01
    2.79999042e+00   8.43407631e-01   1.21455240e+00   7.46365309e-01
   -3.68902832e-01   1.29650807e+00   3.54086399e-01   2.45840955e+00
    1.66985929e+00   1.36125839e+00  -1.08777499e+00   5.40410399e-01
    2.71273708e+00   9.79425430e-01   7.75624514e-01   2.32152128e+00
    6.46586800e+00   2.70881462e+00   1.56947660e+00   2.42733836e-01
    7.27776408e-01   2.03838587e+00   1.25061369e+00   1.39458668e+00
    1.32106030e+00   4.69323881e-02   1.82453156e+00  -9.16593432e-01
   -9.72868204e-01   9.31679368e-01   1.60367668e+00   9.93246078e-01
    2.63974786e+00   1.16757190e+00   4.29991055e+00   2.35450745e+00
    8.64187539e-01   3.09955692e+00   1.05644727e+00  -1.24025381e+00
    6.70471013e-01   7.51022637e-01   1.22491670e+00   1.66155541e+00
    1.43316853e+00   6.21837664e+00   1.37108564e+00  -2.61053264e-01
   -4.68502864e-02  -5.40291965e-02  -9.88955557e-01   5.13667631e+00
    7.68112719e-01   2.82775950e+00   1.81767869e+00  -8.53868052e-02
    7.85454512e-01  -5.53382218e-01  -1.04835033e-02   3.24023342e+00
    6.15784407e-01   1.65605962e+00   8.96400261e+00   1.24226677e+00
    2.11733985e+00   1.51273870e+00   8.30363154e-01   5.68780243e-01
    1.88098693e+00   7.67595291e-01   3.32535744e+00  -1.28387165e+00
    2.13365626e+00   1.02839029e+00  -5.27757227e-01   8.72519732e-01]]
After layer encoder_birnn_forward_l0_t8_slice_output1 (1, 256) <class 'numpy.float32'> [[ 2.54181957  0.29990575  0.58611751  1.00830638  0.88513452  1.01888216
   2.9560318   0.9557597   3.78615975  0.93657851  2.77153635  1.1070869
   1.73187315  1.87963438 -0.49358904  0.84256697  0.9680025   0.89105672
   2.22631359  1.58418572  0.33895782 -0.67217171  2.54119015  0.57476616
   1.3253597   1.48031592  1.78948867  0.96269774  1.92616892  0.70979029
   2.27178931  1.80322444  1.21652579  1.14536309  3.23454285  0.84782219
   0.48596913  1.20714664  3.04604626 -0.16373906  1.68497932  1.08076131
   2.78926015 -0.49213049  0.32223502 -0.63116485  3.00201845  1.28891957
   0.61177123 -0.3925575  -0.64946049  1.27681327  5.60674477 -0.81347984
   2.32721162 -0.94504398  0.71512413  1.36423171  1.32652378  2.04154325
  -0.05847894  0.99181986  0.63401532  2.06508946  0.57216179  1.23095715
   1.85316944  1.91260326  0.95342582  2.87353492 -0.03663474  1.74620509
   3.29425335  1.35071301  0.40589657  5.24036217  0.9454658   5.01256371
   1.81350112 -1.14977252  2.6264956  -0.93679577  4.19099045  1.91524243
   2.2146554   1.64075434  0.1922708   2.88444638  5.34565973  0.89457184
   0.46491012  1.41562843 -0.25411019  1.4120295  -0.57184178 -0.07215074
   2.6253264   2.33577776  2.16581821  2.36042976  0.46475413 -0.41923255
   0.05984316  2.2421298   2.13778591  0.76684529  1.18135464  1.62897456
   1.47868693  1.08018756  2.19233131  2.99409866  3.67912602  4.0232954
   1.98049533  1.08501375  1.8805753   2.67063355  1.04300058  1.02539372
   1.31681824  2.91173577  1.58356118  1.09221697  2.21282029  1.49484563
  -1.24644339  1.19225276  1.13428962  4.11717653  1.05997419  1.97316289
   0.6129874   0.93157965  0.97166669  1.69540012  2.3551178  -1.01944602
   3.05935526  1.92551148  1.24372518  1.54099119  1.80939317  1.73980272
   1.92912531  2.16106129  0.81021374  1.57745183  2.47824121  1.38893485
   2.05560613  0.52375162  1.46857607  1.64873564  1.0949297   0.88554734
   2.51660967  1.06615114  2.76010013  1.47362292  2.9398458   1.60132921
   2.17254543  1.64881718  2.11904263  0.71087199  0.92567414  1.19763815
  -0.60772973  0.55268842 -0.70699698  4.01501131  1.08133245  3.09363437
   0.26892149  0.73762196  1.20736432  2.1302371  -0.22096565  2.77531195
   1.19824004 -0.40248132  2.14150691  1.6144464   1.33078873  1.33545864
   2.10999179  1.54941714  1.56654906  1.83719659 -1.02346337  1.16901028
   2.6964674   1.57351303  0.02148328  0.87338728  8.41656399 -0.22725698
   1.44144773 -0.35907993  0.7526077   1.63017678  1.03488863  2.92056894
   1.45086133  0.86658746  2.29017043 -0.94751376 -0.47268075  2.09521151
   2.01514554  1.25619185  1.82537806  1.4815073   4.14229727  2.82834077
   0.64556617  2.29488254  0.08968464 -0.26526117  0.68293142  1.71961772
   0.07265451  1.93871343  1.37513721  3.31402183 -1.23285174  1.03141344
   1.35468459  0.96772891  0.94267255  3.86882639  0.65115279  1.41397095
   2.45073366  1.32259309  0.74343038  0.374681    0.82014275  3.49605942
   0.51261199  2.37645888  8.57097721 -0.49078363  1.46233404 -0.39291412
   0.62068236  1.17859113  1.60813165  1.58444273  3.02871799 -0.29928803
   2.72424221  1.18467963  1.15062821  1.59498858]]
After layer encoder_birnn_forward_l0_t8_slice_output2 (1, 256) <class 'numpy.float32'> [[ 0.73112184  0.89149719 -2.87514496 -1.1813401   3.42524385 -0.19594891
   2.95626044 -0.32046786 -0.68639064 -0.39354771  2.01510549  2.0013361
   0.51407057 -2.60702634  0.45952594 -0.09147734  1.370152    2.33317733
  -0.88789666  1.32369256 -0.4222661  -4.85237503 -3.92909932  1.51202226
  -0.59286082 -0.58640754 -3.53632593 -0.22994241 -3.04188895  1.77244961
   1.58735001 -0.957394    2.8254981  -0.86532611  5.09444952  1.39215636
   1.10367668 -4.79624367 -3.5618403  -0.15635258 -0.25952163  3.82265425
  -0.93354928  2.8564229  -5.67766619 -1.19437468  0.24906653  1.53329778
   1.72213364  1.06906199  0.22334164  0.18950108 -1.67346931 -1.60971558
   3.72223854  2.23306322 -4.34450626 -0.43474454  2.15912485 -0.02826491
   2.8713901  -0.33076847  0.568097    7.13083553 -2.3642261   0.25805065
   1.94194031  3.50131488  0.84150189 -3.05306077  1.18524289 -0.20118099
  -4.63819695  1.19859004  1.90932703  3.4655478   3.38852739 -6.35534382
   2.08065605 -4.19541931  4.5233283  -1.97593391  0.15252317  0.78100514
  -1.559407   -3.08416247  0.53287131 -4.28271627  0.55112773 -0.04220728
   1.95053804  1.24034274 -3.53670907 -1.14247262 -5.00863314 -0.90378529
  -1.8447175  -4.60780859  1.99258614  0.685983   -2.45089865 -0.15423098
  -0.40489525  2.1164515  -1.61048102 -3.31394601  1.34028387  1.58362031
   1.24142635  1.90618908 -3.94243789 -2.75492239  5.53541756  5.41719103
  -0.68916655  3.42062783  1.89622402  0.8814714   0.9167152   0.52655357
   0.46875095 -2.5508976   3.23730636 -1.31631863  5.90874481 -0.99184525
   4.32187223  2.08502364 -3.57321525 -4.68459702  0.67412156  1.9929142
   1.0558573  -0.67747635  3.42615318  3.95352912  1.44275355  2.8671844
  -4.6416564  -0.9715389  -0.33511472  4.46210289 -3.90533423 -0.60231769
   3.38802648  0.23392114  2.71919131 -0.040195    4.64431524 -0.51998955
   4.82159662 -2.33174062  5.17321873  2.71371746  0.96676385 -4.13495731
   4.33121777 -0.28474018  2.61598921  2.49514079  6.59892654  0.20784403
   1.29426694  3.15006757 -0.71818435  0.52972698 -0.41205332  3.10023093
  -2.02906466 -1.93440425  0.58825809  6.68059921 -1.4647944   5.30190992
  -2.66108418 -4.45652485  0.71993524  0.35904887 -1.72491288 -0.56242371
   4.30325556  2.96546817  1.46289754  1.96913731 -0.23767291 -2.33371234
  -1.24569714  4.16068506  1.91951227 -1.63669074  3.84236836 -2.40229654
  -3.00990272  3.57412171  0.9359231  -4.16269445  0.04603259 -3.5229516
   2.58807874 -0.39853647  0.32268825 -2.89736843 -4.75665855 -1.87418568
  -0.95333552  0.08733243  3.52247787  0.02962522  0.84754968  0.81089997
  -1.0051825   1.84993339  1.60886097  1.06721246  5.27716208 -3.38657284
  -1.81373727 -4.21584558 -1.12852561 -1.63976145 -1.10546255  1.57828021
   3.48662901 -4.88260889  1.02128506 -6.28304815 -3.36240244 -0.86901569
   1.07910514 -0.35768217 -1.31982315 -4.80178356 -0.81195706  4.19534492
  -1.75880682  0.16279741  3.2874887   1.95571268 -0.55644894  6.29412794
   2.95025563  2.95755625 -6.42489004 -3.7333343   3.55800605 -2.36071539
   0.76097041 -0.83416665 -2.40119314  1.95632565 -4.06812    -0.26224855
  -1.96499002 -1.41249037  0.22600845  1.43376958]]
After layer encoder_birnn_forward_l0_t8_slice_output3 (1, 256) <class 'numpy.float32'> [[ 2.71170068  1.48059654  1.53804827  2.10083699  1.55464494  2.23746967
   4.24874735  1.51126289  1.92380905  1.49098468  1.996382    1.76308906
   1.64239907  2.78352833 -0.26574758  0.51433027  1.7737782   1.11274052
   3.99031138  2.11319447  1.37452066 -0.40413409  3.19266653  2.43413019
   1.23921752  1.36021554  3.02630043  1.93608916  0.25669509  1.60356128
   2.678509    2.16324854  0.23992653  1.36296844  1.45160985  1.02859426
   2.06794333  0.82405013 -1.34627402  1.05474305  1.09018862  1.48838723
   1.52034307  1.46939862  1.59307909  1.72301209  3.79722118  2.21614099
   1.44802058  0.40268233 -0.77841151  2.11277604  6.91643572 -0.37937206
   2.01399946 -0.49880251  1.16082025  1.59025323  2.11723256  1.39261758
   0.18480664  0.8582238   0.33295518  2.90741372  1.09107888  1.61410701
   2.52387476  1.22632444  1.81035173  1.08176875  1.97651339  2.02239227
   3.63939333  1.75920069  1.28551137  6.08308649  1.81293988  5.6005187
   2.62918687  0.22387245  3.25756741 -0.41031414  6.9516964   1.48290277
   2.55762196  1.1400274   1.12240362  1.97400177  4.4079361   2.37676263
   1.32359123  1.87149477 -1.06948268  2.75111127  0.45587111  1.8875078
   2.18864369  2.3374362   2.05682588  3.45898342  0.63823324  1.20836985
   0.66899908  3.33336711  2.32451034  0.65190256  1.86783087  2.26027846
   2.61983943  0.55416393  3.00438547  1.92175388  4.47929001  3.92115307
   2.36762023  1.77272761  1.9120189   3.76999164  1.86910594  2.03377032
   1.32805705  3.7854228   2.28958964  1.48778391  2.26621294  2.47330713
  -0.03979597  0.63658512  1.49676394  5.20971346  2.06257892  3.37778258
   1.41879165  1.71450925  0.92730367  1.13035238  2.52561641  1.04159248
   2.67665577  2.17930508  1.16177142  1.93637657  1.67553985  2.18055344
   1.13519621  2.56247163  1.48590946  1.56003773  0.29707605  0.89049429
   4.27227449  1.00503707  1.89228356  0.20958409  1.0957011  -0.05212138
   1.04432797  1.80674899  3.81323028  1.95803559  1.4465574   2.20963621
   0.32554913  2.54911661  3.33773041  0.64762652  1.98250794  0.5622201
  -0.57873923  0.91822064  0.92548364  7.33690691  1.93876433  3.15826678
   0.34810728  0.81685972  1.9037106   2.18333077  1.03221655  2.90836549
   1.57206464 -0.11438297  2.17171144  2.20560813  0.98499018  1.97716105
   1.78014815  1.02759409  2.12628984  2.52327108 -0.38081974  1.67083836
   3.62996483  1.26389515  0.66232347  1.92626143  7.62576294  1.36200511
   1.69714308  1.93213022  0.82129091  0.73697633  2.10833359  2.96453691
   2.20027447  2.28320193  2.88532329  0.08357264 -1.10005081  1.83123159
   2.26450157  0.8991549   3.05229688  2.40551496  5.35555983  3.38927078
   1.26349902  3.3891871   2.27499747  1.00791514  1.33079898  2.21998334
  -0.17684461  0.6243484   2.33066177  1.30992818  1.71199584  1.82702017
   1.94260418  1.25727844  1.1091882   3.33061671  2.09609699  1.84602487
   2.43850493  1.44556487  0.4533062  -0.08123283  1.65692651  4.15178537
   0.37669659  2.78436375  9.77085781  0.50752181  1.66505611  0.33408767
   1.85544097  2.07319665  3.11033297  2.30969477  2.93114257  0.981287
   3.20856118  2.36547899  1.32418609  1.95742822]]
After layer encoder_birnn_forward_l0_t8_o_output (1, 256) <class 'numpy.float32'> [[ 0.9377135   0.81466269  0.82318085  0.89098448  0.82558358  0.90356421
   0.985919    0.81924832  0.87256259  0.81622607  0.88041663  0.85359609
   0.83786112  0.9417792   0.43395138  0.62582105  0.85492694  0.75263965
   0.9818418   0.89217901  0.79810959  0.40031946  0.96055734  0.91939312
   0.77542776  0.79579473  0.95374829  0.87392187  0.5638237   0.83251554
   0.93574649  0.8969003   0.55969554  0.7962417   0.81024605  0.73664331
   0.88774818  0.69509542  0.20648019  0.74168468  0.74841726  0.81583613
   0.82058901  0.81296599  0.83104885  0.8485164   0.97805917  0.90168965
   0.80969363  0.59933192  0.31466234  0.89213878  0.99900961  0.40627837
   0.88225913  0.37782213  0.76148176  0.8306517   0.8925668   0.80100977
   0.54607064  0.7022894   0.58247823  0.94821173  0.74858487  0.83398086
   0.92579865  0.77317464  0.85940433  0.74682862  0.87830901  0.88312811
   0.9744041   0.85310954  0.78338647  0.99772412  0.85971683  0.99631763
   0.93271655  0.55573553  0.96294403  0.39883679  0.99904388  0.81501067
   0.9280839   0.75768465  0.75443435  0.87804025  0.98796624  0.91503811
   0.78977859  0.86663115  0.25550148  0.9399761   0.6120342   0.86847115
   0.89922506  0.91193038  0.88663554  0.96949792  0.65435398  0.77001041
   0.66127896  0.96555591  0.9108867   0.65743905  0.86620712  0.90553343
   0.93212754  0.63510114  0.95277184  0.87233388  0.98878574  0.98056692
   0.91432458  0.85479653  0.8712458   0.97746724  0.86635482  0.88429743
   0.79051906  0.9778046   0.9080112   0.81574541  0.90603983  0.9222492
   0.49005234  0.65398115  0.81709135  0.99456644  0.88721246  0.96700293
   0.8051489   0.84742028  0.716528    0.75590396  0.92591822  0.73915714
   0.93563503  0.89837569  0.7616545   0.87395352  0.84231299  0.89848959
   0.7567966   0.92840695  0.81546354  0.82635874  0.57372755  0.70899218
   0.98624194  0.7320478   0.86901563  0.55220509  0.74945372  0.48697263
   0.73968422  0.8589685   0.97840011  0.87632018  0.80946803  0.90111148
   0.58067602  0.9275142   0.96570075  0.65647537  0.87894821  0.63696605
   0.35922274  0.71467942  0.71615815  0.99934942  0.87421632  0.95923328
   0.58615851  0.6935693   0.8703109   0.89874256  0.7373454   0.94825846
   0.82807773  0.47143537  0.89768034  0.90075201  0.72809726  0.87837815
   0.85571516  0.73644924  0.89343226  0.92575717  0.40592921  0.8416875
   0.97416782  0.77969593  0.65978211  0.87283504  0.99951255  0.79608536
   0.8451612   0.87348503  0.69451028  0.67633426  0.89171052  0.95094603
   0.90027416  0.90747625  0.9471162   0.52088106  0.24973038  0.86190838
   0.90589404  0.71077579  0.95488161  0.91724688  0.99530029  0.96736753
   0.77962786  0.96736485  0.90678507  0.73261189  0.79097277  0.90202975
   0.45590371  0.65120685  0.91138482  0.78750116  0.84709501  0.86140639
   0.87463796  0.77855724  0.75197774  0.96546435  0.89052325  0.86365974
   0.91971678  0.80931491  0.61142498  0.47970298  0.83982497  0.98450744
   0.59307611  0.94182497  0.9999429   0.62422538  0.84091556  0.58275366
   0.86476463  0.88827056  0.95731699  0.90967679  0.94936466  0.72736353
   0.96115524  0.91415679  0.78987736  0.87625432]]
After layer encoder_birnn_forward_l0_t8_f_output (1, 256) <class 'numpy.float32'> [[ 0.92702198  0.5744195   0.64247382  0.73268861  0.70788509  0.7347548
   0.95054781  0.72227204  0.97782052  0.71840805  0.94111818  0.7515856
   0.84965187  0.86756909  0.37904844  0.6990056   0.72472113  0.70910817
   0.90258771  0.82979649  0.58393735  0.33801073  0.92697948  0.63986224
   0.79007202  0.81462032  0.85686457  0.7236616   0.87282479  0.67035484
   0.90651357  0.85854095  0.77145159  0.75866294  0.96211374  0.70011014
   0.61915642  0.76979369  0.95461154  0.45915642  0.84356272  0.746638
   0.94209266  0.37939182  0.57986885  0.34724647  0.95266521  0.78396428
   0.6483447   0.4031018   0.34311113  0.78190684  0.99634051  0.30714947
   0.91110575  0.27988261  0.67153239  0.79644662  0.79026502  0.88509029
   0.48538443  0.72944725  0.65339941  0.88746345  0.6392619   0.77398604
   0.86449879  0.87131131  0.72180361  0.94652253  0.49084237  0.85147351
   0.96423107  0.79424614  0.60010356  0.99472958  0.72020239  0.9933902
   0.85978454  0.24053064  0.93254739  0.28154805  0.98509431  0.87160701
   0.90155786  0.83763754  0.54792017  0.94707221  0.9952538   0.70983273
   0.61417836  0.80465215  0.4368121   0.80408585  0.36081195  0.48197016
   0.9324739   0.91179711  0.8971377   0.91375965  0.6141414   0.39670041
   0.51495636  0.90396947  0.89452189  0.68283802  0.76519132  0.83602917
   0.81437421  0.74652952  0.89955872  0.95230681  0.97537655  0.98242062
   0.87873399  0.74744159  0.86767721  0.93527138  0.73942858  0.73602188
   0.78865182  0.94842356  0.82970828  0.74879891  0.9013949   0.81680447
   0.22331642  0.76714373  0.75662971  0.9839707   0.74268562  0.87795043
   0.64862192  0.71739566  0.72545159  0.84493297  0.91334015  0.26513532
   0.9551847   0.87275177  0.77621174  0.82360882  0.85928851  0.85066205
   0.87315255  0.89669788  0.69215506  0.8288433   0.9226023   0.80042213
   0.88651282  0.62802458  0.81284088  0.83872008  0.74930888  0.70797044
   0.92529809  0.7438643   0.94048119  0.81360739  0.94978142  0.8322041
   0.89775687  0.83873111  0.89274025  0.6705938   0.71619684  0.76810443
   0.35257724  0.63475907  0.33026272  0.98227698  0.74674606  0.95662946
   0.56682807  0.67647558  0.76983225  0.89380753  0.44498226  0.9413271
   0.76821154  0.4007163   0.89487249  0.83402777  0.79097104  0.79174215
   0.89187056  0.82482952  0.82729113  0.86261684  0.26435333  0.7629661
   0.93681782  0.82828385  0.50537062  0.70545006  0.99977893  0.44342899
   0.80867875  0.41118234  0.67974663  0.83619386  0.73786253  0.94885397
   0.81013095  0.7040351   0.90805966  0.27938509  0.38398194  0.89043689
   0.8823781   0.77836984  0.86121023  0.81480014  0.98436213  0.94418818
   0.65601063  0.90845233  0.52240616  0.43407083  0.66439265  0.84807962
   0.51815563  0.87421072  0.79820889  0.96490675  0.22568271  0.73718977
   0.79489446  0.7246666   0.71963918  0.97954434  0.65727019  0.8043915
   0.92061508  0.78961283  0.67774552  0.59258956  0.69426668  0.97057545
   0.6254186   0.91501445  0.99981052  0.37970898  0.81188941  0.40301597
   0.65037376  0.76469439  0.83315182  0.82983279  0.95385474  0.42573151
   0.93844205  0.76578814  0.75962561  0.83131677]]
After layer _mul2068_0 (1, 256) <class 'numpy.float32'> [[ 0.87121904  0.50685024 -0.84588891 -0.68994665  1.25420773 -0.2306817
   2.66205668 -0.04541628 -0.65202332 -0.21938466  1.70380032  1.2533654
   0.40212792 -1.86514783  0.05904353 -0.01889612  0.77707094  1.09045529
  -0.6365515   0.95500338 -0.19451657 -0.11494151 -2.08619356  0.68725181
  -0.42254722 -0.40060955 -1.84086335 -0.08425131 -1.81799185  0.94321656
   1.45321357 -0.8691833   1.50050068 -0.84342682  3.13982821  0.61827224
   0.54993618 -1.88314188 -2.74420357 -0.01878324 -0.13666862  1.29008293
  -0.91523188  0.32766029 -1.09684014 -0.2871201  -0.06963068  1.13566625
   0.6870662   0.1781612   0.01245205  0.05029571 -2.90732193 -0.25547791
   2.44038582  0.19481377 -1.2605747  -0.33958772  1.19224215  0.01556377
   0.5485273  -0.20941414  0.2429492   2.39266205 -0.66274416  0.16921966
   1.59031987  2.25358152  0.72775304 -2.5423708   0.28111333  0.03467168
  -3.22273946  0.92433739  0.72321385  3.58307219  1.26077557 -4.12840557
   1.4843291  -0.09118602  2.45170164 -0.25828728 -0.27737647  0.43313774
  -1.57674849 -1.67621052  0.27524939 -2.92204261  0.83193046 -0.10790284
   0.81348324  0.61156231 -0.32869208 -0.98813397 -0.18319441 -0.13969621
  -2.06265402 -2.50398254  1.848894    0.74221909 -0.73050147 -0.03540613
  -0.08202519  2.06092072 -1.5754596  -0.89731926  0.77303368  1.01771736
   0.68304312  0.82544678 -2.2843678  -2.44581628  3.56287789  3.77285838
  -0.70716196  1.46027136  1.3349725   0.95603907  0.69729507  0.1887103
   0.24923864 -2.44913459  2.0512135  -0.86702555  2.76526666 -0.61863738
   0.21494381  1.10196698 -1.16235435 -3.52834582  0.30358288  1.77962387
   0.59212548 -0.43179241  1.40343511  1.8526969   1.34144366  0.09339611
  -2.59989524 -0.78476399 -0.09844472  1.93804824 -1.88691425 -0.37722278
   1.7617774   0.04909483  0.77651942  0.01437333  2.45765686 -0.31995934
   2.48961115 -0.97587526  2.05083323  1.82364368  0.57484531 -1.36996567
   2.23775005 -0.08784974  2.28720117  1.56459129  3.1587882   0.11421499
   1.27448773  1.83990455 -0.76206851  0.28595379 -0.17430033  1.32738161
  -0.22135986 -0.76473224  0.07491015  4.13645887 -0.83709168  2.95701599
  -0.77493864 -0.8927967   0.3171156   0.23196828 -0.32203516 -0.66214424
   1.65468633  0.4349013   1.36681902  1.22247553 -0.07149526 -1.37106907
  -1.02540326  1.89218986  1.33419681 -1.40870976  0.11197165 -1.05109334
  -2.53756309  1.50060725  0.34421352 -1.39356792 -1.14515758 -0.66347086
   1.50618267 -0.14571375  0.09587067 -1.7472235  -1.3063935  -1.91868567
  -0.73218161 -0.15807848  2.17616582  0.00747241  0.1361734   0.56174314
  -1.0977267   1.0433625   1.55372632  0.91911966  3.66558647 -2.54153538
  -0.78793919 -2.4264648  -0.47263363 -0.20298611 -0.56394804  1.22264111
   0.64926988 -1.96757269  0.82506704 -3.52334261 -0.23413023 -0.48639917
   0.62941146 -0.12225668 -0.35685757 -3.63028693 -0.46000603  1.8952812
  -1.73056662  0.00945286  0.98395175  0.40593928 -0.2638326   3.26768708
   0.78624451  2.14135218 -4.68390608 -0.44551721  1.68951905 -0.46549535
   0.52034628 -0.60670835 -1.64968109  1.2728343  -3.02453876 -0.04857388
  -1.99171257 -1.06162536 -0.02078993  0.98610073]]
After layer encoder_birnn_forward_l0_t8_i_output (1, 256) <class 'numpy.float32'> [[ 0.79470485  0.74669874  0.71238995  0.69630319  0.85003591  0.81097573
   0.94947869  0.57994914  0.2254473   0.73186189  0.73992515  0.84069341
   0.47458419  0.88463193  0.29512581  0.58824539  0.61712122  0.78612584
   0.85124618  0.68627203  0.5273394   0.13903719  0.72501278  0.66995001
   0.60677814  0.6458751   0.85494429  0.48541662  0.81300616  0.85489899
   0.80658591  0.72739786  0.90165114  0.78220886  0.98173147  0.58340919
   0.63522929  0.97523302  0.94067419  0.14488369  0.343786    0.76172227
   0.93546212  0.50129485  0.9733569   0.74024832  0.67605716  0.7910099
   0.63824028  0.39275944  0.38335514  0.35239324  0.99889332  0.65940076
   0.93559456  0.46737921  0.92248672  0.56998575  0.72958958  0.12822677
   0.64472073  0.62018651  0.43262905  0.93578827  0.56619275  0.56279999
   0.85636234  0.95282638  0.79352349  0.92360002  0.37127191  0.13552536
   0.97711378  0.77108318  0.70862573  0.97999018  0.83760583  0.9956429
   0.80016857  0.19539715  0.92067462  0.74483544  0.82447666  0.4591015
   0.91408426  0.82792199  0.70196575  0.96659064  0.92599225  0.40130973
   0.79853064  0.39350063  0.39898938  0.78698051  0.21492837  0.13091263
   0.90532732  0.95024341  0.88626707  0.76101875  0.6925562   0.31303674
   0.70527279  0.94724762  0.81852889  0.67101443  0.52910173  0.61725855
   0.44914138  0.55185348  0.93199849  0.90544152  0.99083078  0.99622715
   0.83908248  0.87662059  0.71655256  0.89959103  0.61368829  0.37585068
   0.39613444  0.92032391  0.98286545  0.73941129  0.97667557  0.6319297
   0.72733766  0.76844603  0.65326983  0.97978926  0.33768895  0.87440729
   0.75584811  0.60517114  0.90661335  0.85481864  0.81491768  0.1845616
   0.84669065  0.49467286  0.59426349  0.93354237  0.84892797  0.51254088
   0.79354006  0.19831975  0.55010593  0.37744275  0.89568329  0.4066118
   0.9691714   0.88129699  0.97441941  0.9374091   0.57856685  0.91549975
   0.80859071  0.40016845  0.88330221  0.85613799  0.98095912  0.43201089
   0.86356008  0.88999599  0.84701037  0.47571695  0.59351838  0.793715
   0.4072457   0.6922012   0.27395782  0.99969423  0.69731694  0.93769288
   0.80835027  0.59677923  0.37574339  0.28134933  0.52878422  0.72065586
   0.94267529  0.69918239  0.7711035   0.67838621  0.40880617  0.78524673
   0.58760816  0.92117429  0.84155709  0.79596412  0.2520375   0.63190788
   0.937774    0.72699422  0.68473637  0.91064388  0.99844676  0.93754482
   0.82770902  0.56038725  0.67431712  0.88476878  0.7774061   0.80132347
   0.78935808  0.51173097  0.86110902  0.28565252  0.27430919  0.71741587
   0.83253163  0.72972858  0.93337625  0.76270586  0.98661184  0.91329181
   0.70353484  0.95687443  0.74201101  0.22439182  0.66160858  0.67940146
   0.77292758  0.84044671  0.80739456  0.99801147  0.79755557  0.43510479
   0.48828959  0.48649603  0.2711184   0.9941572   0.6831125   0.9441576
   0.86028737  0.47866625  0.68685454  0.36508006  0.49737915  0.96232057
   0.64925921  0.83970833  0.99987209  0.77595836  0.89257717  0.81946671
   0.69643176  0.63848168  0.86772442  0.6830005   0.96528852  0.2168919
   0.89413166  0.73660368  0.37104014  0.70526975]]
After layer encoder_birnn_forward_l0_t8_c_output (1, 256) <class 'numpy.float32'> [[ 0.62375122  0.71213245 -0.99365646 -0.82787371  0.99788433 -0.19347896
   0.99460387 -0.30992988 -0.59565824 -0.37441465  0.96507943  0.96412188
   0.47311071 -0.98917967  0.42969778 -0.09122303  0.87872684  0.98136234
  -0.71035326  0.86769927 -0.39883777 -0.99987805 -0.99922717  0.90729725
  -0.53195    -0.52730691 -0.9983055  -0.22597371 -0.99545127  0.94387728
   0.91974205 -0.74311221  0.99299657 -0.69899166  0.99992484  0.8836444
   0.80181581 -0.99986351 -0.99838972 -0.15509085 -0.25384805  0.99904388
  -0.73224437  0.99341524 -0.99997658 -0.8319307   0.24404098  0.91098726
   0.93811941  0.78910756  0.21970074  0.18726483 -0.93200886 -0.923118
   0.99883133  0.97727764 -0.99966323 -0.40927875  0.97370398 -0.02825739
   0.99360883 -0.3192111   0.51396036  0.99999875 -0.98247463  0.25247133
   0.95968759  0.99818265  0.68660372 -0.99555159  0.82909763 -0.19851005
  -0.99981278  0.83322406  0.95702887  0.99804807  0.99772334 -0.99999398
   0.96930426 -0.99954623  0.99976444 -0.96228725  0.15135135  0.65328324
  -0.91532433 -0.99581927  0.48757285 -0.99961889  0.50136495 -0.04218224
   0.96036124  0.84555328 -0.99830675 -0.81524503 -0.99991077 -0.71813601
  -0.95124596 -0.9998011   0.96350002  0.59539521 -0.98524326 -0.15301961
  -0.38412973  0.97139466 -0.92323107 -0.99735761  0.8717404   0.91916537
   0.84586191  0.95676416 -0.99924749 -0.99193913  0.99996889  0.9999606
  -0.59744632  0.99786478  0.95591301  0.7071557   0.72433972  0.48274219
   0.43718958 -0.98790199  0.99692059 -0.86586547  0.99998528 -0.75814807
   0.99964762  0.96956718 -0.9984259  -0.99982941  0.58768451  0.96352351
   0.78407311 -0.58987629  0.99788821  0.999264    0.89425069  0.99355501
  -0.99981409 -0.74937975 -0.32310906  0.99973381 -0.99918956 -0.53869677
   0.99772108  0.22974585  0.99134463 -0.04017337  0.99981511 -0.47769192
   0.9998703  -0.98130918  0.99993581  0.99124974  0.74727875 -0.99948794
   0.99965411 -0.27728653  0.98937088  0.98648447  0.9999963   0.20490196
   0.86023998  0.99633461 -0.61578333  0.48517236 -0.39021474  0.99595124
  -0.96602452 -0.95908791  0.5286417   0.99999684 -0.89857978  0.99995035
  -0.99028313 -0.99973077  0.61686921  0.34437597 -0.93845189 -0.50977355
   0.99963427  0.9947021   0.89821386  0.96178097 -0.23329651 -0.98138207
  -0.8470726   0.99951357  0.9578771  -0.92700851  0.99908084 -0.98374903
  -0.99515152  0.99842876  0.73334348 -0.99951553  0.0460001  -0.9982596
   0.98876411 -0.37869602  0.3119356  -0.99393141 -0.9998523  -0.9539721
  -0.74128938  0.08711108  0.99825794  0.02961656  0.68978715  0.67008644
  -0.76376212  0.95173967  0.92299151  0.7884087   0.99994785 -0.99771446
  -0.94821024 -0.99956441 -0.81051409 -0.92743921 -0.80245262  0.91833287
   0.99812853 -0.9998852   0.77038944 -0.99999303 -0.99760139 -0.70087367
   0.792867   -0.34317079 -0.86673993 -0.99986506 -0.67066848  0.99954617
  -0.94236958  0.16137429  0.9972142   0.96076131 -0.50533795  0.99999321
   0.99453884  0.99461782 -0.99999475 -0.99885702  0.99837732 -0.98235226
   0.64164823 -0.68270695 -0.98371345  0.96080846 -0.99941468 -0.25639746
  -0.96146876 -0.88802183  0.22223732  0.8924365 ]]
After layer _mul2069_0 (1, 256) <class 'numpy.float32'> [[ 0.49569812  0.53174841 -0.70787084 -0.57645112  0.84823751 -0.15690674
   0.94435519 -0.17974357 -0.13428955 -0.27401981  0.71408653  0.8105309
   0.22453086 -0.8750599   0.1268149  -0.05366153  0.54228097  0.7714743
  -0.60468549  0.59547776 -0.21032287 -0.13902023 -0.72445244  0.60784382
  -0.32277563 -0.34057441 -0.8534956  -0.1096914  -0.80930799  0.80691975
   0.74185097 -0.54053825  0.89533651 -0.54675746  0.98165768  0.51552629
   0.50933689 -0.97509992 -0.93915945 -0.02247014 -0.0872694   0.76099396
  -0.68498689  0.49799395 -0.97333407 -0.61583531  0.16498566  0.72059995
   0.59874558  0.30992946  0.0842234   0.06599086 -0.9309774  -0.60870469
   0.93450117  0.45675924 -0.92217606 -0.23328306  0.71040428 -0.00362335
   0.6406002  -0.19797042  0.22235419  0.93578708 -0.55627     0.14209086
   0.82184029  0.95109475  0.54483616 -0.91949147  0.30782065 -0.02690315
  -0.97693086  0.64248508  0.67817527  0.97807729  0.8356989  -0.99563688
   0.77560681 -0.19530849  0.92045772 -0.71674562  0.12478565  0.2999233
  -0.83668357 -0.82446069  0.34225944 -0.96622229  0.46426004 -0.01692814
   0.76687789  0.33272573 -0.39831379 -0.64158195 -0.2149092  -0.09401307
  -0.86118895 -0.95005441  0.85391831  0.45310691 -0.68233633 -0.04790076
  -0.27091625  0.92015129 -0.75569129 -0.66924137  0.46123937  0.56736267
   0.3799116   0.52799362 -0.93129718 -0.89814287  0.99079996  0.99618787
  -0.50130671  0.87474883  0.68496192  0.63615096  0.4445188   0.18143898
   0.17318584 -0.90918982  0.97983879 -0.64023072  0.97666121 -0.47909629
   0.72708136  0.74506003 -0.65224153 -0.97962213  0.19845457  0.84251195
   0.59264016 -0.35697612  0.90469879  0.85418952  0.72874069  0.1833721
  -0.84653324 -0.37069783 -0.19201192  0.93329388 -0.84823996 -0.27610412
   0.79173166  0.04556314  0.54534453 -0.01516315  0.89551771 -0.19423518
   0.9690457  -0.86482483  0.97435689  0.92920655  0.43235072 -0.91503096
   0.80831105 -0.11096132  0.87391347  0.84456682  0.98095548  0.08851988
   0.7428689   0.88673383 -0.52157485  0.23080471 -0.23159961  0.79050142
  -0.39340934 -0.66388178  0.14482553  0.99969107 -0.6265949   0.93764633
  -0.80049562 -0.59661853  0.23178452  0.09688995 -0.49623853 -0.36737129
   0.94233054  0.6954782   0.69261587  0.65245897 -0.09537306 -0.77062708
  -0.49774677  0.92072618  0.80610824 -0.73786551  0.25180584 -0.62163877
  -0.93322724  0.72585195  0.50214696 -0.91020268  0.04592866 -0.93591315
   0.81840897 -0.21221642  0.21034352 -0.87939948 -0.7772913  -0.76444024
  -0.58514273  0.04457743  0.85960889  0.00846004  0.18921496  0.48073065
  -0.63585609  0.69451165  0.86149836  0.60132396  0.9865604  -0.91120446
  -0.66709894 -0.95645761 -0.60141039 -0.20810977 -0.53090954  0.62391669
   0.7714811  -0.84035021  0.62200826 -0.9980045  -0.79564255 -0.30495349
   0.38714871 -0.16695122 -0.23498915 -0.99402303 -0.45814201  0.9437291
  -0.81070864  0.07724442  0.68494111  0.3507548  -0.25134456  0.96231401
   0.64571351  0.83518887 -0.99986684 -0.77507144  0.89112878 -0.80500495
   0.44686422 -0.43589589 -0.85359216  0.65623266 -0.96472353 -0.05561053
  -0.85967964 -0.65412015  0.08245897  0.62940848]]
After layer encoder_birnn_forward_l0_t8_state_0 (1, 256) <class 'numpy.float32'> [[  1.36691713e+00   1.03859866e+00  -1.55375981e+00  -1.26639771e+00
    2.10244513e+00  -3.87588441e-01   3.60641193e+00  -2.25159854e-01
   -7.86312878e-01  -4.93404448e-01   2.41788673e+00   2.06389618e+00
    6.26658797e-01  -2.74020767e+00   1.85858428e-01  -7.25576505e-02
    1.31935191e+00   1.86192966e+00  -1.24123693e+00   1.55048108e+00
   -4.04839456e-01  -2.53961742e-01  -2.81064606e+00   1.29509568e+00
   -7.45322824e-01  -7.41183996e-01  -2.69435883e+00  -1.93942696e-01
   -2.62729979e+00   1.75013638e+00   2.19506454e+00  -1.40972161e+00
    2.39583731e+00  -1.39018428e+00   4.12148571e+00   1.13379860e+00
    1.05927300e+00  -2.85824180e+00  -3.68336296e+00  -4.12533730e-02
   -2.23938018e-01   2.05107689e+00  -1.60021877e+00   8.25654268e-01
   -2.07017422e+00  -9.02955413e-01   9.53549817e-02   1.85626626e+00
    1.28581178e+00   4.88090664e-01   9.66754556e-02   1.16286561e-01
   -3.83829927e+00  -8.64182591e-01   3.37488699e+00   6.51573002e-01
   -2.18275070e+00  -5.72870791e-01   1.90264642e+00   1.19404141e-02
    1.18912745e+00  -4.07384574e-01   4.65303391e-01   3.32844925e+00
   -1.21901417e+00   3.11310530e-01   2.41216016e+00   3.20467615e+00
    1.27258921e+00  -3.46186233e+00   5.88933945e-01   7.76853226e-03
   -4.19967031e+00   1.56682253e+00   1.40138912e+00   4.56114960e+00
    2.09647441e+00  -5.12404251e+00   2.25993586e+00  -2.86494493e-01
    3.37215948e+00  -9.75032926e-01  -1.52590811e-01   7.33061075e-01
   -2.41343212e+00  -2.50067115e+00   6.17508829e-01  -3.88826489e+00
    1.29619050e+00  -1.24830984e-01   1.58036113e+00   9.44288015e-01
   -7.27005839e-01  -1.62971592e+00  -3.98103595e-01  -2.33709276e-01
   -2.92384291e+00  -3.45403695e+00   2.70281219e+00   1.19532597e+00
   -1.41283774e+00  -8.33068937e-02  -3.52941453e-01   2.98107195e+00
   -2.33115101e+00  -1.56656063e+00   1.23427308e+00   1.58508003e+00
    1.06295466e+00   1.35344040e+00  -3.21566486e+00  -3.34395909e+00
    4.55367804e+00   4.76904631e+00  -1.20846868e+00   2.33502007e+00
    2.01993442e+00   1.59219003e+00   1.14181387e+00   3.70149285e-01
    4.22424495e-01  -3.35832453e+00   3.03105235e+00  -1.50725627e+00
    3.74192786e+00  -1.09773374e+00   9.42025185e-01   1.84702706e+00
   -1.81459594e+00  -4.50796795e+00   5.02037466e-01   2.62213588e+00
    1.18476558e+00  -7.88768530e-01   2.30813384e+00   2.70688629e+00
    2.07018423e+00   2.76768208e-01  -3.44642854e+00  -1.15546179e+00
   -2.90456653e-01   2.87134218e+00  -2.73515415e+00  -6.53326869e-01
    2.55350900e+00   9.46579725e-02   1.32186389e+00  -7.89818354e-04
    3.35317469e+00  -5.14194489e-01   3.45865679e+00  -1.84070015e+00
    3.02519011e+00   2.75285029e+00   1.00719607e+00  -2.28499651e+00
    3.04606104e+00  -1.98811054e-01   3.16111469e+00   2.40915823e+00
    4.13974380e+00   2.02734858e-01   2.01735663e+00   2.72663832e+00
   -1.28364336e+00   5.16758502e-01  -4.05899942e-01   2.11788297e+00
   -6.14769220e-01  -1.42861402e+00   2.19735682e-01   5.13614988e+00
   -1.46368659e+00   3.89466238e+00  -1.57543421e+00  -1.48941517e+00
    5.48900127e-01   3.28858227e-01  -8.18273664e-01  -1.02951550e+00
    2.59701681e+00   1.13037944e+00   2.05943489e+00   1.87493443e+00
   -1.66868329e-01  -2.14169621e+00  -1.52314997e+00   2.81291604e+00
    2.14030504e+00  -2.14657521e+00   3.63777488e-01  -1.67273211e+00
   -3.47079039e+00   2.22645926e+00   8.46360445e-01  -2.30377054e+00
   -1.09922886e+00  -1.59938407e+00   2.32459164e+00  -3.57930183e-01
    3.06214213e-01  -2.62662292e+00  -2.08368492e+00  -2.68312597e+00
   -1.31732440e+00  -1.13501042e-01   3.03577471e+00   1.59324519e-02
    3.25388372e-01   1.04247379e+00  -1.73358274e+00   1.73787415e+00
    2.41522455e+00   1.52044368e+00   4.65214682e+00  -3.45273972e+00
   -1.45503807e+00  -3.38292241e+00  -1.07404399e+00  -4.11095858e-01
   -1.09485757e+00   1.84655786e+00   1.42075098e+00  -2.80792284e+00
    1.44707537e+00  -4.52134705e+00  -1.02977276e+00  -7.91352630e-01
    1.01656020e+00  -2.89207906e-01  -5.91846704e-01  -4.62431002e+00
   -9.18148041e-01   2.83901024e+00  -2.54127526e+00   8.66972879e-02
    1.66889286e+00   7.56694078e-01  -5.15177131e-01   4.23000097e+00
    1.43195796e+00   2.97654104e+00  -5.68377304e+00  -1.22058868e+00
    2.58064795e+00  -1.27050030e+00   9.67210531e-01  -1.04260421e+00
   -2.50327325e+00   1.92906690e+00  -3.98926234e+00  -1.04184411e-01
   -2.85139227e+00  -1.71574545e+00   6.16690293e-02   1.61550927e+00]]
After layer activation1034_output (1, 256) <class 'numpy.float32'> [[  8.77987683e-01   7.77334094e-01  -9.14403737e-01  -8.52818310e-01
    9.70593989e-01  -3.69279385e-01   9.98526931e-01  -2.21430495e-01
   -6.56315207e-01  -4.56914306e-01   9.84244049e-01   9.68274534e-01
    5.55747271e-01  -9.91699398e-01   1.83747545e-01  -7.24305883e-02
    8.66622686e-01   9.52856839e-01  -8.45808029e-01   9.13864851e-01
   -3.84082168e-01  -2.48639122e-01  -9.92786169e-01   8.60455275e-01
   -6.32350326e-01  -6.29859984e-01  -9.90905881e-01  -1.91547096e-01
   -9.89607394e-01   9.41391051e-01   9.75505471e-01  -8.87435019e-01
    9.83539522e-01  -8.83211434e-01   9.99473929e-01   8.12315345e-01
    7.85385430e-01  -9.93439078e-01  -9.98736918e-01  -4.12299857e-02
   -2.20268250e-01   9.67464030e-01  -9.21701491e-01   6.78135633e-01
   -9.68664169e-01  -7.17733860e-01   9.50670242e-02   9.52332616e-01
    8.58025670e-01   4.52699691e-01   9.63753983e-02   1.15765221e-01
   -9.99073327e-01  -6.98406339e-01   9.97660458e-01   5.72727919e-01
   -9.74902391e-01  -5.17464519e-01   9.56463456e-01   1.19398469e-02
    8.30308080e-01  -3.86249721e-01   4.34396744e-01   9.97433066e-01
   -8.39363098e-01   3.01628858e-01   9.84063983e-01   9.96713221e-01
    8.54497850e-01  -9.98033643e-01   5.29128492e-01   7.76837580e-03
   -9.99550045e-01   9.16518867e-01   8.85651529e-01   9.99781609e-01
    9.70245957e-01  -9.99929130e-01   9.78453815e-01  -2.78905153e-01
    9.97647643e-01  -7.50907660e-01  -1.51417434e-01   6.24934554e-01
   -9.84104156e-01  -9.86632109e-01   5.49391150e-01  -9.99161422e-01
    8.60739231e-01  -1.24186598e-01   9.18658257e-01   7.37186193e-01
   -6.21230125e-01  -9.26021099e-01  -3.78325164e-01  -2.29545161e-01
   -9.94243503e-01  -9.98002648e-01   9.91057634e-01   8.32223356e-01
   -8.88095200e-01  -8.31147134e-02  -3.38981569e-01   9.94864464e-01
   -9.81287360e-01  -9.16476965e-01   8.43814313e-01   9.19391572e-01
    7.86792040e-01   8.74862909e-01  -9.96784568e-01  -9.97511327e-01
    9.99778330e-01   9.99855876e-01  -8.36219549e-01   9.81430233e-01
    9.65409219e-01   9.20484424e-01   8.15023959e-01   3.54122281e-01
    3.98970991e-01  -9.97581780e-01   9.95351851e-01  -9.06450927e-01
    9.98876452e-01  -7.99683511e-01   7.36151338e-01   9.51465189e-01
   -9.48296845e-01  -9.99757111e-01   4.63717997e-01   9.89500105e-01
    8.28948379e-01  -6.57710850e-01   9.80414391e-01   9.91129935e-01
    9.68664765e-01   2.69911349e-01  -9.97972012e-01  -8.19555402e-01
   -2.82555044e-01   9.93608177e-01  -9.91615415e-01  -5.73905349e-01
    9.87964630e-01   9.43762660e-02   8.67246687e-01  -7.89818179e-04
    9.97556746e-01  -4.73206878e-01   9.98021007e-01  -9.50862288e-01
    9.95297134e-01   9.91905808e-01   7.64599800e-01  -9.79496300e-01
    9.95489001e-01  -1.96232423e-01   9.96414542e-01   9.83968794e-01
    9.99492824e-01   2.00002223e-01   9.65233564e-01   9.91472006e-01
   -8.57452631e-01   4.75194335e-01  -3.84985834e-01   9.71475244e-01
   -5.47475576e-01  -8.91382217e-01   2.16266125e-01   9.99930859e-01
   -8.98366213e-01   9.99172091e-01  -9.17885840e-01  -9.03217077e-01
    4.99695450e-01   3.17494452e-01  -6.74129128e-01  -7.73713946e-01
    9.88962114e-01   8.11149120e-01   9.67994750e-01   9.54039395e-01
   -1.65336579e-01  -9.72783923e-01  -9.09245014e-01   9.92818773e-01
    9.72709119e-01  -9.73044634e-01   3.48536998e-01  -9.31911945e-01
   -9.98068392e-01   9.76979017e-01   6.89163327e-01  -9.80244458e-01
   -8.00221860e-01  -9.21575785e-01   9.81042564e-01  -3.43389571e-01
    2.96989113e-01  -9.89593387e-01  -9.69486833e-01  -9.90700245e-01
   -8.66117001e-01  -1.13016151e-01   9.95395422e-01   1.59311034e-02
    3.14370960e-01   7.78863072e-01  -9.39477921e-01   9.39979613e-01
    9.84160602e-01   9.08774972e-01   9.99817967e-01  -9.97997463e-01
   -8.96684587e-01  -9.97697711e-01  -7.90979922e-01  -3.89402777e-01
   -7.98644245e-01   9.51420724e-01   8.89755487e-01  -9.92746949e-01
    8.95113051e-01  -9.99763548e-01  -7.73817182e-01  -6.59174562e-01
    7.68461764e-01  -2.81405598e-01  -5.31222463e-01  -9.99807537e-01
   -7.25020170e-01   9.93182659e-01  -9.87668395e-01   8.64807218e-02
    9.31405187e-01   6.39125586e-01  -4.73969132e-01   9.99576569e-01
    8.92067134e-01   9.94817793e-01  -9.99976873e-01  -8.39827776e-01
    9.88596857e-01  -8.53933215e-01   7.47475922e-01  -7.78914392e-01
   -9.86701071e-01   9.58657920e-01  -9.99314725e-01  -1.03809088e-01
   -9.93348897e-01  -9.37348664e-01   6.15909733e-02   9.23970044e-01]]
After layer encoder_birnn_forward_l0_t8_out_0 (1, 256) <class 'numpy.float32'> [[  8.23300898e-01   6.33265078e-01  -7.52719641e-01  -7.59847879e-01
    8.01306486e-01  -3.33667636e-01   9.84466672e-01  -1.81406558e-01
   -5.72676122e-01  -3.72945368e-01   8.66544843e-01   8.26515377e-01
    4.65639025e-01  -9.33961868e-01   7.97374994e-02  -4.53285873e-02
    7.40899086e-01   7.17157841e-01  -8.30449700e-01   8.15331042e-01
   -3.06539655e-01  -9.95350778e-02  -9.53628063e-01   7.91096687e-01
   -4.90341991e-01  -5.01239240e-01  -9.45074797e-01  -1.67397201e-01
   -5.57964087e-01   7.83722699e-01   9.12825823e-01  -7.95940757e-01
    5.50482690e-01  -7.03249753e-01   8.09819818e-01   5.98386645e-01
    6.97224498e-01  -6.90534949e-01  -2.06219390e-01  -3.05796489e-02
   -1.64852560e-01   7.89292097e-01  -7.56338120e-01   5.51301181e-01
   -8.05007219e-01  -6.09008968e-01   9.29811746e-02   8.58708441e-01
    6.94737911e-01   2.71317363e-01   3.03257089e-02   1.03278644e-01
   -9.98083830e-01  -2.83747405e-01   8.80195022e-01   2.16389284e-01
   -7.42370367e-01  -4.29832786e-01   8.53707552e-01   9.56393406e-03
    4.53406870e-01  -2.71259099e-01   2.53026634e-01   9.45777714e-01
   -6.28334522e-01   2.51552701e-01   9.11045134e-01   7.70633399e-01
    7.34359145e-01  -7.45360076e-01   4.64738309e-01   6.86047086e-03
   -9.73965645e-01   7.81890988e-01   6.93807423e-01   9.97506201e-01
    8.34136784e-01  -9.96246994e-01   9.12620068e-01  -1.54997498e-01
    9.60678816e-01  -2.99489588e-01  -1.51272655e-01   5.09328306e-01
   -9.13331211e-01  -7.47556031e-01   4.14479554e-01  -8.77303958e-01
    8.50381315e-01  -1.13635473e-01   7.25536644e-01   6.38868511e-01
   -1.58725217e-01  -8.70437682e-01  -2.31547937e-01  -1.99353352e-01
   -8.94048691e-01  -9.10108924e-01   8.78706932e-01   8.06838810e-01
   -5.81128597e-01  -6.39991984e-02  -2.24161386e-01   9.60597277e-01
   -8.93841624e-01  -6.02527738e-01   7.30917990e-01   8.32539797e-01
    7.33390510e-01   5.55626452e-01  -9.49708283e-01  -8.70162904e-01
    9.88566577e-01   9.80425596e-01  -7.64576077e-01   8.38923156e-01
    8.41108739e-01   8.99743378e-01   7.06099927e-01   3.13149422e-01
    3.15394163e-01  -9.75440025e-01   9.03790653e-01  -7.39433169e-01
    9.05021846e-01  -7.37507463e-01   3.60752702e-01   6.22240305e-01
   -7.74845123e-01  -9.94324863e-01   4.11416382e-01   9.56849515e-01
    6.67426884e-01  -5.57357490e-01   7.02494383e-01   7.49199033e-01
    8.96904349e-01   1.99506894e-01  -9.33737576e-01  -7.36268640e-01
   -2.15209320e-01   8.68367374e-01  -8.35250556e-01  -5.15648007e-01
    7.47688293e-01   8.76195803e-02   7.07208037e-01  -6.52673130e-04
    5.72325766e-01  -3.35499972e-01   9.84290183e-01  -6.96076632e-01
    8.64928782e-01   5.47735453e-01   5.73032141e-01  -4.76987898e-01
    7.36347497e-01  -1.68557465e-01   9.74892080e-01   8.62271726e-01
    8.09057474e-01   1.80224299e-01   5.60487986e-01   9.19604361e-01
   -8.28042626e-01   3.11953366e-01  -3.38382602e-01   6.18796766e-01
   -1.96665674e-01  -6.37052536e-01   1.54880747e-01   9.99280334e-01
   -7.85366416e-01   9.58439112e-01  -5.38026571e-01  -6.26443624e-01
    4.34890389e-01   2.85345763e-01  -4.97066021e-01  -7.33680785e-01
    8.18937480e-01   3.82404387e-01   8.68949831e-01   8.59352887e-01
   -1.20381109e-01  -8.54472160e-01  -7.78054714e-01   7.31160641e-01
    8.69049728e-01  -9.00803030e-01   1.41481355e-01  -7.84378648e-01
   -9.72286105e-01   7.61746585e-01   4.54697639e-01  -8.55591714e-01
   -7.99831808e-01  -7.33653009e-01   8.29139113e-01  -2.99945652e-01
    2.06261992e-01  -6.69295907e-01  -8.64501595e-01  -9.42102492e-01
   -7.79742777e-01  -1.02559470e-01   9.42755103e-01   8.29820987e-03
    7.85079822e-02   6.71308577e-01  -8.51067424e-01   6.68114781e-01
    9.39756870e-01   8.33571017e-01   9.95119095e-01  -9.65430319e-01
   -6.99080288e-01  -9.65137720e-01  -7.17248797e-01  -2.85281092e-01
   -6.31705821e-01   8.58209789e-01   4.05642837e-01  -6.46483600e-01
    8.15792441e-01  -7.87314951e-01  -6.55496657e-01  -5.67817152e-01
    6.72125816e-01  -2.19090372e-01  -3.99467468e-01  -9.65278566e-01
   -6.45647347e-01   8.57771873e-01  -9.08375204e-01   6.99901357e-02
    5.69484413e-01   3.06590438e-01  -3.98051113e-01   9.84090567e-01
    5.29063702e-01   9.36944246e-01  -9.99919772e-01  -5.24241805e-01
    8.31326485e-01  -4.97632712e-01   6.46390736e-01  -6.91886723e-01
   -9.44585681e-01   8.72068882e-01  -9.48714077e-01  -7.55069479e-02
   -9.54762518e-01  -8.56883645e-01   4.86493148e-02   8.09632719e-01]]
After layer expand_dims1040_0 (1, 1, 256) <class 'numpy.float32'> [[[  8.23300898e-01   6.33265078e-01  -7.52719641e-01  -7.59847879e-01
     8.01306486e-01  -3.33667636e-01   9.84466672e-01  -1.81406558e-01
    -5.72676122e-01  -3.72945368e-01   8.66544843e-01   8.26515377e-01
     4.65639025e-01  -9.33961868e-01   7.97374994e-02  -4.53285873e-02
     7.40899086e-01   7.17157841e-01  -8.30449700e-01   8.15331042e-01
    -3.06539655e-01  -9.95350778e-02  -9.53628063e-01   7.91096687e-01
    -4.90341991e-01  -5.01239240e-01  -9.45074797e-01  -1.67397201e-01
    -5.57964087e-01   7.83722699e-01   9.12825823e-01  -7.95940757e-01
     5.50482690e-01  -7.03249753e-01   8.09819818e-01   5.98386645e-01
     6.97224498e-01  -6.90534949e-01  -2.06219390e-01  -3.05796489e-02
    -1.64852560e-01   7.89292097e-01  -7.56338120e-01   5.51301181e-01
    -8.05007219e-01  -6.09008968e-01   9.29811746e-02   8.58708441e-01
     6.94737911e-01   2.71317363e-01   3.03257089e-02   1.03278644e-01
    -9.98083830e-01  -2.83747405e-01   8.80195022e-01   2.16389284e-01
    -7.42370367e-01  -4.29832786e-01   8.53707552e-01   9.56393406e-03
     4.53406870e-01  -2.71259099e-01   2.53026634e-01   9.45777714e-01
    -6.28334522e-01   2.51552701e-01   9.11045134e-01   7.70633399e-01
     7.34359145e-01  -7.45360076e-01   4.64738309e-01   6.86047086e-03
    -9.73965645e-01   7.81890988e-01   6.93807423e-01   9.97506201e-01
     8.34136784e-01  -9.96246994e-01   9.12620068e-01  -1.54997498e-01
     9.60678816e-01  -2.99489588e-01  -1.51272655e-01   5.09328306e-01
    -9.13331211e-01  -7.47556031e-01   4.14479554e-01  -8.77303958e-01
     8.50381315e-01  -1.13635473e-01   7.25536644e-01   6.38868511e-01
    -1.58725217e-01  -8.70437682e-01  -2.31547937e-01  -1.99353352e-01
    -8.94048691e-01  -9.10108924e-01   8.78706932e-01   8.06838810e-01
    -5.81128597e-01  -6.39991984e-02  -2.24161386e-01   9.60597277e-01
    -8.93841624e-01  -6.02527738e-01   7.30917990e-01   8.32539797e-01
     7.33390510e-01   5.55626452e-01  -9.49708283e-01  -8.70162904e-01
     9.88566577e-01   9.80425596e-01  -7.64576077e-01   8.38923156e-01
     8.41108739e-01   8.99743378e-01   7.06099927e-01   3.13149422e-01
     3.15394163e-01  -9.75440025e-01   9.03790653e-01  -7.39433169e-01
     9.05021846e-01  -7.37507463e-01   3.60752702e-01   6.22240305e-01
    -7.74845123e-01  -9.94324863e-01   4.11416382e-01   9.56849515e-01
     6.67426884e-01  -5.57357490e-01   7.02494383e-01   7.49199033e-01
     8.96904349e-01   1.99506894e-01  -9.33737576e-01  -7.36268640e-01
    -2.15209320e-01   8.68367374e-01  -8.35250556e-01  -5.15648007e-01
     7.47688293e-01   8.76195803e-02   7.07208037e-01  -6.52673130e-04
     5.72325766e-01  -3.35499972e-01   9.84290183e-01  -6.96076632e-01
     8.64928782e-01   5.47735453e-01   5.73032141e-01  -4.76987898e-01
     7.36347497e-01  -1.68557465e-01   9.74892080e-01   8.62271726e-01
     8.09057474e-01   1.80224299e-01   5.60487986e-01   9.19604361e-01
    -8.28042626e-01   3.11953366e-01  -3.38382602e-01   6.18796766e-01
    -1.96665674e-01  -6.37052536e-01   1.54880747e-01   9.99280334e-01
    -7.85366416e-01   9.58439112e-01  -5.38026571e-01  -6.26443624e-01
     4.34890389e-01   2.85345763e-01  -4.97066021e-01  -7.33680785e-01
     8.18937480e-01   3.82404387e-01   8.68949831e-01   8.59352887e-01
    -1.20381109e-01  -8.54472160e-01  -7.78054714e-01   7.31160641e-01
     8.69049728e-01  -9.00803030e-01   1.41481355e-01  -7.84378648e-01
    -9.72286105e-01   7.61746585e-01   4.54697639e-01  -8.55591714e-01
    -7.99831808e-01  -7.33653009e-01   8.29139113e-01  -2.99945652e-01
     2.06261992e-01  -6.69295907e-01  -8.64501595e-01  -9.42102492e-01
    -7.79742777e-01  -1.02559470e-01   9.42755103e-01   8.29820987e-03
     7.85079822e-02   6.71308577e-01  -8.51067424e-01   6.68114781e-01
     9.39756870e-01   8.33571017e-01   9.95119095e-01  -9.65430319e-01
    -6.99080288e-01  -9.65137720e-01  -7.17248797e-01  -2.85281092e-01
    -6.31705821e-01   8.58209789e-01   4.05642837e-01  -6.46483600e-01
     8.15792441e-01  -7.87314951e-01  -6.55496657e-01  -5.67817152e-01
     6.72125816e-01  -2.19090372e-01  -3.99467468e-01  -9.65278566e-01
    -6.45647347e-01   8.57771873e-01  -9.08375204e-01   6.99901357e-02
     5.69484413e-01   3.06590438e-01  -3.98051113e-01   9.84090567e-01
     5.29063702e-01   9.36944246e-01  -9.99919772e-01  -5.24241805e-01
     8.31326485e-01  -4.97632712e-01   6.46390736e-01  -6.91886723e-01
    -9.44585681e-01   8.72068882e-01  -9.48714077e-01  -7.55069479e-02
    -9.54762518e-01  -8.56883645e-01   4.86493148e-02   8.09632719e-01]]]
After layer encoder_birnn_forward_l0_t9_i2h_output (1, 1024) <class 'numpy.float32'> [[ 0.07376467 -0.04585483  0.06153381 ...,  0.03591035  0.03396329
   0.02903319]]
After layer encoder_birnn_forward_l0_t9_h2h_output (1, 1024) <class 'numpy.float32'> [[ 1.45919549  1.24548519  0.97081923 ...,  2.59524536  1.50305283
   2.17697167]]
After layer _plus1035_0 (1, 1024) <class 'numpy.float32'> [[ 1.53296018  1.19963038  1.03235304 ...,  2.63115573  1.53701615
   2.20600486]]
After layer encoder_birnn_forward_l0_t9_slice_output0 (1, 256) <class 'numpy.float32'> [[ 1.53296018  1.19963038  1.03235304  0.92877579  1.94057333  1.56830919
   3.18988776  0.46299231 -1.46174729  1.11504936  1.17721224  1.80360997
  -0.05565843  2.29530358 -0.93954241  0.38076165  0.45749959  1.3964684
   2.01443791  0.80512834  0.16915268 -2.00163651  1.04347456  0.79759645
   0.50189376  0.72760361  1.95556843 -0.03391264  1.62155378  1.99276209
   1.62540436  1.04135311  2.48626971  1.31046391  4.49763823  0.4352445
   0.58856404  4.02077389  3.1476326  -1.99188697 -0.68380475  1.25999701
   3.0006392  -0.05932418  3.96389866  1.14859331  0.80967015  1.493891
   0.65006602 -0.47861025 -0.51414424 -0.63045269  7.45451641  0.70054734
   2.95664072 -0.23689362  2.81093264  0.2977643   1.11719561 -2.03087735
   0.58989549  0.53307241 -0.24062739  2.98368025  0.35568428  0.22948916
   1.94390833  3.33952045  1.42610848  2.69447303 -0.5974142  -1.98770976
   4.02705812  1.35330427  0.95713174  4.24243546  1.81137979  5.94536924
   1.57707274 -1.62630987  2.70324302  1.18983972  1.75445366 -0.1003757
   2.62383747  1.76646459  0.9841947   3.71870685  2.81984878 -0.36725223
   1.49492133 -0.48143986 -0.45807078  1.4837625  -1.51497781 -2.09691906
   2.48148298  3.37681413  2.21021986  1.29183757  0.95989823 -0.94107306
   0.99180251  3.18592429  1.61175787  0.86665583  0.08601336  0.5295561
  -0.13065284  0.23003326  2.97216535  2.51299596  5.20824575  6.06921721
   1.84474468  2.14511061  1.01162875  2.50991535  0.49956596 -0.51323038
  -0.38843596  2.65434003  4.48892593  1.1518538   4.19427729  0.6457181
   1.0573101   1.38303959  0.69697696  4.2432785  -0.66740751  2.13211942
   1.22304213  0.40605563  2.63368368  1.99600697  1.6693579  -1.71926081
   1.87817514  0.01779356  0.47137526  2.93175983  1.87223279  0.05686389
   1.48484957 -1.54631364  0.30060229 -0.49905807  2.32254052 -0.44305137
   3.83168244  2.27459455  4.01519442  3.01412296  0.39911109  2.68003726
   1.61937487 -0.34286433  2.17048049  1.9206146   4.38585234 -0.21919122
   2.07702327  2.3286922   1.95183158 -0.09095336  0.45102894  1.55732751
  -0.45357323  0.90740275 -1.04941809  8.86477852  0.91197884  3.00200868
   1.60765052  0.41076362 -0.54442865 -1.02310538  0.15877888  1.03194606
   3.08540225  0.94498879  1.40320194  0.89762473 -0.35650814  1.38700414
   0.40046951  2.78867388  1.85581517  1.49270988 -1.21526325  0.69445771
   2.89197111  1.12566042  0.78385019  2.55251479  7.15201426  2.99480796
   1.69821024  0.22494593  0.84775168  2.31811237  1.34737062  1.36541092
   1.51946986  0.09849051  2.02668238 -1.0087117  -1.10773432  1.03693187
   1.79628932  1.19882035  2.94098473  1.31010604  4.70575905  2.54742599
   0.98076415  3.45296621  1.13967347 -1.52138031  0.74712622  0.80309236
   1.45358372  1.9482373   1.67198157  6.84082079  1.4512074  -0.23406385
  -0.0204074  -0.01283044 -1.03872085  5.68990326  0.84975839  3.1744504
   2.12797594 -0.01769265  0.8872717  -0.54543459 -0.04748447  3.55581546
   0.64878154  1.82065308  9.83213234  1.41364431  2.35805535  1.677423
   0.90365696  0.60097939  2.08311582  0.78576165  3.67504025 -1.39414823
   2.37572932  1.0217036  -0.48652071  1.01479352]]
After layer encoder_birnn_forward_l0_t9_slice_output1 (1, 256) <class 'numpy.float32'> [[ 2.94285369  0.38205528  0.71493423  1.17239833  1.0091244   1.16422129
   3.28823566  1.1564486   4.09049416  1.16331112  3.06828094  1.20172668
   1.87865806  2.11477566 -0.62149155  0.92411691  1.0752207   1.09014094
   2.47778034  1.80270851  0.45854324 -0.84064341  2.82136416  0.71897203
   1.46969724  1.73084259  2.03105998  1.13369918  2.05214167  0.84238458
   2.53949118  1.97872627  1.43239832  1.18810785  3.61651397  1.01199424
   0.60831761  1.3110342   3.31140661 -0.25639024  1.90512753  1.14592624
   3.10587883 -0.58561486  0.36938265 -0.7081849   3.3507514   1.37380469
   0.73380172 -0.42472523 -0.73513836  1.51696861  6.18549109 -0.99450976
   2.60701942 -1.09974658  0.81216276  1.54566419  1.4269464   2.35369611
  -0.03762821  1.15846694  0.82470775  2.30500221  0.66648793  1.40205669
   2.09379888  2.17161703  0.98446703  3.11254787 -0.0373466   2.13829422
   3.64580154  1.54815042  0.46896243  5.69250536  1.13051403  5.49126673
   2.07090807 -1.26351905  2.95897889 -1.02112091  4.72727776  2.1882627
   2.47412586  1.80712819  0.24603863  3.13162279  5.98124361  1.15957987
   0.48783511  1.54487884 -0.32455909  1.56826997 -0.73990911 -0.15738335
   2.91168594  2.60250545  2.38181543  2.56845045  0.49026129 -0.43715641
   0.09159338  2.52275205  2.41933179  0.92814803  1.28491998  1.81958127
   1.74475157  1.28564978  2.47617316  3.36924434  4.11671257  4.43558502
   2.28618717  1.17096925  2.04067159  3.00631452  1.1421349   1.20367789
   1.4426558   3.21196461  1.76822555  1.19395494  2.37863517  1.64856446
  -1.46977425  1.34243298  1.26360738  4.54954338  1.21988535  2.25675106
   0.78870195  1.13225889  1.11298954  1.8587079   2.6421783  -1.12694621
   3.36419845  2.08840275  1.46615791  1.6852169   2.05600405  2.00252986
   2.21451354  2.43843079  0.90319782  1.79562771  2.71485972  1.56613731
   2.2444222   0.50945282  1.66182303  1.817433    1.20943654  0.99876183
   2.78046441  1.26947224  3.07554793  1.66180217  3.30762196  1.84451222
   2.42640495  1.79738855  2.37625289  0.80935508  1.05431461  1.36805952
  -0.70248812  0.60562462 -0.828731    4.32597113  1.21641767  3.47629142
   0.3032476   0.89455736  1.41543174  2.39092183 -0.22462647  3.06822944
   1.42068267 -0.44146043  2.34480166  1.78828263  1.53241122  1.45567751
   2.28362417  1.73850989  1.7516104   1.93131661 -1.06422293  1.27508259
   2.94834638  1.75430369  0.11646638  0.96329367  9.2924099  -0.24711955
   1.60759223 -0.47993132  0.82424784  1.81423378  1.13510215  3.15059233
   1.63100314  1.03163528  2.48432231 -1.08868909 -0.63120365  2.30801392
   2.24786115  1.46009254  2.02200127  1.64985931  4.5309844   3.05633521
   0.75589412  2.60621929  0.18219836 -0.41398317  0.71602315  1.9107765
   0.14935821  2.19109011  1.58784771  3.78559232 -1.38063109  1.18648779
   1.49371517  1.05427325  1.1145786   4.3444252   0.785712    1.52318048
   2.73616958  1.4280417   0.82496983  0.48109722  0.92405164  3.8336916
   0.58962923  2.60918617  9.41482353 -0.54179364  1.72526813 -0.43038636
   0.72402793  1.31446195  1.83264208  1.74080706  3.29649973 -0.30754662
   3.03021932  1.32019174  1.37390959  1.81050181]]
After layer encoder_birnn_forward_l0_t9_slice_output2 (1, 256) <class 'numpy.float32'> [[ 0.83447367  0.93829882 -3.26009774 -1.41154122  3.74912691 -0.22527404
   3.2210989  -0.53016365 -0.5644201  -0.51996291  2.24529505  2.17078161
   0.53854752 -2.87110019  0.56000155 -0.13711777  1.55724311  2.55375886
  -1.17157507  1.52643919 -0.49742922 -5.42404842 -4.2601881   1.6221602
  -0.72840738 -0.6939168  -3.98034382 -0.32652673 -3.37273669  1.9498384
   1.80883789 -1.11956728  3.26541662 -0.86130506  5.66906214  1.64791799
   1.17477    -5.27412367 -3.93991494 -0.10812205 -0.33551288  4.17984962
  -1.23699629  3.14451957 -6.21894789 -1.24891078  0.44110584  1.73733556
   1.940992    1.27043402  0.31452972  0.26239473 -1.65687847 -1.76384604
   4.12255383  2.54340005 -4.80019331 -0.47831541  2.34131694 -0.12969546
   3.15227056 -0.43436337  0.60307342  7.85645819 -2.67617273  0.35100853
   2.11275244  3.86742282  0.94311827 -3.25382972  1.25926363 -0.35913327
  -5.06627369  1.39771724  2.14610076  3.69592762  3.820472   -6.92552996
   2.34155583 -4.67370605  5.02046537 -2.1846621   0.3120321   0.90678036
  -1.79297364 -3.32338405  0.55881363 -4.73845911  0.73984873  0.066681
   2.18946457  1.42835975 -3.89156556 -1.22116196 -5.44401121 -0.85197169
  -1.99853432 -5.12977457  2.22668648  0.78718042 -2.73963404 -0.14773291
  -0.60537952  2.33611155 -1.86292672 -3.66975403  1.54513836  1.81768978
   1.44268453  2.14254808 -4.44472599 -3.06925201  6.07091761  6.01982307
  -0.88052607  3.83141971  2.28934693  1.08973289  0.94091332  0.68981588
   0.5027231  -2.86350679  3.61128879 -1.4367733   6.59114552 -1.12377
   4.70233059  2.40976262 -3.88499904 -5.13438272  0.74597335  2.21228528
   1.18813121 -0.70577615  3.87400675  4.39194679  1.59008348  3.14407563
  -5.12529039 -0.95356441 -0.47155854  4.89672709 -4.36015797 -0.72040844
   3.73738623  0.32338402  3.00008821 -0.15157071  5.22687721 -0.64488947
   5.28800154 -2.70804834  5.67307568  3.00682354  1.07554984 -4.52494669
   4.81609392 -0.4119952   2.91373324  2.7661674   7.26719856  0.34665644
   1.51467001  3.53339791 -0.92227709  0.61445218 -0.53911179  3.41143727
  -2.31004286 -2.21776533  0.61403877  7.33223248 -1.72326696  5.93110847
  -2.99649572 -4.9474144   0.84067309  0.39920729 -1.93987405 -0.63815093
   4.75525141  3.26130795  1.70482612  2.22797918 -0.31390828 -2.58719659
  -1.34427106  4.6449194   2.17595029 -1.82720792  4.31635809 -2.62926865
  -3.36130452  3.94319034  1.07626152 -4.56289339  0.35158178 -3.87020016
   2.89125013 -0.37138504  0.51512039 -3.24723577 -5.2115407  -2.00040627
  -1.17188525  0.28022033  3.85713363  0.05690083  0.89275527  1.07774973
  -1.14464509  2.14852357  1.82073092  1.1934799   5.77062273 -3.70752025
  -1.94345343 -4.75536156 -1.22460771 -1.81194997 -1.25303352  1.7448709
   3.94542813 -5.3468585   1.21780145 -6.96440172 -3.77400565 -0.89415717
   1.24055111 -0.4435882  -1.55916739 -5.36984396 -0.96686417  4.64187098
  -2.04283595  0.26278597  3.61253047  2.21420026 -0.68638808  6.84402609
   3.29613948  3.26956415 -6.92446232 -4.12594175  3.89440393 -2.69082165
   0.85012251 -0.92804313 -2.66613626  2.11150479 -4.55664921 -0.26347864
  -2.31612015 -1.54474485  0.37987268  1.69830668]]
After layer encoder_birnn_forward_l0_t9_slice_output3 (1, 256) <class 'numpy.float32'> [[  3.1001327    1.7166028    1.74097753   2.30160832   1.81749153
    2.50089264   4.63053894   1.75380564   2.16121697   1.69390488
    2.2646625    1.99839091   1.87475502   3.01975274  -0.30799484
    0.60825032   1.97600758   1.30557573   4.47642326   2.38050866
    1.5608356   -0.55932075   3.4677186    2.71325135   1.36818409
    1.60298622   3.40249538   2.18593574   0.2395959    1.7029047
    3.0922792    2.41812444   0.28581852   1.52154422   1.64053154
    1.2909683    2.31821179   0.91130018  -1.5052017    1.13777411
    1.265921     1.59828413   1.70944953   1.57731533   1.75238061
    1.85340023   4.21966267   2.44890332   1.60269558   0.51142967
   -0.84640765   2.38706112   7.59710026  -0.4105114    2.22613716
   -0.64816457   1.36234093   1.85160625   2.36421466   1.60035002
    0.20090389   0.92706025   0.34103033   3.28601551   1.22994971
    1.8635993    2.80859804   1.37953651   2.04551339   1.15202439
    2.19768906   2.33366537   4.04644346   2.012568     1.48644459
    6.63551378   2.01288295   6.22761106   2.89495325   0.22678642
    3.58770704  -0.43059969   7.68731213   1.69185305   2.86564088
    1.28060353   1.25477469   2.17253828   4.88537169   2.70653105
    1.49032187   2.11168432  -1.14284742   3.02995133   0.41308701
    2.10944676   2.44705081   2.61414695   2.27270174   3.85064244
    0.6972717    1.35617292   0.87654692   3.7069931    2.5666821
    0.69584906   2.11427331   2.50546956   2.96334767   0.655038
    3.30753803   2.09691191   4.89404106   4.23980618   2.68026853
    2.01020718   2.17978334   4.21098518   2.09287429   2.30689597
    1.49412775   4.15035343   2.56372643   1.61851418   2.54935122
    2.7286768   -0.09220024   0.79344851   1.73380399   5.77056932
    2.27014637   3.73799419   1.58145392   1.94437528   1.02896011
    1.2686758    2.83651853   1.12109566   2.9794836    2.49036574
    1.39258218   2.1449821    1.92694724   2.49763727   1.35259593
    2.88649559   1.63457143   1.8883388    0.35359985   1.03458798
    4.74278736   1.13140452   2.05293822   0.25380623   1.33780205
   -0.06228734   1.19864893   2.11792111   4.2459178    2.23449588
    1.54813123   2.44408703   0.34219116   2.88489103   3.70830011
    0.69156682   2.272645     0.6129536   -0.6797145    1.00871766
    1.00998449   7.97736359   2.11361599   3.54552269   0.45192236
    0.91526151   2.20994568   2.51026487   1.10988951   3.2366693
    1.7274158   -0.17011823   2.44881964   2.41475844   1.11278725
    2.18211055   1.99601543   1.09960365   2.4197588    2.77734518
   -0.44162709   1.90023696   3.97230363   1.34899044   0.76135659
    2.11195421   8.48003769   1.51228571   1.79327679   2.14743733
    0.94639641   0.85764354   2.36592054   3.23861361   2.42699838
    2.51587296   3.21420574   0.09651981  -1.23268306   2.13658047
    2.58277893   0.95745003   3.39895725   2.65222859   5.87358713
    3.73630381   1.51275885   3.77071691   2.52754545   1.02605712
    1.49603677   2.49018812  -0.19982845   0.6715889    2.65009832
    1.42048979   1.79506552   2.09057999   2.22814536   1.44864666
    1.29815984   3.74857926   2.32302737   2.01062775   2.7148273
    1.65440011   0.54159069   0.01927073   1.86941326   4.58339405
    0.52870524   3.06724906  10.67175198   0.6073522    1.86929834
    0.33635899   2.09106064   2.33257461   3.44250011   2.49750519
    3.14551687   1.08122039   3.51868582   2.63115573   1.53701615
    2.20600486]]
After layer encoder_birnn_forward_l0_t9_o_output (1, 256) <class 'numpy.float32'> [[ 0.95689821  0.8476907   0.85081118  0.90901011  0.8602649   0.92420441
   0.99034458  0.85243219  0.8967123   0.84473693  0.90590787  0.88062799
   0.86700749  0.95345849  0.42360425  0.64754158  0.87825495  0.78677183
   0.98875391  0.91532886  0.82647324  0.36370462  0.96975517  0.9378041
   0.7970866   0.83243531  0.96778238  0.89897943  0.55961406  0.84591371
   0.95657313  0.918199    0.57097208  0.82076579  0.83760726  0.78431106
   0.91037416  0.71326619  0.181651    0.75727069  0.78004372  0.83177847
   0.84676486  0.82882398  0.85225284  0.86452579  0.98550946  0.92048126
   0.83239478  0.62514156  0.30018699  0.91583526  0.99949837  0.3987895
   0.90257221  0.34340325  0.79613996  0.86431557  0.91405749  0.83206731
   0.55005771  0.71647853  0.58444077  0.96394587  0.77380979  0.86571592
   0.94313866  0.79891658  0.88549346  0.75988048  0.90004176  0.91162705
   0.98281604  0.8821103   0.81554407  0.99868888  0.88214308  0.99802977
   0.94759637  0.55645484  0.9730829   0.3939831   0.99954164  0.8444677
   0.94612157  0.78255248  0.77812535  0.89775622  0.99250036  0.93741089
   0.81612659  0.8920337   0.24179797  0.95390898  0.60182786  0.89181793
   0.92034554  0.93176651  0.90659082  0.9791767   0.66758263  0.79513699
   0.70610613  0.97603703  0.92868632  0.66726679  0.89228272  0.92452437
   0.95089054  0.65814489  0.96468651  0.89060271  0.99256456  0.98579431
   0.93585223  0.88186455  0.89841926  0.985385    0.89020866  0.9094466
   0.816697    0.98448563  0.92849028  0.83459014  0.92752987  0.93869781
   0.47696626  0.68857127  0.84989834  0.99689168  0.90637416  0.97675157
   0.82941031  0.87483203  0.73671424  0.78051597  0.94461763  0.75419188
   0.95163864  0.92346364  0.80100417  0.895199    0.87291116  0.923976
   0.7945537   0.94717479  0.83679491  0.86856604  0.58749026  0.73780441
   0.99136096  0.75609803  0.88624418  0.56311309  0.79212826  0.4844332
   0.76828438  0.89263284  0.9858796   0.90330476  0.82464367  0.92012799
   0.5847227   0.9470945   0.9760676   0.66631538  0.90658605  0.64861429
   0.33632502  0.73276919  0.73301709  0.99965703  0.89221954  0.97195566
   0.6110962   0.71407562  0.90113908  0.92485827  0.75210851  0.9621911
   0.84908152  0.4575727   0.92047507  0.9179458   0.75264841  0.89863145
   0.88037813  0.75018585  0.91832161  0.94143927  0.39135334  0.86991835
   0.98151797  0.79396451  0.68164819  0.89205968  0.99979252  0.81939971
   0.85732853  0.89542907  0.7203899   0.70216805  0.91419137  0.96226186
   0.91886306  0.92524713  0.9613654   0.52411127  0.2257122   0.89440811
   0.92974508  0.72261095  0.96767199  0.93414819  0.99719512  0.97671312
   0.81946969  0.97748315  0.92605048  0.73615074  0.81698269  0.92345113
   0.45020846  0.66185886  0.93401706  0.80541521  0.85754716  0.88998425
   0.9027487   0.80979007  0.78552514  0.9769907   0.91076624  0.88190842
   0.93789595  0.83948487  0.63218242  0.50481755  0.86639035  0.98988324
   0.62918103  0.95552135  0.99997675  0.64733654  0.86637712  0.58330578
   0.89003128  0.9115392   0.96900672  0.92396671  0.95873171  0.7467249
   0.97121471  0.93283993  0.82303053  0.90078741]]
After layer encoder_birnn_forward_l0_t9_f_output (1, 256) <class 'numpy.float32'> [[ 0.94992465  0.5943687   0.67149055  0.76357824  0.73284882  0.76209891
   0.96402299  0.76068681  0.98354429  0.7619338   0.95556521  0.76883185
   0.86745685  0.89233106  0.34944227  0.71588016  0.74558848  0.74840826
   0.92256939  0.85847831  0.61266851  0.30139929  0.94381946  0.67238063
   0.81301135  0.84952015  0.88401979  0.75652093  0.88616389  0.69896722
   0.92686433  0.87854528  0.8072747   0.76640248  0.97382724  0.73341018
   0.64755696  0.78768617  0.96481812  0.43625128  0.8704707   0.75876606
   0.9571346   0.35764167  0.59130979  0.33000004  0.96612942  0.79799414
   0.67563897  0.39538658  0.32406816  0.82009166  0.99794513  0.27002224
   0.93131196  0.24978739  0.69257015  0.82428658  0.80642509  0.91322756
   0.49059406  0.76105404  0.69523478  0.90929043  0.66071635  0.80251008
   0.89029896  0.89767158  0.72799367  0.95740736  0.49066442  0.89456987
   0.97456342  0.82464647  0.61513811  0.99664021  0.75593376  0.99589431
   0.88804328  0.2203687   0.9506861   0.26480913  0.99122709  0.89919055
   0.92230791  0.85901451  0.56120121  0.95817846  0.99748069  0.76125634
   0.6195963   0.82417291  0.41956508  0.82753688  0.323024    0.46073517
   0.94842106  0.93102264  0.91543013  0.92880332  0.62016797  0.39241877
   0.52288234  0.92572153  0.91828966  0.71669936  0.78328609  0.86051583
   0.85128963  0.78340995  0.92245448  0.9667294   0.98396331  0.98829067
   0.90772659  0.76332021  0.8850016   0.95285863  0.75807136  0.76917839
   0.80886555  0.96128207  0.8542369   0.76744765  0.91518354  0.8386969
   0.18697694  0.79288977  0.77964652  0.98953855  0.77204341  0.9052313
   0.68755257  0.75625551  0.75268608  0.86514628  0.93352729  0.24472511
   0.96656668  0.88977093  0.81247264  0.84359413  0.88655293  0.88106245
   0.90154523  0.91971135  0.71160626  0.85761583  0.93789786  0.82723224
   0.90416831  0.62467819  0.84048259  0.8602578   0.77019924  0.73081505
   0.94161099  0.7806524   0.95587283  0.84047973  0.96468937  0.86348152
   0.91881877  0.85783076  0.91499847  0.69197202  0.7416026   0.79706645
   0.3312608   0.64694208  0.30391347  0.98695183  0.77143252  0.97000557
   0.57523626  0.70982981  0.80462128  0.91613245  0.44407836  0.95556307
   0.80544543  0.39139304  0.91252017  0.85671657  0.82235885  0.81087071
   0.90751171  0.85049772  0.8521558   0.87339509  0.25650325  0.78161156
   0.95018524  0.85249484  0.52908373  0.72378075  0.99990785  0.43853262
   0.83307683  0.38226834  0.69513726  0.85987282  0.75677931  0.95893204
   0.83630705  0.7372328   0.92303544  0.25186521  0.34723768  0.90953857
   0.90446585  0.8115468   0.88308775  0.83887202  0.98934466  0.95505518
   0.68046165  0.93126076  0.54542398  0.39795741  0.6717307   0.87110639
   0.53727031  0.89944655  0.83031309  0.97780824  0.20090765  0.76611233
   0.81663525  0.74159467  0.75298172  0.98718739  0.68690985  0.82100636
   0.9391275   0.80659598  0.69529033  0.61800694  0.71586692  0.97882837
   0.64328009  0.93145043  0.99991846  0.36777043  0.8488062   0.39403409
   0.67349339  0.78825885  0.86207616  0.85078955  0.96430856  0.42371371
   0.95392084  0.7892136   0.79801106  0.8594225 ]]
After layer _mul2070_0 (1, 256) <class 'numpy.float32'> [[  1.29846823e+00   6.17310524e-01  -1.04333508e+00  -9.66993749e-01
    1.54077446e+00  -2.95380741e-01   3.47666407e+00  -1.71276137e-01
   -7.73373544e-01  -3.75941515e-01   2.31044841e+00   1.58678913e+00
    5.43599486e-01  -2.44517231e+00   6.49467930e-02  -5.19425832e-02
    9.83693600e-01   1.39348352e+00  -1.14512718e+00   1.33105433e+00
   -2.48032391e-01  -7.65438899e-02  -2.65274239e+00   8.70797217e-01
   -6.05955899e-01  -6.29650712e-01  -2.38186646e+00  -1.46721706e-01
   -2.32821822e+00   1.22328794e+00   2.03452706e+00  -1.23850429e+00
    1.93409884e+00  -1.06544065e+00   4.01361513e+00   8.31539452e-01
    6.85939610e-01  -2.25139761e+00  -3.55377531e+00  -1.79968365e-02
   -1.94931477e-01   1.55628753e+00  -1.53162479e+00   2.95288354e-01
   -1.22411430e+00  -2.97975332e-01   9.21252519e-02   1.48128963e+00
    8.68744552e-01   1.92984492e-01   3.13294381e-02   9.53656361e-02
   -3.83041215e+00  -2.33348519e-01   3.14307261e+00   1.62754714e-01
   -1.51170802e+00  -4.72209692e-01   1.53434181e+00   1.09043149e-02
    5.83378851e-01  -3.10041666e-01   3.23495090e-01   3.02652717e+00
   -8.05422604e-01   2.49829844e-01   2.14754367e+00   2.87674665e+00
    9.26436901e-01  -3.31441236e+00   2.88968921e-01   6.94949506e-03
   -4.09284496e+00   1.29207468e+00   8.62047851e-01   4.54582500e+00
    1.58479583e+00  -5.10300493e+00   2.00692081e+00  -6.31344169e-02
    3.20586514e+00  -2.58197635e-01  -1.51252151e-01   6.59161568e-01
   -2.22592759e+00  -2.14811277e+00   3.46546710e-01  -3.72565174e+00
    1.29292500e+00  -9.50283781e-02   9.79185939e-01   7.78256595e-01
   -3.05026263e-01  -1.34864998e+00  -1.28597021e-01  -1.07678086e-01
   -2.77303410e+00  -3.21578670e+00   2.47423577e+00   1.11022270e+00
   -8.76196742e-01  -3.26911882e-02  -1.84546858e-01   2.75964236e+00
   -2.14067197e+00  -1.12275302e+00   9.66788948e-01   1.36398649e+00
    9.04882312e-01   1.06029868e+00  -2.96630454e+00  -3.23270369e+00
    4.48065233e+00   4.71320391e+00  -1.09695911e+00   1.78236794e+00
    1.78764522e+00   1.51713204e+00   8.65576386e-01   2.84710824e-01
    3.41684610e-01  -3.22829723e+00   2.58923674e+00  -1.15674031e+00
    3.42455077e+00  -9.20665860e-01   1.76136985e-01   1.46448886e+00
   -1.41474342e+00  -4.46080828e+00   3.87594730e-01   2.37363935e+00
    8.14588606e-01  -5.96510530e-01   1.73730028e+00   2.34185266e+00
    1.93257344e+00   6.77321330e-02  -3.33120298e+00  -1.02809632e+00
   -2.35988081e-01   2.42224741e+00  -2.42485881e+00  -5.75621784e-01
    2.30210376e+00   8.70580152e-02   9.40646648e-01  -6.77360746e-04
    3.14493537e+00  -4.25358266e-01   3.12720776e+00  -1.14984524e+00
    2.54261971e+00   2.36816096e+00   7.75741637e-01  -1.66990983e+00
    2.86820459e+00  -1.55202329e-01   3.02162361e+00   2.02484870e+00
    3.99356675e+00   1.75057799e-01   1.85358512e+00   2.33899426e+00
   -1.17453170e+00   3.57582420e-01  -3.01016450e-01   1.68809342e+00
   -2.03648940e-01  -9.24230516e-01   6.67806342e-02   5.06913233e+00
   -1.12913537e+00   3.77784419e+00  -9.06246901e-01  -1.05723131e+00
    4.41656709e-01   3.01277697e-01  -3.63377631e-01  -9.83766973e-01
    2.09175539e+00   4.42422628e-01   1.87927592e+00   1.60628736e+00
   -1.37225643e-01  -1.73663867e+00  -1.38227642e+00   2.39237857e+00
    1.82387340e+00  -1.87480819e+00   9.33101103e-02  -1.30742681e+00
   -3.29789376e+00   1.89804506e+00   4.47795540e-01  -1.66742480e+00
   -1.09912753e+00  -7.01382101e-01   1.93656349e+00  -1.36825383e-01
    2.12860912e-01  -2.25856161e+00  -1.57688963e+00  -2.57293558e+00
   -1.10168767e+00  -8.36766884e-02   2.80212760e+00   4.01283009e-03
    1.12987101e-01   9.48170125e-01  -1.56796634e+00   1.41036618e+00
    2.13285518e+00   1.27545762e+00   4.60257673e+00  -3.29755688e+00
   -9.90097582e-01  -3.15038300e+00  -5.85809350e-01  -1.63598642e-01
   -7.35449433e-01   1.60854828e+00   7.63327301e-01  -2.52557659e+00
    1.20152557e+00  -4.42101049e+00  -2.06889227e-01  -6.06265008e-01
    8.30158889e-01  -2.14475036e-01  -4.45649743e-01  -4.56506062e+00
   -6.30684912e-01   2.33084536e+00  -2.38658142e+00   6.99296817e-02
    1.16036510e+00   4.67642188e-01  -3.68798256e-01   4.14044476e+00
    9.21150029e-01   2.77250051e+00  -5.68330956e+00  -4.48896438e-01
    2.19046998e+00  -5.00620425e-01   6.51409924e-01  -8.21842015e-01
   -2.15801215e+00   1.64122999e+00  -3.84687972e+00  -4.41443622e-02
   -2.72000241e+00  -1.35408962e+00   4.92125675e-02   1.38840497e+00]]
After layer encoder_birnn_forward_l0_t9_i_output (1, 256) <class 'numpy.float32'> [[ 0.82243901  0.76845902  0.7373718   0.71682686  0.87441516  0.82754242
   0.96045202  0.61372381  0.18820022  0.75306928  0.7644462   0.8585878
   0.48608893  0.90848738  0.28099278  0.59405679  0.61242086  0.80162287
   0.88230467  0.69107044  0.54218763  0.11903122  0.73951989  0.6894601
   0.62290424  0.67427915  0.87605256  0.49152267  0.83500934  0.88003498
   0.8355391   0.73911107  0.92317373  0.78759074  0.98898739  0.60712534
   0.64303559  0.98237705  0.95881534  0.12005738  0.33541265  0.77902555
   0.95260304  0.48517331  0.98136491  0.75925386  0.69203919  0.8166616
   0.65702534  0.38258034  0.37422252  0.34740788  0.99942148  0.66830909
   0.95057642  0.44105199  0.94326377  0.57389593  0.75346816  0.11599892
   0.64334118  0.63019937  0.44013172  0.9518314   0.58799529  0.55712181
   0.87478089  0.96576005  0.80629426  0.93669975  0.3549355   0.12049937
   0.98248553  0.79466933  0.72254717  0.98583108  0.85952848  0.9973889
   0.82878953  0.1643365   0.93721777  0.76671237  0.85251361  0.4749271
   0.93238002  0.8540175   0.72793972  0.97630954  0.94373912  0.40920514
   0.81681573  0.3819122   0.3874436   0.81514025  0.18020225  0.10939663
   0.9228335   0.96697199  0.90116358  0.78445798  0.72310144  0.28068364
   0.72944379  0.96030116  0.8336553   0.70404935  0.5214901   0.62937963
   0.46738318  0.55725604  0.95130074  0.92504787  0.99455851  0.99769235
   0.86350888  0.89521104  0.73333877  0.92483401  0.62235731  0.37443653
   0.40409383  0.93427795  0.98889202  0.75984937  0.98514241  0.6560449
   0.74217618  0.79947871  0.66751719  0.98584288  0.33907759  0.89398605
   0.77259845  0.6001417   0.93299818  0.88037717  0.84149021  0.15196641
   0.86740142  0.50444829  0.61570919  0.94939435  0.86671638  0.51421213
   0.81530398  0.17561933  0.57458973  0.37776205  0.91072673  0.39101416
   0.97878665  0.90675098  0.98228019  0.95320815  0.59847409  0.93583834
   0.83470887  0.41511387  0.89756715  0.87220693  0.98770088  0.44542056
   0.88864982  0.91122562  0.87564623  0.47727731  0.61088383  0.82596958
   0.38851154  0.71246839  0.25933686  0.99985874  0.71340489  0.95266479
   0.83308494  0.60127097  0.36715797  0.26442295  0.53961158  0.737293
   0.95628655  0.7201063   0.80269152  0.71046114  0.41180509  0.80011356
   0.59880048  0.94206071  0.86480844  0.81648469  0.22877111  0.6669578
   0.94744813  0.75503719  0.68650937  0.9277423   0.99921727  0.95233905
   0.84530079  0.55600053  0.7000953   0.91036606  0.79369944  0.79663771
   0.82046044  0.52460277  0.88357025  0.26723206  0.24829353  0.73825753
   0.85769665  0.7683149   0.94983572  0.7875309   0.99103796  0.92740035
   0.72725987  0.96931946  0.75761974  0.17925835  0.67855215  0.69063556
   0.81054938  0.87525433  0.84183979  0.99893194  0.81018418  0.44174972
   0.49489835  0.49679241  0.26139688  0.99663144  0.70051646  0.9598614
   0.89359272  0.49557695  0.70832682  0.36692426  0.48813114  0.97223479
   0.65673584  0.86064446  0.99994636  0.80434012  0.91357237  0.84256303
   0.71170044  0.64588034  0.88925129  0.68692058  0.97527826  0.19874632
   0.91495776  0.7353043   0.38071355  0.73395717]]
After layer encoder_birnn_forward_l0_t9_c_output (1, 256) <class 'numpy.float32'> [[ 0.68287086  0.73443967 -0.99705756 -0.88782096  0.99889249 -0.22153908
   0.99681926 -0.48550615 -0.5112496  -0.47767136  0.97782069  0.97430217
   0.49188769 -0.99360514  0.50797862 -0.13626486  0.91497266  0.98797065
  -0.82477647  0.90981328 -0.46009296 -0.99996114 -0.99960136  0.92493695
  -0.62209004 -0.60049236 -0.99930245 -0.31539643 -0.99765038  0.96030682
   0.94771361 -0.80741835  0.99708867 -0.69692945  0.99997616  0.92857134
   0.82579529 -0.99994755 -0.99924368 -0.10770269 -0.32346559  0.99953187
  -0.84459674  0.99629378 -0.99999207 -0.84797794  0.41456068  0.93991685
   0.95961261  0.85391521  0.30455232  0.25653404 -0.9297955  -0.942931
   0.99947506  0.98772037 -0.99986458 -0.44489348  0.98166049 -0.12897313
   0.99635071 -0.40896139  0.53923297  0.9999997  -0.9905706   0.33726966
   0.97118533  0.99912572  0.73665166 -0.99702048  0.85086095 -0.34445035
  -0.99992049  0.88485724  0.97301936  0.99876827  0.99903971 -0.99999809
   0.98166919 -0.99982566  0.99991286 -0.97499692  0.30228463  0.71958333
  -0.94607353 -0.99740696  0.50709665 -0.99984682  0.62905377  0.06658234
   0.97523302  0.89133    -0.99916697 -0.83999658 -0.99996263 -0.69209808
  -0.96392387 -0.99992996  0.97698933  0.65680873 -0.99168992 -0.14666747
  -0.54086649  0.98147035 -0.95294851 -0.99870211  0.91297978  0.94860756
   0.8942368   0.97282958 -0.99972439 -0.99569297  0.99998933  0.9999882
  -0.70668274  0.99906051  0.97967213  0.79678059  0.7356416   0.59786367
   0.46425602 -0.99350756  0.99854124 -0.89304632  0.99999624 -0.80887628
   0.99983531  0.98398799 -0.99915594 -0.99993062  0.63274056  0.97632492
   0.82999837 -0.60802132  0.99913716  0.99969369  0.92016214  0.9962905
  -0.99992931 -0.74139249 -0.43945774  0.99988836 -0.9996736  -0.61716223
   0.9988662   0.31256354  0.99505562 -0.15042056  0.9999423  -0.56821954
   0.99994898 -0.99115044  0.9999764   0.9951216   0.79154301 -0.99976522
   0.99986887 -0.39016548  0.99412626  0.9921177   0.99999905  0.33340696
   0.90776432  0.99829555 -0.72697282  0.54725349 -0.49231532  0.99782521
  -0.9804883  -0.97657996  0.54696381  0.99999917 -0.93825519  0.99998587
  -0.99502003 -0.99989915  0.68616545  0.37927049 -0.95952404 -0.56363928
   0.99985188  0.99706465  0.93600965  0.9770481  -0.3039884  -0.98874438
  -0.87269425  0.99981529  0.97456306 -0.94955218  0.99964368 -0.98964804
  -0.99759609  0.99924862  0.79180861 -0.99978238  0.33777758 -0.99913061
   0.99385691 -0.35520259  0.47392514 -0.99698102 -0.99994051 -0.96405625
  -0.82487559  0.27310899  0.9991076   0.0568395   0.71275192  0.79236311
  -0.81597233  0.97314805  0.94891125  0.83165503  0.99998057 -0.99879646
  -0.95980692 -0.99985188 -0.84100813 -0.94802964 -0.84913206  0.94078898
   0.99925196 -0.99995464  0.83900446 -0.99999821 -0.99894625 -0.71344101
   0.8456127  -0.41661429 -0.91528547 -0.99995667 -0.74732304  0.99981415
  -0.96693224  0.25689948  0.99854487  0.97641432 -0.59565663  0.99999774
   0.99726194  0.99711269 -0.99999809 -0.99947858  0.99917167 -0.99084163
   0.6911335  -0.72968024 -0.99038035  0.97111434 -0.99977964 -0.25754634
  -0.98072177 -0.91291422  0.3625969   0.93519706]]
After layer _mul2071_0 (1, 256) <class 'numpy.float32'> [[ 0.56161964  0.56438679 -0.73520213 -0.63641393  0.8734467  -0.18333299
   0.95739704 -0.29796669 -0.09621729 -0.35971963  0.7474913   0.83652395
   0.23910116 -0.90267771  0.14273833 -0.08094907  0.56034833  0.79197985
  -0.72770411  0.62874508 -0.24945672 -0.11902659 -0.73922509  0.63770711
  -0.38750252 -0.40489948 -0.87544149 -0.1550245  -0.83304739  0.84510362
   0.79185176 -0.59677184  0.92048609 -0.54889518  0.98896378  0.56375921
   0.53101575 -0.98232555 -0.95809019 -0.0129305  -0.10849445  0.77866089
  -0.80456543  0.48337516 -0.9813571  -0.64383054  0.28689224  0.76759398
   0.63048983  0.32669118  0.11397033  0.08912195 -0.92925757 -0.63016933
   0.95007741  0.43563604 -0.94313604 -0.25532255  0.73964989 -0.01496074
   0.64099342 -0.25772721  0.23733354  0.9518311  -0.58245087  0.18790029
   0.84957439  0.96491569  0.59395802 -0.93390882  0.30200076 -0.04150605
  -0.98240739  0.70316893  0.7030524   0.98461682  0.85870308 -0.99738699
   0.81359714 -0.16430785  0.93713611 -0.7475422   0.25770175  0.34174964
  -0.88210005 -0.851803    0.3691358  -0.97615999  0.59366268  0.02724584
   0.79658568  0.34040982 -0.38712084 -0.68471503 -0.18019551 -0.07571319
  -0.88954127 -0.96690428  0.88042718  0.51523888 -0.71709239 -0.04116716
  -0.3945317   0.94250709 -0.79443055 -0.70313555  0.47610992  0.59703428
   0.41795123  0.54211515 -0.95103854 -0.92106366  0.9945479   0.99768054
  -0.61022681  0.89437002  0.71843153  0.73688978  0.45783192  0.22386199
   0.187603   -0.92821223  0.98744947 -0.6785807   0.98513871 -0.53065914
   0.74205393  0.78667742 -0.66695374 -0.98577446  0.21454814  0.87282085
   0.64125544 -0.36489895  0.93219316  0.88010752  0.77430743  0.15140268
  -0.86734009 -0.37399417 -0.27057818  0.94928837 -0.8664335  -0.31735229
   0.81437957  0.0548922   0.57174873 -0.05682318  0.91067415 -0.22218189
   0.9787367  -0.89872664  0.98225701  0.94855803  0.47371799 -0.93561864
   0.83459944 -0.16196311  0.89229506  0.86533195  0.98769993  0.14850631
   0.80668461  0.9096725  -0.63657099  0.26119167 -0.30074748  0.82417327
  -0.38093102 -0.69578236  0.14184788  0.9998579  -0.66935587  0.95265132
  -0.82893622 -0.60121036  0.2519311   0.10028782 -0.51777029 -0.41556731
   0.95614493  0.71799254  0.75132698  0.69415468 -0.12518397 -0.79110777
  -0.52256972  0.94188672  0.84281033 -0.77529484  0.2286896  -0.66005349
  -0.94517052  0.75446987  0.54358405 -0.92754042  0.33751321 -0.95151109
   0.84010804 -0.19749282  0.33179277 -0.90761769 -0.79365224 -0.76800358
  -0.67677778  0.14327373  0.88278174  0.01518934  0.17697169  0.58496803
  -0.69985676  0.74768412  0.90130979  0.65495402  0.99101871 -0.92628419
  -0.69802904 -0.96917588 -0.63716435 -0.16994223 -0.5761804   0.64974231
   0.80994308 -0.87521464  0.70630735 -0.99893016 -0.80933046 -0.31516236
   0.41849232 -0.20697081 -0.23925278 -0.99658823 -0.52351207  0.959683
  -0.86404359  0.12731346  0.70729613  0.35827011 -0.29075855  0.97223258
   0.65493768  0.85815954 -0.99994445 -0.80392075  0.91281563 -0.83484656
   0.49188003 -0.47128612 -0.88069701  0.66707844 -0.97506332 -0.05118639
  -0.89731902 -0.67126977  0.13804555  0.68639457]]
After layer encoder_birnn_forward_l0_t9_state_0 (1, 256) <class 'numpy.float32'> [[  1.86008787e+00   1.18169737e+00  -1.77853727e+00  -1.60340762e+00
    2.41422129e+00  -4.78713751e-01   4.43406105e+00  -4.69242811e-01
   -8.69590819e-01  -7.35661149e-01   3.05793977e+00   2.42331314e+00
    7.82700658e-01  -3.34785008e+00   2.07685113e-01  -1.32891655e-01
    1.54404187e+00   2.18546343e+00  -1.87283134e+00   1.95979941e+00
   -4.97489095e-01  -1.95570484e-01  -3.39196754e+00   1.50850439e+00
   -9.93458390e-01  -1.03455019e+00  -3.25730801e+00  -3.01746190e-01
   -3.16126561e+00   2.06839156e+00   2.82637882e+00  -1.83527613e+00
    2.85458493e+00  -1.61433578e+00   5.00257874e+00   1.39529872e+00
    1.21695542e+00  -3.23372316e+00  -4.51186562e+00  -3.09273377e-02
   -3.03425938e-01   2.33494854e+00  -2.33619022e+00   7.78663516e-01
   -2.20547152e+00  -9.41805840e-01   3.79017472e-01   2.24888372e+00
    1.49923444e+00   5.19675672e-01   1.45299762e-01   1.84487581e-01
   -4.75966978e+00  -8.63517880e-01   4.09315014e+00   5.98390758e-01
   -2.45484400e+00  -7.27532268e-01   2.27399158e+00  -4.05642856e-03
    1.22437227e+00  -5.67768872e-01   5.60828626e-01   3.97835827e+00
   -1.38787341e+00   4.37730134e-01   2.99711800e+00   3.84166241e+00
    1.52039492e+00  -4.24832106e+00   5.90969682e-01  -3.45565565e-02
   -5.07525253e+00   1.99524355e+00   1.56510019e+00   5.53044176e+00
    2.44349885e+00  -6.10039186e+00   2.82051802e+00  -2.27442265e-01
    4.14300108e+00  -1.00573981e+00   1.06449604e-01   1.00091124e+00
   -3.10802770e+00  -2.99991584e+00   7.15682507e-01  -4.70181179e+00
    1.88658762e+00  -6.77825361e-02   1.77577162e+00   1.11866641e+00
   -6.92147136e-01  -2.03336501e+00  -3.08792531e-01  -1.83391273e-01
   -3.66257524e+00  -4.18269110e+00   3.35466290e+00   1.62546158e+00
   -1.59328914e+00  -7.38583505e-02  -5.79078555e-01   3.70214939e+00
   -2.93510246e+00  -1.82588863e+00   1.44289887e+00   1.96102071e+00
    1.32283354e+00   1.60241389e+00  -3.91734314e+00  -4.15376759e+00
    5.47520018e+00   5.71088457e+00  -1.70718598e+00   2.67673802e+00
    2.50607681e+00   2.25402188e+00   1.32340837e+00   5.08572817e-01
    5.29287577e-01  -4.15650940e+00   3.57668614e+00  -1.83532095e+00
    4.40968943e+00  -1.45132494e+00   9.18190897e-01   2.25116634e+00
   -2.08169723e+00  -5.44658279e+00   6.02142870e-01   3.24646020e+00
    1.45584404e+00  -9.61409450e-01   2.66949344e+00   3.22196007e+00
    2.70688081e+00   2.19134808e-01  -4.19854307e+00  -1.40209055e+00
   -5.06566286e-01   3.37153578e+00  -3.29129219e+00  -8.92974079e-01
    3.11648321e+00   1.41950220e-01   1.51239538e+00  -5.75005412e-02
    4.05560970e+00  -6.47540152e-01   4.10594463e+00  -2.04857183e+00
    3.52487659e+00   3.31671906e+00   1.24945962e+00  -2.60552835e+00
    3.70280409e+00  -3.17165434e-01   3.91391873e+00   2.89018059e+00
    4.98126650e+00   3.23564112e-01   2.66026974e+00   3.24866676e+00
   -1.81110263e+00   6.18774056e-01  -6.01763964e-01   2.51226664e+00
   -5.84579945e-01  -1.62001288e+00   2.08628505e-01   6.06899023e+00
   -1.79849124e+00   4.73049545e+00  -1.73518312e+00  -1.65844166e+00
    6.93587780e-01   4.01565522e-01  -8.81147921e-01  -1.39933431e+00
    3.04790020e+00   1.16041517e+00   2.63060284e+00   2.30044198e+00
   -2.62409627e-01  -2.52774644e+00  -1.90484619e+00   3.33426523e+00
    2.66668367e+00  -2.65010309e+00   3.21999699e-01  -1.96748030e+00
   -4.24306440e+00   2.65251493e+00   9.91379619e-01  -2.59496522e+00
   -7.61614323e-01  -1.65289319e+00   2.77667141e+00  -3.34318221e-01
    5.44653654e-01  -3.16617918e+00  -2.37054181e+00  -3.34093904e+00
   -1.77846551e+00   5.95970377e-02   3.68490934e+00   1.92021653e-02
    2.89958775e-01   1.53313816e+00  -2.26782322e+00   2.15805030e+00
    3.03416491e+00   1.93041158e+00   5.59359550e+00  -4.22384119e+00
   -1.68812656e+00  -4.11955881e+00  -1.22297370e+00  -3.33540857e-01
   -1.31162977e+00   2.25829053e+00   1.57327032e+00  -3.40079117e+00
    1.90783286e+00  -5.41994047e+00  -1.01621974e+00  -9.21427369e-01
    1.24865127e+00  -4.21445847e-01  -6.84902549e-01  -5.56164885e+00
   -1.15419698e+00   3.29052830e+00  -3.25062513e+00   1.97243154e-01
    1.86766124e+00   8.25912297e-01  -6.59556806e-01   5.11267757e+00
    1.57608771e+00   3.63066006e+00  -6.68325424e+00  -1.25281715e+00
    3.10328555e+00  -1.33546698e+00   1.14328992e+00  -1.29312813e+00
   -3.03870916e+00   2.30830836e+00  -4.82194328e+00  -9.53307450e-02
   -3.61732149e+00  -2.02535939e+00   1.87258124e-01   2.07479954e+00]]
After layer activation1035_output (1, 256) <class 'numpy.float32'> [[ 0.95268697  0.82798606 -0.94453764 -0.92217988  0.98412901 -0.4452129
   0.99971843 -0.43758732 -0.70116615 -0.62651658  0.99559468  0.98441279
   0.65425408 -0.99753064  0.20474972 -0.13211484  0.91279703  0.9750365
  -0.95385009  0.96107453 -0.46014017 -0.19311467 -0.99773896  0.90667331
  -0.75883311 -0.77572685 -0.99704111 -0.2929098  -0.99641567  0.96855402
   0.99300885 -0.95033967  0.99339104 -0.9237982   0.9999097   0.88433123
   0.83875376 -0.99689847 -0.99975902 -0.03091748 -0.29444468  0.98142761
  -0.98147327  0.65193892 -0.97600394 -0.73605084  0.3618539   0.97797751
   0.90500981  0.47744963  0.14428581  0.18242264 -0.99985319 -0.69806576
   0.99944329  0.53590345 -0.98535842 -0.6215533   0.9790448  -0.00405641
   0.84093916 -0.5137189   0.50859201  0.99929965 -0.88270211  0.41176119
   0.99502623  0.99907953  0.90876645 -0.99959177  0.53059268 -0.03454281
  -0.99992192  0.96368998  0.9162429   0.99996859  0.98502487 -0.99998993
   0.99292672 -0.2235999   0.9994961  -0.76399422  0.10604934  0.7619766
  -0.99601376 -0.99505395  0.61422783 -0.99983519  0.95507437 -0.06767892
   0.94423854  0.80710459 -0.59935951 -0.96631056 -0.29933822 -0.1813626
  -0.99868333 -0.99953455  0.99756402  0.92541254 -0.92065209 -0.07372434
  -0.52199543  0.99878347 -0.99437129 -0.9494223   0.89427978  0.96116763
   0.86748683  0.9220311  -0.99920881 -0.99950683  0.99996489  0.99997807
  -0.93630135  0.99058121  0.98677492  0.97820026  0.86762905  0.46883246
   0.48483631 -0.99950951  0.99843681 -0.95034403  0.99970436 -0.89595455
   0.72504044  0.97807676 -0.96936715 -0.99996281  0.53857261  0.99697632
   0.89684242 -0.74490488  0.99044442  0.99682474  0.99112982  0.21569328
  -0.99954903 -0.88580269 -0.46726549  0.99764472 -0.9972353  -0.71285957
   0.99608046  0.14100443  0.90736324 -0.05743725  0.9993999  -0.57001168
   0.99945736 -0.96730328  0.99826628  0.99737221  0.84813201 -0.98914742
   0.99878508 -0.30694163  0.99920332  0.99384379  0.99990577  0.31272602
   0.99026734  0.99698961 -0.94794381  0.5502739  -0.53830355  0.98693657
  -0.52598625 -0.92462611  0.20565338  0.99998927 -0.94664955  0.99984437
  -0.9396655  -0.93000698  0.60028189  0.38128769 -0.70699394 -0.88520765
   0.99550551  0.8211751   0.98967546  0.9801138  -0.25654796 -0.98733228
  -0.95665044  0.99746269  0.99039084 -0.99006844  0.31131393 -0.96165657
  -0.99958748  0.990116    0.75795001 -0.98891699 -0.64202684 -0.92925358
   0.99228096 -0.32239553  0.49650252 -0.99645066 -0.98269272 -0.99749631
  -0.94452989  0.05952658  0.99874085  0.01919981  0.28209686  0.91096008
  -0.97878742  0.97364813  0.99538064  0.95876664  0.99997228 -0.99957132
  -0.93390816 -0.9994719  -0.8405292  -0.32169878 -0.8646872   0.97838354
   0.91754436 -0.99777842  0.95690304 -0.99996078 -0.76832229 -0.72657198
   0.84790498 -0.39814779 -0.59469736 -0.9999705  -0.81913966  0.99723107
  -0.99700141  0.19472444  0.9533816   0.67827499 -0.57806838  0.99992752
   0.91798872  0.99859661 -0.99999684 -0.84907174  0.99597585 -0.87057918
   0.81551892 -0.85994363 -0.9954223   0.98042119 -0.99987036 -0.095043
  -0.9985587  -0.96577615  0.18509963  0.96894825]]
After layer encoder_birnn_forward_l0_t9_out_0 (1, 256) <class 'numpy.float32'> [[ 0.91162443  0.7018761  -0.8036232  -0.83827084  0.84661162 -0.41146773
   0.99006575 -0.37301353 -0.6287443  -0.52924168  0.90191704  0.86690146
   0.56724322 -0.95110404  0.08673285 -0.08554985  0.80166852  0.76713127
  -0.94312298  0.87969923 -0.38029355 -0.0702367  -0.9675625   0.85028195
  -0.60485572 -0.64574242 -0.96491879 -0.26331988 -0.55760825  0.81931311
   0.94988561 -0.87260091  0.56719857 -0.75822198  0.83753163  0.69359076
   0.76357973 -0.71105397 -0.18160722 -0.0234129  -0.22967972  0.81633037
  -0.8310771   0.54034263 -0.83180213 -0.63633496  0.35661045  0.90020996
   0.75332546  0.2984736   0.04331272  0.16706908 -0.99935162 -0.27838129
   0.90206975  0.18403099 -0.78448319 -0.53721821  0.89490324 -0.0033752
   0.46256506 -0.36806858  0.2972419   0.96327078 -0.68304354  0.35646823
   0.93844771  0.79818118  0.80470675 -0.7595703   0.47755557 -0.03149016
  -0.98273933  0.85008085  0.74723649  0.99865752  0.86893284 -0.9980197
   0.94089377 -0.12442324  0.97259259 -0.3010008   0.10600074  0.64346462
  -0.94235009 -0.77868193  0.47794625 -0.89760828  0.94791168 -0.06344296
   0.7706182   0.7199645  -0.14492391 -0.9217723  -0.18015008 -0.16174242
  -0.91913378 -0.93133283  0.90438241  0.90614241 -0.61461133 -0.05862095
  -0.36858416  0.97484964 -0.92345899 -0.63351798  0.79795039  0.88862288
   0.82488501  0.60683006 -0.96392328 -0.89016348  0.99252969  0.98577267
  -0.87623972  0.87355846  0.88653761  0.96390384  0.77237087  0.4263781
   0.39596435 -0.98400277  0.92703885 -0.79314774  0.92725563 -0.8410306
   0.34581983  0.67347556 -0.82386351 -0.9968546   0.4881483   0.97379816
   0.74385035 -0.65166664  0.72967452  0.77803761  0.93623871  0.16267411
  -0.95120949 -0.81800658 -0.37428162  0.89309055 -0.87049782 -0.65866512
   0.79143941  0.13355584  0.75927693 -0.04988805  0.5871377  -0.42055714
   0.99082303 -0.73137611  0.88470769  0.56163335  0.67182934 -0.47917587
   0.76735097 -0.27398619  0.98509419  0.89774382  0.82456595  0.28774798
   0.57903177  0.94424337 -0.92525727  0.36665595 -0.48801848  0.64014119
  -0.17690234 -0.6775375   0.15074745  0.99964631 -0.84461921  0.97180438
  -0.57422602 -0.66409534  0.54093748  0.35263708 -0.53173614 -0.85173893
   0.84526533  0.37574729  0.91097158  0.89969134 -0.19309041 -0.88724786
  -0.84221411  0.74828237  0.90949732 -0.93208933  0.12183374 -0.83656269
  -0.98111308  0.78611696  0.51665527 -0.882173   -0.64189363 -0.76143014
   0.85071081 -0.28868234  0.3576754  -0.6996758  -0.89836919 -0.95985264
  -0.86789364  0.0550768   0.96015489  0.01006283  0.0636727   0.8147701
  -0.9100228   0.70356882  0.96320194  0.89563012  0.99716747 -0.9762944
  -0.76530945 -0.97696692 -0.77837247 -0.23681881 -0.70643449  0.90348941
   0.41308624 -0.66038847  0.89376378 -0.80538362 -0.6588726  -0.64663762
   0.76544511 -0.32241613 -0.46714973 -0.97696185 -0.74604475  0.87946647
  -0.93508357  0.16346823  0.60271108  0.34240511 -0.50083286  0.98981148
   0.57758111  0.95418036 -0.9999736  -0.54963517  0.86289066 -0.50781387
   0.72583735 -0.78387231 -0.96457088  0.90587652 -0.95860744 -0.07097097
  -0.9698149  -0.90091455  0.15234265  0.87281638]]
After layer expand_dims1041_0 (1, 1, 256) <class 'numpy.float32'> [[[ 0.91162443  0.7018761  -0.8036232  -0.83827084  0.84661162 -0.41146773
    0.99006575 -0.37301353 -0.6287443  -0.52924168  0.90191704  0.86690146
    0.56724322 -0.95110404  0.08673285 -0.08554985  0.80166852  0.76713127
   -0.94312298  0.87969923 -0.38029355 -0.0702367  -0.9675625   0.85028195
   -0.60485572 -0.64574242 -0.96491879 -0.26331988 -0.55760825  0.81931311
    0.94988561 -0.87260091  0.56719857 -0.75822198  0.83753163  0.69359076
    0.76357973 -0.71105397 -0.18160722 -0.0234129  -0.22967972  0.81633037
   -0.8310771   0.54034263 -0.83180213 -0.63633496  0.35661045  0.90020996
    0.75332546  0.2984736   0.04331272  0.16706908 -0.99935162 -0.27838129
    0.90206975  0.18403099 -0.78448319 -0.53721821  0.89490324 -0.0033752
    0.46256506 -0.36806858  0.2972419   0.96327078 -0.68304354  0.35646823
    0.93844771  0.79818118  0.80470675 -0.7595703   0.47755557 -0.03149016
   -0.98273933  0.85008085  0.74723649  0.99865752  0.86893284 -0.9980197
    0.94089377 -0.12442324  0.97259259 -0.3010008   0.10600074  0.64346462
   -0.94235009 -0.77868193  0.47794625 -0.89760828  0.94791168 -0.06344296
    0.7706182   0.7199645  -0.14492391 -0.9217723  -0.18015008 -0.16174242
   -0.91913378 -0.93133283  0.90438241  0.90614241 -0.61461133 -0.05862095
   -0.36858416  0.97484964 -0.92345899 -0.63351798  0.79795039  0.88862288
    0.82488501  0.60683006 -0.96392328 -0.89016348  0.99252969  0.98577267
   -0.87623972  0.87355846  0.88653761  0.96390384  0.77237087  0.4263781
    0.39596435 -0.98400277  0.92703885 -0.79314774  0.92725563 -0.8410306
    0.34581983  0.67347556 -0.82386351 -0.9968546   0.4881483   0.97379816
    0.74385035 -0.65166664  0.72967452  0.77803761  0.93623871  0.16267411
   -0.95120949 -0.81800658 -0.37428162  0.89309055 -0.87049782 -0.65866512
    0.79143941  0.13355584  0.75927693 -0.04988805  0.5871377  -0.42055714
    0.99082303 -0.73137611  0.88470769  0.56163335  0.67182934 -0.47917587
    0.76735097 -0.27398619  0.98509419  0.89774382  0.82456595  0.28774798
    0.57903177  0.94424337 -0.92525727  0.36665595 -0.48801848  0.64014119
   -0.17690234 -0.6775375   0.15074745  0.99964631 -0.84461921  0.97180438
   -0.57422602 -0.66409534  0.54093748  0.35263708 -0.53173614 -0.85173893
    0.84526533  0.37574729  0.91097158  0.89969134 -0.19309041 -0.88724786
   -0.84221411  0.74828237  0.90949732 -0.93208933  0.12183374 -0.83656269
   -0.98111308  0.78611696  0.51665527 -0.882173   -0.64189363 -0.76143014
    0.85071081 -0.28868234  0.3576754  -0.6996758  -0.89836919 -0.95985264
   -0.86789364  0.0550768   0.96015489  0.01006283  0.0636727   0.8147701
   -0.9100228   0.70356882  0.96320194  0.89563012  0.99716747 -0.9762944
   -0.76530945 -0.97696692 -0.77837247 -0.23681881 -0.70643449  0.90348941
    0.41308624 -0.66038847  0.89376378 -0.80538362 -0.6588726  -0.64663762
    0.76544511 -0.32241613 -0.46714973 -0.97696185 -0.74604475  0.87946647
   -0.93508357  0.16346823  0.60271108  0.34240511 -0.50083286  0.98981148
    0.57758111  0.95418036 -0.9999736  -0.54963517  0.86289066 -0.50781387
    0.72583735 -0.78387231 -0.96457088  0.90587652 -0.95860744 -0.07097097
   -0.9698149  -0.90091455  0.15234265  0.87281638]]]
After layer concat4_output (10, 1, 256) <class 'numpy.float32'> [[[  3.44843185e-03   2.28170734e-02  -6.56714384e-03 ...,  -2.98890993e-02
     1.76206883e-02   2.80917389e-04]]

 [[  2.75869574e-02   5.06735183e-02  -5.15802950e-02 ...,  -4.18002456e-02
     6.65703043e-03   5.02562150e-02]]

 [[  4.40447591e-02   7.92230219e-02  -1.12799339e-01 ...,  -9.01127309e-02
     1.31587964e-02   8.59492794e-02]]

 ...,
 [[  6.63714588e-01   5.45868814e-01  -6.80252373e-01 ...,  -7.78776526e-01
    -2.04498786e-02   6.95370495e-01]]

 [[  8.23300898e-01   6.33265078e-01  -7.52719641e-01 ...,  -8.56883645e-01
     4.86493148e-02   8.09632719e-01]]

 [[  9.11624432e-01   7.01876104e-01  -8.03623199e-01 ...,  -9.00914550e-01
     1.52342647e-01   8.72816384e-01]]]
After layer _zeros2_0 (1,) <class 'numpy.int32'> [0]
After layer broadcast_not_equal2_0 (1, 10) <class 'numpy.int32'> [[1 1 0 0 0 0 0 0 0 0]]
After layer sum2_0 (1,) <class 'numpy.int32'> [2]
After layer cast2_0 (1,) <class 'numpy.float32'> [ 2.]
After layer sequencereverse4_output (10, 1, 256) <class 'numpy.float32'> [[[-0.06872559 -0.00477982 -0.00354767 ..., -0.06140137 -0.04299927
    0.03726196]]

 [[-0.00175095 -0.0164032  -0.0703125  ...,  0.00574493 -0.01233673
    0.0269928 ]]

 [[ 0.06011963  0.00928497  0.03005981 ...,  0.06628418  0.02203369
   -0.06420898]]

 ...,
 [[ 0.06011963  0.00928497  0.03005981 ...,  0.06628418  0.02203369
   -0.06420898]]

 [[ 0.06011963  0.00928497  0.03005981 ...,  0.06628418  0.02203369
   -0.06420898]]

 [[ 0.06011963  0.00928497  0.03005981 ...,  0.06628418  0.02203369
   -0.06420898]]]
After layer split5_output0 (1, 256) <class 'numpy.float32'> [[-0.06872559 -0.00477982 -0.00354767 -0.01820374 -0.01612854  0.08428955
  -0.06951904  0.00264549 -0.06427002  0.05566406  0.03616333  0.06744385
   0.01268768  0.02503967 -0.00322533  0.00941467 -0.03817749 -0.01480103
  -0.06390381 -0.00082541 -0.04299927  0.05258179 -0.03115845 -0.04760742
  -0.01341248  0.00824738 -0.03616333  0.05459595 -0.00548172 -0.08770752
  -0.0380249   0.02459717 -0.05517578 -0.06402588  0.06884766  0.07977295
   0.03912354  0.04818726  0.09075928  0.02204895 -0.09381104 -0.05026245
  -0.06982422  0.02409363 -0.0067482  -0.00616837 -0.02383423  0.05352783
   0.08691406 -0.06396484  0.04638672  0.08349609 -0.03488159 -0.09228516
   0.08404541  0.07086182 -0.04742432  0.02374268 -0.08935547  0.07965088
  -0.07897949  0.03561401  0.06286621  0.06707764  0.015625   -0.04220581
  -0.03765869 -0.01841736  0.00150776 -0.01802063 -0.09423828  0.07720947
   0.03140259 -0.0836792  -0.0725708  -0.04382324  0.00515366 -0.00694656
  -0.05938721  0.03411865  0.09222412  0.04168701  0.03198242 -0.00574875
   0.02363586  0.07275391 -0.0791626   0.0692749  -0.04470825 -0.06378174
   0.07495117 -0.0425415   0.09332275  0.08538818 -0.06231689  0.05157471
   0.04559326 -0.07385254 -0.03271484 -0.040802   -0.05093384  0.03372192
   0.0453186   0.01898193  0.02832031  0.02198792 -0.05975342  0.02789307
  -0.06890869  0.07781982 -0.0451355   0.06726074  0.01552582  0.02284241
   0.0793457   0.09033203  0.05105591  0.06140137  0.00379372  0.02333069
   0.078125    0.01802063  0.04208374  0.05169678  0.08758545 -0.04968262
   0.06512451  0.0064621   0.02359009  0.01506805 -0.03088379  0.0725708
   0.00184059  0.07592773  0.04055786  0.07019043  0.01560211  0.06787109
  -0.00635147  0.01701355 -0.00484848 -0.06152344  0.08978271  0.06109619
  -0.08135986  0.07098389 -0.08624268  0.07788086 -0.02548218 -0.02539062
  -0.04089355 -0.03823853  0.07440186  0.04370117 -0.01373291  0.02972412
   0.03491211 -0.03488159  0.07348633  0.02772522 -0.07122803  0.04489136
   0.03134155  0.06896973  0.00819397 -0.05523682 -0.03001404 -0.08703613
   0.08984375 -0.02163696  0.07391357  0.08508301 -0.06445312 -0.05703735
  -0.01725769  0.02288818  0.09173584  0.0064621   0.05944824  0.07824707
  -0.03109741 -0.05822754 -0.04455566 -0.07830811 -0.03317261 -0.07208252
  -0.04022217  0.0355835   0.06433105 -0.06378174 -0.0163269   0.03146362
  -0.04788208 -0.08764648 -0.06896973  0.06286621 -0.09527588 -0.08459473
  -0.05029297 -0.09246826  0.03024292 -0.03356934  0.05667114 -0.00226593
   0.08392334  0.02262878 -0.0247345  -0.0089798   0.05606079 -0.07501221
  -0.04611206 -0.04418945  0.05441284  0.00803375  0.09259033 -0.03710938
  -0.08795166 -0.04641724  0.01368713  0.02748108  0.03753662  0.06182861
  -0.07946777 -0.02145386 -0.02024841  0.03305054 -0.00712204  0.07513428
  -0.07617188 -0.00623322 -0.02082825 -0.00763702 -0.03875732 -0.00661469
  -0.03726196 -0.07226562  0.08209229  0.00625992  0.04260254  0.09307861
  -0.07598877  0.05856323 -0.05401611  0.09051514 -0.02059937  0.02522278
  -0.07348633 -0.07568359  0.03039551 -0.06561279  0.02690125  0.06768799
   0.07397461 -0.06140137 -0.04299927  0.03726196]]
After layer split5_output1 (1, 256) <class 'numpy.float32'> [[ -1.75094604e-03  -1.64031982e-02  -7.03125000e-02   3.06243896e-02
   -5.19409180e-02  -2.61383057e-02  -1.62506104e-02  -4.49218750e-02
   -7.18593597e-04   2.31018066e-02   5.72814941e-02  -7.00073242e-02
    8.66088867e-02  -6.09436035e-02   4.63867188e-02  -8.91723633e-02
   -3.99169922e-02   4.47692871e-02   6.22863770e-02   3.35388184e-02
    4.08935547e-02  -1.47018433e-02  -5.96618652e-02  -4.84924316e-02
   -1.29013062e-02   4.08325195e-02  -7.45239258e-02  -4.81262207e-02
    1.84936523e-02   6.60400391e-02  -8.18634033e-03  -8.49609375e-02
    7.13500977e-02   2.64892578e-02  -5.14221191e-02   8.77685547e-02
   -3.56292725e-03   4.24804688e-02   4.79507446e-03   8.68530273e-02
    5.55419922e-02  -5.71899414e-02  -6.66379929e-05  -5.02014160e-02
   -6.50024414e-02  -7.35473633e-02  -6.50024414e-02   6.91604614e-03
   -4.83703613e-02   3.69567871e-02   3.84826660e-02  -8.99658203e-02
   -7.94677734e-02  -2.89154053e-02   1.76086426e-02  -2.56958008e-02
   -8.03222656e-02  -8.96930695e-04  -2.29644775e-02   6.87255859e-02
    7.87353516e-02   8.48388672e-02  -8.77075195e-02   3.80859375e-02
    4.70275879e-02   1.64794922e-02   4.80041504e-02   5.49621582e-02
    1.05895996e-02   3.70483398e-02  -2.94036865e-02   1.57165527e-02
    8.14056396e-03   2.80456543e-02  -9.49707031e-02   4.28161621e-02
   -3.33557129e-02   3.94287109e-02   2.30865479e-02  -6.39343262e-03
    6.87789917e-03  -6.32324219e-02   4.43115234e-02   5.30700684e-02
    7.01293945e-02   9.04541016e-02   5.86853027e-02  -2.09197998e-02
   -5.39245605e-02  -9.89913940e-04  -1.98669434e-02  -4.91638184e-02
    8.55712891e-02  -7.08007812e-02   4.53186035e-02   2.46276855e-02
   -3.30505371e-02   6.35375977e-02   9.27734375e-02   6.46972656e-02
    4.85534668e-02   2.13165283e-02  -7.03735352e-02   3.72314453e-02
   -9.88769531e-03  -5.31921387e-02  -3.93390656e-05   6.41479492e-02
    2.13012695e-02  -9.07592773e-02   7.87963867e-02  -9.22851562e-02
   -1.34811401e-02   9.36889648e-02  -4.03747559e-02   3.54919434e-02
    2.44140625e-02   3.03497314e-02  -9.39941406e-02  -3.61633301e-02
   -7.84301758e-02  -6.00433350e-03  -8.94775391e-02  -7.80029297e-02
    6.12792969e-02   6.24084473e-02  -5.09948730e-02   7.50732422e-02
   -1.14898682e-02   5.39855957e-02   1.90429688e-02  -1.08413696e-02
    1.87683105e-02   5.22155762e-02   3.15246582e-02  -6.48193359e-02
    8.28857422e-02  -9.52148438e-02  -2.36511230e-02  -6.02111816e-02
    6.54296875e-02   2.20794678e-02   5.34362793e-02   9.44824219e-02
    4.73937988e-02   6.45141602e-02  -5.77697754e-02   2.14233398e-02
   -2.18963623e-02   6.32934570e-02   3.09143066e-02  -6.65283203e-02
   -2.84881592e-02   7.99560547e-02  -2.42004395e-02  -9.03320312e-02
   -4.91027832e-02  -4.82788086e-02  -5.17272949e-02  -8.64257812e-02
   -7.20596313e-03  -3.64685059e-02  -7.72857666e-03  -1.00860596e-02
   -9.68170166e-03  -7.68432617e-02   8.88671875e-02  -4.43420410e-02
   -3.70788574e-02   1.91192627e-02  -2.69317627e-02  -7.25708008e-02
   -1.19781494e-03   5.15747070e-02  -9.18579102e-02   2.07977295e-02
    3.40576172e-02  -7.94677734e-02   3.50952148e-02   7.12890625e-02
   -3.65295410e-02   8.11157227e-02   5.85937500e-02  -1.91040039e-02
    7.52639771e-03  -5.55725098e-02   6.59561157e-03   8.09936523e-02
    1.13449097e-02   3.52783203e-02  -2.69622803e-02  -7.88574219e-02
    9.19342041e-03   4.10461426e-02  -1.50489807e-03   6.55746460e-03
    1.35345459e-02  -9.20410156e-02   1.93328857e-02  -8.72802734e-02
    7.85522461e-02  -7.56835938e-02  -3.75671387e-02   7.18383789e-02
   -6.65283203e-02  -1.42364502e-02  -4.59289551e-03  -2.31323242e-02
   -7.43865967e-03   1.91879272e-03  -2.13165283e-02   9.43756104e-03
    9.24072266e-02   3.81774902e-02  -1.27105713e-02   5.32836914e-02
    3.09906006e-02  -5.84716797e-02   5.46569824e-02   6.27441406e-02
   -2.81066895e-02  -8.21533203e-02   7.26928711e-02  -1.46560669e-02
   -7.08618164e-02  -6.82373047e-02   6.75659180e-02  -7.94677734e-02
    5.14831543e-02   1.47018433e-02   6.58569336e-02  -7.11059570e-02
   -4.29687500e-02   4.22973633e-02  -1.16195679e-02   6.43310547e-02
    6.09130859e-02  -6.90078735e-03  -6.05163574e-02   2.84881592e-02
   -6.09130859e-02  -6.51855469e-02  -3.97949219e-02   3.13415527e-02
    2.64892578e-02   1.49688721e-02  -3.68118286e-03  -5.97534180e-02
    4.87518311e-03  -9.42993164e-02   4.44335938e-02  -8.22143555e-02
    3.35083008e-02   5.74493408e-03  -1.23367310e-02   2.69927979e-02]]
After layer split5_output2 (1, 256) <class 'numpy.float32'> [[ 0.06011963  0.00928497  0.03005981 -0.03009033 -0.03494263  0.00979614
   0.04443359  0.0892334  -0.0647583   0.06057739 -0.03366089 -0.0413208
   0.05426025  0.00199127 -0.04977417 -0.01615906  0.02236938  0.04937744
  -0.07427979  0.01543427  0.03674316 -0.07714844  0.00384521  0.04898071
   0.04669189  0.0435791   0.05166626 -0.03117371  0.00643921 -0.0916748
  -0.06555176  0.04605103  0.03308105 -0.02362061 -0.05386353  0.05136108
  -0.05328369  0.00138664  0.0087204   0.0222168  -0.08197021  0.01593018
  -0.09448242 -0.01968384 -0.05157471 -0.02156067  0.09191895 -0.0456543
  -0.01366425  0.02568054  0.05508423 -0.06210327 -0.06109619  0.09179688
   0.034729    0.00032783  0.08184814 -0.00460052 -0.06396484 -0.07873535
  -0.07684326  0.03585815  0.03106689 -0.02568054 -0.09423828  0.09216309
   0.05581665 -0.07940674 -0.00190926  0.01980591 -0.01357269 -0.07611084
  -0.03887939 -0.06494141 -0.03253174  0.00991821  0.06130981  0.06057739
  -0.02391052 -0.05252075  0.05300903 -0.06097412  0.06945801  0.03237915
   0.07281494 -0.03497314  0.01681519 -0.01838684  0.03123474  0.05499268
   0.03588867 -0.06677246  0.01105499  0.08728027  0.07897949 -0.04669189
   0.01126862  0.08270264  0.07562256 -0.08111572 -0.07165527  0.0562439
   0.09436035  0.03012085  0.07299805  0.05389404 -0.06439209  0.03515625
   0.09405518  0.03613281 -0.04663086 -0.00576401 -0.03102112  0.0838623
  -0.04074097 -0.05682373 -0.0304718  -0.04257202  0.06616211  0.08886719
  -0.08056641 -0.00977325  0.0760498  -0.06884766 -0.05273438  0.04104614
   0.0186615   0.05349731 -0.05892944  0.05801392  0.07830811  0.00614548
  -0.06091309  0.04446411  0.00978851  0.00144386 -0.07788086  0.08276367
   0.07202148  0.08605957 -0.04882812  0.00289917  0.03555298  0.07757568
  -0.07965088  0.03540039 -0.0254364  -0.05508423  0.05841064 -0.03363037
   0.07727051  0.02099609  0.07696533 -0.0352478  -0.06634521 -0.01145172
  -0.05770874  0.02613831  0.06896973  0.02345276 -0.03134155 -0.03076172
  -0.0869751  -0.05670166 -0.04318237  0.01870728  0.06878662  0.08166504
   0.05862427  0.06976318  0.01977539 -0.0680542   0.07312012  0.04721069
   0.04644775  0.06045532 -0.07788086 -0.02279663  0.00743866  0.01916504
   0.05877686 -0.05581665  0.02497864  0.08215332 -0.04962158 -0.04550171
  -0.07220459  0.02761841 -0.00298882 -0.01675415  0.06939697 -0.08612061
   0.09387207  0.06481934  0.00206184  0.08013916 -0.00548172  0.01785278
   0.04898071 -0.06671143 -0.00177479 -0.04730225  0.02372742  0.05212402
  -0.06420898 -0.0300293  -0.04797363 -0.05340576 -0.06292725 -0.07714844
   0.0657959  -0.03717041 -0.0149765   0.06335449 -0.04147339 -0.05319214
   0.00527573  0.01927185  0.01180267  0.0838623   0.00623322 -0.00313187
   0.09326172  0.03146362  0.00914001  0.09161377  0.06488037 -0.06155396
   0.02760315 -0.06207275 -0.06124878 -0.01649475  0.06549072 -0.01605225
  -0.0793457  -0.02545166 -0.08441162 -0.04592896 -0.06707764  0.06787109
  -0.00608063  0.02279663 -0.0328064   0.04278564 -0.05740356 -0.04873657
   0.06732178 -0.05264282 -0.06866455  0.07745361 -0.03759766 -0.0319519
  -0.05053711  0.06628418  0.02203369 -0.06420898]]
After layer split5_output3 (1, 256) <class 'numpy.float32'> [[ 0.06011963  0.00928497  0.03005981 -0.03009033 -0.03494263  0.00979614
   0.04443359  0.0892334  -0.0647583   0.06057739 -0.03366089 -0.0413208
   0.05426025  0.00199127 -0.04977417 -0.01615906  0.02236938  0.04937744
  -0.07427979  0.01543427  0.03674316 -0.07714844  0.00384521  0.04898071
   0.04669189  0.0435791   0.05166626 -0.03117371  0.00643921 -0.0916748
  -0.06555176  0.04605103  0.03308105 -0.02362061 -0.05386353  0.05136108
  -0.05328369  0.00138664  0.0087204   0.0222168  -0.08197021  0.01593018
  -0.09448242 -0.01968384 -0.05157471 -0.02156067  0.09191895 -0.0456543
  -0.01366425  0.02568054  0.05508423 -0.06210327 -0.06109619  0.09179688
   0.034729    0.00032783  0.08184814 -0.00460052 -0.06396484 -0.07873535
  -0.07684326  0.03585815  0.03106689 -0.02568054 -0.09423828  0.09216309
   0.05581665 -0.07940674 -0.00190926  0.01980591 -0.01357269 -0.07611084
  -0.03887939 -0.06494141 -0.03253174  0.00991821  0.06130981  0.06057739
  -0.02391052 -0.05252075  0.05300903 -0.06097412  0.06945801  0.03237915
   0.07281494 -0.03497314  0.01681519 -0.01838684  0.03123474  0.05499268
   0.03588867 -0.06677246  0.01105499  0.08728027  0.07897949 -0.04669189
   0.01126862  0.08270264  0.07562256 -0.08111572 -0.07165527  0.0562439
   0.09436035  0.03012085  0.07299805  0.05389404 -0.06439209  0.03515625
   0.09405518  0.03613281 -0.04663086 -0.00576401 -0.03102112  0.0838623
  -0.04074097 -0.05682373 -0.0304718  -0.04257202  0.06616211  0.08886719
  -0.08056641 -0.00977325  0.0760498  -0.06884766 -0.05273438  0.04104614
   0.0186615   0.05349731 -0.05892944  0.05801392  0.07830811  0.00614548
  -0.06091309  0.04446411  0.00978851  0.00144386 -0.07788086  0.08276367
   0.07202148  0.08605957 -0.04882812  0.00289917  0.03555298  0.07757568
  -0.07965088  0.03540039 -0.0254364  -0.05508423  0.05841064 -0.03363037
   0.07727051  0.02099609  0.07696533 -0.0352478  -0.06634521 -0.01145172
  -0.05770874  0.02613831  0.06896973  0.02345276 -0.03134155 -0.03076172
  -0.0869751  -0.05670166 -0.04318237  0.01870728  0.06878662  0.08166504
   0.05862427  0.06976318  0.01977539 -0.0680542   0.07312012  0.04721069
   0.04644775  0.06045532 -0.07788086 -0.02279663  0.00743866  0.01916504
   0.05877686 -0.05581665  0.02497864  0.08215332 -0.04962158 -0.04550171
  -0.07220459  0.02761841 -0.00298882 -0.01675415  0.06939697 -0.08612061
   0.09387207  0.06481934  0.00206184  0.08013916 -0.00548172  0.01785278
   0.04898071 -0.06671143 -0.00177479 -0.04730225  0.02372742  0.05212402
  -0.06420898 -0.0300293  -0.04797363 -0.05340576 -0.06292725 -0.07714844
   0.0657959  -0.03717041 -0.0149765   0.06335449 -0.04147339 -0.05319214
   0.00527573  0.01927185  0.01180267  0.0838623   0.00623322 -0.00313187
   0.09326172  0.03146362  0.00914001  0.09161377  0.06488037 -0.06155396
   0.02760315 -0.06207275 -0.06124878 -0.01649475  0.06549072 -0.01605225
  -0.0793457  -0.02545166 -0.08441162 -0.04592896 -0.06707764  0.06787109
  -0.00608063  0.02279663 -0.0328064   0.04278564 -0.05740356 -0.04873657
   0.06732178 -0.05264282 -0.06866455  0.07745361 -0.03759766 -0.0319519
  -0.05053711  0.06628418  0.02203369 -0.06420898]]
After layer split5_output4 (1, 256) <class 'numpy.float32'> [[ 0.06011963  0.00928497  0.03005981 -0.03009033 -0.03494263  0.00979614
   0.04443359  0.0892334  -0.0647583   0.06057739 -0.03366089 -0.0413208
   0.05426025  0.00199127 -0.04977417 -0.01615906  0.02236938  0.04937744
  -0.07427979  0.01543427  0.03674316 -0.07714844  0.00384521  0.04898071
   0.04669189  0.0435791   0.05166626 -0.03117371  0.00643921 -0.0916748
  -0.06555176  0.04605103  0.03308105 -0.02362061 -0.05386353  0.05136108
  -0.05328369  0.00138664  0.0087204   0.0222168  -0.08197021  0.01593018
  -0.09448242 -0.01968384 -0.05157471 -0.02156067  0.09191895 -0.0456543
  -0.01366425  0.02568054  0.05508423 -0.06210327 -0.06109619  0.09179688
   0.034729    0.00032783  0.08184814 -0.00460052 -0.06396484 -0.07873535
  -0.07684326  0.03585815  0.03106689 -0.02568054 -0.09423828  0.09216309
   0.05581665 -0.07940674 -0.00190926  0.01980591 -0.01357269 -0.07611084
  -0.03887939 -0.06494141 -0.03253174  0.00991821  0.06130981  0.06057739
  -0.02391052 -0.05252075  0.05300903 -0.06097412  0.06945801  0.03237915
   0.07281494 -0.03497314  0.01681519 -0.01838684  0.03123474  0.05499268
   0.03588867 -0.06677246  0.01105499  0.08728027  0.07897949 -0.04669189
   0.01126862  0.08270264  0.07562256 -0.08111572 -0.07165527  0.0562439
   0.09436035  0.03012085  0.07299805  0.05389404 -0.06439209  0.03515625
   0.09405518  0.03613281 -0.04663086 -0.00576401 -0.03102112  0.0838623
  -0.04074097 -0.05682373 -0.0304718  -0.04257202  0.06616211  0.08886719
  -0.08056641 -0.00977325  0.0760498  -0.06884766 -0.05273438  0.04104614
   0.0186615   0.05349731 -0.05892944  0.05801392  0.07830811  0.00614548
  -0.06091309  0.04446411  0.00978851  0.00144386 -0.07788086  0.08276367
   0.07202148  0.08605957 -0.04882812  0.00289917  0.03555298  0.07757568
  -0.07965088  0.03540039 -0.0254364  -0.05508423  0.05841064 -0.03363037
   0.07727051  0.02099609  0.07696533 -0.0352478  -0.06634521 -0.01145172
  -0.05770874  0.02613831  0.06896973  0.02345276 -0.03134155 -0.03076172
  -0.0869751  -0.05670166 -0.04318237  0.01870728  0.06878662  0.08166504
   0.05862427  0.06976318  0.01977539 -0.0680542   0.07312012  0.04721069
   0.04644775  0.06045532 -0.07788086 -0.02279663  0.00743866  0.01916504
   0.05877686 -0.05581665  0.02497864  0.08215332 -0.04962158 -0.04550171
  -0.07220459  0.02761841 -0.00298882 -0.01675415  0.06939697 -0.08612061
   0.09387207  0.06481934  0.00206184  0.08013916 -0.00548172  0.01785278
   0.04898071 -0.06671143 -0.00177479 -0.04730225  0.02372742  0.05212402
  -0.06420898 -0.0300293  -0.04797363 -0.05340576 -0.06292725 -0.07714844
   0.0657959  -0.03717041 -0.0149765   0.06335449 -0.04147339 -0.05319214
   0.00527573  0.01927185  0.01180267  0.0838623   0.00623322 -0.00313187
   0.09326172  0.03146362  0.00914001  0.09161377  0.06488037 -0.06155396
   0.02760315 -0.06207275 -0.06124878 -0.01649475  0.06549072 -0.01605225
  -0.0793457  -0.02545166 -0.08441162 -0.04592896 -0.06707764  0.06787109
  -0.00608063  0.02279663 -0.0328064   0.04278564 -0.05740356 -0.04873657
   0.06732178 -0.05264282 -0.06866455  0.07745361 -0.03759766 -0.0319519
  -0.05053711  0.06628418  0.02203369 -0.06420898]]
After layer split5_output5 (1, 256) <class 'numpy.float32'> [[ 0.06011963  0.00928497  0.03005981 -0.03009033 -0.03494263  0.00979614
   0.04443359  0.0892334  -0.0647583   0.06057739 -0.03366089 -0.0413208
   0.05426025  0.00199127 -0.04977417 -0.01615906  0.02236938  0.04937744
  -0.07427979  0.01543427  0.03674316 -0.07714844  0.00384521  0.04898071
   0.04669189  0.0435791   0.05166626 -0.03117371  0.00643921 -0.0916748
  -0.06555176  0.04605103  0.03308105 -0.02362061 -0.05386353  0.05136108
  -0.05328369  0.00138664  0.0087204   0.0222168  -0.08197021  0.01593018
  -0.09448242 -0.01968384 -0.05157471 -0.02156067  0.09191895 -0.0456543
  -0.01366425  0.02568054  0.05508423 -0.06210327 -0.06109619  0.09179688
   0.034729    0.00032783  0.08184814 -0.00460052 -0.06396484 -0.07873535
  -0.07684326  0.03585815  0.03106689 -0.02568054 -0.09423828  0.09216309
   0.05581665 -0.07940674 -0.00190926  0.01980591 -0.01357269 -0.07611084
  -0.03887939 -0.06494141 -0.03253174  0.00991821  0.06130981  0.06057739
  -0.02391052 -0.05252075  0.05300903 -0.06097412  0.06945801  0.03237915
   0.07281494 -0.03497314  0.01681519 -0.01838684  0.03123474  0.05499268
   0.03588867 -0.06677246  0.01105499  0.08728027  0.07897949 -0.04669189
   0.01126862  0.08270264  0.07562256 -0.08111572 -0.07165527  0.0562439
   0.09436035  0.03012085  0.07299805  0.05389404 -0.06439209  0.03515625
   0.09405518  0.03613281 -0.04663086 -0.00576401 -0.03102112  0.0838623
  -0.04074097 -0.05682373 -0.0304718  -0.04257202  0.06616211  0.08886719
  -0.08056641 -0.00977325  0.0760498  -0.06884766 -0.05273438  0.04104614
   0.0186615   0.05349731 -0.05892944  0.05801392  0.07830811  0.00614548
  -0.06091309  0.04446411  0.00978851  0.00144386 -0.07788086  0.08276367
   0.07202148  0.08605957 -0.04882812  0.00289917  0.03555298  0.07757568
  -0.07965088  0.03540039 -0.0254364  -0.05508423  0.05841064 -0.03363037
   0.07727051  0.02099609  0.07696533 -0.0352478  -0.06634521 -0.01145172
  -0.05770874  0.02613831  0.06896973  0.02345276 -0.03134155 -0.03076172
  -0.0869751  -0.05670166 -0.04318237  0.01870728  0.06878662  0.08166504
   0.05862427  0.06976318  0.01977539 -0.0680542   0.07312012  0.04721069
   0.04644775  0.06045532 -0.07788086 -0.02279663  0.00743866  0.01916504
   0.05877686 -0.05581665  0.02497864  0.08215332 -0.04962158 -0.04550171
  -0.07220459  0.02761841 -0.00298882 -0.01675415  0.06939697 -0.08612061
   0.09387207  0.06481934  0.00206184  0.08013916 -0.00548172  0.01785278
   0.04898071 -0.06671143 -0.00177479 -0.04730225  0.02372742  0.05212402
  -0.06420898 -0.0300293  -0.04797363 -0.05340576 -0.06292725 -0.07714844
   0.0657959  -0.03717041 -0.0149765   0.06335449 -0.04147339 -0.05319214
   0.00527573  0.01927185  0.01180267  0.0838623   0.00623322 -0.00313187
   0.09326172  0.03146362  0.00914001  0.09161377  0.06488037 -0.06155396
   0.02760315 -0.06207275 -0.06124878 -0.01649475  0.06549072 -0.01605225
  -0.0793457  -0.02545166 -0.08441162 -0.04592896 -0.06707764  0.06787109
  -0.00608063  0.02279663 -0.0328064   0.04278564 -0.05740356 -0.04873657
   0.06732178 -0.05264282 -0.06866455  0.07745361 -0.03759766 -0.0319519
  -0.05053711  0.06628418  0.02203369 -0.06420898]]
After layer split5_output6 (1, 256) <class 'numpy.float32'> [[ 0.06011963  0.00928497  0.03005981 -0.03009033 -0.03494263  0.00979614
   0.04443359  0.0892334  -0.0647583   0.06057739 -0.03366089 -0.0413208
   0.05426025  0.00199127 -0.04977417 -0.01615906  0.02236938  0.04937744
  -0.07427979  0.01543427  0.03674316 -0.07714844  0.00384521  0.04898071
   0.04669189  0.0435791   0.05166626 -0.03117371  0.00643921 -0.0916748
  -0.06555176  0.04605103  0.03308105 -0.02362061 -0.05386353  0.05136108
  -0.05328369  0.00138664  0.0087204   0.0222168  -0.08197021  0.01593018
  -0.09448242 -0.01968384 -0.05157471 -0.02156067  0.09191895 -0.0456543
  -0.01366425  0.02568054  0.05508423 -0.06210327 -0.06109619  0.09179688
   0.034729    0.00032783  0.08184814 -0.00460052 -0.06396484 -0.07873535
  -0.07684326  0.03585815  0.03106689 -0.02568054 -0.09423828  0.09216309
   0.05581665 -0.07940674 -0.00190926  0.01980591 -0.01357269 -0.07611084
  -0.03887939 -0.06494141 -0.03253174  0.00991821  0.06130981  0.06057739
  -0.02391052 -0.05252075  0.05300903 -0.06097412  0.06945801  0.03237915
   0.07281494 -0.03497314  0.01681519 -0.01838684  0.03123474  0.05499268
   0.03588867 -0.06677246  0.01105499  0.08728027  0.07897949 -0.04669189
   0.01126862  0.08270264  0.07562256 -0.08111572 -0.07165527  0.0562439
   0.09436035  0.03012085  0.07299805  0.05389404 -0.06439209  0.03515625
   0.09405518  0.03613281 -0.04663086 -0.00576401 -0.03102112  0.0838623
  -0.04074097 -0.05682373 -0.0304718  -0.04257202  0.06616211  0.08886719
  -0.08056641 -0.00977325  0.0760498  -0.06884766 -0.05273438  0.04104614
   0.0186615   0.05349731 -0.05892944  0.05801392  0.07830811  0.00614548
  -0.06091309  0.04446411  0.00978851  0.00144386 -0.07788086  0.08276367
   0.07202148  0.08605957 -0.04882812  0.00289917  0.03555298  0.07757568
  -0.07965088  0.03540039 -0.0254364  -0.05508423  0.05841064 -0.03363037
   0.07727051  0.02099609  0.07696533 -0.0352478  -0.06634521 -0.01145172
  -0.05770874  0.02613831  0.06896973  0.02345276 -0.03134155 -0.03076172
  -0.0869751  -0.05670166 -0.04318237  0.01870728  0.06878662  0.08166504
   0.05862427  0.06976318  0.01977539 -0.0680542   0.07312012  0.04721069
   0.04644775  0.06045532 -0.07788086 -0.02279663  0.00743866  0.01916504
   0.05877686 -0.05581665  0.02497864  0.08215332 -0.04962158 -0.04550171
  -0.07220459  0.02761841 -0.00298882 -0.01675415  0.06939697 -0.08612061
   0.09387207  0.06481934  0.00206184  0.08013916 -0.00548172  0.01785278
   0.04898071 -0.06671143 -0.00177479 -0.04730225  0.02372742  0.05212402
  -0.06420898 -0.0300293  -0.04797363 -0.05340576 -0.06292725 -0.07714844
   0.0657959  -0.03717041 -0.0149765   0.06335449 -0.04147339 -0.05319214
   0.00527573  0.01927185  0.01180267  0.0838623   0.00623322 -0.00313187
   0.09326172  0.03146362  0.00914001  0.09161377  0.06488037 -0.06155396
   0.02760315 -0.06207275 -0.06124878 -0.01649475  0.06549072 -0.01605225
  -0.0793457  -0.02545166 -0.08441162 -0.04592896 -0.06707764  0.06787109
  -0.00608063  0.02279663 -0.0328064   0.04278564 -0.05740356 -0.04873657
   0.06732178 -0.05264282 -0.06866455  0.07745361 -0.03759766 -0.0319519
  -0.05053711  0.06628418  0.02203369 -0.06420898]]
After layer split5_output7 (1, 256) <class 'numpy.float32'> [[ 0.06011963  0.00928497  0.03005981 -0.03009033 -0.03494263  0.00979614
   0.04443359  0.0892334  -0.0647583   0.06057739 -0.03366089 -0.0413208
   0.05426025  0.00199127 -0.04977417 -0.01615906  0.02236938  0.04937744
  -0.07427979  0.01543427  0.03674316 -0.07714844  0.00384521  0.04898071
   0.04669189  0.0435791   0.05166626 -0.03117371  0.00643921 -0.0916748
  -0.06555176  0.04605103  0.03308105 -0.02362061 -0.05386353  0.05136108
  -0.05328369  0.00138664  0.0087204   0.0222168  -0.08197021  0.01593018
  -0.09448242 -0.01968384 -0.05157471 -0.02156067  0.09191895 -0.0456543
  -0.01366425  0.02568054  0.05508423 -0.06210327 -0.06109619  0.09179688
   0.034729    0.00032783  0.08184814 -0.00460052 -0.06396484 -0.07873535
  -0.07684326  0.03585815  0.03106689 -0.02568054 -0.09423828  0.09216309
   0.05581665 -0.07940674 -0.00190926  0.01980591 -0.01357269 -0.07611084
  -0.03887939 -0.06494141 -0.03253174  0.00991821  0.06130981  0.06057739
  -0.02391052 -0.05252075  0.05300903 -0.06097412  0.06945801  0.03237915
   0.07281494 -0.03497314  0.01681519 -0.01838684  0.03123474  0.05499268
   0.03588867 -0.06677246  0.01105499  0.08728027  0.07897949 -0.04669189
   0.01126862  0.08270264  0.07562256 -0.08111572 -0.07165527  0.0562439
   0.09436035  0.03012085  0.07299805  0.05389404 -0.06439209  0.03515625
   0.09405518  0.03613281 -0.04663086 -0.00576401 -0.03102112  0.0838623
  -0.04074097 -0.05682373 -0.0304718  -0.04257202  0.06616211  0.08886719
  -0.08056641 -0.00977325  0.0760498  -0.06884766 -0.05273438  0.04104614
   0.0186615   0.05349731 -0.05892944  0.05801392  0.07830811  0.00614548
  -0.06091309  0.04446411  0.00978851  0.00144386 -0.07788086  0.08276367
   0.07202148  0.08605957 -0.04882812  0.00289917  0.03555298  0.07757568
  -0.07965088  0.03540039 -0.0254364  -0.05508423  0.05841064 -0.03363037
   0.07727051  0.02099609  0.07696533 -0.0352478  -0.06634521 -0.01145172
  -0.05770874  0.02613831  0.06896973  0.02345276 -0.03134155 -0.03076172
  -0.0869751  -0.05670166 -0.04318237  0.01870728  0.06878662  0.08166504
   0.05862427  0.06976318  0.01977539 -0.0680542   0.07312012  0.04721069
   0.04644775  0.06045532 -0.07788086 -0.02279663  0.00743866  0.01916504
   0.05877686 -0.05581665  0.02497864  0.08215332 -0.04962158 -0.04550171
  -0.07220459  0.02761841 -0.00298882 -0.01675415  0.06939697 -0.08612061
   0.09387207  0.06481934  0.00206184  0.08013916 -0.00548172  0.01785278
   0.04898071 -0.06671143 -0.00177479 -0.04730225  0.02372742  0.05212402
  -0.06420898 -0.0300293  -0.04797363 -0.05340576 -0.06292725 -0.07714844
   0.0657959  -0.03717041 -0.0149765   0.06335449 -0.04147339 -0.05319214
   0.00527573  0.01927185  0.01180267  0.0838623   0.00623322 -0.00313187
   0.09326172  0.03146362  0.00914001  0.09161377  0.06488037 -0.06155396
   0.02760315 -0.06207275 -0.06124878 -0.01649475  0.06549072 -0.01605225
  -0.0793457  -0.02545166 -0.08441162 -0.04592896 -0.06707764  0.06787109
  -0.00608063  0.02279663 -0.0328064   0.04278564 -0.05740356 -0.04873657
   0.06732178 -0.05264282 -0.06866455  0.07745361 -0.03759766 -0.0319519
  -0.05053711  0.06628418  0.02203369 -0.06420898]]
After layer split5_output8 (1, 256) <class 'numpy.float32'> [[ 0.06011963  0.00928497  0.03005981 -0.03009033 -0.03494263  0.00979614
   0.04443359  0.0892334  -0.0647583   0.06057739 -0.03366089 -0.0413208
   0.05426025  0.00199127 -0.04977417 -0.01615906  0.02236938  0.04937744
  -0.07427979  0.01543427  0.03674316 -0.07714844  0.00384521  0.04898071
   0.04669189  0.0435791   0.05166626 -0.03117371  0.00643921 -0.0916748
  -0.06555176  0.04605103  0.03308105 -0.02362061 -0.05386353  0.05136108
  -0.05328369  0.00138664  0.0087204   0.0222168  -0.08197021  0.01593018
  -0.09448242 -0.01968384 -0.05157471 -0.02156067  0.09191895 -0.0456543
  -0.01366425  0.02568054  0.05508423 -0.06210327 -0.06109619  0.09179688
   0.034729    0.00032783  0.08184814 -0.00460052 -0.06396484 -0.07873535
  -0.07684326  0.03585815  0.03106689 -0.02568054 -0.09423828  0.09216309
   0.05581665 -0.07940674 -0.00190926  0.01980591 -0.01357269 -0.07611084
  -0.03887939 -0.06494141 -0.03253174  0.00991821  0.06130981  0.06057739
  -0.02391052 -0.05252075  0.05300903 -0.06097412  0.06945801  0.03237915
   0.07281494 -0.03497314  0.01681519 -0.01838684  0.03123474  0.05499268
   0.03588867 -0.06677246  0.01105499  0.08728027  0.07897949 -0.04669189
   0.01126862  0.08270264  0.07562256 -0.08111572 -0.07165527  0.0562439
   0.09436035  0.03012085  0.07299805  0.05389404 -0.06439209  0.03515625
   0.09405518  0.03613281 -0.04663086 -0.00576401 -0.03102112  0.0838623
  -0.04074097 -0.05682373 -0.0304718  -0.04257202  0.06616211  0.08886719
  -0.08056641 -0.00977325  0.0760498  -0.06884766 -0.05273438  0.04104614
   0.0186615   0.05349731 -0.05892944  0.05801392  0.07830811  0.00614548
  -0.06091309  0.04446411  0.00978851  0.00144386 -0.07788086  0.08276367
   0.07202148  0.08605957 -0.04882812  0.00289917  0.03555298  0.07757568
  -0.07965088  0.03540039 -0.0254364  -0.05508423  0.05841064 -0.03363037
   0.07727051  0.02099609  0.07696533 -0.0352478  -0.06634521 -0.01145172
  -0.05770874  0.02613831  0.06896973  0.02345276 -0.03134155 -0.03076172
  -0.0869751  -0.05670166 -0.04318237  0.01870728  0.06878662  0.08166504
   0.05862427  0.06976318  0.01977539 -0.0680542   0.07312012  0.04721069
   0.04644775  0.06045532 -0.07788086 -0.02279663  0.00743866  0.01916504
   0.05877686 -0.05581665  0.02497864  0.08215332 -0.04962158 -0.04550171
  -0.07220459  0.02761841 -0.00298882 -0.01675415  0.06939697 -0.08612061
   0.09387207  0.06481934  0.00206184  0.08013916 -0.00548172  0.01785278
   0.04898071 -0.06671143 -0.00177479 -0.04730225  0.02372742  0.05212402
  -0.06420898 -0.0300293  -0.04797363 -0.05340576 -0.06292725 -0.07714844
   0.0657959  -0.03717041 -0.0149765   0.06335449 -0.04147339 -0.05319214
   0.00527573  0.01927185  0.01180267  0.0838623   0.00623322 -0.00313187
   0.09326172  0.03146362  0.00914001  0.09161377  0.06488037 -0.06155396
   0.02760315 -0.06207275 -0.06124878 -0.01649475  0.06549072 -0.01605225
  -0.0793457  -0.02545166 -0.08441162 -0.04592896 -0.06707764  0.06787109
  -0.00608063  0.02279663 -0.0328064   0.04278564 -0.05740356 -0.04873657
   0.06732178 -0.05264282 -0.06866455  0.07745361 -0.03759766 -0.0319519
  -0.05053711  0.06628418  0.02203369 -0.06420898]]
After layer split5_output9 (1, 256) <class 'numpy.float32'> [[ 0.06011963  0.00928497  0.03005981 -0.03009033 -0.03494263  0.00979614
   0.04443359  0.0892334  -0.0647583   0.06057739 -0.03366089 -0.0413208
   0.05426025  0.00199127 -0.04977417 -0.01615906  0.02236938  0.04937744
  -0.07427979  0.01543427  0.03674316 -0.07714844  0.00384521  0.04898071
   0.04669189  0.0435791   0.05166626 -0.03117371  0.00643921 -0.0916748
  -0.06555176  0.04605103  0.03308105 -0.02362061 -0.05386353  0.05136108
  -0.05328369  0.00138664  0.0087204   0.0222168  -0.08197021  0.01593018
  -0.09448242 -0.01968384 -0.05157471 -0.02156067  0.09191895 -0.0456543
  -0.01366425  0.02568054  0.05508423 -0.06210327 -0.06109619  0.09179688
   0.034729    0.00032783  0.08184814 -0.00460052 -0.06396484 -0.07873535
  -0.07684326  0.03585815  0.03106689 -0.02568054 -0.09423828  0.09216309
   0.05581665 -0.07940674 -0.00190926  0.01980591 -0.01357269 -0.07611084
  -0.03887939 -0.06494141 -0.03253174  0.00991821  0.06130981  0.06057739
  -0.02391052 -0.05252075  0.05300903 -0.06097412  0.06945801  0.03237915
   0.07281494 -0.03497314  0.01681519 -0.01838684  0.03123474  0.05499268
   0.03588867 -0.06677246  0.01105499  0.08728027  0.07897949 -0.04669189
   0.01126862  0.08270264  0.07562256 -0.08111572 -0.07165527  0.0562439
   0.09436035  0.03012085  0.07299805  0.05389404 -0.06439209  0.03515625
   0.09405518  0.03613281 -0.04663086 -0.00576401 -0.03102112  0.0838623
  -0.04074097 -0.05682373 -0.0304718  -0.04257202  0.06616211  0.08886719
  -0.08056641 -0.00977325  0.0760498  -0.06884766 -0.05273438  0.04104614
   0.0186615   0.05349731 -0.05892944  0.05801392  0.07830811  0.00614548
  -0.06091309  0.04446411  0.00978851  0.00144386 -0.07788086  0.08276367
   0.07202148  0.08605957 -0.04882812  0.00289917  0.03555298  0.07757568
  -0.07965088  0.03540039 -0.0254364  -0.05508423  0.05841064 -0.03363037
   0.07727051  0.02099609  0.07696533 -0.0352478  -0.06634521 -0.01145172
  -0.05770874  0.02613831  0.06896973  0.02345276 -0.03134155 -0.03076172
  -0.0869751  -0.05670166 -0.04318237  0.01870728  0.06878662  0.08166504
   0.05862427  0.06976318  0.01977539 -0.0680542   0.07312012  0.04721069
   0.04644775  0.06045532 -0.07788086 -0.02279663  0.00743866  0.01916504
   0.05877686 -0.05581665  0.02497864  0.08215332 -0.04962158 -0.04550171
  -0.07220459  0.02761841 -0.00298882 -0.01675415  0.06939697 -0.08612061
   0.09387207  0.06481934  0.00206184  0.08013916 -0.00548172  0.01785278
   0.04898071 -0.06671143 -0.00177479 -0.04730225  0.02372742  0.05212402
  -0.06420898 -0.0300293  -0.04797363 -0.05340576 -0.06292725 -0.07714844
   0.0657959  -0.03717041 -0.0149765   0.06335449 -0.04147339 -0.05319214
   0.00527573  0.01927185  0.01180267  0.0838623   0.00623322 -0.00313187
   0.09326172  0.03146362  0.00914001  0.09161377  0.06488037 -0.06155396
   0.02760315 -0.06207275 -0.06124878 -0.01649475  0.06549072 -0.01605225
  -0.0793457  -0.02545166 -0.08441162 -0.04592896 -0.06707764  0.06787109
  -0.00608063  0.02279663 -0.0328064   0.04278564 -0.05740356 -0.04873657
   0.06732178 -0.05264282 -0.06866455  0.07745361 -0.03759766 -0.0319519
  -0.05053711  0.06628418  0.02203369 -0.06420898]]
After layer encoder_birnn_reverse_l0_t0_i2h_output (1, 1024) <class 'numpy.float32'> [[ 0.08499373  0.07231598 -0.05630327 ..., -0.00509584 -0.01010962
  -0.04166982]]
After layer encoder_birnn_reverse_l0_begin_state_0_0 (1, 256) <class 'numpy.float32'> [[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
   0.  0.  0.  0.]]
After layer encoder_birnn_reverse_l0_t0_h2h_output (1, 1024) <class 'numpy.float32'> [[ 0.01889038  0.01239777  0.0041008  ...,  0.01309967  0.02073669
   0.01248932]]
After layer _plus1036_0 (1, 1024) <class 'numpy.float32'> [[ 0.10388411  0.08471374 -0.05220247 ...,  0.00800383  0.01062707
  -0.0291805 ]]
After layer encoder_birnn_reverse_l0_t0_slice_output0 (1, 256) <class 'numpy.float32'> [[ 0.10388411  0.08471374 -0.05220247  0.05218302 -0.00301887 -0.01617704
   0.01569697  0.18192005  0.18284619 -0.0138018   0.05359614  0.08864149
   0.0959376   0.00598327  0.0854879   0.04367238 -0.02101465  0.02592343
  -0.05158528  0.01480561  0.09416869 -0.02031044  0.08723542 -0.09234609
  -0.03437176  0.0587519   0.03354683 -0.02045543  0.09853832  0.01592945
   0.0726068   0.01285504 -0.00259829  0.00421891 -0.02935334  0.00083872
   0.04723216  0.02958345  0.08738517  0.06205431  0.17785518  0.06175891
   0.06300703  0.00223495  0.0376719   0.01903901  0.03786981  0.05981583
  -0.05806838  0.04826513  0.03316339 -0.00536902  0.16828927  0.11042449
   0.14249919  0.01293579 -0.01962499  0.08959222  0.02295764  0.1036447
   0.00443544  0.0407381  -0.05124432  0.0292242   0.11330428  0.01316326
   0.07516828 -0.00962911  0.08233395  0.23814502  0.09533657  0.0653763
   0.00494728 -0.02707324  0.03077141  0.13858697  0.06925172  0.06705511
   0.06669845  0.04831804  0.03700728  0.06689702 -0.01009881  0.0035434
   0.09905414  0.10547537  0.10720801  0.13800131 -0.0800494   0.21985497
   0.1517849   0.10879973  0.01471358 -0.0062436   0.0690989   0.09576375
   0.11809802  0.14094429 -0.07476512  0.0644094   0.05444888  0.03647511
   0.07515134  0.0616285   0.1357003   0.11092645 -0.02910459 -0.02725077
   0.00817791  0.10915057  0.04587511  0.09864134  0.05725791  0.00893285
   0.09086877  0.21620259 -0.06325901 -0.01360949  0.20900926  0.13385104
   0.07088805  0.04778378  0.05769553  0.09447928  0.06792004  0.02187098
   0.06161956  0.13338558 -0.03208832 -0.05977042  0.11070512  0.21506211
   0.0163152  -0.00636315  0.07541254  0.01939229 -0.07187387  0.02613217
  -0.01972967 -0.05761653  0.08532768  0.01139658  0.04614283  0.00598677
   0.11401365  0.02060067  0.10479792  0.02902204  0.04178244 -0.00262973
   0.00415658  0.05477755  0.05508177 -0.01068321  0.03512196  0.12315056
  -0.02110812  0.09487034  0.07709289 -0.01310403 -0.00597882  0.00035718
   0.05369899  0.00438966 -0.01293822  0.08565789  0.06096928  0.03154114
   0.01655378 -0.04963926  0.02629424  0.0316182   0.07169833  0.23285696
   0.08092906  0.14479285  0.0056823   0.07231539  0.09841815  0.08281457
   0.02377753  0.03628664  0.03299289  0.07427627  0.12444692  0.0189228
   0.05028597  0.04453731  0.2842502   0.09288031  0.04702875 -0.03722865
  -0.11752681 -0.01830214  0.2631242   0.04690328  0.0324076   0.09466549
   0.02828807  0.09217185  0.10630743  0.09457371  0.09105294  0.03376028
   0.00669647  0.01500307  0.068284   -0.03070341  0.07962957  0.05216184
   0.01251467  0.14193943  0.00098341 -0.00693342  0.12809335  0.11717163
   0.04685896  0.06300868  0.07930028  0.12267971 -0.0049817   0.13714358
   0.07541533  0.05528495  0.05896787 -0.0334751   0.0644604   0.12485476
   0.05906343  0.26881298 -0.01690688  0.02150802 -0.03939962  0.03642961
   0.01488027  0.05430506  0.09713551 -0.02289723  0.14492807 -0.05232077
   0.06687362  0.00651925  0.2302098   0.1746476  -0.01455189  0.02294976
   0.05425753  0.11636875  0.09497304  0.10890009  0.1053623   0.16220485
   0.03324157  0.07531886 -0.06511182 -0.03390527]]
After layer encoder_birnn_reverse_l0_t0_slice_output1 (1, 256) <class 'numpy.float32'> [[  1.53712928e-01   1.01379640e-01   1.00148953e-01   4.52061892e-02
    1.09423555e-01   9.79634821e-02   6.46018907e-02   9.55647901e-02
    2.66996145e-01   4.23207767e-02  -5.38238063e-02   3.01640015e-02
    2.54309922e-02   6.22228831e-02   3.02200951e-03   1.15612566e-01
    3.73186767e-02   5.60640171e-02   8.84972960e-02   2.77518462e-02
    8.57841372e-02   5.50390519e-02   2.31701285e-01   7.13621825e-02
    8.30642581e-02   8.10183138e-02   5.85088618e-02  -2.19968110e-02
    5.07807806e-02   3.65460366e-02   1.52422674e-03   3.36798765e-02
    3.17445770e-02   7.52421096e-02   5.19019999e-02  -2.80736126e-02
   -4.72317152e-02  -2.64811963e-02   8.46078619e-02   6.68017343e-02
    6.24705702e-02   1.05431117e-01   5.24418578e-02  -1.33215077e-02
    3.53775136e-02  -2.45319493e-03   4.41014506e-02   9.92610306e-02
    7.58942291e-02   2.45670266e-02   7.73720145e-02   8.00706521e-02
    1.27325892e-01   1.88138753e-01   1.11167401e-01  -1.20718144e-02
    5.61478026e-02   3.11566442e-02   4.26730216e-02   1.11335464e-01
    3.49141061e-02   6.53574467e-02   3.20442133e-02   7.23639727e-02
    5.66309951e-02  -5.80929369e-02   1.44473404e-01   8.32030773e-02
    4.58859429e-02   9.43340361e-02  -8.61373544e-03   9.13190618e-02
    3.79251838e-02  -2.93088853e-02   4.34243493e-02   2.12777257e-01
    1.19325519e-03   6.49239123e-02   2.40732990e-02   2.86809001e-02
    8.40953663e-02   3.35636213e-02   3.63600589e-02   5.87016791e-02
    1.20343983e-01   3.35287713e-02   6.64717406e-02   3.43096927e-02
   -1.01016015e-02   1.56438217e-01   1.98203579e-01   2.07470953e-02
   -3.87035608e-02   4.64899838e-02   1.76052116e-02   7.29993284e-02
    2.53428183e-02   1.94327876e-01   6.17194548e-02   1.26428962e-01
    8.53238031e-02   1.28371129e-02   3.78168486e-02   5.67994826e-02
    2.18984578e-02   7.02682436e-02   4.99989428e-02   1.11193702e-01
    1.23967811e-01   1.36976868e-01  -4.12146375e-03   1.74070485e-02
    9.23690107e-03   4.70708609e-02   8.54197145e-02   7.71975070e-02
    2.30171308e-02   1.23566501e-02   1.72225207e-01   8.66857097e-02
    1.55294031e-01   1.55596491e-02   1.11773368e-02   4.19508107e-02
    3.24752405e-02   5.62345684e-02  -2.38834545e-02  -4.95643169e-03
    7.88216069e-02   1.34993084e-02   5.80844507e-02   1.79209173e-01
    1.42037049e-01   1.87469050e-02   1.63449086e-02   3.91863286e-05
    4.14699875e-03   9.08746868e-02   9.60166007e-03  -4.49489057e-02
    5.09157777e-02   5.48554137e-02   5.65568879e-02   6.41617626e-02
    7.43668713e-03   1.13159873e-01  -1.58325955e-02   1.39684200e-01
    3.74263078e-02   1.08139336e-01   6.66843802e-02  -4.05859053e-02
    3.73191945e-03  -1.25931323e-01   6.21391684e-02  -2.65783966e-02
    8.02849233e-02   1.13715015e-01   8.64032805e-02   1.23322599e-01
    1.16058707e-01  -1.97906084e-02   1.00879088e-01   1.43068165e-01
    8.60285610e-02   4.88796681e-02   8.45920444e-02  -2.15136632e-02
    1.08678482e-01   1.15074851e-01   3.98290716e-02   6.99139163e-02
    8.72810557e-02   1.16259433e-01   1.35131866e-01   4.14507650e-03
    6.95933029e-02  -6.38158470e-02   1.22840323e-01   1.01627201e-01
   -2.94767246e-02   1.21624790e-01   9.20496508e-02   7.08148628e-03
    3.50192338e-02   4.09257449e-02   9.91188288e-02   1.13088019e-01
    1.86287686e-01   8.00880194e-02  -2.73533091e-02  -2.63290964e-02
    1.78391598e-02   5.91333881e-02   2.32009530e-01   9.60557386e-02
    1.22299381e-01   1.28111959e-01   3.32742073e-02   3.84005457e-02
    4.08937037e-03   8.02881122e-02   1.58999860e-01   5.61935306e-02
   -7.65379891e-03   8.43391269e-02  -4.64217998e-02   2.68047415e-02
    3.52975167e-02   5.90391457e-02   7.32253715e-02   9.79177803e-02
    2.09214762e-02   3.09073087e-02   1.02976352e-01   8.50054771e-02
    1.02589451e-01   2.70652920e-02   6.99761361e-02   1.81099959e-02
   -3.76770720e-02  -9.86596942e-03  -4.45321873e-02  -2.09602229e-02
    9.87139121e-02  -1.81480460e-02   5.07868715e-02   4.18159366e-02
    1.50508553e-01   2.27920800e-01   6.37605488e-02   5.28086051e-02
    7.80790150e-02   1.03548309e-02   1.31034963e-02  -3.01924646e-02
    3.18664536e-02  -6.75555877e-03   4.61984053e-02   4.52320091e-03
    6.45132363e-02   7.63530731e-02   2.18947977e-01   1.06654063e-01
   -3.33505869e-03   7.50044128e-03   1.04058117e-01  -3.97944786e-02
    1.55186743e-01  -2.06241384e-03   9.82315615e-02  -3.47656533e-02
    1.65815558e-02   8.99199396e-02   3.71883884e-02   5.31174988e-02]]
After layer encoder_birnn_reverse_l0_t0_slice_output2 (1, 256) <class 'numpy.float32'> [[-0.11193107 -0.04426403 -0.06150822 -0.10733692  0.00270575 -0.19520952
   0.05923934  0.02553587 -0.0429776  -0.11544208 -0.03566259  0.07748866
   0.07294183 -0.09581327  0.08171502 -0.04928929  0.04853709  0.04017888
   0.06648253 -0.03125035  0.06281347 -0.11916515  0.02109686  0.09305795
   0.01397325 -0.00252778 -0.19256523 -0.01654742  0.01694055 -0.07500754
   0.05183347 -0.05888236  0.06365819 -0.03545586  0.04467849 -0.0067548
  -0.15851291 -0.02070861 -0.10295302 -0.00459494  0.02786925  0.02357234
   0.11136982  0.01128879  0.12560126 -0.08843382  0.08976652 -0.07326844
  -0.01211957 -0.14777873 -0.14584953 -0.05296049  0.03126903  0.07213248
  -0.00949243  0.05348392 -0.10592885  0.11528455  0.03614889 -0.12059479
  -0.08413929 -0.01834141 -0.05550949 -0.09045786  0.12197831 -0.09412023
   0.08469522 -0.00147788 -0.10953705 -0.05783159 -0.14337     0.04819073
   0.02604666 -0.07020937  0.01822498 -0.08808486 -0.06802603 -0.09113298
  -0.03694305 -0.04060712 -0.10448976 -0.02436528 -0.07018475 -0.12231785
  -0.08364386  0.07120444 -0.04898421  0.05314189 -0.04171822 -0.12689823
   0.09458505  0.00394684  0.05108215 -0.05390061  0.05629486 -0.00469381
   0.04181767  0.06836045  0.02542027  0.03074092  0.04627432  0.08527379
  -0.13829768  0.05644651 -0.05815796  0.0250923  -0.02140846 -0.12762026
   0.09611516 -0.0137048   0.10370316  0.20294054 -0.00484092  0.06040692
  -0.04634222 -0.01913799 -0.05830546 -0.1245539   0.00138667  0.07180583
   0.04089759  0.07914148 -0.06142356 -0.0388668   0.11707179 -0.09599026
  -0.05797664 -0.0180113   0.0848102   0.16233014  0.08961861  0.09355986
   0.00637177  0.09019382  0.02738891  0.07183677  0.05062851 -0.01650256
   0.06894314  0.13643616 -0.10213614 -0.02746788  0.05567471 -0.0920715
  -0.12807295  0.07349901  0.15586308 -0.09709378  0.01580521 -0.02197879
  -0.07882206 -0.02182122  0.02662229  0.01386111  0.02023022 -0.09936408
  -0.11888984  0.0614013   0.11083328  0.0845832  -0.04621455 -0.05265776
   0.04613881  0.03832349  0.04085527  0.03126483  0.06207929 -0.12671186
   0.00226351 -0.09354223 -0.0406781   0.07360682 -0.03891364 -0.02242498
  -0.06151602  0.04753417  0.24473336 -0.04074768 -0.16315025 -0.05427453
  -0.00890956 -0.01630435 -0.09294572 -0.00868949  0.19637372 -0.08324252
   0.01850979 -0.11110859  0.05008442 -0.07220811  0.02415819  0.13682297
  -0.0041427   0.0166357  -0.05341569  0.04540223 -0.11471643 -0.09860507
   0.04452225  0.04793831 -0.04957315  0.09829976  0.12133905 -0.05386646
   0.09534168 -0.01793967 -0.06761907  0.03812124  0.132524   -0.0706605
  -0.01087396  0.03467306  0.10220462 -0.09204117  0.04721215 -0.07193589
   0.0101089  -0.00454387 -0.05550376  0.10588833  0.11969295 -0.04755495
  -0.0620767  -0.01345908 -0.0377834  -0.02612904 -0.02592834  0.07901437
  -0.01393157  0.02909781 -0.00433908  0.08009194  0.08591523  0.02517789
  -0.04461626  0.11218151 -0.0795702  -0.0165092  -0.04331668  0.07715876
   0.03871704 -0.05063918  0.05659667  0.03891844 -0.11001623  0.04138292
   0.01490956  0.00746582 -0.10567071  0.0554011   0.05408975  0.05335561
   0.13717811 -0.05068496  0.04304296 -0.07229739]]
After layer encoder_birnn_reverse_l0_t0_slice_output3 (1, 256) <class 'numpy.float32'> [[  3.01440097e-02   7.18622506e-02   2.35459805e-02   7.00257644e-02
    7.12479651e-02   1.34077609e-01   4.00202870e-02   1.35312185e-01
    1.56419754e-01   5.33180684e-02  -4.86415401e-02   1.32357538e-01
    3.96635346e-02   4.04861867e-02   1.07052356e-01   8.99878889e-03
   -3.14326361e-02   2.35614609e-02  -9.00294185e-02   8.12320188e-02
    7.39020556e-02   9.18212906e-03   8.25071707e-02  -3.66817564e-02
    4.07631993e-02  -4.95701730e-02   7.62112886e-02   3.77281308e-02
    5.75848036e-02   7.40074068e-02  -4.31433916e-02   9.44847614e-03
   -2.21628770e-02   6.85668141e-02   3.92830186e-02  -8.24115425e-03
    1.63801126e-02   8.89389366e-02   3.27481776e-02   1.95877880e-01
    2.06422880e-01   1.61382243e-01   8.16934034e-02   2.20349059e-03
    4.66819890e-02   5.87329306e-02   7.56326467e-02   2.32447684e-03
    6.85575753e-02   4.85073403e-02   1.10176645e-01  -1.30629465e-02
    1.10012941e-01   1.19076714e-01   1.37476325e-01   5.00640869e-02
   -2.38427520e-02   6.49273545e-02   7.93870687e-02   5.19965887e-02
    4.91109267e-02   1.31518170e-01   8.15919787e-02   4.70471494e-02
    5.19482121e-02   1.13688782e-02   1.63529530e-01  -4.82356921e-03
    1.29147932e-01   1.71280071e-01   1.22214012e-01  -1.49949621e-02
   -3.21728736e-02   1.17004059e-01   2.25362480e-02   1.50763020e-01
    2.78701037e-02  -4.79527563e-03   1.15161061e-01   7.81874210e-02
    7.37830997e-03   5.64602427e-02  -2.60148831e-02   4.32199091e-02
    3.66935730e-02   8.29109922e-03  -5.97491264e-02   8.86140540e-02
    1.19099841e-02   2.09932894e-01   1.52271688e-01   6.87451661e-02
   -1.47192702e-02   1.06617965e-01   3.07133570e-02   8.83538723e-02
    6.83264956e-02   8.55548233e-02   1.01449415e-02   3.70051339e-03
    4.59476821e-02   9.05625802e-03   4.81134653e-02   2.08537020e-02
    1.40772521e-01   6.39614612e-02   8.95057991e-03   1.10898301e-01
    1.39246792e-01   9.07806605e-02   8.67656097e-02   1.63637355e-01
    4.09073532e-02   1.27716705e-01   4.39478792e-02   4.17845324e-02
    4.58887927e-02   3.93485129e-02   2.04369456e-01   5.89347668e-02
    4.63701561e-02   2.96393111e-02   1.07546359e-01   9.79857221e-02
    4.64086533e-02   8.89280625e-03  -6.96256757e-05  -5.82342520e-02
    1.33217365e-01   2.24522687e-02   8.19051266e-02   2.32504696e-01
   -3.37572731e-02   5.74978516e-02   1.17108740e-01   7.40942210e-02
    8.33308622e-02   4.56028506e-02   5.16583323e-02   6.36422560e-02
    5.33279553e-02   7.84548223e-02   1.39921248e-01   1.07542023e-01
    4.35328856e-02   9.55768228e-02   9.75014120e-02   9.11009535e-02
   -1.71164945e-02   1.04801446e-01   9.49664265e-02  -3.09957229e-02
    3.80308367e-02   7.81829208e-02   4.63400632e-02   8.43085498e-02
    7.53939673e-02   1.91996396e-01   1.32433951e-01   6.03084490e-02
    8.04336518e-02   8.37200209e-02   1.01652592e-01   8.47616196e-02
    8.29661414e-02  -8.14349800e-02   6.85336888e-02  -2.10624002e-03
    1.80402398e-01   5.21503426e-02   7.16446415e-02   3.92836183e-02
    8.74565467e-02   1.26072899e-01   7.44709671e-02   6.73123002e-02
    3.84469889e-02   7.68903177e-03   6.54896721e-02   5.51087409e-03
   -1.17048994e-03   2.43097991e-02  -5.12299016e-02   1.24356136e-01
    1.54567569e-01  -1.34499893e-02   7.90441558e-02   1.52698625e-02
    3.40812445e-01   1.09907970e-01   1.02140978e-01  -7.87079930e-02
    7.85682797e-02   1.21114969e-01   3.33287865e-01  -1.69146918e-02
   -9.07656923e-03   1.14252768e-01   3.20039093e-02  -6.95472956e-03
    3.68840359e-02   1.67707071e-01   8.67215991e-02   1.57984607e-02
    1.09744787e-01   1.01210110e-01   3.45034562e-02   5.21696173e-02
    4.60333712e-02   5.79363294e-02   2.44169891e-01   8.67014676e-02
    2.39539742e-02   6.89699650e-02   8.54474455e-02   4.92554680e-02
    3.58570144e-02   1.04054324e-01   5.55794761e-02   1.53472617e-01
    5.73662147e-02   8.86545628e-02   4.27456796e-02   3.12277209e-02
    6.83523715e-02  -5.76770604e-02   8.11945051e-02   6.40129298e-02
    2.11624250e-01   2.31859773e-01  -1.29363313e-03   5.87581992e-02
    3.13339196e-02   6.81949928e-02   9.14535001e-02   4.32499573e-02
    8.28431640e-03  -2.45812573e-02   4.39515114e-02   3.99285629e-02
    7.91482031e-02   8.73978809e-02   2.17614248e-01   2.18022808e-01
    5.93157299e-02   3.19098011e-02   3.22445706e-02   8.90158713e-02
    2.00199947e-01   8.36983323e-04   1.60174258e-02   1.48822069e-01
    8.39023367e-02   8.00382905e-03   1.06270742e-02  -2.91804969e-02]]
After layer encoder_birnn_reverse_l0_t0_o_output (1, 256) <class 'numpy.float32'> [[ 0.50753546  0.51795787  0.50588626  0.51749933  0.51780444  0.53346926
   0.51000375  0.53377652  0.53902543  0.51332635  0.48784205  0.53304112
   0.50991458  0.51012015  0.52673757  0.50224972  0.49214247  0.50589013
   0.47750786  0.52029687  0.51846713  0.50229549  0.5206151   0.4908306
   0.51018941  0.48760998  0.51904362  0.50943089  0.51439226  0.51849341
   0.48921582  0.50236207  0.49445948  0.51713496  0.50981951  0.49793971
   0.50409496  0.52222013  0.50818628  0.54881346  0.55142325  0.54025823
   0.52041203  0.50055087  0.51166838  0.51467901  0.51889914  0.50058109
   0.5171327   0.51212448  0.52751631  0.49673426  0.52747554  0.52973408
   0.53431505  0.5125134   0.49403957  0.51622617  0.51983637  0.51299626
   0.51227528  0.53283221  0.5203867   0.51175964  0.51298416  0.50284219
   0.54079151  0.49879414  0.53224218  0.54271561  0.53051555  0.49625129
   0.49195749  0.52921766  0.50563383  0.53761953  0.50696707  0.49880114
   0.52875847  0.51953691  0.50184458  0.51411128  0.49349666  0.51080328
   0.50917238  0.50207281  0.48506716  0.52213901  0.50297749  0.55229133
   0.53799456  0.51717955  0.49632022  0.52662927  0.50767773  0.5220741
   0.517075    0.52137566  0.50253624  0.50092512  0.51148492  0.50226402
   0.51202607  0.50521326  0.53513515  0.51598489  0.50223762  0.52769619
   0.53475559  0.52267957  0.52167779  0.54081833  0.51022542  0.53188586
   0.5109852   0.51044464  0.5114702   0.5098359   0.5509153   0.51472944
   0.51159048  0.50740927  0.52686071  0.52447689  0.51160008  0.50222319
   0.4999826   0.48544556  0.53325516  0.50561279  0.52046484  0.55786574
   0.4915615   0.5143705   0.52924377  0.51851511  0.52082068  0.51139873
   0.51291174  0.5159052   0.51332879  0.51960367  0.53492337  0.52685964
   0.51088148  0.52387601  0.52435607  0.5227595   0.49572095  0.52617639
   0.52372378  0.49225163  0.50950658  0.51953578  0.51158291  0.5210647
   0.5188396   0.54785222  0.53306019  0.51507252  0.52009755  0.52091777
   0.52539128  0.52117777  0.52072966  0.47965249  0.51712668  0.49947342
   0.54497868  0.51303464  0.51790351  0.50981963  0.52185023  0.53147656
   0.51860917  0.51682174  0.50961059  0.50192231  0.5163666   0.50137776
   0.4997074   0.50607717  0.48719531  0.53104907  0.53856516  0.49663758
   0.51975077  0.50381738  0.58438784  0.52744937  0.52551305  0.48033315
   0.51963198  0.53024185  0.58255911  0.49577141  0.49773082  0.52853221
   0.50800031  0.49826133  0.50922     0.54182881  0.52166682  0.50394952
   0.52740866  0.52528095  0.50862503  0.51303947  0.51150632  0.51447999
   0.56074101  0.52166182  0.50598818  0.5172357   0.52134889  0.5123114
   0.50896329  0.52599013  0.51389128  0.53829306  0.5143376   0.52214915
   0.51068479  0.5078063   0.51708144  0.48558471  0.52028751  0.51599777
   0.55270952  0.55770665  0.49967656  0.51468533  0.50783283  0.51704216
   0.52284741  0.51081079  0.50207108  0.493855    0.51098615  0.5099808
   0.5197767   0.52183557  0.55418986  0.55429083  0.51482457  0.50797677
   0.50806046  0.52223927  0.54988348  0.50020921  0.5040043   0.53713697
   0.52096331  0.50200093  0.50265676  0.4927054 ]]
After layer encoder_birnn_reverse_l0_t0_f_output (1, 256) <class 'numpy.float32'> [[ 0.53835273  0.52532321  0.52501631  0.51129967  0.52732867  0.52447128
   0.51614487  0.52387303  0.56635529  0.51057863  0.48654726  0.5075404
   0.50635743  0.51555073  0.50075549  0.528871    0.5093286   0.51401234
   0.52210987  0.5069375   0.52143288  0.51375628  0.55766755  0.51783299
   0.52075416  0.52024353  0.51462305  0.49450099  0.51269251  0.50913548
   0.50038105  0.50841916  0.50793546  0.51880169  0.51297259  0.49298203
   0.48819426  0.49338007  0.52113932  0.51669425  0.51561254  0.52633339
   0.51310748  0.49666968  0.50884348  0.4993867   0.51102358  0.52479494
   0.51896447  0.50614148  0.51933336  0.52000695  0.53178853  0.5468964
   0.52776325  0.49698207  0.51403332  0.50778854  0.51066661  0.52780515
   0.50872767  0.51633358  0.50801039  0.5180831   0.51415396  0.48548084
   0.53605568  0.52078879  0.51146948  0.52356601  0.49784657  0.52281392
   0.50948018  0.49267328  0.51085436  0.55299455  0.50029832  0.51622528
   0.50601804  0.50716972  0.52101147  0.50839013  0.50908899  0.51467121
   0.53004974  0.50838143  0.51661181  0.50857657  0.49747461  0.53903002
   0.5493893   0.50518656  0.4903253   0.5116204   0.50440121  0.51824176
   0.50633538  0.54842967  0.51542497  0.53156525  0.52131808  0.50320923
   0.50945312  0.51419604  0.50547439  0.51755983  0.51249713  0.5277698
   0.53095233  0.53419077  0.49896964  0.50435168  0.5023092   0.51176554
   0.52134198  0.51928979  0.50575405  0.50308913  0.54295021  0.52165788
   0.53874564  0.50388986  0.50279433  0.51048619  0.50811809  0.51405495
   0.49402943  0.49876091  0.51969522  0.50337481  0.51451701  0.54468274
   0.53544968  0.50468659  0.50408614  0.50000983  0.50103676  0.52270305
   0.5024004   0.4887647   0.51272619  0.51371044  0.51413542  0.5160349
   0.50185919  0.52825981  0.49604195  0.53486437  0.50935549  0.52700853
   0.51666492  0.48985493  0.50093299  0.4685587   0.51552981  0.49335581
   0.52006048  0.52839816  0.52158743  0.53079164  0.52898216  0.49505255
   0.52519846  0.53570616  0.52149391  0.51221746  0.52113545  0.49462181
   0.52714294  0.52873701  0.50995594  0.51747137  0.52180642  0.52903217
   0.53373164  0.50103629  0.51739132  0.48405147  0.53067154  0.52538496
   0.49263138  0.53036875  0.52299619  0.50177038  0.5087539   0.51023
   0.52475941  0.52824193  0.54643774  0.52001131  0.49316207  0.4934181
   0.50445968  0.51477909  0.55774361  0.52399546  0.53053677  0.53198427
   0.50831783  0.50959897  0.50102234  0.52006125  0.53966641  0.5140447
   0.49808654  0.52107233  0.48839658  0.50670081  0.50882345  0.51475549
   0.51829815  0.5244599   0.50523019  0.50772625  0.52572137  0.52123857
   0.52562487  0.50676596  0.51748693  0.50452739  0.49058184  0.4975335
   0.48886877  0.4947601   0.5246585   0.49546307  0.512694    0.51045245
   0.53755629  0.5567348   0.51593477  0.51319909  0.51950985  0.50258869
   0.50327587  0.49245244  0.50796592  0.4983111   0.51154757  0.50113082
   0.51612276  0.51907903  0.55451936  0.52663827  0.49916622  0.5018751
   0.52599108  0.49005267  0.538719    0.49948436  0.52453816  0.49130946
   0.50414532  0.52246487  0.50929606  0.51327622]]
After layer encoder_birnn_reverse_l0_begin_state_1_0 (1, 256) <class 'numpy.float32'> [[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
   0.  0.  0.  0.]]
After layer _mul2072_0 (1, 256) <class 'numpy.float32'> [[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
   0.  0.  0.  0.]]
After layer encoder_birnn_reverse_l0_t0_i_output (1, 256) <class 'numpy.float32'> [[ 0.52594769  0.52116579  0.48695239  0.51304281  0.49924529  0.49595585
   0.50392419  0.54535502  0.54558462  0.49654961  0.51339585  0.52214587
   0.52396601  0.50149584  0.52135897  0.51091635  0.49474657  0.50648052
   0.48710656  0.50370133  0.52352476  0.49492252  0.52179503  0.47692987
   0.4914079   0.51468372  0.50838596  0.49488631  0.52461469  0.50398231
   0.51814371  0.5032137   0.49935043  0.5010547   0.49266216  0.50020969
   0.51180583  0.50739533  0.52183241  0.51550859  0.54434699  0.5154348
   0.51574653  0.50055873  0.50941688  0.50475961  0.50946635  0.5149495
   0.48548698  0.51206392  0.50829005  0.49865773  0.54197335  0.52757812
   0.53556466  0.50323391  0.49509391  0.52238309  0.50573921  0.52588803
   0.50110888  0.5101831   0.48719171  0.50730556  0.52829576  0.50329077
   0.51878321  0.49759278  0.52057189  0.55925649  0.52381611  0.51633829
   0.50123686  0.49323213  0.50769222  0.53459138  0.51730603  0.51675749
   0.51666844  0.51207715  0.50925076  0.51671803  0.49747533  0.50088584
   0.52474332  0.52634442  0.52677637  0.5344457   0.47999832  0.55474341
   0.53787357  0.52717316  0.50367832  0.49843907  0.51726788  0.52392268
   0.52949023  0.53517789  0.48131743  0.51609677  0.51360887  0.50911778
   0.51877898  0.51540226  0.53387308  0.52770323  0.49272433  0.4931877
   0.5020445   0.5272606   0.51146674  0.52464038  0.51431054  0.50223321
   0.52270162  0.55384111  0.48419049  0.49659771  0.55206293  0.53341287
   0.51771456  0.5119437   0.51441985  0.52360231  0.5169735   0.50546753
   0.51540005  0.53329706  0.49197859  0.48506182  0.52764809  0.55355924
   0.50407875  0.49840921  0.51884425  0.50484794  0.48203924  0.50653267
   0.49506775  0.48559991  0.52131897  0.5028491   0.51153368  0.50149667
   0.5284726   0.50515002  0.5261755   0.50725502  0.5104441   0.49934259
   0.50103915  0.51369101  0.51376694  0.49732921  0.50877959  0.53074878
   0.49472317  0.52369982  0.51926368  0.49672404  0.49850529  0.50008929
   0.51342154  0.50109738  0.49676546  0.52140141  0.51523757  0.50788468
   0.50413835  0.48759276  0.5065732   0.50790393  0.51791692  0.55795264
   0.52022123  0.53613514  0.50142062  0.51807094  0.52458471  0.52069181
   0.50594413  0.50907069  0.50824744  0.51856059  0.53107166  0.50473058
   0.51256883  0.51113248  0.57058793  0.52320337  0.51175505  0.49069393
   0.47065207  0.49542457  0.56540412  0.5117237   0.50810122  0.52364874
   0.50707155  0.52302665  0.5265519   0.52362579  0.52274752  0.50843924
   0.50167412  0.50375074  0.51706433  0.4923248   0.51989686  0.51303756
   0.50312865  0.53542536  0.50024587  0.49826664  0.53197962  0.52925944
   0.51171261  0.51574695  0.51981473  0.53063148  0.49875456  0.53423226
   0.5188449   0.51381773  0.51473767  0.49163201  0.51610953  0.53117323
   0.51476157  0.56680149  0.49577335  0.50537682  0.49015135  0.5091064
   0.50371999  0.51357293  0.52426481  0.49427593  0.53616875  0.48692277
   0.51671219  0.50162983  0.55729961  0.54355127  0.49636212  0.50573719
   0.51356107  0.52905941  0.52372545  0.5271982   0.52631623  0.54046255
   0.50830966  0.51882082  0.48372778  0.49152452]]
After layer encoder_birnn_reverse_l0_t0_c_output (1, 256) <class 'numpy.float32'> [[-0.11146596 -0.04423515 -0.06143077 -0.10692659  0.00270574 -0.19276714
   0.05917015  0.02553032 -0.04295116 -0.11493198 -0.03564748  0.07733394
   0.07281274 -0.09552115  0.08153363 -0.04924942  0.04849901  0.04015727
   0.06638476 -0.03124018  0.06273099 -0.11860428  0.02109373  0.09279026
   0.01397234 -0.00252778 -0.19021982 -0.01654591  0.01693892 -0.07486719
   0.0517871  -0.0588144   0.06357234 -0.03544101  0.04464878 -0.0067547
  -0.1571985  -0.02070565 -0.10259082 -0.00459491  0.02786204  0.02356797
   0.11091164  0.01128831  0.12494493 -0.088204    0.08952619 -0.07313762
  -0.01211898 -0.1467123  -0.14482409 -0.05291103  0.03125884  0.07200764
  -0.00949214  0.05343298 -0.10553442  0.11477652  0.03613316 -0.12001357
  -0.0839413  -0.01833935 -0.05545254 -0.09021194  0.12137694 -0.0938433
   0.08449329 -0.00147788 -0.10910106 -0.0577672  -0.14239569  0.04815346
   0.02604077 -0.07009424  0.01822296 -0.08785775 -0.0679213  -0.09088152
  -0.03692625 -0.04058481 -0.10411114 -0.02436046 -0.07006974 -0.12171146
  -0.08344934  0.07108434 -0.04894507  0.05309192 -0.04169403 -0.12622143
   0.09430399  0.00394682  0.05103777 -0.05384848  0.05623547 -0.00469377
   0.04179331  0.06825416  0.0254148   0.03073124  0.04624132  0.0850677
  -0.13742267  0.05638663 -0.05809248  0.02508704 -0.02140519 -0.12693191
   0.09582028 -0.01370394  0.103333    0.20019966 -0.00484088  0.06033356
  -0.04630908 -0.01913565 -0.05823949 -0.12391378  0.00138667  0.07168267
   0.04087481  0.07897667 -0.06134643 -0.03884724  0.11653986 -0.09569652
  -0.05791177 -0.01800935  0.08460744  0.16091916  0.08937945  0.09328783
   0.00637169  0.08995004  0.02738206  0.07171346  0.05058529 -0.01650106
   0.06883412  0.13559584 -0.10178246 -0.02746098  0.05561725 -0.09181221
  -0.12737727  0.07336695  0.15461308 -0.09678982  0.01580389 -0.02197525
  -0.07865923 -0.02181776  0.026616    0.01386022  0.02022746 -0.09903836
  -0.11833283  0.06132425  0.11038168  0.08438206 -0.04618168 -0.05260915
   0.0461061   0.03830474  0.04083255  0.03125465  0.06199967 -0.12603803
   0.0022635  -0.09327035 -0.04065567  0.07347418 -0.03889401 -0.02242122
  -0.06143855  0.0474984   0.23996159 -0.04072514 -0.16171792 -0.0542213
  -0.00890933 -0.0163029  -0.09267899 -0.00868927  0.19388783 -0.08305078
   0.01850767 -0.11065362  0.05004258 -0.07208287  0.02415349  0.13597552
  -0.00414267  0.01663417 -0.05336495  0.04537106 -0.11421585 -0.09828674
   0.04449286  0.04790163 -0.04953258  0.09798437  0.12074704 -0.05381442
   0.09505384 -0.01793775 -0.0675162   0.03810278  0.13175359 -0.07054314
  -0.01087353  0.03465917  0.10185023 -0.09178214  0.04717711 -0.07181206
   0.01010856 -0.00454383 -0.05544683  0.10549435  0.11912462 -0.04751913
  -0.06199708 -0.01345827 -0.03776543 -0.02612309 -0.02592253  0.07885034
  -0.01393067  0.02908961 -0.00433906  0.07992112  0.08570446  0.02517257
  -0.04458668  0.11171328 -0.0794027  -0.0165077  -0.04328961  0.077006
   0.0386977  -0.05059594  0.05653631  0.03889881 -0.1095745   0.04135931
   0.01490845  0.00746569 -0.10527914  0.05534449  0.05403706  0.05330504
   0.13632408 -0.0506416   0.0430164  -0.0721717 ]]
After layer _mul2073_0 (1, 256) <class 'numpy.float32'> [[-0.05862527 -0.02305385 -0.02991386 -0.05485792  0.00135083 -0.095604
   0.02981727  0.01392309 -0.02343349 -0.05706943 -0.01830127  0.0403796
   0.0381514  -0.04790346  0.04250829 -0.02516233  0.02399472  0.02033887
   0.03233645 -0.01573572  0.03284123 -0.05869993  0.01100661  0.04425445
   0.00686612 -0.00130101 -0.09670509 -0.00818835  0.00888641 -0.03773174
   0.02683316 -0.02959621  0.03174488 -0.01775789  0.02199676 -0.00337877
  -0.08045511 -0.01050595 -0.05353522 -0.00236872  0.01516662  0.01214775
   0.0572023   0.00565046  0.06364905 -0.04452182  0.04561058 -0.03766218
  -0.0058836  -0.07512607 -0.07361265 -0.02638449  0.01694146  0.03798966
  -0.00508366  0.02688929 -0.05224945  0.05995731  0.01827395 -0.0631137
  -0.04206373 -0.00935643 -0.02701602 -0.04576502  0.06412292 -0.04723046
   0.0438337  -0.00073538 -0.05679494 -0.03230668 -0.07458916  0.02486347
   0.01305259 -0.03457273  0.00925166 -0.046968   -0.0351361  -0.04696371
  -0.01907863 -0.02078256 -0.05301867 -0.01258749 -0.03485797 -0.06096354
  -0.04378948  0.03741485 -0.02578311  0.02837475 -0.02001307 -0.07002051
   0.05072362  0.00208066  0.02570662 -0.02684018  0.0290888  -0.00245917
   0.02212915  0.03652811  0.01223259  0.01586029  0.02374995  0.04330948
  -0.07129199  0.0290618  -0.03101401  0.01323851 -0.01054686 -0.06260125
   0.04810604 -0.00722555  0.05285139  0.10503283 -0.00248972  0.03030152
  -0.02420583 -0.01059811 -0.02819901 -0.0615353   0.00076553  0.03823646
   0.02116148  0.04043161 -0.03155782 -0.02034051  0.06024802 -0.04837148
  -0.02984773 -0.00960433  0.04162505  0.07805574  0.0471609   0.05164034
   0.00321183  0.04483193  0.01420703  0.03620439  0.0243841  -0.00835833
   0.03407755  0.06584533 -0.05306113 -0.01380873  0.0284501  -0.04604352
  -0.0673154   0.03706132  0.08135361 -0.04909712  0.008067   -0.01097318
  -0.03941135 -0.01120759  0.01367442  0.00689309  0.01029132 -0.05256449
  -0.05854199  0.0321155   0.0573172   0.0419146  -0.02302181 -0.02630927
   0.02367186  0.0191944   0.0202842   0.01629622  0.03194456 -0.06401279
   0.00114112 -0.04547795 -0.02059507  0.03731782 -0.02014386 -0.01250998
  -0.03196163  0.02546556  0.12032169 -0.02109851 -0.08483475 -0.02823259
  -0.00450762 -0.00829933 -0.04710386 -0.00450591  0.10296834 -0.04191827
   0.00948646 -0.05655866  0.02855369 -0.037714    0.01236067  0.06672236
  -0.00194976  0.00824098 -0.03017276  0.02321745 -0.05803321 -0.05146773
   0.02256106  0.02505383 -0.02608148  0.05130714  0.06312022 -0.02736137
   0.04768605 -0.00903615 -0.03491022  0.01875895  0.06849828 -0.03619128
  -0.00547079  0.0185574   0.05095016 -0.04573198  0.02509726 -0.03800721
   0.00517268 -0.00234347 -0.02882208  0.05597862  0.05941395 -0.02538625
  -0.03216687 -0.0069151  -0.01943929 -0.01284295 -0.01337886  0.04188319
  -0.00717097  0.01648803 -0.00215119  0.04039028  0.04200816  0.01281552
  -0.0224592   0.05737292 -0.04162804 -0.00815936 -0.02321054  0.03749598
   0.01999558 -0.02538043  0.03150767  0.0211435  -0.05438863  0.02091694
   0.0076564   0.00394979 -0.05513737  0.02917752  0.02844058  0.02880938
   0.06929485 -0.02627392  0.02080823 -0.03547416]]
After layer encoder_birnn_reverse_l0_t0_state_0 (1, 256) <class 'numpy.float32'> [[-0.05862527 -0.02305385 -0.02991386 -0.05485792  0.00135083 -0.095604
   0.02981727  0.01392309 -0.02343349 -0.05706943 -0.01830127  0.0403796
   0.0381514  -0.04790346  0.04250829 -0.02516233  0.02399472  0.02033887
   0.03233645 -0.01573572  0.03284123 -0.05869993  0.01100661  0.04425445
   0.00686612 -0.00130101 -0.09670509 -0.00818835  0.00888641 -0.03773174
   0.02683316 -0.02959621  0.03174488 -0.01775789  0.02199676 -0.00337877
  -0.08045511 -0.01050595 -0.05353522 -0.00236872  0.01516662  0.01214775
   0.0572023   0.00565046  0.06364905 -0.04452182  0.04561058 -0.03766218
  -0.0058836  -0.07512607 -0.07361265 -0.02638449  0.01694146  0.03798966
  -0.00508366  0.02688929 -0.05224945  0.05995731  0.01827395 -0.0631137
  -0.04206373 -0.00935643 -0.02701602 -0.04576502  0.06412292 -0.04723046
   0.0438337  -0.00073538 -0.05679494 -0.03230668 -0.07458916  0.02486347
   0.01305259 -0.03457273  0.00925166 -0.046968   -0.0351361  -0.04696371
  -0.01907863 -0.02078256 -0.05301867 -0.01258749 -0.03485797 -0.06096354
  -0.04378948  0.03741485 -0.02578311  0.02837475 -0.02001307 -0.07002051
   0.05072362  0.00208066  0.02570662 -0.02684018  0.0290888  -0.00245917
   0.02212915  0.03652811  0.01223259  0.01586029  0.02374995  0.04330948
  -0.07129199  0.0290618  -0.03101401  0.01323851 -0.01054686 -0.06260125
   0.04810604 -0.00722555  0.05285139  0.10503283 -0.00248972  0.03030152
  -0.02420583 -0.01059811 -0.02819901 -0.0615353   0.00076553  0.03823646
   0.02116148  0.04043161 -0.03155782 -0.02034051  0.06024802 -0.04837148
  -0.02984773 -0.00960433  0.04162505  0.07805574  0.0471609   0.05164034
   0.00321183  0.04483193  0.01420703  0.03620439  0.0243841  -0.00835833
   0.03407755  0.06584533 -0.05306113 -0.01380873  0.0284501  -0.04604352
  -0.0673154   0.03706132  0.08135361 -0.04909712  0.008067   -0.01097318
  -0.03941135 -0.01120759  0.01367442  0.00689309  0.01029132 -0.05256449
  -0.05854199  0.0321155   0.0573172   0.0419146  -0.02302181 -0.02630927
   0.02367186  0.0191944   0.0202842   0.01629622  0.03194456 -0.06401279
   0.00114112 -0.04547795 -0.02059507  0.03731782 -0.02014386 -0.01250998
  -0.03196163  0.02546556  0.12032169 -0.02109851 -0.08483475 -0.02823259
  -0.00450762 -0.00829933 -0.04710386 -0.00450591  0.10296834 -0.04191827
   0.00948646 -0.05655866  0.02855369 -0.037714    0.01236067  0.06672236
  -0.00194976  0.00824098 -0.03017276  0.02321745 -0.05803321 -0.05146773
   0.02256106  0.02505383 -0.02608148  0.05130714  0.06312022 -0.02736137
   0.04768605 -0.00903615 -0.03491022  0.01875895  0.06849828 -0.03619128
  -0.00547079  0.0185574   0.05095016 -0.04573198  0.02509726 -0.03800721
   0.00517268 -0.00234347 -0.02882208  0.05597862  0.05941395 -0.02538625
  -0.03216687 -0.0069151  -0.01943929 -0.01284295 -0.01337886  0.04188319
  -0.00717097  0.01648803 -0.00215119  0.04039028  0.04200816  0.01281552
  -0.0224592   0.05737292 -0.04162804 -0.00815936 -0.02321054  0.03749598
   0.01999558 -0.02538043  0.03150767  0.0211435  -0.05438863  0.02091694
   0.0076564   0.00394979 -0.05513737  0.02917752  0.02844058  0.02880938
   0.06929485 -0.02627392  0.02080823 -0.03547416]]
After layer activation1036_output (1, 256) <class 'numpy.float32'> [[-0.0585582  -0.02304976 -0.02990494 -0.05480295  0.00135083 -0.09531378
   0.02980844  0.01392219 -0.0234292  -0.05700755 -0.01829923  0.04035767
   0.0381329  -0.04786685  0.0424827  -0.02515703  0.02399012  0.02033607
   0.03232519 -0.01573442  0.03282943 -0.0586326   0.01100616  0.04422558
   0.00686601 -0.00130101 -0.09640475 -0.00818816  0.00888618 -0.03771384
   0.02682672 -0.02958757  0.03173422 -0.01775602  0.02199322 -0.00337875
  -0.08028197 -0.01050556 -0.05348413 -0.00236871  0.01516545  0.01214715
   0.05713999  0.0056504   0.06356324 -0.04449243  0.04557898 -0.03764439
  -0.00588354 -0.07498506 -0.07347997 -0.02637837  0.01693984  0.03797139
  -0.00508361  0.02688281 -0.05220196  0.05988557  0.01827192 -0.06303003
  -0.04203894 -0.00935615 -0.02700945 -0.04573309  0.06403518 -0.04719537
   0.04380565 -0.00073538 -0.05673395 -0.03229545 -0.07445114  0.02485835
   0.01305185 -0.03455896  0.00925139 -0.04693349 -0.03512165 -0.04692921
  -0.01907631 -0.02077956 -0.05296905 -0.01258682 -0.03484385 -0.06088813
  -0.04376152  0.0373974  -0.0257774   0.02836714 -0.02001039 -0.0699063
   0.05068017  0.00208065  0.02570096 -0.02683374  0.0290806  -0.00245917
   0.02212553  0.03651188  0.01223198  0.01585896  0.02374549  0.04328242
  -0.07117146  0.02905362 -0.03100407  0.01323774 -0.01054647 -0.0625196
   0.04806897 -0.00722542  0.05280223  0.10464829 -0.00248971  0.03029225
  -0.0242011  -0.01059771 -0.02819153 -0.06145775  0.00076553  0.03821784
   0.02115832  0.04040959 -0.03154735 -0.0203377   0.06017523 -0.04833379
  -0.02983887 -0.00960404  0.04160103  0.0778976   0.04712597  0.05159448
   0.00321182  0.04480192  0.01420607  0.03618858  0.02437926 -0.00835813
   0.03406437  0.06575033 -0.05301139 -0.01380785  0.02844242 -0.046011
  -0.06721391  0.03704436  0.08117461 -0.04905771  0.00806683 -0.01097274
  -0.03939096 -0.01120712  0.01367357  0.00689298  0.01029095 -0.05251613
  -0.05847521  0.03210446  0.05725451  0.04189007 -0.02301775 -0.0263032
   0.02366744  0.01919205  0.02028142  0.01629478  0.0319337  -0.0639255
   0.00114112 -0.04544662 -0.02059216  0.03730051 -0.02014114 -0.01250933
  -0.03195076  0.02546006  0.11974439 -0.02109538 -0.08463182 -0.02822509
  -0.00450759 -0.00829914 -0.04706905 -0.00450588  0.10260597 -0.04189374
   0.00948617 -0.05649843  0.02854594 -0.03769613  0.01236004  0.06662352
  -0.00194975  0.00824079 -0.03016361  0.02321328 -0.05796815 -0.05142233
   0.02255723  0.02504859 -0.02607556  0.05126217  0.06303652 -0.02735454
   0.04764994 -0.00903591 -0.03489605  0.01875675  0.06839135 -0.03617549
  -0.00547073  0.01855527  0.05090612 -0.04570012  0.02509199 -0.03798892
   0.00517263 -0.00234346 -0.0288141   0.05592022  0.05934414 -0.0253808
  -0.03215578 -0.00691499 -0.01943684 -0.01284224 -0.01337807  0.04185872
  -0.00717085  0.01648654 -0.00215119  0.04036833  0.04198347  0.01281482
  -0.02245543  0.05731005 -0.04160401 -0.00815918 -0.02320637  0.03747842
   0.01999291 -0.02537498  0.03149724  0.02114035 -0.05433507  0.02091389
   0.00765625  0.00394977 -0.05508156  0.02916924  0.02843292  0.02880141
   0.06918415 -0.02626787  0.02080522 -0.03545929]]
After layer encoder_birnn_reverse_l0_t0_out_0 (1, 256) <class 'numpy.float32'> [[-0.02972036 -0.01193881 -0.0151285  -0.02836049  0.00069946 -0.05084697
   0.01520241  0.00743134 -0.01262894 -0.02926348 -0.00892713  0.0215123
   0.01944452 -0.02441785  0.02237723 -0.01263511  0.01180655  0.01028782
   0.01543553 -0.00818657  0.01702098 -0.02945089  0.00572997  0.02170727
   0.00350297 -0.00063438 -0.05003827 -0.0041713   0.00457098 -0.01955438
   0.01312406 -0.01486368  0.01569128 -0.00918226  0.01121257 -0.00168242
  -0.04046974 -0.00548622 -0.0271799  -0.00129998  0.00836258  0.0065626
   0.02973634  0.00282831  0.0325233  -0.02289932  0.02365089 -0.01884407
  -0.00304257 -0.03840168 -0.03876188 -0.01310304  0.00893535  0.02011474
  -0.00271625  0.0137778  -0.02578983  0.0309145   0.00949841 -0.03233417
  -0.02153551 -0.00498526 -0.01405536 -0.02340435  0.03284904 -0.02373183
   0.02368972 -0.00036681 -0.0301962  -0.01752724 -0.03949749  0.01233599
   0.00642096 -0.01828921  0.00467782 -0.02523236 -0.01780552 -0.02340834
  -0.01008676 -0.01079575 -0.02658223 -0.00647103 -0.01719533 -0.03110186
  -0.02228216  0.01877622 -0.01250377  0.01481159 -0.01006478 -0.03860864
   0.02726565  0.00107607  0.01275591 -0.01413143  0.01476357 -0.00128387
   0.01144056  0.0190364   0.00614701  0.00794415  0.01214546  0.0217392
  -0.03644164  0.01467827 -0.01659137  0.00683047 -0.00529683 -0.03299136
   0.02570515 -0.00377658  0.02754575  0.05659572 -0.00127031  0.01611202
  -0.01236641 -0.00540955 -0.01441913 -0.03133336  0.00042174  0.01967184
   0.0108244   0.0205042  -0.01662106 -0.01066665  0.03078565 -0.02427435
  -0.01491891 -0.00466224  0.02218396  0.03938602  0.02452741  0.0287828
   0.00157881  0.02304478  0.00751847  0.01876433  0.01269723 -0.00427434
   0.01747201  0.03392094 -0.02721227 -0.00717461  0.01521452 -0.02424134
  -0.03433834  0.01940665  0.0425644  -0.02564539  0.0039989  -0.0057736
  -0.02062998 -0.00551672  0.00696677  0.00358115  0.00526468 -0.0273643
  -0.03033925  0.0175885   0.0305201   0.02157643 -0.01197147 -0.0137018
   0.01243467  0.01000247  0.01056114  0.00781583  0.01651376 -0.03192909
   0.00062189 -0.02331569 -0.01066475  0.01901653 -0.01051066 -0.00664841
  -0.01656996  0.01315831  0.06102301 -0.01058824 -0.04370104 -0.01415143
  -0.00225248 -0.0042     -0.02293182 -0.00239285  0.05526    -0.020806
   0.00493044 -0.02846489  0.0166819  -0.0198828   0.00649536  0.03200149
  -0.00101315  0.00436961 -0.01757208  0.01150848 -0.02885254 -0.02717836
   0.01145908  0.01248074 -0.0132782   0.02777532  0.03288406 -0.01378531
   0.02513099 -0.00474639 -0.017749    0.00962295  0.03498261 -0.01861157
  -0.00306766  0.00967958  0.02575789 -0.02363773  0.01308168 -0.01946216
   0.00263268 -0.00123264 -0.01480732  0.03010147  0.03052292 -0.01325256
  -0.01642147 -0.00351147 -0.01005043 -0.006236   -0.00696044  0.02159901
  -0.0039634   0.00919465 -0.0010749   0.02077699  0.02132058  0.0066258
  -0.01174076  0.02927459 -0.02088817 -0.00402945 -0.01185813  0.01911327
   0.01039185 -0.01324157  0.01745545  0.0117179  -0.02797303  0.01062377
   0.00388984  0.00206273 -0.03028844  0.01459072  0.01433031  0.0154703
   0.0360424  -0.0131865   0.01045789 -0.01747098]]
After layer expand_dims1042_0 (1, 1, 256) <class 'numpy.float32'> [[[-0.02972036 -0.01193881 -0.0151285  -0.02836049  0.00069946 -0.05084697
    0.01520241  0.00743134 -0.01262894 -0.02926348 -0.00892713  0.0215123
    0.01944452 -0.02441785  0.02237723 -0.01263511  0.01180655  0.01028782
    0.01543553 -0.00818657  0.01702098 -0.02945089  0.00572997  0.02170727
    0.00350297 -0.00063438 -0.05003827 -0.0041713   0.00457098 -0.01955438
    0.01312406 -0.01486368  0.01569128 -0.00918226  0.01121257 -0.00168242
   -0.04046974 -0.00548622 -0.0271799  -0.00129998  0.00836258  0.0065626
    0.02973634  0.00282831  0.0325233  -0.02289932  0.02365089 -0.01884407
   -0.00304257 -0.03840168 -0.03876188 -0.01310304  0.00893535  0.02011474
   -0.00271625  0.0137778  -0.02578983  0.0309145   0.00949841 -0.03233417
   -0.02153551 -0.00498526 -0.01405536 -0.02340435  0.03284904 -0.02373183
    0.02368972 -0.00036681 -0.0301962  -0.01752724 -0.03949749  0.01233599
    0.00642096 -0.01828921  0.00467782 -0.02523236 -0.01780552 -0.02340834
   -0.01008676 -0.01079575 -0.02658223 -0.00647103 -0.01719533 -0.03110186
   -0.02228216  0.01877622 -0.01250377  0.01481159 -0.01006478 -0.03860864
    0.02726565  0.00107607  0.01275591 -0.01413143  0.01476357 -0.00128387
    0.01144056  0.0190364   0.00614701  0.00794415  0.01214546  0.0217392
   -0.03644164  0.01467827 -0.01659137  0.00683047 -0.00529683 -0.03299136
    0.02570515 -0.00377658  0.02754575  0.05659572 -0.00127031  0.01611202
   -0.01236641 -0.00540955 -0.01441913 -0.03133336  0.00042174  0.01967184
    0.0108244   0.0205042  -0.01662106 -0.01066665  0.03078565 -0.02427435
   -0.01491891 -0.00466224  0.02218396  0.03938602  0.02452741  0.0287828
    0.00157881  0.02304478  0.00751847  0.01876433  0.01269723 -0.00427434
    0.01747201  0.03392094 -0.02721227 -0.00717461  0.01521452 -0.02424134
   -0.03433834  0.01940665  0.0425644  -0.02564539  0.0039989  -0.0057736
   -0.02062998 -0.00551672  0.00696677  0.00358115  0.00526468 -0.0273643
   -0.03033925  0.0175885   0.0305201   0.02157643 -0.01197147 -0.0137018
    0.01243467  0.01000247  0.01056114  0.00781583  0.01651376 -0.03192909
    0.00062189 -0.02331569 -0.01066475  0.01901653 -0.01051066 -0.00664841
   -0.01656996  0.01315831  0.06102301 -0.01058824 -0.04370104 -0.01415143
   -0.00225248 -0.0042     -0.02293182 -0.00239285  0.05526    -0.020806
    0.00493044 -0.02846489  0.0166819  -0.0198828   0.00649536  0.03200149
   -0.00101315  0.00436961 -0.01757208  0.01150848 -0.02885254 -0.02717836
    0.01145908  0.01248074 -0.0132782   0.02777532  0.03288406 -0.01378531
    0.02513099 -0.00474639 -0.017749    0.00962295  0.03498261 -0.01861157
   -0.00306766  0.00967958  0.02575789 -0.02363773  0.01308168 -0.01946216
    0.00263268 -0.00123264 -0.01480732  0.03010147  0.03052292 -0.01325256
   -0.01642147 -0.00351147 -0.01005043 -0.006236   -0.00696044  0.02159901
   -0.0039634   0.00919465 -0.0010749   0.02077699  0.02132058  0.0066258
   -0.01174076  0.02927459 -0.02088817 -0.00402945 -0.01185813  0.01911327
    0.01039185 -0.01324157  0.01745545  0.0117179  -0.02797303  0.01062377
    0.00388984  0.00206273 -0.03028844  0.01459072  0.01433031  0.0154703
    0.0360424  -0.0131865   0.01045789 -0.01747098]]]
After layer encoder_birnn_reverse_l0_t1_i2h_output (1, 1024) <class 'numpy.float32'> [[-0.01039116  0.04133883 -0.0070517  ..., -0.01149436 -0.03637818
   0.08443715]]
After layer encoder_birnn_reverse_l0_t1_h2h_output (1, 1024) <class 'numpy.float32'> [[ 0.00782009  0.02443658 -0.00254407 ...,  0.0350127   0.03723258
   0.03427301]]
After layer _plus1037_0 (1, 1024) <class 'numpy.float32'> [[-0.00257108  0.06577541 -0.00959577 ...,  0.02351834  0.00085441
   0.11871016]]
After layer encoder_birnn_reverse_l0_t1_slice_output0 (1, 256) <class 'numpy.float32'> [[-0.00257108  0.06577541 -0.00959577  0.04677904  0.04007455  0.016101
  -0.02854251 -0.01245547 -0.00781808  0.06116382  0.0361966   0.0546452
  -0.05819307  0.02278244  0.0839536   0.0396646  -0.08578742 -0.09781429
   0.03901401 -0.03367627  0.11611208  0.09421302 -0.08797894 -0.02038038
   0.13621375 -0.01259673 -0.0149644  -0.00120383  0.03630868  0.09701416
   0.03317175 -0.06550159  0.17133649  0.05553271  0.08513316  0.08139262
   0.01956449  0.03424381  0.09740292  0.10015208  0.09829895  0.03682959
  -0.03173492  0.02430475  0.02759483  0.03917987  0.11573406 -0.02464039
   0.0271297   0.0127444   0.09355609  0.1367259   0.06120469  0.14256276
   0.1764638   0.0604036  -0.0608133  -0.05571624 -0.05463277  0.044886
   0.04140652  0.00713754 -0.02581098  0.11352599  0.07566582  0.05690012
   0.1485112  -0.06833494  0.15648746  0.07089454  0.08246943 -0.00835417
   0.02300538  0.05606038  0.10082363  0.27755213  0.01084733 -0.00671151
  -0.04157363 -0.01916695  0.04096951  0.0739835   0.00080735  0.03486113
   0.05973672  0.00924873  0.06551929  0.0430389   0.19015364 -0.04544626
   0.10570763 -0.0521892   0.01072186 -0.04370805  0.01040838  0.00826381
  -0.0474178   0.21471298 -0.11479977  0.03022242  0.06549706  0.014811
   0.09816858  0.04975151  0.0531702   0.01310712  0.05574578  0.00642637
   0.08178365  0.06789096 -0.05460645  0.07710046  0.04351582  0.20675445
   0.04333439  0.13616768 -0.03014119 -0.02166843  0.12212346  0.01249334
   0.05177134  0.02822245  0.04398912  0.05807958  0.06611095  0.13023014
  -0.05115709 -0.00300808  0.09236176 -0.10668255  0.13060707  0.24987443
   0.11706866  0.01562862  0.12552541  0.04757348 -0.08149007  0.07745358
  -0.10143542 -0.118341   -0.01408881  0.08081472  0.01470406 -0.09563777
  -0.02900469  0.16806449  0.01403212 -0.01210984  0.0166424   0.04759666
   0.00814297  0.05723907 -0.0250948  -0.02833045  0.01389439  0.2066583
   0.01530172  0.08094282  0.05146473 -0.00144092  0.13001589 -0.00660851
   0.05921864  0.02009006 -0.00383089  0.10423849 -0.03602311  0.05034084
   0.11587419 -0.08345632 -0.00314822  0.11992741  0.07622804  0.13048863
   0.11116473 -0.05551933  0.00859615  0.07300232 -0.01306855 -0.00392698
   0.03623616 -0.01052654  0.04096416 -0.01969412  0.05012513  0.08160197
   0.08057126  0.00466009  0.24660465 -0.00619636 -0.00386356  0.04488334
  -0.05078653 -0.11131772  0.06614107 -0.00622156 -0.04465106 -0.03617623
   0.09823187 -0.05263359  0.04049615  0.2446827   0.10683289  0.00549167
   0.07533488  0.07893565  0.02441371 -0.02158224 -0.01302329  0.08641595
   0.1039316   0.15760949 -0.00662751  0.1517327   0.07284838 -0.07078316
   0.07068677 -0.17494413  0.07064509  0.13285184 -0.02296093 -0.03267324
   0.09442414 -0.01677031 -0.03856348  0.09112361 -0.02150388 -0.03710451
  -0.1188251   0.20528734  0.11230002 -0.050087    0.13522932 -0.0341659
   0.06697809  0.07489084 -0.01656653  0.03850855  0.0067849  -0.02912814
  -0.09594556 -0.0424296   0.19652393  0.23794822  0.01748537 -0.0398483
  -0.03629277  0.00489148  0.07042468  0.05641122  0.02613979 -0.00527121
  -0.03536659  0.0531073   0.02097489  0.10925084]]
After layer encoder_birnn_reverse_l0_t1_slice_output1 (1, 256) <class 'numpy.float32'> [[ -1.70011818e-02   3.21394280e-02   8.39441866e-02   5.90085648e-02
    8.38349909e-02   5.30189574e-02   1.19749017e-01  -6.80370927e-02
    1.65840179e-01   6.02105111e-02   6.70655668e-02   1.62028924e-01
    4.03915420e-02   9.93996561e-02   5.94930165e-02   1.43139198e-01
    7.72814751e-02   1.44070104e-01   5.89984246e-02   1.04506776e-01
    1.41377360e-01   1.77096203e-03   3.03895473e-01   8.36402327e-02
   -1.89346783e-02   9.48904604e-02   1.63144208e-02   1.50301084e-02
    8.12225863e-02  -4.12056670e-02   7.50820264e-02   7.26111606e-02
    1.38160884e-01   3.20950449e-02  -2.72082165e-03  -4.87799160e-02
    8.87899995e-02   1.76312402e-01   1.60612352e-02   5.78646362e-02
   -2.70603262e-02   6.45285249e-02   1.23560064e-01   1.60455123e-01
    4.87058796e-02   2.03364734e-02   1.07382730e-01   8.19192156e-02
    1.36335716e-02   5.09445071e-02   6.30919263e-02   7.27224723e-02
    5.93811683e-02   9.83797610e-02   1.58738941e-01   2.01577526e-02
    2.17990950e-03   6.59721196e-02   2.88333111e-02   6.65382072e-02
    4.63986881e-02   1.20880030e-01   5.88351674e-03   4.04988267e-02
    6.76573664e-02   1.41561836e-01   2.00618833e-01   9.48857367e-02
   -4.43206280e-02   8.13922584e-02   1.07250199e-01   6.72027022e-02
    3.42244245e-02  -3.06143984e-02   1.28583685e-01   1.55341223e-01
    8.32692832e-02  -1.34991109e-03   6.84812665e-02   1.04442015e-01
    4.52824719e-02   1.01864174e-01  -3.23231779e-02  -2.85616405e-02
    1.04056150e-02   1.17175415e-01   3.44259739e-02   7.52711743e-02
    1.09154448e-01  -4.96807694e-03   2.06750631e-01   9.48638320e-02
    7.22006559e-02   6.54840693e-02   7.43037090e-02  -6.21161759e-02
    1.09591521e-02   1.53462008e-01  -2.70656385e-02   3.37145701e-02
    1.12482607e-02   4.60138805e-02   2.27170754e-02   1.41802400e-01
    1.39382295e-03  -3.76804657e-02   1.44341476e-02   1.13886058e-01
    7.49726593e-03   7.47245550e-03   7.95217007e-02   5.63184470e-02
    4.09141630e-02   1.26580894e-01   5.98154552e-02   9.69579220e-02
    2.95385439e-02   1.82849355e-03   5.71107902e-02   1.71059668e-02
    1.44302770e-01   2.46697828e-01   7.03831315e-02   5.62138073e-02
   -1.51525065e-02   7.53651410e-02   4.61772010e-02   4.51925471e-02
    1.08614881e-02  -2.22247541e-02   1.23290479e-01   1.49970263e-01
    5.47820330e-02   1.64244920e-02   1.11123458e-01   9.00620222e-02
    1.58032373e-01   7.91864246e-02   6.26339689e-02   7.10935891e-02
    1.91519670e-02   1.10626787e-01   1.06053159e-01   7.32569546e-02
    1.20932069e-02   2.78679617e-02  -4.85884026e-02   5.17381132e-02
    6.36200234e-02   4.96522598e-02   8.91247243e-02   7.14097470e-02
    1.58358157e-01   8.15803707e-02   4.93065082e-02   1.33677632e-01
    5.09053022e-02   2.51132995e-04   5.03871515e-02   1.42763168e-01
    4.78750467e-02   5.37100956e-02   4.80025932e-02   1.51989967e-01
   -3.36686969e-02   5.61100021e-02   3.31475317e-01   2.90654339e-02
   -1.15925401e-01   4.49299775e-02   1.20802596e-01   8.53483751e-02
    4.34119180e-02   1.93693385e-01   5.02183661e-02   2.02781931e-02
    7.59903044e-02   2.99692713e-02   7.52401724e-03  -3.87664512e-03
   -1.93881132e-02   1.03008948e-01   8.56131464e-02   9.16012563e-04
    5.79380728e-02  -4.93390113e-02   5.39757162e-02   6.01672307e-02
    4.95702177e-02  -4.38345149e-02   9.57906470e-02   7.46727437e-02
    1.08430088e-01   2.90622972e-02   1.52320981e-01  -4.10067551e-02
    2.38038879e-02   4.78201136e-02   6.26145452e-02   1.81132127e-02
    9.60763842e-02   4.62485962e-02   8.33828598e-02   1.30663648e-01
    4.77860570e-02   4.99273911e-02   1.67621188e-02   1.42001167e-01
    6.08962029e-03   1.06666371e-01   7.58641064e-02   1.65319294e-01
   -7.04597309e-03   1.08163059e-01  -4.84031141e-02   2.09589787e-02
    2.14819685e-01   4.80160788e-02   1.33453220e-01   1.08685851e-01
   -2.89923698e-02  -1.96803510e-02   1.42128646e-01   6.69491440e-02
    7.50431716e-02   9.16963741e-02   4.70920801e-02   3.39143649e-02
    2.11530179e-01   1.16531447e-01   1.43631985e-02   3.48837227e-02
    7.18641579e-02   3.06208041e-02  -6.92729950e-02   1.51879340e-01
    8.70479196e-02   9.40439105e-02   5.45801520e-02   8.39397162e-02
    1.51870698e-02   1.88165635e-01   1.71367049e-01   1.35885090e-01
   -5.83420619e-02   3.20693627e-02   8.65912810e-03   9.56282020e-05
    8.10120776e-02   4.77792956e-02   1.40872061e-01   4.28172722e-02
    9.13880616e-02   3.75555791e-02   1.34025812e-01  -4.32949774e-02]]
After layer encoder_birnn_reverse_l0_t1_slice_output2 (1, 256) <class 'numpy.float32'> [[-0.043818   -0.03053785  0.09212522  0.0997157   0.10393573  0.03579435
   0.01154696 -0.00547639 -0.08389361 -0.12125263 -0.05326464  0.00741939
   0.07200736 -0.06318206  0.08303709 -0.11197843 -0.00616627 -0.06112034
  -0.00163195  0.08629753  0.1111819  -0.07363036  0.03714847  0.01382732
   0.02415162  0.00818895 -0.05082891  0.02420515 -0.04588381 -0.0323187
   0.06816176 -0.12135531  0.05028359 -0.0804744   0.03023109 -0.12593409
  -0.01243168 -0.08364686  0.02113257  0.05034724  0.11042619  0.00929075
   0.034241    0.02111734  0.05844216 -0.08939788  0.04060486  0.00631504
  -0.00477927  0.09301721 -0.00460575 -0.07084496 -0.08363029  0.01751881
   0.06969981 -0.06583843 -0.04540664  0.1345166   0.02754058 -0.0714104
  -0.09563169 -0.03660486 -0.01472916  0.01174817  0.14335433 -0.01972143
   0.10231879  0.09741648 -0.02500424  0.00984453 -0.14093651  0.09802771
   0.02683997 -0.04674758  0.1323071   0.01196563 -0.17173286 -0.05071947
  -0.08060609 -0.03758113 -0.00850439 -0.08920942  0.01985065 -0.11178678
  -0.09572749  0.04068251 -0.02401564  0.04195011 -0.04789684  0.03407657
   0.03259443  0.03375766  0.02262379 -0.06236704 -0.05123856 -0.02537277
  -0.011524   -0.11770599 -0.01069422 -0.06254182  0.11566471  0.02448174
  -0.04400967  0.01060313 -0.05121314  0.08760871 -0.02546418  0.02660462
  -0.01970007 -0.01345851  0.0836862   0.01469908  0.02066056  0.07959194
  -0.08111066  0.03228162 -0.05559513 -0.052632    0.09029084  0.0429875
   0.03480656  0.08169588  0.01592194 -0.0925594   0.03266262 -0.11743592
   0.12839785 -0.12416564 -0.0212293   0.10165967  0.06552384 -0.09048329
   0.05000528 -0.15050206  0.06869792  0.05275915  0.08941284  0.12690596
  -0.07082278  0.03850698 -0.00651865 -0.04620966  0.11112268  0.00611995
   0.0567141   0.01631656  0.03928852 -0.07819722  0.01961577  0.04495648
  -0.0167382  -0.0066308  -0.08484694 -0.04464832  0.07244005  0.06057581
  -0.01996109  0.00083308 -0.01550063  0.04133737 -0.20821437 -0.08799718
  -0.04361099 -0.0311304  -0.02816324  0.08925761 -0.04053181 -0.12470634
  -0.16397165 -0.07699661 -0.10235219  0.05184206 -0.01635461 -0.0826419
   0.05622311 -0.01334285  0.08979237 -0.08516533 -0.03544157 -0.02786141
   0.13196838  0.0566617   0.08715047 -0.00692686  0.04475515 -0.05003976
   0.01207967 -0.10046979  0.04951212 -0.00819906  0.21771622  0.05495956
  -0.0646316  -0.00244599 -0.15457585  0.05219488 -0.08962341 -0.10632206
   0.03998497  0.10511573 -0.04322636 -0.09587805  0.08625192 -0.0113334
   0.07535883 -0.03496366  0.02563111 -0.01811251  0.17049831 -0.09430628
   0.02875872  0.08896041  0.02427692  0.02883222 -0.08306082 -0.057039
  -0.02660595 -0.00203387  0.07963085  0.05550529  0.01995796  0.04205641
   0.09781487 -0.07594552  0.01102192  0.00973972  0.02409083 -0.03297581
   0.02185855 -0.00174647 -0.08117945 -0.02392686  0.04761457  0.02022999
  -0.06602402 -0.02242747 -0.03944872  0.04289626 -0.08124737  0.01551775
  -0.01596709 -0.05889609 -0.00160659 -0.12577109 -0.02847121 -0.06094575
  -0.01729388 -0.01470151  0.01666821  0.15087742  0.15750107  0.02301409
  -0.01549059 -0.0034101   0.01485673 -0.09340228]]
After layer encoder_birnn_reverse_l0_t1_slice_output3 (1, 256) <class 'numpy.float32'> [[  6.79234788e-02   1.28993660e-01   2.84681022e-02   1.00801840e-01
    1.15419820e-01   1.70489587e-02   1.35306507e-01   7.55549595e-02
    1.84508473e-01   8.61395672e-02  -5.32423239e-03   5.07833846e-02
    9.16200280e-02   2.73194537e-02   6.69472218e-02   4.03990075e-02
    5.02404347e-02   6.90777078e-02   2.57413574e-02   9.19633508e-02
   -3.83637995e-02   3.67165618e-02   2.75966883e-01   6.27542585e-02
    3.83133590e-02   8.58506709e-02   1.10923126e-01  -7.06864521e-04
    3.26509513e-02   1.29231811e-01   5.25582656e-02   5.77585362e-02
    2.01439291e-01   3.05541251e-02   6.67285100e-02   4.04373407e-02
    1.05318651e-02   6.46963343e-02  -2.10267175e-02   2.99456716e-03
    1.86444327e-01   4.97563817e-02   4.36680317e-02  -1.58618242e-02
   -4.69578803e-03   1.04732536e-01   1.37490243e-01   1.37854479e-02
    8.43295082e-03   2.72386633e-02   3.33323628e-02   2.39222925e-02
   -5.05339727e-02   1.15276515e-01   1.32565349e-01   3.38858552e-02
   -7.78373182e-02   5.04520126e-02  -3.04903090e-03   1.22190014e-01
    8.96590650e-02   1.08188376e-01   2.18390860e-02   1.10123619e-01
    7.63010085e-02   6.67866096e-02   3.07251334e-01   9.86118615e-02
    7.43005648e-02   1.90554589e-01  -1.75583959e-02   2.18858384e-02
    1.74330492e-02   1.60166994e-02   6.74565285e-02   1.75489560e-01
    9.58503336e-02  -8.49597156e-04   5.27457856e-02   6.79434538e-02
    3.68990377e-02   9.97407883e-02   8.96838307e-02   3.17427777e-02
    8.72789174e-02   7.51471370e-02   4.50499654e-02   7.39584342e-02
    1.22927800e-01   7.29851872e-02   1.55476674e-01  -1.30455252e-02
    1.26413694e-02  -9.22049582e-03  -1.68777425e-02   9.67852026e-02
    2.16840822e-02   2.36754909e-01   9.53515992e-04  -7.14347139e-03
    1.33019060e-01  -4.96798232e-02   3.05769388e-02  -3.77365574e-03
    3.50251868e-02   6.49926439e-02  -4.22322340e-02   8.64032581e-02
    3.11951712e-02   8.25024471e-02   9.76212323e-04   6.39752671e-02
   -7.41849095e-03   8.64357352e-02   5.57697490e-02   8.85451585e-02
   -6.56716079e-02   4.14657630e-02   1.24271259e-01   4.99806814e-02
    6.01012409e-02  -1.71295330e-02  -9.69325565e-03   8.71274322e-02
    4.29800823e-02   1.77006051e-03   9.25524533e-02  -3.10243405e-02
    2.99229287e-02   1.60518549e-02   8.97307247e-02   2.75688618e-01
    7.40814880e-02   1.22179568e-01   1.12243891e-01   7.53730163e-03
    5.73219731e-02   3.64978239e-02  -4.67253849e-03  -2.78998166e-02
    5.27196452e-02   4.20580097e-02   6.02210537e-02   2.94076651e-02
    1.06166244e-01   1.56429410e-03   7.57184029e-02  -1.99318230e-02
    8.25117975e-02   4.94773090e-02   1.74716953e-02  -1.02295294e-01
   -1.52206086e-02   2.33976990e-02   4.97071892e-02   1.24389902e-01
    1.98308080e-02   1.53945774e-01   2.75425743e-02   1.15045205e-01
    9.03738141e-02   1.35842431e-02   1.42767116e-01   7.28849322e-02
    1.58127114e-01  -1.02049038e-02   2.38748908e-01   1.21429175e-01
   -1.59131158e-02  -1.40134782e-01   6.22429401e-02   9.96955186e-02
    5.62849790e-02   2.60417819e-01   1.72148198e-01   7.30695352e-02
    6.11195564e-02   1.16573408e-01  -1.04185995e-02   2.79061496e-05
   -4.29572798e-02  -1.97581165e-02   6.38310760e-02  -3.00278291e-02
    8.88051391e-02   1.65820867e-01  -5.10793217e-02   5.32477051e-02
    2.45202482e-01   3.31827328e-02  -7.32833743e-02   1.38574600e-01
    8.66724029e-02  -1.42851844e-03   8.44961032e-02  -3.07950303e-02
    1.01886466e-01   8.09069127e-02   8.20083097e-02   2.54340805e-02
    1.29227608e-01   2.36512765e-01   1.21450052e-01   9.62777883e-02
    7.00579509e-02   6.24743216e-02  -1.56559050e-02  -1.88070238e-02
    2.35922933e-02   1.45183235e-01   4.77857143e-02   2.46712148e-01
    8.63710344e-02   2.60355324e-02   6.27277642e-02   2.67612021e-02
   -2.99473722e-02   3.90147418e-03  -1.44119188e-02   3.01006306e-02
    2.52753831e-02   1.48165021e-02   4.49718721e-02   4.48608994e-02
    1.07362866e-01   9.28371474e-02   4.69746366e-02   5.98990172e-02
    1.64883092e-01   2.45222986e-01   5.13932779e-02   1.15704685e-02
    4.58041243e-02   1.27139837e-02   9.12824571e-02   1.76018123e-02
    3.81258614e-02  -2.54384857e-02   2.06517935e-01   8.41076300e-02
   -1.10964149e-01   9.16881561e-02   1.95232123e-01   3.69523346e-01
    2.82695740e-02   1.44950733e-01  -7.94683769e-03   7.04058930e-02
    6.06696159e-02  -6.03143349e-02   7.00018555e-03   7.01863170e-02
    1.11681543e-01   2.35183351e-02   8.54406506e-04   1.18710160e-01]]
After layer encoder_birnn_reverse_l0_t1_o_output (1, 256) <class 'numpy.float32'> [[ 0.51697439  0.53220379  0.50711656  0.52517915  0.52882296  0.50426209
   0.53377509  0.51887977  0.54599667  0.52152157  0.49866894  0.51269311
   0.52288902  0.50682944  0.51673055  0.5100984   0.51255751  0.51726258
   0.50643498  0.52297467  0.49041021  0.5091781   0.5685572   0.51568341
   0.50957716  0.52144951  0.52770239  0.49982327  0.50816202  0.53226304
   0.51313657  0.51443565  0.55019021  0.50763798  0.51667595  0.51010793
   0.50263292  0.51616848  0.49474353  0.50074863  0.54647654  0.51243651
   0.51091528  0.49603462  0.49882606  0.52615923  0.53431851  0.50344634
   0.50210828  0.50680923  0.50833231  0.50598031  0.48736918  0.52878726
   0.53309292  0.50847065  0.48055047  0.51261038  0.49923775  0.53050953
   0.52239978  0.52702075  0.50545955  0.52750313  0.51906598  0.51669043
   0.57621419  0.52463299  0.51856661  0.54749501  0.49561048  0.50547123
   0.50435817  0.50400412  0.51685774  0.54376018  0.52394426  0.4997876
   0.51318341  0.51697934  0.5092237   0.52491456  0.52240592  0.50793505
   0.52180588  0.51877791  0.51126057  0.51848119  0.53069335  0.51823819
   0.53879106  0.49673867  0.5031603   0.49769491  0.49578068  0.52417743
   0.5054208   0.55891383  0.50023836  0.49821416  0.53320581  0.48758259
   0.50764364  0.49905658  0.50875539  0.51624244  0.48944354  0.52158737
   0.50779819  0.52061391  0.50024402  0.51598835  0.49814534  0.52159548
   0.51393878  0.52212185  0.48358801  0.51036501  0.53102791  0.5124926
   0.51502079  0.49571767  0.49757671  0.52176809  0.51074332  0.5004425
   0.5231216   0.49224454  0.5074802   0.50401288  0.52241766  0.56848896
   0.51851189  0.53050691  0.52803153  0.50188434  0.51432657  0.50912344
   0.49883187  0.49302551  0.51317686  0.51051295  0.51505071  0.5073514
   0.52651668  0.50039107  0.51892054  0.49501726  0.52061623  0.51236683
   0.50436783  0.4744485   0.49619493  0.50584918  0.51242423  0.53105748
   0.50495756  0.53841066  0.50688523  0.52872962  0.52257812  0.50339597
   0.53563124  0.51821315  0.53944963  0.49744877  0.55940527  0.53032005
   0.49602184  0.46502355  0.51555574  0.52490324  0.51406753  0.56473899
   0.54293108  0.51825929  0.51527512  0.52911037  0.49739534  0.50000697
   0.48926231  0.49506062  0.51595235  0.4924936   0.5221867   0.5413605
   0.48723295  0.51330876  0.56099534  0.50829494  0.48168734  0.53458834
   0.52165455  0.49964288  0.52111149  0.49230185  0.52544963  0.52021569
   0.52049065  0.50635815  0.53226203  0.5588541   0.53032523  0.52405089
   0.51750731  0.5156135   0.49608612  0.49529839  0.50589782  0.53623223
   0.51194417  0.56136709  0.52157933  0.50650853  0.5156768   0.50668991
   0.49251372  0.50097537  0.49639705  0.50752461  0.50631851  0.50370407
   0.51124108  0.51121336  0.52681494  0.52319264  0.51174152  0.5149703
   0.54112762  0.56100035  0.51284552  0.50289261  0.51144904  0.50317848
   0.5228048   0.50440037  0.50953031  0.49364069  0.55144674  0.52101451
   0.47228739  0.52290601  0.54865354  0.59134382  0.50706691  0.53617436
   0.49801332  0.51759422  0.51516277  0.48492596  0.50175005  0.51753944
   0.5278914   0.50587928  0.50021362  0.52964276]]
After layer encoder_birnn_reverse_l0_t1_f_output (1, 256) <class 'numpy.float32'> [[ 0.4957498   0.50803417  0.52097374  0.51474786  0.5209465   0.51325166
   0.5299015   0.4829973   0.54136533  0.51504809  0.51676011  0.5404188
   0.51009649  0.52482951  0.51486886  0.53572381  0.51931077  0.53595537
   0.51474535  0.52610296  0.53528559  0.50044274  0.57539457  0.52089792
   0.4952665   0.52370483  0.50407857  0.50375748  0.52029449  0.48969999
   0.51876169  0.51814485  0.5344854   0.50802308  0.49931976  0.48780745
   0.52218294  0.54396427  0.50401527  0.51446211  0.49323532  0.51612657
   0.53085077  0.54002792  0.51217407  0.50508398  0.52681988  0.52046835
   0.50340837  0.51273334  0.51576775  0.51817262  0.5148409   0.52457511
   0.53960162  0.50503927  0.50054497  0.51648706  0.50720781  0.51662838
   0.51159757  0.53018326  0.50147086  0.51012331  0.51690793  0.53533149
   0.5499872   0.52370369  0.48892161  0.52033681  0.52678686  0.51679432
   0.50855529  0.492347    0.53210169  0.53875738  0.5208053   0.49966252
   0.51711363  0.52608681  0.51131868  0.52544403  0.4919199   0.49286005
   0.50260139  0.5292604   0.50860566  0.5188089   0.52726156  0.49875796
   0.55150431  0.52369821  0.51804233  0.51636517  0.51856738  0.48447594
   0.50273973  0.53829044  0.49323398  0.50842786  0.50281203  0.51150143
   0.50567901  0.53539133  0.50034845  0.49058104  0.50360847  0.52844077
   0.50187433  0.50186813  0.51986992  0.51407588  0.51022708  0.53160304
   0.51494938  0.52422053  0.50738412  0.50045711  0.51427382  0.50427639
   0.53601325  0.56136358  0.51758856  0.51404971  0.49621195  0.51883239
   0.5115422   0.51129621  0.50271535  0.49444404  0.53078365  0.53742248
   0.51369208  0.50410604  0.52775228  0.52250028  0.53942609  0.51978624
   0.51565337  0.51776594  0.50478786  0.52762854  0.52648848  0.51830602
   0.50302327  0.50696653  0.48785532  0.51293164  0.51589966  0.51241052
   0.52226645  0.51784486  0.53950703  0.52038383  0.51232415  0.53336972
   0.51272357  0.50006276  0.5125941   0.53563029  0.51196653  0.51342428
   0.51199836  0.53792453  0.49158362  0.51402384  0.58211827  0.50726587
   0.4710511   0.51123059  0.53016394  0.52132416  0.51085126  0.54827255
   0.51255196  0.50506938  0.51898843  0.50749177  0.501881    0.4990308
   0.49515313  0.52572948  0.52139026  0.500229    0.51448047  0.48766774
   0.51349068  0.5150373   0.51239002  0.48904315  0.52392936  0.51865953
   0.52708101  0.50726509  0.53800678  0.48974976  0.50595069  0.51195276
   0.51564848  0.50452816  0.52400064  0.51156008  0.52083361  0.53261954
   0.51194423  0.51247925  0.50419044  0.53544074  0.50152242  0.52664137
   0.51895696  0.54123592  0.49823847  0.52701443  0.48790157  0.50523955
   0.55349934  0.51200169  0.53331387  0.52714479  0.4927524   0.49508008
   0.53547245  0.51673108  0.51875198  0.52290803  0.51177084  0.50847775
   0.55268627  0.52909994  0.50359076  0.50872004  0.51795834  0.50765461
   0.4826887   0.53789699  0.52174824  0.52349365  0.51364166  0.52097261
   0.5037967   0.54690307  0.54273719  0.5339191   0.48541859  0.50801665
   0.50216478  0.5000239   0.52024198  0.51194257  0.53515989  0.51070267
   0.52283114  0.50938779  0.53345639  0.48917797]]
After layer _mul2074_0 (1, 256) <class 'numpy.float32'> [[-0.02906346 -0.01171214 -0.01558434 -0.02823799  0.00070371 -0.04906891
   0.01580022  0.00672481 -0.01268608 -0.0293935  -0.00945737  0.02182189
   0.0194609  -0.02514115  0.02188619 -0.01348006  0.01246072  0.01090073
   0.01664504 -0.00827861  0.01757944 -0.02937595  0.00633314  0.02305205
   0.00340056 -0.00068134 -0.04874696 -0.00412494  0.00462355 -0.01847723
   0.01392002 -0.01533512  0.01696717 -0.00902142  0.01098342 -0.00164819
  -0.04201229 -0.00571486 -0.02698257 -0.00121861  0.00748071  0.00626978
   0.03036588  0.00305141  0.03259939 -0.02248726  0.02402856 -0.01960197
  -0.00296186 -0.03851964 -0.03796703 -0.01367172  0.00872216  0.01992843
  -0.00274315  0.01358015 -0.0261532   0.03096718  0.00926869 -0.03260633
  -0.0215197  -0.00496062 -0.01354775 -0.0233458   0.03314565 -0.02528396
   0.02410797 -0.00038512 -0.02776827 -0.01681036 -0.03929259  0.0128493
   0.00663797 -0.01702178  0.00492282 -0.02530436 -0.01829907 -0.023466
  -0.00986582 -0.01093343 -0.02710944 -0.00661402 -0.01714733 -0.0300465
  -0.02200866  0.0198022  -0.01311344  0.01472107 -0.01055212 -0.03492329
   0.0279743   0.00108964  0.01331712 -0.01385934  0.0150845  -0.00119141
   0.0111252   0.01966273  0.00603353  0.00806381  0.01194176  0.02215286
  -0.03605086  0.01555943 -0.01551781  0.00649456 -0.00531149 -0.03308105
   0.02414319 -0.00362627  0.02747585  0.05399485 -0.00127032  0.01610838
  -0.01246478 -0.00555575 -0.01430773 -0.03079578  0.00039369  0.01928174
   0.01134283  0.02269683 -0.01633397 -0.01045603  0.02989579 -0.02509669
  -0.01526837 -0.00491066  0.02092555  0.03859419  0.02503223  0.02775268
   0.00164989  0.02260005  0.00749779  0.0189168   0.01315342 -0.00434454
   0.0175722   0.03409247 -0.02678461 -0.00728588  0.01497865 -0.02386463
  -0.03386121  0.01878885  0.03968879 -0.02518347  0.00416176 -0.00562277
  -0.02058323 -0.00580379  0.00737745  0.00358705  0.00527249 -0.02803631
  -0.03001586  0.01605977  0.02938046  0.02245073 -0.0117864  -0.01350782
   0.01211996  0.01032514  0.00997138  0.00837664  0.01859551 -0.0324715
   0.00053753 -0.02324972 -0.01091877  0.01945468 -0.01029052 -0.00685888
  -0.016382    0.01286187  0.06244557 -0.01070732 -0.04257695 -0.01408893
  -0.00223196 -0.0043632  -0.02455949 -0.00225399  0.0529752  -0.02044219
   0.00487121 -0.02912982  0.01463063 -0.01844377  0.00647612  0.03460619
  -0.00102768  0.00418036 -0.01623315  0.01137074 -0.02936194 -0.02634905
   0.01163358  0.01264036 -0.01366671  0.02624669  0.03287513 -0.0145732
   0.0244126  -0.00463084 -0.0176014   0.0100443   0.03435342 -0.01905983
  -0.0028391   0.01004393  0.02538533 -0.02410141  0.01224499 -0.01920275
   0.00286307 -0.00119986 -0.01537121  0.02950884  0.02927637 -0.01256823
  -0.01722447 -0.00357325 -0.01008417 -0.00671568 -0.00684691  0.02129667
  -0.0039633   0.00872382 -0.00108332  0.02054735  0.02175848  0.00650586
  -0.0108408   0.03086072 -0.02171936 -0.00427137 -0.0119219   0.01953438
   0.0100737  -0.01388064  0.01710038  0.01128892 -0.02640125  0.01062615
   0.00384477  0.00197499 -0.02868477  0.01493721  0.01522026  0.01471303
   0.03622951 -0.01338361  0.01110028 -0.01735318]]
After layer encoder_birnn_reverse_l0_t1_i_output (1, 256) <class 'numpy.float32'> [[ 0.49935722  0.51643795  0.49760103  0.51169264  0.51001728  0.50402516
   0.49286485  0.49688622  0.49804547  0.51528621  0.50904816  0.51365793
   0.48545584  0.50569534  0.52097607  0.50991482  0.47856626  0.47556591
   0.50975227  0.49158171  0.52899545  0.52353585  0.47801942  0.49490511
   0.53400087  0.49685091  0.49625897  0.49969906  0.50907618  0.52423453
   0.5082922   0.48363045  0.54272968  0.5138796   0.52127045  0.52033693
   0.50489098  0.50856012  0.52433151  0.52501714  0.52455497  0.50920635
   0.49206695  0.50607592  0.50689828  0.5097937   0.52890128  0.49384022
   0.50678205  0.50318605  0.52337199  0.53412831  0.5152964   0.53558046
   0.54400182  0.51509631  0.48480135  0.48607454  0.48634517  0.51121962
   0.51035017  0.50178438  0.49354762  0.52835107  0.51890743  0.51422119
   0.53705972  0.48292288  0.53904223  0.51771623  0.52060568  0.49791151
   0.50575107  0.51401144  0.52518457  0.568946    0.50271177  0.49832213
   0.48960808  0.49520838  0.51024091  0.51848745  0.50020182  0.50871444
   0.51492971  0.50231218  0.51637399  0.5107581   0.54739571  0.4886404
   0.52640235  0.48695567  0.50268048  0.48907474  0.5026021   0.50206596
   0.48814774  0.553473    0.47133154  0.50755507  0.51636845  0.5037027
   0.52452248  0.51243532  0.51328945  0.50327671  0.51393282  0.50160658
   0.52043456  0.51696622  0.48635176  0.51926559  0.51087725  0.55150527
   0.51083189  0.53398937  0.49246526  0.4945831   0.53049296  0.50312328
   0.51293999  0.50705516  0.51099551  0.51451582  0.51652175  0.53251159
   0.48721349  0.49924797  0.52307403  0.47335464  0.53260541  0.56214565
   0.52923375  0.50390708  0.53134024  0.51189113  0.47963873  0.51935375
   0.47466284  0.47044921  0.49647784  0.52019274  0.50367594  0.47610876
   0.49274933  0.5419175   0.50350797  0.49697259  0.50416052  0.51189691
   0.50203574  0.51430583  0.49372664  0.49291784  0.50347352  0.55148149
   0.50382537  0.52022463  0.51286334  0.49963978  0.53245825  0.49834788
   0.51480037  0.50502235  0.49904227  0.52603602  0.4909952   0.51258254
   0.52893615  0.479148    0.49921292  0.52994597  0.5190478   0.53257596
   0.52776259  0.48612377  0.50214905  0.51824248  0.49673292  0.49901822
   0.50905806  0.49736837  0.5102396   0.49507663  0.51252866  0.5203892
   0.52013195  0.50116503  0.56134063  0.49845093  0.49903414  0.51121897
   0.48730609  0.47219929  0.51652926  0.49844465  0.48883909  0.49095693
   0.52453828  0.48684466  0.51012266  0.56086731  0.52668285  0.50137293
   0.51882482  0.51972371  0.50610316  0.49460468  0.49674428  0.52159059
   0.52595955  0.53932101  0.49834314  0.53786057  0.51820403  0.48231158
   0.51766437  0.45637515  0.51765394  0.5331642   0.49426004  0.49183241
   0.52358854  0.49580753  0.49036035  0.52276516  0.49462426  0.49072492
   0.4703286   0.55114233  0.52804554  0.48748088  0.5337559   0.49145937
   0.51673824  0.51871395  0.49585846  0.50962591  0.50169623  0.49271849
   0.47603205  0.48939419  0.5489735   0.55920798  0.50437129  0.49003929
   0.49092779  0.50122285  0.51759887  0.51409906  0.50653458  0.49868217
   0.49115929  0.51327372  0.50524354  0.52728558]]
After layer encoder_birnn_reverse_l0_t1_c_output (1, 256) <class 'numpy.float32'> [[-0.04378998 -0.03052836  0.09186548  0.09938651  0.10356308  0.03577907
   0.01154645 -0.00547634 -0.08369735 -0.12066188 -0.05321433  0.00741926
   0.07188316 -0.06309813  0.08284677 -0.11151273 -0.00616619 -0.06104434
  -0.00163195  0.08608394  0.11072604 -0.07349759  0.03713139  0.01382644
   0.02414693  0.00818877 -0.05078518  0.02420042 -0.04585164 -0.03230745
   0.0680564  -0.12076306  0.05024125 -0.08030113  0.03022188 -0.12527254
  -0.01243104 -0.08345232  0.02112942  0.05030474  0.10997953  0.00929048
   0.03422763  0.0211142   0.05837571 -0.08916049  0.04058256  0.00631495
  -0.00477923  0.09274986 -0.00460571 -0.07072668 -0.08343587  0.01751702
   0.06958716 -0.06574347 -0.04537546  0.13371108  0.02753362 -0.07128926
  -0.09534122 -0.03658852 -0.0147281   0.01174763  0.14238034 -0.01971887
   0.10196322  0.09710948 -0.02499903  0.00984421 -0.14001073  0.09771492
   0.02683352 -0.04671356  0.13154045  0.01196506 -0.17006429 -0.05067603
  -0.08043197 -0.03756344 -0.00850419 -0.08897352  0.01984804 -0.11132345
  -0.09543615  0.04066008 -0.02401102  0.04192552 -0.04786025  0.03406338
   0.03258289  0.03374484  0.02261993 -0.06228631 -0.05119377 -0.02536733
  -0.01152349 -0.1171654  -0.01069381 -0.0624604   0.11515165  0.02447685
  -0.04398128  0.01060273 -0.05116841  0.08738526 -0.02545868  0.02659834
  -0.01969752 -0.0134577   0.08349138  0.01469803  0.02065762  0.07942429
  -0.08093325  0.03227041 -0.05553792 -0.05258346  0.09004627  0.04296103
   0.03479251  0.08151461  0.01592059 -0.09229597  0.03265101 -0.11689902
   0.12769689 -0.12353146 -0.02122611  0.10131091  0.06543023 -0.09023716
   0.04996364 -0.14937593  0.06859005  0.05271025  0.08917533  0.12622905
  -0.0707046   0.03848796 -0.00651855 -0.0461768   0.11066754  0.00611987
   0.05665337  0.01631511  0.03926831 -0.07803822  0.01961325  0.04492621
  -0.01673664 -0.0066307  -0.08464392 -0.04461867  0.07231361  0.06050182
  -0.01995844  0.00083308 -0.01549939  0.04131384 -0.20525673 -0.08777075
  -0.04358336 -0.03112035 -0.02815579  0.08902133 -0.04050963 -0.12406388
  -0.16251774 -0.07684481 -0.10199627  0.05179567 -0.01635315 -0.08245427
   0.05616395 -0.01334205  0.08955183 -0.08496002 -0.03542674 -0.0278542
   0.13120759  0.05660114  0.0869305  -0.00692675  0.04472529 -0.04999804
   0.01207908 -0.1001331   0.0494717  -0.00819888  0.21434027  0.05490429
  -0.06454175 -0.00244599 -0.15335639  0.05214753 -0.08938422 -0.10592324
   0.03996367  0.10473029 -0.04319946 -0.09558534  0.08603867 -0.01133291
   0.0752165  -0.03494942  0.0256255  -0.01811053  0.16886519 -0.09402769
   0.02875079  0.08872648  0.02427215  0.02882423 -0.08287033 -0.05697722
  -0.02659967 -0.00203387  0.07946297  0.05544836  0.01995531  0.04203163
   0.09750411 -0.07579985  0.01102147  0.00973941  0.02408617 -0.03296386
   0.02185507 -0.00174646 -0.08100159 -0.02392229  0.04757862  0.02022723
  -0.06592825 -0.02242371 -0.03942827  0.04286997 -0.08106907  0.0155165
  -0.01596573 -0.05882809 -0.00160659 -0.1251121  -0.02846351 -0.0608704
  -0.01729215 -0.01470045  0.01666666  0.14974289  0.15621151  0.02301002
  -0.01548935 -0.00341009  0.01485564 -0.09313162]]
After layer _mul2075_0 (1, 256) <class 'numpy.float32'> [[-0.02186684 -0.015766    0.04571236  0.05085535  0.05281896  0.01803355
   0.00569084 -0.00272112 -0.04168509 -0.0621754  -0.02708866  0.00381096
   0.0348961  -0.03190843  0.04316118 -0.05686199 -0.00295093 -0.02903061
  -0.00083189  0.04231729  0.05857357 -0.03847862  0.01774952  0.00684278
   0.01289448  0.0040686  -0.0252026   0.01209293 -0.02334198 -0.01693668
   0.03459254 -0.0584047   0.02726742 -0.04126511  0.01575377 -0.06518393
  -0.00627632 -0.04244052  0.01107882  0.02641085  0.05769031  0.00473077
   0.01684229  0.01068539  0.02959055 -0.04545346  0.02146417  0.00311858
  -0.00242203  0.04667044 -0.0024105  -0.03777712 -0.0429942   0.00938177
   0.03785554 -0.03386422 -0.02199808  0.06499355  0.01339084 -0.03644447
  -0.04865741 -0.01835955 -0.00726902  0.00620687  0.07388221 -0.01013986
   0.05476034  0.04689639 -0.01347553  0.00509651 -0.07289038  0.04865338
   0.01357108 -0.0240113   0.06908301  0.00680747 -0.08549332 -0.02525298
  -0.03938014 -0.01860173 -0.00433918 -0.04613166  0.00992803 -0.05663185
  -0.04914291  0.02042405 -0.01239867  0.0214138  -0.02619849  0.01664475
   0.01715171  0.01643224  0.0113706  -0.03046266 -0.0257301  -0.01273607
  -0.00562517 -0.06484789 -0.00504033 -0.03170209  0.05946068  0.01232905
  -0.02306917  0.00543321 -0.02626421  0.04397897 -0.01308405  0.0133419
  -0.01025127 -0.00695718  0.04060618  0.00763218  0.01055351  0.04380292
  -0.04134329  0.01723206 -0.0273505  -0.02600689  0.04776891  0.0216147
   0.01784647  0.04133241  0.00813535 -0.04748774  0.01686496 -0.06225009
   0.06221564 -0.06167283 -0.01110283  0.04795599  0.0348485  -0.05072642
   0.02644245 -0.07527159  0.03644466  0.02698191  0.04277194  0.06555753
  -0.03356085  0.01810663 -0.00323632 -0.02402084  0.05574058  0.00291372
   0.02791591  0.00884144  0.01977191 -0.03878286  0.00988823  0.02299759
  -0.00840239 -0.00341021 -0.04179096 -0.02199334  0.03640798  0.03336563
  -0.01005557  0.00043339 -0.00794907  0.02064204 -0.10929064 -0.04374037
  -0.02243673 -0.01571647 -0.01405093  0.04682843 -0.01989003 -0.06359298
  -0.08596151 -0.03682004 -0.05091786  0.02744891 -0.00848806 -0.04391316
   0.02964123 -0.00648589  0.04496837 -0.04402989 -0.01759763 -0.01389975
   0.06679228  0.02815161  0.04435538 -0.00342927  0.02292299 -0.02601844
   0.00628272 -0.05018321  0.02777048 -0.00408674  0.10696311  0.02806812
  -0.03145159 -0.00115499 -0.07921306  0.02599266 -0.0436945  -0.05200374
   0.02096248  0.05098738 -0.02203702 -0.05361069  0.04531509 -0.00568202
   0.03902419 -0.01816404  0.01296915 -0.00895755  0.08388282 -0.04904396
   0.01512175  0.04785205  0.01209586  0.01550342 -0.04294374 -0.02748077
  -0.0137697  -0.00092821  0.04113432  0.02956308  0.00986311  0.02067252
   0.05105203 -0.03758213  0.00540449  0.00509142  0.0119136  -0.01617619
   0.01027906 -0.00096255 -0.04277253 -0.01166166  0.02539537  0.00994086
  -0.03406765 -0.01163149 -0.01955084  0.02184765 -0.04067205  0.00764527
  -0.0076002  -0.02879013 -0.00088197 -0.06996369 -0.01435618 -0.02982889
  -0.0084892  -0.0073682   0.00862665  0.07698268  0.07912653  0.01147469
  -0.00760774 -0.00175031  0.00750571 -0.04910696]]
After layer encoder_birnn_reverse_l0_t1_state_0 (1, 256) <class 'numpy.float32'> [[-0.05093031 -0.02747815  0.03012802  0.02261735  0.05352267 -0.03103536
   0.02149105  0.0040037  -0.05437116 -0.0915689  -0.03654602  0.02563285
   0.054357   -0.05704958  0.06504738 -0.07034206  0.00950978 -0.01812988
   0.01581315  0.03403868  0.07615301 -0.06785458  0.02408266  0.02989483
   0.01629504  0.00338725 -0.07394957  0.00796799 -0.01871843 -0.03541391
   0.04851255 -0.07373982  0.04423459 -0.05028653  0.02673719 -0.06683212
  -0.04828861 -0.04815538 -0.01590374  0.02519224  0.06517103  0.01100055
   0.04720817  0.01373679  0.06218994 -0.06794071  0.04549272 -0.0164834
  -0.00538388  0.00815079 -0.04037753 -0.05144884 -0.03427205  0.0293102
   0.03511239 -0.02028407 -0.04815128  0.09596073  0.02265953 -0.06905079
  -0.07017711 -0.02332017 -0.02081676 -0.01713893  0.10702786 -0.03542382
   0.07886831  0.04651127 -0.04124381 -0.01171385 -0.11218297  0.06150268
   0.02020905 -0.04103308  0.07400583 -0.01849688 -0.10379238 -0.04871899
  -0.04924596 -0.02953516 -0.03144862 -0.05274567 -0.0072193  -0.08667834
  -0.07115156  0.04022625 -0.0255121   0.03613487 -0.03675061 -0.01827854
   0.04512601  0.01752188  0.02468771 -0.044322   -0.01064559 -0.01392748
   0.00550004 -0.04518515  0.0009932  -0.02363828  0.07140245  0.03448191
  -0.05912004  0.02099265 -0.04178202  0.05047353 -0.01839554 -0.01973915
   0.01389192 -0.01058345  0.06808203  0.06162702  0.00928319  0.0599113
  -0.05380806  0.01167631 -0.04165823 -0.05680267  0.04816261  0.04089644
   0.0291893   0.06402924 -0.00819862 -0.05794377  0.04676075 -0.08734678
   0.04694727 -0.06658349  0.00982273  0.08655018  0.05988073 -0.02297375
   0.02809234 -0.05267154  0.04394245  0.04589871  0.05592536  0.06121299
  -0.01598864  0.0521991  -0.03002093 -0.03130672  0.07071923 -0.02095091
  -0.0059453   0.02763029  0.0594607  -0.06396633  0.01404999  0.01737482
  -0.02898562 -0.009214   -0.03441351 -0.01840628  0.04168047  0.00532933
  -0.04007143  0.01649315  0.02143139  0.04309276 -0.12107703 -0.05724818
  -0.01031677 -0.00539133 -0.00407955  0.05520507 -0.00129452 -0.09606448
  -0.08542398 -0.06006975 -0.06183662  0.04690359 -0.01877858 -0.05077204
   0.01325923  0.00637598  0.10741393 -0.05473721 -0.06017457 -0.02798868
   0.06456032  0.02378841  0.01979589 -0.00568326  0.07589819 -0.04646063
   0.01115392 -0.07931302  0.04240111 -0.02253051  0.11343923  0.06267431
  -0.03247927  0.00302537 -0.09544621  0.0373634  -0.07305644 -0.07835279
   0.03259606  0.06362774 -0.03570373 -0.027364    0.07819022 -0.02025521
   0.06343679 -0.02279489 -0.00463225  0.00108675  0.11823624 -0.06810378
   0.01228265  0.05789598  0.03748119 -0.00859799 -0.03069875 -0.04668352
  -0.01090663 -0.00212807  0.02576311  0.05907192  0.03913948  0.00810429
   0.03382756 -0.04115538 -0.00467968 -0.00162426  0.00506669  0.00512048
   0.00631577  0.00776127 -0.04385585  0.00888569  0.04715385  0.01644672
  -0.04490845  0.01922923 -0.0412702   0.01757628 -0.05259395  0.02717965
   0.0024735  -0.04267076  0.01621841 -0.05867477 -0.04075743 -0.01920273
  -0.00464442 -0.00539321 -0.02005813  0.09191989  0.09434679  0.02618771
   0.02862177 -0.01513392  0.018606   -0.06646013]]
After layer activation1037_output (1, 256) <class 'numpy.float32'> [[-0.05088632 -0.02747123  0.03011891  0.0226135   0.05347162 -0.0310254
   0.02148775  0.00400368 -0.05431765 -0.09131383 -0.03652976  0.02562724
   0.05430353 -0.05698777  0.06495579 -0.07022627  0.0095095  -0.01812789
   0.01581183  0.03402554  0.07600614 -0.06775063  0.02407801  0.02988592
   0.0162936   0.00338724 -0.07381506  0.00796782 -0.01871624 -0.03539912
   0.04847453 -0.07360645  0.04420576 -0.05024418  0.02673082 -0.06673279
  -0.04825111 -0.04811819 -0.0159024   0.02518691  0.06507891  0.01100011
   0.04717313  0.01373593  0.0621099  -0.06783637  0.04546137 -0.0164819
  -0.00538383  0.00815061 -0.0403556  -0.0514035  -0.03425864  0.02930181
   0.03509797 -0.02028129 -0.0481141   0.09566727  0.02265566 -0.06894125
  -0.07006213 -0.02331594 -0.02081376 -0.01713725  0.10662106 -0.03540901
   0.0787052   0.04647776 -0.04122044 -0.01171331 -0.11171472  0.06142525
   0.0202063  -0.04101007  0.07387102 -0.01849478 -0.10342127 -0.04868048
  -0.04920619 -0.02952658 -0.03143826 -0.05269681 -0.00721918 -0.08646192
  -0.07103173  0.04020457 -0.02550657  0.03611915 -0.03673408 -0.01827651
   0.0450954   0.01752008  0.0246827  -0.044293   -0.01064519 -0.01392658
   0.00549998 -0.04515443  0.0009932  -0.02363388  0.07128135  0.03446825
  -0.05905126  0.02098957 -0.04175772  0.05043071 -0.01839346 -0.01973659
   0.01389103 -0.01058305  0.06797704  0.06154912  0.00928292  0.05983972
  -0.05375619  0.01167578 -0.04163415 -0.05674165  0.0481254   0.04087365
   0.02918102  0.06394188 -0.00819843 -0.05787901  0.04672669 -0.08712532
   0.04691281 -0.06648527  0.00982241  0.08633472  0.05980926 -0.02296971
   0.02808495 -0.05262289  0.04391419  0.04586651  0.05586713  0.06113665
  -0.01598728  0.05215174 -0.03001192 -0.0312965   0.07060157 -0.02094784
  -0.00594523  0.02762326  0.05939072 -0.06387923  0.01404907  0.01737307
  -0.0289775  -0.00921374 -0.03439993 -0.01840421  0.04165635  0.00532928
  -0.04004999  0.01649166  0.02142811  0.04306611 -0.12048884 -0.05718572
  -0.01031641 -0.00539128 -0.00407953  0.05514906 -0.00129452 -0.09577006
  -0.08521681 -0.05999761 -0.06175793  0.04686922 -0.01877638 -0.05072846
   0.01325846  0.0063759   0.10700273 -0.05468261 -0.06010205 -0.02798138
   0.06447077  0.02378393  0.0197933  -0.0056832   0.07575279 -0.04642723
   0.01115346 -0.07914714  0.04237571 -0.0225267   0.11295513  0.06259237
  -0.03246785  0.00302536 -0.09515743  0.03734602 -0.07292675 -0.07819284
   0.03258451  0.06354202 -0.03568857 -0.02735718  0.07803127 -0.02025244
   0.06335183 -0.02279094 -0.00463222  0.00108675  0.11768834 -0.06799868
   0.01228203  0.05783138  0.03746365 -0.00859778 -0.03068911 -0.04664964
  -0.0109062  -0.00212807  0.02575741  0.05900331  0.0391195   0.00810411
   0.03381466 -0.04113216 -0.00467964 -0.00162426  0.00506665  0.00512044
   0.00631568  0.00776111 -0.04382775  0.00888545  0.04711893  0.01644524
  -0.04487829  0.01922686 -0.04124678  0.01757446 -0.05254551  0.02717295
   0.0024735  -0.04264488  0.01621699 -0.05860753 -0.04073488 -0.01920037
  -0.00464439 -0.00539316 -0.02005544  0.09166188  0.09406785  0.02618173
   0.02861395 -0.01513277  0.01860385 -0.06636246]]
After layer encoder_birnn_reverse_l0_t1_out_0 (1, 256) <class 'numpy.float32'> [[-0.02630692 -0.01462029  0.0152738   0.01187614  0.02827702 -0.01564493
   0.01146962  0.00207743 -0.02965726 -0.04762213 -0.01821626  0.01313891
   0.02839472 -0.02888308  0.03356464 -0.03582231  0.00487416 -0.00937688
   0.00800766  0.0177945   0.03727419 -0.03449713  0.01368973  0.01541167
   0.00830284  0.00176628 -0.03895238  0.0039825  -0.00951088 -0.01884164
   0.02487405 -0.03786578  0.02432158 -0.02550586  0.01381117 -0.03404093
  -0.0242526  -0.02483709 -0.00786761  0.01261231  0.0355641   0.00563686
   0.02410147  0.0068135   0.03098203 -0.03569273  0.02429085 -0.00829775
  -0.00270327  0.00413081 -0.02051406 -0.02600916 -0.0166966   0.01549442
   0.01871048 -0.01031244 -0.02312125  0.04904003  0.01131056 -0.03657399
  -0.03660044 -0.01228799 -0.01052051 -0.00903995  0.05534336 -0.01829549
   0.04535105  0.02438376 -0.02137554 -0.00641298 -0.05536699  0.0310487
   0.01019121 -0.02066924  0.03818081 -0.01005672 -0.05418698 -0.0243299
  -0.0252518  -0.01526463 -0.01600911 -0.02766133 -0.00377134 -0.04391704
  -0.03706478  0.02085724 -0.0130405   0.0187271  -0.01949453 -0.00947158
   0.024297    0.0087029   0.01241936 -0.0220444  -0.00527768 -0.0073
   0.0027798  -0.02523743  0.00049683 -0.01177473  0.03800763  0.01680612
  -0.029977    0.01047498 -0.02124447  0.02603447 -0.00900256 -0.01029436
   0.00705384 -0.00550969  0.03400511  0.03175863  0.00462424  0.03121213
  -0.02762739  0.00609618 -0.02013377 -0.02895896  0.02555593  0.02094745
   0.01502883  0.03169712 -0.00407935 -0.03019942  0.02386535 -0.04360121
   0.0245411  -0.03272701  0.00498468  0.04351381  0.03124541 -0.01305802
   0.01456238 -0.02791681  0.02318808  0.02301968  0.02873395  0.0311261
  -0.00797497  0.02571214 -0.01540142 -0.01597727  0.03636339 -0.01062792
  -0.00313026  0.01382243  0.03081907 -0.03162132  0.00731417  0.00890138
  -0.01461532 -0.00437144 -0.01706907 -0.00930975  0.02134573  0.00283015
  -0.02022355  0.00887928  0.01086159  0.02277033 -0.06296483 -0.02878706
  -0.00552579 -0.00279383 -0.0022007   0.02743383 -0.00072416 -0.05078878
  -0.0422694  -0.0279003  -0.03183965  0.02460181 -0.00965232 -0.02864834
   0.00719843  0.00330437  0.05513584 -0.02893314 -0.02989448 -0.01399088
   0.03154312  0.01177449  0.0102124  -0.00279894  0.0395571  -0.02513387
   0.00543433 -0.04062692  0.02377258 -0.01145021  0.05440906  0.03346115
  -0.016937    0.0015116  -0.04958763  0.01838551 -0.03831933 -0.04067715
   0.01695994  0.03217502 -0.01899567 -0.01528867  0.04138195 -0.01061331
   0.03278504 -0.01175132 -0.00229798  0.00053827  0.05953827 -0.03646309
   0.00628772  0.03246463  0.01954026 -0.00435485 -0.01582566 -0.0236369
  -0.00537145 -0.00106611  0.0127859   0.02994563  0.01980693  0.00408208
   0.01728745 -0.02102731 -0.00246531 -0.0008498   0.00259281  0.00263687
   0.00341759  0.00435399 -0.02247687  0.00446843  0.02409893  0.00827489
  -0.02346258  0.00969803 -0.02101649  0.00867547 -0.02897605  0.0141575
   0.0011682  -0.02229927  0.00889751 -0.0346572  -0.02065531 -0.01029475
  -0.00231297 -0.00279147 -0.01033181  0.04444923  0.04719855  0.01355008
   0.01510506 -0.00765535  0.0093059  -0.03514839]]
After layer expand_dims1043_0 (1, 1, 256) <class 'numpy.float32'> [[[-0.02630692 -0.01462029  0.0152738   0.01187614  0.02827702 -0.01564493
    0.01146962  0.00207743 -0.02965726 -0.04762213 -0.01821626  0.01313891
    0.02839472 -0.02888308  0.03356464 -0.03582231  0.00487416 -0.00937688
    0.00800766  0.0177945   0.03727419 -0.03449713  0.01368973  0.01541167
    0.00830284  0.00176628 -0.03895238  0.0039825  -0.00951088 -0.01884164
    0.02487405 -0.03786578  0.02432158 -0.02550586  0.01381117 -0.03404093
   -0.0242526  -0.02483709 -0.00786761  0.01261231  0.0355641   0.00563686
    0.02410147  0.0068135   0.03098203 -0.03569273  0.02429085 -0.00829775
   -0.00270327  0.00413081 -0.02051406 -0.02600916 -0.0166966   0.01549442
    0.01871048 -0.01031244 -0.02312125  0.04904003  0.01131056 -0.03657399
   -0.03660044 -0.01228799 -0.01052051 -0.00903995  0.05534336 -0.01829549
    0.04535105  0.02438376 -0.02137554 -0.00641298 -0.05536699  0.0310487
    0.01019121 -0.02066924  0.03818081 -0.01005672 -0.05418698 -0.0243299
   -0.0252518  -0.01526463 -0.01600911 -0.02766133 -0.00377134 -0.04391704
   -0.03706478  0.02085724 -0.0130405   0.0187271  -0.01949453 -0.00947158
    0.024297    0.0087029   0.01241936 -0.0220444  -0.00527768 -0.0073
    0.0027798  -0.02523743  0.00049683 -0.01177473  0.03800763  0.01680612
   -0.029977    0.01047498 -0.02124447  0.02603447 -0.00900256 -0.01029436
    0.00705384 -0.00550969  0.03400511  0.03175863  0.00462424  0.03121213
   -0.02762739  0.00609618 -0.02013377 -0.02895896  0.02555593  0.02094745
    0.01502883  0.03169712 -0.00407935 -0.03019942  0.02386535 -0.04360121
    0.0245411  -0.03272701  0.00498468  0.04351381  0.03124541 -0.01305802
    0.01456238 -0.02791681  0.02318808  0.02301968  0.02873395  0.0311261
   -0.00797497  0.02571214 -0.01540142 -0.01597727  0.03636339 -0.01062792
   -0.00313026  0.01382243  0.03081907 -0.03162132  0.00731417  0.00890138
   -0.01461532 -0.00437144 -0.01706907 -0.00930975  0.02134573  0.00283015
   -0.02022355  0.00887928  0.01086159  0.02277033 -0.06296483 -0.02878706
   -0.00552579 -0.00279383 -0.0022007   0.02743383 -0.00072416 -0.05078878
   -0.0422694  -0.0279003  -0.03183965  0.02460181 -0.00965232 -0.02864834
    0.00719843  0.00330437  0.05513584 -0.02893314 -0.02989448 -0.01399088
    0.03154312  0.01177449  0.0102124  -0.00279894  0.0395571  -0.02513387
    0.00543433 -0.04062692  0.02377258 -0.01145021  0.05440906  0.03346115
   -0.016937    0.0015116  -0.04958763  0.01838551 -0.03831933 -0.04067715
    0.01695994  0.03217502 -0.01899567 -0.01528867  0.04138195 -0.01061331
    0.03278504 -0.01175132 -0.00229798  0.00053827  0.05953827 -0.03646309
    0.00628772  0.03246463  0.01954026 -0.00435485 -0.01582566 -0.0236369
   -0.00537145 -0.00106611  0.0127859   0.02994563  0.01980693  0.00408208
    0.01728745 -0.02102731 -0.00246531 -0.0008498   0.00259281  0.00263687
    0.00341759  0.00435399 -0.02247687  0.00446843  0.02409893  0.00827489
   -0.02346258  0.00969803 -0.02101649  0.00867547 -0.02897605  0.0141575
    0.0011682  -0.02229927  0.00889751 -0.0346572  -0.02065531 -0.01029475
   -0.00231297 -0.00279147 -0.01033181  0.04444923  0.04719855  0.01355008
    0.01510506 -0.00765535  0.0093059  -0.03514839]]]
After layer encoder_birnn_reverse_l0_t2_i2h_output (1, 1024) <class 'numpy.float32'> [[-0.0128371  -0.04095686  0.03787835 ...,  0.06970935 -0.04625846
   0.03761056]]
After layer encoder_birnn_reverse_l0_t2_h2h_output (1, 1024) <class 'numpy.float32'> [[ 0.02050369  0.03257855  0.00370883 ...,  0.05359891  0.05166855
   0.04726375]]
After layer _plus1038_0 (1, 1024) <class 'numpy.float32'> [[ 0.0076666  -0.00837831  0.04158718 ...,  0.12330826  0.00541009
   0.0848743 ]]
After layer encoder_birnn_reverse_l0_t2_slice_output0 (1, 256) <class 'numpy.float32'> [[  7.66659528e-03  -8.37831199e-03   4.15871814e-02  -2.11241432e-02
    7.61785060e-02   2.72411872e-02   6.82398602e-02   3.14982459e-02
    7.11452663e-02   5.62334433e-02  -4.24404629e-02   4.12531830e-02
    2.73697339e-02   5.65674156e-02   2.25234777e-03   2.17995405e-01
   -2.86597647e-02  -4.06989045e-02   1.99891180e-02  -2.73643248e-02
    8.63389075e-02   6.82970285e-02  -5.89700714e-02  -5.25665805e-02
    8.29880461e-02  -8.94787461e-02  -2.20376253e-02  -5.95322624e-03
    5.54528162e-02   7.74153322e-03  -5.45318518e-03  -5.08226454e-02
   -2.84848772e-02  -3.90170515e-02   7.11678341e-02  -7.23302960e-02
    6.19768724e-03  -9.08193737e-03  -4.34158742e-02  -2.62206011e-02
   -4.85203378e-02   6.26882464e-02  -5.59630916e-02   9.86777991e-03
    4.12322357e-02   4.46841307e-03   7.07915276e-02  -7.01575056e-02
    1.89620871e-02  -1.34732239e-02  -2.71183327e-02   7.85686374e-02
    2.39697248e-02   6.87493533e-02   2.15960801e-01   7.03914315e-02
   -2.93980911e-02  -9.84655693e-03  -1.24884434e-02  -2.43028309e-02
    5.75640202e-02  -4.45220992e-02   1.32502705e-01  -2.53565442e-02
   -9.53776315e-02  -4.93336618e-02   9.15682092e-02  -6.62451982e-03
   -1.46319345e-02   5.12896180e-02   9.03360546e-02  -1.65585391e-02
    6.40617684e-03   9.49603319e-03  -3.30730155e-02   1.02119558e-01
    1.23363376e-01   9.82300192e-02  -2.39258930e-02   3.01010851e-02
    2.45423876e-02   2.70884596e-02   8.66356343e-02  -1.33480895e-02
    1.44843817e-01   6.99819624e-02  -2.92933825e-02   1.47309154e-04
   -4.84964065e-02   1.67793855e-01   1.45369232e-01  -1.02716014e-02
   -7.91605189e-02   1.27291128e-01   6.41323105e-02   5.19538522e-02
   -2.02346742e-02   1.42058387e-01  -5.54918759e-02  -7.99088478e-02
   -2.37132236e-02   6.59416318e-02  -2.31434554e-02  -1.43870115e-01
   -1.43514462e-02  -7.91853666e-03  -1.30953081e-03  -1.18390493e-01
    4.27012704e-02   9.27995890e-02  -1.37994334e-01   6.24303259e-02
   -1.23230172e-02   1.29058614e-01  -9.97987948e-03   2.53570825e-01
   -2.12203711e-02   1.30453650e-02   1.23109236e-01  -1.24116987e-02
    1.89694464e-01  -9.25462842e-02  -1.36066973e-02   8.60518143e-02
   -5.13721332e-02   4.91231196e-02  -9.39402431e-02   4.72852662e-02
   -9.48522426e-03  -7.86900520e-04   1.15673721e-01   7.00347200e-02
    2.45233644e-02  -1.22676771e-02  -2.78492905e-02  -6.90509379e-03
    8.21379125e-02   1.34938270e-01   1.95003804e-02  -1.09122247e-02
   -3.16296630e-02  -5.51032685e-02   3.85983102e-02   7.30686039e-02
   -2.24527400e-02   7.90958852e-03   2.43952218e-02   7.52559379e-02
   -2.30788887e-02   6.10705316e-02   7.35090524e-02  -3.04739326e-02
    3.18130106e-03  -7.69813880e-02  -2.14693211e-02   1.80859536e-01
    4.09077853e-02   1.30997539e-01  -5.19189984e-03  -1.77259911e-02
    1.39752939e-01  -1.07282773e-03  -2.17036773e-02   5.63116185e-02
    3.73981185e-02  -3.44711095e-02   3.01152542e-02  -2.85897851e-02
    7.42678046e-02  -1.48738278e-02   3.42887715e-02   2.93089673e-02
    4.81943600e-03   7.90512562e-02   4.14006040e-02  -8.52314830e-02
    3.77039537e-02  -9.17732045e-02  -4.00852710e-02  -1.58601981e-02
    1.82348154e-02  -3.22766677e-02  -4.54994217e-02   4.79961969e-02
    1.00746632e-01  -2.98707671e-02  -1.62604079e-02  -5.30714765e-02
    1.44144699e-01   1.03006884e-01  -6.83687255e-03   2.46514212e-02
    3.23573500e-02   2.16817465e-02   1.65622443e-01   5.35976738e-02
    5.10353073e-02  -1.28671691e-01   4.68488708e-02   1.98590420e-02
   -5.61617687e-03   1.78757593e-01   6.14582822e-02   3.55548039e-03
    3.97474989e-02   6.93559088e-03   4.43741027e-03  -3.12122591e-02
   -2.93106623e-02   3.77517939e-02   1.85414329e-02   7.64031559e-02
    1.43048689e-02   7.63146505e-02   3.00068967e-02   8.52972120e-02
   -4.13317792e-03  -2.59449407e-02  -3.39736789e-03   7.68691115e-03
   -4.98894528e-02   8.24105740e-03   3.47616822e-02  -9.14586186e-02
    1.57432854e-02   8.31976533e-02  -2.86373179e-02  -5.84986061e-02
   -2.44106576e-02   1.96531534e-01  -2.14230325e-02  -1.25206672e-02
   -5.09758107e-03  -1.31782591e-02   3.27236392e-02   6.62983656e-02
   -6.76874071e-03   3.56715247e-02   2.58124564e-02  -3.95368338e-02
   -3.05566788e-02  -6.97178394e-02   1.42906353e-01   2.18783855e-01
   -2.44490560e-02   4.63979021e-02   5.18794730e-02  -5.82668185e-02
    3.70073132e-03   6.83336034e-02   1.21772401e-01   1.51349343e-02
   -5.72432317e-02   4.74348105e-02   2.95997225e-02  -3.41767371e-02]]
After layer encoder_birnn_reverse_l0_t2_slice_output1 (1, 256) <class 'numpy.float32'> [[ 0.1060625   0.01877578  0.07318767  0.04991622  0.02735254  0.05105047
   0.14615002 -0.04594627  0.24472481  0.08906645  0.1317398   0.06723789
   0.08484732  0.01828107  0.09362919  0.08917902  0.07173596 -0.03602326
  -0.09995672  0.03380273  0.0904794  -0.01046328  0.20589253  0.05361265
   0.09740307  0.08229117  0.11032338  0.10625096  0.07661848  0.00039887
   0.00131534 -0.02235479  0.19847549 -0.03592375 -0.00511385  0.02793415
  -0.05412903  0.05606386 -0.00038155  0.0820104   0.05902327  0.08593521
   0.0034465   0.11296032  0.01170448  0.09317077  0.02878926 -0.03424452
   0.00071996  0.03305512  0.03908663  0.02930055  0.09129643  0.11131737
   0.14706957  0.08981655  0.01586349  0.06877389  0.0309244  -0.03562991
   0.00927179  0.0470049  -0.01404002  0.06633683 -0.00873629  0.12007982
   0.17051814  0.07104393 -0.0438693   0.03465283  0.06363591 -0.03270488
  -0.00385672  0.01041946  0.08651712  0.20410891  0.04919612  0.01004392
   0.0252923   0.06357376  0.18429127  0.12048525  0.02701703  0.0221121
   0.11793812  0.02616649  0.04825643  0.20401609  0.02845302 -0.05155516
   0.20385835  0.09324586  0.07474376  0.0771765  -0.02396212  0.01640014
   0.04326057  0.15445974 -0.08100946 -0.0969149   0.03646948  0.01890054
  -0.01107075  0.08508395  0.02543914 -0.01206327 -0.06678658  0.06332646
   0.01001372 -0.01982835 -0.0307905   0.0102903  -0.00808861  0.0915902
   0.1051471   0.16932093  0.08020103  0.10272957  0.17435358  0.08393267
   0.15453516  0.12425801  0.00626853  0.01630238  0.02716498 -0.01388378
   0.123659   -0.00319368  0.08442385 -0.05476832  0.05436306  0.18381155
   0.02552101  0.14201733  0.11270197  0.10258922  0.0283561   0.00841515
   0.1252892   0.11048586 -0.06288282  0.08255839  0.07274793  0.04534332
   0.02048445  0.10323152 -0.00045712  0.01287449  0.00470543 -0.00906979
  -0.03372974  0.05581222  0.00607677  0.06142836  0.09730542  0.16317341
   0.10968213  0.05254258 -0.00089853  0.10414802  0.18643138  0.07801815
  -0.03626933  0.07196973  0.02625171  0.01987145  0.20066902 -0.05991795
   0.00347793 -0.01801388  0.06107836  0.08055162 -0.06394032  0.15422717
   0.00693027  0.06758733  0.12933861  0.02276411  0.00918444  0.09272362
   0.08968936 -0.06569633  0.17038129 -0.03484488  0.03863752 -0.03023418
   0.02189405  0.12161995  0.13743144  0.00735601 -0.036389    0.01946146
   0.14331636  0.13695586  0.1006906  -0.01058774 -0.02791013  0.02169549
   0.01945944  0.01334525  0.01249792  0.08996975  0.09774945 -0.04611832
   0.04647586 -0.08254956  0.00448156  0.12603627  0.0282826   0.03868659
   0.0448439   0.12023684 -0.04713377  0.0214484  -0.0326876  -0.04069603
   0.03726278  0.07577183  0.01437403  0.08700624 -0.08661607  0.00385951
   0.19325896  0.0318381   0.04644328 -0.00848453  0.0295886   0.01603175
   0.23501237  0.24458426 -0.00235001 -0.1816428   0.11876421  0.0347077
   0.05425201  0.00415009  0.0371362   0.084558    0.00609428  0.0930877
   0.08428532 -0.01024884  0.09907616  0.22830263 -0.10210437 -0.01929533
   0.03372297 -0.08435267  0.06458105 -0.00193183  0.08968587 -0.0736087
   0.1166613  -0.02542184  0.12034018  0.01405674]]
After layer encoder_birnn_reverse_l0_t2_slice_output2 (1, 256) <class 'numpy.float32'> [[ -1.18287310e-01  -1.19295113e-01   3.46403103e-03   3.65559682e-02
    3.79736610e-02  -3.87216806e-02   4.27577496e-02   1.08360603e-01
    5.06304801e-02  -4.33822945e-02  -6.21412061e-02   9.26459283e-02
    9.38282758e-02  -3.45829874e-02   5.27984016e-02  -1.78103909e-01
    1.35321040e-02   5.36285900e-03   7.15751275e-02   4.78081480e-02
    1.62556201e-01  -1.64555684e-02   8.00828449e-04   8.38203952e-02
   -1.06067225e-01   3.75942215e-02   6.14471063e-02  -2.47823745e-02
   -1.32377893e-01  -7.69575313e-02   1.33096501e-02  -1.26632601e-01
   -3.72962579e-02   6.58124499e-03   1.05704673e-01  -1.16667502e-01
   -6.95176646e-02  -7.41427066e-03  -1.17312990e-01  -9.69340354e-02
    3.94714773e-02  -1.62774205e-01   1.09409742e-01   9.42129269e-02
    7.95897245e-02  -9.18149129e-02   3.92107219e-02  -7.75897950e-02
   -5.20912092e-03  -7.83536881e-02   5.13844676e-02  -8.77543241e-02
   -6.41688406e-02   6.61539733e-02   6.22444563e-02   3.41526717e-02
   -5.83850853e-02   1.53410167e-01   6.63792714e-02  -5.03637344e-02
   -3.84035483e-02  -9.97351333e-02  -4.67156023e-02   1.68893486e-04
    6.07370883e-02  -2.73884498e-02   4.12912071e-02  -7.09094256e-02
   -1.25401333e-01  -4.55983430e-02  -1.93394452e-01  -1.95682142e-02
    6.69985414e-02   4.36157323e-02   1.12313405e-01  -6.22375011e-02
    1.57374144e-03  -1.29126996e-01  -4.21880819e-02  -1.98949315e-02
   -8.54267329e-02   2.71752700e-02  -6.91275075e-02  -1.20925725e-01
   -2.09436446e-01   2.26534456e-02  -1.60291314e-01   3.92004848e-02
   -1.21340983e-01  -1.14118360e-01  -8.84008482e-02  -6.54788241e-02
   -3.48299667e-02  -1.93326548e-02  -4.08483222e-02   3.47384401e-02
    1.09063022e-01  -2.24353783e-02  -1.14591241e-01  -5.13584465e-02
    3.00776288e-02   1.20391794e-01  -7.02761859e-02   4.42068316e-02
    5.99727780e-02   6.89822957e-02  -4.68582474e-02  -4.01268415e-02
    1.49264187e-01  -1.52871981e-01   4.93052527e-02   1.03811007e-02
    4.76434082e-02   3.49533036e-02  -8.70815217e-02   2.28564858e-01
   -1.12096690e-01  -3.23920175e-02   2.84802038e-02  -4.41791788e-02
    1.16589502e-01   1.02334954e-01  -3.05260159e-02  -5.83877340e-02
    1.04396105e-01  -1.48921683e-01  -8.16058517e-02  -3.93242277e-02
   -3.48203182e-02  -3.55071239e-02   5.54968491e-02  -5.53406179e-02
    7.79378265e-02  -1.90799609e-02  -3.28496844e-03   5.25313467e-02
    1.10354945e-01   1.71227738e-01  -4.62220144e-03   5.07792383e-02
   -1.23505183e-02  -5.51417805e-02   1.03226595e-01   1.45154335e-02
   -1.24824487e-01   8.08912516e-02   3.88091952e-02  -1.18366219e-01
   -1.03426978e-01  -9.04534981e-02  -7.11376816e-02  -3.42253335e-02
   -2.76611894e-02  -1.03525788e-01  -4.02277559e-02   6.37264922e-02
   -9.08978581e-02   6.78889304e-02   5.26929274e-02   5.23593873e-02
   -1.47157162e-01  -7.41567165e-02   4.32493612e-02   1.46670833e-01
    1.99777596e-02   8.09165537e-02   7.69699225e-03  -7.03110844e-02
   -1.27454519e-01   2.08180770e-02  -6.50410205e-02   1.43092647e-02
   -1.93567984e-02  -1.22287095e-01  -2.11501978e-02   6.77279234e-02
    1.11629024e-01  -3.92680541e-02  -7.57069439e-02  -3.97516936e-02
    6.31206036e-02  -1.03696920e-02   2.80341171e-02  -2.97424383e-02
   -6.29293025e-02   7.13322833e-02   3.43905762e-02  -9.48642716e-02
    9.32427049e-02  -1.07723251e-01   1.38700619e-01  -3.02233696e-02
    3.20672467e-02  -1.15823671e-02  -1.11486539e-01  -1.13258734e-02
   -1.69647872e-01  -7.78099224e-02  -2.02539433e-02   2.50433162e-02
   -1.29757836e-01  -2.42467970e-04   1.60463393e-01  -7.04208612e-02
   -2.64341477e-02  -2.03309581e-04   4.97687012e-02  -5.78710996e-03
    7.11546540e-02  -9.02979076e-02  -1.55580774e-01  -4.86791879e-03
    1.87984183e-02  -1.19697981e-01  -5.82101159e-02  -6.87892213e-02
    2.36857571e-02  -4.31252122e-02  -6.21576980e-03   8.42171088e-02
   -4.06159684e-02  -9.66259614e-02   7.20687062e-02   1.16404966e-02
   -3.89561849e-03  -3.96785140e-02  -7.51595851e-03   4.49706241e-02
    5.94421476e-02  -2.81140339e-02  -1.33695707e-01   1.62613347e-01
    5.93870059e-02   9.36040282e-02  -6.61498159e-02   7.14929998e-02
   -1.19012430e-01   1.50971189e-02  -1.18526988e-01   1.36545748e-01
    3.51573713e-02  -3.18670794e-02   1.17539540e-02  -6.81607947e-02
   -3.61315385e-02  -8.61855969e-02  -5.72934486e-02  -1.29564330e-01
   -1.99375674e-04   2.04204351e-01   1.36756808e-01   8.71752277e-02
    6.31617010e-02  -6.12332262e-02  -4.88702431e-02  -1.15969870e-02]]
After layer encoder_birnn_reverse_l0_t2_slice_output3 (1, 256) <class 'numpy.float32'> [[  5.47676720e-02   1.18736178e-02  -1.70244519e-02   4.35999967e-02
    7.78535232e-02   1.84729069e-01   1.02725007e-01   1.33652478e-01
    2.70024091e-01   1.29068345e-01  -1.35773066e-02   7.16543049e-02
    1.16428800e-01  -3.59403938e-02   3.00855301e-02   9.27785039e-02
   -3.22539657e-02  -1.86948124e-02   2.57482938e-03  -2.67496947e-02
   -1.73905715e-02  -1.30156517e-01   2.05531865e-01   9.16576013e-02
    9.50768292e-02   1.07809231e-02  -2.40573380e-03   2.44751908e-02
   -5.88300265e-02   3.04868482e-02   8.97676647e-02   1.10212602e-01
    3.19280773e-02   1.37843043e-02  -2.74885669e-02   5.03964908e-03
    8.67267400e-02  -2.17459239e-02   9.97929573e-02   1.40123293e-02
    1.08435035e-01  -2.51257867e-02  -1.14831887e-03   2.06512585e-03
   -2.04950050e-02   7.12636113e-03   2.50320099e-02  -3.66896689e-02
    5.65247163e-02   4.02152725e-02   9.67959687e-02  -7.43520260e-02
    7.87274241e-02   6.01893999e-02   2.26597473e-01  -9.92720872e-02
    1.15141578e-01   2.82424353e-02   2.17015836e-02  -8.61055553e-02
    2.65637226e-02   1.47478282e-03   3.60657014e-02   1.29837990e-01
   -1.39665725e-02  -4.46767844e-02   1.24995522e-01   5.87728098e-02
    7.03921393e-02   1.18998326e-01   1.40421763e-02   4.90422994e-02
    3.50611955e-02  -2.82479487e-02   6.01239800e-02   2.34330922e-01
    1.03370182e-01   6.15416728e-02   9.48460847e-02   1.71736404e-01
    1.28380820e-01   1.73066616e-01   7.98785016e-02   1.37504697e-01
    9.70447958e-02   7.49487653e-02   4.01271544e-02   1.36029363e-01
    6.42099679e-02   1.46863669e-01   1.16204716e-01  -1.32487100e-02
   -8.52984339e-02   3.76242846e-02   6.28009886e-02   2.59405822e-02
    7.68851265e-02   1.50896996e-01  -1.05749726e-01  -4.03424986e-02
    2.69589014e-02  -9.83646736e-02  -2.01786179e-02  -5.80462776e-02
    3.81476767e-02   1.76657308e-02  -3.95058915e-02   1.28545299e-01
    3.88876908e-02   1.97095394e-01   7.60742649e-03   4.10238579e-02
   -6.66290969e-02   1.12993255e-01   4.60997447e-02   1.36621743e-01
   -8.34723860e-02  -4.24238406e-02   1.43377244e-01  -8.81076157e-02
    4.10000384e-02   7.49606937e-02   1.19446367e-01  -6.31557032e-03
   -8.16216879e-03   2.77848504e-02  -1.26366829e-02  -3.04222275e-02
   -5.09840436e-02  -2.62167677e-03   1.43765584e-02   1.67229921e-01
    2.57504620e-02   1.03288397e-01   1.87454596e-02  -4.49528471e-02
    1.04930505e-01   6.66057914e-02   1.11331381e-01   3.99136096e-02
   -6.84976205e-03   2.25468427e-02  -1.11029491e-01   3.06350924e-02
    1.66679397e-02   1.93887800e-02   1.04543045e-01   2.57402770e-02
    5.00739887e-02  -1.14965718e-02  -4.95977700e-04  -4.07056510e-02
    3.94603983e-02   1.26317233e-01   7.28036091e-02   9.16218162e-02
    4.19680290e-02   1.81412101e-01   3.90557498e-02   1.10790789e-01
    4.53877300e-02   3.51127908e-02  -3.33727300e-02   1.34030253e-01
    9.23978835e-02  -6.11973591e-02   1.81040749e-01   8.04578513e-02
   -5.80615550e-02   4.35823351e-02  -6.70857579e-02   7.48578459e-02
    8.92264545e-02   1.46311045e-01   5.88672683e-02   1.25361800e-01
    1.34618789e-01  -8.30465183e-03   1.06622182e-01  -7.00965524e-04
   -4.80870120e-02  -3.62966880e-02   4.87715118e-02   3.33117694e-03
   -1.30160823e-02   5.18406220e-02  -1.76721476e-02   8.18790495e-02
    1.02441922e-01  -2.33497769e-02   6.15231618e-02   1.22408330e-01
    5.31976297e-02  -1.44545250e-02   1.55281052e-01   5.72978072e-02
   -1.51310321e-02   6.77195936e-02   6.28865510e-02  -1.13380738e-02
    4.86765504e-02   2.11316645e-01   9.53786224e-02   1.30500734e-01
    7.32947886e-02   8.22525471e-02  -3.80130708e-02   1.88880879e-03
   -4.42051999e-02   1.20639324e-01  -2.63570026e-02   2.70408273e-01
    2.24481262e-02   1.22745998e-01   8.45428705e-02  -3.28439660e-03
    6.52251691e-02   1.34483606e-01  -3.98347005e-02  -5.46528548e-02
   -5.90340681e-02  -5.96505739e-02   1.04863100e-01   1.90488994e-03
    7.74266422e-02   7.88293332e-02   2.08223686e-02  -1.14866532e-02
    2.21250594e-01   2.15802848e-01   4.51606438e-02  -4.94988337e-02
    1.17783044e-02   4.27365303e-05  -1.76787432e-02   1.28617138e-02
   -2.09453367e-02   6.17677271e-02   9.77518409e-02   1.45938583e-02
   -1.82708874e-02   9.65533555e-02   1.96282417e-01   3.15286040e-01
   -6.43467754e-02   6.30675554e-02   9.91879329e-02  -9.56137925e-02
    5.40192053e-03   3.90363894e-02   8.87673423e-02  -5.24247847e-02
    7.34119043e-02   1.23308256e-01   5.41009009e-03   8.48743021e-02]]
After layer encoder_birnn_reverse_l0_t2_o_output (1, 256) <class 'numpy.float32'> [[ 0.5136885   0.50296837  0.49574399  0.51089829  0.51945359  0.54605138
   0.52565867  0.53336346  0.5670988   0.53222239  0.49660569  0.51790589
   0.52907437  0.49101591  0.50752085  0.52317804  0.49193722  0.4953264
   0.50064373  0.49331301  0.49565244  0.46750674  0.55120283  0.52289838
   0.52375138  0.5026952   0.49939859  0.50611848  0.48529673  0.50762117
   0.52242684  0.52752531  0.50798136  0.50344604  0.49312827  0.50125992
   0.52166814  0.49456373  0.52492756  0.50350302  0.5270822   0.49371889
   0.49971288  0.5005163   0.49487644  0.50178158  0.50625771  0.49082857
   0.51412743  0.51005244  0.52418011  0.48142052  0.51967168  0.51504278
   0.55640817  0.47520232  0.52875364  0.50706011  0.50542516  0.47848687
   0.50664055  0.50036871  0.50901544  0.53241396  0.49650842  0.48883265
   0.53120828  0.51468897  0.51759076  0.52971452  0.50351053  0.51225811
   0.50876439  0.49293846  0.51502645  0.55831611  0.52581954  0.51538056
   0.52369374  0.54282886  0.53205121  0.54315895  0.51995903  0.53432208
   0.52424222  0.51872844  0.51003039  0.53395498  0.516047    0.53665006
   0.52901852  0.49668792  0.47868833  0.50940496  0.5156951   0.50648481
   0.51921183  0.53765285  0.47358719  0.48991576  0.50673932  0.47542867
   0.49495551  0.48549253  0.50953573  0.50441635  0.49012482  0.53209215
   0.50972068  0.54911494  0.50190187  0.51025456  0.48334891  0.52821827
   0.51152289  0.53410238  0.47914401  0.48939562  0.53578305  0.47798735
   0.5102486   0.51873142  0.52982616  0.49842107  0.49795946  0.50694579
   0.49684089  0.49239507  0.48725674  0.49934462  0.5035941   0.54171032
   0.5064373   0.52579916  0.50468624  0.48876369  0.52620858  0.51664531
   0.52780414  0.5099771   0.49828753  0.50563645  0.47227111  0.50765818
   0.5041669   0.50484705  0.52611202  0.50643474  0.5125159   0.49712592
   0.49987599  0.48982501  0.50986385  0.53153735  0.51819289  0.52288944
   0.51049048  0.54522908  0.5097627   0.52766943  0.51134497  0.50877726
   0.49165761  0.53345752  0.52308309  0.48470545  0.54513699  0.52010363
   0.48548871  0.51089388  0.48323485  0.51870573  0.52229178  0.53651261
   0.51471257  0.53129947  0.53360397  0.49792379  0.52663034  0.49982476
   0.48798054  0.49092683  0.51219046  0.5008328   0.49674603  0.51295727
   0.4955821   0.52045834  0.5255881   0.49416286  0.51537591  0.53056395
   0.51329625  0.49638644  0.53874248  0.51432055  0.49621737  0.51692343
   0.51571649  0.4971655   0.51216674  0.55263346  0.5238266   0.532579
   0.51831549  0.52055156  0.49049786  0.50047219  0.48895046  0.53012335
   0.49341112  0.56719309  0.50561178  0.53064805  0.52112317  0.49917892
   0.5163005   0.53357035  0.49004266  0.48634022  0.48524573  0.48509175
   0.52619177  0.50047624  0.51934701  0.51969713  0.50520539  0.4971284
   0.5550881   0.55374229  0.51128823  0.48762783  0.50294453  0.50001073
   0.49558043  0.50321543  0.49476382  0.51543707  0.52441853  0.5036484
   0.49543241  0.52411962  0.54891366  0.57817501  0.48391888  0.51576167
   0.5247767   0.47611472  0.50135052  0.50975788  0.52217728  0.48689675
   0.5183447   0.53078806  0.50135255  0.52120584]]
After layer encoder_birnn_reverse_l0_t2_f_output (1, 256) <class 'numpy.float32'> [[ 0.52649075  0.50469381  0.51828879  0.5124765   0.50683773  0.51275986
   0.53647262  0.48851547  0.56087768  0.52225196  0.5328874   0.51680315
   0.52119911  0.50457013  0.52339017  0.52227998  0.51792634  0.4909952
   0.47503161  0.50844985  0.52260441  0.49738425  0.55129206  0.51339996
   0.52433151  0.52056122  0.5275529   0.52653778  0.51914531  0.50009972
   0.50032884  0.49441153  0.5494566   0.49102005  0.49872154  0.5069831
   0.48647109  0.51401234  0.49990466  0.52049112  0.51475149  0.52147061
   0.50086164  0.5282101   0.50292611  0.52327585  0.50719684  0.49143967
   0.50018001  0.50826305  0.50977045  0.50732464  0.52280825  0.52780062
   0.53670126  0.52243906  0.5039658   0.5171867   0.50773048  0.49109346
   0.50231791  0.51174909  0.49649003  0.51657814  0.49781591  0.52998394
   0.54252654  0.51775354  0.48903441  0.50866234  0.51590359  0.49182451
   0.49903581  0.50260484  0.5216158   0.55085081  0.51229656  0.50251096
   0.50632274  0.51588809  0.5459429   0.53008497  0.50675386  0.50552779
   0.52945042  0.50654125  0.51206177  0.55082786  0.5071128   0.48711401
   0.55078882  0.52329457  0.51867729  0.51928455  0.49400976  0.50409991
   0.51081342  0.53853834  0.47975871  0.47579023  0.50911635  0.50472504
   0.49723235  0.52125818  0.50635946  0.49698418  0.48330957  0.51582634
   0.5025034   0.49504307  0.49230295  0.50257254  0.49797785  0.52288157
   0.52626258  0.54222941  0.52003956  0.52565986  0.54347831  0.52097082
   0.53855705  0.53102458  0.50156713  0.50407553  0.50679088  0.4965291
   0.53087544  0.49920163  0.52109343  0.48631135  0.51358742  0.54582399
   0.5063799   0.5354448   0.52814573  0.52562481  0.50708854  0.50210375
   0.53128141  0.52759343  0.48428446  0.52062792  0.518179    0.51133388
   0.50512093  0.52578497  0.49988571  0.50321859  0.50117636  0.49773261
   0.49156836  0.51394945  0.5015192   0.51535225  0.52430719  0.54070306
   0.5273931   0.51313263  0.49977538  0.52601349  0.54647332  0.51949465
   0.49093366  0.51798469  0.50656253  0.50496769  0.54999959  0.48502499
   0.50086945  0.49549666  0.51526487  0.52012706  0.48402035  0.53848052
   0.50173253  0.51689041  0.53228962  0.50569075  0.50229609  0.52316433
   0.52240735  0.48358184  0.54249257  0.49128968  0.50965822  0.49244201
   0.50547332  0.53036755  0.5343039   0.50183898  0.49090374  0.50486523
   0.53576791  0.53418553  0.52515143  0.49735311  0.49302295  0.50542367
   0.50486469  0.50333625  0.50312448  0.52247727  0.52441794  0.48847246
   0.51161689  0.47937435  0.50112039  0.53146744  0.50707018  0.50967044
   0.51120907  0.53002304  0.48821875  0.50536186  0.49182883  0.48982742
   0.5093146   0.51893389  0.50359344  0.52173787  0.47835952  0.50096488
   0.54816496  0.50795889  0.51160872  0.49787888  0.50739664  0.50400788
   0.55848414  0.56084305  0.49941251  0.45471373  0.52965617  0.50867605
   0.5135597   0.50103754  0.50928301  0.52112693  0.50152361  0.52325517
   0.52105886  0.4974378   0.5247488   0.55682904  0.47449604  0.49517635
   0.50842994  0.4789243   0.51613969  0.49951708  0.52240646  0.48160613
   0.52913225  0.49364486  0.53004879  0.50351411]]
After layer _mul2076_0 (1, 256) <class 'numpy.float32'> [[-0.02681434 -0.01386805  0.01561502  0.01159086  0.02712731 -0.01591369
   0.01152936  0.00195587 -0.03049557 -0.04782204 -0.01947491  0.01324714
   0.02833082 -0.02878551  0.03404516 -0.03673825  0.00492537 -0.00890168
   0.00751175  0.01730696  0.0397979  -0.0337498   0.01327658  0.015348
   0.008544    0.00176327 -0.03901231  0.00419545 -0.00971758 -0.01771049
   0.02427223 -0.03645782  0.02430499 -0.02469169  0.01333441 -0.03388276
  -0.02349101 -0.02475246 -0.00795036  0.01311234  0.03354688  0.00573646
   0.02364476  0.00725591  0.03127695 -0.03555173  0.02307377 -0.00810059
  -0.00269291  0.00414275 -0.02058327 -0.02610127 -0.01791771  0.01546994
   0.01884487 -0.01059719 -0.0242666   0.04962961  0.01150494 -0.03391039
  -0.03525122 -0.01193407 -0.01033532 -0.0088536   0.05328017 -0.01877405
   0.04278816  0.02408137 -0.02016964 -0.00595839 -0.0578756   0.03024853
   0.01008504 -0.02062343  0.03860261 -0.01018902 -0.05317248 -0.02448183
  -0.02493435 -0.01523684 -0.01716915 -0.02795969 -0.00365841 -0.04381831
  -0.03767122  0.02037626 -0.01306377  0.01990409 -0.01863671 -0.00890373
   0.0248549   0.0091691   0.01280496 -0.02301573 -0.00525903 -0.00702084
   0.00280949 -0.02433394  0.00047649 -0.01124686  0.03635215  0.01740389
  -0.02939639  0.01094259 -0.02115672  0.02508455 -0.00889074 -0.01018197
   0.00698074 -0.00523926  0.03351699  0.03097205  0.00462282  0.03132651
  -0.02831717  0.00633124 -0.02166393 -0.02985888  0.02617533  0.02130585
   0.0157201   0.0340011  -0.00411216 -0.02920804  0.02369792 -0.04337022
   0.02492315 -0.03323859  0.00511856  0.04209034  0.03075399 -0.01253962
   0.0142254  -0.02820271  0.02320802  0.0241255   0.02835911  0.03073527
  -0.00849447  0.0275399  -0.01453867 -0.01629915  0.03664522 -0.01071291
  -0.0030031   0.01452759  0.02972355 -0.03218905  0.00704152  0.00864801
  -0.01424841 -0.00473553 -0.01725904 -0.00948572  0.02185337  0.00288158
  -0.02113339  0.00846318  0.01071088  0.02266738 -0.06616537 -0.02974012
  -0.00506485 -0.00279263 -0.00206655  0.02787678 -0.00071199 -0.04659367
  -0.04278626 -0.02976436 -0.03186224  0.02439583 -0.00908922 -0.02733975
   0.00665259  0.00329569  0.05717532 -0.0276801  -0.03022545 -0.01464268
   0.03372679  0.01150364  0.01073912 -0.00279213  0.03868213 -0.02287916
   0.00563801 -0.04206505  0.02265508 -0.01130669  0.05568774  0.03164208
  -0.01740135  0.00161611 -0.05012372  0.0185828  -0.0360185  -0.03960136
   0.0164566   0.03202615 -0.01796342 -0.01429707  0.04100436 -0.00989411
   0.03245533 -0.01092728 -0.00232132  0.00057757  0.05995407 -0.03471049
   0.006279    0.0306862   0.01829902 -0.0043451  -0.01509853 -0.02286687
  -0.0055549  -0.00110433  0.01297413  0.03082006  0.01872274  0.00405997
   0.01854309 -0.02090524 -0.00239416 -0.00080868  0.00257082  0.00258076
   0.00352726  0.00435285 -0.02190216  0.00404044  0.02497533  0.00836605
  -0.02306317  0.00963456 -0.02101821  0.00915947 -0.02637711  0.01422189
   0.00128884 -0.02122605  0.00851059 -0.03267181 -0.01933924 -0.00950874
  -0.00236136 -0.00258294 -0.01035279  0.04591556  0.04928738  0.01261216
   0.0151447  -0.00747078  0.00986209 -0.03346362]]
After layer encoder_birnn_reverse_l0_t2_i_output (1, 256) <class 'numpy.float32'> [[ 0.50191665  0.49790543  0.51039529  0.49471912  0.5190354   0.50680989
   0.51705337  0.50787395  0.51777881  0.51405466  0.48939145  0.51031184
   0.50684202  0.5141381   0.50056309  0.55428404  0.49283555  0.48982668
   0.50499713  0.49315935  0.52157134  0.51706761  0.4852618   0.48686138
   0.52073514  0.47764522  0.49449083  0.4985117   0.51385969  0.50193536
   0.49863669  0.48729703  0.49287927  0.49024698  0.51778448  0.48192531
   0.50154942  0.49772954  0.48914775  0.49344522  0.4878723   0.5156669
   0.48601291  0.50246692  0.5103066   0.50111711  0.51769048  0.4824678
   0.50474042  0.49663177  0.49322084  0.51963204  0.50599217  0.51718056
   0.55378133  0.51759058  0.49265099  0.49753836  0.49687797  0.49392459
   0.51438701  0.48887134  0.5330773   0.4936612   0.47617364  0.48766905
   0.52287608  0.49834386  0.49634209  0.51281965  0.5225687   0.49586046
   0.50160152  0.50237399  0.49173248  0.52550769  0.53080177  0.5245378
   0.49401879  0.50752473  0.50613528  0.50677174  0.52164537  0.49666303
   0.53614777  0.51748836  0.49267721  0.50003684  0.48787826  0.54185033
   0.53627843  0.49743214  0.48022023  0.53177989  0.51602757  0.51298559
   0.4949415   0.53545499  0.48613063  0.48003337  0.49407199  0.51647949
   0.49421445  0.46409437  0.49641222  0.49802041  0.49967262  0.4704369
   0.5106737   0.52318329  0.46555603  0.51560253  0.4969193   0.53221995
   0.49750507  0.56305522  0.4946951   0.50326133  0.53073853  0.49689716
   0.54728192  0.47687992  0.49659842  0.52149969  0.48715979  0.51227832
   0.47653219  0.51181912  0.49762866  0.49980327  0.5288862   0.51750153
   0.50613052  0.49693313  0.49303815  0.49827376  0.52052295  0.53368348
   0.50487494  0.49727196  0.49209324  0.48622769  0.50964838  0.51825905
   0.49438703  0.50197738  0.50609851  0.51880509  0.49423051  0.5152629
   0.51836902  0.49238214  0.5007953   0.48076418  0.4946329   0.54509205
   0.51022553  0.53270262  0.49870202  0.49556863  0.53488147  0.49973181
   0.49457428  0.51407421  0.50934845  0.49138308  0.50752825  0.49285305
   0.51855844  0.49628159  0.50857139  0.50732672  0.50120485  0.51975256
   0.51034868  0.47870499  0.50942487  0.47707281  0.48997998  0.49603501
   0.50455856  0.49193156  0.48862714  0.51199675  0.52516538  0.49253288
   0.49593502  0.48673528  0.53597391  0.525729    0.49829081  0.50616258
   0.50808865  0.50542021  0.5413112   0.5133962   0.51275605  0.46787637
   0.51171005  0.50496459  0.49859598  0.5445708   0.5153597   0.50088888
   0.50993556  0.5017339   0.50110936  0.49219757  0.4926728   0.50943685
   0.50463521  0.51909149  0.50357616  0.51906943  0.50750118  0.5213114
   0.49896669  0.49351412  0.49915063  0.50192171  0.48753023  0.50206023
   0.50868952  0.4771513   0.50393575  0.52078742  0.49284115  0.48537949
   0.49389762  0.54897535  0.49464446  0.49686986  0.49872556  0.4967055
   0.5081802   0.51656854  0.49830785  0.50891691  0.50645274  0.49011704
   0.49236143  0.48257762  0.53566593  0.55447882  0.49388808  0.51159739
   0.51296693  0.48543742  0.50092518  0.51707679  0.53040558  0.5037837
   0.48569313  0.5118565   0.50739938  0.49145666]]
After layer encoder_birnn_reverse_l0_t2_c_output (1, 256) <class 'numpy.float32'> [[ -1.17738694e-01  -1.18732408e-01   3.46401706e-03   3.65396924e-02
    3.79554182e-02  -3.87023389e-02   4.27317135e-02   1.07938468e-01
    5.05872630e-02  -4.33550999e-02  -6.20613433e-02   9.23817679e-02
    9.35539007e-02  -3.45692076e-02   5.27493954e-02  -1.76244289e-01
    1.35312779e-02   5.36280777e-03   7.14531541e-02   4.77717593e-02
    1.61139354e-01  -1.64540838e-02   8.00828275e-04   8.36246461e-02
   -1.05671249e-01   3.75765190e-02   6.13698885e-02  -2.47773025e-02
   -1.31610021e-01  -7.68059641e-02   1.33088641e-02  -1.25960037e-01
   -3.72789763e-02   6.58115000e-03   1.05312735e-01  -1.16141036e-01
   -6.94058985e-02  -7.41413468e-03  -1.16777770e-01  -9.66315717e-02
    3.94509919e-02  -1.61351696e-01   1.08975261e-01   9.39351693e-02
    7.94220939e-02  -9.15577859e-02   3.91906388e-02  -7.74344727e-02
   -5.20907389e-03  -7.81937391e-02   5.13392910e-02  -8.75297561e-02
   -6.40809089e-02   6.60576373e-02   6.21641949e-02   3.41393985e-02
   -5.83188348e-02   1.52217910e-01   6.62819520e-02  -5.03211953e-02
   -3.83846797e-02  -9.94057581e-02  -4.66816500e-02   1.68893486e-04
    6.06625117e-02  -2.73816045e-02   4.12677564e-02  -7.07908198e-02
   -1.24748111e-01  -4.55667675e-02  -1.91018909e-01  -1.95657164e-02
    6.68984726e-02   4.35880981e-02   1.11843526e-01  -6.21572658e-02
    1.57374016e-03  -1.28414080e-01  -4.21630703e-02  -1.98923070e-02
   -8.52195323e-02   2.71685831e-02  -6.90176040e-02  -1.20339721e-01
   -2.06427023e-01   2.26495713e-02  -1.58932477e-01   3.91804166e-02
   -1.20748945e-01  -1.13625541e-01  -8.81712958e-02  -6.53854087e-02
   -3.48158889e-02  -1.93302464e-02  -4.08256166e-02   3.47244740e-02
    1.08632647e-01  -2.24316157e-02  -1.14092290e-01  -5.13133369e-02
    3.00685614e-02   1.19813487e-01  -7.01607242e-02   4.41780575e-02
    5.99009804e-02   6.88730851e-02  -4.68239821e-02  -4.01053205e-02
    1.48165464e-01  -1.51692152e-01   4.92653400e-02   1.03807282e-02
    4.76073921e-02   3.49390768e-02  -8.68620723e-02   2.24666089e-01
   -1.11629516e-01  -3.23806927e-02   2.84725055e-02  -4.41504568e-02
    1.16064094e-01   1.01979211e-01  -3.05165369e-02  -5.83214760e-02
    1.04018502e-01  -1.47830456e-01  -8.14251825e-02  -3.93039696e-02
   -3.48062515e-02  -3.54922079e-02   5.54399453e-02  -5.52841909e-02
    7.77804032e-02  -1.90776456e-02  -3.28495656e-03   5.24830781e-02
    1.09909147e-01   1.69573739e-01  -4.62216837e-03   5.07356375e-02
   -1.23498905e-02  -5.50859608e-02   1.02861501e-01   1.45144137e-02
   -1.24180205e-01   8.07152763e-02   3.87897231e-02  -1.17816508e-01
   -1.03059761e-01  -9.02076140e-02  -7.10179284e-02  -3.42119746e-02
   -2.76541375e-02  -1.03157520e-01  -4.02060710e-02   6.36403635e-02
   -9.06483382e-02   6.77848235e-02   5.26442155e-02   5.23115918e-02
   -1.46104053e-01  -7.40210786e-02   4.32224162e-02   1.45628065e-01
    1.99751016e-02   8.07404146e-02   7.69684045e-03  -7.01954514e-02
   -1.26768827e-01   2.08150707e-02  -6.49494603e-02   1.43082878e-02
   -1.93543807e-02  -1.21681154e-01  -2.11470444e-02   6.76245540e-02
    1.11167654e-01  -3.92478816e-02  -7.55626336e-02  -3.97307687e-02
    6.30369112e-02  -1.03693204e-02   2.80267745e-02  -2.97336709e-02
   -6.28463626e-02   7.12115467e-02   3.43770236e-02  -9.45807248e-02
    9.29734185e-02  -1.07308492e-01   1.37817979e-01  -3.02141700e-02
    3.20562609e-02  -1.15818493e-02  -1.11026928e-01  -1.13253891e-02
   -1.68038890e-01  -7.76532739e-02  -2.02511735e-02   2.50380822e-02
   -1.29034460e-01  -2.42467970e-04   1.59100205e-01  -7.03046843e-02
   -2.64279917e-02  -2.03309581e-04   4.97276522e-02  -5.78704523e-03
    7.10348114e-02  -9.00532901e-02  -1.54337525e-01  -4.86788014e-03
    1.87962037e-02  -1.19129583e-01  -5.81444576e-02  -6.86809272e-02
    2.36813296e-02  -4.30984981e-02  -6.21568970e-03   8.40185732e-02
   -4.05936502e-02  -9.63263661e-02   7.19441921e-02   1.16399704e-02
   -3.89559870e-03  -3.96577045e-02  -7.51581695e-03   4.49403338e-02
    5.93722351e-02  -2.81066298e-02  -1.32904783e-01   1.61195025e-01
    5.93172908e-02   9.33316052e-02  -6.60535023e-02   7.13714436e-02
   -1.18453704e-01   1.50959725e-02  -1.17975049e-01   1.35703415e-01
    3.51428948e-02  -3.18562984e-02   1.17534129e-02  -6.80554360e-02
   -3.61158252e-02  -8.59728381e-02  -5.72308414e-02  -1.28844172e-01
   -1.99375674e-04   2.01412514e-01   1.35910586e-01   8.69550705e-02
    6.30778447e-02  -6.11568093e-02  -4.88313735e-02  -1.15964673e-02]]
After layer _mul2077_0 (1, 256) <class 'numpy.float32'> [[ -5.90950102e-02  -5.91175109e-02   1.76801800e-03   1.80768836e-02
    1.97002050e-02  -1.96147282e-02   2.20945757e-02   5.48191369e-02
    2.61930134e-02  -2.22868901e-02  -3.03722899e-02   4.71435115e-02
    4.74170484e-02  -1.77733470e-02   2.64043994e-02  -9.76893976e-02
    6.66869478e-03   2.62684631e-03   3.60836387e-02   2.35590898e-02
    8.40456709e-02  -8.50787386e-03   3.88611370e-04   4.07136120e-02
   -5.50267324e-02   1.79482438e-02   3.03468481e-02  -1.23517755e-02
   -6.76290840e-02  -3.85516286e-02   6.63628802e-03  -6.13799505e-02
   -1.83740351e-02   3.22638894e-03   5.45292981e-02  -5.59713058e-02
   -3.48104872e-02  -3.69023392e-03  -5.71215823e-02  -4.76823859e-02
    1.92470457e-02  -8.32037255e-02   5.29633835e-02   4.71993163e-02
    4.05296199e-02  -4.58811745e-02   2.02886201e-02  -3.73596400e-02
   -2.62923003e-03  -3.88334952e-02   2.53216084e-02  -4.54832651e-02
   -3.24244387e-02   3.41637246e-02   3.44253704e-02   1.76702309e-02
   -2.87308320e-02   7.57342502e-02   3.29340398e-02  -2.48548761e-02
   -1.97445806e-02  -4.85966243e-02  -2.48849280e-02   8.33761587e-05
    2.88858898e-02  -1.33531615e-02   2.15779226e-02  -3.52781713e-02
   -6.19177371e-02  -2.33675335e-02  -9.98205021e-02  -9.70186479e-03
    3.35563757e-02   2.18975265e-02   5.49970940e-02  -3.26641202e-02
    8.35344079e-04  -6.73580393e-02  -2.08293498e-02  -1.00958375e-02
   -4.31326106e-02   1.37682706e-02  -3.60027142e-02  -5.97682893e-02
   -1.10675387e-01   1.17208892e-02  -7.83024132e-02   1.95916519e-02
   -5.89107871e-02  -6.15680367e-02  -4.72843647e-02  -3.25248055e-02
   -1.67192947e-02  -1.02794366e-02  -2.10671443e-02   1.78131554e-02
    5.37668057e-02  -1.20111201e-02  -5.54637574e-02  -2.46321131e-02
    1.48560340e-02   6.18812107e-02  -3.46744433e-02   2.05027871e-02
    2.97355782e-02   3.43002006e-02  -2.33966615e-02  -1.88670233e-02
    7.56642073e-02  -7.93628022e-02   2.29357760e-02   5.35232993e-03
    2.36570314e-02   1.85952727e-02  -4.32143211e-02   1.26499414e-01
   -5.52225746e-02  -1.62959509e-02   1.51114557e-02  -2.19382364e-02
    6.35197833e-02   4.86318395e-02  -1.51544642e-02  -3.04146316e-02
    5.06736301e-02  -7.57303387e-02  -3.88017222e-02  -2.01165229e-02
   -1.73205882e-02  -1.77391209e-02   2.93214228e-02  -2.86096539e-02
    3.93670350e-02  -9.48031433e-03  -1.61960896e-03   2.61509400e-02
    5.72102331e-02   9.04987007e-02  -2.33361707e-03   2.52294093e-02
   -6.07729750e-03  -2.67843194e-02   5.24231978e-02   7.52222631e-03
   -6.13930821e-02   4.05172445e-02   1.96314212e-02  -6.11238033e-02
   -5.09352796e-02  -4.64806370e-02  -3.68134938e-02  -1.68453660e-02
   -1.38490619e-02  -4.95944396e-02  -1.98872462e-02   3.46898548e-02
   -4.62510958e-02   3.61091532e-02   2.62537766e-02   2.59239841e-02
   -7.81483501e-02  -3.69906873e-02   2.13766955e-02   7.48636350e-02
    1.01742875e-02   3.96744721e-02   3.90636409e-03  -3.45960408e-02
   -6.57370463e-02   1.03301369e-02  -3.30314375e-02   7.25897681e-03
   -9.70050972e-03  -6.32440895e-02  -1.07923662e-02   3.23722102e-02
    5.66315688e-02  -1.87240969e-02  -3.70241776e-02  -1.97078530e-02
    3.18058133e-02  -5.10099577e-03   1.36946421e-02  -1.52235432e-02
   -3.30047347e-02   3.50740291e-02   1.70487706e-02  -4.60357778e-02
    4.98313271e-02  -5.64151853e-02   6.86734319e-02  -1.52932825e-02
    1.62874218e-02  -5.85370092e-03  -6.01001196e-02  -5.81441168e-03
   -8.61629546e-02  -3.63321342e-02  -1.03627294e-02   1.26433447e-02
   -6.43360615e-02  -1.32040979e-04   8.19938332e-02  -3.52148339e-02
   -1.34765729e-02  -1.02007310e-04   2.49189921e-02  -2.84836954e-03
    3.49969193e-02  -4.58764657e-02  -7.78841525e-02  -2.52687512e-03
    9.46532004e-03  -6.18365258e-02  -2.95083802e-02  -3.58041488e-02
    1.18161943e-02  -2.12697182e-02  -3.10256542e-03   4.21707444e-02
   -1.97906308e-02  -4.83616367e-02   3.65972556e-02   5.55402692e-03
   -1.96313136e-03  -2.06532329e-02  -3.70410387e-03   2.18131170e-02
    2.93238051e-02  -1.54298469e-02  -6.57406151e-02   8.00929517e-02
    2.95830499e-02   4.63583209e-02  -3.35670821e-02   3.68682407e-02
   -5.90264127e-02   7.68259587e-03  -5.97487874e-02   6.65105581e-02
    1.73030067e-02  -1.53731368e-02   6.29590265e-03  -3.77352983e-02
   -1.78371761e-02  -4.39834818e-02  -2.93575283e-02  -6.25457838e-02
   -9.98722971e-05   1.04145736e-01   7.20877349e-02   4.38065492e-02
    3.06364764e-02  -3.13035101e-02  -2.47770082e-02  -5.69916097e-03]]
After layer encoder_birnn_reverse_l0_t2_state_0 (1, 256) <class 'numpy.float32'> [[-0.08590934 -0.07298556  0.01738304  0.02966774  0.04682751 -0.03552841
   0.03362394  0.056775   -0.00430256 -0.07010893 -0.0498472   0.06039065
   0.07574787 -0.04655886  0.06044956 -0.13442764  0.01159406 -0.00627484
   0.04359538  0.04086605  0.12384357 -0.04225767  0.01366519  0.05606161
  -0.04648273  0.01971152 -0.00866546 -0.00815633 -0.07734667 -0.05626212
   0.03090852 -0.09783777  0.00593095 -0.02146531  0.06786371 -0.08985406
  -0.0583015  -0.02844269 -0.06507194 -0.03457005  0.05279393 -0.07746726
   0.07660814  0.05445523  0.07180656 -0.08143291  0.04336239 -0.04546024
  -0.00532214 -0.03469075  0.00473834 -0.07158453 -0.05034215  0.04963367
   0.05327024  0.00707304 -0.05299743  0.12536386  0.04443898 -0.05876527
  -0.0549958  -0.0605307  -0.03522024 -0.00877022  0.08216606 -0.03212722
   0.06436608 -0.0111968  -0.08208738 -0.02932593 -0.1576961   0.02054666
   0.04364141  0.0012741   0.09359971 -0.04285314 -0.05233714 -0.09183986
  -0.0457637  -0.02533267 -0.06030176 -0.01419142 -0.03966112 -0.1035866
  -0.1483466   0.03209715 -0.09136619  0.03949574 -0.07754749 -0.07047177
  -0.02242946 -0.0233557  -0.00391434 -0.03329516 -0.02632617  0.01079231
   0.0565763  -0.03634506 -0.05498726 -0.03587897  0.05120819  0.0792851
  -0.06407084  0.03144538  0.00857886  0.05938475 -0.0322874  -0.029049
   0.08264495 -0.08460207  0.05645277  0.03632438  0.02827985  0.04992179
  -0.07153149  0.13283065 -0.0768865  -0.04615483  0.04128679 -0.00063238
   0.07923989  0.08263294 -0.01926662 -0.05962267  0.07437155 -0.11910056
  -0.01387857 -0.05335511 -0.01220203  0.02435122  0.06007541 -0.04114927
   0.05359243 -0.03768302  0.02158841  0.05027644  0.08556934  0.12123397
  -0.01082809  0.05276931 -0.02061597 -0.04308347  0.08906841 -0.00319068
  -0.06439618  0.05504483  0.04935497 -0.09331284 -0.04389375 -0.03783263
  -0.05106191 -0.0215809  -0.0311081  -0.05908016  0.00196613  0.03757144
  -0.06738449  0.04457233  0.03696466  0.04859136 -0.14431372 -0.06673081
   0.01631184  0.07207101  0.00810774  0.06755125  0.00319438 -0.08118971
  -0.10852331 -0.01943423 -0.06489368  0.0316548  -0.01878973 -0.09058385
  -0.00413978  0.0356679   0.11380689 -0.0464042  -0.06724963 -0.03435053
   0.06553259  0.00640265  0.02443376 -0.01801567  0.0056774   0.01219486
   0.02268678 -0.08810084  0.0724864  -0.06772187  0.12436117  0.0163488
  -0.00111393 -0.00423759 -0.11022384  0.01276839 -0.12218146 -0.07593349
   0.00609387  0.04466949 -0.08229949 -0.01442911  0.12299819 -0.04510895
   0.01897876 -0.01102929  0.02259768 -0.0022708   0.09495099 -0.08058695
  -0.07160515  0.02815933  0.02776434 -0.06618162 -0.04460691 -0.05867102
   0.00626129 -0.02237405  0.00987157  0.0729908  -0.00106789 -0.04430167
   0.05514034 -0.01535121 -0.0043573  -0.02146192 -0.00113328  0.02439388
   0.03285106 -0.01107699 -0.08764277  0.08413339  0.05455837  0.05472437
  -0.05663025  0.04650281 -0.08004462  0.01684207 -0.0861259   0.08073245
   0.01859185 -0.03659919  0.01480649 -0.07040711 -0.03717642 -0.05349222
  -0.03171889 -0.06512872 -0.01045267  0.15006129  0.12137511  0.05641871
   0.04578118 -0.03877429 -0.01491492 -0.03916278]]
After layer activation1038_output (1, 256) <class 'numpy.float32'> [[-0.08569862 -0.07285624  0.01738128  0.02965904  0.04679331 -0.03551347
   0.03361127  0.05671408 -0.00430253 -0.06999429 -0.04980596  0.06031734
   0.07560333 -0.04652524  0.06037603 -0.13362372  0.01159354 -0.00627475
   0.04356779  0.04084332  0.12321429 -0.04223254  0.01366434  0.05600296
  -0.04644928  0.01970896 -0.00866524 -0.00815615 -0.0771928  -0.05620283
   0.03089868 -0.09752679  0.00593088 -0.02146201  0.06775972 -0.08961302
  -0.05823553 -0.02843503 -0.06498025 -0.03455628  0.05274493 -0.07731267
   0.07645863  0.05440146  0.07168341 -0.08125339  0.04333523 -0.04542895
  -0.00532209 -0.03467684  0.0047383  -0.0714625  -0.05029967  0.04959295
   0.0532199   0.00707292 -0.05294787  0.12471122  0.04440975 -0.05869772
  -0.05494042 -0.06045688 -0.03520569 -0.00877     0.08198165 -0.03211617
   0.06427734 -0.01119633 -0.08190349 -0.02931752 -0.15640178  0.02054377
   0.04361373  0.0012741   0.09332732 -0.04282693 -0.0522894  -0.09158253
  -0.04573178 -0.02532726 -0.06022878 -0.01419047 -0.03964034 -0.10321768
  -0.14726789  0.03208613 -0.0911128   0.03947522 -0.07739242 -0.07035534
  -0.0224257  -0.02335146 -0.00391432 -0.03328286 -0.02632009  0.01079189
   0.05651601 -0.03632906 -0.05493191 -0.03586359  0.05116347  0.07911938
  -0.06398331  0.03143502  0.00857865  0.05931504 -0.03227619 -0.02904083
   0.0824573  -0.0844008   0.05639287  0.03630841  0.02827232  0.04988036
  -0.07140974  0.13205491 -0.07673535 -0.04612209  0.04126335 -0.00063238
   0.07907446  0.08244538 -0.01926424 -0.05955212  0.07423473 -0.11854059
  -0.01387768 -0.05330454 -0.01220142  0.02434641  0.06000324 -0.04112606
   0.05354118 -0.03766519  0.02158505  0.05023412  0.0853611   0.12064349
  -0.01082766  0.05272039 -0.02061305 -0.04305683  0.08883363 -0.00319067
  -0.06430732  0.05498931  0.04931494 -0.09304295 -0.04386559 -0.03781459
  -0.05101757 -0.02157755 -0.03109807 -0.05901152  0.00196612  0.03755377
  -0.06728268  0.04454283  0.03694783  0.04855315 -0.14332016 -0.06663194
   0.0163104   0.07194649  0.00810756  0.06744868  0.00319437 -0.08101179
  -0.10809927 -0.01943178 -0.06480274  0.03164423 -0.01878752 -0.0903369
  -0.00413975  0.03565278  0.11331808 -0.04637092 -0.06714843 -0.03433703
   0.06543895  0.00640256  0.0244289  -0.01801372  0.00567734  0.01219426
   0.02268289 -0.0878736   0.07235971 -0.06761853  0.12372401  0.01634734
  -0.00111393 -0.00423757 -0.10977962  0.0127677  -0.12157708 -0.07578788
   0.00609379  0.04463981 -0.08211418 -0.01442811  0.12238166 -0.04507838
   0.01897648 -0.01102884  0.02259383 -0.00227079  0.09466667 -0.08041295
  -0.07148302  0.02815189  0.02775721 -0.06608517 -0.04457735 -0.05860379
   0.00626121 -0.02237031  0.00987125  0.07286146 -0.00106789 -0.04427271
   0.05508452 -0.01535001 -0.00435727 -0.02145862 -0.00113328  0.02438904
   0.03283925 -0.01107654 -0.08741906  0.08393545  0.05450431  0.05466981
  -0.0565698   0.04646932 -0.07987411  0.01684047 -0.08591358  0.08055751
   0.01858971 -0.03658286  0.01480541 -0.070291   -0.0371593  -0.05344126
  -0.03170826 -0.06503679 -0.01045229  0.14894497  0.12078258  0.05635893
   0.04574922 -0.03875487 -0.01491382 -0.03914277]]
After layer encoder_birnn_reverse_l0_t2_out_0 (1, 256) <class 'numpy.float32'> [[-0.0440224  -0.03664438  0.00861667  0.01515276  0.02430695 -0.01939218
   0.01766806  0.03024922 -0.00243996 -0.03725253 -0.02473392  0.03123871
   0.03999978 -0.02284463  0.0306421  -0.069909    0.0057033  -0.00310805
   0.02181194  0.02014854  0.06107146 -0.019744    0.00753182  0.02928386
  -0.02432787  0.0099076  -0.00432741 -0.00412798 -0.03746141 -0.02852975
   0.0161423  -0.05144785  0.00301278 -0.01080496  0.03341423 -0.04491942
  -0.03037962 -0.01406293 -0.03410992 -0.01739919  0.02780092 -0.03817073
   0.03820736  0.02722882  0.03547443 -0.04077145  0.02193879 -0.02229783
  -0.00273623 -0.01768701  0.00248372 -0.03440351 -0.02613931  0.02554249
   0.02961199  0.00336107 -0.02799638  0.06323609  0.0224458  -0.02808609
  -0.02783505 -0.03025073 -0.01792024 -0.00466927  0.04070458 -0.01569943
   0.03414465 -0.00576263 -0.04239249 -0.01552992 -0.07874995  0.01052371
   0.02218911  0.00062805  0.04806604 -0.02391097 -0.02749479 -0.04719986
  -0.02394945 -0.01374837 -0.03204479 -0.00770768 -0.02061135 -0.05515149
  -0.07720405  0.01664399 -0.0464703   0.02107799 -0.03993813 -0.0377562
  -0.01186361 -0.01159839 -0.00187374 -0.01695446 -0.01357314  0.00546593
   0.02934378 -0.01953242 -0.02601505 -0.01757014  0.02592654  0.03761562
  -0.03166889  0.01526147  0.00437113  0.02991948 -0.01581936 -0.0154524
   0.04203019 -0.04634574  0.02830369  0.01852653  0.01366539  0.02634772
  -0.03652772  0.07053084 -0.03676729 -0.02257195  0.0221082  -0.00030227
   0.04034763  0.04276701 -0.0102067  -0.02968203  0.03696589 -0.06009365
  -0.006895   -0.02624689 -0.00594523  0.01215725  0.03021728 -0.02227841
   0.02711525 -0.01980433  0.01089368  0.02455262  0.04491774  0.06232989
  -0.00571488  0.02688619 -0.01027123 -0.02177111  0.04195356 -0.00161977
  -0.03242162  0.02776119  0.02594518 -0.04712018 -0.02248181 -0.01879861
  -0.02550246 -0.01056922 -0.01585578 -0.03136683  0.00101883  0.01963647
  -0.03434717  0.02428605  0.01883463  0.02562002 -0.07328604 -0.03390081
   0.00801913  0.0383804   0.00424093  0.03269275  0.00174137 -0.04213452
  -0.05248098 -0.00992758 -0.03131494  0.01641404 -0.00981257 -0.04846688
  -0.00213078  0.0189423   0.06046697 -0.02308918 -0.0353624  -0.0171625
   0.03193294  0.00314319  0.01251225 -0.00902186  0.00282019  0.00625513
   0.01124123 -0.04573455  0.0380314  -0.03341457  0.06376437  0.00867331
  -0.00057177 -0.00210347 -0.05914294  0.00656669 -0.06032866 -0.03917653
   0.00314267  0.02219337 -0.04205615 -0.00797346  0.06410677 -0.0240078
   0.0098358  -0.00574108  0.01108223 -0.00113647  0.04628731 -0.04262878
  -0.03527052  0.01596756  0.01403437 -0.03506796 -0.02323029 -0.02925378
   0.00323266 -0.01193614  0.00483733  0.03543546 -0.00051819 -0.02147633
   0.02898502 -0.00768231 -0.00226293 -0.01115198 -0.00057254  0.01212449
   0.01822867 -0.00613355 -0.04469634  0.04092926  0.02741264  0.02733549
  -0.02803488  0.02338408 -0.03951882  0.0086802  -0.04505467  0.04057266
   0.00920994 -0.01917379  0.00812689 -0.0406405  -0.01798209 -0.02756295
  -0.01663976 -0.03096497 -0.00524026  0.07592587  0.06306992  0.02744098
   0.02371387 -0.02057062 -0.00747708 -0.02040144]]
After layer expand_dims1044_0 (1, 1, 256) <class 'numpy.float32'> [[[-0.0440224  -0.03664438  0.00861667  0.01515276  0.02430695 -0.01939218
    0.01766806  0.03024922 -0.00243996 -0.03725253 -0.02473392  0.03123871
    0.03999978 -0.02284463  0.0306421  -0.069909    0.0057033  -0.00310805
    0.02181194  0.02014854  0.06107146 -0.019744    0.00753182  0.02928386
   -0.02432787  0.0099076  -0.00432741 -0.00412798 -0.03746141 -0.02852975
    0.0161423  -0.05144785  0.00301278 -0.01080496  0.03341423 -0.04491942
   -0.03037962 -0.01406293 -0.03410992 -0.01739919  0.02780092 -0.03817073
    0.03820736  0.02722882  0.03547443 -0.04077145  0.02193879 -0.02229783
   -0.00273623 -0.01768701  0.00248372 -0.03440351 -0.02613931  0.02554249
    0.02961199  0.00336107 -0.02799638  0.06323609  0.0224458  -0.02808609
   -0.02783505 -0.03025073 -0.01792024 -0.00466927  0.04070458 -0.01569943
    0.03414465 -0.00576263 -0.04239249 -0.01552992 -0.07874995  0.01052371
    0.02218911  0.00062805  0.04806604 -0.02391097 -0.02749479 -0.04719986
   -0.02394945 -0.01374837 -0.03204479 -0.00770768 -0.02061135 -0.05515149
   -0.07720405  0.01664399 -0.0464703   0.02107799 -0.03993813 -0.0377562
   -0.01186361 -0.01159839 -0.00187374 -0.01695446 -0.01357314  0.00546593
    0.02934378 -0.01953242 -0.02601505 -0.01757014  0.02592654  0.03761562
   -0.03166889  0.01526147  0.00437113  0.02991948 -0.01581936 -0.0154524
    0.04203019 -0.04634574  0.02830369  0.01852653  0.01366539  0.02634772
   -0.03652772  0.07053084 -0.03676729 -0.02257195  0.0221082  -0.00030227
    0.04034763  0.04276701 -0.0102067  -0.02968203  0.03696589 -0.06009365
   -0.006895   -0.02624689 -0.00594523  0.01215725  0.03021728 -0.02227841
    0.02711525 -0.01980433  0.01089368  0.02455262  0.04491774  0.06232989
   -0.00571488  0.02688619 -0.01027123 -0.02177111  0.04195356 -0.00161977
   -0.03242162  0.02776119  0.02594518 -0.04712018 -0.02248181 -0.01879861
   -0.02550246 -0.01056922 -0.01585578 -0.03136683  0.00101883  0.01963647
   -0.03434717  0.02428605  0.01883463  0.02562002 -0.07328604 -0.03390081
    0.00801913  0.0383804   0.00424093  0.03269275  0.00174137 -0.04213452
   -0.05248098 -0.00992758 -0.03131494  0.01641404 -0.00981257 -0.04846688
   -0.00213078  0.0189423   0.06046697 -0.02308918 -0.0353624  -0.0171625
    0.03193294  0.00314319  0.01251225 -0.00902186  0.00282019  0.00625513
    0.01124123 -0.04573455  0.0380314  -0.03341457  0.06376437  0.00867331
   -0.00057177 -0.00210347 -0.05914294  0.00656669 -0.06032866 -0.03917653
    0.00314267  0.02219337 -0.04205615 -0.00797346  0.06410677 -0.0240078
    0.0098358  -0.00574108  0.01108223 -0.00113647  0.04628731 -0.04262878
   -0.03527052  0.01596756  0.01403437 -0.03506796 -0.02323029 -0.02925378
    0.00323266 -0.01193614  0.00483733  0.03543546 -0.00051819 -0.02147633
    0.02898502 -0.00768231 -0.00226293 -0.01115198 -0.00057254  0.01212449
    0.01822867 -0.00613355 -0.04469634  0.04092926  0.02741264  0.02733549
   -0.02803488  0.02338408 -0.03951882  0.0086802  -0.04505467  0.04057266
    0.00920994 -0.01917379  0.00812689 -0.0406405  -0.01798209 -0.02756295
   -0.01663976 -0.03096497 -0.00524026  0.07592587  0.06306992  0.02744098
    0.02371387 -0.02057062 -0.00747708 -0.02040144]]]
After layer encoder_birnn_reverse_l0_t3_i2h_output (1, 1024) <class 'numpy.float32'> [[-0.0128371  -0.04095686  0.03787835 ...,  0.06970935 -0.04625846
   0.03761056]]
After layer encoder_birnn_reverse_l0_t3_h2h_output (1, 1024) <class 'numpy.float32'> [[ 0.01337649  0.03061109 -0.02444895 ...,  0.0598764   0.03834873
   0.03900358]]
After layer _plus1039_0 (1, 1024) <class 'numpy.float32'> [[ 0.0005394  -0.01034578  0.01342941 ...,  0.12958574 -0.00790973
   0.07661413]]
After layer encoder_birnn_reverse_l0_t3_slice_output0 (1, 256) <class 'numpy.float32'> [[  5.39395958e-04  -1.03457756e-02   1.34294070e-02  -1.90999061e-02
    6.86089844e-02   6.68771565e-03   5.17749116e-02   2.80150063e-02
    8.33774954e-02   5.13352975e-02  -3.74465100e-02   6.06022887e-02
    2.41514836e-02   5.10927066e-02  -6.55084848e-04   2.36992121e-01
   -6.44978210e-02  -5.05673550e-02   1.53340511e-02  -1.51921343e-02
    8.10816363e-02   4.27638255e-02  -7.29679316e-02  -3.96038741e-02
    8.94441307e-02  -1.07974604e-01  -2.68901698e-02  -1.67276300e-02
    4.28140685e-02  -9.49030183e-03   2.62934621e-03  -2.71214843e-02
   -3.47147696e-02  -4.53889295e-02   6.74720183e-02  -1.01955436e-01
   -2.69233622e-03  -4.62788902e-03  -6.15528822e-02  -3.85969803e-02
   -6.79249391e-02   4.36239243e-02  -5.42872548e-02   4.40426171e-03
    3.80448252e-02  -2.25926004e-03   6.52444735e-02  -7.18599409e-02
    9.97073948e-04   9.54005495e-03  -1.33626089e-02   8.89785588e-02
   -2.68052816e-02   6.52784407e-02   1.98637694e-01   8.66786391e-02
   -4.30841893e-02   4.47642058e-03  -4.04547006e-02  -2.39040516e-02
    6.34662658e-02  -3.98755930e-02   1.48844048e-01  -2.53356770e-02
   -1.05694190e-01  -4.30157743e-02   9.12894458e-02  -1.18951127e-02
   -4.00044471e-02   2.90891901e-02   9.18288678e-02  -2.29529738e-02
    6.25707954e-03   3.33292130e-03  -1.62529610e-02   7.93551356e-02
    1.24569505e-01   1.22826345e-01  -4.22348455e-03   3.90630215e-02
    2.58761290e-02   4.18825820e-02   8.63445252e-02  -1.50279291e-02
    1.53728813e-01   6.46525696e-02  -2.73258202e-02  -1.80281829e-02
   -3.46805900e-02   1.23087771e-01   1.25363022e-01  -2.18955874e-02
   -7.79179484e-02   1.02207370e-01   7.45274276e-02   4.86749858e-02
   -1.95800364e-02   1.15280882e-01  -7.23466724e-02  -9.38275605e-02
   -4.93299887e-02   7.21438080e-02  -1.28624961e-02  -1.39950350e-01
   -3.88040431e-02   2.43995339e-03  -1.39430892e-02  -1.12462275e-01
    4.66187224e-02   6.96519017e-02  -1.26571476e-01   4.60485257e-02
    6.47377223e-03   1.53424963e-01  -4.32851166e-03   2.71336615e-01
   -3.06480192e-02   9.65110771e-03   7.33964741e-02  -3.08847576e-02
    1.99747562e-01  -1.10503405e-01   5.73098660e-05   8.86152536e-02
   -4.69456017e-02   5.08068576e-02  -1.01560444e-01   5.99240661e-02
   -1.10865701e-02   1.90975890e-03   1.53924257e-01   6.82159364e-02
    3.03101540e-03  -2.45071426e-02  -5.16053960e-02  -3.32759693e-02
    8.53216425e-02   1.40877575e-01   1.10522229e-02  -1.69963203e-02
   -3.43746431e-02  -7.53516331e-02   6.08674139e-02   6.92240447e-02
   -3.25233154e-02  -6.51057810e-04   2.76079290e-02   6.20515682e-02
   -1.92862060e-02   5.56404963e-02   9.62596536e-02  -4.01831120e-02
    4.30931337e-03  -9.01021957e-02  -4.80481684e-02   1.86139345e-01
    3.58249918e-02   9.00943279e-02  -1.12205707e-02  -2.96214744e-02
    1.67074025e-01   9.18063335e-03  -3.53024490e-02   4.37977016e-02
    2.35105678e-02  -5.05909845e-02   1.96476020e-02  -3.74145359e-02
    6.28039986e-02  -2.90020183e-02   2.46747546e-02   3.48337144e-02
    7.53092952e-03   9.10372809e-02   3.55902985e-02  -9.95459557e-02
    3.58078144e-02  -1.03165999e-01  -4.28703018e-02  -2.19871774e-02
    2.75581703e-02  -5.29927276e-02  -2.97284555e-02   3.91012728e-02
    9.50312018e-02  -2.79545560e-02  -1.33299790e-02  -5.79113364e-02
    1.29862964e-01   7.67612010e-02  -1.40887946e-02   2.65408494e-03
    4.34520207e-02  -4.76387143e-03   1.10857293e-01   6.20691180e-02
    6.74212575e-02  -1.41434148e-01   4.54431660e-02   4.29367572e-02
   -3.00240517e-03   1.52187109e-01   6.18427023e-02   2.09210776e-02
    3.70263793e-02  -5.47661819e-03   4.87330370e-03  -4.38811406e-02
   -4.36875857e-02   4.52809818e-02   3.33425105e-02   8.57337341e-02
    1.98962651e-02   6.64281771e-02   2.17267051e-02   5.93827479e-02
   -5.03918156e-03  -2.38016620e-02   8.12474638e-03   8.42025504e-03
   -4.77799922e-02  -2.28946954e-02   5.44191934e-02  -7.52250776e-02
    1.46267712e-02   6.72626421e-02  -1.88380647e-02  -7.73102343e-02
   -4.05288190e-02   1.65311277e-01  -1.43910907e-02  -5.53577431e-02
   -1.61313303e-02  -2.92767454e-02   3.39388922e-02   6.45784885e-02
   -7.39771780e-03   6.66463375e-02   3.09085567e-02  -4.46057245e-02
   -5.46426624e-02  -9.53703821e-02   1.17717050e-01   2.28263527e-01
   -4.12670076e-02   3.63542661e-02   3.90119851e-04  -5.92378080e-02
    1.54906139e-02   3.49212736e-02   1.23519644e-01   1.42558180e-02
   -7.05228895e-02   4.84331138e-02   4.21051905e-02  -2.69670095e-02]]
After layer encoder_birnn_reverse_l0_t3_slice_output1 (1, 256) <class 'numpy.float32'> [[ 0.12642246  0.01922046  0.08013016  0.04788213  0.02469094  0.0618345
   0.15640685 -0.07098608  0.29137385  0.11320343  0.12349742  0.08379911
   0.08837441  0.01471327  0.10299404  0.10549827  0.08065253 -0.04643979
  -0.1222205   0.04080131  0.10452714 -0.00514477  0.25786284  0.04756228
   0.1068885   0.07081696  0.11575571  0.10145716  0.09318025  0.02318135
   0.03659364 -0.00178043  0.20588559 -0.04781423 -0.01326104  0.01504343
  -0.0580948   0.07437492  0.01637924  0.09008682  0.01447779  0.09357332
   0.0078352   0.0951267   0.01695544  0.09445042  0.02843213 -0.0714479
   0.00666199  0.03776207  0.0537374   0.05653738  0.05295445  0.12264027
   0.10389867  0.07748008  0.03182533  0.07829396  0.01796023 -0.05637667
   0.03553217  0.03765875  0.01909288  0.04985771 -0.01184328  0.11975086
   0.17971712  0.06063627 -0.07725424  0.00574715  0.06051589 -0.02405786
  -0.01375218  0.02223846  0.08672884  0.18922344  0.04837485  0.0227759
   0.05363277  0.06773867  0.19374277  0.13481081  0.0359284   0.03182351
   0.1311592   0.01516367  0.05760012  0.184508    0.02788341 -0.0829154
   0.23873839  0.09329511  0.07550979  0.07234339 -0.0335787   0.02387826
   0.02996616  0.13030674 -0.11175888 -0.12917043 -0.00778843  0.01298682
   0.01349659  0.08667317  0.01428445 -0.0174013  -0.08411014  0.06879815
   0.04090274 -0.04789065 -0.01399282 -0.00772044  0.02129603  0.12895487
   0.09776295  0.17062113  0.08361796  0.10906595  0.13032416  0.09415057
   0.16376913  0.14045678  0.02372136  0.01573603  0.01307392 -0.01022031
   0.14602719 -0.0035831   0.09595156 -0.07898393  0.07380645  0.15869626
   0.01713075  0.13447756  0.08620658  0.08188017  0.02144972  0.02339096
   0.11300594  0.14265162 -0.07038631  0.07754833  0.06154848  0.03274518
   0.01801379  0.11792722  0.03317562  0.03101452  0.02831591 -0.01208498
  -0.02926674  0.05808291  0.01214261  0.06859984  0.05754807  0.16833688
   0.09990494  0.01897705  0.01726588  0.11877094  0.1996581   0.07313231
  -0.03080269  0.07510399  0.03848841  0.00771811  0.22137411 -0.04857612
   0.00132319 -0.02870182  0.04659669  0.09907688 -0.0499959   0.17529589
  -0.01378191  0.08526582  0.14022863  0.00829011  0.01765605  0.10273004
   0.07906453 -0.06962852  0.19489956 -0.04061428  0.02126278 -0.01542088
   0.03256437  0.15061414  0.07053204 -0.02104166 -0.03392857  0.01978105
   0.15318744  0.13095672  0.03577264 -0.00483109 -0.02005915  0.00531499
   0.0239908   0.01393697  0.01713055  0.07631933  0.08148347 -0.04205799
   0.07452086 -0.10858187 -0.01143928  0.12961946 -0.01621144  0.06961752
   0.06550205  0.11421803 -0.04777677  0.01984688 -0.02445535 -0.05632382
   0.04896124  0.08326077 -0.00171538  0.09642664 -0.08807444 -0.01808494
   0.20266315  0.02831965  0.06442414 -0.00881406  0.01927813  0.02533216
   0.27722627  0.23884279  0.00652408 -0.2172107   0.13136743  0.0320153
   0.05031095  0.00309045  0.02065765  0.08324382  0.01764967  0.09378253
   0.07866991  0.00903553  0.06814392  0.21850343 -0.11799877 -0.02406109
  -0.00482264 -0.0655629   0.07589029 -0.00844572  0.11818887 -0.11402011
   0.13393345 -0.02471957  0.12403805  0.00670119]]
After layer encoder_birnn_reverse_l0_t3_slice_output2 (1, 256) <class 'numpy.float32'> [[-0.14230575 -0.13127455 -0.00659126  0.03447367  0.0428391  -0.05531979
   0.0427275   0.09617878  0.05532517 -0.07815526 -0.07132964  0.11608534
   0.08615248 -0.03136232  0.0575517  -0.20776328  0.05087307  0.02081193
   0.07799652  0.04994677  0.1834605  -0.04183573  0.00121866  0.07242966
  -0.10965949  0.03630967  0.06071683 -0.0435082  -0.13516402 -0.09835088
   0.03380131 -0.12675883 -0.02347619  0.01102421  0.11011952 -0.14044799
  -0.06709253 -0.00915757 -0.12309696 -0.1002082   0.03009135 -0.18342435
   0.12195555  0.08823767  0.08504793 -0.10367802  0.0350389  -0.07367088
  -0.01092065 -0.08927708  0.06544862 -0.10873873 -0.07726699  0.11010319
   0.04315989  0.02998544 -0.04071261  0.17186502  0.08473069 -0.0473643
  -0.0725195  -0.10006367 -0.03050646 -0.01134167  0.06098383 -0.03259746
   0.03550298 -0.09883483 -0.11534533 -0.02362368 -0.2349357  -0.00034538
   0.06213761  0.03313246  0.12322479 -0.04631366 -0.02482605 -0.16815221
  -0.05577916 -0.0342541  -0.10381983  0.02502969 -0.07989462 -0.15118548
  -0.23350474  0.01457682 -0.14246117  0.03497994 -0.16318451 -0.11979313
  -0.10821999 -0.06220715 -0.03081326 -0.01377762 -0.04546405  0.04265443
   0.09818514 -0.03912539 -0.1103579  -0.06999466  0.02535387  0.13345784
  -0.06806412  0.04475202  0.05910173  0.12928391 -0.04689191 -0.0494441
   0.15270552 -0.17770314  0.08077378  0.00470471  0.06376439  0.0770743
  -0.09028079  0.24770126 -0.14158769 -0.06390964  0.04015572 -0.06204216
   0.14800087  0.081843   -0.02561988 -0.08133943  0.10963054 -0.17156668
  -0.10437944 -0.06225759 -0.04542011 -0.03132697  0.06926673 -0.04178539
   0.07843684 -0.00064602  0.00033187  0.06728524  0.09363925  0.1977371
  -0.00598161  0.05696248 -0.0080068  -0.04971488  0.12349707  0.02167961
  -0.09988973  0.08970524  0.05779986 -0.11389502 -0.09806212 -0.1159336
  -0.05850543 -0.02920003 -0.04766633 -0.09074821 -0.01978002  0.06778448
  -0.11085615  0.05180575  0.05417679  0.06231115 -0.18955183 -0.0711585
   0.03039929  0.15538646  0.03033244  0.09314574  0.01553909 -0.05756531
  -0.16894603  0.018779   -0.08676223  0.0352964  -0.03349807 -0.13743746
  -0.02364279  0.07357164  0.13598883 -0.0456434  -0.06275699 -0.03674982
   0.06814019  0.00537265  0.03479481 -0.03467227 -0.06156903  0.06716499
   0.04318212 -0.10030048  0.09702749 -0.12764046  0.17884329 -0.02123708
   0.00754612  0.01141435 -0.17871946 -0.00841257 -0.20422328 -0.09068884
  -0.03535566  0.05059015 -0.14934838 -0.02373884  0.17066903 -0.06038485
  -0.02293059 -0.02010975  0.06722049  0.00940451  0.10732211 -0.08530822
  -0.16216952 -0.00143937  0.0245612  -0.15988228 -0.05666661 -0.07967261
   0.02715734 -0.03815546 -0.026959    0.10813877 -0.03975466 -0.09237755
   0.07106797  0.01929992  0.00457774 -0.05116012  0.00372274  0.03611823
   0.0439537  -0.01309116 -0.14199734  0.17097156  0.04974981  0.09202304
  -0.0687215   0.04491587 -0.10507832  0.01577722 -0.16215731  0.13223112
   0.02312836 -0.01975873  0.02118248 -0.05433836 -0.03712612 -0.07248715
  -0.0589463  -0.16134648  0.01320303  0.22044528  0.17656323  0.10258973
   0.05458031 -0.07144791 -0.04813373 -0.01047423]]
After layer encoder_birnn_reverse_l0_t3_slice_output3 (1, 256) <class 'numpy.float32'> [[  5.78276403e-02   2.37724930e-02  -1.50559433e-02   5.14157377e-02
    6.14711866e-02   1.97832376e-01   1.05614856e-01   1.29875466e-01
    3.16132545e-01   1.14337616e-01  -2.92328987e-02   5.99672869e-02
    1.43142596e-01  -3.02572772e-02   3.36153321e-02   1.00246087e-01
   -4.91564274e-02  -5.50453812e-02   1.93541124e-02  -2.27246806e-02
   -2.54034773e-02  -1.25269026e-01   2.19445169e-01   9.89643335e-02
    8.12385976e-02   2.63871700e-02   2.37446465e-03   7.28464499e-03
   -6.88887015e-02   2.19148956e-02   1.00302711e-01   1.03021421e-01
    2.99996808e-02   2.24116072e-02  -2.79738568e-02  -1.83004327e-02
    9.44050103e-02  -1.31590031e-02   8.93422365e-02   6.86038658e-03
    9.59103405e-02  -2.92214565e-02   9.87229869e-04   7.62332231e-04
   -2.49673761e-02   1.66634284e-02   1.97742060e-02  -4.90449965e-02
    3.91746648e-02   7.49764740e-02   8.92233998e-02  -5.11346906e-02
    2.18272656e-02   5.64219058e-02   1.94885373e-01  -1.09109029e-01
    1.25502408e-01   1.61873437e-02   2.54300255e-02  -1.03004552e-01
    3.46890949e-02   3.75090986e-02   3.22715454e-02   1.40582502e-01
   -1.31227626e-02  -5.82951121e-02   1.60986483e-01   5.62663823e-02
    4.29000482e-02   1.04078203e-01   1.75930392e-02   4.47341949e-02
    2.15539634e-02  -2.13558488e-02   7.96949491e-02   2.21661657e-01
    1.22541688e-01   4.79941070e-02   1.00161895e-01   1.90620512e-01
    1.48050651e-01   1.82448477e-01   7.97925666e-02   1.24930874e-01
    1.25809580e-01   6.12904541e-02   3.01874354e-02   1.23397708e-01
    6.83704764e-02   1.10861868e-01   1.35023788e-01  -3.06976419e-02
   -8.73161852e-02   3.34807634e-02   6.16436824e-02   3.56633924e-02
    7.38573372e-02   1.37225091e-01  -1.24409601e-01  -7.21577704e-02
    3.79830599e-05  -1.20966226e-01  -4.65232357e-02  -6.68861121e-02
    1.27693191e-02   1.43360142e-02  -3.57884318e-02   1.22651398e-01
    4.54608053e-02   1.84768021e-01   7.28274882e-03   5.04211821e-02
   -7.14261681e-02   1.19932413e-01   2.62537394e-02   1.38337493e-01
   -8.58256146e-02  -2.54134573e-02   1.09325565e-01  -6.89064786e-02
    3.14080864e-02   8.34794790e-02   1.01807237e-01   4.88292053e-03
   -2.86030639e-02   3.18876766e-02  -1.79775693e-02  -1.77817997e-02
   -3.72049510e-02  -4.56120633e-02   1.46106109e-02   1.78973302e-01
    1.06021296e-03   9.21525732e-02   3.13039087e-02  -5.41542321e-02
    1.13125876e-01   6.17878139e-02   1.08655281e-01   2.76305098e-02
    5.26059605e-03   9.01428983e-03  -9.66459960e-02   4.91726510e-02
    1.34882107e-02   2.23676562e-02   1.19930059e-01   3.63353044e-02
    4.36679497e-02  -1.29778497e-02  -1.78148560e-02  -3.17644775e-02
    4.97645661e-02   1.28179163e-01   4.07709926e-02   8.88534337e-02
    6.31518140e-02   1.41546115e-01   4.31227237e-02   1.19490370e-01
    6.15073368e-02   2.57910900e-02  -2.88586468e-02   1.39259189e-01
    8.48231912e-02  -6.12298809e-02   2.12291062e-01   9.34530720e-02
   -8.64679515e-02   3.04380804e-02  -7.80712515e-02   8.47685933e-02
    8.03106278e-02   1.68654948e-01   4.31331471e-02   1.44609153e-01
    1.39068067e-01  -3.35209668e-02   9.82780084e-02  -7.68854842e-03
   -8.05896223e-02  -4.50548977e-02   3.89036946e-02  -2.78446600e-02
   -2.78813317e-02   7.94343501e-02  -1.96751356e-02   8.89535397e-02
    5.11763021e-02  -5.32423854e-02   3.95666212e-02   1.31271183e-01
    4.93988246e-02  -2.57008523e-03   9.74925756e-02   5.69194891e-02
   -2.00271420e-02   6.21640421e-02   8.59917179e-02  -3.79349291e-03
    6.10437840e-02   2.19148383e-01   8.96411091e-02   1.34687871e-01
    8.07825923e-02   8.80666822e-02  -5.54538518e-02   2.50547677e-02
   -6.37279600e-02   1.42789170e-01  -1.75504871e-02   2.84938693e-01
    3.04707102e-02   1.31887630e-01   8.38353708e-02  -2.54903473e-02
    6.60347342e-02   1.52235895e-01  -3.32266986e-02  -5.03111295e-02
   -5.30011654e-02  -8.30826610e-02   1.22495838e-01   1.84904188e-02
    7.00512081e-02   9.27755386e-02   1.89648718e-02   1.19875148e-02
    2.54549384e-01   2.06175983e-01   2.76282635e-02  -8.33093002e-02
   -1.29418671e-02   9.73682851e-04  -1.72165781e-02   1.73793547e-02
   -3.13278772e-02   6.85858876e-02   9.91789401e-02   2.02415809e-02
   -5.78267351e-02   8.26880559e-02   1.48969471e-01   3.17279011e-01
   -8.93381089e-02   5.87125793e-02   7.20509291e-02  -1.06472671e-01
    2.38549188e-02   1.40467584e-02   8.95119309e-02  -6.29368573e-02
    8.52710158e-02   1.29585743e-01  -7.90973008e-03   7.66141340e-02]]
After layer encoder_birnn_reverse_l0_t3_o_output (1, 256) <class 'numpy.float32'> [[ 0.51445287  0.50594282  0.49623609  0.51285112  0.51536292  0.54929739
   0.52637923  0.53242332  0.57838148  0.52855331  0.49269226  0.51498735
   0.53572464  0.49243623  0.50840306  0.52504057  0.4877134   0.48624212
   0.50483841  0.49431905  0.49364945  0.46872362  0.5546422   0.52472091
   0.52029848  0.50659639  0.5005936   0.50182116  0.48278463  0.5054785
   0.52505469  0.52573264  0.50749934  0.50560266  0.49300694  0.49542505
   0.52358371  0.49671027  0.52232069  0.50171506  0.52395922  0.49269515
   0.50024682  0.50019056  0.49375847  0.50416577  0.50494337  0.48774117
   0.50979239  0.51873535  0.52229106  0.48721915  0.50545663  0.51410174
   0.54856777  0.47274977  0.53133452  0.50404674  0.50635719  0.47427157
   0.5086714   0.50937617  0.50806719  0.53508788  0.49671933  0.48543033
   0.54015994  0.51406288  0.51072335  0.52599609  0.50439811  0.51118171
   0.50538826  0.49466124  0.5199132   0.55518967  0.53059715  0.51199627
   0.52501953  0.5475114   0.53694522  0.54548597  0.51993757  0.53119218
   0.53141099  0.5153178   0.50754631  0.53081036  0.51708597  0.52768707
   0.53370476  0.49232617  0.47818476  0.50836945  0.51540601  0.50891489
   0.51845598  0.53425252  0.46893764  0.4819684   0.50000948  0.46979529
   0.48837128  0.48328468  0.50319231  0.50358397  0.49105385  0.53062451
   0.51136321  0.54606104  0.50182068  0.51260263  0.482151    0.52994722
   0.50656307  0.53452933  0.47855675  0.49364695  0.52730423  0.48278019
   0.50785136  0.52085775  0.52542984  0.50122076  0.49284974  0.50797129
   0.49550569  0.49555469  0.49069983  0.48859897  0.50365257  0.54462427
   0.50026506  0.52302188  0.50782537  0.48646477  0.52825135  0.51544207
   0.52713716  0.50690722  0.50131512  0.50225359  0.47585726  0.51229072
   0.50337201  0.50559169  0.52994663  0.50908285  0.51091522  0.49675557
   0.49554643  0.49205959  0.51243854  0.53200102  0.51019132  0.52219874
   0.51578271  0.53532755  0.51077896  0.52983713  0.51537198  0.50644743
   0.49278581  0.53475863  0.52119309  0.48469731  0.55287433  0.5233463
   0.47839651  0.50760895  0.48049212  0.5211795   0.52006686  0.54206407
   0.51078165  0.53608942  0.53471112  0.49162054  0.52454972  0.4980779
   0.47986349  0.48873815  0.50972474  0.49303928  0.49303013  0.51984817
   0.49508142  0.52222371  0.51279128  0.48669252  0.50989038  0.53277075
   0.51234722  0.49935746  0.52435386  0.51422602  0.49499342  0.51553601
   0.52148467  0.49905157  0.51525623  0.55456889  0.52239531  0.53362119
   0.5201847   0.52200246  0.4861401   0.50626338  0.48407337  0.53563672
   0.49561247  0.57075661  0.50761712  0.53292418  0.52094656  0.49362779
   0.51650268  0.53798568  0.49169409  0.48742491  0.48675278  0.47924125
   0.53058571  0.50462246  0.51750565  0.52317727  0.50474107  0.50299686
   0.56329596  0.55136216  0.50690663  0.47918475  0.49676457  0.50024343
   0.49569601  0.50434476  0.49216869  0.51713979  0.52477443  0.50506026
   0.48554739  0.52066022  0.53717363  0.57866102  0.47768036  0.51467395
   0.51800495  0.47340694  0.50596344  0.50351161  0.52236307  0.48427099
   0.52130485  0.5323512   0.49802253  0.51914418]]
After layer encoder_birnn_reverse_l0_t3_f_output (1, 256) <class 'numpy.float32'> [[ 0.53156358  0.50480497  0.52002186  0.51196826  0.50617242  0.5154537
   0.53902221  0.48226094  0.57233244  0.52827066  0.53083521  0.5209375
   0.52207923  0.50367826  0.52572578  0.52635014  0.52015221  0.48839214
   0.46948287  0.51019889  0.52610803  0.49871382  0.56411082  0.51188833
   0.52669674  0.51769686  0.5289067   0.52534258  0.52327818  0.50579506
   0.50914741  0.4995549   0.55129033  0.48804873  0.49668479  0.50376081
   0.4854804   0.51858521  0.50409472  0.52250654  0.50361937  0.52337629
   0.50195879  0.52376378  0.50423878  0.52359509  0.50710756  0.48214558
   0.50166547  0.50943941  0.51343113  0.51413059  0.51323551  0.53062171
   0.52595133  0.51936036  0.50795567  0.5195635   0.50448996  0.48590952
   0.50888211  0.50941354  0.50477308  0.51246184  0.4970392   0.52990198
   0.54480875  0.51515442  0.48069608  0.50143683  0.51512438  0.4939858
   0.49656203  0.50555938  0.52166861  0.54716522  0.51209134  0.50569373
   0.51340497  0.5169282   0.54828477  0.53365171  0.50898111  0.50795519
   0.53274292  0.50379086  0.51439601  0.54599661  0.50697041  0.47928298
   0.5594027   0.52330685  0.51886851  0.51807797  0.49160615  0.50596929
   0.50749099  0.53253067  0.47208932  0.46775219  0.49805287  0.50324667
   0.5033741   0.52165473  0.50357103  0.49564978  0.47898483  0.51719278
   0.51022428  0.4880296   0.49650189  0.49806985  0.50532383  0.53219414
   0.52442127  0.54255211  0.52089232  0.5272395   0.53253502  0.52352023
   0.540851    0.53505659  0.50593007  0.50393391  0.50326842  0.49744493
   0.53644204  0.4991042   0.52396947  0.48026428  0.51844329  0.53959101
   0.50428259  0.53356886  0.52153832  0.52045864  0.50536221  0.50584751
   0.52822149  0.53560251  0.48241067  0.51937735  0.51538223  0.50818557
   0.50450331  0.52944767  0.50829315  0.50775301  0.50707853  0.49697876
   0.4926838   0.51451665  0.5030356   0.51714325  0.51438302  0.54198515
   0.52495545  0.50474411  0.50431639  0.52965784  0.54974937  0.51827496
   0.49229994  0.51876718  0.5096209   0.50192952  0.55511862  0.48785833
   0.50033081  0.49282506  0.51164705  0.52474898  0.48750365  0.54371214
   0.49655455  0.52130353  0.53499985  0.50207251  0.5044139   0.52565992
   0.51975584  0.48259994  0.54857129  0.48984778  0.50531548  0.49614486
   0.50814039  0.53758252  0.51762569  0.4947398   0.49151871  0.50494516
   0.53822219  0.53269249  0.50894219  0.49879223  0.49498537  0.50132877
   0.50599742  0.50348425  0.50428253  0.51907057  0.52035964  0.48948705
   0.51862162  0.4728812   0.49714023  0.53235954  0.49594721  0.51739734
   0.51636964  0.5285235   0.48805809  0.50496155  0.49388644  0.48592275
   0.51223785  0.52080315  0.49957114  0.52408797  0.4779956   0.49547887
   0.55049306  0.50707942  0.51610047  0.49779651  0.50481939  0.5063327
   0.56886607  0.55942845  0.50163102  0.44590983  0.53279471  0.50800312
   0.51257509  0.5007726   0.50516427  0.52079898  0.50441229  0.52342844
   0.51965731  0.50225884  0.5170294   0.55440956  0.4705345   0.493985
   0.49879438  0.48361513  0.51896346  0.49788857  0.52951288  0.47152579
   0.53343338  0.4938204   0.5309698   0.50167531]]
After layer _mul2078_0 (1, 256) <class 'numpy.float32'> [[-0.04566628 -0.03684347  0.00903956  0.01518894  0.02370279 -0.01831325
   0.01812405  0.02738037 -0.00246249 -0.03703649 -0.02646065  0.03145976
   0.03954639 -0.02345068  0.03177989 -0.070756    0.00603068 -0.00306458
   0.02046729  0.02084982  0.0651551  -0.02107449  0.00770868  0.02869729
  -0.0244823   0.01020459 -0.00458322 -0.00428487 -0.04047382 -0.0284571
   0.01573699 -0.04887534  0.00326968 -0.01047612  0.03370687 -0.04526496
  -0.02830423 -0.01474996 -0.03280242 -0.01806308  0.02658805 -0.04054453
   0.03845413  0.02852168  0.03620765 -0.04263787  0.02198939 -0.02191845
  -0.00266993 -0.01767283  0.00243281 -0.0368038  -0.02583738  0.0263367
   0.02801755  0.00367346 -0.02692035  0.06513448  0.02241902 -0.0285546
  -0.02798638 -0.03083516 -0.01777823 -0.0044944   0.04083975 -0.01702427
   0.0350672  -0.00576808 -0.03945908 -0.0147051  -0.08123311  0.01014976
   0.02167067  0.00064413  0.04882803 -0.02344775 -0.02680139 -0.04644284
  -0.02349531 -0.01309517 -0.03306254 -0.00757327 -0.02018676 -0.05261735
  -0.0790306   0.01617025 -0.0469984   0.02156454 -0.03931428 -0.03377592
  -0.0125471  -0.0122222  -0.00203103 -0.01724949 -0.01294211  0.00546058
   0.02871196 -0.01935486 -0.0259589  -0.01678247  0.02550438  0.03989996
  -0.0322516   0.01640363  0.00432007  0.02943404 -0.01546517 -0.01502393
   0.04216746 -0.04128831  0.02802891  0.01809208  0.01429048  0.02656808
  -0.03751263  0.07206755 -0.04004959 -0.02433465  0.02198666 -0.00033107
   0.04285697  0.0442133  -0.00974756 -0.03004588  0.03742885 -0.05924597
  -0.00744505 -0.02662976 -0.00639349  0.01169502  0.03114569 -0.02220378
   0.02702573 -0.02010649  0.01125918  0.02616681  0.04324351  0.0613259
  -0.00571963  0.02826338 -0.00994536 -0.02237658  0.04590428 -0.00162146
  -0.03248809  0.02914336  0.0250868  -0.04737988 -0.02225758 -0.01880201
  -0.02515737 -0.01110373 -0.01564848 -0.03055291  0.00101134  0.02036316
  -0.03537386  0.02249762  0.01864188  0.0257368  -0.07933638 -0.03458491
   0.00803032  0.03738808  0.00413187  0.03390596  0.00177326 -0.03960908
  -0.05429756 -0.00957767 -0.03320266  0.01661083 -0.00916006 -0.04925154
  -0.00205563  0.0185938   0.06088667 -0.02329827 -0.03392165 -0.0180567
   0.03406095  0.00308992  0.01340366 -0.00882494  0.00286888  0.00605042
   0.01152807 -0.04736147  0.03752082 -0.03350471  0.06112584  0.00825525
  -0.00059954 -0.00225733 -0.05609756  0.00636877 -0.06047804 -0.03806764
   0.00308348  0.02249039 -0.04150219 -0.00748973  0.0640033  -0.02208025
   0.0098428  -0.00521554  0.01123421 -0.00120888  0.04709068 -0.04169548
  -0.03697473  0.01488287  0.01355061 -0.03341917 -0.02203075 -0.02850958
   0.00320727 -0.01165247  0.00493155  0.0382536  -0.00051045 -0.02195054
   0.03035437 -0.00778429 -0.0022488  -0.01068367 -0.0005721   0.01235142
   0.01868785 -0.00619679 -0.04396433  0.03751591  0.02906841  0.02780015
  -0.02902726  0.02328733 -0.04043568  0.00877133 -0.04344296  0.04225766
   0.00966139 -0.01838227  0.00765539 -0.03903437 -0.01749279 -0.02642435
  -0.01582121 -0.03149724 -0.00542455  0.0747138   0.06426968  0.02660288
   0.02442121 -0.01914754 -0.00791937 -0.019647  ]]
After layer encoder_birnn_reverse_l0_t3_i_output (1, 256) <class 'numpy.float32'> [[ 0.50013489  0.49741361  0.50335729  0.49522522  0.51714551  0.50167191
   0.51294082  0.50700331  0.5208323   0.51283103  0.49063945  0.51514596
   0.50603759  0.51277041  0.49983627  0.55897224  0.48388115  0.48736086
   0.50383341  0.49620202  0.52025932  0.51068932  0.4817661   0.49010032
   0.52234614  0.47303256  0.49327785  0.49581817  0.51070184  0.49762744
   0.50065732  0.49322006  0.49132219  0.4886547   0.51686162  0.4745332
   0.49932688  0.49884301  0.48461661  0.49035197  0.48302531  0.51090425
   0.48643154  0.50110108  0.50951004  0.49943516  0.51630533  0.48204273
   0.50024927  0.50238502  0.4966594   0.52222997  0.49329907  0.51631385
   0.54949677  0.5216561   0.4892306   0.50111908  0.48988771  0.49402431
   0.51586127  0.4900324   0.53714246  0.49366644  0.47360101  0.48924771
   0.52280653  0.49702623  0.49000025  0.50727177  0.52294111  0.49426201
   0.50156426  0.50083321  0.4959369   0.51982838  0.53110218  0.53066808
   0.49894413  0.50976449  0.50646871  0.51046914  0.52157277  0.49624306
   0.53835672  0.51615751  0.49316898  0.49549305  0.49133077  0.53073317
   0.53129977  0.4945263   0.48053035  0.52552962  0.51862329  0.51216638
   0.49510515  0.52878833  0.48192123  0.47656029  0.48767     0.51802814
   0.49678439  0.46506944  0.49030021  0.50060993  0.49651429  0.47191402
   0.51165259  0.51740593  0.46839929  0.51151007  0.50161844  0.5382812
   0.49891791  0.56742102  0.49233854  0.50241274  0.51834089  0.49227944
   0.54977155  0.47240224  0.50001431  0.52213931  0.48826572  0.51269901
   0.47463167  0.5149765   0.49722838  0.50047743  0.53840524  0.51704741
   0.50075775  0.49387354  0.48710153  0.49168175  0.52131748  0.53516126
   0.50276303  0.49575102  0.49140722  0.48117098  0.51521218  0.51729912
   0.4918699   0.49983722  0.5069015   0.51550794  0.49517855  0.51390654
   0.52404636  0.48995557  0.50107735  0.47748971  0.48799032  0.54640096
   0.5089553   0.52250832  0.49719486  0.49259517  0.54167157  0.50229514
   0.49117529  0.51094764  0.50587738  0.48735496  0.50491178  0.49064749
   0.51569581  0.49275002  0.50616837  0.50870758  0.50188273  0.52274364
   0.50889665  0.47513407  0.50895101  0.47423133  0.48928407  0.49450344
   0.5068891   0.48675492  0.49256843  0.50977409  0.52373993  0.49301183
   0.49666756  0.4855262   0.53242016  0.51918089  0.49647784  0.50066352
   0.51086128  0.49880901  0.52768594  0.51551229  0.51684892  0.46470028
   0.51135886  0.51073253  0.4992494   0.53797352  0.51545572  0.50523007
   0.50925553  0.49863082  0.50121832  0.48903146  0.4890798   0.51131833
   0.50833488  0.5214203   0.50497389  0.51660097  0.50543147  0.51484132
   0.49874017  0.49404988  0.50203121  0.50210506  0.48805732  0.49427658
   0.51360148  0.48120257  0.50365663  0.51680934  0.49529061  0.48068208
   0.48986918  0.54123396  0.49640235  0.48616409  0.49596727  0.49268132
   0.50848389  0.51613903  0.49815053  0.51665545  0.50772655  0.48885038
   0.48634276  0.47617546  0.52939534  0.55681938  0.48968467  0.50908756
   0.50009751  0.48519489  0.50387257  0.50872946  0.53084069  0.50356388
   0.48237658  0.51210588  0.51052475  0.49325866]]
After layer encoder_birnn_reverse_l0_t3_c_output (1, 256) <class 'numpy.float32'> [[-0.14135286 -0.13052563 -0.00659117  0.03446002  0.04281292 -0.05526343
   0.04270152  0.09588332  0.05526879 -0.07799652 -0.07120891  0.11556669
   0.08593997 -0.03135204  0.05748824 -0.20482461  0.05082923  0.02080893
   0.07783874  0.04990528  0.18142956 -0.04181134  0.00121866  0.07230327
  -0.10922204  0.03629373  0.06064233 -0.04348077 -0.13434689 -0.09803499
   0.03378844 -0.12608425 -0.02347188  0.01102376  0.10967656 -0.13953175
  -0.06699204 -0.00915731 -0.12247895 -0.09987412  0.03008227 -0.18139459
   0.12135451  0.08800937  0.08484347 -0.10330813  0.03502456 -0.07353789
  -0.01092022 -0.08904064  0.06535533 -0.10831217 -0.07711359  0.10966042
   0.04313311  0.02997645 -0.04069013  0.17019261  0.08452851 -0.04732892
  -0.07239264 -0.09973103 -0.030497   -0.01134119  0.06090834 -0.03258592
   0.03548807 -0.09851427 -0.1148365  -0.02361929 -0.23070663 -0.00034538
   0.06205776  0.03312035  0.12260487 -0.04628058 -0.02482095 -0.1665851
  -0.05572138 -0.03424071 -0.10344843  0.02502446 -0.07972506 -0.15004404
  -0.2293514   0.01457579 -0.14150517  0.03496568 -0.16175129 -0.11922338
  -0.10779949 -0.06212704 -0.03080351 -0.01377675 -0.04543275  0.04262858
   0.09787084 -0.03910544 -0.10991206 -0.06988057  0.02534844  0.1326711
  -0.06795921  0.04472217  0.05903301  0.1285684  -0.04685757 -0.04940385
   0.15152952 -0.17585595  0.08059857  0.00470468  0.06367811  0.07692205
  -0.0900363   0.24275659 -0.14064908 -0.06382278  0.04013415 -0.06196268
   0.14692964  0.08166075 -0.02561427 -0.08116052  0.10919344 -0.16990291
  -0.10400201 -0.06217728 -0.0453889  -0.03131673  0.06915616 -0.04176108
   0.07827638 -0.00064602  0.00033187  0.06718388  0.09336653  0.19519961
  -0.00598154  0.05690096 -0.00800663 -0.04967396  0.12287304  0.02167622
  -0.09955882  0.08946539  0.05773558 -0.11340508 -0.097749   -0.11541697
  -0.05843877 -0.02919173 -0.04763026 -0.09049992 -0.01977744  0.06768086
  -0.11040426  0.05175946  0.05412385  0.06223063 -0.18731381 -0.07103864
   0.03038993  0.15414783  0.03032314  0.0928773   0.01553784 -0.05750181
  -0.16735677  0.01877679 -0.08654518  0.03528174 -0.03348554 -0.1365786
  -0.02363838  0.07343918  0.13515671 -0.04561174 -0.06267473 -0.03673328
   0.06803492  0.0053726   0.03478078 -0.03465838 -0.06149135  0.06706417
   0.0431553  -0.09996549  0.09672415 -0.12695177  0.17696062 -0.02123389
   0.00754598  0.01141385 -0.17684066 -0.00841237 -0.20143066 -0.09044103
  -0.03534093  0.05054703 -0.14824779 -0.02373438  0.16903104 -0.06031156
  -0.02292657 -0.02010704  0.06711943  0.00940423  0.10691196 -0.08510188
  -0.16076268 -0.00143937  0.02455626 -0.15853375 -0.05660603 -0.07950446
   0.02715067 -0.03813696 -0.02695248  0.10771921 -0.03973373 -0.09211568
   0.07094856  0.01929753  0.00457771 -0.05111553  0.00372273  0.03610253
   0.04392542 -0.01309041 -0.14105061  0.1693249   0.0497088   0.09176416
  -0.06861353  0.04488569 -0.10469329  0.01577591 -0.16075081  0.13146578
   0.02312423 -0.01975616  0.02117931 -0.05428495 -0.03710907 -0.07236046
  -0.05887813 -0.15996082  0.01320226  0.21694243  0.17475107  0.10223134
   0.05452618 -0.07132658 -0.04809659 -0.01047385]]
After layer _mul2079_0 (1, 256) <class 'numpy.float32'> [[-0.0706955  -0.06492522 -0.00331771  0.01706547  0.02214051 -0.02772411
   0.02190335  0.04861316  0.02878577 -0.03999904 -0.0349379   0.05953371
   0.04348885 -0.0160764   0.02873471 -0.11449127  0.02459531  0.01014146
   0.03921776  0.0247631   0.09439042 -0.02135261  0.00058711  0.03543586
  -0.05705171  0.01716811  0.02991352 -0.02155855 -0.0686112  -0.0487849
   0.01691643 -0.06218728 -0.01153225  0.00538681  0.0566876  -0.06621245
  -0.03345093 -0.00456806 -0.05935533 -0.04897347  0.0145305  -0.09267527
   0.05903066  0.04410159  0.0432286  -0.05159571  0.01808337 -0.0354484
  -0.00546283 -0.04473269  0.03245934 -0.05656386 -0.03804006  0.0566192
   0.02370151  0.0156374  -0.01990686  0.08528677  0.04140948 -0.02338164
  -0.03734456 -0.04887144 -0.01638123 -0.00559876  0.02884625 -0.01594259
   0.0185534  -0.04896418 -0.05626991 -0.0119814  -0.12064599 -0.00017071
   0.03112596  0.01658777  0.06080428 -0.02405796 -0.01318246 -0.0884014
  -0.02780186 -0.0174547  -0.05239339  0.01277422 -0.04158242 -0.07445832
  -0.12347287  0.0075234  -0.06978596  0.01732525 -0.07947338 -0.0632758
  -0.05727384 -0.03072345 -0.01480202 -0.00724009 -0.02356248  0.02183293
   0.04845636 -0.0206785  -0.05296896 -0.03330231  0.01236167  0.06872737
  -0.03376108  0.02079892  0.0289439   0.06436262 -0.02326545 -0.02331437
   0.07753047 -0.09098891  0.03775231  0.00240649  0.03194211  0.04140569
  -0.04492072  0.13774519 -0.06924696 -0.03206538  0.02080317 -0.03050295
   0.08077773  0.03857672 -0.0128075  -0.0423771   0.05331541 -0.08710905
  -0.04936265 -0.03201984 -0.02256865 -0.01567332  0.03723404 -0.02159246
   0.0391975  -0.00031905  0.00016165  0.03303309  0.0486736   0.10446326
  -0.0030073   0.02820871 -0.00393452 -0.02390167  0.06330568  0.01121309
  -0.04896998  0.04471813  0.02926625 -0.05846122 -0.04840321 -0.05931354
  -0.03062462 -0.01430265 -0.02386644 -0.04321278 -0.0096512   0.03698089
  -0.05619083  0.02704475  0.0269101   0.03065451 -0.10146257 -0.03568237
   0.01492678  0.07876147  0.01533979  0.04526421  0.00784524 -0.02821312
  -0.08630519  0.00925227 -0.04380643  0.01794809 -0.01680582 -0.0713956
  -0.01202949  0.03489346  0.06878814 -0.02163051 -0.03066575 -0.01816473
   0.03448616  0.00261514  0.01713191 -0.01766795 -0.03220547  0.03306343
   0.02143384 -0.04853586  0.05149789 -0.06591094  0.08785702 -0.01063103
   0.00385495  0.00569333 -0.09331633 -0.00433668 -0.10410922 -0.04202797
  -0.0180719   0.02581601 -0.07401262 -0.01276847  0.08712801 -0.03047122
  -0.01167548 -0.01002599  0.03364149  0.00459896  0.05228848 -0.04351415
  -0.08172128 -0.00075051  0.01240027 -0.08189869 -0.02861047 -0.04093218
   0.01354113 -0.01884156 -0.01353098  0.05408636 -0.01939234 -0.04553062
   0.03643929  0.00928602  0.00230559 -0.02641698  0.00184383  0.01735384
   0.02151771 -0.00708497 -0.07001785  0.08231969  0.02465394  0.04521049
  -0.03488887  0.02316726 -0.05215302  0.00815071 -0.08161745  0.0642671
   0.0112463  -0.0094074   0.01121223 -0.03022691 -0.01817174 -0.03683781
  -0.0294448  -0.07761218  0.00665226  0.110365    0.09276498  0.05148001
   0.02630215 -0.03652676 -0.0245545  -0.00516632]]
After layer encoder_birnn_reverse_l0_t3_state_0 (1, 256) <class 'numpy.float32'> [[ -1.16361775e-01  -1.01768702e-01   5.72184706e-03   3.22544165e-02
    4.58433032e-02  -4.60373610e-02   4.00274023e-02   7.59935230e-02
    2.63232756e-02  -7.70355314e-02  -6.13985509e-02   9.09934640e-02
    8.30352455e-02  -3.95270810e-02   6.05145991e-02  -1.85247272e-01
    3.06259822e-02   7.07687577e-03   5.96850440e-02   4.56129164e-02
    1.59545511e-01  -4.24270928e-02   8.29579309e-03   6.41331449e-02
   -8.15340132e-02   2.73727030e-02   2.53302958e-02  -2.58434191e-02
   -1.09085023e-01  -7.72420019e-02   3.26534212e-02  -1.11062616e-01
   -8.26257840e-03  -5.08930208e-03   9.03944820e-02  -1.11477405e-01
   -6.17551617e-02  -1.93180218e-02  -9.21577513e-02  -6.70365542e-02
    4.11185436e-02  -1.33219793e-01   9.74847972e-02   7.26232678e-02
    7.94362575e-02  -9.42335874e-02   4.00727615e-02  -5.73668554e-02
   -8.13276693e-03  -6.24055192e-02   3.48921493e-02  -9.33676511e-02
   -6.38774410e-02   8.29558969e-02   5.17190546e-02   1.93108562e-02
   -4.68272045e-02   1.50421247e-01   6.38284981e-02  -5.19362390e-02
   -6.53309375e-02  -7.97065943e-02  -3.41594629e-02  -1.00931665e-02
    6.96860105e-02  -3.29668596e-02   5.36205992e-02  -5.47322556e-02
   -9.57289934e-02  -2.66864970e-02  -2.01879084e-01   9.97904968e-03
    5.27966246e-02   1.72319040e-02   1.09632306e-01  -4.75057065e-02
   -3.99838537e-02  -1.34844244e-01  -5.12971692e-02  -3.05498727e-02
   -8.54559243e-02   5.20094112e-03  -6.17691837e-02  -1.27075672e-01
   -2.02503473e-01   2.36936510e-02  -1.16784364e-01   3.88897881e-02
   -1.18787661e-01  -9.70517248e-02  -6.98209479e-02  -4.29456532e-02
   -1.68330483e-02  -2.44895797e-02  -3.65045927e-02   2.72935051e-02
    7.71683156e-02  -4.00333554e-02  -7.89278597e-02  -5.00847772e-02
    3.78660560e-02   1.08627334e-01  -6.60126805e-02   3.72025445e-02
    3.32639627e-02   9.37966555e-02  -3.87306288e-02  -3.83382998e-02
    1.19697928e-01  -1.32277220e-01   6.57812208e-02   2.04985663e-02
    4.62325960e-02   6.79737777e-02  -8.24333578e-02   2.09812731e-01
   -1.09296553e-01  -5.64000309e-02   4.27898318e-02  -3.08340192e-02
    1.23634711e-01   8.27900246e-02  -2.25550644e-02  -7.24229813e-02
    9.07442644e-02  -1.46355018e-01  -5.68076968e-02  -5.86495996e-02
   -2.89621390e-02  -3.97829525e-03   6.83797374e-02  -4.37962376e-02
    6.62232339e-02  -2.04255357e-02   1.14208339e-02   5.91998994e-02
    9.19171125e-02   1.65789172e-01  -8.72692652e-03   5.64720817e-02
   -1.38798803e-02  -4.62782457e-02   1.09209962e-01   9.59162973e-03
   -8.14580694e-02   7.38614947e-02   5.43530509e-02  -1.05841100e-01
   -7.06607923e-02  -7.81155452e-02  -5.57819977e-02  -2.54063830e-02
   -3.95149253e-02  -7.37656876e-02  -8.63985810e-03   5.73440492e-02
   -9.15646851e-02   4.95423675e-02   4.55519818e-02   5.63913062e-02
   -1.80798948e-01  -7.02672750e-02   2.29571015e-02   1.16149545e-01
    1.94716677e-02   7.91701823e-02   9.61849745e-03  -6.78221956e-02
   -1.40602738e-01  -3.25407833e-04  -7.70090967e-02   3.45589146e-02
   -2.59658769e-02  -1.20647132e-01  -1.40851177e-02   5.34872562e-02
    1.29674807e-01  -4.49287891e-02  -6.45873994e-02  -3.62214297e-02
    6.85471147e-02   5.70505671e-03   3.05355750e-02  -2.64928825e-02
   -2.93365959e-02   3.91138494e-02   3.29619087e-02  -9.58973318e-02
    8.90187100e-02  -9.94156450e-02   1.48982868e-01  -2.37578712e-03
    3.25540756e-03   3.43599776e-03  -1.49413884e-01   2.03209324e-03
   -1.64587259e-01  -8.00956190e-02  -1.49884149e-02   4.83063981e-02
   -1.15514815e-01  -2.02581938e-02   1.51131302e-01  -5.25514632e-02
   -1.83268730e-03  -1.52415354e-02   4.48757000e-02   3.39008356e-03
    9.93791595e-02  -8.52096230e-02  -1.18696004e-01   1.41323516e-02
    2.59508826e-02  -1.15317866e-01  -5.06412163e-02  -6.94417655e-02
    1.67483985e-02  -3.04940306e-02  -8.59943405e-03   9.23399627e-02
   -1.99027825e-02  -6.74811602e-02   6.67936653e-02   1.50173577e-03
    5.67913521e-05  -3.71006504e-02   1.27172947e-03   2.97052599e-02
    4.02055606e-02  -1.32817589e-02  -1.13982186e-01   1.19835600e-01
    5.37223518e-02   7.30106384e-02  -6.39161319e-02   4.64545935e-02
   -9.25887004e-02   1.69220380e-02  -1.25060409e-01   1.06524758e-01
    2.09076945e-02  -2.77896635e-02   1.88676231e-02  -6.92612827e-02
   -3.56645286e-02  -6.32621646e-02  -4.52660099e-02  -1.09109417e-01
    1.22770481e-03   1.85078800e-01   1.57034665e-01   7.80828893e-02
    5.07233590e-02  -5.56742996e-02  -3.24738771e-02  -2.48133168e-02]]
After layer activation1039_output (1, 256) <class 'numpy.float32'> [[ -1.15839422e-01  -1.01418823e-01   5.72178466e-03   3.22432369e-02
    4.58112173e-02  -4.60048653e-02   4.00060378e-02   7.58475736e-02
    2.63171978e-02  -7.68835023e-02  -6.13215156e-02   9.07431617e-02
    8.28449354e-02  -3.95065099e-02   6.04408383e-02  -1.83156952e-01
    3.06164101e-02   7.07675749e-03   5.96142747e-02   4.55813110e-02
    1.58205435e-01  -4.24016528e-02   8.29560310e-03   6.40453622e-02
   -8.13538209e-02   2.73658689e-02   2.53248792e-02  -2.58376673e-02
   -1.08654387e-01  -7.70887509e-02   3.26418206e-02  -1.10608213e-01
   -8.26239027e-03  -5.08925831e-03   9.01490748e-02  -1.11017905e-01
   -6.16767779e-02  -1.93156190e-02  -9.18977335e-02  -6.69363141e-02
    4.10953872e-02  -1.32437244e-01   9.71771628e-02   7.24958628e-02
    7.92695954e-02  -9.39556435e-02   4.00513262e-02  -5.73040098e-02
   -8.13258719e-03  -6.23246357e-02   3.48779969e-02  -9.30972844e-02
   -6.37907013e-02   8.27661306e-02   5.16729914e-02   1.93084572e-02
   -4.67930064e-02   1.49296924e-01   6.37419596e-02  -5.18895909e-02
   -6.52381480e-02  -7.95382261e-02  -3.41461822e-02  -1.00928238e-02
    6.95734322e-02  -3.29549238e-02   5.35692684e-02  -5.46776690e-02
   -9.54376459e-02  -2.66801640e-02  -1.99180529e-01   9.97871812e-03
    5.27476221e-02   1.72301978e-02   1.09195180e-01  -4.74700034e-02
   -3.99625599e-02  -1.34032860e-01  -5.12522236e-02  -3.05403732e-02
   -8.52485150e-02   5.20089408e-03  -6.16907440e-02  -1.26396045e-01
   -1.99780077e-01   2.36892179e-02  -1.16256326e-01   3.88701931e-02
   -1.18232086e-01  -9.67481583e-02  -6.97077140e-02  -4.29192707e-02
   -1.68314595e-02  -2.44846847e-02  -3.64883877e-02   2.72867307e-02
    7.70155042e-02  -4.00119834e-02  -7.87643716e-02  -5.00429422e-02
    3.78479697e-02   1.08202077e-01  -6.59169629e-02   3.71853895e-02
    3.32516991e-02   9.35225561e-02  -3.87112759e-02  -3.83195281e-02
    1.19129531e-01  -1.31511092e-01   6.56865016e-02   2.04956960e-02
    4.61996831e-02   6.78692833e-02  -8.22471455e-02   2.06787243e-01
   -1.08863413e-01  -5.63403070e-02   4.27637361e-02  -3.08242515e-02
    1.23008601e-01   8.26013908e-02  -2.25512404e-02  -7.22966269e-02
    9.04960036e-02  -1.45318940e-01  -5.67466691e-02  -5.85824437e-02
   -2.89540440e-02  -3.97827430e-03   6.82733580e-02  -4.37682569e-02
    6.61265999e-02  -2.04226952e-02   1.14203375e-02   5.91308400e-02
    9.16591212e-02   1.64286733e-01  -8.72670487e-03   5.64121269e-02
   -1.38789890e-02  -4.62452359e-02   1.08777851e-01   9.59133543e-03
   -8.12783763e-02   7.37274736e-02   5.42995892e-02  -1.05447643e-01
   -7.05434233e-02  -7.79570490e-02  -5.57242110e-02  -2.54009180e-02
   -3.94943729e-02  -7.36321807e-02  -8.63964297e-03   5.72812781e-02
   -9.13096443e-02   4.95018736e-02   4.55205031e-02   5.63316084e-02
   -1.78854376e-01  -7.01518580e-02   2.29530688e-02   1.15630038e-01
    1.94692072e-02   7.90051892e-02   9.61820129e-03  -6.77183941e-02
   -1.39683485e-01  -3.25407833e-04  -7.68572241e-02   3.45451646e-02
   -2.59600431e-02  -1.20065153e-01  -1.40841864e-02   5.34363091e-02
    1.28952816e-01  -4.48985845e-02  -6.44977391e-02  -3.62055972e-02
    6.84399530e-02   5.70499478e-03   3.05260886e-02  -2.64866855e-02
   -2.93281823e-02   3.90939154e-02   3.29499766e-02  -9.56044421e-02
    8.87843147e-02  -9.90894139e-02   1.47890300e-01  -2.37578270e-03
    3.25539615e-03   3.43598425e-03  -1.48311868e-01   2.03209044e-03
   -1.63117021e-01  -7.99247772e-02  -1.49872927e-02   4.82688583e-02
   -1.15003750e-01  -2.02554222e-02   1.49991080e-01  -5.25031425e-02
   -1.83268520e-03  -1.52403554e-02   4.48455997e-02   3.39007052e-03
    9.90532860e-02  -8.50039944e-02  -1.18141703e-01   1.41314110e-02
    2.59450581e-02  -1.14809401e-01  -5.05979694e-02  -6.93303645e-02
    1.67468321e-02  -3.04845814e-02  -8.59922171e-03   9.20784026e-02
   -1.99001543e-02  -6.73789158e-02   6.66945130e-02   1.50173460e-03
    5.67913521e-05  -3.70836370e-02   1.27172878e-03   2.96965260e-02
    4.01839092e-02  -1.32809775e-02  -1.13491125e-01   1.19265243e-01
    5.36707304e-02   7.28811845e-02  -6.38292357e-02   4.64212075e-02
   -9.23250318e-02   1.69204231e-02  -1.24412484e-01   1.06123649e-01
    2.09046490e-02  -2.77825128e-02   1.88653842e-02  -6.91507459e-02
   -3.56494151e-02  -6.31779060e-02  -4.52351198e-02  -1.08678497e-01
    1.22770423e-03   1.82994127e-01   1.55756459e-01   7.79245868e-02
    5.06799035e-02  -5.56168482e-02  -3.24624665e-02  -2.48082262e-02]]
After layer encoder_birnn_reverse_l0_t3_out_0 (1, 256) <class 'numpy.float32'> [[ -5.95939234e-02  -5.13121262e-02   2.83935596e-03   1.65359806e-02
    2.36094035e-02  -2.52703521e-02   2.10583471e-02   4.03830186e-02
    1.52213797e-02  -4.06370312e-02  -3.02126370e-02   4.67315800e-02
    4.43820730e-02  -1.94544364e-02   3.07283066e-02  -9.61648300e-02
    1.49320336e-02   3.44101759e-03   3.00955754e-02   2.25317106e-02
    7.80980289e-02  -1.98746566e-02   4.60109161e-03   3.36059406e-02
   -4.23282683e-02   1.38634499e-02   1.26774721e-02  -1.29658878e-02
   -5.24566695e-02  -3.89667079e-02   1.71387419e-02  -5.81503473e-02
   -4.19315742e-03  -2.57314253e-03   4.44441214e-02  -5.50010502e-02
   -3.22929546e-02  -9.59426630e-03  -4.80000861e-02  -3.35829556e-02
    2.15323064e-02  -6.52511865e-02   4.86125685e-02   3.62617448e-02
    3.91400345e-02  -4.73692194e-02   2.02236511e-02  -2.79495250e-02
   -4.14593099e-03  -3.23299915e-02   1.82164665e-02  -4.53587808e-02
   -3.22434343e-02   4.25502136e-02   2.83461381e-02   9.12806857e-03
   -2.48627402e-02   7.52526298e-02   3.22761983e-02  -2.46097576e-02
   -3.31847817e-02  -4.05148752e-02  -1.73485540e-02  -5.40054776e-03
    3.45584676e-02  -1.59973204e-02   2.89359726e-02  -2.81077605e-02
   -4.87422347e-02  -1.40336622e-02  -1.00466281e-01   5.10093803e-03
    2.66580284e-02   8.52311123e-03   5.67720160e-02  -2.63548549e-02
   -2.12040208e-02  -6.86243251e-02  -2.69084182e-02  -1.67212021e-02
   -4.57737818e-02   2.83701485e-03  -3.20753343e-02  -6.71405941e-02
   -1.06165327e-01   1.22074755e-02  -5.90054691e-02   2.06327010e-02
   -6.11361526e-02  -5.10527529e-02  -3.72033380e-02  -2.11302806e-02
   -8.04854743e-03  -1.24472659e-02  -1.88063346e-02   1.38866231e-02
    3.99291478e-02  -2.13765036e-02  -3.69355790e-02  -2.41191164e-02
    1.89243443e-02   5.08328266e-02  -3.21919508e-02   1.79711301e-02
    1.67319998e-02   4.70964611e-02  -1.90093219e-02  -2.03332808e-02
    6.09184578e-02  -7.18130842e-02   3.29628438e-02   1.05061475e-02
    2.22752243e-02   3.59671377e-02  -4.16633673e-02   1.10533848e-01
   -5.20973206e-02  -2.78122202e-02   2.25494988e-02  -1.48813380e-02
    6.24700859e-02   4.30235751e-02  -1.18490951e-02  -3.62365693e-02
    4.46009301e-02  -7.38178492e-02  -2.81182975e-02  -2.90308036e-02
   -1.42077440e-02  -1.94378069e-03   3.43860537e-02  -2.38372553e-02
    3.30808274e-02  -1.06815165e-02   5.79953706e-03   2.87650712e-02
    4.84190546e-02   8.46802965e-02  -4.60017053e-03   2.85957139e-02
   -6.95774704e-03  -2.32268367e-02   5.17627299e-02   4.91355220e-03
   -4.09132615e-02   3.72759998e-02   2.87758838e-02  -5.36815859e-02
   -3.60417068e-02  -3.87255996e-02  -2.76139341e-02  -1.24987653e-02
   -2.02384386e-02  -3.91723961e-02  -4.40787105e-03   2.99122110e-02
   -4.70959358e-02   2.64997166e-02   2.32509151e-02   2.98465770e-02
   -9.21765342e-02  -3.55282277e-02   1.13109462e-02   6.18341602e-02
    1.01472158e-02   3.82936038e-02   5.31765679e-03  -3.54401730e-02
   -6.68240935e-02  -1.65179925e-04  -3.69292907e-02   1.80042312e-02
   -1.35009577e-02  -6.50830045e-02  -7.19394395e-03   2.86466405e-02
    6.89525083e-02  -2.20730659e-02  -3.38322707e-02  -1.80332083e-02
    3.28418352e-02   2.78824870e-03   1.55599024e-02  -1.30589763e-02
   -1.44596780e-02   2.03229003e-02   1.63129214e-02  -4.99269068e-02
    4.55278233e-02  -4.82260771e-02   7.54078403e-02  -1.26574759e-03
    1.66789314e-03   1.71578443e-03  -7.77679011e-02   1.04495382e-03
   -8.07418525e-02  -4.12041023e-02  -7.81564321e-03   2.40886491e-02
   -5.92563972e-02  -1.12330271e-02   7.83546343e-02  -2.80167889e-02
   -9.53334791e-04  -7.95550272e-03   2.18012445e-02   1.71626860e-03
    4.79490571e-02  -4.55312617e-02  -5.85524999e-02   8.06559622e-03
    1.31701557e-02  -6.11847043e-02  -2.63588391e-02  -3.42233926e-02
    8.64978321e-03  -1.64002683e-02  -4.22818633e-03   4.48813066e-02
   -9.68645513e-03  -3.22907567e-02   3.53871547e-02   7.57809030e-04
    2.93898447e-05  -1.94013156e-02   6.41893770e-04   1.49372593e-02
    2.26354338e-02  -7.32262852e-03  -5.75294048e-02   5.71500845e-02
    2.66617183e-02   3.64583321e-02  -3.16398963e-02   2.34122928e-02
   -4.54394892e-02   8.75022449e-03  -6.52884915e-02   5.35988361e-02
    1.01501979e-02  -1.44652491e-02   1.01339873e-02  -4.00148407e-02
   -1.70290247e-02  -3.25160213e-02  -2.34320164e-02  -5.14491536e-02
    6.21173473e-04   9.21396688e-02   8.13614205e-02   3.77366170e-02
    2.64196787e-02  -2.96076965e-02  -1.61670391e-02  -1.28790466e-02]]
After layer expand_dims1045_0 (1, 1, 256) <class 'numpy.float32'> [[[ -5.95939234e-02  -5.13121262e-02   2.83935596e-03   1.65359806e-02
     2.36094035e-02  -2.52703521e-02   2.10583471e-02   4.03830186e-02
     1.52213797e-02  -4.06370312e-02  -3.02126370e-02   4.67315800e-02
     4.43820730e-02  -1.94544364e-02   3.07283066e-02  -9.61648300e-02
     1.49320336e-02   3.44101759e-03   3.00955754e-02   2.25317106e-02
     7.80980289e-02  -1.98746566e-02   4.60109161e-03   3.36059406e-02
    -4.23282683e-02   1.38634499e-02   1.26774721e-02  -1.29658878e-02
    -5.24566695e-02  -3.89667079e-02   1.71387419e-02  -5.81503473e-02
    -4.19315742e-03  -2.57314253e-03   4.44441214e-02  -5.50010502e-02
    -3.22929546e-02  -9.59426630e-03  -4.80000861e-02  -3.35829556e-02
     2.15323064e-02  -6.52511865e-02   4.86125685e-02   3.62617448e-02
     3.91400345e-02  -4.73692194e-02   2.02236511e-02  -2.79495250e-02
    -4.14593099e-03  -3.23299915e-02   1.82164665e-02  -4.53587808e-02
    -3.22434343e-02   4.25502136e-02   2.83461381e-02   9.12806857e-03
    -2.48627402e-02   7.52526298e-02   3.22761983e-02  -2.46097576e-02
    -3.31847817e-02  -4.05148752e-02  -1.73485540e-02  -5.40054776e-03
     3.45584676e-02  -1.59973204e-02   2.89359726e-02  -2.81077605e-02
    -4.87422347e-02  -1.40336622e-02  -1.00466281e-01   5.10093803e-03
     2.66580284e-02   8.52311123e-03   5.67720160e-02  -2.63548549e-02
    -2.12040208e-02  -6.86243251e-02  -2.69084182e-02  -1.67212021e-02
    -4.57737818e-02   2.83701485e-03  -3.20753343e-02  -6.71405941e-02
    -1.06165327e-01   1.22074755e-02  -5.90054691e-02   2.06327010e-02
    -6.11361526e-02  -5.10527529e-02  -3.72033380e-02  -2.11302806e-02
    -8.04854743e-03  -1.24472659e-02  -1.88063346e-02   1.38866231e-02
     3.99291478e-02  -2.13765036e-02  -3.69355790e-02  -2.41191164e-02
     1.89243443e-02   5.08328266e-02  -3.21919508e-02   1.79711301e-02
     1.67319998e-02   4.70964611e-02  -1.90093219e-02  -2.03332808e-02
     6.09184578e-02  -7.18130842e-02   3.29628438e-02   1.05061475e-02
     2.22752243e-02   3.59671377e-02  -4.16633673e-02   1.10533848e-01
    -5.20973206e-02  -2.78122202e-02   2.25494988e-02  -1.48813380e-02
     6.24700859e-02   4.30235751e-02  -1.18490951e-02  -3.62365693e-02
     4.46009301e-02  -7.38178492e-02  -2.81182975e-02  -2.90308036e-02
    -1.42077440e-02  -1.94378069e-03   3.43860537e-02  -2.38372553e-02
     3.30808274e-02  -1.06815165e-02   5.79953706e-03   2.87650712e-02
     4.84190546e-02   8.46802965e-02  -4.60017053e-03   2.85957139e-02
    -6.95774704e-03  -2.32268367e-02   5.17627299e-02   4.91355220e-03
    -4.09132615e-02   3.72759998e-02   2.87758838e-02  -5.36815859e-02
    -3.60417068e-02  -3.87255996e-02  -2.76139341e-02  -1.24987653e-02
    -2.02384386e-02  -3.91723961e-02  -4.40787105e-03   2.99122110e-02
    -4.70959358e-02   2.64997166e-02   2.32509151e-02   2.98465770e-02
    -9.21765342e-02  -3.55282277e-02   1.13109462e-02   6.18341602e-02
     1.01472158e-02   3.82936038e-02   5.31765679e-03  -3.54401730e-02
    -6.68240935e-02  -1.65179925e-04  -3.69292907e-02   1.80042312e-02
    -1.35009577e-02  -6.50830045e-02  -7.19394395e-03   2.86466405e-02
     6.89525083e-02  -2.20730659e-02  -3.38322707e-02  -1.80332083e-02
     3.28418352e-02   2.78824870e-03   1.55599024e-02  -1.30589763e-02
    -1.44596780e-02   2.03229003e-02   1.63129214e-02  -4.99269068e-02
     4.55278233e-02  -4.82260771e-02   7.54078403e-02  -1.26574759e-03
     1.66789314e-03   1.71578443e-03  -7.77679011e-02   1.04495382e-03
    -8.07418525e-02  -4.12041023e-02  -7.81564321e-03   2.40886491e-02
    -5.92563972e-02  -1.12330271e-02   7.83546343e-02  -2.80167889e-02
    -9.53334791e-04  -7.95550272e-03   2.18012445e-02   1.71626860e-03
     4.79490571e-02  -4.55312617e-02  -5.85524999e-02   8.06559622e-03
     1.31701557e-02  -6.11847043e-02  -2.63588391e-02  -3.42233926e-02
     8.64978321e-03  -1.64002683e-02  -4.22818633e-03   4.48813066e-02
    -9.68645513e-03  -3.22907567e-02   3.53871547e-02   7.57809030e-04
     2.93898447e-05  -1.94013156e-02   6.41893770e-04   1.49372593e-02
     2.26354338e-02  -7.32262852e-03  -5.75294048e-02   5.71500845e-02
     2.66617183e-02   3.64583321e-02  -3.16398963e-02   2.34122928e-02
    -4.54394892e-02   8.75022449e-03  -6.52884915e-02   5.35988361e-02
     1.01501979e-02  -1.44652491e-02   1.01339873e-02  -4.00148407e-02
    -1.70290247e-02  -3.25160213e-02  -2.34320164e-02  -5.14491536e-02
     6.21173473e-04   9.21396688e-02   8.13614205e-02   3.77366170e-02
     2.64196787e-02  -2.96076965e-02  -1.61670391e-02  -1.28790466e-02]]]
After layer encoder_birnn_reverse_l0_t4_i2h_output (1, 1024) <class 'numpy.float32'> [[-0.0128371  -0.04095686  0.03787835 ...,  0.06970935 -0.04625846
   0.03761056]]
After layer encoder_birnn_reverse_l0_t4_h2h_output (1, 1024) <class 'numpy.float32'> [[ 0.00686097  0.02535675 -0.04446622 ...,  0.06372035  0.03655343
   0.03141598]]
After layer _plus1040_0 (1, 1024) <class 'numpy.float32'> [[-0.00597613 -0.01560012 -0.00658786 ...,  0.13342969 -0.00970503
   0.06902653]]
After layer encoder_birnn_reverse_l0_t4_slice_output0 (1, 256) <class 'numpy.float32'> [[ -5.97612932e-03  -1.56001151e-02  -6.58786297e-03  -2.04464346e-02
    5.26723564e-02  -7.69961253e-03   3.66066620e-02   2.30205096e-02
    9.16994661e-02   5.51537797e-02  -3.70850302e-02   7.68961161e-02
    1.96794979e-02   4.05452587e-02  -1.28442422e-03   2.57033974e-01
   -9.06760916e-02  -6.15499243e-02   1.29447198e-02  -1.20114023e-02
    8.44392255e-02   2.60493271e-02  -8.89017805e-02  -3.93689945e-02
    8.45534131e-02  -1.18551061e-01  -3.14612538e-02  -1.84832774e-02
    2.97283456e-02  -1.70210525e-02   2.43999902e-03  -1.80766433e-02
   -4.24181707e-02  -4.57604825e-02   6.90815896e-02  -1.23220757e-01
   -8.97440128e-03  -5.89624606e-03  -7.20429942e-02  -5.24090491e-02
   -9.28834975e-02   3.31427380e-02  -5.38458228e-02   1.42599270e-03
    3.56479920e-02  -8.65138322e-03   6.40020519e-02  -7.54615068e-02
   -1.46161616e-02   2.04986706e-02   5.70084900e-04   9.65387672e-02
   -7.15595484e-02   6.77022189e-02   1.86172783e-01   9.85341370e-02
   -5.46721406e-02   1.11641474e-02  -5.83104268e-02  -2.32513715e-02
    7.05310851e-02  -4.34065945e-02   1.55174404e-01  -2.67871078e-02
   -1.10945493e-01  -4.11620066e-02   9.62150618e-02  -1.76678225e-02
   -5.91332465e-02   1.73499733e-02   9.55960602e-02  -2.32152529e-02
    2.72247940e-04  -6.40072860e-03  -3.61724570e-03   6.86851516e-02
    1.23601682e-01   1.41010910e-01   1.11520439e-02   4.38167378e-02
    2.52735335e-02   4.59240079e-02   8.57852250e-02  -1.75875202e-02
    1.60018325e-01   5.80707043e-02  -2.71477420e-02  -3.90970632e-02
   -2.71305069e-02   9.37773511e-02   1.16478726e-01  -1.94365196e-02
   -8.02231431e-02   9.08962786e-02   7.43148327e-02   4.31826860e-02
   -2.32738666e-02   8.97298530e-02  -8.73018205e-02  -1.06954500e-01
   -7.27708042e-02   7.54060522e-02  -1.76042318e-03  -1.32970348e-01
   -6.45532161e-02   6.99965656e-03  -2.14130823e-02  -1.10713102e-01
    5.33035994e-02   5.00011221e-02  -1.20013505e-01   2.97976434e-02
    1.75201111e-02   1.79589614e-01   2.16187537e-03   2.86674559e-01
   -3.54667716e-02   8.49277340e-03   3.94560695e-02  -3.95182297e-02
    2.04985917e-01  -1.20153517e-01   4.31105867e-03   9.17104185e-02
   -5.20750657e-02   5.36421984e-02  -1.14937864e-01   6.76374137e-02
   -1.67700294e-02   3.64825502e-03   1.80573910e-01   6.52438179e-02
   -4.85293940e-03  -3.46059985e-02  -6.53023124e-02  -5.84255159e-02
    9.37486440e-02   1.49386674e-01   7.59722665e-04  -1.71841960e-02
   -3.76820453e-02  -9.45280790e-02   7.41578713e-02   6.56373128e-02
   -3.36522311e-02  -3.81785445e-03   3.04730237e-02   5.92055470e-02
   -1.70724560e-02   5.57607114e-02   1.09192923e-01  -5.02669811e-02
    2.95258686e-03  -9.40551162e-02  -6.73107877e-02   1.88912511e-01
    3.25879827e-02   6.35945201e-02  -1.58624984e-02  -3.25359851e-02
    1.89379901e-01   1.01331994e-02  -4.72250916e-02   3.44891101e-02
    1.54922809e-02  -6.26773983e-02   1.14200264e-02  -4.35884781e-02
    5.15375733e-02  -3.92882526e-02   1.33750048e-02   3.87708843e-02
    5.51686436e-03   9.85208601e-02   2.91397925e-02  -1.21137775e-01
    3.48321013e-02  -1.13776937e-01  -4.87829298e-02  -2.38642078e-02
    3.61308791e-02  -6.34442121e-02  -1.76935717e-02   3.20744962e-02
    9.43116099e-02  -2.45650709e-02  -1.39412247e-02  -5.97212613e-02
    1.17227025e-01   5.98829985e-02  -2.43601203e-02  -1.58443935e-02
    4.41464409e-02  -2.44713724e-02   6.22888505e-02   7.26488084e-02
    7.98273906e-02  -1.54857099e-01   4.38212715e-02   5.89513890e-02
    1.11111253e-03   1.31240129e-01   6.51139989e-02   3.62555869e-02
    2.96562873e-02  -1.65163595e-02   1.31632760e-03  -5.01034297e-02
   -5.54364212e-02   4.66979817e-02   4.06525210e-02   9.62308049e-02
    2.05803849e-02   6.01598024e-02   1.25638954e-02   3.77032757e-02
   -6.26149215e-03  -2.27662101e-02   1.67705491e-02   4.35532257e-03
   -5.24536595e-02  -5.07353097e-02   7.07152486e-02  -7.20214471e-02
    1.29948109e-02   6.28335178e-02  -2.10798737e-02  -8.91676247e-02
   -6.28997535e-02   1.40649170e-01  -1.10320095e-02  -8.78607333e-02
   -1.99162569e-02  -4.08229977e-02   3.25247012e-02   6.26142994e-02
   -6.74506649e-03   7.70731047e-02   3.07102054e-02  -4.49616872e-02
   -7.64404610e-02  -1.16038382e-01   1.04522720e-01   2.33013868e-01
   -5.11086732e-02   2.78994478e-02  -3.95335928e-02  -6.49242103e-02
    1.75687969e-02   1.53506640e-02   1.35218918e-01   5.50958887e-03
   -8.55384320e-02   4.82466184e-02   4.93166149e-02  -1.96100604e-02]]
After layer encoder_birnn_reverse_l0_t4_slice_output1 (1, 256) <class 'numpy.float32'> [[  1.38838738e-01   2.38367841e-02   8.94671082e-02   4.74576391e-02
    1.98443606e-02   7.01195598e-02   1.67964950e-01  -8.60049129e-02
    3.27648640e-01   1.33586124e-01   1.19716875e-01   1.02570161e-01
    9.91575122e-02   7.43877515e-03   1.10650077e-01   1.16616987e-01
    8.46423209e-02  -4.63415757e-02  -1.35902405e-01   5.19786626e-02
    1.16789430e-01   3.92565504e-03   3.09727490e-01   4.95771542e-02
    1.13814041e-01   6.87522292e-02   1.28084391e-01   9.41585675e-02
    1.04944840e-01   3.29973064e-02   5.77021465e-02   1.34447664e-02
    2.16462076e-01  -5.46806380e-02  -1.46832727e-02   1.07906759e-04
   -5.76142110e-02   9.51395556e-02   2.11606920e-02   9.19007063e-02
   -2.30949949e-02   9.97299328e-02   1.17731821e-02   8.99374336e-02
    2.46485695e-02   1.01823986e-01   3.04904692e-02  -9.51102823e-02
    2.70035677e-03   3.37942354e-02   6.15999848e-02   7.51035362e-02
    1.84371024e-02   1.31394476e-01   7.85629451e-02   6.77481964e-02
    4.04084697e-02   8.68886858e-02   9.63298231e-03  -7.48865679e-02
    5.75008132e-02   3.63088213e-02   4.16521542e-02   4.06008549e-02
   -1.63046736e-02   1.28438398e-01   1.91245183e-01   6.05839193e-02
   -1.04419798e-01  -1.60449371e-02   6.22759834e-02  -1.39684193e-02
   -2.80942693e-02   2.92837173e-02   9.24351811e-02   1.79865211e-01
    5.31573445e-02   3.73021364e-02   7.24270865e-02   7.33390972e-02
    2.04486847e-01   1.52777299e-01   3.78783718e-02   3.58609408e-02
    1.48368806e-01   6.00394234e-03   6.89401180e-02   1.77178919e-01
    3.11059654e-02  -1.14004843e-01   2.71552205e-01   9.11684036e-02
    7.71660805e-02   7.09700733e-02  -4.63760719e-02   2.19033062e-02
    1.76879019e-02   1.04479708e-01  -1.38306364e-01  -1.52036875e-01
   -3.88339534e-02   7.60855526e-03   2.66575664e-02   9.29979980e-02
    3.33733112e-03  -2.37123258e-02  -9.47375372e-02   6.90307915e-02
    6.32544309e-02  -7.62301609e-02   4.69830632e-03  -1.75186899e-02
    3.95335704e-02   1.60488471e-01   9.52735692e-02   1.78770617e-01
    9.18935835e-02   1.18003786e-01   9.56760347e-02   1.02196172e-01
    1.76128626e-01   1.52403712e-01   3.38197015e-02   1.68036222e-02
   -1.85216218e-03  -9.41926613e-03   1.61811233e-01  -5.09952195e-03
    1.01034328e-01  -9.27547440e-02   9.45403501e-02   1.41600773e-01
    1.37682762e-02   1.44379750e-01   7.20191300e-02   6.83379620e-02
    2.09154859e-02   3.78749520e-02   1.16071343e-01   1.70315832e-01
   -7.42250383e-02   6.63447082e-02   6.26103133e-02   2.89482567e-02
    2.66752075e-02   1.25795543e-01   5.69722876e-02   3.80326994e-02
    4.12053019e-02  -1.71253756e-02  -2.81736236e-02   6.30055144e-02
    2.24736035e-02   7.76859447e-02   2.90068090e-02   1.75056666e-01
    9.65139419e-02  -6.41950965e-03   3.44621912e-02   1.32752687e-01
    2.10063785e-01   7.64885768e-02  -3.15962210e-02   8.06942284e-02
    5.68867102e-02  -2.78337672e-03   2.43770823e-01  -4.06199656e-02
   -2.44753808e-03  -3.01230662e-02   3.72515768e-02   1.12826616e-01
   -3.88264656e-02   1.90393999e-01  -3.45454365e-02   1.00362226e-01
    1.52524590e-01  -4.55686450e-03   1.76869333e-02   1.07566550e-01
    7.84010962e-02  -7.09576756e-02   2.14130372e-01  -4.07953076e-02
    9.33723710e-03   4.00640070e-04   3.56639363e-02   1.72131479e-01
    2.05434114e-02  -4.25610542e-02  -3.33601311e-02   2.51944363e-02
    1.62837312e-01   1.38303101e-01  -2.36626342e-02  -1.02895126e-03
   -1.47531591e-02  -6.68801740e-03   2.68765651e-02   1.56044187e-02
    2.89175883e-02   6.40846342e-02   7.48280138e-02  -3.67243811e-02
    9.30281803e-02  -1.24029838e-01  -2.59479210e-02   1.40216723e-01
   -4.34821323e-02   8.68847296e-02   7.42747784e-02   1.08224839e-01
   -4.90422845e-02   2.17724629e-02  -1.94947198e-02  -7.18239620e-02
    5.48774675e-02   8.93589482e-02  -1.17335785e-02   1.05461344e-01
   -9.15732235e-02  -4.23969887e-02   2.20460683e-01   2.26244144e-02
    7.77591169e-02  -5.93328476e-03   1.72745846e-02   3.59742455e-02
    3.18053842e-01   2.26155430e-01   1.64154954e-02  -2.46218011e-01
    1.40653998e-01   3.25094685e-02   5.42494766e-02   1.02978200e-04
    1.12779252e-02   8.37717578e-02   2.98036784e-02   9.36378464e-02
    7.65269324e-02   2.68054828e-02   4.15221378e-02   2.16000736e-01
   -1.33089811e-01  -2.32917275e-02  -3.62572223e-02  -5.76822236e-02
    8.80765766e-02  -1.54337063e-02   1.41365543e-01  -1.44541726e-01
    1.43982798e-01  -1.98539346e-02   1.28639847e-01   3.19248065e-03]]
After layer encoder_birnn_reverse_l0_t4_slice_output2 (1, 256) <class 'numpy.float32'> [[-0.1540679  -0.13934872 -0.01789506  0.04066113  0.03834011 -0.06106035
   0.0342505   0.08613992  0.06406091 -0.10618    -0.07927506  0.14192909
   0.0889536  -0.02642479  0.06479906 -0.23298575  0.07123289  0.02780081
   0.08835707  0.05298612  0.20932755 -0.05902676 -0.00563538  0.06032699
  -0.11724213  0.03576007  0.05923319 -0.0533734  -0.1439542  -0.1135834
   0.04246768 -0.12394588 -0.01166707  0.01039986  0.11843041 -0.15463531
  -0.06412781 -0.00447379 -0.12560135 -0.10645784  0.025213   -0.2004765
   0.1288227   0.0926054   0.09138533 -0.11317161  0.04027513 -0.07206856
  -0.0138067  -0.10067412  0.07252375 -0.12587544 -0.08247349  0.14618134
   0.02960894  0.0240269  -0.03003252  0.19313565  0.10521149 -0.04753757
  -0.09704406 -0.10149419 -0.02303346 -0.02053087  0.06867643 -0.03657133
   0.03286651 -0.11220382 -0.11002959 -0.00855689 -0.26547432  0.01522627
   0.05273718  0.02744784  0.13378167 -0.03545618 -0.04532804 -0.20088957
  -0.06886228 -0.0421061  -0.12212694  0.01959057 -0.09174417 -0.17318706
  -0.26240608  0.01032406 -0.1243663   0.02644009 -0.19117519 -0.12034581
  -0.11935405 -0.0616879  -0.03044568 -0.00649046 -0.05146239  0.05181599
   0.09642047 -0.0467265  -0.10835595 -0.08980626  0.01980129  0.14441781
  -0.07039808  0.04998217  0.0630341   0.1664111  -0.04628209 -0.04786738
   0.16308621 -0.19881108  0.10516668 -0.00426095  0.08124641  0.10255648
  -0.09233259  0.27310696 -0.16599046 -0.08554297  0.04132692 -0.07083294
   0.16909333  0.07169852 -0.01839626 -0.09795231  0.10896897 -0.18478654
  -0.11931497 -0.07721736 -0.04936589 -0.02809458  0.09002604 -0.03189023
   0.07934815  0.00852937  0.00172389  0.07433417  0.08545089  0.22220373
  -0.0037651   0.06487086 -0.00352705 -0.04767516  0.14168474  0.0253394
  -0.09178659  0.10166733  0.07292506 -0.11222239 -0.1004034  -0.13457927
  -0.06164475 -0.02773748 -0.06766261 -0.08223537 -0.00855168  0.07633451
  -0.1259301   0.0352934   0.05474716  0.07238488 -0.22653669 -0.06677441
   0.02712861  0.16006885  0.03591403  0.10025331  0.01667394 -0.0477033
  -0.20663062  0.01782061 -0.10323152  0.05369917 -0.03843944 -0.15086614
  -0.02830233  0.07902846  0.15538259 -0.05181482 -0.05868008 -0.02855424
   0.07270955  0.01526871  0.04268745 -0.03811291 -0.06856956  0.0586037
   0.05039097 -0.10929251  0.09487099 -0.13599204  0.21007803 -0.016958
  -0.00724627  0.0297184  -0.22366475 -0.00500925 -0.22954616 -0.10027969
  -0.03876971  0.07162316 -0.16831806 -0.03984142  0.18334436 -0.05987202
  -0.02075505 -0.0305606   0.0764561   0.0140005   0.13125798 -0.08100058
  -0.17517352 -0.00039122  0.03012626 -0.18965411 -0.06392145 -0.09048628
   0.03377767 -0.0417651  -0.04059248  0.12567909 -0.03594715 -0.08947709
   0.08145395  0.02632932  0.01234501 -0.05933172  0.00857156  0.03454578
   0.02989711 -0.00202305 -0.14953499  0.17851588  0.04215278  0.09226129
  -0.06968786  0.03291896 -0.09806487  0.02132599 -0.19879818  0.1295137
   0.01278649 -0.01122168  0.02828162 -0.05032404 -0.03782242 -0.06293225
  -0.06184426 -0.18379518  0.02109587  0.23531286  0.21511523  0.11036272
   0.04526538 -0.07927716 -0.05469035 -0.00812886]]
After layer encoder_birnn_reverse_l0_t4_slice_output3 (1, 256) <class 'numpy.float32'> [[  6.05067387e-02   3.55236083e-02  -1.51944757e-02   5.89059927e-02
    4.98824976e-02   2.01717898e-01   1.03051051e-01   1.26413405e-01
    3.55750293e-01   1.14057563e-01  -4.27268967e-02   6.06908016e-02
    1.55756503e-01  -3.29812914e-02   3.91924568e-02   1.09110221e-01
   -5.69229349e-02  -7.61476606e-02   2.78764144e-02  -2.02668123e-02
   -3.43261957e-02  -1.26745820e-01   2.40777820e-01   1.03485361e-01
    6.92405477e-02   4.12708297e-02  -3.46048176e-03  -3.90706770e-03
   -8.21286067e-02   1.73437856e-02   1.07586220e-01   1.00371428e-01
    3.03929821e-02   2.61490382e-02  -2.62193121e-02  -3.34510878e-02
    1.00489303e-01  -1.03156492e-02   8.09062198e-02  -4.53488156e-03
    8.47871602e-02  -2.89573520e-02  -5.15878201e-05   1.48144364e-03
   -2.84519047e-02   2.46681273e-02   2.01889090e-02  -6.05734922e-02
    3.09304968e-02   9.73702967e-02   8.57706517e-02  -3.55218612e-02
   -2.34620571e-02   5.50033115e-02   1.74214944e-01  -1.11929432e-01
    1.36338875e-01   1.72556564e-02   2.80509926e-02  -1.11854702e-01
    4.82020266e-02   5.82492054e-02   2.89679989e-02   1.52536854e-01
   -9.68918763e-03  -6.07951432e-02   1.82950109e-01   5.70051149e-02
    2.20523998e-02   9.01418552e-02   1.82354711e-02   4.01581302e-02
    1.21156909e-02  -1.80208609e-02   9.81096402e-02   2.11371809e-01
    1.35588825e-01   4.30506282e-02   1.09426662e-01   2.02020258e-01
    1.60634801e-01   1.90992847e-01   8.72007981e-02   1.18070267e-01
    1.44917116e-01   5.57027124e-02   2.91047730e-02   1.09135464e-01
    7.29681253e-02   8.45836699e-02   1.48050010e-01  -3.98721248e-02
   -8.81857127e-02   3.02395839e-02   5.58851585e-02   3.52592804e-02
    6.84859753e-02   1.20415598e-01  -1.34845138e-01  -9.27754417e-02
   -2.40765475e-02  -1.33902043e-01  -6.38164282e-02  -7.71691203e-02
   -4.12870944e-03   1.13769136e-02  -3.58484089e-02   1.23131126e-01
    5.20495698e-02   1.62606180e-01   7.59835169e-03   5.47125228e-02
   -7.74562955e-02   1.29164547e-01   1.33696944e-02   1.44742727e-01
   -8.28059539e-02  -2.24379599e-02   8.15872550e-02  -5.98588362e-02
    2.77970880e-02   8.76318142e-02   9.22683403e-02   7.65139610e-03
   -4.21510637e-02   3.27800028e-02  -1.61474217e-02  -1.01956800e-02
   -2.83524767e-02  -7.49625415e-02   1.62907690e-02   1.83892116e-01
   -1.31509667e-02   9.29475203e-02   3.93474475e-02  -6.46792501e-02
    1.20733768e-01   5.97091876e-02   1.13502353e-01   2.62455922e-02
    1.16735362e-02   7.95695931e-04  -8.56919885e-02   6.16762452e-02
    4.98016644e-03   2.38208100e-02   1.37144744e-01   4.96857502e-02
    3.96371596e-02  -1.40737798e-02  -2.34804042e-02  -2.99832504e-02
    5.93413711e-02   1.30165130e-01   1.67482607e-02   8.34750012e-02
    8.02530199e-02   1.20318912e-01   4.29607704e-02   1.27280399e-01
    7.18325302e-02   2.55966298e-02  -2.10073143e-02   1.39405221e-01
    8.18764791e-02  -6.72695488e-02   2.39825755e-01   1.02034479e-01
   -1.09857738e-01   2.38483921e-02  -9.09328312e-02   9.60420668e-02
    8.02665651e-02   1.85534894e-01   3.05365436e-02   1.60206199e-01
    1.45038307e-01  -4.89988178e-02   8.92329663e-02  -1.15466677e-02
   -1.01111703e-01  -5.69258779e-02   4.01806198e-02  -5.24343178e-02
   -4.14091423e-02   1.05877832e-01  -2.07120348e-02   9.60021764e-02
    1.27585903e-02  -8.04900676e-02   2.69247293e-02   1.37230575e-01
    4.84012216e-02   7.52227008e-03   4.94586378e-02   5.77538460e-02
   -2.58284397e-02   5.48883379e-02   1.01423934e-01   5.86978346e-03
    6.98471591e-02   2.18692109e-01   8.85877982e-02   1.41631916e-01
    8.59855041e-02   9.07120779e-02  -6.64159134e-02   3.79847325e-02
   -8.12837034e-02   1.55949205e-01  -9.90955159e-03   2.92114913e-01
    4.31433879e-02   1.42308384e-01   8.93244892e-02  -4.00740020e-02
    6.23069964e-02   1.71055868e-01  -3.31860259e-02  -5.10434061e-02
   -4.68658023e-02  -1.09030865e-01   1.36992544e-01   2.58477814e-02
    6.89176619e-02   9.78601724e-02   1.10904202e-02   2.63247788e-02
    2.86025286e-01   1.95117325e-01   1.91359092e-02  -1.13612540e-01
   -2.33654846e-02   2.41754949e-03  -1.91271231e-02   2.04666443e-02
   -3.38239633e-02   7.19832107e-02   1.04785487e-01   2.67029703e-02
   -9.34699625e-02   8.11387300e-02   1.16269946e-01   3.18462670e-01
   -1.09030187e-01   5.77940904e-02   4.56322730e-02  -1.18554175e-01
    3.28972377e-02  -2.03222781e-03   9.62367728e-02  -7.53339604e-02
    9.46934074e-02   1.33429691e-01  -9.70502943e-03   6.90265298e-02]]
After layer encoder_birnn_reverse_l0_t4_o_output (1, 256) <class 'numpy.float32'> [[ 0.51512206  0.50887996  0.49620152  0.51472223  0.51246804  0.55025917
   0.52573997  0.53156137  0.58801132  0.52848351  0.48931986  0.51516807
   0.53886062  0.49175543  0.50979686  0.52725053  0.48577312  0.48097223
   0.50696868  0.49493349  0.49141929  0.46835589  0.55990535  0.52584827
   0.51730323  0.51031625  0.49913484  0.4990232   0.47947934  0.50433582
   0.52687067  0.5250718   0.50759768  0.5065369   0.49344555  0.491638
   0.52510124  0.49742112  0.52021557  0.49886626  0.52118409  0.49276114
   0.49998713  0.50037038  0.4928875   0.5061667   0.50504708  0.48486125
   0.50773197  0.5243234   0.52142954  0.49112049  0.49413478  0.51374739
   0.54344392  0.47204682  0.53403199  0.50431383  0.50701231  0.47206542
   0.51204818  0.5145582   0.50724149  0.53806049  0.49757773  0.48480588
   0.54561037  0.51424742  0.50551289  0.52252024  0.50455874  0.5100382
   0.50302887  0.4954949   0.52450776  0.55264711  0.53384537  0.51076102
   0.52732939  0.55033398  0.54007256  0.54760361  0.52178639  0.52948332
   0.53616601  0.51392204  0.5072757   0.52725685  0.51823395  0.5211333
   0.53694504  0.49003333  0.47796783  0.5075593   0.51396763  0.50881392
   0.51711482  0.53006756  0.46633971  0.47682279  0.49398115  0.46657443
   0.48405129  0.4807173   0.49896783  0.50284421  0.49103889  0.53074396
   0.51300949  0.54056221  0.5018996   0.51367474  0.48064563  0.53224629
   0.50334233  0.53612262  0.47931036  0.4943907   0.5203855   0.4850398
   0.50694883  0.52189392  0.52305073  0.50191283  0.48946375  0.50819427
   0.49596322  0.49745113  0.49291235  0.48126817  0.50407261  0.5458439
   0.49671233  0.52322018  0.5098356   0.48383582  0.53014684  0.51492286
   0.52834517  0.50656104  0.50291836  0.5001989   0.47859013  0.51541418
   0.50124502  0.50595492  0.53423256  0.51241893  0.50990796  0.49648163
   0.49413013  0.49250472  0.51483101  0.53249544  0.50418693  0.52085668
   0.52005249  0.53004348  0.51073855  0.5317772   0.51795042  0.50639886
   0.49474835  0.53479499  0.52045768  0.48318899  0.55967075  0.52548653
   0.47256312  0.50596184  0.47728246  0.52399206  0.52005589  0.54625112
   0.50763357  0.53996611  0.53619617  0.48775277  0.52229345  0.49711335
   0.47474357  0.48577237  0.5100438   0.4868944   0.48964924  0.52644479
   0.4948222   0.52398211  0.50318962  0.47988832  0.50673079  0.5342539
   0.51209795  0.50188059  0.51236212  0.51443446  0.49354321  0.51371861
   0.5253343   0.50146747  0.51745468  0.55445617  0.52213246  0.53534889
   0.52148312  0.52266246  0.48340216  0.50949502  0.47969025  0.53890854
   0.49752265  0.57251382  0.51078421  0.53551722  0.52231628  0.48998284
   0.51557171  0.54266     0.49170423  0.48724189  0.48828572  0.47276926
   0.53419465  0.50646162  0.51722258  0.52444553  0.50277263  0.50658083
   0.57102281  0.54862517  0.50478387  0.47162738  0.49415889  0.50060439
   0.49521837  0.50511652  0.49154484  0.51798803  0.5261724   0.5066753
   0.47664949  0.52027357  0.52903479  0.57894957  0.47276944  0.51444447
   0.51140612  0.47039613  0.50822353  0.49949196  0.52404064  0.48117539
   0.52365571  0.53330803  0.49757376  0.51724976]]
After layer encoder_birnn_reverse_l0_t4_f_output (1, 256) <class 'numpy.float32'> [[ 0.53465402  0.50595891  0.52235192  0.51186222  0.50496095  0.51752269
   0.54189283  0.47851205  0.58118719  0.53334695  0.52989352  0.52562004
   0.52476907  0.50185972  0.52763432  0.52912128  0.52114797  0.48841667
   0.46607661  0.51299173  0.5291642   0.50098139  0.57681876  0.51239175
   0.52842283  0.51718128  0.53197742  0.52352226  0.52621216  0.50824857
   0.51442152  0.50336117  0.55390519  0.48633322  0.49632928  0.500027
   0.48560044  0.52376699  0.50528997  0.52295905  0.49422655  0.52491182
   0.50294328  0.52246922  0.50616181  0.52543402  0.507622    0.47624034
   0.50067508  0.50844777  0.5153951   0.51876706  0.50460917  0.53280145
   0.51963067  0.51693058  0.51010078  0.52170855  0.50240827  0.48128709
   0.51437122  0.50907618  0.51041156  0.51014882  0.49592394  0.53206551
   0.54766613  0.51514137  0.47391874  0.49598885  0.51556396  0.496508
   0.49297687  0.5073204   0.52309233  0.54484552  0.51328623  0.50932443
   0.51809883  0.51832658  0.55094433  0.53812015  0.50946844  0.5089643
   0.53702432  0.50150096  0.51722825  0.54417926  0.50777584  0.4715296
   0.56747395  0.52277631  0.51928198  0.51773506  0.48840809  0.50547564
   0.50442183  0.52609617  0.46547842  0.46206382  0.4902927   0.50190216
   0.50666404  0.52323276  0.50083435  0.49407214  0.47633332  0.5172509
   0.51580834  0.48095173  0.50117457  0.49562046  0.50988209  0.54003626
   0.52380043  0.54457402  0.52295727  0.52946675  0.52390075  0.52552682
   0.54391873  0.53802735  0.50845408  0.50420082  0.49953693  0.4976452
   0.5403648   0.49872509  0.52523714  0.47682795  0.52361751  0.5353412
   0.50344205  0.53603238  0.51799703  0.51707786  0.5052287   0.5094676
   0.52898532  0.54247636  0.48145223  0.5165801   0.51564747  0.50723654
   0.50666839  0.53140748  0.51423925  0.509507    0.51029986  0.49571875
   0.49295706  0.51574618  0.50561816  0.51941174  0.5072512   0.54365277
   0.52410978  0.49839512  0.50861472  0.53313953  0.5523237   0.51911283
   0.49210161  0.52016264  0.51421785  0.49930421  0.56064272  0.48984641
   0.49938813  0.49246979  0.5093118   0.52817678  0.49029464  0.54745519
   0.49136448  0.52506953  0.53805739  0.49886081  0.50442159  0.52686578
   0.51959026  0.48226798  0.55332899  0.4898026   0.5023343   0.50010014
   0.50891507  0.54292697  0.50513566  0.48936132  0.49166077  0.50629824
   0.54061961  0.53452075  0.4940846   0.49974275  0.49631178  0.49832797
   0.50671875  0.50390106  0.50722885  0.51601571  0.51869828  0.49081996
   0.52324027  0.46903226  0.49351338  0.53499687  0.48913121  0.52170753
   0.51856017  0.52702981  0.48774186  0.50544292  0.49512649  0.4820517
   0.51371592  0.52232492  0.49706665  0.5263409   0.47712269  0.48940229
   0.55489302  0.50565588  0.51942998  0.49851668  0.50431854  0.50899255
   0.57884991  0.55629915  0.50410378  0.43875456  0.53510565  0.50812668
   0.51355904  0.50002575  0.50281942  0.52093071  0.5074504   0.52339238
   0.51912242  0.50670099  0.51037908  0.55379122  0.46677658  0.49417728
   0.4909367   0.48558342  0.52200496  0.49614164  0.53528261  0.46392733
   0.53593361  0.49503666  0.5321157   0.50079811]]
After layer _mul2080_0 (1, 256) <class 'numpy.float32'> [[ -6.22132905e-02  -5.14907837e-02   2.98881787e-03   1.65098179e-02
    2.31490787e-02  -2.38253791e-02   2.16905624e-02   3.63638178e-02
    1.52987503e-02  -4.10866663e-02  -3.25346924e-02   4.78279889e-02
    4.35743295e-02  -1.98370498e-02   3.19295786e-02  -9.80182737e-02
    1.59606691e-02   3.45646404e-03   2.78178025e-02   2.33990494e-02
    8.44257697e-02  -2.12551840e-02   4.78516892e-03   3.28612924e-02
   -4.30844352e-02   1.41566498e-02   1.34751452e-02  -1.35296052e-02
   -5.74018657e-02  -3.92581373e-02   1.67976227e-02  -5.59046082e-02
   -4.57668491e-03  -2.47509661e-03   4.48654294e-02  -5.57417125e-02
   -2.99883336e-02  -1.01181418e-02  -4.65663858e-02  -3.50573733e-02
    2.03218758e-02  -6.99286461e-02   4.90293242e-02   3.79434228e-02
    4.02075984e-02  -4.95135337e-02   2.03418154e-02  -2.73204111e-02
   -4.07187361e-03  -3.17299478e-02   1.79832429e-02  -4.84360605e-02
   -3.22331414e-02   4.41990234e-02   2.68748067e-02   9.98237170e-03
   -2.38865931e-02   7.84760490e-02   3.20679657e-02  -2.49962416e-02
   -3.36043537e-02  -4.05767299e-02  -1.74353849e-02  -5.14901709e-03
    3.45589593e-02  -1.75405294e-02   2.93661859e-02  -2.81948484e-02
   -4.53677624e-02  -1.32362051e-02  -1.04081579e-01   4.95467801e-03
    2.60275155e-02   8.74209683e-03   5.73478192e-02  -2.58832723e-02
   -2.05231626e-02  -6.86794668e-02  -2.65770033e-02  -1.58348102e-02
   -4.70814556e-02   2.79873121e-03  -3.14694494e-02  -6.46769777e-02
   -1.08749293e-01   1.18823890e-02  -6.04041703e-02   2.11630166e-02
   -6.03175052e-02  -4.57627624e-02  -3.96215692e-02  -2.24509705e-02
   -8.74109846e-03  -1.26791140e-02  -1.78291388e-02   1.37962019e-02
    3.89253832e-02  -2.10613944e-02  -3.67392153e-02  -2.31423639e-02
    1.85654499e-02   5.45202941e-02  -3.34462523e-02   1.94655899e-02
    1.66597348e-02   4.63423133e-02  -1.84486881e-02  -1.98305193e-02
    6.17411919e-02  -6.36189580e-02   3.29678766e-02   1.01595093e-02
    2.35731732e-02   3.67083065e-02  -4.31786291e-02   1.14258565e-01
   -5.71574271e-02  -2.98619401e-02   2.24176254e-02  -1.62041038e-02
    6.72472343e-02   4.45432961e-02  -1.14682149e-02  -3.65157276e-02
    4.53301109e-02  -7.28328750e-02  -3.06968801e-02  -2.92500257e-02
   -1.52119910e-02  -1.89696241e-03   3.58048268e-02  -2.34459303e-02
    3.33395600e-02  -1.09487483e-02   5.91595797e-03   3.06109581e-02
    4.64391634e-02   8.44642147e-02  -4.61641606e-03   3.06347683e-02
   -6.68249931e-03  -2.39064209e-02   5.63138425e-02   4.86522494e-03
   -4.12722304e-02   3.92505489e-02   2.79504731e-02  -5.39267808e-02
   -3.60581912e-02  -3.87233384e-02  -2.74981298e-02  -1.31032448e-02
   -1.99794639e-02  -3.83147635e-02  -4.38257819e-03   3.11752521e-02
   -4.79899459e-02   2.46916749e-02   2.31684092e-02   3.00644338e-02
   -9.98595431e-02  -3.64766419e-02   1.12972269e-02   6.04166538e-02
    1.00126788e-02   3.95300053e-02   5.39254071e-03  -3.32224593e-02
   -7.02153370e-02  -1.60253519e-04  -3.92216407e-02   1.82532165e-02
   -1.27309300e-02  -6.60488978e-02  -6.92092674e-03   2.80845296e-02
    6.97724894e-02  -2.24132128e-02  -3.25792804e-02  -1.90838315e-02
    3.56164128e-02   2.75136624e-03   1.68962181e-02  -1.29762823e-02
   -1.47367781e-02   1.95608418e-02   1.67748127e-02  -5.20652458e-02
    4.49665226e-02  -4.86501716e-02   7.32490346e-02  -1.20285689e-03
    1.75993715e-03   1.83661212e-03  -7.38231018e-02   1.01552380e-03
   -8.16865936e-02  -3.99138890e-02  -7.59491092e-03   2.43416447e-02
   -5.85924461e-02  -1.04535464e-02   7.83915445e-02  -2.57933065e-02
   -9.58935765e-04  -7.14877155e-03   2.21467577e-02   1.81368412e-03
    4.86094505e-02  -4.44545038e-02  -6.15510195e-02   7.44817080e-03
    1.26573313e-02  -5.82865998e-02  -2.50738077e-02  -3.34745198e-02
    8.60391930e-03  -1.59277916e-02  -4.27449169e-03   4.86022979e-02
   -9.49606951e-03  -3.30254361e-02   3.70633379e-02   7.59361545e-04
    2.94991314e-05  -1.84952933e-02   6.41356746e-04   1.51197556e-02
    2.32729856e-02  -7.38863135e-03  -5.74588515e-02   5.25784157e-02
    2.87471339e-02   3.70986536e-02  -3.28247063e-02   2.32284926e-02
   -4.65553962e-02   8.81520938e-03  -6.34619519e-02   5.57542481e-02
    1.08536528e-02  -1.40810497e-02   9.62963980e-03  -3.83562893e-02
   -1.66473668e-02  -3.12627256e-02  -2.22227462e-02  -5.29817231e-02
    6.40867976e-04   9.18252990e-02   8.40579271e-02   3.62247862e-02
    2.71843523e-02  -2.75608189e-02  -1.72798596e-02  -1.24264620e-02]]
After layer encoder_birnn_reverse_l0_t4_i_output (1, 256) <class 'numpy.float32'> [[ 0.49850595  0.4961001   0.49835303  0.49488857  0.51316506  0.49807507
   0.50915062  0.50575489  0.52290881  0.51378495  0.49072981  0.51921457
   0.50491971  0.51013494  0.49967888  0.56390703  0.47734645  0.48461735
   0.50323611  0.49699721  0.52109724  0.50651199  0.47778919  0.49015903
   0.52112579  0.47039688  0.49213532  0.49537927  0.50743157  0.49574488
   0.50060999  0.49548098  0.48939705  0.4885619   0.51726353  0.46923375
   0.49775639  0.49852592  0.48199704  0.48690072  0.47679579  0.50828493
   0.48654178  0.5003565   0.50891107  0.49783716  0.51599509  0.48114362
   0.49634609  0.50512451  0.50014251  0.52411598  0.48211777  0.51691914
   0.54640925  0.52461368  0.48633537  0.50279099  0.48542652  0.49418741
   0.51762545  0.48915002  0.53871596  0.4933036   0.47229207  0.48971099
   0.52403522  0.49558321  0.48522097  0.50433737  0.52388084  0.49419644
   0.50006807  0.49839985  0.49909565  0.51716453  0.53086114  0.5351944
   0.50278795  0.51095247  0.50631809  0.51147896  0.52143317  0.49560323
   0.53991944  0.51451361  0.49321344  0.49022695  0.4932178   0.52342719
   0.52908683  0.49514103  0.47995493  0.52270842  0.51857018  0.51079398
   0.49418181  0.52241743  0.47818837  0.47328684  0.48181531  0.51884258
   0.49955991  0.46680629  0.48386729  0.50174993  0.49464691  0.47234994
   0.51332277  0.51249766  0.4700326   0.50744885  0.50437993  0.54477715
   0.50054049  0.57118183  0.49113423  0.50212324  0.50986272  0.49012172
   0.55106777  0.46999773  0.50107777  0.52291155  0.48698416  0.51340735
   0.47129712  0.51690292  0.49580759  0.50091207  0.54502124  0.51630521
   0.49878678  0.4913494   0.48368025  0.48539782  0.52342004  0.53727734
   0.5001899   0.49570408  0.49058059  0.47638553  0.51853096  0.51640344
   0.4915877   0.49904552  0.50761765  0.51479709  0.49573198  0.51393658
   0.52727115  0.48743591  0.50073814  0.47650352  0.48317868  0.54708815
   0.50814629  0.51589328  0.4960345   0.49186674  0.54720402  0.50253326
   0.48819593  0.50862145  0.50387299  0.48433575  0.502855    0.48910463
   0.51288158  0.49017918  0.5033437   0.50969154  0.50137925  0.52461028
   0.50728446  0.46975255  0.50870717  0.47158644  0.48780671  0.4940342
   0.50903177  0.48414427  0.49557677  0.50801796  0.52356046  0.49385899
   0.49651477  0.48507413  0.52927321  0.51496625  0.49391028  0.49603894
   0.51103485  0.49388251  0.51556718  0.5181542   0.51994628  0.46136293
   0.51095361  0.51473355  0.50027782  0.532763    0.51627272  0.50906289
   0.50741351  0.49587101  0.50032908  0.4874768   0.48614445  0.51167238
   0.51016176  0.52403915  0.50514495  0.51503545  0.50314093  0.50942469
   0.49843463  0.49430868  0.50419253  0.50108886  0.48688957  0.4873189
   0.51767147  0.48200241  0.50324863  0.5157032   0.49473023  0.47772285
   0.48428029  0.53510445  0.497242    0.47804895  0.4950211   0.48979568
   0.50813049  0.51564842  0.49831375  0.51925874  0.50767696  0.48876145
   0.48089918  0.4710229   0.52610695  0.55799133  0.48722559  0.5069744
   0.49011791  0.48377466  0.50439209  0.50383759  0.53375334  0.5013774
   0.4786284   0.51205933  0.51232666  0.49509767]]
After layer encoder_birnn_reverse_l0_t4_c_output (1, 256) <class 'numpy.float32'> [[-0.15286034 -0.13845371 -0.01789315  0.04063873  0.03832133 -0.06098457
   0.03423711  0.0859275   0.06397343 -0.10578276 -0.07910941  0.14098372
   0.08871972 -0.02641864  0.06470852 -0.22885965  0.07111266  0.02779365
   0.08812785  0.05293658  0.20632277 -0.05895831 -0.00563532  0.06025392
  -0.11670788  0.03574484  0.05916401 -0.05332277 -0.142968   -0.11309746
   0.04244217 -0.12331505 -0.01166654  0.01039948  0.11787982 -0.15341444
  -0.06404005 -0.00447376 -0.12494501 -0.10605748  0.02520765 -0.19783321
   0.12811479  0.09234159  0.09113179 -0.11269092  0.04025336 -0.07194404
  -0.01380582 -0.10033538  0.07239687 -0.12521482 -0.08228701  0.14514892
   0.02960029  0.02402228 -0.0300235   0.19076954  0.10482499 -0.04750179
  -0.09674057 -0.10114712 -0.02302939 -0.02052799  0.06856866 -0.03655504
   0.03285468 -0.11173531 -0.10958771 -0.00855668 -0.25940868  0.01522509
   0.05268835  0.02744095  0.13298923 -0.03544134 -0.04529702 -0.19823009
  -0.06875364 -0.04208124 -0.12152337  0.01958807 -0.09148763 -0.17147608
  -0.25654465  0.0103237  -0.12372906  0.02643393 -0.18887973 -0.11976817
  -0.11879051 -0.06160977 -0.03043628 -0.00649037 -0.05141701  0.05176967
   0.09612277 -0.04669252 -0.10793387 -0.0895656   0.01979871  0.1434221
  -0.07028201  0.04994059  0.06295075  0.16489181 -0.04624908 -0.04783086
   0.16165556 -0.19623245  0.10478067 -0.00426092  0.08106811  0.10219844
  -0.0920711   0.2665135  -0.16448258 -0.08533493  0.04130341 -0.07071471
   0.16749994  0.07157591 -0.01839419 -0.09764023  0.10853971 -0.18271165
  -0.11875199 -0.07706425 -0.04932583 -0.02808719  0.08978362 -0.03187942
   0.07918204  0.00852916  0.00172388  0.07419757  0.08524351  0.21861748
  -0.00376508  0.06478002 -0.00352704 -0.04763907  0.14074421  0.02533398
  -0.0915297   0.10131849  0.07279606 -0.11175365 -0.10006737 -0.13377264
  -0.06156678 -0.02773037 -0.06755954 -0.0820505  -0.00855147  0.07618659
  -0.12526862  0.03527875  0.05469253  0.07225873 -0.22273941 -0.06667534
   0.02712196  0.15871564  0.0358986   0.09991879  0.0166724  -0.04766715
  -0.20373921  0.01781872 -0.10286637  0.05364762 -0.03842052 -0.14973186
  -0.02829478  0.07886434  0.15414405 -0.0517685  -0.05861282 -0.02854648
   0.07258169  0.01526753  0.04266154 -0.03809446 -0.0684623   0.0585367
   0.05034836 -0.10885943  0.09458739 -0.13515987  0.20704119 -0.01695637
  -0.00724615  0.02970965 -0.22000822 -0.00500921 -0.22559765 -0.0999449
  -0.0387503   0.07150094 -0.16674633 -0.03982036  0.18131724 -0.05980059
  -0.02075207 -0.03055109  0.07630748  0.01399959  0.13050935 -0.0808239
  -0.17340347 -0.00039122  0.03011714 -0.1874125  -0.06383453 -0.09024013
   0.03376483 -0.04174083 -0.0405702   0.12502153 -0.03593168 -0.08923907
   0.08127429  0.02632324  0.01234439 -0.0592622   0.00857135  0.03453205
   0.02988821 -0.00202304 -0.1484303   0.17664345  0.04212784  0.0920004
  -0.06957527  0.03290707 -0.09775172  0.02132276 -0.19622006  0.12879439
   0.01278579 -0.01122121  0.02827408 -0.0502816  -0.03780439 -0.0628493
  -0.06176554 -0.1817532   0.02109274  0.23106369  0.21185741  0.10991682
   0.04523449 -0.07911149 -0.05463589 -0.00812868]]
After layer _mul2081_0 (1, 256) <class 'numpy.float32'> [[-0.07620179 -0.0686869  -0.00891711  0.02011164  0.01966517 -0.0303749
   0.01743185  0.04345825  0.03345227 -0.05434959 -0.03882134  0.0732008
   0.04479633 -0.01347707  0.03233348 -0.12905556  0.03394537  0.01346929
   0.04434912  0.02630933  0.10751423 -0.02986309 -0.00269249  0.029534
  -0.06081948  0.01681426  0.0291167  -0.026415   -0.07254647 -0.05606749
   0.02124697 -0.06110026 -0.00570957  0.00508079  0.06097493 -0.07198723
  -0.03187634 -0.00223028 -0.06022313 -0.05163946  0.0120189  -0.10055564
   0.0623332   0.04620372  0.04637798 -0.05610172  0.02077054 -0.03461542
  -0.00685246 -0.05068186  0.03620875 -0.06562708 -0.03967203  0.07503025
   0.01617387  0.01260242 -0.01460149  0.0959172   0.05088483 -0.02347479
  -0.05007538 -0.04947612 -0.0124063  -0.01012653  0.03238444 -0.0179014
   0.01721701 -0.05537415 -0.05317426 -0.00431545 -0.13589925  0.00752419
   0.02634776  0.01367656  0.06637435 -0.018329   -0.02404643 -0.10609163
  -0.0345685  -0.02150151 -0.06152948  0.01001888 -0.04770469 -0.0849841
  -0.13851345  0.00531168 -0.06102483  0.01295862 -0.09315884 -0.06268992
  -0.0628505  -0.03050552 -0.01460804 -0.00339257 -0.02666333  0.02644363
   0.04750213 -0.02439299 -0.05161272 -0.04239022  0.00953932  0.07441349
  -0.03511008  0.02331258  0.03045981  0.08273445 -0.02287696 -0.0225929
   0.08298148 -0.10056867  0.04925033 -0.0021622   0.04088913  0.05567537
  -0.04608531  0.15222767 -0.08078302 -0.04284865  0.02105907 -0.03465882
   0.09230382  0.03364052 -0.00921692 -0.0510572   0.05285712 -0.0938055
  -0.05596747 -0.03983474 -0.02445612 -0.01406921  0.04893398 -0.01645951
   0.03949496  0.0041908   0.00083381  0.03601534  0.04461816  0.11745822
  -0.00188325  0.03211172 -0.0017303  -0.02269457  0.07298023  0.01308255
  -0.04499487  0.05056254  0.03695257 -0.05753046 -0.0496066  -0.06875066
  -0.03246239 -0.01351678 -0.03382964 -0.03909735 -0.00413189  0.04168078
  -0.06365479  0.01820007  0.02712938  0.03554166 -0.1218839  -0.03350657
   0.01324083  0.08072618  0.01808834  0.04839424  0.0083838  -0.02331422
  -0.10449409  0.00873437 -0.05177714  0.02734374 -0.01926325 -0.07855088
  -0.0143535   0.03704673  0.07841418 -0.02441332 -0.02859172 -0.01410294
   0.03694639  0.00739169  0.02114207 -0.01935267 -0.03584415  0.02890888
   0.0249987  -0.05280489  0.05006257 -0.06960277  0.10225977 -0.00841102
  -0.00370303  0.01467308 -0.11342902 -0.00259554 -0.11729866 -0.04611087
  -0.01979961  0.03680393 -0.08341949 -0.02121481  0.09360915 -0.03044226
  -0.01052988 -0.0151494   0.03817885  0.00682447  0.0634464  -0.04135536
  -0.08846382 -0.00020502  0.01521352 -0.09652408 -0.03211777 -0.04597055
   0.01682956 -0.02063286 -0.02045519  0.0626469  -0.01749476 -0.04348788
   0.04207338  0.01268786  0.0062123  -0.03056171  0.0042405   0.01649675
   0.01447427 -0.00108254 -0.07380578  0.08444422  0.02085417  0.0450614
  -0.03535331  0.01696848 -0.04871103  0.01107203 -0.0996164   0.06294973
   0.00614868 -0.00528545  0.01487519 -0.0280567  -0.01841927 -0.03186299
  -0.0302724  -0.08792759  0.01063901  0.11641857  0.1130796   0.05510981
   0.02165051 -0.04050978 -0.02799143 -0.00402449]]
After layer encoder_birnn_reverse_l0_t4_state_0 (1, 256) <class 'numpy.float32'> [[-0.13841508 -0.12017768 -0.00592829  0.03662146  0.04281425 -0.05420028
   0.03912241  0.07982207  0.04875102 -0.09543626 -0.07135604  0.12102879
   0.08837067 -0.03331412  0.06426306 -0.22707383  0.04990605  0.01692575
   0.07216692  0.04970838  0.19194001 -0.05111827  0.00209268  0.0623953
  -0.10390392  0.03097091  0.04259184 -0.0399446  -0.12994835 -0.09532562
   0.03804459 -0.11700487 -0.01028625  0.00260569  0.10584036 -0.12772894
  -0.06186468 -0.01234843 -0.10678951 -0.08669683  0.03234078 -0.17048427
   0.11136252  0.08414714  0.08658558 -0.10561526  0.04111236 -0.06193583
  -0.01092434 -0.08241181  0.054192   -0.11406314 -0.07190517  0.11922927
   0.04304868  0.02258479 -0.03848808  0.17439325  0.0829528  -0.04847103
  -0.08367974 -0.09005284 -0.02984168 -0.01527555  0.06694339 -0.03544194
   0.04658319 -0.08356899 -0.09854202 -0.01755166 -0.23998082  0.01247886
   0.05237527  0.02241866  0.12372217 -0.04421227 -0.04456959 -0.1747711
  -0.0611455  -0.03733632 -0.10861094  0.01281762 -0.07917413 -0.14966108
  -0.24726275  0.01719407 -0.121429    0.03412164 -0.15347634 -0.10845268
  -0.10247207 -0.0529565  -0.02334914 -0.01607168 -0.04449247  0.04023984
   0.08642751 -0.04545438 -0.08835194 -0.06553259  0.02810477  0.12893379
  -0.06855632  0.04277817  0.04711954  0.12907676 -0.04132565 -0.04242342
   0.14472267 -0.16418764  0.08221821  0.00799731  0.0644623   0.09238368
  -0.08926395  0.26648623 -0.13794045 -0.07271059  0.04347669 -0.05086292
   0.15955105  0.07818381 -0.02068513 -0.08757293  0.09818723 -0.16663837
  -0.08666435 -0.06908476 -0.03966811 -0.01596618  0.08473881 -0.03990544
   0.07283452 -0.00675795  0.00674977  0.0666263   0.09105732  0.20192243
  -0.00649967  0.06274649 -0.0084128  -0.04660099  0.12929407  0.01794778
  -0.0862671   0.08981308  0.06490304 -0.11145724 -0.08566479 -0.107474
  -0.05996052 -0.02662002 -0.05380911 -0.07741211 -0.00851447  0.07285603
  -0.11164473  0.04289174  0.05029779  0.0656061  -0.22174343 -0.06998321
   0.02453806  0.14114283  0.02810101  0.08792424  0.01377634 -0.05653668
  -0.17470942  0.00857411 -0.09099878  0.04559695 -0.03199418 -0.14459977
  -0.02127443  0.06513125  0.14818667 -0.04682653 -0.061171   -0.03318677
   0.0725628   0.01014305  0.03803828 -0.03232896 -0.05058093  0.04846972
   0.04177352 -0.10487014  0.09502909 -0.11825293  0.1755088  -0.00961388
  -0.0019431   0.01650969 -0.18725212 -0.00158002 -0.19898525 -0.08602476
  -0.02739452  0.06114558 -0.14201194 -0.03166836  0.17200069 -0.05623557
  -0.01148881 -0.02229817  0.06032561  0.00863816  0.11205585 -0.08580986
  -0.15001485  0.00724316  0.02787086 -0.15481068 -0.05719157 -0.07944506
   0.02543348 -0.03656065 -0.02472968  0.11124919 -0.02699083 -0.07651332
   0.07913671  0.01344723  0.00624179 -0.049057    0.00488186  0.0316165
   0.03774726 -0.00847117 -0.13126463  0.13702263  0.0496013   0.08216006
  -0.06817802  0.04019697 -0.09526642  0.01988724 -0.16307835  0.11870398
   0.01700233 -0.0193665   0.02450483 -0.06641299 -0.03506663 -0.06312571
  -0.05249514 -0.14090931  0.01127988  0.20824388  0.19713753  0.0913346
   0.04883487 -0.0680706  -0.04527128 -0.01645095]]
After layer activation1040_output (1, 256) <class 'numpy.float32'> [[-0.13753785 -0.11960244 -0.00592822  0.0366051   0.04278811 -0.05414727
   0.03910246  0.07965297  0.04871244 -0.09514757 -0.07123517  0.1204413
   0.08814134 -0.0333018   0.06417474 -0.22324985  0.04986465  0.01692413
   0.0720419   0.04966748  0.18961716 -0.05107379  0.00209267  0.06231445
  -0.10353161  0.03096101  0.04256611 -0.03992337 -0.1292218  -0.09503793
   0.03802625 -0.11647385 -0.01028589  0.00260569  0.1054469  -0.12703882
  -0.06178588 -0.0123478  -0.10638542 -0.08648027  0.03232951 -0.16885155
   0.11090443  0.0839491   0.08636985 -0.1052243   0.04108921 -0.06185675
  -0.0109239  -0.08222575  0.05413901 -0.11357104 -0.0717815   0.1186675
   0.04302211  0.02258095 -0.03846909  0.17264657  0.08276305 -0.04843311
  -0.08348496 -0.08981021 -0.02983283 -0.01527436  0.06684357 -0.0354271
   0.04654953 -0.08337499 -0.09822429 -0.01754986 -0.23547763  0.01247822
   0.05232743  0.02241491  0.12309473 -0.04418349 -0.0445401  -0.17301312
  -0.06106941 -0.03731898 -0.10818587  0.01281691 -0.07900911 -0.14855361
  -0.24234389  0.01719238 -0.12083568  0.0341084  -0.15228255 -0.10802946
  -0.1021149  -0.05290705 -0.0233449  -0.0160703  -0.04446313  0.04021813
   0.08621296 -0.04542311 -0.08812276 -0.06543894  0.02809737  0.12822405
  -0.06844912  0.0427521   0.0470847   0.12836467 -0.04130214 -0.04239799
   0.14372069 -0.16272801  0.08203346  0.00799714  0.06437317  0.09212176
  -0.08902761  0.26035225 -0.13707218 -0.07258272  0.04344932 -0.0508191
   0.15821083  0.0780249  -0.02068218 -0.08734975  0.09787291 -0.1651129
  -0.08644803 -0.06897507 -0.03964732 -0.01596482  0.08453656 -0.03988428
   0.07270601 -0.00675785  0.00674966  0.06652789  0.09080649  0.19922216
  -0.00649958  0.06266427 -0.0084126  -0.04656728  0.12857839  0.01794585
  -0.08605374  0.08957237  0.06481206 -0.11099799 -0.08545585 -0.10706211
  -0.05988877 -0.02661374 -0.05375724 -0.07725785 -0.00851426  0.0727274
  -0.11118317  0.04286546  0.05025542  0.06551214 -0.21817914 -0.06986919
   0.02453314  0.140213    0.02809362  0.08769837  0.01377547 -0.05647652
  -0.17295329  0.0085739  -0.09074844  0.04556538 -0.03198327 -0.14360031
  -0.02127122  0.06503931  0.14711143 -0.04679234 -0.06109482 -0.03317459
   0.07243571  0.0101427   0.03801995 -0.0323177  -0.05053784  0.0484318
   0.04174924 -0.10448738  0.09474407 -0.11770479  0.17372864 -0.00961358
  -0.00194309  0.01650819 -0.18509383 -0.00158002 -0.19639991 -0.08581319
  -0.02738767  0.06106949 -0.14106491 -0.03165777  0.17032436 -0.05617636
  -0.01148831 -0.02229447  0.06025254  0.00863794  0.11158919 -0.08559986
  -0.14889956  0.00724303  0.02786364 -0.15358569 -0.0571293  -0.07927835
   0.025428   -0.03654437 -0.02472464  0.1107925  -0.02698427 -0.07636436
   0.07897193  0.01344642  0.00624171 -0.04901768  0.00488182  0.03160597
   0.03772934 -0.00847097 -0.13051587  0.13617149  0.04956066  0.08197569
  -0.06807258  0.04017533 -0.09497926  0.01988462 -0.1616479   0.11814956
   0.01700069 -0.01936408  0.02449993 -0.06631552 -0.03505227 -0.063042
  -0.05244698 -0.13998406  0.0112794   0.205285    0.19462283  0.09108147
   0.04879608 -0.06796566 -0.04524038 -0.01644947]]
After layer encoder_birnn_reverse_l0_t4_out_0 (1, 256) <class 'numpy.float32'> [[-0.07084878 -0.06086329 -0.00294159  0.01884146  0.02192754 -0.02979503
   0.02055773  0.04234044  0.02864346 -0.05028392 -0.03485679  0.06204751
   0.0474959  -0.01637634  0.03271608 -0.1177086   0.02422291  0.00814004
   0.03652298  0.0245821   0.09318153 -0.02392071  0.0011717   0.03276795
  -0.05355724  0.01579991  0.02124623 -0.01992269 -0.06195918 -0.04793103
   0.02003492 -0.06115713 -0.00522109  0.00131988  0.05203231 -0.06245711
  -0.03244384 -0.00614206 -0.05534335 -0.04314209  0.01684963 -0.08320349
   0.05545079  0.04200564  0.04257062 -0.05326104  0.02075198 -0.02999194
  -0.00554641 -0.04311289  0.02822968 -0.05577707 -0.03546974  0.06096512
   0.0233801   0.01065927 -0.02054372  0.08706805  0.04196189 -0.0228636
  -0.04274832 -0.04621258 -0.01513245 -0.00821853  0.03325987 -0.01717527
   0.02539791 -0.04287538 -0.04965365 -0.00917016 -0.11881229  0.00636437
   0.02632221  0.01110647  0.06456414 -0.02441788 -0.02377753 -0.08836836
  -0.0322037  -0.0205379  -0.05842822  0.00701859 -0.04122588 -0.07865666
  -0.12993656  0.00883554 -0.06129701  0.01798389 -0.07891799 -0.05629775
  -0.05483009 -0.02592622 -0.01115811 -0.00815663 -0.02285261  0.02046355
   0.044582   -0.02407731 -0.04109515 -0.03120278  0.01387957  0.05982606
  -0.03313289  0.02055167  0.02349375  0.06454743 -0.02028096 -0.02250248
   0.07373007 -0.08796462  0.04117256  0.00410793  0.03094068  0.04903146
  -0.04481137  0.13958073 -0.06570011 -0.03588422  0.0226104  -0.02464929
   0.08020479  0.04072072 -0.01081783 -0.04384196  0.04790524 -0.08390943
  -0.04287504 -0.03431173 -0.01954265 -0.00768336  0.04261256 -0.02177059
   0.03611397 -0.00353584  0.00344122  0.03218858  0.04814078  0.10258404
  -0.00343402  0.03174328 -0.00423085 -0.0232929   0.06153635  0.00924955
  -0.04313401  0.04531958  0.03462471 -0.05687747 -0.04357462 -0.05315437
  -0.02959284 -0.01310739 -0.02767589 -0.04113945 -0.00429278  0.03788055
  -0.05782108  0.02272056  0.02566738  0.03483786 -0.11300597 -0.03538168
   0.01213773  0.07498521  0.01462154  0.04237489  0.00770973 -0.02967765
  -0.08173135  0.00433807 -0.04331264  0.0238759  -0.01663309 -0.07844184
  -0.01079798  0.03511903  0.07888059 -0.02282309 -0.03190942 -0.01649153
   0.03438839  0.00492705  0.01939184 -0.01573531 -0.02474581  0.02549667
   0.02065845 -0.05474952  0.04767423 -0.05648516  0.08803365 -0.00513609
  -0.00099505  0.00828514 -0.09483507 -0.00081281 -0.09693184 -0.04408383
  -0.01438768  0.03062436 -0.0729947  -0.01755285  0.08893187 -0.03007395
  -0.00599096 -0.01165248  0.02912621  0.00440099  0.05352825 -0.0461305
  -0.0740809   0.00414673  0.01423231 -0.08224778 -0.02983956 -0.03884503
   0.01310996 -0.01983117 -0.01215721  0.05398275 -0.01317604 -0.03610272
   0.04218638  0.00681009  0.00322835 -0.02570711  0.00245445  0.01601098
   0.02154431 -0.00464739 -0.06588231  0.0642222   0.02449084  0.04103739
  -0.03371079  0.02029322 -0.04668657  0.01029999 -0.08505467  0.05986347
   0.00810337 -0.01007462  0.01296131 -0.03839334 -0.01657164 -0.03243161
  -0.0268217  -0.06584796  0.00573246  0.10253821  0.10199028  0.04382616
   0.02555235 -0.03624663 -0.02251043 -0.00850848]]
After layer expand_dims1046_0 (1, 1, 256) <class 'numpy.float32'> [[[-0.07084878 -0.06086329 -0.00294159  0.01884146  0.02192754 -0.02979503
    0.02055773  0.04234044  0.02864346 -0.05028392 -0.03485679  0.06204751
    0.0474959  -0.01637634  0.03271608 -0.1177086   0.02422291  0.00814004
    0.03652298  0.0245821   0.09318153 -0.02392071  0.0011717   0.03276795
   -0.05355724  0.01579991  0.02124623 -0.01992269 -0.06195918 -0.04793103
    0.02003492 -0.06115713 -0.00522109  0.00131988  0.05203231 -0.06245711
   -0.03244384 -0.00614206 -0.05534335 -0.04314209  0.01684963 -0.08320349
    0.05545079  0.04200564  0.04257062 -0.05326104  0.02075198 -0.02999194
   -0.00554641 -0.04311289  0.02822968 -0.05577707 -0.03546974  0.06096512
    0.0233801   0.01065927 -0.02054372  0.08706805  0.04196189 -0.0228636
   -0.04274832 -0.04621258 -0.01513245 -0.00821853  0.03325987 -0.01717527
    0.02539791 -0.04287538 -0.04965365 -0.00917016 -0.11881229  0.00636437
    0.02632221  0.01110647  0.06456414 -0.02441788 -0.02377753 -0.08836836
   -0.0322037  -0.0205379  -0.05842822  0.00701859 -0.04122588 -0.07865666
   -0.12993656  0.00883554 -0.06129701  0.01798389 -0.07891799 -0.05629775
   -0.05483009 -0.02592622 -0.01115811 -0.00815663 -0.02285261  0.02046355
    0.044582   -0.02407731 -0.04109515 -0.03120278  0.01387957  0.05982606
   -0.03313289  0.02055167  0.02349375  0.06454743 -0.02028096 -0.02250248
    0.07373007 -0.08796462  0.04117256  0.00410793  0.03094068  0.04903146
   -0.04481137  0.13958073 -0.06570011 -0.03588422  0.0226104  -0.02464929
    0.08020479  0.04072072 -0.01081783 -0.04384196  0.04790524 -0.08390943
   -0.04287504 -0.03431173 -0.01954265 -0.00768336  0.04261256 -0.02177059
    0.03611397 -0.00353584  0.00344122  0.03218858  0.04814078  0.10258404
   -0.00343402  0.03174328 -0.00423085 -0.0232929   0.06153635  0.00924955
   -0.04313401  0.04531958  0.03462471 -0.05687747 -0.04357462 -0.05315437
   -0.02959284 -0.01310739 -0.02767589 -0.04113945 -0.00429278  0.03788055
   -0.05782108  0.02272056  0.02566738  0.03483786 -0.11300597 -0.03538168
    0.01213773  0.07498521  0.01462154  0.04237489  0.00770973 -0.02967765
   -0.08173135  0.00433807 -0.04331264  0.0238759  -0.01663309 -0.07844184
   -0.01079798  0.03511903  0.07888059 -0.02282309 -0.03190942 -0.01649153
    0.03438839  0.00492705  0.01939184 -0.01573531 -0.02474581  0.02549667
    0.02065845 -0.05474952  0.04767423 -0.05648516  0.08803365 -0.00513609
   -0.00099505  0.00828514 -0.09483507 -0.00081281 -0.09693184 -0.04408383
   -0.01438768  0.03062436 -0.0729947  -0.01755285  0.08893187 -0.03007395
   -0.00599096 -0.01165248  0.02912621  0.00440099  0.05352825 -0.0461305
   -0.0740809   0.00414673  0.01423231 -0.08224778 -0.02983956 -0.03884503
    0.01310996 -0.01983117 -0.01215721  0.05398275 -0.01317604 -0.03610272
    0.04218638  0.00681009  0.00322835 -0.02570711  0.00245445  0.01601098
    0.02154431 -0.00464739 -0.06588231  0.0642222   0.02449084  0.04103739
   -0.03371079  0.02029322 -0.04668657  0.01029999 -0.08505467  0.05986347
    0.00810337 -0.01007462  0.01296131 -0.03839334 -0.01657164 -0.03243161
   -0.0268217  -0.06584796  0.00573246  0.10253821  0.10199028  0.04382616
    0.02555235 -0.03624663 -0.02251043 -0.00850848]]]
After layer encoder_birnn_reverse_l0_t5_i2h_output (1, 1024) <class 'numpy.float32'> [[-0.0128371  -0.04095686  0.03787835 ...,  0.06970935 -0.04625846
   0.03761056]]
After layer encoder_birnn_reverse_l0_t5_h2h_output (1, 1024) <class 'numpy.float32'> [[ 0.00198321  0.0203812  -0.05965566 ...,  0.06721139  0.03806279
   0.02574649]]
After layer _plus1041_0 (1, 1024) <class 'numpy.float32'> [[-0.01085389 -0.02057566 -0.02177731 ...,  0.13692074 -0.00819566
   0.06335704]]
After layer encoder_birnn_reverse_l0_t5_slice_output0 (1, 256) <class 'numpy.float32'> [[ -1.08538885e-02  -2.05756575e-02  -2.17773058e-02  -2.24563256e-02
    3.36050540e-02  -1.85771063e-02   2.25411430e-02   1.73616670e-02
    9.67458934e-02   6.11437820e-02  -3.97486351e-02   9.01299268e-02
    1.51232313e-02   3.07989083e-02  -1.48860365e-03   2.76901007e-01
   -1.09858036e-01  -7.26772323e-02   1.22749433e-02  -1.15188072e-02
    9.14126188e-02   1.46233402e-02  -1.06498271e-01  -4.36870530e-02
    7.65352547e-02  -1.24852486e-01  -3.38316038e-02  -1.62396505e-02
    1.78436339e-02  -2.02592276e-02  -1.78391114e-04  -1.41477436e-02
   -4.93631773e-02  -4.51497622e-02   7.37055987e-02  -1.39852852e-01
   -1.33500118e-02  -9.35271941e-03  -7.93093741e-02  -6.41167983e-02
   -1.18636593e-01   2.75867730e-02  -5.27946800e-02   1.26516446e-03
    3.31536755e-02  -1.35977045e-02   6.57005310e-02  -7.98391327e-02
   -2.81064734e-02   2.51322612e-02   1.22051761e-02   1.02318630e-01
   -1.10268757e-01   7.26201981e-02   1.79264739e-01   1.07682735e-01
   -6.41081184e-02   1.39150023e-02  -7.12226182e-02  -2.12437585e-02
    7.73410350e-02  -5.00624180e-02   1.57447800e-01  -2.79274452e-02
   -1.13755941e-01  -4.15407494e-02   1.02188990e-01  -2.15118006e-02
   -7.59408027e-02   8.83150101e-03   1.00310236e-01  -2.21112892e-02
   -7.12222978e-03  -1.58585720e-02   5.88547811e-03   6.24135807e-02
    1.22166216e-01   1.54694170e-01   2.36908197e-02   4.86496091e-02
    2.42121704e-02   4.66633588e-02   8.64693522e-02  -2.07035858e-02
    1.64549887e-01   5.04593104e-02  -2.71436870e-02  -5.80599159e-02
   -2.25698911e-02   7.43483678e-02   1.13804743e-01  -1.23400912e-02
   -8.29241350e-02   8.41098875e-02   7.22177029e-02   3.87558043e-02
   -2.72854455e-02   6.65589273e-02  -9.98293459e-02  -1.18436664e-01
   -9.38818976e-02   7.75050670e-02   7.74734467e-03  -1.26177877e-01
   -8.97117704e-02   8.80423188e-03  -2.59432923e-02  -1.10390514e-01
    6.03751466e-02   3.21717858e-02  -1.15039222e-01   1.50493234e-02
    2.48810798e-02   2.03659698e-01   7.78839737e-03   2.98901021e-01
   -3.55500169e-02   7.92437606e-03   1.69696659e-02  -4.59861830e-02
    2.09274054e-01  -1.25312284e-01   2.62012705e-03   9.51156840e-02
   -6.10122010e-02   5.88571355e-02  -1.27383888e-01   7.29476959e-02
   -2.28456538e-02   5.52655011e-03   2.00285077e-01   6.04818389e-02
   -7.80417770e-03  -4.25353013e-02  -7.46488050e-02  -8.05474892e-02
    1.02992803e-01   1.57122940e-01  -8.77311267e-03  -1.56888235e-02
   -4.02296558e-02  -1.11064494e-01   8.43631700e-02   6.19185790e-02
   -3.03166918e-02  -3.39227915e-03   3.30969542e-02   6.06509335e-02
   -1.50260534e-02   5.97499609e-02   1.17104739e-01  -5.89710027e-02
    8.82364810e-04  -9.45890248e-02  -8.41411725e-02   1.91868395e-01
    3.00695151e-02   4.33608443e-02  -1.97114050e-02  -3.26603130e-02
    2.08427683e-01   7.40448758e-03  -5.81235625e-02   2.75880210e-02
    1.04417074e-02  -7.06026554e-02   4.49864008e-03  -4.89703864e-02
    4.24111895e-02  -4.54174206e-02   2.84883939e-03   4.16345224e-02
    3.01325321e-03   1.02233842e-01   2.39478182e-02  -1.42824829e-01
    3.55934463e-02  -1.22417748e-01  -5.47736473e-02  -2.38063298e-02
    4.36435454e-02  -6.92751631e-02  -1.06184483e-02   2.73538753e-02
    9.64077413e-02  -2.10535675e-02  -1.59821808e-02  -5.94126843e-02
    1.07295029e-01   4.86507118e-02  -3.46098021e-02  -2.97258720e-02
    4.12632897e-02  -3.99608761e-02   1.92866027e-02   8.20723772e-02
    9.08423737e-02  -1.65457457e-01   4.28145900e-02   7.24606514e-02
    5.41403145e-03   1.15761794e-01   7.02507421e-02   5.01036458e-02
    2.15992313e-02  -2.59438250e-02  -3.40022892e-03  -5.28827794e-02
   -6.58963323e-02   4.50405031e-02   4.48001847e-02   1.07147932e-01
    2.05021538e-02   5.56561612e-02   3.52922454e-03   1.91837028e-02
   -6.95616007e-03  -2.23037489e-02   2.43288018e-02   3.81176360e-04
   -5.82890287e-02  -7.56935775e-02   8.48162472e-02  -7.42715374e-02
    9.11237951e-03   6.22509718e-02  -2.60396358e-02  -9.68748182e-02
   -8.62725377e-02   1.19878516e-01  -1.09380744e-02  -1.13225415e-01
   -2.09333561e-02  -4.86204103e-02   3.02066300e-02   6.10369146e-02
   -6.09361101e-03   8.04871768e-02   3.02639455e-02  -4.17679623e-02
   -9.64763686e-02  -1.32073939e-01   9.70631912e-02   2.36007303e-01
   -5.76284677e-02   2.22502537e-02  -7.10863099e-02  -7.17498884e-02
    1.61102526e-02   2.53059901e-03   1.48762435e-01  -3.81408259e-03
   -1.00577630e-01   4.91047911e-02   5.30558601e-02  -1.31860152e-02]]
After layer encoder_birnn_reverse_l0_t5_slice_output1 (1, 256) <class 'numpy.float32'> [[ 0.14727315  0.02977024  0.0985705   0.0469032   0.01370816  0.07633643
   0.17938735 -0.09513508  0.35542676  0.15119141  0.11973628  0.1205122
   0.11091518  0.00046156  0.11758415  0.12692578  0.08658721 -0.04175865
  -0.14473668  0.06441887  0.12804458  0.01263975  0.35874501  0.05477331
   0.11904228  0.07148779  0.14293616  0.08748193  0.11436931  0.03786014
   0.07257742  0.02541271  0.22748956 -0.05742519 -0.0133297  -0.01189626
  -0.05705729  0.11574944  0.02262953  0.09126159 -0.0538108   0.10505641
   0.01433247  0.09189925  0.03266959  0.11099805  0.03293046 -0.11202728
  -0.00392145  0.02717052  0.06683523  0.08814958 -0.01092741  0.1403909
   0.06500658  0.05970635  0.0463659   0.09481215  0.00274774 -0.08980884
   0.07690355  0.03792433  0.05887635  0.03418721 -0.02080185  0.13898256
   0.20262952  0.06605782 -0.12699537 -0.03294874  0.06565586 -0.00541739
  -0.04128011  0.03444839  0.10030559  0.1723659   0.05984911  0.0519162
   0.08693442  0.08099511  0.21466023  0.17094007  0.03777429  0.03494647
   0.16549867 -0.00152117  0.08026108  0.173961    0.03505208 -0.14117445
   0.30085176  0.08799684  0.07886223  0.07129283 -0.05719694  0.016947
   0.00644115  0.07965104 -0.16042358 -0.16799465 -0.06070473  0.00089497
   0.0365058   0.10093917 -0.00760916 -0.02885393 -0.10246208  0.0669623
   0.08002365 -0.1014182   0.02262423 -0.02321902  0.05224196  0.18724903
   0.09550981  0.18940341  0.10384982  0.12693085  0.07091166  0.10856904
   0.18951635  0.16289786  0.04034774  0.01777356 -0.01665244 -0.0087564
   0.17218962 -0.00597999  0.10344534 -0.10257804  0.1142454   0.13012275
   0.01340656  0.16026005  0.06319971  0.05809744  0.0222038   0.05009359
   0.12518062  0.19494182 -0.07530303  0.05463468  0.0687077   0.02913295
   0.03690682  0.12997025  0.07666627  0.0411263   0.04795144 -0.02274142
  -0.02798194  0.07011139  0.03360562  0.08822653  0.00699111  0.18119064
   0.09635836 -0.02792348  0.04974125  0.14455616  0.21936995  0.08290213
  -0.03293658  0.08717382  0.07551303 -0.01111646  0.26399311 -0.03471648
  -0.00546332 -0.02657619  0.03051317  0.12388328 -0.02945589  0.2024115
  -0.05016177  0.11381852  0.16337809 -0.01533129  0.01454623  0.11161283
   0.0804155  -0.0721616   0.22935101 -0.03889601  0.00153939  0.0156826
   0.03553833  0.18915425 -0.01544575 -0.05868635 -0.03425109  0.03369293
   0.17296275  0.14833781 -0.07577274  0.00232543 -0.00962554 -0.01393068
   0.02954023  0.01846761  0.04257877  0.05377401  0.0743546  -0.03160021
   0.10539076 -0.13403541 -0.03915614  0.1525338  -0.06242963  0.09765537
   0.07816452  0.10533524 -0.05059951  0.02620263 -0.01629546 -0.08600658
   0.05876457  0.09450263 -0.01944078  0.1141308  -0.09538404 -0.06446476
   0.23959021  0.01633205  0.08745203 -0.00365539  0.01954681  0.04624749
   0.35508323  0.21349078  0.02695424 -0.27005208  0.14876771  0.03436425
   0.06248391 -0.00267059  0.00668136  0.08557581  0.04243666  0.09419213
   0.07297373  0.0413769   0.02093739  0.21692705 -0.14641    -0.01969064
  -0.06046501 -0.05439703  0.10010345 -0.02297447  0.16021974 -0.16726387
   0.15094578 -0.01364294  0.13291796  0.00182875]]
After layer encoder_birnn_reverse_l0_t5_slice_output2 (1, 256) <class 'numpy.float32'> [[ -1.60377339e-01  -1.45165071e-01  -2.80772150e-02   4.94960397e-02
    2.99445242e-02  -6.24858141e-02   2.28722524e-02   7.76810274e-02
    7.53097683e-02  -1.30025044e-01  -8.51109922e-02   1.67989522e-01
    9.58111435e-02  -2.05891598e-02   7.30925351e-02  -2.54925698e-01
    8.31180438e-02   3.06844618e-02   9.92639139e-02   5.69367744e-02
    2.35242799e-01  -7.08100796e-02  -1.60111729e-02   4.95476499e-02
   -1.25618175e-01   3.49518843e-02   5.67025207e-02  -5.78214563e-02
   -1.53080285e-01  -1.25309512e-01   4.69675213e-02  -1.21255085e-01
   -2.79781222e-03   7.01875798e-03   1.27968892e-01  -1.63134024e-01
   -6.12873361e-02   1.45379687e-03  -1.27173677e-01  -1.13916695e-01
    2.16701701e-02  -2.14169532e-01   1.34737939e-01   1.02021307e-01
    9.68773812e-02  -1.22446090e-01   5.03317863e-02  -7.13941380e-02
   -1.69676095e-02  -1.10304944e-01   7.51683116e-02  -1.40305609e-01
   -8.17587525e-02   1.78042516e-01   1.43757463e-02   1.79879218e-02
   -2.16047242e-02   2.13794827e-01   1.23563416e-01  -4.91482653e-02
   -1.16597705e-01  -1.02513373e-01  -1.87943317e-02  -2.90397406e-02
    7.90257156e-02  -4.10039350e-02   3.17249037e-02  -1.19807690e-01
   -1.08199552e-01   1.90728158e-03  -2.90219486e-01   2.70634964e-02
    4.21832725e-02   2.48824470e-02   1.44091964e-01  -2.64276844e-02
   -6.09926283e-02  -2.28812814e-01  -8.17472115e-02  -4.88659404e-02
   -1.38701662e-01   1.26709715e-02  -1.03000090e-01  -1.90567523e-01
   -2.91170448e-01   7.22854957e-03  -1.07776992e-01   1.64694898e-02
   -2.13113129e-01  -1.15960844e-01  -1.28582209e-01  -6.10860810e-02
   -3.18406299e-02   1.13019440e-03  -5.55707216e-02   6.01391755e-02
    9.68644395e-02  -4.93486188e-02  -1.06979549e-01  -1.06820568e-01
    1.43506415e-02   1.54233664e-01  -7.46263936e-02   5.69731444e-02
    6.84899390e-02   1.91970423e-01  -4.69581522e-02  -4.26624455e-02
    1.76562160e-01  -2.13993013e-01   1.25957131e-01  -1.36710424e-02
    9.89706963e-02   1.22418284e-01  -9.25701112e-02   2.98833728e-01
   -1.86458871e-01  -1.01303041e-01   3.55574414e-02  -7.57241175e-02
    1.87822491e-01   6.63087666e-02  -1.03198588e-02  -1.10536896e-01
    1.05458930e-01  -1.95046335e-01  -1.30081400e-01  -8.79371315e-02
   -5.18240072e-02  -2.56318785e-02   1.12402208e-01  -2.33235061e-02
    8.11891556e-02   1.13715529e-02   5.48925251e-04   7.76771680e-02
    8.19830298e-02   2.44275272e-01   7.81696290e-05   7.32709169e-02
   -1.63306668e-03  -4.72081006e-02   1.57000452e-01   2.68277787e-02
   -9.22292545e-02   1.13760181e-01   8.70650262e-02  -1.12192601e-01
   -1.04820073e-01  -1.47854775e-01  -7.06528723e-02  -2.84092408e-02
   -8.48673731e-02  -7.81472847e-02  -3.88099998e-03   8.77050608e-02
   -1.38621360e-01   1.89744905e-02   5.64731658e-02   8.24793726e-02
   -2.59795904e-01  -6.25967085e-02   2.47278623e-02   1.63397044e-01
    3.99042219e-02   1.04079545e-01   1.40898898e-02  -4.04706001e-02
   -2.38321960e-01   1.54018402e-02  -1.16188169e-01   7.06401244e-02
   -3.79078202e-02  -1.61252633e-01  -3.54785174e-02   8.24382603e-02
    1.71936989e-01  -5.81031069e-02  -5.71031608e-02  -2.08076984e-02
    7.63652548e-02   2.19821110e-02   5.18662259e-02  -4.13175896e-02
   -7.78624564e-02   4.74447012e-02   5.61761148e-02  -1.20485581e-01
    8.79513994e-02  -1.37595847e-01   2.34860510e-01  -1.33654401e-02
   -1.61587503e-02   4.25071567e-02  -2.54511893e-01  -1.86614692e-03
   -2.50252962e-01  -1.09420002e-01  -3.75480540e-02   9.03832763e-02
   -1.85869515e-01  -5.22555821e-02   1.96996272e-01  -6.34954274e-02
   -2.08453499e-02  -3.68664116e-02   8.22733268e-02   1.53358039e-02
    1.47268593e-01  -7.74519071e-02  -1.90329194e-01   1.57877803e-05
    3.67705561e-02  -2.12282330e-01  -7.43998066e-02  -1.00443140e-01
    4.09346335e-02  -4.76464555e-02  -5.13770878e-02   1.41419426e-01
   -3.17291208e-02  -8.67921785e-02   9.70629454e-02   3.22200656e-02
    1.98832899e-02  -6.57767057e-02   1.07402680e-02   3.53693403e-02
    1.52957998e-02   9.90307145e-03  -1.56020731e-01   1.83518559e-01
    3.61694247e-02   9.28278789e-02  -7.14343935e-02   2.74994858e-02
   -9.50914696e-02   2.84523070e-02  -2.30895385e-01   1.30457044e-01
    2.47936137e-03  -4.27274220e-03   3.01414318e-02  -5.24157584e-02
   -3.79008986e-02  -5.51719852e-02  -6.66513592e-02  -2.00337499e-01
    2.77875010e-02   2.50009745e-01   2.51299798e-01   1.14594236e-01
    3.62801142e-02  -8.58041421e-02  -6.26708195e-02  -5.64644486e-03]]
After layer encoder_birnn_reverse_l0_t5_slice_output3 (1, 256) <class 'numpy.float32'> [[ 0.06430312  0.04617597 -0.0155037   0.06574129  0.04023042  0.20263852
   0.09844911  0.12297598  0.39057413  0.11876692 -0.05307587  0.06583817
   0.16275178 -0.03743254  0.04530765  0.11903626 -0.06054504 -0.08882516
   0.03381386 -0.0173111  -0.04131719 -0.13141602  0.26268029  0.10663736
   0.05807903  0.05526477 -0.01143952 -0.01207251 -0.09505069  0.01477948
   0.11160692  0.09977673  0.03255587  0.02917743 -0.02302047 -0.04436108
   0.10599279 -0.01046971  0.07285885 -0.01605698  0.07450626 -0.02843663
  -0.00176264  0.0036047  -0.03125672  0.03116344  0.02368116 -0.071603
   0.02646865  0.11179987  0.08442018 -0.02311886 -0.05911414  0.0550903
   0.16241252 -0.11136776  0.14651723  0.02206396  0.02936968 -0.11634979
   0.06151262  0.07264142  0.02702755  0.16312373 -0.00697448 -0.05908945
   0.19776902  0.0590032   0.00496746  0.07789869  0.0173918   0.03574616
   0.00523951 -0.01732136  0.11402738  0.20216699  0.1445877   0.04122164
   0.11932443  0.21008533  0.17114037  0.19834593  0.09725678  0.11335496
   0.15833792  0.05350802  0.0327731   0.09608239  0.07800776  0.0645025
   0.15886818 -0.04500638 -0.0900255   0.02811923  0.0484572   0.03237725
   0.06266287  0.10224751 -0.14190713 -0.10828851 -0.04446978 -0.14270507
  -0.07616912 -0.08655157 -0.01701902  0.00879977 -0.03821414  0.12644093
   0.05770505  0.13987562  0.0106495   0.05645892 -0.08388065  0.13876028
   0.0047619   0.15160507 -0.07905054 -0.02504503  0.06126872 -0.05643198
   0.0283251   0.09132913  0.0858012   0.0055736  -0.05304888  0.03435875
  -0.01101838 -0.00396182 -0.02250541 -0.09552447  0.01817801  0.18529382
  -0.02039049  0.09872258  0.04488402 -0.07449391  0.12902682  0.05795332
   0.12122539  0.0297432   0.01577111 -0.00478756 -0.07780339  0.07199568
  -0.00322565  0.02587717  0.15370411  0.06393494  0.03598724 -0.01566486
  -0.02416015 -0.0299492   0.06950939  0.13320065 -0.0022892   0.07847491
   0.09459999  0.10627316  0.04149631  0.13467881  0.07863905  0.03027287
  -0.0119673   0.13885945  0.08206568 -0.07541515  0.26391247  0.10856061
  -0.12875357  0.02180729 -0.10380599  0.10797057  0.08551694  0.20088279
   0.01954756  0.17203286  0.15022755 -0.05956095  0.08019551 -0.0149998
  -0.11499762 -0.06954705  0.04615765 -0.07183003 -0.05373172  0.12871948
  -0.02282391  0.10408691 -0.01573963 -0.1027018   0.01873484  0.1417743
   0.05070588  0.01617634  0.00961907  0.0605639  -0.03064174  0.04912885
   0.1116939   0.01552638  0.07690771  0.21717189  0.09019795  0.14937109
   0.09059621  0.09239662 -0.07533232  0.04693131 -0.09616333  0.16620289
  -0.00370884  0.29819822  0.05644072  0.15260404  0.09723794 -0.05157316
   0.05912179  0.18974349 -0.03419313 -0.05348271 -0.0413897  -0.13296799
   0.14987525  0.02896403  0.0705191   0.10035473  0.00358146  0.03592788
   0.31508246  0.18410063  0.01516619 -0.13772787 -0.02785198  0.00448938
  -0.02043895  0.02392136 -0.03254972  0.07643079  0.1109571   0.03433905
  -0.12461941  0.08400415  0.09426484  0.3203769  -0.12704147  0.0588186
   0.02275821 -0.13059823  0.03791177 -0.01355029  0.10487851 -0.0865672
   0.10345425  0.13692074 -0.00819566  0.06335704]]
After layer encoder_birnn_reverse_l0_t5_o_output (1, 256) <class 'numpy.float32'> [[ 0.51607025  0.51154196  0.49612415  0.51642942  0.51005626  0.55048698
   0.5245924   0.53070533  0.59642088  0.52965689  0.48673415  0.51645356
   0.54059839  0.49064296  0.511325    0.52972394  0.48486832  0.4778083
   0.50845271  0.49567235  0.48967215  0.46719319  0.56529504  0.5266341
   0.5145157   0.51381272  0.49714017  0.49698195  0.47625521  0.50369483
   0.5278728   0.5249235   0.50813824  0.50729382  0.49424511  0.48891157
   0.5264734   0.49738258  0.51820666  0.49598587  0.51861793  0.49289131
   0.49955931  0.50090116  0.49218649  0.50779027  0.50591999  0.48210689
   0.50661677  0.5279209   0.52109253  0.4942205   0.48522574  0.51376909
   0.54051411  0.4721868   0.53656393  0.50551575  0.50734192  0.47094533
   0.51537335  0.51815236  0.50675648  0.54069072  0.49825636  0.48523194
   0.54928172  0.51474655  0.50124186  0.51946485  0.50434786  0.50893557
   0.50130987  0.49566975  0.528476    0.55037034  0.53608406  0.51030397
   0.52979577  0.552329    0.54268098  0.54942453  0.52429503  0.52830845
   0.53950197  0.51337379  0.50819254  0.52400213  0.51949203  0.51612002
   0.53963375  0.48875031  0.47750884  0.50702935  0.5121119   0.5080936
   0.51566058  0.52553964  0.46458262  0.4729543   0.48888433  0.46438417
   0.48096696  0.47837564  0.49574533  0.50219995  0.49044761  0.53156817
   0.5144223   0.53491205  0.50266236  0.51411098  0.47904211  0.53463453
   0.50119048  0.53782886  0.48024762  0.49373907  0.51531237  0.48589572
   0.50708079  0.52281642  0.52143717  0.50139338  0.48674086  0.50858885
   0.49724543  0.49900955  0.49437386  0.47613704  0.50454438  0.54619139
   0.49490255  0.52466065  0.51121914  0.48138514  0.53221202  0.51448423
   0.53026932  0.50743526  0.50394273  0.49880314  0.48055893  0.51799119
   0.49919355  0.50646895  0.53835058  0.51597828  0.50899583  0.49608389
   0.49396026  0.49251327  0.51737034  0.53325099  0.49942774  0.51960868
   0.52363241  0.52654332  0.51037258  0.53361893  0.51964962  0.50756764
   0.4970082   0.53465921  0.52050489  0.48115516  0.56559783  0.5271135
   0.46785602  0.50545162  0.47407177  0.52696645  0.52136618  0.55005252
   0.50488675  0.54290247  0.53748643  0.48511419  0.52003813  0.49625012
   0.47128224  0.48262027  0.51153737  0.48205021  0.4865703   0.53213555
   0.49429429  0.52599829  0.49606517  0.47434708  0.50468355  0.5353843
   0.51267374  0.504044    0.50240475  0.51513636  0.49234018  0.51227975
   0.5278945   0.50388151  0.51921743  0.55408055  0.52253419  0.53727353
   0.52263355  0.52308273  0.48117584  0.51173073  0.47597769  0.54145533
   0.49907279  0.57400203  0.51410645  0.53807718  0.52429038  0.4871096
   0.51477611  0.54729408  0.49145257  0.4866325   0.48965403  0.46680692
   0.53739887  0.50724047  0.51762247  0.52506769  0.50089538  0.50898099
   0.57812536  0.54589558  0.50379151  0.46562237  0.49303743  0.50112236
   0.49489039  0.50598007  0.49186328  0.5190984   0.52771086  0.50858396
   0.46888542  0.5209887   0.52354878  0.5794161   0.46828225  0.51470041
   0.50568932  0.46739677  0.50947678  0.49661252  0.52619565  0.47837174
   0.52584052  0.53417683  0.49795112  0.51583397]]
After layer encoder_birnn_reverse_l0_t5_f_output (1, 256) <class 'numpy.float32'> [[ 0.53675187  0.507442    0.52462274  0.51172364  0.50342697  0.51907486
   0.54472697  0.4762342   0.58793294  0.53772604  0.52989835  0.53009164
   0.52770042  0.50011533  0.5293622   0.53168893  0.52163327  0.48956186
   0.46387884  0.51609915  0.53196746  0.50315988  0.58873665  0.51368988
   0.52972549  0.51786435  0.53567332  0.52185655  0.52856123  0.50946391
   0.51813638  0.50635284  0.55662841  0.48564762  0.49666762  0.497026
   0.48573959  0.52890509  0.50565714  0.52279961  0.48655054  0.52623999
   0.50358307  0.52295864  0.50816667  0.52772105  0.50823188  0.47202247
   0.49901965  0.50679225  0.51670259  0.52202314  0.4972682   0.5350402
   0.5162459   0.51492214  0.51158941  0.52368528  0.50068694  0.47756287
   0.51921642  0.50947994  0.51471484  0.50854594  0.49479967  0.53468984
   0.55048472  0.51650846  0.46829376  0.49176356  0.51640809  0.49864563
   0.48968142  0.50861126  0.52505541  0.54298514  0.51495779  0.51297611
   0.52171999  0.52023774  0.55345994  0.54263127  0.50944245  0.50873572
   0.54128051  0.49961972  0.52005452  0.54338092  0.50876212  0.46476486
   0.57465076  0.52198505  0.51970536  0.51781571  0.48570466  0.50423664
   0.50161028  0.51990223  0.45997992  0.45809984  0.48482841  0.50022376
   0.50912541  0.52521342  0.49809772  0.49278703  0.47440684  0.5167343
   0.51999527  0.47466713  0.50565583  0.49419552  0.51305753  0.54667598
   0.52385938  0.5472098   0.52593917  0.53169018  0.51772052  0.52711564
   0.54723781  0.54063463  0.51008558  0.50444329  0.495837    0.49781093
   0.54294133  0.49850494  0.52583832  0.47437799  0.5285303   0.53248489
   0.50335157  0.53997946  0.51579469  0.51452029  0.50555068  0.51252079
   0.53125435  0.54858172  0.48118314  0.51365525  0.51717019  0.50728273
   0.50922567  0.53244692  0.51915717  0.51028013  0.51198554  0.49431485
   0.49300498  0.51752067  0.50840062  0.52204233  0.50174779  0.54517418
   0.52407098  0.49301958  0.51243275  0.53607625  0.5546236   0.52071369
   0.4917666   0.52177966  0.51886934  0.4972209   0.56561762  0.49132177
   0.49863416  0.49335635  0.50762773  0.53093129  0.49263659  0.55043083
   0.48746219  0.52842396  0.5407539   0.49616721  0.50363654  0.52787429
   0.52009308  0.48196742  0.55708772  0.49027723  0.50038487  0.50392061
   0.50888366  0.54714805  0.49613863  0.48533261  0.49143806  0.50842243
   0.54313326  0.53701663  0.48106587  0.50058132  0.49759358  0.49651742
   0.50738454  0.5046168   0.51064306  0.51344031  0.51858014  0.49210057
   0.52632338  0.46654123  0.49021223  0.53805971  0.48439762  0.52439445
   0.51953119  0.52630949  0.48735282  0.50655031  0.49592623  0.4785116
   0.51468688  0.52360809  0.49513999  0.52850175  0.476172    0.4838894
   0.55961263  0.50408292  0.5218491   0.49908614  0.50488651  0.51155984
   0.58784968  0.55317086  0.50673813  0.43289429  0.5371235   0.50859022
   0.51561594  0.49933237  0.50167036  0.5213809   0.5106076   0.52353066
   0.51823533  0.51034278  0.50523418  0.55402011  0.46346274  0.49507749
   0.48488835  0.48640412  0.52500498  0.49425659  0.53996944  0.45828125
   0.53766495  0.49658936  0.53318065  0.50045717]]
After layer _mul2082_0 (1, 256) <class 'numpy.float32'> [[-0.07429455 -0.0609832  -0.00311011  0.01874007  0.02155385 -0.028134
   0.02131103  0.038014    0.02866233 -0.05131856 -0.03781145  0.06415635
   0.04663324 -0.0166609   0.03401843 -0.12073264  0.02603265  0.0082862
   0.03347671  0.02565445  0.10210584 -0.02572066  0.00123203  0.03205183
  -0.05504055  0.01603873  0.02281532 -0.02084535 -0.06868566 -0.04856496
   0.01971229 -0.05924575 -0.00572562  0.00126545  0.05256748 -0.0634846
  -0.03005012 -0.00653115 -0.05399888 -0.04532507  0.01573542 -0.08971564
   0.05608028  0.04400547  0.04399991 -0.05573539  0.02089461 -0.0292351
  -0.00545146 -0.04176567  0.02800114 -0.0595436  -0.03575615  0.06379245
   0.02222371  0.01162941 -0.01969009  0.09132718  0.04153338 -0.02314797
  -0.04344789 -0.04588012 -0.01535996 -0.00776832  0.03312357 -0.01895044
   0.02564334 -0.04316409 -0.04614661 -0.00863127 -0.12392803  0.00622253
   0.0256472   0.01140238  0.06496099 -0.02400661 -0.02295146 -0.0896534
  -0.03190083 -0.01942376 -0.0601118   0.00695524 -0.04033466 -0.07613794
  -0.1338385   0.0085905  -0.06314971  0.01854105 -0.07808295 -0.050405
  -0.05888565 -0.0276425  -0.01213467 -0.00832217 -0.0216102   0.0202904
   0.04335293 -0.02363184 -0.04064012 -0.03002047  0.01362599  0.06449574
  -0.03490376  0.02246767  0.02347014  0.06360736 -0.01960517 -0.02192164
   0.0752551  -0.07793447  0.04157412  0.00395223  0.03307287  0.05050394
  -0.04676175  0.14582388 -0.07254829 -0.03865951  0.02250878 -0.02681064
   0.08731237  0.04226888 -0.01055119 -0.04417558  0.04868486 -0.08295441
  -0.04705366 -0.03443909 -0.02085901 -0.007574    0.04478703 -0.02124905
   0.03666137 -0.00364915  0.00348149  0.03428058  0.04603409  0.10348944
  -0.00345298  0.03442157 -0.0040481  -0.02393684  0.06686704  0.0091046
  -0.04392942  0.0478207   0.03369488 -0.05687441 -0.04385913 -0.05312599
  -0.02956083 -0.01377641 -0.02735658 -0.0404124  -0.00427212  0.03971923
  -0.05850976  0.02114647  0.02577423  0.03516987 -0.12298414 -0.03644122
   0.012067    0.07364546  0.01458075  0.04371777  0.00779214 -0.0277777
  -0.08711608  0.00423009 -0.04619351  0.02420885 -0.0157615  -0.07959217
  -0.01037048  0.03441691  0.08013252 -0.02323379 -0.03080795 -0.01751844
   0.03773941  0.00488862  0.02119066 -0.01585015 -0.02530993  0.02442489
   0.02125786 -0.05737949  0.04714761 -0.057392    0.08625171 -0.00488791
  -0.00105536  0.00886598 -0.0900806  -0.00079093 -0.09901378 -0.04271279
  -0.01389956  0.03085509 -0.07251741 -0.01625981  0.08919615 -0.02767355
  -0.00604683 -0.01040301  0.02957235  0.00464784  0.05427958 -0.04499821
  -0.07793739  0.00381214  0.01358294 -0.0784194  -0.0283628  -0.03801538
   0.01309028 -0.01914345 -0.01224465  0.05879539 -0.01285228 -0.03702398
   0.0442859   0.00677852  0.00325727 -0.02448367  0.00246479  0.01617373
   0.02218971 -0.004686   -0.06651679  0.05931631  0.02664202  0.0417858
  -0.03515368  0.02007165 -0.04779234  0.01036883 -0.08326904  0.06214517
   0.00881121 -0.00988355  0.01238068 -0.03679413 -0.01625208 -0.03125212
  -0.02545428 -0.06853887  0.00592199  0.1029259   0.10644825  0.04185693
   0.0262568  -0.03380314 -0.02413777 -0.008233  ]]
After layer encoder_birnn_reverse_l0_t5_i_output (1, 256) <class 'numpy.float32'> [[ 0.49728659  0.4948563   0.49455592  0.49438617  0.5084005   0.49535587
   0.50563508  0.50434035  0.52416766  0.5152812   0.49006411  0.52251726
   0.50378072  0.50769913  0.49962786  0.56878632  0.47256309  0.48183867
   0.50306869  0.49712038  0.52283728  0.50365579  0.47340056  0.48907998
   0.51912451  0.46882737  0.49154288  0.49594018  0.50446081  0.49493536
   0.49995542  0.49646309  0.48766169  0.48871449  0.51841807  0.46509367
   0.49666259  0.49766186  0.48018306  0.48397627  0.47037557  0.50689626
   0.48680443  0.50031626  0.50828767  0.49660066  0.51641923  0.48005083
   0.4929738   0.50628275  0.50305128  0.52555734  0.47246072  0.51814711
   0.54469657  0.52689469  0.48397845  0.50347871  0.4822019   0.49468926
   0.51932561  0.48748699  0.53928083  0.4930186   0.47159165  0.4896163
   0.52552503  0.49462229  0.48102388  0.50220788  0.52505654  0.49447241
   0.49821943  0.49603543  0.50147134  0.51559836  0.53050363  0.53859663
   0.50592244  0.51216     0.50605279  0.51166373  0.52160388  0.49482432
   0.54104489  0.51261216  0.49321449  0.4854891   0.49435773  0.51857853
   0.52842051  0.49691507  0.47928083  0.52101511  0.51804656  0.50968772
   0.49317905  0.51663357  0.47506335  0.4704254   0.47654676  0.51936656
   0.50193679  0.46849734  0.47758707  0.50220108  0.49351454  0.47243038
   0.51508921  0.50804228  0.47127187  0.50376225  0.50621992  0.55073971
   0.5019471   0.57417387  0.49111342  0.50198108  0.5042423   0.48850545
   0.55212837  0.46871284  0.500655    0.52376103  0.48475164  0.51471007
   0.46819705  0.51822883  0.49428886  0.50138164  0.54990453  0.51511586
   0.49804896  0.48936781  0.48134649  0.47987399  0.52572548  0.53920013
   0.49780673  0.4960779   0.48994392  0.47226238  0.52107829  0.51547468
   0.49242145  0.49915195  0.50827348  0.51515806  0.49624354  0.51493305
   0.52924275  0.4852615   0.5002206   0.47637039  0.47897711  0.54782051
   0.5075168   0.51083851  0.49507231  0.49183568  0.5519191   0.50185114
   0.48547322  0.50689656  0.50261039  0.48235667  0.50112468  0.48775986
   0.51060122  0.48864764  0.50071222  0.51040715  0.50075334  0.52553624
   0.50598669  0.46435437  0.50889742  0.46943372  0.48630998  0.49404868
   0.5109092   0.48268813  0.49734542  0.50683808  0.52408326  0.49473676
   0.49600458  0.4851512   0.52679807  0.5121603   0.49134845  0.49256909
   0.51031435  0.4900111   0.50482154  0.52050656  0.522695    0.45872977
   0.51070201  0.51810724  0.5013535   0.52890813  0.51755542  0.51252329
   0.50539958  0.49351442  0.49914995  0.4867824   0.48353189  0.51125824
   0.51119816  0.52676141  0.5051254   0.51391047  0.50088233  0.50479579
   0.49826097  0.49442428  0.50608188  0.50009531  0.48543185  0.48108566
   0.52119136  0.48144063  0.50227809  0.51555771  0.49349049  0.47580028
   0.47844529  0.52993381  0.49726549  0.47172382  0.49476686  0.48784727
   0.50755107  0.5152545   0.49847656  0.52011096  0.50756544  0.4895595
   0.47589961  0.46702942  0.52424675  0.55872947  0.48559687  0.50556237
   0.48223594  0.48207021  0.50402749  0.50063264  0.53712219  0.49904647
   0.47487676  0.51227373  0.51326084  0.49670357]]
After layer encoder_birnn_reverse_l0_t5_c_output (1, 256) <class 'numpy.float32'> [[ -1.59016326e-01  -1.44153923e-01  -2.80698389e-02   4.94556613e-02
    2.99355779e-02  -6.24046177e-02   2.28682645e-02   7.75251538e-02
    7.51677155e-02  -1.29297212e-01  -8.49060789e-02   1.66426912e-01
    9.55190435e-02  -2.05862503e-02   7.29626492e-02  -2.49543279e-01
    8.29271600e-02   3.06748357e-02   9.89391729e-02   5.68753295e-02
    2.30997369e-01  -7.06919655e-02  -1.60098057e-02   4.95071448e-02
   -1.24961577e-01   3.49376574e-02   5.66418283e-02  -5.77571057e-02
   -1.51895657e-01  -1.24657720e-01   4.69330177e-02  -1.20664299e-01
   -2.79780501e-03   7.01864250e-03   1.27274901e-01  -1.61702126e-01
   -6.12107180e-02   1.45379582e-03  -1.26492485e-01  -1.13426477e-01
    2.16667783e-02  -2.10953966e-01   1.33928463e-01   1.01668820e-01
    9.65754464e-02  -1.21837795e-01   5.02893291e-02  -7.12730810e-02
   -1.69659816e-02  -1.09859750e-01   7.50270560e-02  -1.39392138e-01
   -8.15770701e-02   1.76184803e-01   1.43747563e-02   1.79859828e-02
   -2.16013640e-02   2.10595906e-01   1.22938387e-01  -4.91087288e-02
   -1.16072185e-01  -1.02155775e-01  -1.87921189e-02  -2.90315803e-02
    7.88616166e-02  -4.09809686e-02   3.17142643e-02  -1.19237728e-01
   -1.07779287e-01   1.90727925e-03  -2.82336801e-01   2.70568915e-02
    4.21582684e-02   2.48773135e-02   1.43102944e-01  -2.64215339e-02
   -6.09171093e-02  -2.24901512e-01  -8.15656036e-02  -4.88270819e-02
   -1.37819007e-01   1.26702935e-02  -1.02637388e-01  -1.88293666e-01
   -2.83211738e-01   7.22842384e-03  -1.07361615e-01   1.64680015e-02
   -2.09944353e-01  -1.15443856e-01  -1.27878234e-01  -6.10102154e-02
   -3.18298750e-02   1.13019394e-03  -5.55135906e-02   6.00667782e-02
    9.65626240e-02  -4.93085980e-02  -1.06573299e-01  -1.06416121e-01
    1.43496562e-02   1.53022230e-01  -7.44881704e-02   5.69115803e-02
    6.83830455e-02   1.89646468e-01  -4.69236672e-02  -4.26365808e-02
    1.74750030e-01  -2.10785300e-01   1.25295222e-01  -1.36701912e-02
    9.86488163e-02   1.21810399e-01  -9.23065990e-02   2.90244937e-01
   -1.84327647e-01  -1.00957923e-01   3.55424620e-02  -7.55797103e-02
    1.85644597e-01   6.62117526e-02  -1.03194928e-02  -1.10088892e-01
    1.05069704e-01  -1.92610025e-01  -1.29352629e-01  -8.77111629e-02
   -5.17776608e-02  -2.56262664e-02   1.11931220e-01  -2.33192779e-02
    8.10112357e-02   1.13710631e-02   5.48925193e-04   7.75213167e-02
    8.17998499e-02   2.39529833e-01   7.81696290e-05   7.31400773e-02
   -1.63306529e-03  -4.71730642e-02   1.55723080e-01   2.68213451e-02
   -9.19686332e-02   1.13271974e-01   8.68456960e-02  -1.11724235e-01
   -1.04437858e-01  -1.46786705e-01  -7.05355480e-02  -2.84016002e-02
   -8.46642107e-02  -7.79885948e-02  -3.88098042e-03   8.74808729e-02
   -1.37740225e-01   1.89722143e-02   5.64132072e-02   8.22928473e-02
   -2.54104614e-01  -6.25150800e-02   2.47228239e-02   1.61958262e-01
    3.98830548e-02   1.03705354e-01   1.40889576e-02  -4.04485203e-02
   -2.33910143e-01   1.54006220e-02  -1.15668148e-01   7.05228597e-02
   -3.78896743e-02  -1.59869373e-01  -3.54636386e-02   8.22520182e-02
    1.70262501e-01  -5.80378100e-02  -5.70411757e-02  -2.08046958e-02
    7.62171596e-02   2.19785701e-02   5.18197678e-02  -4.12940942e-02
   -7.77054876e-02   4.74091358e-02   5.61170988e-02  -1.19905934e-01
    8.77253190e-02  -1.36734024e-01   2.30635449e-01  -1.33646447e-02
   -1.61573440e-02   4.24815752e-02  -2.49155194e-01  -1.86614471e-03
   -2.45156437e-01  -1.08985402e-01  -3.75304185e-02   9.01379660e-02
   -1.83758244e-01  -5.22080697e-02   1.94486916e-01  -6.34102374e-02
   -2.08423305e-02  -3.68497185e-02   8.20881948e-02   1.53346015e-02
    1.46213099e-01  -7.72974044e-02  -1.88063785e-01   1.57877803e-05
    3.67539935e-02  -2.09150031e-01  -7.42628351e-02  -1.00106716e-01
    4.09117863e-02  -4.76104319e-02  -5.13319299e-02   1.40484139e-01
   -3.17184776e-02  -8.65749046e-02   9.67592746e-02   3.22089195e-02
    1.98806711e-02  -6.56820089e-02   1.07398555e-02   3.53545994e-02
    1.52946068e-02   9.90274735e-03  -1.54766962e-01   1.81485698e-01
    3.61536592e-02   9.25621614e-02  -7.13131353e-02   2.74925567e-02
   -9.48058888e-02   2.84446310e-02  -2.26877823e-01   1.29721969e-01
    2.47935625e-03  -4.27271612e-03   3.01323067e-02  -5.23678102e-02
   -3.78827602e-02  -5.51160723e-02  -6.65528402e-02  -1.97699651e-01
    2.77803522e-02   2.44927824e-01   2.46140093e-01   1.14095248e-01
    3.62642035e-02  -8.55941921e-02  -6.25889003e-02  -5.64638479e-03]]
After layer _mul2083_0 (1, 256) <class 'numpy.float32'> [[ -7.90766850e-02  -7.13354796e-02  -1.38821052e-02   2.44501941e-02
    1.52192628e-02  -3.09124943e-02   1.15629965e-02   3.90990637e-02
    3.94004844e-02  -6.66244254e-02  -4.16094214e-02   8.69609341e-02
    4.81206514e-02  -1.04516214e-02   3.64541709e-02  -1.41936809e-01
    3.91883142e-02   1.47803221e-02   4.97732013e-02   2.82738861e-02
    1.20774038e-01  -3.56044173e-02  -7.57905096e-03   2.42129527e-02
   -6.48706183e-02   1.63797308e-02   2.78418865e-02  -2.86440700e-02
   -7.66254067e-02  -6.16975129e-02   2.34644171e-02  -5.99053688e-02
   -1.36438233e-03   3.43011227e-03   6.59816116e-02  -7.52066374e-02
   -3.04010734e-02   7.23498757e-04  -6.07395507e-02  -5.48957251e-02
    1.01915235e-02  -1.06931776e-01   6.51969686e-02   5.08665629e-02
    4.90881093e-02  -6.05047308e-02   2.59703770e-02  -3.42147015e-02
   -8.36378429e-03  -5.56200966e-02   3.77424583e-02  -7.32585639e-02
   -3.85419615e-02   9.12896469e-02   7.82988034e-03   9.47671849e-03
   -1.04545951e-02   1.06030554e-01   5.92811257e-02  -2.42935605e-02
   -6.02792576e-02  -4.97996099e-02  -1.01342294e-02  -1.43131092e-02
    3.71904783e-02  -2.00649500e-02   1.66666396e-02  -5.89776374e-02
   -5.18444106e-02   9.57850658e-04  -1.48242787e-01   1.33788865e-02
    2.10040677e-02   1.23400288e-02   7.17620254e-02  -1.36228995e-02
   -3.23167481e-02  -1.21131197e-01  -4.12658677e-02  -2.50072777e-02
   -6.97436929e-02   6.48292946e-03  -5.35360612e-02  -9.31722820e-02
   -1.53230265e-01   3.70537792e-03  -5.29523045e-02   7.99503550e-03
   -1.03787616e-01  -5.98667040e-02  -6.75734803e-02  -3.03168949e-02
   -1.52554484e-02   5.88848139e-04  -2.87586246e-02   3.06152999e-02
    4.76226620e-02  -2.54744776e-02  -5.06290682e-02  -5.00608459e-02
    6.83828210e-03   7.94746280e-02  -3.73883545e-02   2.66629234e-02
    3.26588601e-02   9.52406600e-02  -2.31575128e-02  -2.01428160e-02
    9.00118575e-02  -1.07087843e-01   5.90481125e-02  -6.88652601e-03
    4.99379970e-02   6.70858249e-02  -4.63330299e-02   1.66651055e-01
   -9.05257836e-02  -5.06789684e-02   1.79220121e-02  -3.69210988e-02
    1.02499649e-01   3.10342982e-02  -5.16650546e-03  -5.76602705e-02
    5.09327129e-02  -9.91383195e-02  -6.05625175e-02  -4.54544537e-02
   -2.55931206e-02  -1.28485393e-02   6.15514852e-02  -1.20121296e-02
    4.03475612e-02   5.56463236e-03   2.64223199e-04   3.72004621e-02
    4.30042669e-02   1.29154518e-01   3.89133675e-05   3.62831764e-02
   -8.00110400e-04  -2.22780630e-02   8.11439157e-02   1.38257239e-02
   -4.52873260e-02   5.65399267e-02   4.41413634e-02  -5.75556383e-02
   -5.18266112e-02  -7.55853280e-02  -3.73304263e-02  -1.37822032e-02
   -4.23507802e-02  -3.71514559e-02  -1.85890077e-03   4.79238145e-02
   -6.99054748e-02   9.69173759e-03   2.79286169e-02   4.04745601e-02
   -1.40245184e-01  -3.13732624e-02   1.20022688e-02   8.20960850e-02
    2.00456381e-02   5.00229672e-02   7.06032431e-03  -1.97291654e-02
   -1.19434804e-01   7.52547756e-03  -5.79164550e-02   3.59953716e-02
   -1.89733803e-02  -8.40171501e-02  -1.79441292e-02   3.81940827e-02
    8.66461471e-02  -2.72449050e-02  -2.77396925e-02  -1.02785323e-02
    3.89400497e-02   1.06087951e-02   2.57723238e-02  -2.09294204e-02
   -4.07241434e-02   2.34550424e-02   2.78343372e-02  -5.81725091e-02
    4.62135300e-02  -7.00297356e-02   1.13322370e-01  -6.58301078e-03
   -8.24532472e-03   2.08164435e-02  -1.25778913e-01  -9.71340574e-04
   -1.28142044e-01  -4.99948487e-02  -1.91668607e-02   4.67011333e-02
   -9.21278372e-02  -2.76132729e-02   1.00657754e-01  -3.24992239e-02
   -1.05337054e-02  -1.81858670e-02   4.09743190e-02   7.46461423e-03
    7.06986934e-02  -3.95189337e-02  -9.61378589e-02   8.31639318e-06
    1.85653754e-02  -1.07484393e-01  -3.71969417e-02  -5.05334474e-02
    2.03847457e-02  -2.35397536e-02  -2.59781592e-02   7.02554584e-02
   -1.53971594e-02  -4.16499451e-02   5.04300967e-02   1.55066829e-02
    9.98562574e-03  -3.38628665e-02   5.30001661e-03   1.68217290e-02
    7.31763244e-03   5.24780061e-03  -7.69602656e-02   8.56111273e-02
    1.78876333e-02   4.51561958e-02  -3.61950584e-02   1.41656632e-02
   -4.72585149e-02   1.47943646e-02  -1.15155339e-01   6.35066256e-02
    1.17992470e-03  -1.99548411e-03   1.57967638e-02  -2.92594396e-02
   -1.83957499e-02  -2.78646126e-02  -3.20941731e-02  -9.53051150e-02
    1.40020614e-02   1.22618861e-01   1.32207304e-01   5.69388308e-02
    1.72210280e-02  -4.38476577e-02  -3.21244299e-02  -2.80457945e-03]]
After layer encoder_birnn_reverse_l0_t5_state_0 (1, 256) <class 'numpy.float32'> [[-0.15337124 -0.13231868 -0.01699222  0.04319026  0.03677311 -0.0590465
   0.03287403  0.07711306  0.06806281 -0.11794299 -0.07942086  0.15111728
   0.09475389 -0.02711252  0.07047261 -0.26266944  0.06522097  0.02306652
   0.08324991  0.05392834  0.22287989 -0.06132508 -0.00634702  0.05626478
  -0.11991117  0.03241846  0.0506572  -0.04948942 -0.14531106 -0.11026248
   0.0431767  -0.11915112 -0.00709     0.00469556  0.11854909 -0.13869125
  -0.06045119 -0.00580765 -0.11473843 -0.1002208   0.02592695 -0.19664742
   0.12127724  0.09487204  0.09308802 -0.11624013  0.04686499 -0.0634498
  -0.01381524 -0.09738576  0.0657436  -0.13280216 -0.07429811  0.15508211
   0.03005359  0.02110613 -0.03014469  0.19735773  0.10081451 -0.04744153
  -0.10372715 -0.09567973 -0.02549419 -0.02208143  0.07031405 -0.03901539
   0.04230998 -0.10214172 -0.09799102 -0.00767342 -0.27217081  0.01960142
   0.04665127  0.02374241  0.13672301 -0.03762951 -0.05526821 -0.2107846
  -0.0731667  -0.04443104 -0.1298555   0.01343817 -0.09387073 -0.16931021
  -0.28706878  0.01229587 -0.11610201  0.02653608 -0.18187056 -0.1102717
  -0.12645914 -0.05795939 -0.02739012 -0.00773332 -0.05036882  0.0509057
   0.09097559 -0.04910631 -0.09126918 -0.08008131  0.02046427  0.14397037
  -0.07229212  0.04913059  0.056129    0.15884802 -0.04276268 -0.04206445
   0.16526696 -0.18502232  0.10062224 -0.00293429  0.08301087  0.11758976
  -0.09309478  0.31247494 -0.16307408 -0.08933847  0.04043079 -0.06373174
   0.18981202  0.07330318 -0.01571769 -0.10183585  0.09961757 -0.18209273
  -0.10761617 -0.07989354 -0.04645213 -0.02042254  0.10633852 -0.03326118
   0.07700893  0.00191548  0.00374572  0.07148104  0.08903836  0.23264396
  -0.00341406  0.07070475 -0.00484821 -0.0462149   0.14801095  0.02293032
  -0.08921675  0.10436063  0.07783625 -0.11443006 -0.09568574 -0.12871131
  -0.06689126 -0.02755862 -0.06970736 -0.07756385 -0.00613102  0.08764304
  -0.12841524  0.03083821  0.05370285  0.07564443 -0.26322931 -0.06781448
   0.02406927  0.15574154  0.03462639  0.09374074  0.01485246 -0.04750687
  -0.2065509   0.01175557 -0.10410996  0.06020422 -0.03473488 -0.16360933
  -0.02831461  0.072611    0.16677867 -0.0504787  -0.05854765 -0.02779698
   0.07667946  0.01549742  0.04696298 -0.03677957 -0.06603408  0.04787993
   0.0490922  -0.115552    0.09336114 -0.12742174  0.19957408 -0.01147092
  -0.00930069  0.02968242 -0.21585952 -0.00176227 -0.22715583 -0.09270764
  -0.03306641  0.07755622 -0.16464525 -0.04387309  0.18985391 -0.06017278
  -0.01658054 -0.02858888  0.07054667  0.01211246  0.12497827 -0.08451715
  -0.17407525  0.00382046  0.03214832 -0.18590379 -0.06555974 -0.08854883
   0.03347502 -0.04268321 -0.03822281  0.12905085 -0.02824944 -0.07867393
   0.094716    0.0222852   0.0132429  -0.05834653  0.0077648   0.03299546
   0.02950734  0.0005618  -0.14347705  0.14492744  0.04452966  0.086942
  -0.07134873  0.03423731 -0.09505086  0.02516319 -0.19842438  0.12565179
   0.00999113 -0.01187904  0.02817744 -0.06605357 -0.03464783 -0.05911673
  -0.05754846 -0.16384399  0.01992406  0.22554477  0.23865555  0.09879576
   0.04347783 -0.07765079 -0.0562622  -0.01103758]]
After layer activation1041_output (1, 256) <class 'numpy.float32'> [[-0.15217988 -0.13155183 -0.01699059  0.04316343  0.03675654 -0.05897797
   0.03286219  0.07696058  0.06795791 -0.11739913 -0.0792543   0.14997737
   0.09447134 -0.02710588  0.07035618 -0.25679064  0.06512865  0.02306243
   0.08305813  0.05387612  0.21926123 -0.06124832 -0.00634693  0.05620549
  -0.11933974  0.03240711  0.05061391 -0.04944906 -0.14429687 -0.10981779
   0.04314989 -0.11859044 -0.00708988  0.00469553  0.11799684 -0.13780878
  -0.06037766 -0.00580758 -0.11423757 -0.0998866   0.02592114 -0.19415124
   0.12068614  0.09458842  0.09282006 -0.11571941  0.04683071 -0.06336479
  -0.01381436 -0.09707906  0.06564905 -0.13202691 -0.0741617   0.15385069
   0.03004454  0.02110299 -0.03013556  0.19483466  0.10047435 -0.04740597
  -0.10335673 -0.09538883 -0.02548866 -0.02207784  0.0701984  -0.0389956
   0.04228475 -0.10178799 -0.09767858 -0.00767327 -0.26564363  0.01959891
   0.04661745  0.02373795  0.13587742 -0.03761176 -0.055212   -0.20771737
  -0.07303642 -0.04440182 -0.1291305   0.01343736 -0.09359598 -0.16771074
  -0.27943468  0.01229526 -0.11558314  0.02652986 -0.17989151 -0.10982691
  -0.12578931 -0.05789458 -0.02738328 -0.00773317 -0.05032627  0.05086178
   0.09072543 -0.04906688 -0.0910166  -0.07991057  0.02046142  0.14298384
  -0.07216645  0.0490911   0.05607013  0.15752532 -0.04273663 -0.04203966
   0.16377857 -0.18293954  0.10028402 -0.00293428  0.08282072  0.11705077
  -0.09282678  0.30268696 -0.16164374 -0.08910155  0.04040877 -0.06364559
   0.18756485  0.07317217 -0.0157164  -0.10148527  0.09928935 -0.18010648
  -0.10720265 -0.07972399 -0.04641875 -0.0204197   0.1059395  -0.03324892
   0.07685706  0.00191548  0.0037457   0.07135954  0.08880381  0.22853573
  -0.00341405  0.07058717 -0.00484817 -0.04618203  0.14693952  0.0229263
  -0.08898079  0.1039834   0.07767944 -0.11393321 -0.09539478 -0.12800522
  -0.06679168 -0.02755164 -0.06959468 -0.07740868 -0.00613094  0.08741932
  -0.12771399  0.03082844  0.05365129  0.07550048 -0.25731352 -0.06771072
   0.02406462  0.15449445  0.03461256  0.09346712  0.01485137 -0.04747116
  -0.2036628   0.01175503 -0.10373544  0.06013159 -0.03472092 -0.16216496
  -0.02830704  0.07248366  0.16524936 -0.05043587 -0.05848084 -0.02778982
   0.07652953  0.01549618  0.04692849 -0.036763   -0.06593826  0.04784338
   0.0490528  -0.11504044  0.09309083 -0.12673657  0.19696596 -0.01147042
  -0.00930042  0.02967371 -0.21256816 -0.00176227 -0.22332777 -0.09244295
  -0.03305437  0.0774011  -0.16317348 -0.04384496  0.18760526 -0.06010026
  -0.01657902 -0.0285811   0.07042987  0.01211187  0.12433162 -0.08431648
  -0.17233802  0.00382044  0.03213724 -0.18379137 -0.06546598 -0.08831812
   0.03346252 -0.0426573  -0.03820421  0.12833919 -0.02824192 -0.07851201
   0.09443378  0.02228151  0.01324213 -0.05828041  0.00776465  0.03298349
   0.02949878  0.0005618  -0.14250058  0.14392121  0.04450025  0.0867236
  -0.07122791  0.03422394 -0.09476564  0.02515788 -0.19586062  0.12499467
   0.0099908  -0.01187848  0.02816999 -0.06595767 -0.03463397 -0.05904796
  -0.05748501 -0.16239345  0.01992142  0.2217965   0.23422547  0.09847558
   0.04345045 -0.0774951  -0.05620291 -0.01103713]]
After layer encoder_birnn_reverse_l0_t5_out_0 (1, 256) <class 'numpy.float32'> [[-0.07853551 -0.06729428 -0.00842944  0.02229086  0.0187479  -0.03246661
   0.01723926  0.04084339  0.04053152 -0.06218126 -0.03857578  0.07745635
   0.05107105 -0.01329931  0.03597487 -0.13602816  0.03157882  0.01101942
   0.04223113  0.0267049   0.10736611 -0.0286148  -0.00358789  0.02959973
  -0.06140217  0.01665119  0.02516221 -0.02457529 -0.06872214 -0.05531465
   0.02277765 -0.06225091 -0.00360264  0.00238201  0.05831936 -0.06737631
  -0.03178724 -0.00288859 -0.05919867 -0.04954234  0.01344317 -0.09569546
   0.06028988  0.04737945  0.04568478 -0.05876119  0.02369259 -0.0305486
  -0.00699859 -0.05125007  0.03420923 -0.0652504  -0.03598516  0.07904373
   0.0162395   0.00996455 -0.01616966  0.09849199  0.05097485 -0.02232562
  -0.05326731 -0.04942595 -0.01291655 -0.01193728  0.0349768  -0.01892191
   0.02322624 -0.05239502 -0.04896059 -0.00398599 -0.13397679  0.00997458
   0.02336979  0.01176618  0.07180795 -0.0207004  -0.02959827 -0.105999
  -0.03869439 -0.02452441 -0.07007667  0.00738282 -0.04907191 -0.088603
  -0.15075555  0.00631206 -0.05873849  0.0139017  -0.09345221 -0.05668386
  -0.06788016 -0.02829599 -0.01307576 -0.00392094 -0.02577268  0.02584254
   0.04678353 -0.02578659 -0.04228473 -0.03779405  0.01000327  0.06639943
  -0.03470968  0.02348399  0.0277965   0.07910921 -0.02096008 -0.02234694
   0.08425135 -0.09785657  0.050409   -0.00150855  0.03967461  0.06257938
  -0.0465239   0.16279379 -0.07762902 -0.04399292  0.02082314 -0.03092512
   0.09511054  0.03825561 -0.00819511 -0.05088405  0.04832818 -0.09160014
  -0.05330603 -0.03978303 -0.02294822 -0.00972258  0.05345118 -0.01816027
   0.03803676  0.00100497  0.00191487  0.03435142  0.04726246  0.11757803
  -0.00181037  0.03581842 -0.0024432  -0.02303574  0.07061309  0.01187562
  -0.04441863  0.05266437  0.04181877 -0.05878706 -0.04855555 -0.06350133
  -0.03299243 -0.01356955 -0.03600622 -0.04127825 -0.00306196  0.04542384
  -0.06687518  0.01623251  0.02738215  0.04028849 -0.13371287 -0.03436777
   0.01196031  0.08260188  0.01801601  0.04497219  0.0083999  -0.02502269
  -0.09528486  0.0059416  -0.04917805  0.03168733 -0.01810231 -0.08919924
  -0.01429185  0.03935156  0.08881929 -0.02446716 -0.03041227 -0.0137907
   0.03606701  0.00747877  0.02400568 -0.01772161 -0.0320836   0.02545916
   0.02424652 -0.06051108  0.04617912 -0.06011712  0.09940548 -0.00614108
  -0.00476808  0.01495685 -0.10679526 -0.00090781 -0.10995323 -0.04735665
  -0.01744922  0.03900098 -0.08472252 -0.02429364  0.09803016 -0.03229028
  -0.00866475 -0.01495028  0.03388915  0.00619801  0.05917908 -0.04565361
  -0.08600922  0.00219294  0.01652196 -0.09889394 -0.03432318 -0.04302061
   0.01722571 -0.02334609 -0.01877556  0.06245402 -0.01382877 -0.03664995
   0.05074861  0.01130208  0.00685442 -0.03060116  0.00388928  0.01678797
   0.017054    0.00030668 -0.07179058  0.06701294  0.02194029  0.04345914
  -0.03525001  0.01731663 -0.04661174  0.01305942 -0.10335778  0.06357028
   0.00468454 -0.00618855  0.01474836 -0.03821694 -0.01621847 -0.03039201
  -0.02906956 -0.07590217  0.0101495   0.11014692  0.12324842  0.04710793
   0.02284801 -0.04139609 -0.0279863  -0.00569333]]
After layer expand_dims1047_0 (1, 1, 256) <class 'numpy.float32'> [[[-0.07853551 -0.06729428 -0.00842944  0.02229086  0.0187479  -0.03246661
    0.01723926  0.04084339  0.04053152 -0.06218126 -0.03857578  0.07745635
    0.05107105 -0.01329931  0.03597487 -0.13602816  0.03157882  0.01101942
    0.04223113  0.0267049   0.10736611 -0.0286148  -0.00358789  0.02959973
   -0.06140217  0.01665119  0.02516221 -0.02457529 -0.06872214 -0.05531465
    0.02277765 -0.06225091 -0.00360264  0.00238201  0.05831936 -0.06737631
   -0.03178724 -0.00288859 -0.05919867 -0.04954234  0.01344317 -0.09569546
    0.06028988  0.04737945  0.04568478 -0.05876119  0.02369259 -0.0305486
   -0.00699859 -0.05125007  0.03420923 -0.0652504  -0.03598516  0.07904373
    0.0162395   0.00996455 -0.01616966  0.09849199  0.05097485 -0.02232562
   -0.05326731 -0.04942595 -0.01291655 -0.01193728  0.0349768  -0.01892191
    0.02322624 -0.05239502 -0.04896059 -0.00398599 -0.13397679  0.00997458
    0.02336979  0.01176618  0.07180795 -0.0207004  -0.02959827 -0.105999
   -0.03869439 -0.02452441 -0.07007667  0.00738282 -0.04907191 -0.088603
   -0.15075555  0.00631206 -0.05873849  0.0139017  -0.09345221 -0.05668386
   -0.06788016 -0.02829599 -0.01307576 -0.00392094 -0.02577268  0.02584254
    0.04678353 -0.02578659 -0.04228473 -0.03779405  0.01000327  0.06639943
   -0.03470968  0.02348399  0.0277965   0.07910921 -0.02096008 -0.02234694
    0.08425135 -0.09785657  0.050409   -0.00150855  0.03967461  0.06257938
   -0.0465239   0.16279379 -0.07762902 -0.04399292  0.02082314 -0.03092512
    0.09511054  0.03825561 -0.00819511 -0.05088405  0.04832818 -0.09160014
   -0.05330603 -0.03978303 -0.02294822 -0.00972258  0.05345118 -0.01816027
    0.03803676  0.00100497  0.00191487  0.03435142  0.04726246  0.11757803
   -0.00181037  0.03581842 -0.0024432  -0.02303574  0.07061309  0.01187562
   -0.04441863  0.05266437  0.04181877 -0.05878706 -0.04855555 -0.06350133
   -0.03299243 -0.01356955 -0.03600622 -0.04127825 -0.00306196  0.04542384
   -0.06687518  0.01623251  0.02738215  0.04028849 -0.13371287 -0.03436777
    0.01196031  0.08260188  0.01801601  0.04497219  0.0083999  -0.02502269
   -0.09528486  0.0059416  -0.04917805  0.03168733 -0.01810231 -0.08919924
   -0.01429185  0.03935156  0.08881929 -0.02446716 -0.03041227 -0.0137907
    0.03606701  0.00747877  0.02400568 -0.01772161 -0.0320836   0.02545916
    0.02424652 -0.06051108  0.04617912 -0.06011712  0.09940548 -0.00614108
   -0.00476808  0.01495685 -0.10679526 -0.00090781 -0.10995323 -0.04735665
   -0.01744922  0.03900098 -0.08472252 -0.02429364  0.09803016 -0.03229028
   -0.00866475 -0.01495028  0.03388915  0.00619801  0.05917908 -0.04565361
   -0.08600922  0.00219294  0.01652196 -0.09889394 -0.03432318 -0.04302061
    0.01722571 -0.02334609 -0.01877556  0.06245402 -0.01382877 -0.03664995
    0.05074861  0.01130208  0.00685442 -0.03060116  0.00388928  0.01678797
    0.017054    0.00030668 -0.07179058  0.06701294  0.02194029  0.04345914
   -0.03525001  0.01731663 -0.04661174  0.01305942 -0.10335778  0.06357028
    0.00468454 -0.00618855  0.01474836 -0.03821694 -0.01621847 -0.03039201
   -0.02906956 -0.07590217  0.0101495   0.11014692  0.12324842  0.04710793
    0.02284801 -0.04139609 -0.0279863  -0.00569333]]]
After layer encoder_birnn_reverse_l0_t6_i2h_output (1, 1024) <class 'numpy.float32'> [[-0.0128371  -0.04095686  0.03787835 ...,  0.06970935 -0.04625846
   0.03761056]]
After layer encoder_birnn_reverse_l0_t6_h2h_output (1, 1024) <class 'numpy.float32'> [[-0.00099201  0.01633937 -0.07182207 ...,  0.07131833  0.04021711
   0.02216883]]
After layer _plus1042_0 (1, 1024) <class 'numpy.float32'> [[-0.01382911 -0.02461749 -0.03394372 ...,  0.14102767 -0.00604135
   0.05977938]]
After layer encoder_birnn_reverse_l0_t6_slice_output0 (1, 256) <class 'numpy.float32'> [[-0.01382911 -0.02461749 -0.03394372 -0.02483576  0.01330889 -0.02673566
   0.00925622  0.01158038  0.09899786  0.06716087 -0.04419808  0.10075204
   0.01069717  0.02320604 -0.00149888  0.29591325 -0.12396115 -0.08299425
   0.01241358 -0.0116279   0.10030319  0.00635137 -0.12441514 -0.0493219
   0.0678934  -0.12855121 -0.03413612 -0.01216732  0.00747079 -0.02138433
  -0.0034381  -0.01226452 -0.0549821  -0.04457793  0.07975438 -0.15372142
  -0.01617401 -0.01320409 -0.08500001 -0.07353291 -0.14378154  0.02505999
  -0.05118035  0.00291984  0.03089706 -0.01724889  0.06927343 -0.08419853
  -0.03982233  0.0265021   0.02136377  0.10729197 -0.14320563  0.07868676
   0.1776115   0.11573049 -0.07160268  0.01492018 -0.08167029 -0.01801551
   0.08401103 -0.05789497  0.15847802 -0.02793045 -0.11517939 -0.04240923
   0.10814951 -0.02325166 -0.09154066  0.00158855  0.10542898 -0.02089424
  -0.01423418 -0.02415314  0.01274104  0.05734126  0.12053061  0.16512448
   0.03450969  0.05486498  0.02356653  0.04685793  0.08847457 -0.02376667
   0.16751686  0.04232102 -0.02671117 -0.07474574 -0.01933645  0.06144794
   0.11473015 -0.00424577 -0.08524956  0.07910535  0.07102689  0.03582641
  -0.03037036  0.04554409 -0.11065003 -0.12808588 -0.11273179  0.07845062
   0.01501275 -0.12000309 -0.11314185  0.00886933 -0.02858718 -0.11068421
   0.06734894  0.01528673 -0.11034669  0.00174109  0.02987915  0.22530428
   0.01276339  0.30858031 -0.03213639  0.00755786  0.00319706 -0.05233384
   0.21425936 -0.12818477 -0.0027549   0.09890327 -0.07151085  0.06612931
  -0.13725643  0.07753454 -0.02814291  0.00748283  0.21591529  0.05438704
  -0.00881477 -0.04836601 -0.08200926 -0.09941143  0.11137458  0.16301718
  -0.01706541 -0.01385612 -0.04187521 -0.12512793  0.0928934   0.05801039
  -0.02410142 -0.0008085   0.03565398  0.06327052 -0.01242893  0.06618891
   0.12260152 -0.06595268 -0.00106943 -0.09406428 -0.09975759  0.19543831
   0.02816806  0.02646071 -0.0225658  -0.03189244  0.22545794  0.00346388
  -0.06780797  0.02237478  0.0069952  -0.07607321 -0.00180638 -0.05376688
   0.03580464 -0.04872205 -0.00599642  0.04392179  0.00168127  0.10320273
   0.02066591 -0.16255584  0.03815091 -0.1296473  -0.06017544 -0.02211573
   0.05030382 -0.07318186 -0.00736849  0.02498497  0.10007671 -0.0179718
  -0.01788457 -0.05775894  0.10079221  0.04095741 -0.04392893 -0.03943104
   0.03726683 -0.05234483 -0.01873216  0.08971703  0.10073853 -0.17314968
   0.0425203   0.08456792  0.00888766  0.10495267  0.07626001  0.06288105
   0.01410341 -0.0342793  -0.00839279 -0.05331585 -0.07510146  0.04216514
   0.04772501  0.11846459  0.02057492  0.05153686 -0.00469448  0.00254882
  -0.00698287 -0.02187976  0.03164257 -0.00246627 -0.06392593 -0.09854725
   0.09735289 -0.07853094  0.00353812  0.06345593 -0.03054036 -0.10231701
  -0.10871869  0.10188871 -0.01240689 -0.13355501 -0.02056865 -0.05365179
   0.0281844   0.06006901 -0.0056458   0.08225469  0.03141327 -0.03600718
  -0.11515566 -0.14468139  0.0935613   0.23818384 -0.06246611  0.01910183
  -0.09634206 -0.0788323   0.01372042 -0.00688087  0.16154817 -0.01158014
  -0.11456561  0.05106148  0.05450704 -0.0072224 ]]
After layer encoder_birnn_reverse_l0_t6_slice_output1 (1, 256) <class 'numpy.float32'> [[ 0.15382397  0.03662612  0.10735992  0.04541338  0.00614307  0.08093345
   0.19025053 -0.10097831  0.37722647  0.16725388  0.12227556  0.13679083
   0.12209427 -0.00490844  0.1244069   0.13735402  0.08808281 -0.03515493
  -0.15022489  0.07749622  0.13870704  0.01994985  0.4037168   0.06175905
   0.12339602  0.07656797  0.15823668  0.08219839  0.1223767   0.0404312
   0.08457035  0.03532793  0.23840362 -0.05737741 -0.01073442 -0.01985751
  -0.05708864  0.13582548  0.02350738  0.08963853 -0.07879764  0.1105278
   0.01601972  0.09760273  0.04043189  0.12028548  0.03521836 -0.12485926
  -0.00998618  0.02020393  0.07123075  0.09795652 -0.03486872  0.14992383
   0.06002249  0.05353916  0.05149849  0.10238054 -0.00397977 -0.10188335
   0.09485428  0.04040759  0.07299094  0.02930935 -0.02518739  0.14957139
   0.21344298  0.07473829 -0.14626335 -0.0467575   0.06937382  0.00141108
  -0.05199636  0.03900456  0.1088004   0.16531049  0.06675929  0.06577608
   0.09875318  0.09048238  0.22378884  0.18823972  0.03762826  0.03097885
   0.18154706 -0.00762379  0.09110834  0.17188448  0.03875388 -0.16333751
   0.32661593  0.08450751  0.08050342  0.07235106 -0.06479803  0.01197162
  -0.00379103  0.05646193 -0.17836621 -0.17879365 -0.07625539 -0.0072614
   0.0451462   0.10908402 -0.01840254 -0.03279776 -0.10871917  0.06441925
   0.09291561 -0.12296951  0.03913146 -0.02669161  0.06225583  0.21036159
   0.09755219  0.20028231  0.11824984  0.13473564  0.05517237  0.11361542
   0.20314957  0.17257077  0.04442169  0.01825871 -0.03092415 -0.0078339
   0.17876169 -0.00602962  0.1050798  -0.11092679  0.13213538  0.12260992
   0.01494776  0.17794584  0.05681036  0.04931489  0.02418765  0.06004561
   0.13702632  0.21768218 -0.07406919  0.04453264  0.07687119  0.03201187
   0.04627787  0.13187659  0.09430986  0.04273606  0.05123994 -0.02800554
  -0.02769162  0.07895802  0.04470274  0.10001702 -0.0106031   0.18642595
   0.09872669 -0.0470168   0.06320829  0.15473017  0.22813681  0.09061342
  -0.03320731  0.09386699  0.09286392 -0.01783472  0.28143576 -0.03014881
  -0.00670532 -0.02029425  0.02561752  0.13373998 -0.02089487  0.2126829
  -0.06057893  0.12673111  0.17250784 -0.02420904  0.01032338  0.11598226
   0.08299807 -0.07370394  0.24195144 -0.0361039  -0.00351995  0.03020992
   0.03422953  0.20362556 -0.04017583 -0.07041471 -0.03607661  0.04417893
   0.18355468  0.1583218  -0.12082396  0.00586917 -0.00437101 -0.0173024
   0.03198209  0.02220314  0.05653594  0.04537344  0.07748456 -0.02629321
   0.11397972 -0.14098543 -0.05076438  0.16549601 -0.07682484  0.10539649
   0.07997791  0.10625938 -0.05224558  0.03138407 -0.01370367 -0.09917999
   0.0623607   0.09984622 -0.02623331  0.12307139 -0.09886639 -0.08346732
   0.2581805   0.00992263  0.09486876 -0.00223474  0.02440582  0.05590764
   0.38847983  0.20253024  0.03808231 -0.28935045  0.15606798  0.0370471
   0.07232556 -0.00482503  0.00510296  0.08873545  0.05537078  0.09578896
   0.06759867  0.05387539  0.00573464  0.22024158 -0.15813191 -0.01500084
  -0.07835689 -0.05285263  0.11193773 -0.03059848  0.17624839 -0.18396579
   0.15712088 -0.00720531  0.13714908  0.0018778 ]]
After layer encoder_birnn_reverse_l0_t6_slice_output2 (1, 256) <class 'numpy.float32'> [[-0.16435938 -0.14923735 -0.03695257  0.05830752  0.01990909 -0.06271215
   0.01104292  0.06908444  0.0885991  -0.15155751 -0.08889952  0.19307902
   0.1042354  -0.0138399   0.0815399  -0.27432171  0.09078698  0.03189844
   0.10896184  0.06158153  0.26035652 -0.07930382 -0.02808633  0.04058426
  -0.13378605  0.03411664  0.0530756  -0.0589899  -0.16099855 -0.13519318
   0.04966581 -0.119387    0.00378358  0.00206443  0.13769002 -0.16804612
  -0.05884108  0.0067499  -0.12816021 -0.12142076  0.01800323 -0.22548769
   0.14090523  0.11394356  0.10217527 -0.13236327  0.06326579 -0.07124381
  -0.02121366 -0.1177687   0.07500287 -0.15314919 -0.07648697  0.20752381
  -0.00374177  0.01218913 -0.01399342  0.23298812  0.13906971 -0.05108086
  -0.13371181 -0.10308606 -0.01557889 -0.03764508  0.08993769 -0.04570449
   0.0310747  -0.12478969 -0.10856263  0.00954382 -0.3127569   0.03631163
   0.03117516  0.02408346  0.15455259 -0.01791986 -0.07327895 -0.25343749
  -0.09476351 -0.05670918 -0.15425679  0.00540433 -0.11377104 -0.20537852
  -0.31860638  0.00409351 -0.09285645  0.00625854 -0.23240137 -0.10743871
  -0.13831958 -0.06025024 -0.03390997  0.00895178 -0.05741035  0.0674253
   0.09650798 -0.04814113 -0.10527253 -0.12023085  0.00974567  0.16356999
  -0.07978272  0.0649323   0.07441121  0.21110642 -0.04914259 -0.03642997
   0.19143806 -0.22340313  0.14469916 -0.02291538  0.1160247   0.14093538
  -0.09140576  0.32301912 -0.20398799 -0.11292373  0.02415821 -0.07851615
   0.20671771  0.06298384 -0.00170737 -0.1210594   0.10040578 -0.204823
  -0.13870327 -0.09675114 -0.05455518 -0.02305941  0.13516033 -0.01559148
   0.08389465  0.00949425 -0.00228643  0.07896324  0.08142784  0.26407498
   0.00468137  0.08182584 -0.00243722 -0.04715743  0.16973455  0.02622347
  -0.09704469  0.12574354  0.10095946 -0.11318978 -0.1097492  -0.15754512
  -0.08204608 -0.02985407 -0.09925596 -0.0775236  -0.0042078   0.10066998
  -0.14969946  0.00349429  0.05916162  0.09222263 -0.29054722 -0.05944289
   0.02100522  0.16656773  0.0438338   0.10571451  0.00899852 -0.03546982
  -0.26434946  0.01148254 -0.1266571   0.08725861 -0.033647   -0.16847429
  -0.04479571  0.08356245  0.18671955 -0.06485058 -0.05592196 -0.01464587
   0.07926795  0.02697138  0.06214302 -0.04554252 -0.08785627  0.03505088
   0.06062704 -0.13322833  0.07712116 -0.13434318  0.254612   -0.00917647
  -0.0216542   0.05053796 -0.27546453  0.00121127 -0.26845211 -0.11949997
  -0.03436782  0.10741317 -0.20230576 -0.06202904  0.21109025 -0.06901798
  -0.02262884 -0.04100242  0.08676366  0.01621645  0.15759259 -0.07459293
  -0.2059439   0.00093929  0.0442712  -0.23022792 -0.08640921 -0.10888904
   0.04813952 -0.05371455 -0.06117689  0.15664013 -0.0280632  -0.08348314
   0.11552145  0.03670622  0.02665382 -0.07126793  0.01196874  0.03747635
  -0.00045599  0.02310416 -0.16163489  0.18657157  0.03136009  0.09369709
  -0.07447831  0.02543702 -0.09489527  0.03633887 -0.26022387  0.13425483
  -0.00778837  0.00164181  0.02683203 -0.05792517 -0.03790266 -0.04808533
  -0.07305748 -0.21300897  0.03415485  0.26524562  0.28553599  0.1174992
   0.02815946 -0.09145965 -0.0701548  -0.00320903]]
After layer encoder_birnn_reverse_l0_t6_slice_output3 (1, 256) <class 'numpy.float32'> [[  6.94775954e-02   5.60131297e-02  -1.51402848e-02   7.16424063e-02
    3.17958184e-02   2.03433514e-01   9.31342393e-02   1.18944794e-01
    4.21623319e-01   1.25866801e-01  -6.08844683e-02   7.19532818e-02
    1.67905986e-01  -4.14375626e-02   5.13075106e-02   1.29353002e-01
   -6.21111616e-02  -9.61175486e-02   3.92559171e-02  -1.32855736e-02
   -4.59481254e-02  -1.37472034e-01   2.83370078e-01   1.09568283e-01
    4.78584915e-02   6.84924275e-02  -1.85297281e-02  -1.81916878e-02
   -1.06653124e-01   1.28019042e-02   1.14255339e-01   1.00768149e-01
    3.61020193e-02   3.27308625e-02  -1.93417966e-02  -5.31685576e-02
    1.11103028e-01  -1.14345066e-02   6.49370998e-02  -2.67514549e-02
    6.44899383e-02  -2.77418122e-02  -2.92265974e-03   6.76272810e-03
   -3.27859372e-02   3.64877880e-02   2.87663601e-02  -8.25463012e-02
    2.44293213e-02   1.21124312e-01   8.41675028e-02  -1.25193372e-02
   -8.71534646e-02   5.60788959e-02   1.58457235e-01  -1.09075628e-01
    1.55555263e-01   2.80671716e-02   2.96110362e-02  -1.18393987e-01
    7.38383681e-02   8.41312408e-02   2.64083371e-02   1.72346205e-01
   -5.81270549e-03  -5.56508861e-02   2.09223509e-01   6.15817457e-02
   -9.69796628e-03   6.72313571e-02   1.62755065e-02   3.25552300e-02
    3.34974378e-04  -1.77055970e-02   1.28247529e-01   1.93324715e-01
    1.50241762e-01   4.02451828e-02   1.28779367e-01   2.16910541e-01
    1.81224734e-01   2.04557732e-01   1.08459771e-01   1.09271370e-01
    1.68733269e-01   5.28896861e-02   3.91206704e-02   8.50086808e-02
    8.28410685e-02   4.90862206e-02   1.69023544e-01  -4.80770171e-02
   -9.31349546e-02   2.71671824e-02   4.06725928e-02   2.97538564e-02
    5.74638322e-02   8.41652527e-02  -1.47164732e-01  -1.20209172e-01
   -6.07340634e-02  -1.49382591e-01  -8.56140107e-02  -9.41214487e-02
   -2.76047252e-02   6.75600767e-03  -4.14686501e-02   1.30817935e-01
    6.25604317e-02   1.19315162e-01   1.66281909e-02   5.75077720e-02
   -9.00840312e-02   1.47580594e-01  -1.02473050e-03   1.57758415e-01
   -7.53494352e-02  -2.93237381e-02   4.81650606e-02  -5.57371899e-02
    3.13614123e-02   9.51096043e-02   8.12563896e-02   9.65863466e-04
   -6.26094267e-02   3.71824615e-02  -3.95509042e-03   1.79047883e-03
   -1.81420222e-02  -1.10439658e-01   2.07536593e-02   1.84832200e-01
   -2.33583748e-02   1.06955372e-01   4.86916155e-02  -8.31590444e-02
    1.38011932e-01   5.57368025e-02   1.30022615e-01   3.59840021e-02
    1.93196088e-02  -8.56224820e-03  -7.17942864e-02   8.16409141e-02
   -9.84588172e-03   2.91473866e-02   1.69323638e-01   7.78700635e-02
    3.25708501e-02  -1.78944729e-02  -2.26858854e-02  -3.01010590e-02
    8.03781152e-02   1.37657300e-01  -1.79169215e-02   7.45884255e-02
    1.07206866e-01   9.54897553e-02   4.00677137e-02   1.42390653e-01
    8.35781023e-02   3.81542556e-02  -2.96229124e-03   1.38817102e-01
    8.49249959e-02  -8.41669738e-02   2.85396814e-01   1.14514075e-01
   -1.43361762e-01   2.27200314e-02  -1.16192490e-01   1.20058492e-01
    9.42303538e-02   2.15708554e-01   1.04108267e-02   1.81230307e-01
    1.54542357e-01  -6.71232641e-02   7.18968585e-02  -1.84326619e-02
   -1.25420362e-01  -8.22995082e-02   5.41700758e-02  -8.70961174e-02
   -6.44759908e-02   1.48074105e-01  -2.67825555e-02   1.12640068e-01
   -3.62420157e-02  -1.20320246e-01   1.37497410e-02   1.45772696e-01
    5.51758111e-02   2.38910168e-02  -2.39305049e-02   6.50118068e-02
   -3.44215892e-02   4.49057519e-02   1.18555687e-01   2.49114558e-02
    8.32594037e-02   2.17034757e-01   9.32585299e-02   1.57091498e-01
    9.45011228e-02   9.38550383e-02  -8.39092806e-02   5.43552488e-02
   -1.09013841e-01   1.75410017e-01   1.46790594e-03   3.05676967e-01
    6.86921030e-02   1.62210226e-01   1.06138453e-01  -6.21147603e-02
    5.75412065e-02   2.08044142e-01  -3.45387682e-02  -5.61286360e-02
   -3.67313474e-02  -1.54150799e-01   1.62357897e-01   3.00010219e-02
    7.30172396e-02   1.02152497e-01  -1.67853758e-03   4.31338474e-02
    3.41868252e-01   1.73693463e-01   1.31804990e-02  -1.56328559e-01
   -2.99418550e-02   7.52262399e-03  -2.03540232e-02   2.86087207e-02
   -2.94736493e-02   8.28408226e-02   1.17637038e-01   4.26479131e-02
   -1.52181089e-01   8.80596191e-02   8.01097304e-02   3.23492944e-01
   -1.44459262e-01   6.07748218e-02   3.79907340e-03  -1.41994685e-01
    4.14714590e-02  -2.28240751e-02   1.13822736e-01  -9.57353264e-02
    1.12070084e-01   1.41027674e-01  -6.04134798e-03   5.97793832e-02]]
After layer encoder_birnn_reverse_l0_t6_o_output (1, 256) <class 'numpy.float32'> [[ 0.51736242  0.51399964  0.49621502  0.51790291  0.50794828  0.55068374
   0.52326673  0.52970123  0.60387164  0.53142524  0.48478359  0.51798058
   0.54187816  0.48964208  0.51282406  0.5322932   0.48447719  0.4759891
   0.50981271  0.49667862  0.48851502  0.46568602  0.57037228  0.52736473
   0.51196235  0.51711643  0.49536771  0.4954522   0.47336194  0.50320047
   0.5285328   0.52517074  0.5090245   0.50818199  0.49516469  0.486711
   0.52774721  0.49714142  0.51622856  0.49331254  0.51611692  0.49306497
   0.49926937  0.50169069  0.49180421  0.50912094  0.50719112  0.47937509
   0.50610703  0.53024411  0.52102947  0.49687022  0.47822544  0.51401609
   0.53953165  0.47275808  0.53881061  0.50701636  0.50740224  0.47043601
   0.51845121  0.52102041  0.50660169  0.54298025  0.49854678  0.48609087
   0.55211586  0.51539057  0.49757552  0.51680154  0.50406879  0.50813812
   0.50008374  0.49557373  0.53201801  0.54818124  0.53748995  0.51005995
   0.53215045  0.55401599  0.54518259  0.55096185  0.5270884   0.5272907
   0.5420835   0.51321936  0.50977892  0.5212394   0.52069843  0.51226908
   0.54215556  0.48798305  0.47673306  0.50679135  0.51016676  0.50743794
   0.51436198  0.52102888  0.46327507  0.46998385  0.48482114  0.46272367
   0.47860956  0.47648701  0.49309921  0.50168896  0.48963431  0.53265792
   0.51563501  0.5297935   0.50415695  0.514373    0.47749421  0.53682834
   0.49974382  0.53935802  0.48117155  0.49266958  0.51203895  0.48606935
   0.50783968  0.52375948  0.52030295  0.50024146  0.48435274  0.50929457
   0.49901122  0.50044763  0.49546459  0.47241813  0.50518823  0.54607695
   0.49416068  0.52671337  0.51217049  0.47922218  0.53444833  0.51393062
   0.53245991  0.508995    0.50482976  0.49785945  0.48205915  0.52039891
   0.4975386   0.50728631  0.54223007  0.5194577   0.50814199  0.49552652
   0.49432877  0.49247533  0.52008373  0.53436011  0.49552092  0.51863849
   0.52677608  0.52385432  0.51001561  0.53553766  0.52088243  0.5095374
   0.49925938  0.5346486   0.52121848  0.47897068  0.57086885  0.52859724
   0.46422085  0.50567979  0.47098452  0.52997863  0.5235402   0.55371898
   0.5026027   0.54518396  0.53855884  0.48322549  0.51796645  0.49539196
   0.46868595  0.4794367   0.51353925  0.47823974  0.4838866   0.53695107
   0.49330476  0.52813029  0.49094051  0.46995613  0.5034374   0.5363788
   0.51379043  0.50597245  0.49401769  0.51624727  0.49139547  0.51122457
   0.52960426  0.50622755  0.52080286  0.55404669  0.52329773  0.53919232
   0.52360773  0.52344656  0.47903499  0.51358551  0.47277352  0.54374039
   0.50036699  0.57582974  0.51716632  0.54046386  0.52650976  0.48447627
   0.51438135  0.55182421  0.49136615  0.48597151  0.49081817  0.4615384
   0.54050052  0.50749969  0.51824623  0.52551591  0.49958038  0.51078176
   0.58464426  0.54331452  0.50329506  0.46099722  0.49251512  0.50188065
   0.49491164  0.50715166  0.49263209  0.52069837  0.52937537  0.51066035
   0.462028    0.52200067  0.52001673  0.58017528  0.46394786  0.51518905
   0.5009498   0.46456087  0.51036638  0.49429423  0.52842498  0.47608444
   0.5279882   0.53519863  0.49848968  0.51494044]]
After layer encoder_birnn_reverse_l0_t6_f_output (1, 256) <class 'numpy.float32'> [[ 0.53838032  0.50915551  0.52681422  0.51135141  0.50153577  0.52022231
   0.54741973  0.47477683  0.59320402  0.54171628  0.53053087  0.53414452
   0.53048575  0.49877289  0.53106171  0.53428465  0.52200651  0.49121216
   0.46251425  0.51936436  0.53462124  0.5049873   0.59958035  0.51543486
   0.53080994  0.51913267  0.53947681  0.52053803  0.53055608  0.51010638
   0.52113003  0.50883102  0.55932021  0.4856596   0.49731642  0.49503577
   0.48573172  0.53390425  0.5058766   0.52239466  0.48031074  0.52760386
   0.50400484  0.52438134  0.51010656  0.5300352   0.50880367  0.4688257
   0.49750346  0.50505078  0.51780015  0.52446955  0.49128368  0.53741091
   0.51500112  0.5133816   0.5128718   0.52557284  0.49900505  0.47455114
   0.52369583  0.51010048  0.51823968  0.50732678  0.49370351  0.5373233
   0.55315912  0.51867586  0.46349922  0.48831278  0.51733649  0.5003528
   0.48700383  0.50974995  0.52717328  0.54123378  0.51668364  0.51643813
   0.52466828  0.52260518  0.55571491  0.54692143  0.50940597  0.50774413
   0.54526258  0.49809405  0.52276134  0.54286563  0.50968724  0.45925617
   0.58093578  0.52111435  0.52011496  0.51807994  0.48380613  0.50299287
   0.49905223  0.51411176  0.45552629  0.45542026  0.48094538  0.49818462
   0.51128465  0.52724397  0.49539953  0.49180132  0.47284698  0.51609927
   0.52321219  0.46929634  0.5097816   0.4933275   0.51555896  0.55239731
   0.52436876  0.54990387  0.52952808  0.53363305  0.51378959  0.5283733
   0.55061346  0.54303592  0.51110363  0.50456458  0.49226955  0.49804151
   0.54457182  0.49849263  0.52624583  0.47229674  0.53298587  0.53061414
   0.50373685  0.54436946  0.51419878  0.51232618  0.50604659  0.5150069
   0.53420305  0.55420667  0.48149115  0.51113135  0.51920831  0.50800228
   0.51156741  0.53292143  0.52356005  0.5106824   0.51280719  0.49299908
   0.49307755  0.51972926  0.51117384  0.52498347  0.49734926  0.54647195
   0.52466166  0.48824796  0.51579684  0.53860557  0.55678815  0.52263784
   0.49169892  0.52344954  0.52319932  0.49554139  0.56989819  0.49246335
   0.49832365  0.4949266   0.50640404  0.53338528  0.49477643  0.55297118
   0.48485991  0.53164047  0.54302031  0.49394804  0.50258082  0.52896309
   0.52073759  0.48158237  0.56019449  0.49097499  0.49912     0.50755191
   0.50855654  0.55073124  0.48995742  0.48240355  0.49098182  0.51104295
   0.54576027  0.53949797  0.46983069  0.50146729  0.49890721  0.49567452
   0.50799483  0.50555056  0.51413023  0.51134139  0.5193615   0.4934271
   0.52846414  0.46481189  0.48731163  0.54127985  0.48080319  0.52632475
   0.51998383  0.52653986  0.48694158  0.50784534  0.49657413  0.47522527
   0.51558512  0.52494085  0.49344206  0.53072906  0.47530353  0.47914526
   0.56418896  0.50248063  0.5236994   0.4994413   0.50610113  0.51397324
   0.59591669  0.55046022  0.5095194   0.42816287  0.53893805  0.50926071
   0.5180735   0.49879378  0.50127572  0.52216929  0.51383913  0.52392894
   0.51689321  0.51346558  0.50143367  0.5548389   0.46054921  0.49624988
   0.48042077  0.48678991  0.52795523  0.49235097  0.54394841  0.4541378
   0.53919965  0.49819872  0.53423363  0.50046945]]
After layer _mul2084_0 (1, 256) <class 'numpy.float32'> [[-0.08257206 -0.06737078 -0.00895174  0.0220854   0.01844303 -0.0307173
   0.01799589  0.03661149  0.04037513 -0.06389163 -0.04213522  0.08071847
   0.05026559 -0.01352299  0.0374253  -0.14034025  0.03404577  0.01133056
   0.03850427  0.02800846  0.11915632 -0.03096839 -0.00380555  0.02900083
  -0.06365004  0.01682948  0.02732839 -0.02576113 -0.07709567 -0.05624559
   0.02250068 -0.06062778 -0.00396558  0.00228044  0.05895641 -0.06865713
  -0.02936306 -0.00310073 -0.05804349 -0.05235481  0.01245299 -0.10375194
   0.06112432  0.04974912  0.04748481 -0.06161136  0.02384508 -0.0297469
  -0.00687313 -0.04918475  0.03404205 -0.06965069 -0.03650145  0.08334282
   0.01547763  0.0108355  -0.01546036  0.10372586  0.05030695 -0.02251343
  -0.05432148 -0.04880628 -0.0132121  -0.0112025   0.03471429 -0.02096388
   0.02340415 -0.05297844 -0.04541876 -0.00374703 -0.14080389  0.00980762
   0.02271935  0.01210269  0.07207672 -0.02036636 -0.02855618 -0.10885721
  -0.03838824 -0.02321989 -0.07216264  0.00734962 -0.04781831 -0.08596627
  -0.15652786  0.0061245  -0.06069364  0.01440553 -0.09269711 -0.05064296
  -0.07346464 -0.03020347 -0.01424601 -0.00400648 -0.02436875  0.0256052
   0.04540157 -0.02524613 -0.04157551 -0.03647065  0.0098422   0.07172383
  -0.03696185  0.02590381  0.02780628  0.07812166 -0.02022021 -0.02170943
   0.08646969 -0.0868303   0.05129537 -0.00144757  0.042797    0.06495627
  -0.048816    0.17183118 -0.0863523  -0.04767396  0.02077292 -0.03367415
   0.10451306  0.03980626 -0.00803337 -0.05138276  0.0490387  -0.09068973
  -0.05860473 -0.03982634 -0.02444524 -0.0096455   0.05667692 -0.01764885
   0.03879224  0.00104273  0.00192604  0.03662161  0.04505756  0.11981325
  -0.0018238   0.03918504 -0.00233437 -0.02362189  0.07684851  0.01164866
  -0.04564038  0.05561601  0.04075195 -0.05843741 -0.04906834 -0.06345456
  -0.03298258 -0.01432302 -0.03563258 -0.04071974 -0.00304926  0.04789446
  -0.06737456  0.01505669  0.02769976  0.04074251 -0.14656296 -0.03544242
   0.01183483  0.08152284  0.01811651  0.04645242  0.00846439 -0.02339539
  -0.1029292   0.00581814 -0.05272171  0.03211205 -0.017186   -0.09047125
  -0.01372862  0.03860294  0.09056421 -0.02493385 -0.02942492 -0.01470357
   0.03992988  0.00746328  0.0263084  -0.01805785 -0.03295893  0.02430155
   0.02496616 -0.0636381   0.04574298 -0.0614687   0.09798725 -0.00586213
  -0.00507594  0.01601361 -0.10141743 -0.00088372 -0.11332969 -0.04595282
  -0.01679757  0.03920859 -0.0846491  -0.02243412  0.09860281 -0.02969088
  -0.00876222 -0.01328845  0.03437821  0.00655623  0.06008995 -0.04448347
  -0.09051631  0.00201162  0.01565435 -0.09441037 -0.03255527 -0.04208064
   0.01725922 -0.02240616 -0.01886074  0.06849103 -0.01342706 -0.03769624
   0.05343772  0.01119788  0.0069353  -0.02914067  0.00392978  0.01695878
   0.01758392  0.00030925 -0.07310434  0.06205255  0.02399873  0.04427614
  -0.03696389  0.01707736 -0.04764669  0.01313945 -0.10195822  0.06583261
   0.00516435 -0.00609948  0.01412912 -0.03664909 -0.01595703 -0.02933667
  -0.02764747 -0.0797576   0.01051901  0.11104719  0.12981631  0.04486689
   0.02344323 -0.03868553 -0.03005716 -0.00552397]]
After layer encoder_birnn_reverse_l0_t6_i_output (1, 256) <class 'numpy.float32'> [[ 0.49654281  0.49384597  0.49151489  0.49379137  0.50332719  0.49331647
   0.50231403  0.50289512  0.52472931  0.51678389  0.48895228  0.52516675
   0.50267428  0.50580126  0.49962524  0.57344317  0.46904933  0.47926337
   0.50310338  0.49709302  0.52505475  0.50158781  0.46893629  0.487672
   0.51696682  0.46790639  0.49146679  0.49695823  0.50186771  0.49465415
   0.49914044  0.49693391  0.48625794  0.48885733  0.51992804  0.46164519
   0.4959566   0.49669904  0.47876281  0.48162505  0.46411642  0.50626469
   0.48720771  0.50072998  0.50772363  0.49568793  0.51731145  0.47896278
   0.49004576  0.50662518  0.50534075  0.52679729  0.46425968  0.51966155
   0.54428649  0.52890033  0.48210695  0.50372994  0.47959375  0.49549621
   0.52099043  0.48553029  0.53953677  0.49301785  0.47123697  0.48939928
   0.52701104  0.4941873   0.47713077  0.50039715  0.52633286  0.49477661
   0.49644154  0.49396202  0.50318521  0.5143314   0.53009629  0.54118758
   0.50862658  0.51371282  0.50589138  0.51171237  0.52210426  0.49405858
   0.5417816   0.51057869  0.49332264  0.48132229  0.49516603  0.51535714
   0.52865112  0.49893856  0.47870052  0.51976603  0.51774925  0.50895566
   0.49240804  0.51138407  0.47236568  0.46802226  0.47184682  0.5196026
   0.50375313  0.4700352   0.47174466  0.50221729  0.49285367  0.47235718
   0.51683086  0.50382161  0.47244129  0.50043529  0.50746924  0.55608898
   0.50319082  0.57653868  0.49196661  0.50188947  0.50079924  0.48691949
   0.55336088  0.46799761  0.49931127  0.52470565  0.4821299   0.51652634
   0.46573964  0.51937395  0.49296477  0.50187069  0.55377012  0.51359344
   0.49779627  0.48791084  0.47950915  0.47516754  0.52781487  0.54066432
   0.49573374  0.49653605  0.48953271  0.46875876  0.52320665  0.51449853
   0.49397492  0.49979791  0.50891256  0.51581234  0.49689281  0.51654118
   0.53061205  0.48351777  0.49973264  0.47650123  0.47508126  0.54870468
   0.50704157  0.5066148   0.49435878  0.49202761  0.55612695  0.500866
   0.48305446  0.50559348  0.5017488   0.48099089  0.49954838  0.48656148
   0.50895023  0.48782185  0.49850091  0.51097864  0.50042033  0.52577782
   0.50516629  0.45945027  0.50953662  0.46763349  0.48496068  0.49447125
   0.5125733   0.48171267  0.49815789  0.50624591  0.52499831  0.49550721
   0.495529    0.48556426  0.5251767   0.51023787  0.48901954  0.49014351
   0.50931561  0.48691678  0.4953171   0.52241421  0.52516335  0.45682043
   0.51062852  0.52112943  0.50222188  0.52621412  0.51905578  0.51571506
   0.50352579  0.49143106  0.49790183  0.48667416  0.48123348  0.51053971
   0.51192904  0.52958155  0.50514358  0.5128814   0.49882641  0.50063723
   0.49825427  0.49453026  0.50791001  0.49938345  0.48402399  0.47538307
   0.52431899  0.48037732  0.50088453  0.51585865  0.49236548  0.47444302
   0.47284707  0.52545017  0.49689835  0.46666077  0.494858    0.48659027
   0.50704569  0.51501274  0.4985885   0.5205521   0.50785267  0.49099916
   0.47124285  0.46389261  0.52337325  0.55926603  0.48438856  0.50477535
   0.47593307  0.48030213  0.50343007  0.49827978  0.54029942  0.497105
   0.47138986  0.51276261  0.51362336  0.49819446]]
After layer encoder_birnn_reverse_l0_t6_c_output (1, 256) <class 'numpy.float32'> [[-0.1628952  -0.14813921 -0.03693577  0.05824154  0.01990646 -0.06263006
   0.01104247  0.06897475  0.088368   -0.15040767 -0.08866607  0.19071499
   0.10385953 -0.01383902  0.08135967 -0.26764157  0.09053837  0.03188762
   0.10853265  0.06150381  0.25462896 -0.079138   -0.02807894  0.04056199
  -0.13299353  0.03410341  0.05302582 -0.05892157 -0.15962178 -0.13437551
   0.04962501 -0.118823    0.00378357  0.00206442  0.13682644 -0.16648194
  -0.05877326  0.0067498  -0.12746312 -0.12082756  0.01800128 -0.22174223
   0.13998006  0.113453    0.10182118 -0.13159566  0.06318151 -0.07112352
  -0.02121048 -0.11722725  0.07486255 -0.15196297 -0.07633817  0.20459516
  -0.00374175  0.01218852 -0.01399251  0.22886188  0.13818003 -0.05103648
  -0.13292061 -0.10272245 -0.01557763 -0.03762731  0.08969598 -0.0456727
   0.0310647  -0.12414595 -0.10813814  0.00954353 -0.30294305  0.03629568
   0.03116506  0.02407881  0.15333366 -0.01791794 -0.07314806 -0.24814722
  -0.09448086 -0.05664847 -0.1530448   0.00540428 -0.11328269 -0.20253877
  -0.30824625  0.00409348 -0.09259049  0.00625846 -0.2283058  -0.10702722
  -0.13744417 -0.06017744 -0.03389698  0.00895154 -0.05734736  0.06732331
   0.09620947 -0.04810397 -0.10488536 -0.11965486  0.00974536  0.16212666
  -0.07961388  0.0648412   0.07427418  0.20802529 -0.04910307 -0.03641386
   0.18913321 -0.21975926  0.14369765 -0.02291137  0.11550687  0.14000961
  -0.09115205  0.31223425 -0.20120491 -0.11244617  0.02415351 -0.0783552
   0.20382269  0.06290069 -0.00170737 -0.12047146  0.10006973 -0.202006
  -0.13782059 -0.09645038 -0.05450112 -0.02305533  0.13434325 -0.01559022
   0.08369838  0.00949397 -0.00228643  0.07879954  0.08124835  0.25810304
   0.00468134  0.08164371 -0.00243721 -0.0471225   0.16812313  0.02621746
  -0.09674119  0.12508498  0.10061784 -0.11270885 -0.10931067 -0.15625449
  -0.08186247 -0.0298452  -0.0989313  -0.07736867 -0.00420777  0.10033128
  -0.14859115  0.00349427  0.05909269  0.09196207 -0.2826384  -0.05937297
   0.02100213  0.16504417  0.04380575  0.10532247  0.00899827 -0.03545495
  -0.25835919  0.01148204 -0.12598415  0.08703782 -0.03363431 -0.16689822
  -0.04476577  0.0833685   0.18457946 -0.06475983 -0.05586374 -0.01464483
   0.07910234  0.02696484  0.06206315 -0.04551106 -0.08763092  0.03503654
   0.06055287 -0.13244563  0.07696863 -0.13354076  0.24924909 -0.00917622
  -0.02165082  0.05049498 -0.26870224  0.00121127 -0.26218393 -0.11893437
  -0.0343543   0.10700198 -0.19959025 -0.06194961  0.20800982 -0.06890859
  -0.02262498 -0.04097945  0.0865466   0.01621502  0.1563008  -0.07445489
  -0.20308091  0.00093929  0.0442423  -0.22624461 -0.08619479 -0.10846071
   0.04810237 -0.05366296 -0.06110068  0.15537147 -0.02805583 -0.08328974
   0.11501029  0.03668974  0.0266475  -0.07114752  0.01196817  0.03745881
  -0.00045599  0.02310005 -0.16024184  0.18443651  0.03134981  0.09342385
  -0.07434091  0.02543153 -0.09461145  0.03632288 -0.25450492  0.13345398
  -0.00778822  0.00164181  0.02682559 -0.05786047 -0.03788452 -0.04804831
  -0.07292778 -0.20984478  0.03414157  0.25919536  0.27802098  0.11696144
   0.02815202 -0.09120549 -0.07003994 -0.00320902]]
After layer _mul2085_0 (1, 256) <class 'numpy.float32'> [[-0.08088444 -0.07315795 -0.01815448  0.02875917  0.01001946 -0.03089644
   0.00554679  0.03468706  0.04636928 -0.07772826 -0.04335348  0.10015717
   0.05220751 -0.00699979  0.04064934 -0.15347724  0.04246696  0.01528257
   0.05460314  0.03057311  0.13369414 -0.03969466 -0.01316724  0.01978095
  -0.06875324  0.0159572   0.02606043 -0.02928156 -0.08010902 -0.0664694
   0.02476985 -0.05904718  0.00183979  0.00100921  0.0711399  -0.07685558
  -0.02914899  0.00335262 -0.0610246  -0.05819358  0.00835469 -0.11226026
   0.06819937  0.05680932  0.05169702 -0.06523038  0.03268452 -0.03406552
  -0.0103941  -0.05939028  0.0378311  -0.08005368 -0.03544074  0.10632024
  -0.00203659  0.00644651 -0.00674588  0.11528458  0.06627028 -0.02528838
  -0.06925037 -0.04987486 -0.00840471 -0.01855093  0.04226806 -0.02235219
   0.01637144 -0.06135135 -0.05159603  0.00477556 -0.15944888  0.01795825
   0.01547163  0.01189402  0.07715523 -0.00921576 -0.03877552 -0.1342942
  -0.04805548 -0.02910105 -0.07742405  0.00276544 -0.05914538 -0.10006602
  -0.16700216  0.00209005 -0.04567698  0.00301234 -0.11304928 -0.05515724
  -0.07266001 -0.03002485 -0.0162265   0.00465271 -0.02969155  0.03426458
   0.04737432 -0.0245996  -0.04954425 -0.05600113  0.00459832  0.08424143
  -0.04010574  0.03047765  0.03503845  0.1044739  -0.02420063 -0.01720035
   0.09774988 -0.11071946  0.0678887  -0.01146566  0.05861618  0.0778578
  -0.04586687  0.18001513 -0.0989861  -0.05643555  0.01209606 -0.03815268
   0.1127875   0.02943737 -0.00085251 -0.06321205  0.04824661 -0.10434142
  -0.06418851 -0.05009381 -0.02686713 -0.01157079  0.07439528 -0.00800703
   0.04166474  0.00463221 -0.00109636  0.03744298  0.04288409  0.13954711
   0.0023207   0.04053904 -0.0011931  -0.02208909  0.08796313  0.01348885
  -0.04778772  0.06251721  0.05120568 -0.05813662 -0.05431569 -0.08071188
  -0.04343721 -0.01443068 -0.0494392  -0.03686627 -0.00199903  0.05505224
  -0.07534189  0.00177025  0.02921299  0.04524788 -0.15718283 -0.0297379
   0.01014517  0.08344526  0.02197948  0.05065915  0.00449507 -0.01725101
  -0.13149197  0.00560119 -0.06280321  0.04447447 -0.01683129 -0.08775138
  -0.02261416  0.03830368  0.09405    -0.03028386 -0.02709172 -0.00724145
   0.04054575  0.0129893   0.03091725 -0.02303979 -0.04600608  0.01736086
   0.0300057  -0.06431086  0.04042213 -0.06813756  0.12188768 -0.00449766
  -0.0110271   0.02458685 -0.13309282  0.00063278 -0.1376894  -0.05433165
  -0.01754229  0.05576188 -0.10023859 -0.03259876  0.1079687  -0.0355372
  -0.01139226 -0.02013857  0.04309171  0.00789143  0.07521718 -0.03801218
  -0.10396301  0.00049743  0.02234871 -0.11603665 -0.04299624 -0.05429947
   0.02396721 -0.02653795 -0.03103365  0.07758994 -0.0135797  -0.03959453
   0.06030208  0.01762492  0.01334732 -0.03670206  0.00589271  0.01777207
  -0.00021562  0.01213793 -0.07962391  0.08606929  0.0155137   0.04545914
  -0.03769424  0.01309756 -0.04717218  0.01890795 -0.129251    0.06552579
  -0.00367014  0.00076162  0.01403979 -0.0323594  -0.01835083 -0.0242536
  -0.03470874 -0.1007889   0.0171879   0.12915181  0.15021457  0.05814212
   0.01327057 -0.04676677 -0.03597414 -0.00159872]]
After layer encoder_birnn_reverse_l0_t6_state_0 (1, 256) <class 'numpy.float32'> [[ -1.63456500e-01  -1.40528738e-01  -2.71062218e-02   5.08445725e-02
    2.84624938e-02  -6.16137460e-02   2.35426798e-02   7.12985545e-02
    8.67444128e-02  -1.41619891e-01  -8.54886919e-02   1.80875629e-01
    1.02473103e-01  -2.05227863e-02   7.80746490e-02  -2.93817490e-01
    7.65127316e-02   2.66131237e-02   9.31074172e-02   5.85815683e-02
    2.52850473e-01  -7.06630424e-02  -1.69727821e-02   4.87817824e-02
   -1.32403284e-01   3.27866860e-02   5.33888154e-02  -5.50426841e-02
   -1.57204688e-01  -1.22714996e-01   4.72705290e-02  -1.19674966e-01
   -2.12579360e-03   3.28965252e-03   1.30096316e-01  -1.45512715e-01
   -5.85120507e-02   2.51892488e-04  -1.19068086e-01  -1.10548392e-01
    2.08076816e-02  -2.16012210e-01   1.29323691e-01   1.06558442e-01
    9.91818309e-02  -1.26841739e-01   5.65295964e-02  -6.38124198e-02
   -1.72672346e-02  -1.08575031e-01   7.18731433e-02  -1.49704367e-01
   -7.19421878e-02   1.89663053e-01   1.34410448e-02   1.72820091e-02
   -2.22062469e-02   2.19010442e-01   1.16577223e-01  -4.78018150e-02
   -1.23571843e-01  -9.86811370e-02  -2.16168053e-02  -2.97534335e-02
    7.69823492e-02  -4.33160625e-02   3.97755876e-02  -1.14329800e-01
   -9.70147923e-02   1.02852867e-03  -3.00252765e-01   2.77658757e-02
    3.81909795e-02   2.39967108e-02   1.49231941e-01  -2.95821205e-02
   -6.73316941e-02  -2.43151397e-01  -8.64437222e-02  -5.23209348e-02
   -1.49586678e-01   1.01150600e-02  -1.06963687e-01  -1.86032295e-01
   -3.23530018e-01   8.21454730e-03  -1.06370628e-01   1.74178630e-02
   -2.05746382e-01  -1.05800197e-01  -1.46124661e-01  -6.02283180e-02
   -3.04725170e-02   6.46229368e-04  -5.40602989e-02   5.98697811e-02
    9.27758887e-02  -4.98457402e-02  -9.11197513e-02  -9.24717858e-02
    1.44405160e-02   1.55965269e-01  -7.70675912e-02   5.63814566e-02
    6.28447235e-02   1.82595551e-01  -4.44208309e-02  -3.89097854e-02
    1.84219569e-01  -1.97549760e-01   1.19184062e-01  -1.29132234e-02
    1.01413175e-01   1.42814070e-01  -9.46828723e-02   3.51846308e-01
   -1.85338408e-01  -1.04109511e-01   3.28689776e-02  -7.18268231e-02
    2.17300564e-01   6.92436323e-02  -8.88587907e-03  -1.14594817e-01
    9.72853079e-02  -1.95031151e-01  -1.22793242e-01  -8.99201632e-02
   -5.13123795e-02  -2.12162919e-02   1.31072193e-01  -2.56558843e-02
    8.04569721e-02   5.67493821e-03   8.29678844e-04   7.40645900e-02
    8.79416466e-02   2.59360373e-01   4.96895169e-04   7.97240883e-02
   -3.52746435e-03  -4.57109734e-02   1.64811641e-01   2.51375027e-02
   -9.34281051e-02   1.18133225e-01   9.19576287e-02  -1.16574034e-01
   -1.03384018e-01  -1.44166440e-01  -7.64197931e-02  -2.87537035e-02
   -8.50717798e-02  -7.75860101e-02  -5.04829036e-03   1.02946706e-01
   -1.42716438e-01   1.68269407e-02   5.69127537e-02   8.59903917e-02
   -3.03745806e-01  -6.51803166e-02   2.19800025e-02   1.64968103e-01
    4.00959887e-02   9.71115679e-02   1.29594645e-02  -4.06464040e-02
   -2.34421164e-01   1.14193344e-02  -1.15524918e-01   7.65865147e-02
   -3.40172946e-02  -1.78222626e-01  -3.63427773e-02   7.69066215e-02
    1.84614211e-01  -5.52177206e-02  -5.65166399e-02  -2.19450202e-02
    8.04756284e-02   2.04525869e-02   5.72256520e-02  -4.10976410e-02
   -7.89650083e-02   4.16624099e-02   5.49718589e-02  -1.27948970e-01
    8.61651152e-02  -1.29606247e-01   2.19874918e-01  -1.03597967e-02
   -1.61030442e-02   4.06004563e-02  -2.34510243e-01  -2.50934972e-04
   -2.51019090e-01  -1.00284465e-01  -3.43398526e-02   9.49704647e-02
   -1.84887692e-01  -5.50328791e-02   2.06571519e-01  -6.52280822e-02
   -2.01544780e-02  -3.34270261e-02   7.74699226e-02   1.44476630e-02
    1.35307133e-01  -8.24956447e-02  -1.94479316e-01   2.50905240e-03
    3.80030647e-02  -2.10447028e-01  -7.55515099e-02  -9.63801146e-02
    4.12264317e-02  -4.89441156e-02  -4.98943925e-02   1.46080971e-01
   -2.70067528e-02  -7.72907734e-02   1.13739803e-01   2.88228001e-02
    2.02826224e-02  -6.58427328e-02   9.82248783e-03   3.47308591e-02
    1.73683036e-02   1.24471737e-02  -1.52728260e-01   1.48121834e-01
    3.95124294e-02   8.97352844e-02  -7.46581256e-02   3.01749185e-02
   -9.48188677e-02   3.20473984e-02  -2.31209219e-01   1.31358400e-01
    1.49420719e-03  -5.33785438e-03   2.81689130e-02  -6.90084845e-02
   -3.43078598e-02  -5.35902753e-02  -6.23562150e-02  -1.80546492e-01
    2.77069043e-02   2.40199000e-01   2.80030876e-01   1.03009008e-01
    3.67138013e-02  -8.54522884e-02  -6.60313070e-02  -7.12268660e-03]]
After layer activation1042_output (1, 256) <class 'numpy.float32'> [[ -1.62016153e-01  -1.39610931e-01  -2.70995852e-02   5.08008040e-02
    2.84548104e-02  -6.15358986e-02   2.35383306e-02   7.11779892e-02
    8.65274966e-02  -1.40680641e-01  -8.52810442e-02   1.78928599e-01
    1.02115922e-01  -2.05199048e-02   7.79163986e-02  -2.85644621e-01
    7.63637722e-02   2.66068429e-02   9.28393006e-02   5.85146472e-02
    2.47596264e-01  -7.05456659e-02  -1.69711523e-02   4.87431251e-02
   -1.31634966e-01   3.27749439e-02   5.33381477e-02  -5.49871661e-02
   -1.55922353e-01  -1.22102700e-01   4.72353511e-02  -1.19106889e-01
   -2.12579034e-03   3.28964065e-03   1.29367292e-01  -1.44494325e-01
   -5.84453680e-02   2.51892488e-04  -1.18508577e-01  -1.10100247e-01
    2.08046790e-02  -2.12713957e-01   1.28607526e-01   1.06156953e-01
    9.88578871e-02  -1.26165852e-01   5.64694591e-02  -6.37259483e-02
   -1.72655191e-02  -1.08150393e-01   7.17496425e-02  -1.48595944e-01
   -7.18183294e-02   1.87421113e-01   1.34402355e-02   1.72802880e-02
   -2.22025979e-02   2.15574697e-01   1.16051979e-01  -4.77654375e-02
   -1.22946687e-01  -9.83620659e-02  -2.16134395e-02  -2.97446568e-02
    7.68306404e-02  -4.32889909e-02   3.97546254e-02  -1.13834247e-01
   -9.67115760e-02   1.02852832e-03  -2.91543901e-01   2.77587418e-02
    3.81724238e-02   2.39921063e-02   1.48133919e-01  -2.95734946e-02
   -6.72301278e-02  -2.38470152e-01  -8.62290487e-02  -5.22732437e-02
   -1.48480847e-01   1.01147154e-02  -1.06557615e-01  -1.83915526e-01
   -3.12695265e-01   8.21436290e-03  -1.05971254e-01   1.74161009e-02
   -2.02891529e-01  -1.05407193e-01  -1.45093441e-01  -6.01556003e-02
   -3.04630883e-02   6.46229251e-04  -5.40076979e-02   5.97983524e-02
    9.25106183e-02  -4.98045012e-02  -9.08684060e-02  -9.22091082e-02
    1.44395120e-02   1.54712826e-01  -7.69153759e-02   5.63217886e-02
    6.27621189e-02   1.80592939e-01  -4.43916358e-02  -3.88901606e-02
    1.82163537e-01  -1.95019409e-01   1.18622921e-01  -1.29125053e-02
    1.01066940e-01   1.41850993e-01  -9.44009498e-02   3.38011920e-01
   -1.83245033e-01  -1.03735000e-01   3.28571461e-02  -7.17035607e-02
    2.13943675e-01   6.91331774e-02  -8.88564531e-03  -1.14095822e-01
    9.69795510e-02  -1.92595392e-01  -1.22179776e-01  -8.96785930e-02
   -5.12673929e-02  -2.12131087e-02   1.30326718e-01  -2.56502572e-02
    8.02838132e-02   5.67487720e-03   8.29678669e-04   7.39294589e-02
    8.77156407e-02   2.53697157e-01   4.96895111e-04   7.95556083e-02
   -3.52744968e-03  -4.56791632e-02   1.63335428e-01   2.51322091e-02
   -9.31572169e-02   1.17586747e-01   9.16993022e-02  -1.16048828e-01
   -1.03017256e-01  -1.43175900e-01  -7.62713775e-02  -2.87457816e-02
   -8.48671496e-02  -7.74307102e-02  -5.04824752e-03   1.02584563e-01
   -1.41755328e-01   1.68253519e-02   5.68513870e-02   8.57790709e-02
   -2.94736773e-01  -6.50881678e-02   2.19764635e-02   1.63487718e-01
    4.00745161e-02   9.68074426e-02   1.29587390e-02  -4.06240337e-02
   -2.30219424e-01   1.14188381e-02  -1.15013719e-01   7.64371306e-02
   -3.40041779e-02  -1.76359326e-01  -3.63267846e-02   7.67553598e-02
    1.82545051e-01  -5.51616699e-02  -5.64565435e-02  -2.19414979e-02
    8.03023502e-02   2.04497352e-02   5.71632683e-02  -4.10745181e-02
   -7.88012892e-02   4.16383222e-02   5.49165532e-02  -1.27255306e-01
    8.59525055e-02  -1.28885388e-01   2.16398850e-01  -1.03594260e-02
   -1.61016528e-02   4.05781642e-02  -2.30303779e-01  -2.50934972e-04
   -2.45876387e-01  -9.99496281e-02  -3.43263596e-02   9.46859717e-02
   -1.82809412e-01  -5.49773909e-02   2.03682572e-01  -6.51357323e-02
   -2.01517493e-02  -3.34145799e-02   7.73153156e-02   1.44466581e-02
    1.34487405e-01  -8.23090151e-02  -1.92063972e-01   2.50904704e-03
    3.79847810e-02  -2.07394347e-01  -7.54080862e-02  -9.60827917e-02
    4.12030928e-02  -4.89050709e-02  -4.98530306e-02   1.45050660e-01
   -2.70001888e-02  -7.71372318e-02   1.13251857e-01   2.88148206e-02
    2.02798415e-02  -6.57477528e-02   9.82217211e-03   3.47169004e-02
    1.73665583e-02   1.24465311e-02  -1.51551738e-01   1.47047997e-01
    3.94918807e-02   8.94951969e-02  -7.45197237e-02   3.01657636e-02
   -9.45357308e-02   3.20364311e-02  -2.27175474e-01   1.30608052e-01
    1.49420602e-03  -5.33780362e-03   2.81614643e-02  -6.88991472e-02
   -3.42944041e-02  -5.35390340e-02  -6.22755215e-02  -1.78609982e-01
    2.76998170e-02   2.35683709e-01   2.72933662e-01   1.02646209e-01
    3.66973132e-02  -8.52449015e-02  -6.59355074e-02  -7.12256599e-03]]
After layer encoder_birnn_reverse_l0_t6_out_0 (1, 256) <class 'numpy.float32'> [[ -8.38210657e-02  -7.17599690e-02  -1.34472214e-02   2.63098851e-02
    1.44535722e-02  -3.38868201e-02   1.23168249e-02   3.77030671e-02
    5.22515029e-02  -7.47612417e-02  -4.13428508e-02   9.26815420e-02
    5.53343892e-02  -1.00474088e-02   3.99574041e-02  -1.52046695e-01
    3.69965062e-02   1.26645677e-02   4.73306552e-02   2.90629733e-02
    1.20954491e-01  -3.28521319e-02  -9.67987534e-03   2.57054046e-02
   -6.73921481e-02   1.69484615e-02   2.64219958e-02  -2.72435118e-02
   -7.38077089e-02  -6.14421368e-02   2.49654334e-02  -6.25514537e-02
   -1.08207937e-03   1.67173613e-03   6.40581176e-02  -7.03269765e-02
   -3.08443792e-02   1.25226186e-04  -6.11775108e-02  -5.43138310e-02
    1.07376464e-02  -1.04881801e-01   6.42097965e-02   5.32579534e-02
    4.86187264e-02  -6.42336756e-02   2.86408085e-02  -3.05486321e-02
   -8.73820111e-03  -5.73461093e-02   3.73836793e-02  -7.38328993e-02
   -3.43453512e-02   9.63374674e-02   7.25143263e-03   8.16939585e-03
   -1.19629949e-02   1.09299898e-01   5.88850342e-02  -2.24705823e-02
   -6.37418628e-02  -5.12486435e-02  -1.09494049e-02  -1.61507614e-02
    3.83036695e-02  -2.10423823e-02   2.19491590e-02  -5.86690977e-02
   -4.81213145e-02   5.31545025e-04  -1.46958187e-01   1.41052753e-02
    1.90894082e-02   1.18898572e-02   7.88099095e-02  -1.62116345e-02
   -3.61355171e-02  -1.21634074e-01  -4.58868258e-02  -2.89602131e-02
   -8.09491724e-02   5.57282241e-03  -5.61652817e-02  -9.69769433e-02
   -1.69506937e-01   4.21576994e-03  -5.40219098e-02   9.07795783e-03
   -1.05645299e-01  -5.39968461e-02  -7.86632150e-02  -2.93549132e-02
   -1.45227611e-02   3.27503396e-04  -2.75529325e-02   3.03439535e-02
    4.75839451e-02  -2.59495825e-02  -4.20970693e-02  -4.33367901e-02
    7.00058090e-03   7.15892836e-02  -3.68124358e-02   2.68366002e-02
    3.09479516e-02   9.06014815e-02  -2.17356682e-02  -2.07151528e-02
    9.39298943e-02  -1.03320017e-01   5.98045699e-02  -6.64184429e-03
    4.82588783e-02   7.61496350e-02  -4.71762903e-02   1.82309434e-01
   -8.81722942e-02  -5.11070788e-02   1.68241393e-02  -3.48529033e-02
    1.08649090e-01   3.62091586e-02  -4.62322729e-03  -5.70754595e-02
    4.69723120e-02  -9.80877876e-02  -6.09690808e-02  -4.48794402e-02
   -2.54011787e-02  -1.00214574e-02   6.58395216e-02  -1.40070142e-02
    3.96731049e-02   2.98903370e-03   4.24936938e-04   3.54286358e-02
    4.68794778e-02   1.30382732e-01   2.64576724e-04   4.04934064e-02
   -1.78076164e-03  -2.27418039e-02   7.87373409e-02   1.30787743e-02
   -4.63493094e-02   5.96501455e-02   4.97221202e-02  -6.02824576e-02
   -5.23473956e-02  -7.09474534e-02  -3.77031378e-02  -1.41565884e-02
   -4.41380218e-02  -4.13758829e-02  -2.50151218e-03   5.32043017e-02
   -7.46733174e-02   8.81403312e-03   2.89950948e-02   4.59379219e-02
   -1.53523207e-01  -3.31648551e-02   1.09719560e-02   8.74084756e-02
    2.08875779e-02   4.63679247e-02   7.39774061e-03  -2.14737523e-02
   -1.06872655e-01   5.77427540e-03  -5.41696809e-02   4.05100472e-02
   -1.78025533e-02  -9.76535082e-02  -1.82579402e-02   4.18457910e-02
    9.83112529e-02  -2.66555250e-02  -2.92425957e-02  -1.08696418e-02
    3.76365855e-02   9.80435312e-03   2.93555818e-02  -1.96434669e-02
   -3.81308869e-02   2.23577414e-02   2.70905979e-02  -6.72073811e-02
    4.21975665e-02  -6.05704784e-02   1.08943276e-01  -5.55657642e-03
   -8.27287510e-03   2.05314327e-02  -1.13774143e-01  -1.29544496e-04
   -1.20822541e-01  -5.10967039e-02  -1.81793869e-02   4.79326472e-02
   -9.52076614e-02  -3.04600410e-02   1.06586628e-01  -3.51206884e-02
   -1.05516119e-02  -1.74907465e-02   3.70367430e-02   7.41959410e-03
    6.35820851e-02  -4.47547361e-02  -9.61024687e-02   1.44478388e-03
    1.96444485e-02  -1.12089150e-01  -3.97030935e-02  -4.65498306e-02
    2.11941022e-02  -2.69870013e-02  -2.44960915e-02   7.04904869e-02
   -1.32521838e-02  -3.56017947e-02   6.12126887e-02   1.46235125e-02
    1.05099510e-02  -3.45514901e-02   4.90696449e-03   1.77327599e-02
    1.01532582e-02   6.76238118e-03  -7.62752444e-02   6.77887201e-02
    1.94503479e-02   4.49159071e-02  -3.68806794e-02   1.52986171e-02
   -4.65713330e-02   1.66813172e-02  -1.20261103e-01   6.66963533e-02
    6.90365036e-04  -2.78633717e-03   1.46444328e-02  -3.99735831e-02
   -1.59108154e-02  -2.75827236e-02  -3.11969109e-02  -8.29752088e-02
    1.41370557e-02   1.16497099e-01   1.44224972e-01   4.88682650e-02
    1.93757489e-02  -4.56229560e-02  -3.28681692e-02  -3.66769731e-03]]
After layer expand_dims1048_0 (1, 1, 256) <class 'numpy.float32'> [[[ -8.38210657e-02  -7.17599690e-02  -1.34472214e-02   2.63098851e-02
     1.44535722e-02  -3.38868201e-02   1.23168249e-02   3.77030671e-02
     5.22515029e-02  -7.47612417e-02  -4.13428508e-02   9.26815420e-02
     5.53343892e-02  -1.00474088e-02   3.99574041e-02  -1.52046695e-01
     3.69965062e-02   1.26645677e-02   4.73306552e-02   2.90629733e-02
     1.20954491e-01  -3.28521319e-02  -9.67987534e-03   2.57054046e-02
    -6.73921481e-02   1.69484615e-02   2.64219958e-02  -2.72435118e-02
    -7.38077089e-02  -6.14421368e-02   2.49654334e-02  -6.25514537e-02
    -1.08207937e-03   1.67173613e-03   6.40581176e-02  -7.03269765e-02
    -3.08443792e-02   1.25226186e-04  -6.11775108e-02  -5.43138310e-02
     1.07376464e-02  -1.04881801e-01   6.42097965e-02   5.32579534e-02
     4.86187264e-02  -6.42336756e-02   2.86408085e-02  -3.05486321e-02
    -8.73820111e-03  -5.73461093e-02   3.73836793e-02  -7.38328993e-02
    -3.43453512e-02   9.63374674e-02   7.25143263e-03   8.16939585e-03
    -1.19629949e-02   1.09299898e-01   5.88850342e-02  -2.24705823e-02
    -6.37418628e-02  -5.12486435e-02  -1.09494049e-02  -1.61507614e-02
     3.83036695e-02  -2.10423823e-02   2.19491590e-02  -5.86690977e-02
    -4.81213145e-02   5.31545025e-04  -1.46958187e-01   1.41052753e-02
     1.90894082e-02   1.18898572e-02   7.88099095e-02  -1.62116345e-02
    -3.61355171e-02  -1.21634074e-01  -4.58868258e-02  -2.89602131e-02
    -8.09491724e-02   5.57282241e-03  -5.61652817e-02  -9.69769433e-02
    -1.69506937e-01   4.21576994e-03  -5.40219098e-02   9.07795783e-03
    -1.05645299e-01  -5.39968461e-02  -7.86632150e-02  -2.93549132e-02
    -1.45227611e-02   3.27503396e-04  -2.75529325e-02   3.03439535e-02
     4.75839451e-02  -2.59495825e-02  -4.20970693e-02  -4.33367901e-02
     7.00058090e-03   7.15892836e-02  -3.68124358e-02   2.68366002e-02
     3.09479516e-02   9.06014815e-02  -2.17356682e-02  -2.07151528e-02
     9.39298943e-02  -1.03320017e-01   5.98045699e-02  -6.64184429e-03
     4.82588783e-02   7.61496350e-02  -4.71762903e-02   1.82309434e-01
    -8.81722942e-02  -5.11070788e-02   1.68241393e-02  -3.48529033e-02
     1.08649090e-01   3.62091586e-02  -4.62322729e-03  -5.70754595e-02
     4.69723120e-02  -9.80877876e-02  -6.09690808e-02  -4.48794402e-02
    -2.54011787e-02  -1.00214574e-02   6.58395216e-02  -1.40070142e-02
     3.96731049e-02   2.98903370e-03   4.24936938e-04   3.54286358e-02
     4.68794778e-02   1.30382732e-01   2.64576724e-04   4.04934064e-02
    -1.78076164e-03  -2.27418039e-02   7.87373409e-02   1.30787743e-02
    -4.63493094e-02   5.96501455e-02   4.97221202e-02  -6.02824576e-02
    -5.23473956e-02  -7.09474534e-02  -3.77031378e-02  -1.41565884e-02
    -4.41380218e-02  -4.13758829e-02  -2.50151218e-03   5.32043017e-02
    -7.46733174e-02   8.81403312e-03   2.89950948e-02   4.59379219e-02
    -1.53523207e-01  -3.31648551e-02   1.09719560e-02   8.74084756e-02
     2.08875779e-02   4.63679247e-02   7.39774061e-03  -2.14737523e-02
    -1.06872655e-01   5.77427540e-03  -5.41696809e-02   4.05100472e-02
    -1.78025533e-02  -9.76535082e-02  -1.82579402e-02   4.18457910e-02
     9.83112529e-02  -2.66555250e-02  -2.92425957e-02  -1.08696418e-02
     3.76365855e-02   9.80435312e-03   2.93555818e-02  -1.96434669e-02
    -3.81308869e-02   2.23577414e-02   2.70905979e-02  -6.72073811e-02
     4.21975665e-02  -6.05704784e-02   1.08943276e-01  -5.55657642e-03
    -8.27287510e-03   2.05314327e-02  -1.13774143e-01  -1.29544496e-04
    -1.20822541e-01  -5.10967039e-02  -1.81793869e-02   4.79326472e-02
    -9.52076614e-02  -3.04600410e-02   1.06586628e-01  -3.51206884e-02
    -1.05516119e-02  -1.74907465e-02   3.70367430e-02   7.41959410e-03
     6.35820851e-02  -4.47547361e-02  -9.61024687e-02   1.44478388e-03
     1.96444485e-02  -1.12089150e-01  -3.97030935e-02  -4.65498306e-02
     2.11941022e-02  -2.69870013e-02  -2.44960915e-02   7.04904869e-02
    -1.32521838e-02  -3.56017947e-02   6.12126887e-02   1.46235125e-02
     1.05099510e-02  -3.45514901e-02   4.90696449e-03   1.77327599e-02
     1.01532582e-02   6.76238118e-03  -7.62752444e-02   6.77887201e-02
     1.94503479e-02   4.49159071e-02  -3.68806794e-02   1.52986171e-02
    -4.65713330e-02   1.66813172e-02  -1.20261103e-01   6.66963533e-02
     6.90365036e-04  -2.78633717e-03   1.46444328e-02  -3.99735831e-02
    -1.59108154e-02  -2.75827236e-02  -3.11969109e-02  -8.29752088e-02
     1.41370557e-02   1.16497099e-01   1.44224972e-01   4.88682650e-02
     1.93757489e-02  -4.56229560e-02  -3.28681692e-02  -3.66769731e-03]]]
After layer encoder_birnn_reverse_l0_t7_i2h_output (1, 1024) <class 'numpy.float32'> [[-0.0128371  -0.04095686  0.03787835 ...,  0.06970935 -0.04625846
   0.03761056]]
After layer encoder_birnn_reverse_l0_t7_h2h_output (1, 1024) <class 'numpy.float32'> [[-0.0022884   0.01316012 -0.08186831 ...,  0.07623111  0.04241878
   0.02037329]]
After layer _plus1043_0 (1, 1024) <class 'numpy.float32'> [[-0.0151255  -0.02779674 -0.04398996 ...,  0.14594045 -0.00383968
   0.05798385]]
After layer encoder_birnn_reverse_l0_t7_slice_output0 (1, 256) <class 'numpy.float32'> [[ -1.51254982e-02  -2.77967397e-02  -4.39899601e-02  -2.75904089e-02
   -7.43622333e-03  -3.27819102e-02  -3.55111063e-03   5.70785813e-03
    9.88030732e-02   7.25513101e-02  -4.97221015e-02   1.09229922e-01
    6.32395595e-03   1.76217631e-02  -1.25033408e-03   3.13780904e-01
   -1.34326488e-01  -9.19868052e-02   1.28133940e-02  -1.15772011e-02
    1.10361315e-01  -1.06953084e-05  -1.41718745e-01  -5.50185889e-02
    5.94657250e-02  -1.30602002e-01  -3.28676887e-02  -7.09629804e-03
   -1.56436488e-03  -2.15859693e-02  -6.81826007e-03  -1.12715587e-02
   -5.94441444e-02  -4.42078635e-02   8.63859206e-02  -1.65832654e-01
   -1.77649986e-02  -1.66962389e-02  -8.96916687e-02  -8.14279765e-02
   -1.68059915e-01   2.45259926e-02  -4.91291173e-02   5.67846373e-03
    2.91157681e-02  -1.99565850e-02   7.39437938e-02  -8.82579684e-02
   -5.02799898e-02   2.60702074e-02   2.83956006e-02   1.11794591e-01
   -1.71237692e-01   8.52901787e-02   1.80386245e-01   1.23457164e-01
   -7.73893744e-02   1.53520778e-02  -9.09159854e-02  -1.40498187e-02
    9.07592103e-02  -6.60817549e-02   1.59453228e-01  -2.67943814e-02
   -1.15505099e-01  -4.29322571e-02   1.13992356e-01  -2.33625136e-02
   -1.06405869e-01  -5.15215099e-03   1.10646114e-01  -1.96727272e-02
   -2.05896385e-02  -3.11491229e-02   1.76530220e-02   5.22839539e-02
    1.18591502e-01   1.73239529e-01   4.43787426e-02   6.27052635e-02
    2.36137211e-02   4.73647788e-02   9.14572030e-02  -2.65784636e-02
    1.69078335e-01   3.39820385e-02  -2.57593654e-02  -8.96967426e-02
   -1.66288838e-02   5.29476181e-02   1.17761686e-01   3.55727226e-03
   -8.70967656e-02   7.49572068e-02   7.12684020e-02   3.40395048e-02
   -3.22818644e-02   2.61407793e-02  -1.20511144e-01  -1.36171684e-01
   -1.29564881e-01   7.80734271e-02   2.03359127e-02  -1.14264429e-01
   -1.34540349e-01   7.65907392e-03  -3.00197396e-02  -1.11237101e-01
    7.43315071e-02  -1.17234886e-03  -1.05394989e-01  -1.01743340e-02
    3.33341919e-02   2.44974077e-01   1.74452104e-02   3.16352069e-01
   -2.64887959e-02   7.16737844e-03  -3.98226082e-03  -5.90178445e-02
    2.20320702e-01  -1.29858434e-01  -1.04961395e-02   1.03046834e-01
   -8.26706588e-02   7.49824420e-02  -1.44647092e-01   8.22056606e-02
   -3.23393196e-02   9.48042423e-03   2.29231775e-01   4.73796166e-02
   -9.03811306e-03  -5.25963195e-02  -8.83701071e-02  -1.15661100e-01
    1.18601337e-01   1.67221174e-01  -2.44875122e-02  -1.22098243e-02
   -4.26088162e-02  -1.37365609e-01   1.00185655e-01   5.40490262e-02
   -1.59960110e-02   3.14782187e-03   3.80835682e-02   6.56464100e-02
   -9.18669999e-03   7.41848499e-02   1.26925260e-01  -7.14325905e-02
   -2.55177543e-03  -9.32926759e-02  -1.14558294e-01   1.99606508e-01
    2.69842669e-02   1.15161389e-02  -2.44807303e-02  -3.09609249e-02
    2.41308689e-01  -8.18520784e-04  -7.61388838e-02   1.83701217e-02
    4.78289835e-03  -8.00483227e-02  -7.86511227e-03  -5.78780845e-02
    3.13618593e-02  -5.03772572e-02  -1.31564904e-02   4.57982942e-02
    2.09079497e-03   1.02248080e-01   1.93517823e-02  -1.80049941e-01
    4.22083698e-02  -1.36014342e-01  -6.50022030e-02  -1.91738084e-02
    5.61391152e-02  -7.63854831e-02  -6.61942735e-03   2.47534588e-02
    1.04483649e-01  -1.54479183e-02  -1.91167686e-02  -5.50924763e-02
    9.75442603e-02   3.54072154e-02  -5.20917699e-02  -4.57936265e-02
    3.29139084e-02  -6.23761043e-02  -5.26450872e-02   9.59027335e-02
    1.09595150e-01  -1.78449988e-01   4.27847169e-02   9.56057683e-02
    1.13215260e-02   9.76726562e-02   8.25665444e-02   7.48005211e-02
    7.49360397e-03  -4.20169383e-02  -1.34871807e-02  -5.21866605e-02
   -8.29756558e-02   3.89056504e-02   5.03544435e-02   1.30148962e-01
    2.09314562e-02   4.71502654e-02  -1.19193215e-02  -1.29735544e-02
   -6.45683985e-03  -2.12842785e-02   3.90847065e-02  -4.34826128e-03
   -6.90849572e-02  -1.20036125e-01   1.08929977e-01  -8.31763670e-02
   -3.25254630e-03   6.57051504e-02  -3.36210877e-02  -1.06639653e-01
   -1.29590183e-01   8.57846215e-02  -1.43441269e-02  -1.50326639e-01
   -1.93550717e-02  -5.66815846e-02   2.68183853e-02   5.96163385e-02
   -5.29150385e-03   8.44016895e-02   3.43344249e-02  -2.85297837e-02
   -1.32906497e-01  -1.54966444e-01   9.30453092e-02   2.39942461e-01
   -6.65132254e-02   1.77831128e-02  -1.17077596e-01  -8.61570239e-02
    1.13781132e-02  -1.46405082e-02   1.73104495e-01  -1.74822100e-02
   -1.27297372e-01   5.38458042e-02   5.45480773e-02  -1.34629384e-03]]
After layer encoder_birnn_reverse_l0_t7_slice_output1 (1, 256) <class 'numpy.float32'> [[ 0.15957838  0.0443936   0.11604801  0.04287001 -0.0031381   0.08434772
   0.20058927 -0.10511534  0.39517099  0.18254563  0.12638015  0.1514093
   0.1324327  -0.00847134  0.13148049  0.14781386  0.08987832 -0.0274825
  -0.15318429  0.09088911  0.14904857  0.02598797  0.44486973  0.07000957
   0.1273279   0.08288149  0.17326361  0.07829159  0.12943825  0.04177153
   0.09523812  0.04376894  0.24921784 -0.05553387 -0.00779953 -0.02415582
  -0.05755572  0.15552565  0.02463093  0.08753292 -0.09939429  0.11640965
   0.01746464  0.10527076  0.04783057  0.12902805  0.03719555 -0.13508609
  -0.01438257  0.01370935  0.07548421  0.1061656  -0.05369733  0.15971869
   0.06163174  0.0491421   0.05668255  0.10975369 -0.01093995 -0.1117562
   0.11207567  0.04307393  0.08514817  0.02537111 -0.02946351  0.15979934
   0.22370334  0.08544664 -0.16309814 -0.05883566  0.07295036  0.00696713
  -0.06033393  0.04357834  0.11739721  0.1581234   0.0731373   0.07856196
   0.10879245  0.10152205  0.23205447  0.20453957  0.03806176  0.02517671
   0.1965131  -0.01254938  0.10146861  0.16964157  0.04209417 -0.18085846
   0.349096    0.081091    0.08216849  0.07383501 -0.06932014  0.00805011
  -0.01303918  0.03472146 -0.19283494 -0.18563268 -0.08741156 -0.01669542
   0.05332173  0.11701026 -0.02903363 -0.03583257 -0.11399169  0.0624537
   0.10316099 -0.14145266  0.05423219 -0.02893949  0.07111031  0.23104535
   0.10090119  0.21056205  0.13428286  0.14097957  0.04702449  0.11746484
   0.21683411  0.18160529  0.04664336  0.01847907 -0.0445657  -0.00678885
   0.18307619 -0.00527306  0.10701413 -0.11860006  0.14807844  0.11780956
   0.01781016  0.19586091  0.05155783  0.04119146  0.02662659  0.06815758
   0.15018335  0.239214   -0.07106493  0.03645504  0.08582128  0.03687128
   0.05456889  0.1323185   0.11082952  0.04362273  0.05261265 -0.0327374
  -0.02709258  0.08926862  0.05546685  0.11294693 -0.02498355  0.19102435
   0.10319756 -0.06456922  0.07523536  0.16402419  0.23665762  0.09910212
  -0.03226189  0.10040405  0.10908221 -0.02329773  0.29680738 -0.02624606
  -0.00600748 -0.01249669  0.02210738  0.14333253 -0.0124495   0.22200018
  -0.06658924  0.13978614  0.18031645 -0.03171708  0.00590077  0.12077712
   0.0854841  -0.07563383  0.2530207  -0.03286261 -0.00673534  0.0442616
   0.03263431  0.21679959 -0.05600718 -0.07867108 -0.03851302  0.05587801
   0.19428739  0.16792229 -0.15980464  0.0098577   0.00079757 -0.01774262
   0.03403468  0.02657006  0.07036946  0.03857872  0.08244206 -0.02038041
   0.12030392 -0.14623776 -0.0607854   0.17881005 -0.0886456   0.11180055
   0.08074287  0.1106848  -0.05394986  0.03648875 -0.01098245 -0.11162096
   0.0662348   0.10588868 -0.03262524  0.13260135 -0.1017745  -0.09961519
   0.27588066  0.00361653  0.10092285 -0.00139267  0.03115506  0.06511005
   0.41922903  0.1932983   0.04984048 -0.30492043  0.16280907  0.04041249
   0.08241455 -0.00630881  0.0054053   0.09322003  0.06844728  0.0982956
   0.06078839  0.06519806 -0.00500161  0.22539279 -0.1686655  -0.00993021
  -0.09134932 -0.05186445  0.1238035  -0.03799181  0.19047567 -0.19602001
   0.16346546 -0.00100274  0.14158945  0.00293081]]
After layer encoder_birnn_reverse_l0_t7_slice_output2 (1, 256) <class 'numpy.float32'> [[ -1.67296797e-01  -1.52054921e-01  -4.47282456e-02   6.62585646e-02
    9.27304849e-03  -6.30251914e-02  -3.04188579e-04   5.95718473e-02
    1.03731789e-01  -1.71844840e-01  -9.10506994e-02   2.16860801e-01
    1.13111779e-01  -6.16999716e-03   8.98031890e-02  -2.91643560e-01
    9.63414013e-02   3.26091498e-02   1.16854727e-01   6.67803437e-02
    2.84937531e-01  -8.58273432e-02  -4.09759134e-02   3.32377851e-02
   -1.41340584e-01   3.36819105e-02   4.82959077e-02  -5.81486970e-02
   -1.67482778e-01  -1.44132107e-01   5.14802486e-02  -1.18303023e-01
    8.83526355e-03  -3.91882658e-03   1.47254020e-01  -1.70703337e-01
   -5.69629110e-02   1.10510159e-02  -1.28788427e-01  -1.28597975e-01
    1.35389790e-02  -2.35389486e-01   1.47505909e-01   1.27283052e-01
    1.07603177e-01  -1.43227935e-01   7.81337544e-02  -7.15062097e-02
   -2.66585127e-02  -1.23423226e-01   7.30092302e-02  -1.65194422e-01
   -6.75687194e-02   2.35752046e-01  -2.47230157e-02   6.57908618e-03
   -6.79921731e-03   2.50816941e-01   1.51981980e-01  -5.28393872e-02
   -1.49811596e-01  -1.03460163e-01  -1.25245024e-02  -4.65875119e-02
    1.00606441e-01  -5.03224283e-02   3.03430334e-02  -1.28238976e-01
   -1.10339120e-01   1.54965371e-02  -3.35013777e-01   4.39043567e-02
    1.96643025e-02   2.42856070e-02   1.65353954e-01  -9.30045918e-03
   -8.35101306e-02  -2.75936097e-01  -1.07964873e-01  -6.62820190e-02
   -1.69547275e-01  -1.78804994e-03  -1.24150366e-01  -2.18803748e-01
   -3.44684094e-01   5.34679741e-04  -7.92704076e-02  -3.79122421e-03
   -2.50506967e-01  -9.56371129e-02  -1.49261564e-01  -5.96318394e-02
   -3.60812359e-02   1.69281196e-02  -5.73441684e-02   7.39833713e-02
    9.43016857e-02  -4.36010510e-02  -1.02720283e-01  -1.30279258e-01
    6.14392012e-03   1.72849804e-01  -8.54404718e-02   7.35108554e-02
    8.03874210e-02   2.26436511e-01  -5.24665937e-02  -3.00070029e-02
    2.07022026e-01  -2.28072792e-01   1.62205607e-01  -3.17740142e-02
    1.32155746e-01   1.59588397e-01  -8.92524570e-02   3.45324814e-01
   -2.19678685e-01  -1.21674135e-01   8.05946626e-03  -7.99353793e-02
    2.26624921e-01   6.04751669e-02   7.47434236e-03  -1.30559832e-01
    9.42456350e-02  -2.15074942e-01  -1.46186888e-01  -1.04852185e-01
   -5.77309653e-02  -1.96983591e-02   1.58062130e-01  -8.43978673e-03
    8.71318728e-02   4.19573300e-03  -6.13526627e-03   7.88622126e-02
    8.27674270e-02   2.82161087e-01   9.74838994e-03   9.05076414e-02
   -5.38403913e-03  -4.69383299e-02   1.80576265e-01   2.35145614e-02
   -1.04173437e-01   1.37820020e-01   1.15028203e-01  -1.14874400e-01
   -1.14963867e-01  -1.65072471e-01  -9.45046097e-02  -3.15045714e-02
   -1.11558244e-01  -7.90900365e-02  -8.45051184e-03   1.14716858e-01
   -1.59195334e-01  -1.08727477e-02   6.22211397e-02   1.01571083e-01
   -3.19719970e-01  -5.74725866e-02   1.55803338e-02   1.69951156e-01
    4.83495966e-02   1.05788901e-01   1.82344252e-03  -3.22741084e-02
   -2.85830736e-01   6.26382977e-03  -1.35491967e-01   1.04226910e-01
   -2.67391894e-02  -1.72659263e-01  -5.58743589e-02   8.26027095e-02
    2.00363412e-01  -7.21062049e-02  -5.45696020e-02  -9.96227376e-03
    8.16159099e-02   3.10750827e-02   7.32313544e-02  -5.12051210e-02
   -9.82678235e-02   2.20855698e-02   6.40481040e-02  -1.46858513e-01
    6.29507154e-02  -1.27217755e-01   2.70550758e-01  -4.25384939e-03
   -2.51508392e-02   5.48528060e-02  -2.89205015e-01   4.35965881e-03
   -2.85270423e-01  -1.31111398e-01  -3.02900281e-02   1.23139814e-01
   -2.18185395e-01  -6.97494447e-02   2.25346997e-01  -7.54944980e-02
   -2.54282691e-02  -4.40417677e-02   9.08580497e-02   1.77037120e-02
    1.63781881e-01  -7.21436739e-02  -2.21557200e-01   2.85435840e-03
    5.22748046e-02  -2.45128870e-01  -9.94927287e-02  -1.15718022e-01
    5.53424284e-02  -5.90418205e-02  -7.08456710e-02   1.71732932e-01
   -2.49711610e-02  -7.93353096e-02   1.35793939e-01   3.99054363e-02
    3.25243697e-02  -7.63177648e-02   1.29188048e-02   4.04959060e-02
   -1.74900480e-02   3.73637229e-02  -1.66552126e-01   1.88270062e-01
    2.73988061e-02   9.50383842e-02  -7.86430836e-02   2.53637992e-02
   -9.67118666e-02   4.48518693e-02  -2.87904352e-01   1.39859095e-01
   -1.79520342e-02   6.83807582e-03   1.93028562e-02  -6.52076453e-02
   -3.81335132e-02  -4.09996957e-02  -8.06281790e-02  -2.23185986e-01
    4.02846411e-02   2.81301379e-01   3.18416268e-01   1.20191477e-01
    2.09133737e-02  -9.65160504e-02  -7.67000541e-02  -8.26781616e-04]]
After layer encoder_birnn_reverse_l0_t7_slice_output3 (1, 256) <class 'numpy.float32'> [[ 0.07574114  0.06533755 -0.01383651  0.07670655  0.02426909  0.20518215
   0.08767615  0.11404246  0.44998601  0.13452238 -0.06669962  0.07777344
   0.17274791 -0.04440596  0.05704885  0.13947508 -0.0623087  -0.09982224
   0.04498787 -0.0081067  -0.04875587 -0.14406617  0.30274582  0.11296807
   0.0385802   0.08122566 -0.02366952 -0.02287035 -0.11687107  0.01084091
   0.11680104  0.10299206  0.04070926  0.03698196 -0.01551223 -0.06091908
   0.11590293 -0.01207137  0.0570845  -0.03674586  0.05436664 -0.02652163
  -0.00316433  0.01071605 -0.03272573  0.04086117  0.03468317 -0.0936503
   0.02402248  0.12710901  0.08449789 -0.00314926 -0.10934323  0.05752819
   0.16137391 -0.10599524  0.16349906  0.03440735  0.02890728 -0.11918895
   0.08555301  0.09432819  0.02670408  0.18052006 -0.00622821 -0.05125888
   0.219356    0.06468222 -0.02281613  0.05775832  0.01531711  0.03093275
  -0.00281728 -0.01832636  0.14146385  0.18441734  0.15318421  0.03932964
   0.13754563  0.2235115   0.19154644  0.20990333  0.12033312  0.10520512
   0.17759532  0.05298457  0.04678129  0.07540383  0.0870703   0.03738195
   0.17917772 -0.04996072 -0.09727375  0.02716846  0.03300722  0.02811949
   0.0531925   0.06666422 -0.15124215 -0.12939407 -0.07331415 -0.15475932
  -0.09313346 -0.09979736 -0.03685432  0.00516523 -0.04478047  0.13556193
   0.06677073  0.10119313  0.02499817  0.05863789 -0.09595376  0.155358
  -0.00487038  0.1631801  -0.07172051 -0.03366081  0.0414378  -0.05621964
   0.03585939  0.0989719   0.07819396 -0.00492077 -0.07129905  0.04091944
   0.00438595  0.00716492 -0.01431985 -0.12160711  0.02424568  0.18335359
  -0.02370494  0.11652382  0.05117059 -0.0907591   0.14757201  0.05305025
   0.13901517  0.04404103  0.02306033 -0.01102059 -0.0669376   0.09126575
  -0.01488532  0.0337422   0.18433996  0.09100237  0.02955651 -0.02064604
  -0.02022262 -0.0298983   0.09186552  0.14351791 -0.03110224  0.07184279
   0.11869316  0.08644807  0.03912476  0.15066333  0.08759695  0.04842158
   0.00558355  0.1394363   0.09006316 -0.09280629  0.30514789  0.1204768
  -0.15426829  0.02549019 -0.12793465  0.13215455  0.10529301  0.23029834
   0.00341659  0.18905765  0.15844694 -0.07270539  0.06465593 -0.0217745
  -0.13424599 -0.09490149  0.06317881 -0.09917177 -0.07366574  0.16488135
  -0.03264932  0.12124082 -0.0503516  -0.13436791  0.01123311  0.14963087
   0.06090133  0.03116925 -0.05283968  0.07065858 -0.03747469  0.04194593
   0.12312438  0.03414132  0.08925898  0.21883157  0.09692848  0.16446562
   0.09758468  0.0953756  -0.09275313  0.06134662 -0.12020324  0.18413697
   0.00580258  0.31522548  0.07956702  0.1708995   0.11555046 -0.07258633
   0.05759105  0.22605568 -0.03404874 -0.05828381 -0.03266534 -0.17288457
   0.1751847   0.02996917  0.07552565  0.10392967 -0.00442566  0.04903101
   0.36690548  0.16383359  0.01208357 -0.17082569 -0.03103052  0.0115738
  -0.01883953  0.03464099 -0.02546822  0.09092754  0.12506145  0.05139674
  -0.17714703  0.09224612  0.07159813  0.32776588 -0.16182677  0.06320397
  -0.01166076 -0.152583    0.04459261 -0.03082193  0.12251673 -0.10287158
   0.12081812  0.14594045 -0.00383968  0.05798385]]
After layer encoder_birnn_reverse_l0_t7_o_output (1, 256) <class 'numpy.float32'> [[ 0.51892626  0.51632857  0.49654093  0.51916724  0.50606698  0.55111635
   0.521905    0.52847975  0.61063588  0.53357995  0.48333123  0.51943356
   0.54307991  0.4889003   0.51425838  0.53481239  0.48442784  0.47506514
   0.51124507  0.49797335  0.48781344  0.46404561  0.57511365  0.52821201
   0.50964385  0.52029526  0.49408287  0.49428269  0.47081542  0.50271022
   0.52916712  0.52572525  0.51017588  0.50924444  0.49612203  0.48477498
   0.5289433   0.49698219  0.51426727  0.49081457  0.51358837  0.49337
   0.49920887  0.50267899  0.49181932  0.51021385  0.50866991  0.47660455
   0.50600535  0.53173453  0.52111191  0.49921268  0.47269139  0.51437807
   0.54025614  0.473526    0.54078394  0.50860095  0.50722629  0.47023803
   0.52137518  0.52356458  0.50667566  0.54500788  0.49844292  0.48718807
   0.55462021  0.5161649   0.49429619  0.51443559  0.50382918  0.50773257
   0.49929562  0.49541855  0.53530711  0.54597414  0.53822136  0.50983119
   0.53433233  0.55564642  0.54774076  0.552284    0.530047    0.52627707
   0.5442825   0.51324308  0.51169318  0.51884204  0.52175385  0.5093444
   0.54467499  0.48751244  0.47570077  0.50679171  0.50825107  0.50702941
   0.51329499  0.51665992  0.46226138  0.46769655  0.48167971  0.46138719
   0.47673348  0.47507131  0.49078745  0.50129133  0.48880675  0.53383869
   0.5166865   0.52527672  0.50624919  0.51465523  0.47602999  0.53876156
   0.4987824   0.54070473  0.48207754  0.49158564  0.51035798  0.48594883
   0.50896388  0.52472281  0.51953852  0.49876982  0.48218277  0.51022846
   0.50109649  0.50179124  0.49642009  0.46963567  0.50606114  0.54571038
   0.49407402  0.52909803  0.51278985  0.47732583  0.53682619  0.51325947
   0.53469789  0.5110085   0.50576478  0.49724483  0.48327187  0.52280062
   0.49627876  0.50843477  0.54595494  0.52273488  0.50738859  0.49483865
   0.49494448  0.49252599  0.52295023  0.53581798  0.49222508  0.51795298
   0.52963847  0.52159858  0.50977993  0.53759474  0.52188522  0.51210302
   0.50139588  0.53480268  0.52250057  0.4768151   0.57570046  0.53008282
   0.46150926  0.50637221  0.46805987  0.53299063  0.526299    0.55732149
   0.50085413  0.54712415  0.53952909  0.48183164  0.5161584   0.49455661
   0.46648881  0.47629237  0.51578945  0.47522736  0.48159188  0.5411272
   0.4918384   0.53027314  0.48741478  0.46645847  0.50280827  0.53733808
   0.51522064  0.5077917   0.48679313  0.51765734  0.49063244  0.51048493
   0.53074229  0.50853449  0.52229995  0.55449063  0.52421319  0.54102397
   0.52437681  0.52382588  0.47682834  0.51533186  0.46998531  0.54590464
   0.5014506   0.57816023  0.51988131  0.5426212   0.5288555   0.48186138
   0.51439375  0.55627447  0.49148864  0.48543319  0.49183443  0.4568862
   0.54368448  0.50749171  0.51887244  0.52595907  0.49889356  0.51225531
   0.590711    0.54086703  0.50302082  0.4573971   0.49224299  0.50289339
   0.49529025  0.50865936  0.49363324  0.52271628  0.53122473  0.51284635
   0.4558287   0.52304518  0.51789188  0.58121568  0.45963135  0.51579577
   0.49708486  0.46192807  0.51114631  0.49229509  0.53059095  0.47430483
   0.53016782  0.53642046  0.49904007  0.51449192]]
After layer encoder_birnn_reverse_l0_t7_f_output (1, 256) <class 'numpy.float32'> [[ 0.53981018  0.5110966   0.52897948  0.51071584  0.49921551  0.52107447
   0.54997987  0.47374529  0.59752685  0.54551011  0.53155309  0.53778017
   0.5330599   0.49788219  0.53282285  0.53688633  0.52245444  0.49312985
   0.46177864  0.52270663  0.53719336  0.50649661  0.60941875  0.51749527
   0.53178906  0.5207085   0.54320788  0.5195629   0.53231448  0.51044136
   0.52379155  0.51094049  0.561984    0.4861201   0.49805009  0.49396136
   0.48561502  0.53880322  0.50615746  0.52186924  0.47517186  0.5290696
   0.50436604  0.52629346  0.51195538  0.53221232  0.50929785  0.46627977
   0.49640447  0.50342727  0.51886213  0.5265165   0.48657888  0.53984499
   0.51540303  0.51228309  0.51416683  0.52741092  0.49726501  0.47208995
   0.52798963  0.5107668   0.52127421  0.50634247  0.49263462  0.53986508
   0.55569381  0.52134866  0.45931563  0.4852953   0.51822948  0.50174177
   0.48492107  0.51089281  0.52931565  0.53944868  0.51827621  0.51963037
   0.52717131  0.52535874  0.5577547   0.55095738  0.50951433  0.50629383
   0.54897082  0.49686268  0.52534539  0.54230899  0.51052201  0.45490825
   0.58639836  0.52026165  0.52053058  0.51845038  0.48267689  0.50201249
   0.49674028  0.50867951  0.45194009  0.45372462  0.47816101  0.49582621
   0.5133273   0.52921921  0.49274209  0.49104279  0.47153291  0.51560837
   0.52576739  0.46469566  0.51355469  0.49276567  0.51777011  0.55750573
   0.52520394  0.5524469   0.53352034  0.53518665  0.51175392  0.52933246
   0.55399716  0.545277    0.51165873  0.50461966  0.4888604   0.49830276
   0.54564166  0.49868169  0.52672803  0.47038469  0.53695214  0.52941841
   0.50445241  0.54880929  0.51288658  0.5102964   0.50665629  0.5170328
   0.53747541  0.55951995  0.48224127  0.50911278  0.52144217  0.50921679
   0.51363885  0.53303146  0.52767909  0.51090395  0.51315016  0.49181637
   0.49322727  0.52230233  0.51386321  0.52820677  0.49375448  0.54761136
   0.52577651  0.48386329  0.51879996  0.54091436  0.55888981  0.5247553
   0.49193525  0.52507997  0.52724355  0.49417582  0.57366186  0.49343881
   0.49849814  0.49687585  0.50552666  0.53577191  0.49688762  0.55527323
   0.48335886  0.53488976  0.5449574   0.49207142  0.50147521  0.53015763
   0.52135801  0.48110056  0.56291986  0.49178508  0.49831614  0.51106358
   0.50815785  0.55398858  0.48600188  0.48034233  0.49037296  0.5139659
   0.54841965  0.54188222  0.46013364  0.50246441  0.50019938  0.49556446
   0.50850785  0.50664216  0.5175851   0.5096435   0.52059883  0.49490511
   0.53003979  0.46350557  0.4848083   0.5445838   0.47785309  0.52792108
   0.5201748   0.52764297  0.48651576  0.50912118  0.4972544   0.47212371
   0.51655269  0.52644747  0.49184442  0.53310186  0.47457829  0.47511673
   0.56853604  0.50090414  0.52520931  0.49965179  0.50778812  0.51627177
   0.60329878  0.54817468  0.51245755  0.42435509  0.54061264  0.51010174
   0.52059197  0.49842277  0.5013513   0.52328813  0.51710516  0.52455413
   0.51519239  0.51629376  0.49874958  0.55611086  0.45793331  0.49751747
   0.47717854  0.48703676  0.53091145  0.49050319  0.54747546  0.45115131
   0.5407756   0.4997493   0.53533834  0.50073272]]
After layer _mul2086_0 (1, 256) <class 'numpy.float32'> [[ -8.82354826e-02  -7.18237609e-02  -1.43386349e-02   2.59671286e-02
    1.42089184e-02  -3.21053490e-02   1.29479999e-02   3.37773524e-02
    5.18321171e-02  -7.72550851e-02  -4.54417765e-02   9.72713232e-02
    5.46243005e-02  -1.02179302e-02   4.15999554e-02  -1.57746598e-01
    3.99744175e-02   1.31237255e-02   4.29950170e-02   3.06209736e-02
    1.35829598e-01  -3.57905924e-02  -1.03435321e-02   2.52443422e-02
   -7.04106167e-02   1.70723069e-02   2.90012248e-02  -2.85981372e-02
   -8.36823285e-02  -6.26388118e-02   2.47599036e-02  -6.11467846e-02
   -1.19466195e-03   1.59916619e-03   6.47944808e-02  -7.18776584e-02
   -2.84143295e-02   1.35720489e-04  -6.02671988e-02  -5.76918051e-02
    9.88722499e-03  -1.14285491e-01   6.52264804e-02   5.60810119e-02
    5.07766716e-02  -6.75067380e-02   2.87904013e-02  -2.97544412e-02
   -8.57153255e-03  -5.46596311e-02   3.72922532e-02  -7.88218156e-02
   -3.50055508e-02   1.02388650e-01   6.92755543e-03   8.85328092e-03
   -1.14177158e-02   1.15508497e-01   5.79697751e-02  -2.25667562e-02
   -6.52446523e-02  -5.04030474e-02  -1.12682832e-02  -1.50654269e-02
    3.79241705e-02  -2.33848300e-02   2.21030470e-02  -5.96056879e-02
   -4.45604101e-02   4.99140122e-04  -1.55599833e-01   1.39312996e-02
    1.85196102e-02   1.22597469e-02   7.89908022e-02  -1.59580354e-02
   -3.48964147e-02  -1.26348853e-01  -4.55706492e-02  -2.74872594e-02
   -8.34326744e-02   5.57296677e-03  -5.44995330e-02  -9.41870064e-02
   -1.77608535e-01   4.08150209e-03  -5.58813177e-02   9.44586378e-03
   -1.05038054e-01  -4.81293835e-02  -8.56872648e-02  -3.13344821e-02
   -1.58618763e-02   3.35037854e-04  -2.60936581e-02   3.00553776e-02
    4.60855216e-02  -2.53555067e-02  -4.11806703e-02  -4.19567265e-02
    6.90489169e-03   7.73316696e-02  -3.95608991e-02   2.98381504e-02
    3.09662409e-02   8.96622315e-02  -2.09458843e-02  -2.00622119e-02
    9.68566388e-02  -9.18005183e-02   6.12075329e-02  -6.36319304e-03
    5.25087118e-02   7.96196610e-02  -4.97278161e-02   1.94376409e-01
   -9.88818109e-02  -5.57180196e-02   1.68208275e-02  -3.80202681e-02
    1.20383896e-01   3.77569608e-02  -4.54653753e-03  -5.78267984e-02
    4.75589335e-02  -9.71845612e-02  -6.70011118e-02  -4.48415391e-02
   -2.70276684e-02  -9.97981895e-03   7.03794956e-02  -1.35826971e-02
    4.05867137e-02   3.11445887e-03   4.25531151e-04   3.77948955e-02
    4.45561893e-02   1.34097815e-01   2.67068943e-04   4.46072184e-02
   -1.70108886e-03  -2.32720412e-02   8.59397426e-02   1.28004383e-02
   -4.79883030e-02   6.29687235e-02   4.85241190e-02  -5.95581345e-02
   -5.30515239e-02  -7.09034130e-02  -3.76923271e-02  -1.50181260e-02
   -4.37152572e-02  -4.09814566e-02  -2.49261595e-03   5.63747846e-02
   -7.50369504e-02   8.14193860e-03   2.95263343e-02   4.65134382e-02
   -1.69760436e-01  -3.42037156e-02   1.08127380e-02   8.66214484e-02
    2.11403519e-02   4.79901880e-02   7.43435044e-03  -2.00565141e-02
   -1.16858512e-01   5.67399152e-03  -5.84009252e-02   4.10329029e-02
   -1.69027727e-02  -9.89622548e-02  -1.75666027e-02   4.11365628e-02
    1.00606881e-01  -2.71710623e-02  -2.83416938e-02  -1.16343200e-02
    4.19566147e-02   9.83975083e-03   3.22134569e-02  -2.02112067e-02
   -3.93495373e-02   2.12921407e-02   2.79343817e-02  -7.08822682e-02
    4.18764092e-02  -6.22553676e-02   1.07820712e-01  -5.32458210e-03
   -8.83122627e-03   2.20006648e-02  -1.07906051e-01  -1.26085899e-04
   -1.25559598e-01  -4.96974178e-02  -1.74620841e-02   4.81160432e-02
   -9.56951156e-02  -2.80471481e-02   1.07540891e-01  -3.22817117e-02
   -1.06826751e-02  -1.54936127e-02   3.75580601e-02   7.86796305e-03
    6.46569282e-02  -4.35511917e-02  -1.01163238e-01   1.32388389e-03
    1.84890907e-02  -1.07143037e-01  -3.75683196e-02  -4.55033369e-02
    2.12956239e-02  -2.57665068e-02  -2.45402791e-02   7.78760388e-02
   -1.28168184e-02  -3.67221385e-02   6.46651760e-02   1.44374603e-02
    1.06526222e-02  -3.28984410e-02   4.98774275e-03   1.79305617e-02
    1.04782768e-02   6.82322541e-03  -7.82667473e-02   6.28562570e-02
    2.13609189e-02   4.57741246e-02  -3.88664193e-02   1.50398668e-02
   -4.75375615e-02   1.67700239e-02  -1.19559482e-01   6.89045936e-02
    7.69804174e-04  -2.75590084e-03   1.40492339e-02  -3.83763686e-02
   -1.57107115e-02  -2.66620982e-02  -2.97550485e-02  -8.79327804e-02
    1.47099122e-02   1.17818378e-01   1.53310031e-01   4.64726500e-02
    1.98539272e-02  -4.27047201e-02  -3.53490897e-02  -3.56656220e-03]]
After layer encoder_birnn_reverse_l0_t7_i_output (1, 256) <class 'numpy.float32'> [[ 0.49621871  0.49305123  0.48900425  0.49310282  0.49814096  0.49180526
   0.49911222  0.50142694  0.52468067  0.51812989  0.48757204  0.52728039
   0.50158101  0.50440538  0.4996874   0.5778079   0.46646878  0.47701955
   0.50320333  0.49710575  0.52756238  0.49999732  0.46462947  0.48624882
   0.51486206  0.46739581  0.4917838   0.49822593  0.49960893  0.49460375
   0.49829543  0.49718213  0.48514336  0.48894984  0.52158308  0.45863658
   0.49555886  0.49582604  0.47759214  0.47965425  0.45808363  0.50613117
   0.48772019  0.5014196   0.50727844  0.495011    0.51847756  0.4779498
   0.4874326   0.50651717  0.50709844  0.52791953  0.45729488  0.52130961
   0.54497468  0.53082514  0.48066232  0.50383794  0.47728667  0.49648762
   0.52267426  0.48348558  0.53977907  0.49330181  0.47115576  0.4892686
   0.52846724  0.49415964  0.4734236   0.49871194  0.52763331  0.49508199
   0.49485278  0.49221334  0.50441313  0.51306802  0.5296132   0.54320186
   0.51109284  0.51567119  0.50590318  0.51183897  0.52284837  0.49335581
   0.54216915  0.50849468  0.49356052  0.47759083  0.49584284  0.51323378
   0.52940643  0.5008893   0.47823957  0.51873052  0.51780957  0.5085091
   0.49193025  0.50653481  0.46990865  0.46600956  0.46765405  0.51950848
   0.5050838   0.47146496  0.46641555  0.5019148   0.49249563  0.47221932
   0.51857436  0.49970692  0.47367564  0.49745643  0.50833279  0.56093907
   0.50436121  0.57843494  0.49337822  0.50179183  0.49900445  0.48524985
   0.55485839  0.46758094  0.49737599  0.52573895  0.4793441   0.51873684
   0.46390116  0.52053988  0.49191588  0.50237012  0.55705833  0.51184267
   0.49774051  0.48685393  0.47792181  0.47111693  0.52961558  0.54170817
   0.49387842  0.49694756  0.48934942  0.46571249  0.52502549  0.51350898
   0.49600106  0.50078696  0.50951976  0.5164057   0.49770331  0.51853776
   0.53168875  0.48214945  0.49936202  0.47669372  0.47139171  0.54973662
   0.5067457   0.50287902  0.49388018  0.49226037  0.56003612  0.49979541
   0.48097444  0.50459242  0.50119573  0.47999859  0.4980337   0.48553452
   0.50783986  0.48740837  0.49671099  0.51144761  0.50052273  0.52553976
   0.50483781  0.45510873  0.51055056  0.46604875  0.48375517  0.49520668
   0.51403111  0.48091289  0.49834514  0.50618804  0.52609718  0.49613813
   0.49522096  0.48623037  0.52436674  0.50885087  0.48697999  0.48855361
   0.50822777  0.48441103  0.48684177  0.52395731  0.52737141  0.45550552
   0.51069456  0.52388322  0.50283033  0.5243988   0.52062994  0.51869142
   0.50187337  0.48949733  0.49662828  0.4869563   0.47926795  0.50972521
   0.51258594  0.53249139  0.50523269  0.51178539  0.49702021  0.49675664
   0.49838576  0.49467909  0.50976992  0.4989129   0.48273563  0.47002691
   0.52720565  0.47921792  0.49918687  0.51642042  0.49159554  0.47336537
   0.46764773  0.521433    0.49641404  0.46248895  0.49516138  0.48583338
   0.50670421  0.51489973  0.49867713  0.52108794  0.50858277  0.49286804
   0.46682218  0.46133575  0.52324456  0.55969948  0.48337781  0.50444567
   0.47076401  0.47847411  0.50284451  0.49633998  0.54316843  0.49562958
   0.46821859  0.51345819  0.51363361  0.49966347]]
After layer encoder_birnn_reverse_l0_t7_c_output (1, 256) <class 'numpy.float32'> [[ -1.65753305e-01  -1.50893793e-01  -4.46984433e-02   6.61617741e-02
    9.27278306e-03  -6.29418790e-02  -3.04188579e-04   5.95014766e-02
    1.03361323e-01  -1.70173034e-01  -9.07999203e-02   2.13523999e-01
    1.12631842e-01  -6.16991892e-03   8.95625576e-02  -2.83646822e-01
    9.60444361e-02   3.25975977e-02   1.16325736e-01   6.66812509e-02
    2.77468681e-01  -8.56172219e-02  -4.09529954e-02   3.32255512e-02
   -1.40406862e-01   3.36691812e-02   4.82583940e-02  -5.80832474e-02
   -1.65934160e-01  -1.43142268e-01   5.14348187e-02  -1.17754191e-01
    8.83503351e-03  -3.91880656e-03   1.46198839e-01  -1.69064373e-01
   -5.69013804e-02   1.10505661e-02  -1.28081068e-01  -1.27893746e-01
    1.35381520e-02  -2.31136218e-01   1.46445334e-01   1.26600116e-01
    1.07189804e-01  -1.42256513e-01   7.79751465e-02  -7.13845864e-02
   -2.66522001e-02  -1.22800313e-01   7.28797838e-02  -1.63707972e-01
   -6.74660802e-02   2.31479391e-01  -2.47179791e-02   6.57899119e-03
   -6.79911254e-03   2.45686442e-01   1.50822505e-01  -5.27902655e-02
   -1.48700804e-01  -1.03092596e-01  -1.25238476e-02  -4.65538353e-02
    1.00268379e-01  -5.02799936e-02   3.03337239e-02  -1.27540603e-01
   -1.09893508e-01   1.54952966e-02  -3.23018640e-01   4.38761674e-02
    1.96617674e-02   2.42808331e-02   1.63863227e-01  -9.30019096e-03
   -8.33165422e-02  -2.69139677e-01  -1.07547328e-01  -6.61851242e-02
   -1.67941123e-01  -1.78804807e-03  -1.23516425e-01  -2.15377599e-01
   -3.31652701e-01   5.34679682e-04  -7.91047886e-02  -3.79120605e-03
   -2.45395154e-01  -9.53465998e-02  -1.48162887e-01  -5.95612563e-02
   -3.60655859e-02   1.69265028e-02  -5.72813973e-02   7.38486871e-02
    9.40231457e-02  -4.35734428e-02  -1.02360524e-01  -1.29547164e-01
    6.14384282e-03   1.71148717e-01  -8.52331743e-02   7.33787268e-02
    8.02147090e-02   2.22644210e-01  -5.24185039e-02  -2.99980007e-02
    2.04114348e-01  -2.24198803e-01   1.60797849e-01  -3.17633264e-02
    1.31391719e-01   1.58247247e-01  -8.90162140e-02   3.32222849e-01
   -2.16211796e-01  -1.21077232e-01   8.05929210e-03  -7.97655582e-02
    2.22823277e-01   6.04015514e-02   7.47420313e-03  -1.29823029e-01
    9.39675868e-02  -2.11818919e-01  -1.45154357e-01  -1.04469620e-01
   -5.76669164e-02  -1.96958110e-02   1.56758830e-01  -8.43958650e-03
    8.69120434e-02   4.19570832e-03  -6.13518944e-03   7.86991343e-02
    8.25789496e-02   2.74904013e-01   9.74808075e-03   9.02613178e-02
   -5.38398698e-03  -4.69038896e-02   1.78638801e-01   2.35102288e-02
   -1.03798233e-01   1.36954010e-01   1.14523545e-01  -1.14371754e-01
   -1.14460051e-01  -1.63589299e-01  -9.42242667e-02  -3.14941518e-02
   -1.11097753e-01  -7.89255425e-02  -8.45031068e-03   1.14216276e-01
   -1.57863989e-01  -1.08723193e-02   6.21409677e-02   1.01223230e-01
   -3.09253693e-01  -5.74093908e-02   1.55790728e-02   1.68333590e-01
    4.83119562e-02   1.05396025e-01   1.82344054e-03  -3.22629064e-02
   -2.78292924e-01   6.26374781e-03  -1.34668887e-01   1.03851132e-01
   -2.67328192e-02  -1.70963749e-01  -5.58162853e-02   8.24153498e-02
    1.97724551e-01  -7.19814971e-02  -5.45154996e-02  -9.96194407e-03
    8.14351737e-02   3.10650840e-02   7.31007233e-02  -5.11604175e-02
   -9.79527310e-02   2.20819805e-02   6.39606714e-02  -1.45811766e-01
    6.28676936e-02  -1.26535863e-01   2.64137238e-01  -4.25382378e-03
   -2.51455382e-02   5.47978580e-02  -2.81402946e-01   4.35963133e-03
   -2.77775913e-01  -1.30365252e-01  -3.02807689e-02   1.22521162e-01
   -2.14787856e-01  -6.96365535e-02   2.21608445e-01  -7.53514022e-02
   -2.54227892e-02  -4.40133139e-02   9.06088576e-02   1.77018624e-02
    1.62332982e-01  -7.20187724e-02  -2.18001768e-01   2.85435072e-03
    5.22272401e-02  -2.40334287e-01  -9.91657376e-02  -1.15204267e-01
    5.52859977e-02  -5.89733124e-02  -7.07273856e-02   1.70064360e-01
   -2.49659717e-02  -7.91692808e-02   1.34965375e-01   3.98842692e-02
    3.25129069e-02  -7.61699453e-02   1.29180858e-02   4.04737853e-02
   -1.74882654e-02   3.73463444e-02  -1.65029004e-01   1.86076716e-01
    2.73919515e-02   9.47532803e-02  -7.84813538e-02   2.53583621e-02
   -9.64114740e-02   4.48218174e-02  -2.80204833e-01   1.38954267e-01
   -1.79501064e-02   6.83796918e-03   1.93004590e-02  -6.51153848e-02
   -3.81150395e-02  -4.09767367e-02  -8.04539174e-02  -2.19552591e-01
    4.02628630e-02   2.74109095e-01   3.08074176e-01   1.19616047e-01
    2.09103245e-02  -9.62174684e-02  -7.65499994e-02  -8.26781441e-04]]
After layer _mul2087_0 (1, 256) <class 'numpy.float32'> [[ -8.22498947e-02  -7.43983686e-02  -2.18577292e-02   3.26245576e-02
    4.61915322e-03  -3.09551470e-02  -1.51824235e-04   2.98356432e-02
    5.42316884e-02  -8.81717354e-02  -4.42715026e-02   1.12587020e-01
    5.64939938e-02  -3.11214034e-03   4.47532833e-02  -1.63893372e-01
    4.48017307e-02   1.55496914e-02   5.85354976e-02   3.31476331e-02
    1.46382034e-01  -4.28083800e-02  -1.90279689e-02   1.61558855e-02
   -7.22901672e-02   1.57368351e-02   2.37326957e-02  -2.89385803e-02
   -8.29021856e-02  -7.07987025e-02   2.56297346e-02  -5.85452802e-02
    4.28625802e-03  -1.91609981e-03   7.62548372e-02  -7.75391087e-02
   -2.81979833e-02   5.47915837e-03  -6.11705109e-02  -6.13447800e-02
    6.20160578e-03  -1.16985247e-01   7.14243427e-02   6.34797812e-02
    5.43750785e-02  -7.04185367e-02   4.04283628e-02  -3.41182500e-02
   -1.29911508e-02  -6.22004680e-02   3.69572230e-02  -8.64246339e-02
   -3.08518931e-02   1.20672435e-01  -1.34706730e-02   3.49229388e-03
   -3.26807727e-03   1.23786151e-01   7.19855726e-02  -2.62097139e-02
   -7.77220801e-02  -4.98437844e-02  -6.76011061e-03  -2.29650903e-02
    4.72420231e-02  -2.46004220e-02   1.60303786e-02  -6.30254149e-02
   -5.20261787e-02   7.72768958e-03  -1.70435399e-01   2.17223000e-02
    9.72968061e-03   1.19513497e-02   8.26547593e-02  -4.77163075e-03
   -4.41255420e-02  -1.46197170e-01  -5.49666695e-02  -3.41297612e-02
   -8.49619508e-02  -9.15192708e-04  -6.45803586e-02  -1.06257789e-01
   -1.79811865e-01   2.71881785e-04  -3.90430018e-02  -1.81064522e-03
   -1.21677428e-01  -4.89350967e-02  -7.84383863e-02  -2.98335962e-02
   -1.72479898e-02   8.78029317e-03  -2.96608564e-02   3.75527292e-02
    4.62528281e-02  -2.20714658e-02  -4.81000952e-02  -6.03702180e-02
    2.87319301e-03   8.89132097e-02  -4.30498943e-02   3.45954970e-02
    3.74133885e-02   1.11748427e-01  -2.58158837e-02  -1.41656352e-02
    1.05848469e-01  -1.12033695e-01   7.61660263e-02  -1.58008710e-02
    6.67907223e-02   8.87670666e-02  -4.48963270e-02   1.92169309e-01
   -1.06674194e-01  -6.07555658e-02   4.02162271e-03  -3.87062244e-02
    1.23635367e-01   2.82426141e-02   3.71748931e-03  -6.82530254e-02
    4.50428091e-02  -1.09878279e-01  -6.73372746e-02  -5.43806031e-02
   -2.83672716e-02  -9.89458710e-03   8.73238146e-02  -4.31974046e-03
    4.32596430e-02   2.04269704e-03  -2.93214084e-03   3.70764956e-02
    4.37350981e-02   1.48917750e-01   4.81436681e-03   4.48551401e-02
   -2.63465103e-03  -2.18437277e-02   9.37899202e-02   1.20727131e-02
   -5.14840335e-02   6.85847849e-02   5.83520085e-02  -5.90622276e-02
   -5.69671467e-02  -8.48272294e-02  -5.00979833e-02  -1.51848877e-02
   -5.54779992e-02  -3.76233086e-02  -3.98340635e-03   6.27888665e-02
   -7.99968988e-02  -5.46746142e-03   3.06901932e-02   4.98281829e-02
   -1.73193246e-01  -2.86929496e-02   7.49313552e-03   8.49398524e-02
    2.42137462e-02   5.05899414e-02   9.08134854e-04  -1.56647544e-02
   -1.41328245e-01   3.05300322e-03  -6.68915138e-02   5.31144142e-02
   -1.33803841e-02  -8.98482502e-02  -2.81781722e-02   3.75079438e-02
    1.00948378e-01  -3.35468873e-02  -2.63721552e-02  -4.93322127e-03
    4.18602116e-02   1.49395997e-02   3.64293903e-02  -2.58967914e-02
   -5.15326560e-02   1.09557128e-02   3.16746645e-02  -7.08981082e-02
    3.29657272e-02  -6.43878877e-02   1.28629550e-01  -2.07822095e-03
   -1.27796605e-02   2.65446864e-02  -1.36998713e-01   2.28426070e-03
   -1.46491081e-01  -5.93820922e-02  -1.54642239e-02   6.41867816e-02
   -1.08001851e-01  -3.65173258e-02   1.15375996e-01  -3.90841253e-02
   -1.27590206e-02  -2.15444006e-02   4.49989215e-02   8.62003304e-03
    7.78009966e-02  -3.67097855e-02  -1.11744642e-01   1.51991716e-03
    2.63869092e-02  -1.22999579e-01  -4.92873751e-02  -5.72284833e-02
    2.75537539e-02  -2.91728638e-02  -3.60546932e-02   8.48473012e-02
   -1.20519642e-02  -3.72116938e-02   7.11545050e-02   1.91132557e-02
    1.62300169e-02  -3.93357165e-02   6.35047350e-03   1.91588886e-02
   -8.17834772e-03   1.94736160e-02  -8.19227174e-02   8.60584229e-02
    1.35634365e-02   4.60343063e-02  -3.97668332e-02   1.30570140e-02
   -4.80781980e-02   2.33561080e-02  -1.42507344e-01   6.84861168e-02
   -8.37950781e-03   3.15459957e-03   1.00988606e-02  -3.64450477e-02
   -1.84239652e-02  -2.06705369e-02  -3.78748104e-02  -1.05050229e-01
    2.02459600e-02   1.36051297e-01   1.67336166e-01   5.92852496e-02
    9.79060307e-03  -4.94036488e-02  -3.93186510e-02  -4.13112488e-04]]
After layer encoder_birnn_reverse_l0_t7_state_0 (1, 256) <class 'numpy.float32'> [[ -1.70485377e-01  -1.46222129e-01  -3.61963660e-02   5.85916862e-02
    1.88280717e-02  -6.30604923e-02   1.27961757e-02   6.36129975e-02
    1.06063806e-01  -1.65426821e-01  -8.97132754e-02   2.09858343e-01
    1.11118294e-01  -1.33300703e-02   8.63532424e-02  -3.21639955e-01
    8.47761482e-02   2.86734179e-02   1.01530515e-01   6.37686104e-02
    2.82211632e-01  -7.85989761e-02  -2.93715000e-02   4.14002277e-02
   -1.42700791e-01   3.28091420e-02   5.27339205e-02  -5.75367175e-02
   -1.66584522e-01  -1.33437514e-01   5.03896400e-02  -1.19692065e-01
    3.09159607e-03  -3.16933612e-04   1.41049325e-01  -1.49416775e-01
   -5.66123128e-02   5.61487908e-03  -1.21437714e-01  -1.19036585e-01
    1.60888303e-02  -2.31270730e-01   1.36650831e-01   1.19560793e-01
    1.05151750e-01  -1.37925267e-01   6.92187622e-02  -6.38726950e-02
   -2.15626843e-02  -1.16860099e-01   7.42494762e-02  -1.65246457e-01
   -6.58574402e-02   2.23061085e-01  -6.54311758e-03   1.23455748e-02
   -1.46857928e-02   2.39294648e-01   1.29955351e-01  -4.87764701e-02
   -1.42966732e-01  -1.00246832e-01  -1.80283934e-02  -3.80305164e-02
    8.51661935e-02  -4.79852520e-02   3.81334275e-02  -1.22631103e-01
   -9.65865850e-02   8.22682958e-03  -3.26035231e-01   3.56535986e-02
    2.82492898e-02   2.42110975e-02   1.61645561e-01  -2.07296666e-02
   -7.90219605e-02  -2.72546023e-01  -1.00537315e-01  -6.16170205e-02
   -1.68394625e-01   4.65777423e-03  -1.19079888e-01  -2.00444788e-01
   -3.57420385e-01   4.35338402e-03  -9.49243158e-02   7.63521856e-03
   -2.26715475e-01  -9.70644802e-02  -1.64125651e-01  -6.11680783e-02
   -3.31098661e-02   9.11533087e-03  -5.57545125e-02   6.76081032e-02
    9.23383534e-02  -4.74269725e-02  -8.92807692e-02  -1.02326944e-01
    9.77808423e-03   1.66244879e-01  -8.26107934e-02   6.44336492e-02
    6.83796257e-02   2.01410651e-01  -4.67617661e-02  -3.42278481e-02
    2.02705115e-01  -2.03834206e-01   1.37373567e-01  -2.21640635e-02
    1.19299434e-01   1.68386728e-01  -9.46241468e-02   3.86545718e-01
   -2.05556005e-01  -1.16473585e-01   2.08424497e-02  -7.67264962e-02
    2.44019270e-01   6.59995750e-02  -8.29048222e-04  -1.26079828e-01
    9.26017463e-02  -2.07062840e-01  -1.34338379e-01  -9.92221385e-02
   -5.53949401e-02  -1.98744051e-02   1.57703310e-01  -1.79024376e-02
    8.38463604e-02   5.15715592e-03  -2.50660977e-03   7.48713911e-02
    8.82912874e-02   2.83015549e-01   5.08143567e-03   8.94623548e-02
   -4.33573965e-03  -4.51157689e-02   1.79729670e-01   2.48731524e-02
   -9.94723365e-02   1.31553501e-01   1.06876127e-01  -1.18620366e-01
   -1.10018671e-01  -1.55730635e-01  -8.77903104e-02  -3.02030146e-02
   -9.91932601e-02  -7.86047652e-02  -6.47602230e-03   1.19163647e-01
   -1.55033857e-01   2.67447717e-03   6.02165274e-02   9.63416249e-02
   -3.42953682e-01  -6.28966689e-02   1.83058735e-02   1.71561301e-01
    4.53540981e-02   9.85801294e-02   8.34248494e-03  -3.57212685e-02
   -2.58186758e-01   8.72699451e-03  -1.25292435e-01   9.41473171e-02
   -3.02831568e-02  -1.88810498e-01  -4.57447767e-02   7.86445066e-02
    2.01555252e-01  -6.07179478e-02  -5.47138490e-02  -1.65675413e-02
    8.38168263e-02   2.47793496e-02   6.86428472e-02  -4.61080000e-02
   -9.08821970e-02   3.22478525e-02   5.96090481e-02  -1.41780376e-01
    7.48421401e-02  -1.26643255e-01   2.36450255e-01  -7.40280282e-03
   -2.16108859e-02   4.85453531e-02  -2.44904757e-01   2.15817476e-03
   -2.72050679e-01  -1.09079510e-01  -3.29263061e-02   1.12302825e-01
   -2.03696966e-01  -6.45644739e-02   2.22916886e-01  -7.13658333e-02
   -2.34416947e-02  -3.70380133e-02   8.25569779e-02   1.64879970e-02
    1.42457932e-01  -8.02609771e-02  -2.12907881e-01   2.84380093e-03
    4.48760018e-02  -2.30142623e-01  -8.68556947e-02  -1.02731824e-01
    4.88493778e-02  -5.49393706e-02  -6.05949722e-02   1.62723333e-01
   -2.48687826e-02  -7.39338323e-02   1.35819674e-01   3.35507169e-02
    2.68826392e-02  -7.22341537e-02   1.13382163e-02   3.70894521e-02
    2.29992904e-03   2.62968410e-02  -1.60189465e-01   1.48914680e-01
    3.49243544e-02   9.18084309e-02  -7.86332488e-02   2.80968808e-02
   -9.56157595e-02   4.01261300e-02  -2.62066841e-01   1.37390703e-01
   -7.60970358e-03   3.98698729e-04   2.41480954e-02  -7.48214126e-02
   -3.41346785e-02  -4.73326370e-02  -6.76298589e-02  -1.92983001e-01
    3.49558741e-02   2.53869683e-01   3.20646197e-01   1.05757900e-01
    2.96445303e-02  -9.21083689e-02  -7.46677369e-02  -3.97967454e-03]]
After layer activation1043_output (1, 256) <class 'numpy.float32'> [[ -1.68852627e-01  -1.45188853e-01  -3.61805670e-02   5.85247315e-02
    1.88258477e-02  -6.29770383e-02   1.27954772e-02   6.35273308e-02
    1.05667867e-01  -1.63934141e-01  -8.94733667e-02   2.06830904e-01
    1.10663213e-01  -1.33292805e-02   8.61392394e-02  -3.10989022e-01
    8.45736340e-02   2.86655631e-02   1.01183079e-01   6.36823177e-02
    2.74950743e-01  -7.84375221e-02  -2.93630566e-02   4.13765907e-02
   -1.41739994e-01   3.27973738e-02   5.26850931e-02  -5.74733093e-02
   -1.65060520e-01  -1.32651135e-01   5.03470339e-02  -1.19123749e-01
    3.09158629e-03  -3.16933612e-04   1.40121326e-01  -1.48314700e-01
   -5.65519109e-02   5.61481994e-03  -1.20844267e-01  -1.18477523e-01
    1.60874426e-02  -2.27233812e-01   1.35806561e-01   1.18994340e-01
    1.04765907e-01  -1.37057275e-01   6.91084266e-02  -6.37859777e-02
   -2.15593427e-02  -1.16331033e-01   7.41133317e-02  -1.63758621e-01
   -6.57623932e-02   2.19433710e-01  -6.54302398e-03   1.23449480e-02
   -1.46847367e-02   2.34829411e-01   1.29228681e-01  -4.87378240e-02
   -1.42000586e-01  -9.99123678e-02  -1.80264413e-02  -3.80121917e-02
    8.49608779e-02  -4.79484573e-02   3.81149538e-02  -1.22020058e-01
   -9.62873548e-02   8.22664425e-03  -3.14953744e-01   3.56385000e-02
    2.82417778e-02   2.42063683e-02   1.60252228e-01  -2.07266975e-02
   -7.88578913e-02  -2.65992314e-01  -1.00199945e-01  -6.15391582e-02
   -1.66820779e-01   4.65774070e-03  -1.18520215e-01  -1.97802752e-01
   -3.42939824e-01   4.35335655e-03  -9.46402326e-02   7.63507001e-03
   -2.22909331e-01  -9.67607945e-02  -1.62667662e-01  -6.10919073e-02
   -3.30977738e-02   9.11507849e-03  -5.56968115e-02   6.75052851e-02
    9.20768082e-02  -4.73914444e-02  -8.90443027e-02  -1.01971291e-01
    9.77777224e-03   1.64730102e-01  -8.24233815e-02   6.43446296e-02
    6.82732463e-02   1.98730648e-01  -4.67277132e-02  -3.42144892e-02
    1.99973658e-01  -2.01057360e-01   1.36515900e-01  -2.21604351e-02
    1.18736669e-01   1.66813090e-01  -9.43427458e-02   3.68378520e-01
   -2.02708974e-01  -1.15949735e-01   2.08394323e-02  -7.65762925e-02
    2.39288509e-01   6.59039095e-02  -8.29048047e-04  -1.25415996e-01
    9.23379660e-02  -2.04153448e-01  -1.33536056e-01  -9.88977998e-02
   -5.53383492e-02  -1.98717881e-02   1.56408817e-01  -1.79005247e-02
    8.36504251e-02   5.15711028e-03  -2.50660442e-03   7.47318044e-02
    8.80625844e-02   2.75693715e-01   5.08139189e-03   8.92244503e-02
   -4.33571264e-03  -4.50851843e-02   1.77819103e-01   2.48680245e-02
   -9.91455466e-02   1.30799815e-01   1.06471047e-01  -1.18067123e-01
   -1.09576918e-01  -1.54483810e-01  -8.75654668e-02  -3.01938336e-02
   -9.88692045e-02  -7.84432739e-02  -6.47593196e-03   1.18602797e-01
   -1.53803587e-01   2.67447089e-03   6.01438507e-02   9.60446596e-02
   -3.30111742e-01  -6.28138632e-02   1.83038283e-02   1.69897690e-01
    4.53230254e-02   9.82620344e-02   8.34229123e-03  -3.57060842e-02
   -2.52598763e-01   8.72677285e-03  -1.24640912e-01   9.38701406e-02
   -3.02739032e-02  -1.86598375e-01  -4.57128957e-02   7.84827694e-02
    1.98869526e-01  -6.06434420e-02  -5.46593182e-02  -1.65660251e-02
    8.36210996e-02   2.47742794e-02   6.85352385e-02  -4.60753553e-02
   -9.06328037e-02   3.22366804e-02   5.95385469e-02  -1.40837952e-01
    7.47027174e-02  -1.25970513e-01   2.32140079e-01  -7.40266778e-03
   -2.16075219e-02   4.85072546e-02  -2.40123108e-01   2.15817150e-03
   -2.65531957e-01  -1.08648941e-01  -3.29144113e-02   1.11833081e-01
   -2.00925663e-01  -6.44749105e-02   2.19296440e-01  -7.12449253e-02
   -2.34374013e-02  -3.70210856e-02   8.23699310e-02   1.64865032e-02
    1.41502008e-01  -8.00890774e-02  -2.09748149e-01   2.84379325e-03
    4.48459014e-02  -2.26163685e-01  -8.66379440e-02  -1.02371939e-01
    4.88105603e-02  -5.48841618e-02  -6.05209172e-02   1.61302149e-01
   -2.48636566e-02  -7.37994164e-02   1.34990647e-01   3.35381329e-02
    2.68761646e-02  -7.21087828e-02   1.13377301e-02   3.70724536e-02
    2.29992508e-03   2.62907818e-02  -1.58833206e-01   1.47823602e-01
    3.49101610e-02   9.15513560e-02  -7.84715787e-02   2.80894898e-02
   -9.53254402e-02   4.01046090e-02  -2.56227702e-01   1.36532709e-01
   -7.60955689e-03   3.98698699e-04   2.41434034e-02  -7.46821016e-02
   -3.41214277e-02  -4.72973213e-02  -6.75269365e-02  -1.90622449e-01
    3.49416435e-02   2.48552755e-01   3.10091078e-01   1.05365366e-01
    2.96358503e-02  -9.18487683e-02  -7.45292827e-02  -3.97965359e-03]]
After layer encoder_birnn_reverse_l0_t7_out_0 (1, 256) <class 'numpy.float32'> [[ -8.76220614e-02  -7.49651566e-02  -1.79651324e-02   3.03841233e-02
    9.52713937e-03  -3.47076766e-02   6.67802338e-03   3.35729085e-02
    6.45245910e-02  -8.74719694e-02  -4.32452708e-02   1.07434914e-01
    6.00989684e-02  -6.51668943e-03   4.42978255e-02  -1.66320786e-01
    4.09698226e-02   1.36180101e-02   5.17293513e-02   3.17120962e-02
    1.34124666e-01  -3.63985896e-02  -1.68870948e-02   2.18556114e-02
   -7.22369179e-02   1.70643181e-02   2.60308012e-02  -2.84080617e-02
   -7.77130350e-02  -6.66850805e-02   2.66419947e-02  -6.26263618e-02
    1.57725275e-03  -1.61396674e-04   6.95172772e-02  -7.18992576e-02
   -2.99127549e-02   2.79046549e-03  -6.21462502e-02  -5.81504926e-02
    8.26232322e-03  -1.12110347e-01   6.77958429e-02   5.98159544e-02
    5.15258983e-02  -6.99285194e-02   3.51533778e-02  -3.04006878e-02
   -1.09091429e-02  -6.18572272e-02   3.86213399e-02  -8.17503780e-02
   -3.10853161e-02   1.12871885e-01  -3.53490887e-03   5.84565382e-03
   -7.94127025e-03   1.19434461e-01   6.55481815e-02  -2.29183789e-02
   -7.40355775e-02  -5.23105748e-02  -9.13355872e-03  -2.07169447e-02
    4.23481464e-02  -2.33599171e-02   2.11393237e-02  -6.29824698e-02
   -4.75944728e-02   4.23207879e-03  -1.58682883e-01   1.80948265e-02
    1.41009958e-02   1.19922841e-02   8.57841596e-02  -1.13162408e-02
   -4.24429998e-02  -1.35611176e-01  -5.35400696e-02  -3.41940112e-02
   -9.13745388e-02   2.57239561e-03  -6.28212839e-02  -1.04099050e-01
   -1.86656147e-01   2.23433017e-03  -4.84267622e-02   3.96139547e-03
   -1.16303802e-01  -4.92845699e-02  -8.86010081e-02  -2.97830645e-02
   -1.57446358e-02   4.61944612e-03  -2.83079650e-02   3.42271663e-02
    4.72625643e-02  -2.44852602e-02  -4.11617421e-02  -4.76916209e-02
    4.70975460e-03   7.60043561e-02  -3.92939858e-02   3.05682868e-02
    3.35076526e-02   9.96219516e-02  -2.28408221e-02  -1.82650182e-02
    1.03323691e-01  -1.05610751e-01   6.91110641e-02  -1.14049837e-02
    5.65222166e-02   8.98724794e-02  -4.70564999e-02   1.99184000e-01
   -9.77214426e-02  -5.69992252e-02   1.06355706e-02  -3.72121595e-02
    1.21789210e-01   3.45812850e-02  -4.30722401e-04  -6.25537112e-02
    4.45237756e-02  -1.04164898e-01  -6.69144467e-02  -4.96260487e-02
   -2.74710674e-02  -9.33250040e-03   7.91524202e-02  -9.76850186e-03
    4.13295031e-02   2.72861682e-03  -1.28536124e-03   3.56714204e-02
    4.72743027e-02   1.41502410e-01   2.71700951e-03   4.55944538e-02
   -2.19285069e-03  -2.24183742e-02   8.59349668e-02   1.30010191e-02
   -4.92038280e-02   6.65031746e-02   5.81283942e-02  -6.17178045e-02
   -5.55980764e-02  -7.64445588e-02  -4.33400460e-02  -1.48712480e-02
   -5.17036729e-02  -4.20313179e-02  -3.18761612e-03   6.14306703e-02
   -8.14602971e-02   1.39500026e-03   3.06601282e-02   5.16331047e-02
   -1.72280431e-01  -3.21671702e-02   9.17746406e-03   9.08617377e-02
    2.36813072e-02   4.68528233e-02   4.80266102e-03  -1.89271811e-02
   -1.16576664e-01   4.41899523e-03  -5.83394095e-02   5.00319041e-02
   -1.59331243e-02  -1.03995286e-01  -2.28954926e-02   4.29398194e-02
    1.07295893e-01  -2.92199291e-02  -2.82128658e-02  -8.19283724e-03
    3.90083082e-02   1.17998002e-02   3.53497528e-02  -2.18962692e-02
   -4.36480232e-02   1.74441449e-02   2.92833429e-02  -7.46825859e-02
    3.64112072e-02  -5.87600134e-02   1.16721950e-01  -3.97773506e-03
   -1.11326417e-02   2.46315803e-02  -1.16890281e-01   1.11719337e-03
   -1.30278587e-01  -5.54636456e-02  -1.74690709e-02   5.68709783e-02
   -1.04943462e-01  -3.57507318e-02   1.14958085e-01  -3.85452136e-02
   -1.22900298e-02  -1.93926021e-02   3.92763168e-02   8.49601999e-03
    6.65038675e-02  -4.37209979e-02  -1.05178334e-01   1.64416817e-03
    2.33145468e-02  -1.22721210e-01  -4.58189547e-02  -4.93290834e-02
    2.51078475e-02  -3.05306576e-02  -2.97453422e-02   7.83014148e-02
   -1.22288028e-02  -3.37179340e-02   7.33923167e-02   1.70203242e-02
    1.39453011e-02  -3.79262678e-02   5.65632060e-03   1.89905614e-02
    1.35859102e-03   1.42198168e-02  -7.98964128e-02   6.76140860e-02
    1.71842817e-02   4.60405722e-02  -3.88662070e-02   1.42879821e-02
   -4.70558070e-02   2.09633317e-02  -1.36114493e-01   7.00203031e-02
   -3.46865435e-03   2.08537429e-04   1.25036724e-02  -4.34064083e-02
   -1.56832784e-02  -2.43957583e-02  -3.35666165e-02  -8.80538598e-02
    1.78602915e-02   1.22361302e-01   1.64531514e-01   4.99753021e-02
    1.57119744e-02  -4.92695607e-02  -3.71930972e-02  -2.04749964e-03]]
After layer expand_dims1049_0 (1, 1, 256) <class 'numpy.float32'> [[[ -8.76220614e-02  -7.49651566e-02  -1.79651324e-02   3.03841233e-02
     9.52713937e-03  -3.47076766e-02   6.67802338e-03   3.35729085e-02
     6.45245910e-02  -8.74719694e-02  -4.32452708e-02   1.07434914e-01
     6.00989684e-02  -6.51668943e-03   4.42978255e-02  -1.66320786e-01
     4.09698226e-02   1.36180101e-02   5.17293513e-02   3.17120962e-02
     1.34124666e-01  -3.63985896e-02  -1.68870948e-02   2.18556114e-02
    -7.22369179e-02   1.70643181e-02   2.60308012e-02  -2.84080617e-02
    -7.77130350e-02  -6.66850805e-02   2.66419947e-02  -6.26263618e-02
     1.57725275e-03  -1.61396674e-04   6.95172772e-02  -7.18992576e-02
    -2.99127549e-02   2.79046549e-03  -6.21462502e-02  -5.81504926e-02
     8.26232322e-03  -1.12110347e-01   6.77958429e-02   5.98159544e-02
     5.15258983e-02  -6.99285194e-02   3.51533778e-02  -3.04006878e-02
    -1.09091429e-02  -6.18572272e-02   3.86213399e-02  -8.17503780e-02
    -3.10853161e-02   1.12871885e-01  -3.53490887e-03   5.84565382e-03
    -7.94127025e-03   1.19434461e-01   6.55481815e-02  -2.29183789e-02
    -7.40355775e-02  -5.23105748e-02  -9.13355872e-03  -2.07169447e-02
     4.23481464e-02  -2.33599171e-02   2.11393237e-02  -6.29824698e-02
    -4.75944728e-02   4.23207879e-03  -1.58682883e-01   1.80948265e-02
     1.41009958e-02   1.19922841e-02   8.57841596e-02  -1.13162408e-02
    -4.24429998e-02  -1.35611176e-01  -5.35400696e-02  -3.41940112e-02
    -9.13745388e-02   2.57239561e-03  -6.28212839e-02  -1.04099050e-01
    -1.86656147e-01   2.23433017e-03  -4.84267622e-02   3.96139547e-03
    -1.16303802e-01  -4.92845699e-02  -8.86010081e-02  -2.97830645e-02
    -1.57446358e-02   4.61944612e-03  -2.83079650e-02   3.42271663e-02
     4.72625643e-02  -2.44852602e-02  -4.11617421e-02  -4.76916209e-02
     4.70975460e-03   7.60043561e-02  -3.92939858e-02   3.05682868e-02
     3.35076526e-02   9.96219516e-02  -2.28408221e-02  -1.82650182e-02
     1.03323691e-01  -1.05610751e-01   6.91110641e-02  -1.14049837e-02
     5.65222166e-02   8.98724794e-02  -4.70564999e-02   1.99184000e-01
    -9.77214426e-02  -5.69992252e-02   1.06355706e-02  -3.72121595e-02
     1.21789210e-01   3.45812850e-02  -4.30722401e-04  -6.25537112e-02
     4.45237756e-02  -1.04164898e-01  -6.69144467e-02  -4.96260487e-02
    -2.74710674e-02  -9.33250040e-03   7.91524202e-02  -9.76850186e-03
     4.13295031e-02   2.72861682e-03  -1.28536124e-03   3.56714204e-02
     4.72743027e-02   1.41502410e-01   2.71700951e-03   4.55944538e-02
    -2.19285069e-03  -2.24183742e-02   8.59349668e-02   1.30010191e-02
    -4.92038280e-02   6.65031746e-02   5.81283942e-02  -6.17178045e-02
    -5.55980764e-02  -7.64445588e-02  -4.33400460e-02  -1.48712480e-02
    -5.17036729e-02  -4.20313179e-02  -3.18761612e-03   6.14306703e-02
    -8.14602971e-02   1.39500026e-03   3.06601282e-02   5.16331047e-02
    -1.72280431e-01  -3.21671702e-02   9.17746406e-03   9.08617377e-02
     2.36813072e-02   4.68528233e-02   4.80266102e-03  -1.89271811e-02
    -1.16576664e-01   4.41899523e-03  -5.83394095e-02   5.00319041e-02
    -1.59331243e-02  -1.03995286e-01  -2.28954926e-02   4.29398194e-02
     1.07295893e-01  -2.92199291e-02  -2.82128658e-02  -8.19283724e-03
     3.90083082e-02   1.17998002e-02   3.53497528e-02  -2.18962692e-02
    -4.36480232e-02   1.74441449e-02   2.92833429e-02  -7.46825859e-02
     3.64112072e-02  -5.87600134e-02   1.16721950e-01  -3.97773506e-03
    -1.11326417e-02   2.46315803e-02  -1.16890281e-01   1.11719337e-03
    -1.30278587e-01  -5.54636456e-02  -1.74690709e-02   5.68709783e-02
    -1.04943462e-01  -3.57507318e-02   1.14958085e-01  -3.85452136e-02
    -1.22900298e-02  -1.93926021e-02   3.92763168e-02   8.49601999e-03
     6.65038675e-02  -4.37209979e-02  -1.05178334e-01   1.64416817e-03
     2.33145468e-02  -1.22721210e-01  -4.58189547e-02  -4.93290834e-02
     2.51078475e-02  -3.05306576e-02  -2.97453422e-02   7.83014148e-02
    -1.22288028e-02  -3.37179340e-02   7.33923167e-02   1.70203242e-02
     1.39453011e-02  -3.79262678e-02   5.65632060e-03   1.89905614e-02
     1.35859102e-03   1.42198168e-02  -7.98964128e-02   6.76140860e-02
     1.71842817e-02   4.60405722e-02  -3.88662070e-02   1.42879821e-02
    -4.70558070e-02   2.09633317e-02  -1.36114493e-01   7.00203031e-02
    -3.46865435e-03   2.08537429e-04   1.25036724e-02  -4.34064083e-02
    -1.56832784e-02  -2.43957583e-02  -3.35666165e-02  -8.80538598e-02
     1.78602915e-02   1.22361302e-01   1.64531514e-01   4.99753021e-02
     1.57119744e-02  -4.92695607e-02  -3.71930972e-02  -2.04749964e-03]]]
After layer encoder_birnn_reverse_l0_t8_i2h_output (1, 1024) <class 'numpy.float32'> [[-0.0128371  -0.04095686  0.03787835 ...,  0.06970935 -0.04625846
   0.03761056]]
After layer encoder_birnn_reverse_l0_t8_h2h_output (1, 1024) <class 'numpy.float32'> [[-0.00223176  0.01062416 -0.09029895 ...,  0.08187129  0.04470106
   0.01998497]]
After layer _plus1044_0 (1, 1024) <class 'numpy.float32'> [[-0.01506886 -0.03033271 -0.0524206  ...,  0.15158063 -0.00155739
   0.05759553]]
After layer encoder_birnn_reverse_l0_t8_slice_output0 (1, 256) <class 'numpy.float32'> [[ -1.50688551e-02  -3.03327069e-02  -5.24205975e-02  -3.07343192e-02
   -2.83618942e-02  -3.72615382e-02  -1.61281824e-02  -3.19257379e-04
    9.65056270e-02   7.71884918e-02  -5.59124686e-02   1.16036825e-01
    1.85849518e-03   1.35473460e-02  -6.66148961e-04   3.30562025e-01
   -1.41957209e-01  -9.95695069e-02   1.31558543e-02  -1.11212563e-02
    1.21204667e-01  -5.19042835e-03  -1.57996297e-01  -6.03582636e-02
    5.14180511e-02  -1.31597415e-01  -3.04395445e-02  -1.34320557e-03
   -9.58609954e-03  -2.15466879e-02  -1.01595148e-02  -1.07782185e-02
   -6.30816817e-02  -4.39703837e-02   9.32409391e-02  -1.76821038e-01
   -1.83709916e-02  -1.95795279e-02  -9.36154127e-02  -8.85543749e-02
   -1.91708252e-01   2.53632516e-02  -4.67174426e-02   9.13883746e-03
    2.78598070e-02  -2.20366158e-02   7.92790130e-02  -9.19797868e-02
   -5.99847138e-02   2.45054364e-02   3.37760299e-02   1.15957737e-01
   -1.95440486e-01   9.21328068e-02   1.86742246e-01   1.31182805e-01
   -8.17442983e-02   1.57841966e-02  -9.95799825e-02  -9.76623222e-03
    9.77612138e-02  -7.43742958e-02   1.60803258e-01  -2.47595459e-02
   -1.14850335e-01  -4.28587422e-02   1.19819321e-01  -2.23887563e-02
   -1.20814815e-01  -1.17755383e-02   1.15786836e-01  -1.83433369e-02
   -2.61920802e-02  -3.69200967e-02   2.12609507e-02   4.68805954e-02
    1.16246715e-01   1.79743290e-01   5.37950844e-02   7.20485896e-02
    2.43426953e-02   4.83495034e-02   9.50903147e-02  -2.91260295e-02
    1.69439524e-01   2.55602524e-02  -2.43559778e-02  -1.03468649e-01
   -1.40940733e-02   4.74862829e-02   1.22098461e-01   1.07037611e-02
   -8.85598660e-02   7.13104829e-02   7.28068426e-02   3.29598561e-02
   -3.31204683e-02   7.74976611e-03  -1.29960254e-01  -1.43086150e-01
   -1.44683838e-01   7.63133541e-02   2.41884217e-02  -1.08722724e-01
   -1.54120490e-01   5.41267544e-03  -3.06892190e-02  -1.11885130e-01
    8.15134794e-02  -1.75836235e-02  -1.00008398e-01  -2.07805932e-02
    3.57900038e-02   2.63192207e-01   2.20843740e-02   3.22750628e-01
   -1.94951706e-02   6.63339347e-03  -6.19480014e-03  -6.60602748e-02
    2.27400124e-01  -1.30815521e-01  -1.98209509e-02   1.07516602e-01
   -9.42045152e-02   8.49980488e-02  -1.50116637e-01   8.72943848e-02
   -3.54563259e-02   1.15089603e-02   2.41304845e-01   3.97633091e-02
   -8.88598710e-03  -5.56904040e-02  -9.41764712e-02  -1.30080715e-01
    1.24825083e-01   1.70169443e-01  -3.15438360e-02  -1.08953342e-02
   -4.24988791e-02  -1.48427919e-01   1.06440581e-01   5.01529127e-02
   -6.64497167e-03   8.05268437e-03   4.02273946e-02   6.72275200e-02
   -5.34721464e-03   8.31999034e-02   1.30598575e-01  -7.57709146e-02
   -3.45626287e-03  -9.25382301e-02  -1.28802627e-01   2.04283446e-01
    2.65550017e-02  -2.24219263e-03  -2.55940817e-02  -3.01445611e-02
    2.56528080e-01  -5.20728528e-03  -8.31554160e-02   1.52244344e-02
    3.67165171e-03  -8.30478370e-02  -1.38605535e-02  -6.12432212e-02
    2.85903364e-02  -5.11137396e-02  -1.89440344e-02   4.73765060e-02
    4.28189151e-03   9.99180302e-02   1.98376495e-02  -1.95620388e-01
    4.73692417e-02  -1.41938686e-01  -6.94714561e-02  -1.52837597e-02
    6.12234585e-02  -7.94475526e-02  -7.38655776e-03   2.63152793e-02
    1.09132484e-01  -1.34674758e-02  -1.96286030e-02  -5.15752211e-02
    9.70219970e-02   3.11175734e-02  -5.91499656e-02  -4.96466048e-02
    2.83555444e-02  -7.06286654e-02  -8.34059417e-02   1.01067685e-01
    1.17539659e-01  -1.81902960e-01   4.34381776e-02   1.05787218e-01
    1.28063411e-02   9.28812101e-02   8.89236704e-02   8.60005617e-02
    1.69974938e-03  -4.95220944e-02  -1.87011212e-02  -5.00509590e-02
   -8.96082819e-02   3.55849825e-02   5.30847237e-02   1.42121777e-01
    2.14950480e-02   4.22783345e-02  -1.82016362e-02  -2.79107466e-02
   -5.47168218e-03  -2.05101110e-02   4.68246154e-02  -5.64167090e-03
   -7.38195851e-02  -1.40748292e-01   1.20066628e-01  -8.75115097e-02
   -1.09478580e-02   6.86419159e-02  -3.52545604e-02  -1.10473305e-01
   -1.48847818e-01   7.08546788e-02  -1.61477961e-02  -1.64562792e-01
   -1.75401922e-02  -5.82572594e-02   2.61184517e-02   5.94770387e-02
   -4.94165346e-03   8.75751749e-02   3.86726744e-02  -1.99248120e-02
   -1.50138468e-01  -1.63744643e-01   9.47793573e-02   2.41408676e-01
   -7.02889636e-02   1.77190378e-02  -1.34717137e-01  -9.39224213e-02
    9.33671370e-03  -2.17013936e-02   1.83626503e-01  -2.18298770e-02
   -1.38922632e-01   5.72086312e-02   5.38079962e-02   4.61925566e-03]]
After layer encoder_birnn_reverse_l0_t8_slice_output1 (1, 256) <class 'numpy.float32'> [[ 0.16510122  0.05306405  0.12479486  0.03940246 -0.0142356   0.08690622
   0.21057878 -0.10845134  0.41086179  0.19754365  0.13143621  0.16469902
   0.14203191 -0.01039989  0.13893226  0.15807945  0.09224382 -0.01905207
  -0.15410379  0.10447721  0.15927941  0.03114414  0.48304155  0.07931196
   0.13107893  0.0899189   0.18786213  0.07553568  0.13584512  0.0423579
   0.10536256  0.05102673  0.2601437  -0.05248724 -0.00499207 -0.02550624
  -0.05822544  0.17507306  0.02619408  0.08505236 -0.11682244  0.12263519
   0.01908608  0.11405884  0.05496472  0.1370289   0.03883283 -0.14363305
  -0.01696707  0.00784483  0.0798326   0.11382799 -0.06809404  0.16948768
   0.06845897  0.04623618  0.06229235  0.11699536 -0.01824192 -0.11992828
   0.12902226  0.04577887  0.09605139  0.02202546 -0.03365256  0.1697351
   0.23359101  0.09763365 -0.17810723 -0.07011595  0.07626039  0.0117298
  -0.06675072  0.04846649  0.12601304  0.15057147  0.07869586  0.09024866
   0.11766376  0.11384249  0.23975416  0.22003451  0.03917848  0.01816681
   0.21067283 -0.01649831  0.1115043   0.1667681   0.04520519 -0.1945022
   0.3687658   0.07793069  0.08396125  0.07568368 -0.07131134  0.00543947
  -0.02137036  0.01398648 -0.20459083 -0.1893789  -0.09551208 -0.02725805
   0.06130325  0.12469055 -0.0395878  -0.03823164 -0.11849593  0.06151168
   0.11168137 -0.15763484  0.06820675 -0.03045878  0.07958     0.25032216
   0.10522349  0.2200803   0.1514861   0.14560214  0.04500823  0.12025136
   0.23058163  0.19012628  0.04745421  0.01866802 -0.05764831 -0.00580723
   0.1862866  -0.00379189  0.1098     -0.1258297   0.16223866  0.11479898
   0.02165822  0.21352397  0.0468563   0.03338934  0.02950694  0.07496235
   0.16407485  0.2599543  -0.06675625  0.03019273  0.09506307  0.04334222
   0.06212277  0.1317724   0.12671417  0.04399401  0.05291721 -0.03699288
  -0.02620568  0.10084213  0.06582627  0.12692682 -0.03692782  0.19532079
   0.10943119 -0.08124501  0.08622852  0.17297429  0.24511543  0.10826035
  -0.03037231  0.10660818  0.12466124 -0.02779206  0.31098559 -0.02252584
  -0.00359058 -0.00379467  0.01962192  0.153179   -0.00366181  0.23086153
  -0.06900547  0.15339136  0.1872853  -0.03835699  0.00161875  0.1258913
   0.08771026 -0.07792665  0.26327816 -0.02932402 -0.00868069  0.05817435
   0.03111004  0.22938648 -0.06493044 -0.08427908 -0.04139929  0.06840814
   0.2048983   0.17739871 -0.19392461  0.01439608  0.00569774 -0.01602799
   0.0355808   0.03133091  0.08406534  0.03298985  0.08817524 -0.01363473
   0.12523842 -0.15051997 -0.06943101  0.19241367 -0.09892292  0.11771234
   0.08085904  0.11800766 -0.05569293  0.04125343 -0.00777709 -0.12354644
   0.0705125   0.11279957 -0.03877633  0.14284204 -0.10405733 -0.11342135
   0.29285467 -0.00254777  0.10620165 -0.0008895   0.03947819  0.07410542
   0.44842577  0.18537933  0.06223702 -0.31755525  0.16918059  0.04442137
   0.09220092 -0.00720515  0.00694747  0.09894517  0.08159285  0.10150073
   0.05292768  0.07591656 -0.01214876  0.23200506 -0.1783963  -0.00470844
  -0.10069349 -0.05104023  0.13587981 -0.04504255  0.20360592 -0.20452231
   0.1703174   0.00484859  0.1463979   0.00472483]]
After layer encoder_birnn_reverse_l0_t8_slice_output2 (1, 256) <class 'numpy.float32'> [[ -1.69719130e-01  -1.54035151e-01  -5.16997837e-02   7.32385218e-02
   -1.58360228e-03  -6.39115050e-02  -1.09020472e-02   4.88788523e-02
    1.20551981e-01  -1.91506475e-01  -9.20172781e-02   2.39448607e-01
    1.22027382e-01   2.39944365e-03   9.78698879e-02  -3.07291955e-01
    1.00832678e-01   3.33337225e-02   1.22964449e-01   7.24399686e-02
    3.09450507e-01  -9.11559686e-02  -5.42462543e-02   2.71448977e-02
   -1.48192048e-01   3.39381956e-02   4.23508584e-02  -5.60277067e-02
   -1.72711760e-01  -1.52614027e-01   5.28350696e-02  -1.17809661e-01
    1.28969029e-02  -1.07240714e-02   1.56612754e-01  -1.71947598e-01
   -5.56863472e-02   1.44876614e-02  -1.29222944e-01  -1.35406762e-01
    8.01707059e-03  -2.44565353e-01   1.54499531e-01   1.41587213e-01
    1.13301776e-01  -1.55077338e-01   9.44680199e-02  -7.21542239e-02
   -3.32057141e-02  -1.27759576e-01   6.97943643e-02  -1.76978827e-01
   -5.56703396e-02   2.63511747e-01  -4.82962728e-02   1.04516372e-03
    5.21354377e-05   2.67667085e-01   1.62824482e-01  -5.42678051e-02
   -1.65683776e-01  -1.03830978e-01  -9.34860483e-03  -5.58954552e-02
    1.10812843e-01  -5.46565801e-02   2.93117668e-02  -1.30530387e-01
   -1.13127537e-01   2.05200762e-02  -3.57962996e-01   5.04828095e-02
    7.49936700e-03   2.50729490e-02   1.76544547e-01  -2.61217356e-04
   -9.26424712e-02  -2.97187299e-01  -1.21322691e-01  -7.76086301e-02
   -1.85098052e-01  -8.85894895e-03  -1.34238124e-01  -2.31578067e-01
   -3.69781166e-01  -3.51926126e-03  -6.66403696e-02  -1.36205442e-02
   -2.68156201e-01  -8.12216550e-02  -1.61497667e-01  -5.96052930e-02
   -3.81362215e-02   2.50503849e-02  -5.58412820e-02   8.01880583e-02
    9.00512561e-02  -3.61299217e-02  -9.91814733e-02  -1.37559250e-01
    3.46077234e-03   1.82340026e-01  -9.14450958e-02   8.24970305e-02
    8.62897038e-02   2.39451483e-01  -5.65560386e-02  -2.35854387e-02
    2.23104313e-01  -2.29107693e-01   1.78986907e-01  -4.01796475e-02
    1.47466466e-01   1.78813726e-01  -8.64241123e-02   3.66019875e-01
   -2.34382421e-01  -1.28463253e-01  -1.19769443e-02  -8.03278834e-02
    2.47801110e-01   5.82611933e-02   1.73003469e-02  -1.39605373e-01
    8.71583968e-02  -2.26160958e-01  -1.53075770e-01  -1.12801254e-01
   -6.10968731e-02  -1.51962489e-02   1.81201518e-01  -1.69729441e-03
    9.06601250e-02  -3.56359407e-03  -1.06058978e-02   7.76904449e-02
    8.54288638e-02   2.99178332e-01   1.51680522e-02   9.93440598e-02
   -9.90469009e-03  -4.63235863e-02   1.90181449e-01   1.87828504e-02
   -1.12658627e-01   1.50248185e-01   1.29543096e-01  -1.17075846e-01
   -1.20528415e-01  -1.71430260e-01  -1.07563138e-01  -3.31521221e-02
   -1.22489721e-01  -8.18779022e-02  -1.57825164e-02   1.29681438e-01
   -1.67124838e-01  -2.41382383e-02   6.52469620e-02   1.10640660e-01
   -3.48024845e-01  -5.65631650e-02   8.63058120e-03   1.73627257e-01
    5.36586456e-02   1.04693130e-01  -7.28779472e-03  -3.04858685e-02
   -3.03915232e-01  -1.61901116e-05  -1.43392757e-01   1.21895991e-01
   -1.79199837e-02  -1.74100772e-01  -6.84721172e-02   7.99092352e-02
    2.13273033e-01  -7.98183084e-02  -5.29922023e-02  -6.40687346e-03
    8.35783854e-02   3.47958505e-02   8.49537700e-02  -5.83031736e-02
   -1.09158769e-01   8.77045095e-03   6.67730272e-02  -1.60952568e-01
    4.59097065e-02  -1.16892874e-01   2.83675015e-01   1.25087053e-03
   -2.73999497e-02   5.63684739e-02  -2.97599137e-01   7.67933577e-03
   -3.01399678e-01  -1.44385368e-01  -2.56911572e-02   1.37948647e-01
   -2.34058619e-01  -7.58706927e-02   2.39687040e-01  -8.25381130e-02
   -2.88264565e-02  -4.65891734e-02   9.49242413e-02   2.01042220e-02
    1.66950718e-01  -6.98771924e-02  -2.37184480e-01   5.87473065e-03
    6.05324246e-02  -2.58060753e-01  -1.13504782e-01  -1.21076606e-01
    6.26524314e-02  -6.33116886e-02  -8.07752460e-02   1.86879680e-01
   -2.21640095e-02  -7.43912309e-02   1.57406285e-01   4.20298353e-02
    3.75546068e-02  -8.12715217e-02   1.37780616e-02   4.42555249e-02
   -3.58074717e-02   5.24461940e-02  -1.70958742e-01   1.89027488e-01
    2.40575820e-02   9.69807804e-02  -8.36693347e-02   2.66499165e-02
   -1.00030437e-01   5.40543571e-02  -3.14720929e-01   1.46522567e-01
   -2.80093420e-02   1.15047488e-02   8.52928311e-03  -7.33788311e-02
   -3.86869721e-02  -3.35403085e-02  -8.90268832e-02  -2.31789246e-01
    4.61620241e-02   2.98304379e-01   3.50508153e-01   1.23182252e-01
    1.43376403e-02  -1.01159774e-01  -8.23631138e-02   1.47357024e-03]]
After layer encoder_birnn_reverse_l0_t8_slice_output3 (1, 256) <class 'numpy.float32'> [[ 0.082776    0.0743852  -0.01161243  0.08111472  0.01740744  0.20815273
   0.08232045  0.10818308  0.47663331  0.14446802 -0.0710206   0.08298407
   0.17783639 -0.04632988  0.06256227  0.1491328  -0.06139493 -0.10106824
   0.05128463 -0.00188302 -0.050359   -0.15085515  0.32119215  0.11719182
   0.03011835  0.09374973 -0.02667102 -0.02651541 -0.12593663  0.00870287
   0.11994591  0.10616889  0.04616879  0.04185558 -0.01158785 -0.06820799
   0.12048814 -0.01187722  0.04922339 -0.0463873   0.04391192 -0.02452287
  -0.00246009  0.01534032 -0.03102519  0.04445363  0.04105779 -0.10505225
   0.02471795  0.1308306   0.0851752   0.00531171 -0.12714556  0.05916376
   0.17016093 -0.10266706  0.17058001  0.0408165   0.02735363 -0.11950068
   0.09713463  0.10408525  0.02752547  0.18798867 -0.00796959 -0.04614288
   0.22916764  0.06837898 -0.03501561  0.04906045  0.01460597  0.03082207
  -0.0044528  -0.01878199  0.15417585  0.17517018  0.15397292  0.03826721
   0.14574803  0.23039714  0.20239951  0.21467203  0.13276038  0.10087866
   0.18570334  0.05344468  0.0549863   0.06652108  0.09058848  0.02865716
   0.18961455 -0.05110108 -0.10209884  0.02792175  0.02558796  0.02752351
   0.04980605  0.04971549 -0.15447013 -0.13648926 -0.08290335 -0.1592381
  -0.09924398 -0.10384282 -0.04538048  0.00382865 -0.04774695  0.1404497
   0.07046635  0.0850303   0.03522244  0.06012376 -0.10154331  0.1622014
  -0.00727005  0.16809481 -0.06803223 -0.03751733  0.04005998 -0.05713524
   0.04127275  0.10282106  0.07632121 -0.01146883 -0.07932536  0.04513236
   0.01366004  0.01214083 -0.01055597 -0.13024302  0.02870968  0.18128836
  -0.02240754  0.12696342  0.05255366 -0.09750199  0.15760601  0.05002401
   0.14785926  0.05351733  0.02725789 -0.01246794 -0.06276278  0.10121424
  -0.01867851  0.0395721   0.19917595  0.10325833  0.02704625 -0.02379093
  -0.01722236 -0.0291736   0.10389979  0.15063022 -0.04250014  0.07006728
   0.12948118  0.07849942  0.03874088  0.1595152   0.09120198  0.06068642
   0.01364949  0.14058898  0.09712991 -0.10106705  0.32388729  0.12661973
  -0.16215673  0.02949202 -0.13905367  0.14428011  0.11805734  0.24482071
  -0.0014212   0.19642174  0.16238983 -0.07693431  0.05850015 -0.0249228
  -0.14246197 -0.10728475  0.07283053 -0.10886843 -0.08149851  0.18010142
  -0.04026238  0.12970887 -0.05943542 -0.14584909  0.01057924  0.1535731
   0.06732811  0.03841567 -0.07846297  0.07716438 -0.04008354  0.03998237
   0.12612021  0.04337627  0.09500828  0.22248317  0.10072467  0.1714135
   0.09986014  0.09706971 -0.10204482  0.06843227 -0.13001588  0.1925548
   0.00939494  0.32679331  0.08921766  0.17865573  0.12533474 -0.08339623
   0.05901693  0.243985   -0.03293031 -0.05968924 -0.02888992 -0.18975383
   0.18873069  0.02928258  0.07771191  0.10596035 -0.00495669  0.05409586
   0.39084625  0.15424934  0.01143467 -0.18252005 -0.03164043  0.01658435
  -0.0160688   0.04185134 -0.02091518  0.1002298   0.13335893  0.06046513
  -0.20032649  0.09634137  0.06710367  0.33301184 -0.17949642  0.06592631
  -0.0242401  -0.16246156  0.0476458  -0.03797433  0.1308541  -0.10831015
   0.12985624  0.15158063 -0.00155739  0.05759553]]
After layer encoder_birnn_reverse_l0_t8_o_output (1, 256) <class 'numpy.float32'> [[ 0.52068222  0.51858777  0.49709693  0.52026755  0.50435174  0.55185109
   0.52056849  0.52701938  0.6169526   0.53605431  0.48225236  0.52073413
   0.54434234  0.48841956  0.51563549  0.53721422  0.4846561   0.47475442
   0.5128184   0.49952921  0.4874129   0.46235758  0.57961476  0.52926445
   0.50752902  0.52342027  0.49333262  0.49337155  0.46855742  0.50217569
   0.52995056  0.52651733  0.51154017  0.5104624   0.49710304  0.48295462
   0.53008562  0.49703071  0.51230335  0.48840523  0.5109762   0.49386957
   0.49938497  0.50383502  0.4922443   0.51111156  0.51026303  0.47376102
   0.50617921  0.53266108  0.52128094  0.50132793  0.46825632  0.5147866
   0.54243791  0.47435576  0.54254192  0.51020271  0.50683802  0.47016034
   0.52426463  0.52599782  0.50688094  0.54685926  0.49800763  0.48846632
   0.55704248  0.51708812  0.49124697  0.51226264  0.50365144  0.50770491
   0.49888679  0.49530464  0.53846782  0.54368091  0.53841734  0.50956565
   0.53637266  0.55734587  0.55042791  0.55346286  0.53314143  0.52519828
   0.5462929   0.513358    0.5137431   0.51662415  0.52263165  0.50716382
   0.54726213  0.48722753  0.47449744  0.50698     0.50639665  0.50688046
   0.51244897  0.51242632  0.46145907  0.46593055  0.47928604  0.46027443
   0.47520933  0.47406262  0.48865685  0.50095719  0.48806548  0.5350548
   0.5176093   0.52124476  0.50880468  0.51502639  0.47463599  0.54046166
   0.49818248  0.54192501  0.48299852  0.49062178  0.51001364  0.48572007
   0.51031673  0.52568263  0.51907104  0.49713287  0.48017904  0.51128119
   0.50341499  0.50303519  0.497361    0.46748516  0.50717694  0.54519838
   0.49439836  0.53169829  0.51313537  0.47564378  0.53932011  0.51250339
   0.5368976   0.51337612  0.50681406  0.49688303  0.48431444  0.52528197
   0.49533048  0.50989169  0.54962999  0.5257917   0.50676113  0.49405253
   0.49569449  0.49270713  0.52595162  0.53758651  0.48937654  0.51750964
   0.53232515  0.51961476  0.50968397  0.53979445  0.52278471  0.515167
   0.50341231  0.53508943  0.52426338  0.47475469  0.5802713   0.53161269
   0.45954943  0.5073725   0.46529251  0.53600758  0.5294801   0.56090134
   0.4996447   0.54894817  0.54050845  0.48077592  0.51462084  0.49376965
   0.46444467  0.47320452  0.51819962  0.47280976  0.47963664  0.54490405
   0.48993579  0.53238183  0.48514548  0.46360224  0.50264478  0.53831798
   0.51682568  0.50960273  0.4803943   0.51928157  0.48998043  0.50999427
   0.53148836  0.51084238  0.52373421  0.5553925   0.5251599   0.54274875
   0.52494431  0.52424842  0.47451091  0.51710141  0.46754175  0.5479905
   0.50234872  0.58097893  0.52228963  0.54454547  0.53129274  0.47916299
   0.51474994  0.56069553  0.49176818  0.48508209  0.49277803  0.45270339
   0.54704314  0.50732011  0.51941818  0.52646536  0.49876079  0.51352072
   0.59648639  0.53848606  0.50285864  0.45449623  0.49209052  0.50414604
   0.49598289  0.51046133  0.49477142  0.52503651  0.53329039  0.51511168
   0.45008522  0.52406669  0.51676965  0.58249199  0.45524597  0.51647562
   0.49394029  0.45947373  0.51190919  0.49050754  0.53266692  0.47294891
   0.53241849  0.53782278  0.49961066  0.51439488]]
After layer encoder_birnn_reverse_l0_t8_f_output (1, 256) <class 'numpy.float32'> [[ 0.5411818   0.51326293  0.53115827  0.50984931  0.49644113  0.5217129
   0.55245101  0.47291371  0.60129452  0.54922593  0.53281182  0.54108196
   0.53544843  0.49740005  0.53467733  0.53943777  0.52304465  0.49523714
   0.46155012  0.52609557  0.53973585  0.50778544  0.61846584  0.51981759
   0.53272289  0.52246457  0.54682791  0.51887494  0.5339092   0.51058793
   0.52631629  0.5127539   0.56467164  0.48688117  0.49875197  0.49362379
   0.48544776  0.54365677  0.50654817  0.52125031  0.47082752  0.5306204
   0.50477141  0.52848381  0.51373774  0.53420371  0.50970697  0.46415335
   0.49575835  0.50196123  0.51994753  0.52842629  0.48298305  0.54227078
   0.51710808  0.51155698  0.51556808  0.52921551  0.49543965  0.47005379
   0.53221089  0.51144272  0.52399439  0.50550616  0.49158764  0.54233223
   0.55813366  0.52438909  0.45559052  0.4824782   0.51905584  0.50293243
   0.48331854  0.51211429  0.53146166  0.53757191  0.51966381  0.52254689
   0.52938205  0.52842993  0.55965304  0.55478776  0.50979334  0.50454158
   0.55247426  0.49587557  0.52784723  0.5415957   0.51129937  0.45152715
   0.59116071  0.51947284  0.52097797  0.5189119   0.48217973  0.50135988
   0.49465764  0.50349659  0.44902995  0.45279622  0.47614011  0.49318591
   0.51532102  0.53113228  0.49010432  0.49044326  0.47041065  0.51537305
   0.52789134  0.46067268  0.51704508  0.49238589  0.51988453  0.5622558
   0.5262816   0.55479908  0.53779924  0.53633636  0.51125014  0.53002667
   0.55739135  0.54738891  0.51186132  0.50466686  0.48559192  0.49854821
   0.54643744  0.49905205  0.52742249  0.46858403  0.54047096  0.52866828
   0.50541437  0.55317909  0.51171196  0.50834656  0.50737619  0.51873177
   0.54092693  0.56462508  0.48331714  0.50754762  0.52374786  0.51083386
   0.5155257   0.53289551  0.53163624  0.5109967   0.51322621  0.49075285
   0.49344891  0.52518922  0.51645058  0.53168917  0.49076909  0.54867554
   0.52733052  0.47969988  0.5215438   0.54313606  0.56097388  0.52703869
   0.4924075   0.52662683  0.53112507  0.49305239  0.57712579  0.49436879
   0.49910235  0.49905136  0.50490534  0.53822005  0.49908453  0.55746043
   0.48275545  0.53827286  0.54668492  0.49041194  0.50040466  0.53143132
   0.52191353  0.48052821  0.56544197  0.49266952  0.49782982  0.51453948
   0.50777692  0.55709648  0.48377308  0.47894266  0.48965162  0.51709539
   0.55104613  0.54423374  0.4516702   0.50359899  0.50142443  0.49599308
   0.50889426  0.50783211  0.52100396  0.50824672  0.52202952  0.49659136
   0.53126872  0.46244091  0.48264924  0.54795557  0.4752894   0.52939415
   0.52020377  0.5294677   0.48608038  0.5103119   0.49805579  0.4691526
   0.51762086  0.52817005  0.49030715  0.53564996  0.47400913  0.47167501
   0.57269484  0.49936303  0.5265255   0.49977764  0.50986826  0.51851785
   0.61026484  0.54621255  0.51555425  0.42127168  0.54219455  0.51110351
   0.52303392  0.49819872  0.50173688  0.52471614  0.52038693  0.52535343
   0.51322883  0.51897007  0.49696288  0.55774254  0.45551884  0.49882284
   0.47484791  0.4872427   0.53391778  0.48874125  0.55072635  0.44904694
   0.54247671  0.50121212  0.53653425  0.50118119]]
After layer _mul2088_0 (1, 256) <class 'numpy.float32'> [[ -9.22635868e-02  -7.50503987e-02  -1.92259997e-02   2.98729315e-02
    9.34702903e-03  -3.28994729e-02   7.06926035e-03   3.00834589e-02
    6.37755841e-02  -9.08567011e-02  -4.78002951e-02   1.13550566e-01
    5.94981164e-02  -6.63037738e-03   4.61711213e-02  -1.73504740e-01
    4.43417095e-02   1.42001417e-02   4.68614213e-02   3.35483849e-02
    1.52319729e-01  -3.99114154e-02  -1.81652699e-02   2.15205662e-02
   -7.60199800e-02   1.71416141e-02   2.88363788e-02  -2.98543610e-02
   -8.89410079e-02  -6.81315809e-02   2.65208874e-02  -6.13725744e-02
    1.74573658e-03  -1.54309004e-04   7.03486279e-02  -7.37556741e-02
   -2.74823215e-02   3.05256690e-03  -6.15140498e-02  -6.20478578e-02
    7.57506397e-03  -1.22716963e-01   6.89774305e-02   6.31859452e-02
    5.40204234e-02  -7.36801922e-02   3.52812856e-02  -2.96467245e-02
   -1.06898807e-02  -5.86592406e-02   3.86058316e-02  -8.73205736e-02
   -3.18080261e-02   1.20959505e-01  -3.38349887e-03   6.31546509e-03
   -7.57152587e-03   1.26638442e-01   6.43850341e-02  -2.29275655e-02
   -7.60884508e-02  -5.12705110e-02  -9.44677647e-03  -1.92246605e-02
    4.18666489e-02  -2.60239486e-02   2.12835502e-02  -6.43064156e-02
   -4.40039337e-02   3.96926608e-03  -1.69230491e-01   1.79313514e-02
    1.36534050e-02   1.23988492e-02   8.59084204e-02  -1.11436862e-02
   -4.10648547e-02  -1.42418072e-01  -5.32226488e-02  -3.25602777e-02
   -9.42425653e-02   2.58407602e-03  -6.07061349e-02  -1.01132728e-01
   -1.97465569e-01   2.15873681e-03  -5.01055382e-02   4.13520169e-03
   -1.15919478e-01  -4.38272469e-02  -9.70246345e-02  -3.17751542e-02
   -1.72495116e-02   4.73005371e-03  -2.68836953e-02   3.38959917e-02
    4.56758700e-02  -2.38793194e-02  -4.00897413e-02  -4.63332534e-02
    4.65573790e-03   8.19896311e-02  -4.25710790e-02   3.42227928e-02
    3.35131511e-02   9.87804979e-02  -2.19972320e-02  -1.76401101e-02
    1.07006274e-01  -9.39008519e-02   7.10283294e-02  -1.09132724e-02
    6.20219298e-02   9.46764126e-02  -4.97989468e-02   2.14455202e-01
   -1.10547863e-01  -6.24690205e-02   1.06557049e-02  -4.06670906e-02
    1.36014223e-01   3.61274369e-02  -4.24357713e-04  -6.36283085e-02
    4.49666604e-02  -1.03230812e-01  -7.34075233e-02  -4.95170131e-02
   -2.92165373e-02  -9.31282900e-03   8.52340609e-02  -9.46445111e-03
    4.23771553e-02   2.85283080e-03  -1.28266215e-03   3.80606130e-02
    4.47968990e-02   1.46809161e-01   2.74868542e-03   5.05126901e-02
   -2.09553726e-03  -2.28984002e-02   9.41330269e-02   1.27060488e-02
   -5.12805469e-02   7.01042712e-02   5.68192229e-02  -6.06146157e-02
   -5.64644672e-02  -7.64252543e-02  -4.33200337e-02  -1.58622973e-02
   -5.12284189e-02  -4.17933017e-02  -3.17823165e-03   6.53821751e-02
   -8.17540810e-02   1.28294632e-03   3.14055569e-02   5.23266122e-02
   -1.92388058e-01  -3.31489779e-02   9.01394896e-03   9.03487802e-02
    2.40886994e-02   4.86051701e-02   4.81466297e-03  -1.76594798e-02
   -1.28861621e-01   4.35521873e-03  -6.32608235e-02   5.06719723e-02
   -1.51138548e-02  -1.05254382e-01  -2.20835395e-02   4.23322022e-02
    1.10187218e-01  -2.97768060e-02  -2.73790639e-02  -8.80451035e-03
    4.37451340e-02   1.19071761e-02   3.88135463e-02  -2.27160063e-02
   -4.52438667e-02   1.65927932e-02   3.02680992e-02  -7.89853483e-02
    3.62066142e-02  -6.06548563e-02   1.15778252e-01  -3.82795511e-03
   -1.19085955e-02   2.64200196e-02  -1.10616177e-01   1.08685461e-03
   -1.36412859e-01  -5.41026816e-02  -1.67560074e-02   5.70309795e-02
   -1.06126927e-01  -3.28146815e-02   1.16369195e-01  -3.54396552e-02
   -1.24538392e-02  -1.71278920e-02   3.98460627e-02   9.03468952e-03
    6.77087456e-02  -4.24896926e-02  -1.10755481e-01   1.50570075e-03
    2.18133442e-02  -1.17444523e-01  -4.32589799e-02  -4.81969006e-02
    2.52854563e-02  -2.90173292e-02  -2.97101475e-02   8.71627480e-02
   -1.17880302e-02  -3.48727405e-02   7.77832270e-02   1.67539883e-02
    1.41543951e-02  -3.61010134e-02   5.78099675e-03   1.92315429e-02
    1.40356587e-03   1.43636651e-02  -8.25863555e-02   6.27335384e-02
    1.89357940e-02   4.69236113e-02  -4.11278568e-02   1.39978295e-02
   -4.79739532e-02   2.10548285e-02  -1.36376157e-01   7.21786767e-02
   -3.90551938e-03   2.06912708e-04   1.20007070e-02  -4.17310856e-02
   -1.55489892e-02  -2.36106012e-02  -3.21138985e-02  -9.40295607e-02
    1.86635628e-02   1.24076582e-01   1.76588312e-01   4.74902615e-02
    1.60814673e-02  -4.61658314e-02  -4.00617979e-02  -1.99453789e-03]]
After layer encoder_birnn_reverse_l0_t8_i_output (1, 256) <class 'numpy.float32'> [[ 0.49623287  0.4924174   0.48689789  0.49231705  0.49290997  0.49068573
   0.49596804  0.49992019  0.52410769  0.51928753  0.48602551  0.52897674
   0.50046462  0.5033868   0.49983346  0.58189613  0.46457016  0.47512814
   0.50328892  0.49721974  0.53026414  0.49870238  0.46058288  0.48491502
   0.51285166  0.4671481   0.49239069  0.49966419  0.49760351  0.49461353
   0.4974601   0.49730545  0.48423475  0.48900917  0.52329338  0.45590955
   0.49540737  0.49510527  0.47661322  0.47787586  0.45221919  0.5063405
   0.48832279  0.50228471  0.5069645   0.49449107  0.51980937  0.47702128
   0.48500827  0.50612605  0.50844318  0.52895701  0.45129478  0.52301693
   0.54655033  0.53274876  0.47957528  0.50394595  0.47512558  0.49755847
   0.52442086  0.48141497  0.54011446  0.49381039  0.47131893  0.48928699
   0.52991903  0.49440306  0.46983296  0.49705616  0.52891439  0.49541426
   0.4934524   0.49077103  0.50531507  0.51171798  0.52902901  0.54481518
   0.51344556  0.51800436  0.5060854   0.51208502  0.52375472  0.49271899
   0.54225886  0.50638974  0.4939113   0.47415584  0.4964765   0.51186937
   0.53048676  0.50267589  0.47787449  0.51782006  0.51819366  0.50823921
   0.49172062  0.50193745  0.46755561  0.4642894   0.46389198  0.51906908
   0.50604683  0.47284606  0.46154597  0.50135314  0.49232826  0.47205788
   0.52036709  0.49560422  0.47501871  0.49480504  0.50894654  0.56542087
   0.50552088  0.57999444  0.49512637  0.50165832  0.49845126  0.48349091
   0.55660629  0.46734264  0.49504495  0.52685326  0.47646627  0.52123672
   0.46254119  0.52180976  0.49113688  0.50287718  0.56003517  0.50993949
   0.49777851  0.486081    0.4764733   0.4675256   0.53116578  0.54244
   0.49211472  0.49727622  0.48937684  0.46296099  0.52658504  0.51253563
   0.49833876  0.50201315  0.51005548  0.51680058  0.49866319  0.52078795
   0.53260332  0.48106635  0.49913591  0.47688195  0.4678438   0.55089396
   0.50663835  0.49943945  0.49360183  0.49246445  0.56378269  0.49869817
   0.4792231   0.50380605  0.50091791  0.47925001  0.49653491  0.48469394
   0.50714713  0.48722437  0.49526417  0.51184195  0.50107044  0.52495879
   0.50495929  0.45125026  0.51184011  0.46457481  0.48263913  0.49617913
   0.51530111  0.48014855  0.49815339  0.50657845  0.52725607  0.49663323
   0.49509299  0.48710904  0.5242365   0.50777876  0.48521683  0.48759094
   0.50708842  0.48235017  0.47916061  0.52524543  0.52935112  0.45464927
   0.51085782  0.5264222   0.50320154  0.52320361  0.52221632  0.52148688
   0.50042492  0.48762199  0.49532488  0.48748988  0.47761291  0.50889534
   0.51326805  0.53547078  0.5053736   0.51056802  0.49544972  0.49302277
   0.49863207  0.49487266  0.51170403  0.49858958  0.48155349  0.46487087
   0.52998066  0.47813603  0.49726304  0.51715374  0.49118724  0.47240973
   0.46285662  0.51770627  0.49596319  0.45895189  0.49561507  0.48543984
   0.50652927  0.51486486  0.4987646   0.52187979  0.50966698  0.49501896
   0.46253571  0.45915508  0.52367711  0.56006074  0.48243496  0.5044297
   0.46637154  0.47653663  0.50233418  0.49457487  0.5457781   0.49454275
   0.46532509  0.51429826  0.51344877  0.50115484]]
After layer encoder_birnn_reverse_l0_t8_c_output (1, 256) <class 'numpy.float32'> [[ -1.68108135e-01  -1.52828351e-01  -5.16537726e-02   7.31078535e-02
   -1.58360100e-03  -6.38246313e-02  -1.09016150e-02   4.88399640e-02
    1.19971372e-01  -1.89199179e-01  -9.17584449e-02   2.34974861e-01
    1.21425278e-01   2.39943899e-03   9.75586027e-02  -2.97971487e-01
    1.00492336e-01   3.33213806e-02   1.22348428e-01   7.23135248e-02
    2.99937099e-01  -9.09043252e-02  -5.41931093e-02   2.71382332e-02
   -1.47116691e-01   3.39251719e-02   4.23255563e-02  -5.59691563e-02
   -1.71014711e-01  -1.51440129e-01   5.27859628e-02  -1.17267638e-01
    1.28961876e-02  -1.07236607e-02   1.55344754e-01  -1.70272812e-01
   -5.56288585e-02   1.44866481e-02  -1.28508449e-01  -1.34585232e-01
    8.01689923e-03  -2.39803255e-01   1.53281853e-01   1.40648618e-01
    1.12819426e-01  -1.53846040e-01   9.41880047e-02  -7.20292702e-02
   -3.31935138e-02  -1.27068967e-01   6.96812570e-02  -1.75153941e-01
   -5.56128994e-02   2.57577240e-01  -4.82587591e-02   1.04516337e-03
    5.21354377e-05   2.61452705e-01   1.61400661e-01  -5.42145967e-02
   -1.64184183e-01  -1.03459455e-01  -9.34833288e-03  -5.58373183e-02
    1.10361487e-01  -5.46022207e-02   2.93033756e-02  -1.29794076e-01
   -1.12647399e-01   2.05171965e-02  -3.43418509e-01   5.04399687e-02
    7.49922637e-03   2.50676963e-02   1.74732953e-01  -2.61217356e-04
   -9.23783407e-02  -2.88736492e-01  -1.20730922e-01  -7.74531886e-02
   -1.83012739e-01  -8.85871705e-03  -1.33437574e-01  -2.27525264e-01
   -3.53800267e-01  -3.51924682e-03  -6.65418953e-02  -1.36197023e-02
   -2.61908352e-01  -8.10435191e-02  -1.60108134e-01  -5.95348068e-02
   -3.81177440e-02   2.50451472e-02  -5.57833128e-02   8.00166279e-02
    8.98086280e-02  -3.61142084e-02  -9.88575369e-02  -1.36698112e-01
    3.46075860e-03   1.80345744e-01  -9.11910534e-02   8.23103860e-02
    8.60761702e-02   2.34977588e-01  -5.64958155e-02  -2.35810671e-02
    2.19474852e-01  -2.25181460e-01   1.77099735e-01  -4.01580408e-02
    1.46406740e-01   1.76931977e-01  -8.62095878e-02   3.50505441e-01
   -2.30182737e-01  -1.27761230e-01  -1.19763715e-02  -8.01555589e-02
    2.42850557e-01   5.81953637e-02   1.72986202e-02  -1.38705432e-01
    8.69383663e-02  -2.22382292e-01  -1.51891246e-01  -1.12325251e-01
   -6.10209666e-02  -1.51950791e-02   1.79244041e-01  -1.69729278e-03
    9.04125571e-02  -3.56357894e-03  -1.06055001e-02   7.75345117e-02
    8.52216482e-02   2.90560484e-01   1.51668889e-02   9.90185291e-02
   -9.90436599e-03  -4.62904796e-02   1.87921256e-01   1.87806413e-02
   -1.12184420e-01   1.49127707e-01   1.28823295e-01  -1.16543859e-01
   -1.19948149e-01  -1.69770420e-01  -1.07150219e-01  -3.31399813e-02
   -1.21880777e-01  -8.16954225e-02  -1.57812070e-02   1.28959343e-01
   -1.65586054e-01  -2.41335519e-02   6.51545301e-02   1.10191397e-01
   -3.34622711e-01  -5.65029196e-02   8.63036700e-03   1.71903297e-01
    5.36072068e-02   1.04312301e-01  -7.28766574e-03  -3.04764286e-02
   -2.94891477e-01  -1.61901116e-05  -1.42417982e-01   1.21295825e-01
   -1.79180652e-02  -1.72362790e-01  -6.83653131e-02   7.97395855e-02
    2.10097209e-01  -7.96492323e-02  -5.29426560e-02  -6.40678592e-03
    8.33843201e-02   3.47818136e-02   8.47499892e-02  -5.82372025e-02
   -1.08727261e-01   8.77022650e-03   6.66739643e-02  -1.59576967e-01
    4.58774790e-02  -1.16363369e-01   2.76302963e-01   1.25086983e-03
   -2.73930952e-02   5.63088469e-02  -2.89113939e-01   7.67918490e-03
   -2.92592973e-01  -1.43390328e-01  -2.56855059e-02   1.37080222e-01
   -2.29876071e-01  -7.57254511e-02   2.35200122e-01  -8.23511928e-02
   -2.88184751e-02  -4.65554968e-02   9.46401581e-02   2.01015137e-02
    1.65416718e-01  -6.97636828e-02  -2.32834622e-01   5.87466313e-03
    6.04586005e-02  -2.52480805e-01  -1.13019846e-01  -1.20488420e-01
    6.25705868e-02  -6.32272363e-02  -8.06000307e-02   1.84734121e-01
   -2.21603811e-02  -7.42543042e-02   1.56119049e-01   4.20051031e-02
    3.75369601e-02  -8.10930580e-02   1.37771899e-02   4.42266539e-02
   -3.57921757e-02   5.23981601e-02  -1.69312462e-01   1.86807811e-01
    2.40529422e-02   9.66778770e-02  -8.34746361e-02   2.66436096e-02
   -9.96981338e-02   5.40017709e-02  -3.04725766e-01   1.45482942e-01
   -2.80020200e-02   1.15042413e-02   8.52907635e-03  -7.32474104e-02
   -3.86676826e-02  -3.35277356e-02  -8.87924284e-02  -2.27725506e-01
    4.61292639e-02   2.89760113e-01   3.36826116e-01   1.22562967e-01
    1.43366577e-02  -1.00816116e-01  -8.21773782e-02   1.47356919e-03]]
After layer _mul2089_0 (1, 256) <class 'numpy.float32'> [[ -8.34207833e-02  -7.52553418e-02  -2.51501128e-02   3.59922424e-02
   -7.80572707e-04  -3.13178375e-02  -5.40685281e-03   2.44160835e-02
    6.28779158e-02  -9.82487723e-02  -4.45969440e-02   1.24296233e-01
    6.07690550e-02   1.20784587e-03   4.87630554e-02  -1.73388451e-01
    4.66857404e-02   1.58319250e-02   6.15766086e-02   3.59557122e-02
    1.59045890e-01  -4.53342013e-02  -2.49604192e-02   1.31597370e-02
   -7.54490420e-02   1.58480797e-02   2.08407100e-02  -2.79657822e-02
   -8.50975215e-02  -7.49043375e-02   2.62589101e-02  -5.83178364e-02
    6.24478236e-03  -5.24396822e-03   8.12908784e-02  -7.76289999e-02
   -2.75589470e-02   7.17241596e-03  -6.12488277e-02  -6.43150359e-02
    3.62539571e-03  -1.21422097e-01   7.48510212e-02   7.06456527e-02
    5.71954437e-02  -7.60754943e-02   4.89598066e-02  -3.43594961e-02
   -1.60991289e-02  -6.43129125e-02   3.54289599e-02  -9.26489010e-02
   -2.50978116e-02   1.34717256e-01  -2.63758413e-02   5.56809478e-04
    2.50028661e-05   1.31758034e-01   7.66855851e-02  -2.69749314e-02
   -8.61016065e-02  -4.98069301e-02  -5.04916999e-03  -2.75730472e-02
    5.20154573e-02  -2.67161559e-02   1.55284163e-02  -6.41705915e-02
   -5.29254600e-02   1.01981992e-02  -1.81638986e-01   2.49886792e-02
    3.70051130e-03   1.23024993e-02   8.82951915e-02  -1.33669615e-04
   -4.88708206e-02  -1.57308027e-01  -6.19887561e-02  -4.01210897e-02
   -9.26200747e-02  -4.53641638e-03  -6.98885620e-02  -1.12106018e-01
   -1.91851333e-01  -1.78211043e-03  -3.28657925e-02  -6.45786151e-03
   -1.30031347e-01  -4.14836966e-02  -8.49352479e-02  -2.99267117e-02
   -1.82154980e-02   1.29688792e-02  -2.89065596e-02   4.06675860e-02
    4.41607535e-02  -1.81270745e-02  -4.62213978e-02  -6.34674802e-02
    1.60541816e-03   9.36118960e-02  -4.61469442e-02   3.89201418e-02
    3.97281088e-02   1.17806755e-01  -2.78144870e-02  -1.11316284e-02
    1.14207491e-01  -1.11600883e-01   8.41256902e-02  -1.98704004e-02
    7.45132044e-02   1.00041032e-01  -4.35807481e-02   2.03291208e-01
   -1.13969542e-01  -6.40924871e-02  -5.96963754e-03  -3.87544855e-02
    1.35172144e-01   2.71971747e-02   8.56359489e-03  -7.30774105e-02
    4.14231978e-02  -1.15913816e-01  -7.02559575e-02  -5.86124137e-02
   -2.99696475e-02  -7.64125865e-03   1.00382969e-01  -8.65516602e-04
    4.50054258e-02  -1.73218804e-03  -5.05323755e-03   3.62493694e-02
    4.52668220e-02   1.57611623e-01   7.46384915e-03   4.92395610e-02
   -4.84696729e-03  -2.14306861e-02   9.89565253e-02   9.62574780e-03
   -5.59058450e-02   7.48640671e-02   6.57070279e-02  -6.02299348e-02
   -5.98137267e-02  -8.84143859e-02  -5.70685640e-02  -1.59425288e-02
   -6.08350746e-02  -3.89590710e-02  -7.38313980e-03   7.10429251e-02
   -8.38922486e-02  -1.20532475e-02   3.21603939e-02   5.42653464e-02
   -1.88654497e-01  -2.81779021e-02   4.13587131e-03   8.66059214e-02
    2.68528108e-02   4.99916710e-02  -3.61858052e-03  -1.47717400e-02
   -1.49553373e-01  -7.88821671e-06  -7.05345273e-02   6.20842911e-02
   -8.97821318e-03  -9.04833600e-02  -3.45216990e-02   3.59825082e-02
    1.07536174e-01  -3.70030291e-02  -2.55521983e-02  -3.17891338e-03
    4.29680310e-02   1.67004373e-02   4.22184952e-02  -2.95017119e-02
   -5.73271103e-02   4.35558613e-03   3.30098122e-02  -7.77313858e-02
    2.40506493e-02  -5.90868481e-02   1.34066850e-01   6.09912793e-04
   -1.38907218e-02   2.71605812e-02  -1.38532013e-01   4.03345656e-03
   -1.54884413e-01  -6.51923046e-02  -1.31216412e-02   7.21620694e-02
   -1.15673997e-01  -3.96198295e-02   1.22825339e-01  -4.29450683e-02
   -1.44214835e-02  -2.27014832e-02   4.68776263e-02   9.79928486e-03
    7.90051594e-02  -3.55024114e-02  -1.19506575e-01   3.14571057e-03
    3.05541810e-02  -1.28908619e-01  -5.59956506e-02  -5.94035350e-02
    3.11997011e-02  -3.12894322e-02  -4.12433594e-02   9.21065062e-02
   -1.06714088e-02  -3.45186628e-02   8.27400759e-02   2.00841539e-02
    1.86657421e-02  -4.19375785e-02   6.76717982e-03   2.08931006e-02
   -1.65666454e-02   2.71268561e-02  -8.39727446e-02   8.57357979e-02
    1.19210007e-02   4.69312929e-02  -4.22823466e-02   1.37178581e-02
   -4.97259013e-02   2.81824321e-02  -1.55308664e-01   7.20168129e-02
   -1.29519338e-02   5.28223068e-03   4.46648197e-03  -4.10229973e-02
   -1.86546426e-02  -1.69123858e-02  -4.14102599e-02  -1.08519547e-01
    2.31723059e-02   1.43308073e-01   1.83832318e-01   6.06126264e-02
    6.67120656e-03  -5.18495515e-02  -4.21938747e-02   7.38486357e-04]]
After layer encoder_birnn_reverse_l0_t8_state_0 (1, 256) <class 'numpy.float32'> [[ -1.75684363e-01  -1.50305748e-01  -4.43761125e-02   6.58651739e-02
    8.56645592e-03  -6.42173141e-02   1.66240754e-03   5.44995442e-02
    1.26653492e-01  -1.89105481e-01  -9.23972428e-02   2.37846792e-01
    1.20267168e-01  -5.42253163e-03   9.49341804e-02  -3.46893191e-01
    9.10274535e-02   3.00320666e-02   1.08438030e-01   6.95040971e-02
    3.11365604e-01  -8.52456167e-02  -4.31256890e-02   3.46803032e-02
   -1.51469022e-01   3.29896957e-02   4.96770889e-02  -5.78201413e-02
   -1.74038529e-01  -1.43035918e-01   5.27797975e-02  -1.19690411e-01
    7.99051858e-03  -5.39827719e-03   1.51639506e-01  -1.51384681e-01
   -5.50412685e-02   1.02249831e-02  -1.22762874e-01  -1.26362890e-01
    1.12004597e-02  -2.44139060e-01   1.43828452e-01   1.33831590e-01
    1.11215867e-01  -1.49755687e-01   8.42410922e-02  -6.40062243e-02
   -2.67890096e-02  -1.22972153e-01   7.40347952e-02  -1.79969475e-01
   -5.69058359e-02   2.55676746e-01  -2.97593400e-02   6.87227445e-03
   -7.54652312e-03   2.58396477e-01   1.41070619e-01  -4.99024987e-02
   -1.62190050e-01  -1.01077437e-01  -1.44959465e-02  -4.67977077e-02
    9.38821062e-02  -5.27401045e-02   3.68119664e-02  -1.28477007e-01
   -9.69293937e-02   1.41674653e-02  -3.50869477e-01   4.29200307e-02
    1.73539165e-02   2.47013494e-02   1.74203604e-01  -1.12773562e-02
   -8.99356753e-02  -2.99726099e-01  -1.15211405e-01  -7.26813674e-02
   -1.86862648e-01  -1.95234036e-03  -1.30594701e-01  -2.13238746e-01
   -3.89316916e-01   3.76626384e-04  -8.29713345e-02  -2.32265983e-03
   -2.45950818e-01  -8.53109434e-02  -1.81959882e-01  -6.17018640e-02
   -3.54650095e-02   1.76989324e-02  -5.57902530e-02   7.45635778e-02
    8.98366272e-02  -4.20063958e-02  -8.63111392e-02  -1.09800734e-01
    6.26115594e-03   1.75601527e-01  -8.87180269e-02   7.31429309e-02
    7.32412636e-02   2.16587245e-01  -4.98117208e-02  -2.87717395e-02
    2.21213758e-01  -2.05501735e-01   1.55154020e-01  -3.07836719e-02
    1.36535138e-01   1.94717437e-01  -9.33796912e-02   4.17746425e-01
   -2.24517405e-01  -1.26561508e-01   4.68606735e-03  -7.94215798e-02
    2.71186352e-01   6.33246154e-02   8.13923683e-03  -1.36705726e-01
    8.63898546e-02  -2.19144627e-01  -1.43663481e-01  -1.08129427e-01
   -5.91861829e-02  -1.69540867e-02   1.85617030e-01  -1.03299674e-02
    8.73825848e-02   1.12064276e-03  -6.33589970e-03   7.43099824e-02
    9.00637209e-02   3.04420769e-01   1.02125350e-02   9.97522473e-02
   -6.94250455e-03  -4.43290845e-02   1.93089545e-01   2.23317966e-02
   -1.07186392e-01   1.44968331e-01   1.22526251e-01  -1.20844550e-01
   -1.16278194e-01  -1.64839640e-01  -1.00388601e-01  -3.18048261e-02
   -1.12063497e-01  -8.07523727e-02  -1.05613712e-02   1.36425108e-01
   -1.65646330e-01  -1.07703013e-02   6.35659546e-02   1.06591955e-01
   -3.81042540e-01  -6.13268800e-02   1.31498203e-02   1.76954702e-01
    5.09415120e-02   9.85968411e-02   1.19608245e-03  -3.24312188e-02
   -2.78414994e-01   4.34733042e-03  -1.33795351e-01   1.12756267e-01
   -2.40920670e-02  -1.95737749e-01  -5.66052385e-02   7.83147067e-02
    2.17723399e-01  -6.67798370e-02  -5.29312640e-02  -1.19834235e-02
    8.67131650e-02   2.86076143e-02   8.10320377e-02  -5.22177182e-02
   -1.02570981e-01   2.09483802e-02   6.32779151e-02  -1.56716734e-01
    6.02572635e-02  -1.19741708e-01   2.49845102e-01  -3.21804220e-03
   -2.57993173e-02   5.35806008e-02  -2.49148190e-01   5.12031093e-03
   -2.91297257e-01  -1.19294986e-01  -2.98776478e-02   1.29193053e-01
   -2.21800923e-01  -7.24345148e-02   2.39194542e-01  -7.83847272e-02
   -2.68753227e-02  -3.98293734e-02   8.67236853e-02   1.88339744e-02
    1.46713912e-01  -7.79921040e-02  -2.30262056e-01   4.65141144e-03
    5.23675233e-02  -2.46353149e-01  -9.92546305e-02  -1.07600436e-01
    5.64851575e-02  -6.03067614e-02  -7.09535033e-02   1.79269254e-01
   -2.24594399e-02  -6.93913996e-02   1.60523295e-01   3.68381441e-02
    3.28201354e-02  -7.80385882e-02   1.25481766e-02   4.01246436e-02
   -1.51630798e-02   4.14905213e-02  -1.66559100e-01   1.48469329e-01
    3.08567956e-02   9.38549042e-02  -8.34102035e-02   2.77156867e-02
   -9.76998508e-02   4.92372587e-02  -2.91684806e-01   1.44195497e-01
   -1.68574527e-02   5.48914354e-03   1.64671894e-02  -8.27540830e-02
   -3.42036337e-02  -4.05229852e-02  -7.35241622e-02  -2.02549100e-01
    4.18358669e-02   2.67384648e-01   3.60420644e-01   1.08102888e-01
    2.27526743e-02  -9.80153829e-02  -8.22556764e-02  -1.25605147e-03]]
After layer activation1044_output (1, 256) <class 'numpy.float32'> [[ -1.73898906e-01  -1.49184003e-01  -4.43470068e-02   6.57700971e-02
    8.56624637e-03  -6.41291887e-02   1.66240602e-03   5.44456504e-02
    1.25980601e-01  -1.86883077e-01  -9.21351984e-02   2.33460933e-01
    1.19690649e-01  -5.42247854e-03   9.46500078e-02  -3.33617389e-01
    9.07768682e-02   3.00230402e-02   1.08014986e-01   6.93923905e-02
    3.01678926e-01  -8.50397274e-02  -4.30989750e-02   3.46664079e-02
   -1.50321186e-01   3.29777338e-02   4.96362634e-02  -5.77557944e-02
   -1.72302395e-01  -1.42068371e-01   5.27308434e-02  -1.19122118e-01
    7.99034815e-03  -5.39822457e-03   1.50487810e-01  -1.50238752e-01
   -5.49857542e-02   1.02246264e-02  -1.22149862e-01  -1.25694588e-01
    1.11999912e-02  -2.39401430e-01   1.42844826e-01   1.33038267e-01
    1.10759586e-01  -1.48646131e-01   8.40423852e-02  -6.39189631e-02
   -2.67826039e-02  -1.22356020e-01   7.38998279e-02  -1.78051323e-01
   -5.68444915e-02   2.50247419e-01  -2.97505576e-02   6.87216641e-03
   -7.54637970e-03   2.52795100e-01   1.40142202e-01  -4.98611182e-02
   -1.60782695e-01  -1.00734614e-01  -1.44949313e-02  -4.67635766e-02
    9.36072543e-02  -5.26912585e-02   3.67953479e-02  -1.27774760e-01
   -9.66269746e-02   1.41665172e-02  -3.37146401e-01   4.28936966e-02
    1.73521750e-02   2.46963277e-02   1.72462568e-01  -1.12768784e-02
   -8.96939784e-02  -2.91061938e-01  -1.14704341e-01  -7.25536570e-02
   -1.84717670e-01  -1.95233792e-03  -1.29857302e-01  -2.10064426e-01
   -3.70771199e-01   3.76626354e-04  -8.27814639e-02  -2.32265564e-03
   -2.41108611e-01  -8.51045847e-02  -1.79977939e-01  -6.16236813e-02
   -3.54501493e-02   1.76970847e-02  -5.57324439e-02   7.44257048e-02
    8.95957276e-02  -4.19817045e-02  -8.60974491e-02  -1.09361596e-01
    6.26107398e-03   1.73818573e-01  -8.84859934e-02   7.30127767e-02
    7.31105804e-02   2.13262901e-01  -4.97705638e-02  -2.87638027e-02
    2.17674613e-01  -2.02656940e-01   1.53920904e-01  -3.07739526e-02
    1.35692999e-01   1.92293301e-01  -9.31092203e-02   3.95030230e-01
   -2.20819458e-01  -1.25890061e-01   4.68603289e-03  -7.92550072e-02
    2.64728397e-01   6.32401109e-02   8.13905708e-03  -1.35860443e-01
    8.61755833e-02  -2.15702638e-01  -1.42683208e-01  -1.07709974e-01
   -5.91171719e-02  -1.69524625e-02   1.83514282e-01  -1.03295995e-02
    8.71608555e-02   1.12064229e-03  -6.33581495e-03   7.41735026e-02
    8.98209959e-02   2.95352995e-01   1.02121802e-02   9.94227007e-02
   -6.94239279e-03  -4.43000719e-02   1.90725118e-01   2.23280843e-02
   -1.06777787e-01   1.43961266e-01   1.21916763e-01  -1.20259725e-01
   -1.15756966e-01  -1.63362682e-01  -1.00052722e-01  -3.17941047e-02
   -1.11596741e-01  -8.05773064e-02  -1.05609782e-02   1.35584995e-01
   -1.64147735e-01  -1.07698850e-02   6.34804815e-02   1.06190093e-01
   -3.63612503e-01  -6.12501130e-02   1.31490622e-02   1.75130561e-01
    5.08974940e-02   9.82785821e-02   1.19608187e-03  -3.24198529e-02
   -2.71437466e-01   4.34730295e-03  -1.33002669e-01   1.12280831e-01
   -2.40874067e-02  -1.93275690e-01  -5.65448590e-02   7.81549960e-02
    2.14347124e-01  -6.66807443e-02  -5.28818853e-02  -1.19828498e-02
    8.64964798e-02   2.85998136e-02   8.08551461e-02  -5.21703102e-02
   -1.02212779e-01   2.09453162e-02   6.31935969e-02  -1.55446231e-01
    6.01844415e-02  -1.19172685e-01   2.44773045e-01  -3.21803102e-03
   -2.57935952e-02   5.35293855e-02  -2.44117782e-01   5.12026623e-03
   -2.83328354e-01  -1.18732288e-01  -2.98687611e-02   1.28479049e-01
   -2.18233883e-01  -7.23081008e-02   2.34734818e-01  -7.82245845e-02
   -2.68688537e-02  -3.98083255e-02   8.65069255e-02   1.88317485e-02
    1.45670235e-01  -7.78343529e-02  -2.26277009e-01   4.65137791e-03
    5.23197055e-02  -2.41487518e-01  -9.89299789e-02  -1.07187092e-01
    5.64251617e-02  -6.02337569e-02  -7.08346739e-02   1.77373216e-01
   -2.24556644e-02  -6.92802370e-02   1.59158587e-01   3.68214883e-02
    3.28083560e-02  -7.78805539e-02   1.25475181e-02   4.01031226e-02
   -1.51619175e-02   4.14667316e-02  -1.65035784e-01   1.47387952e-01
    3.08470055e-02   9.35802907e-02  -8.32173079e-02   2.77085919e-02
   -9.73901823e-02   4.91975099e-02  -2.83684760e-01   1.43204361e-01
   -1.68558564e-02   5.48908859e-03   1.64657012e-02  -8.25656950e-02
   -3.41903009e-02  -4.05008197e-02  -7.33919665e-02  -1.99823886e-01
    4.18114774e-02   2.61189580e-01   3.45584482e-01   1.07683748e-01
    2.27487497e-02  -9.77027118e-02  -8.20706636e-02  -1.25605077e-03]]
After layer encoder_birnn_reverse_l0_t8_out_0 (1, 256) <class 'numpy.float32'> [[ -9.05460641e-02  -7.73649961e-02  -2.20447611e-02   3.42180468e-02
    4.32040123e-03  -3.53897624e-02   8.65396170e-04   2.86939126e-02
    7.77240619e-02  -1.00179479e-01  -4.44324166e-02   1.21571079e-01
    6.51526898e-02  -2.64844461e-03   4.88049015e-02  -1.79223999e-01
    4.39955629e-02   1.42535707e-02   5.53920716e-02   3.46635245e-02
    1.47042200e-01  -3.93187627e-02  -2.49808021e-02   1.83476973e-02
   -7.62923658e-02   1.72612146e-02   2.44871881e-02  -2.84950659e-02
   -8.07335675e-02  -7.13432804e-02   2.79447399e-02  -6.27198592e-02
    4.08738386e-03  -2.75559071e-03   7.48079494e-02  -7.25584999e-02
   -2.91471574e-02   5.08195348e-03  -6.25777841e-02  -6.13898933e-02
    5.72292879e-03  -1.18233085e-01   7.13345557e-02   6.70293421e-02
    5.45207746e-02  -7.59747550e-02   4.28837202e-02  -3.02823130e-02
   -1.35567971e-02  -6.51742890e-02   3.85225713e-02  -8.92620981e-02
   -2.66177934e-02   1.28824025e-01  -1.61378309e-02   3.25985160e-03
   -4.09422722e-03   1.28976747e-01   7.10293949e-02  -2.34427191e-02
   -8.42926800e-02  -5.29861860e-02  -7.34720426e-03  -2.55730953e-02
    4.66171280e-02  -2.57379059e-02   2.04965714e-02  -6.60708100e-02
   -4.74677086e-02   7.25697773e-03  -1.69804275e-01   2.17773411e-02
    8.65677092e-03   1.22322058e-02   9.28655416e-02  -6.13102363e-03
   -4.82927933e-02  -1.48315161e-01  -6.15242720e-02  -4.04374823e-02
   -1.01673760e-01  -1.08054653e-03  -6.92323074e-02  -1.10325478e-01
   -2.02549681e-01   1.93344153e-04  -4.25284058e-02  -1.19993999e-03
   -1.26010984e-01  -4.31619659e-02  -9.84951109e-02  -3.00247539e-02
   -1.68210045e-02   8.97206832e-03  -2.82227229e-02   3.77249345e-02
    4.59132381e-02  -2.15125307e-02  -3.97304483e-02  -5.09549081e-02
    3.00084543e-03   8.00042450e-02  -4.20493707e-02   3.46126296e-02
    3.57259847e-02   1.06835581e-01  -2.42912937e-02  -1.53902108e-02
    1.12670407e-01  -1.05633870e-01   7.83156753e-02  -1.58493984e-02
    6.44047782e-02   1.03927158e-01  -4.63853814e-02   2.14076757e-01
   -1.06655471e-01  -6.17644042e-02   2.38994067e-03  -3.84957492e-02
    1.35095328e-01   3.32442261e-02   4.22474882e-03  -6.75406903e-02
    4.13797088e-02  -1.10284701e-01  -7.18288645e-02  -5.41819073e-02
   -2.94025764e-02  -7.92502426e-03   9.30742100e-02  -5.63168107e-03
    4.30921838e-02   5.95843594e-04  -3.25113069e-03   3.52801643e-02
    4.84422706e-02   1.51369408e-01   5.48289483e-03   5.10412417e-02
   -3.51850223e-03  -2.20119543e-02   9.23709273e-02   1.17285401e-02
   -5.28902933e-02   7.34046549e-02   6.70091063e-02  -6.32315651e-02
   -5.86611331e-02  -8.07097480e-02  -4.95955832e-02  -1.56651828e-02
   -5.86944856e-02  -4.33172733e-02  -5.16829500e-03   7.01665431e-02
   -8.73799697e-02  -5.59619116e-03   3.23549844e-02   5.73208220e-02
   -1.90091059e-01  -3.15540358e-02   6.61939988e-03   9.37105119e-02
    2.66836919e-02   4.66582179e-02   6.94051967e-04  -1.72348060e-02
   -1.24738932e-01   2.20570201e-03  -6.18851446e-02   6.01833761e-02
   -1.27538024e-02  -1.08408593e-01  -2.82523390e-02   4.29030433e-02
    1.15856431e-01  -3.20584960e-02  -2.72141211e-02  -5.91676729e-03
    4.01728302e-02   1.35335615e-02   4.18991074e-02  -2.46666316e-02
   -4.90249954e-02   1.14131877e-02   3.09608039e-02  -8.27567503e-02
    2.91982088e-02  -5.52487224e-02   1.23033896e-01  -1.73232390e-03
   -1.33307921e-02   2.72787213e-02  -1.17272794e-01   2.65885983e-03
   -1.38825342e-01  -6.05527870e-02  -1.58748981e-02   6.56325445e-02
   -1.14296548e-01  -4.01593782e-02   1.23273313e-01  -4.24562953e-02
   -1.41046513e-02  -2.08694525e-02   4.10484783e-02   9.73792374e-03
    6.81069195e-02  -4.26524878e-02  -1.13669969e-01   2.70235259e-03
    2.73260400e-02  -1.31500930e-01  -5.25607802e-02  -5.13600893e-02
    2.90448479e-02  -3.37727964e-02  -3.48342396e-02   8.60405713e-02
   -1.10656582e-02  -3.13633978e-02   8.70666131e-02   1.86802819e-02
    1.70412567e-02  -4.10014130e-02   6.25821017e-03   2.05937847e-02
   -9.04387701e-03   2.23292578e-02  -8.29896703e-02   6.69872686e-02
    1.51795195e-02   4.71781343e-02  -4.12743613e-02   1.41441645e-02
   -4.81858775e-02   2.58304887e-02  -1.51286349e-01   7.37662390e-02
   -7.58657185e-03   2.87664845e-03   8.50897469e-03  -4.80938554e-02
   -1.55649967e-02  -2.09176857e-02  -3.62512507e-02  -9.18138251e-02
    2.14036796e-02   1.28115460e-01   1.84081420e-01   5.09289093e-02
    1.21118547e-02  -5.25467433e-02  -4.10033800e-02  -6.46106084e-04]]
After layer expand_dims1050_0 (1, 1, 256) <class 'numpy.float32'> [[[ -9.05460641e-02  -7.73649961e-02  -2.20447611e-02   3.42180468e-02
     4.32040123e-03  -3.53897624e-02   8.65396170e-04   2.86939126e-02
     7.77240619e-02  -1.00179479e-01  -4.44324166e-02   1.21571079e-01
     6.51526898e-02  -2.64844461e-03   4.88049015e-02  -1.79223999e-01
     4.39955629e-02   1.42535707e-02   5.53920716e-02   3.46635245e-02
     1.47042200e-01  -3.93187627e-02  -2.49808021e-02   1.83476973e-02
    -7.62923658e-02   1.72612146e-02   2.44871881e-02  -2.84950659e-02
    -8.07335675e-02  -7.13432804e-02   2.79447399e-02  -6.27198592e-02
     4.08738386e-03  -2.75559071e-03   7.48079494e-02  -7.25584999e-02
    -2.91471574e-02   5.08195348e-03  -6.25777841e-02  -6.13898933e-02
     5.72292879e-03  -1.18233085e-01   7.13345557e-02   6.70293421e-02
     5.45207746e-02  -7.59747550e-02   4.28837202e-02  -3.02823130e-02
    -1.35567971e-02  -6.51742890e-02   3.85225713e-02  -8.92620981e-02
    -2.66177934e-02   1.28824025e-01  -1.61378309e-02   3.25985160e-03
    -4.09422722e-03   1.28976747e-01   7.10293949e-02  -2.34427191e-02
    -8.42926800e-02  -5.29861860e-02  -7.34720426e-03  -2.55730953e-02
     4.66171280e-02  -2.57379059e-02   2.04965714e-02  -6.60708100e-02
    -4.74677086e-02   7.25697773e-03  -1.69804275e-01   2.17773411e-02
     8.65677092e-03   1.22322058e-02   9.28655416e-02  -6.13102363e-03
    -4.82927933e-02  -1.48315161e-01  -6.15242720e-02  -4.04374823e-02
    -1.01673760e-01  -1.08054653e-03  -6.92323074e-02  -1.10325478e-01
    -2.02549681e-01   1.93344153e-04  -4.25284058e-02  -1.19993999e-03
    -1.26010984e-01  -4.31619659e-02  -9.84951109e-02  -3.00247539e-02
    -1.68210045e-02   8.97206832e-03  -2.82227229e-02   3.77249345e-02
     4.59132381e-02  -2.15125307e-02  -3.97304483e-02  -5.09549081e-02
     3.00084543e-03   8.00042450e-02  -4.20493707e-02   3.46126296e-02
     3.57259847e-02   1.06835581e-01  -2.42912937e-02  -1.53902108e-02
     1.12670407e-01  -1.05633870e-01   7.83156753e-02  -1.58493984e-02
     6.44047782e-02   1.03927158e-01  -4.63853814e-02   2.14076757e-01
    -1.06655471e-01  -6.17644042e-02   2.38994067e-03  -3.84957492e-02
     1.35095328e-01   3.32442261e-02   4.22474882e-03  -6.75406903e-02
     4.13797088e-02  -1.10284701e-01  -7.18288645e-02  -5.41819073e-02
    -2.94025764e-02  -7.92502426e-03   9.30742100e-02  -5.63168107e-03
     4.30921838e-02   5.95843594e-04  -3.25113069e-03   3.52801643e-02
     4.84422706e-02   1.51369408e-01   5.48289483e-03   5.10412417e-02
    -3.51850223e-03  -2.20119543e-02   9.23709273e-02   1.17285401e-02
    -5.28902933e-02   7.34046549e-02   6.70091063e-02  -6.32315651e-02
    -5.86611331e-02  -8.07097480e-02  -4.95955832e-02  -1.56651828e-02
    -5.86944856e-02  -4.33172733e-02  -5.16829500e-03   7.01665431e-02
    -8.73799697e-02  -5.59619116e-03   3.23549844e-02   5.73208220e-02
    -1.90091059e-01  -3.15540358e-02   6.61939988e-03   9.37105119e-02
     2.66836919e-02   4.66582179e-02   6.94051967e-04  -1.72348060e-02
    -1.24738932e-01   2.20570201e-03  -6.18851446e-02   6.01833761e-02
    -1.27538024e-02  -1.08408593e-01  -2.82523390e-02   4.29030433e-02
     1.15856431e-01  -3.20584960e-02  -2.72141211e-02  -5.91676729e-03
     4.01728302e-02   1.35335615e-02   4.18991074e-02  -2.46666316e-02
    -4.90249954e-02   1.14131877e-02   3.09608039e-02  -8.27567503e-02
     2.91982088e-02  -5.52487224e-02   1.23033896e-01  -1.73232390e-03
    -1.33307921e-02   2.72787213e-02  -1.17272794e-01   2.65885983e-03
    -1.38825342e-01  -6.05527870e-02  -1.58748981e-02   6.56325445e-02
    -1.14296548e-01  -4.01593782e-02   1.23273313e-01  -4.24562953e-02
    -1.41046513e-02  -2.08694525e-02   4.10484783e-02   9.73792374e-03
     6.81069195e-02  -4.26524878e-02  -1.13669969e-01   2.70235259e-03
     2.73260400e-02  -1.31500930e-01  -5.25607802e-02  -5.13600893e-02
     2.90448479e-02  -3.37727964e-02  -3.48342396e-02   8.60405713e-02
    -1.10656582e-02  -3.13633978e-02   8.70666131e-02   1.86802819e-02
     1.70412567e-02  -4.10014130e-02   6.25821017e-03   2.05937847e-02
    -9.04387701e-03   2.23292578e-02  -8.29896703e-02   6.69872686e-02
     1.51795195e-02   4.71781343e-02  -4.12743613e-02   1.41441645e-02
    -4.81858775e-02   2.58304887e-02  -1.51286349e-01   7.37662390e-02
    -7.58657185e-03   2.87664845e-03   8.50897469e-03  -4.80938554e-02
    -1.55649967e-02  -2.09176857e-02  -3.62512507e-02  -9.18138251e-02
     2.14036796e-02   1.28115460e-01   1.84081420e-01   5.09289093e-02
     1.21118547e-02  -5.25467433e-02  -4.10033800e-02  -6.46106084e-04]]]
After layer encoder_birnn_reverse_l0_t9_i2h_output (1, 1024) <class 'numpy.float32'> [[-0.0128371  -0.04095686  0.03787835 ...,  0.06970935 -0.04625846
   0.03761056]]
After layer encoder_birnn_reverse_l0_t9_h2h_output (1, 1024) <class 'numpy.float32'> [[-0.00111588  0.00853575 -0.09745395 ...,  0.08810843  0.04722881
   0.02069173]]
After layer _plus1045_0 (1, 1024) <class 'numpy.float32'> [[-0.01395298 -0.03242111 -0.0595756  ...,  0.15781778  0.00097036
   0.05830228]]
After layer encoder_birnn_reverse_l0_t9_slice_output0 (1, 256) <class 'numpy.float32'> [[ -1.39529761e-02  -3.24211121e-02  -5.95755987e-02  -3.42577659e-02
   -4.94432673e-02  -4.06283662e-02  -2.86812186e-02  -6.56912848e-03
    9.24302787e-02   8.11244100e-02  -6.25470206e-02   1.21600419e-01
   -2.82925740e-03   1.05043687e-02   2.85200775e-04   3.46505463e-01
   -1.47610053e-01  -1.05900608e-01   1.32641112e-02  -1.02109006e-02
    1.32639110e-01  -9.63065401e-03  -1.73199236e-01  -6.52704984e-02
    4.36771736e-02  -1.31914645e-01  -2.71313712e-02   4.96558845e-03
   -1.69115476e-02  -2.16349624e-02  -1.34107945e-02  -1.06744841e-02
   -6.61980212e-02  -4.37707752e-02   1.00209996e-01  -1.87136918e-01
   -1.81706529e-02  -2.18273122e-02  -9.69131738e-02  -9.54254195e-02
   -2.15109453e-01   2.71697156e-02  -4.39876504e-02   1.30970627e-02
    2.70838756e-02  -2.37176903e-02   8.50797743e-02  -9.54175293e-02
   -6.93407282e-02   2.21142620e-02   3.79522443e-02   1.19869530e-01
   -2.16842100e-01   9.90654677e-02   1.95969909e-01   1.39031619e-01
   -8.49506855e-02   1.64786875e-02  -1.07964218e-01  -5.42536378e-03
    1.05124846e-01  -8.27722251e-02   1.62631765e-01  -2.20736638e-02
   -1.13310181e-01  -4.22081128e-02   1.25746444e-01  -2.07549930e-02
   -1.34982824e-01  -1.85232460e-02   1.20769560e-01  -1.68432239e-02
   -3.12227048e-02  -4.16040681e-02   2.40508504e-02   4.10672836e-02
    1.13459960e-01   1.85154706e-01   6.30684197e-02   8.26978981e-02
    2.56481264e-02   4.97660376e-02   9.91575792e-02  -3.14730294e-02
    1.68825030e-01   1.70567781e-02  -2.25955173e-02  -1.16492584e-01
   -1.15848407e-02   4.41691950e-02   1.27328306e-01   1.71774849e-02
   -8.97649229e-02   6.79773614e-02   7.53870755e-02   3.22669074e-02
   -3.30812372e-02  -1.01549178e-02  -1.39355034e-01  -1.49210334e-01
   -1.58400029e-01   7.32249022e-02   2.69738361e-02  -1.03192918e-01
   -1.72302768e-01   2.27331743e-03  -3.08835451e-02  -1.12551607e-01
    8.90612751e-02  -3.42528820e-02  -9.41591784e-02  -3.02101895e-02
    3.76112163e-02   2.80396402e-01   2.68316828e-02   3.28190863e-01
   -1.16955433e-02   5.91248833e-03  -4.66033816e-03  -7.34054297e-02
    2.35345781e-01  -1.31254286e-01  -3.02676335e-02   1.12294607e-01
   -1.06081314e-01   9.58971903e-02  -1.54241249e-01   9.29084793e-02
   -3.76225412e-02   1.35585219e-02   2.52787411e-01   3.17287743e-02
   -8.49028304e-03  -5.79909049e-02  -9.96613130e-02  -1.43345892e-01
    1.30298927e-01   1.72261298e-01  -3.86382863e-02  -9.90759209e-03
   -4.16404195e-02  -1.58830971e-01   1.11820266e-01   4.63810116e-02
    3.55042890e-03   1.36750638e-02   4.19596061e-02   6.78747892e-02
   -9.72662121e-04   9.29294825e-02   1.33823410e-01  -7.93026760e-02
   -3.79525125e-03  -9.18789655e-02  -1.42746329e-01   2.09394246e-01
    2.68327594e-02  -1.53140277e-02  -2.60645766e-02  -2.95473319e-02
    2.71485329e-01  -9.69619676e-03  -8.90277028e-02   1.26694143e-02
    3.55505757e-03  -8.53549391e-02  -1.98902674e-02  -6.38815835e-02
    2.70561464e-02  -5.13275862e-02  -2.37209741e-02   4.87728640e-02
    8.08469579e-03   9.65522751e-02   2.18910147e-02  -2.09725365e-01
    5.32904342e-02  -1.47718444e-01  -7.38086253e-02  -1.06434673e-02
    6.56847507e-02  -8.26329440e-02  -9.04333219e-03   2.93178186e-02
    1.13754630e-01  -1.19715352e-02  -1.95509959e-02  -4.73067276e-02
    9.86459330e-02   2.75468975e-02  -6.52585104e-02  -5.16744070e-02
    2.35746522e-02  -7.75405392e-02  -1.11907423e-01   1.05553940e-01
    1.24747470e-01  -1.83946162e-01   4.43597510e-02   1.15344673e-01
    1.35028437e-02   8.97734538e-02   9.52698588e-02   9.66114849e-02
   -3.48654389e-03  -5.70307896e-02  -2.40910612e-02  -4.72858101e-02
   -9.51873213e-02   3.23006772e-02   5.60602769e-02   1.54318139e-01
    2.21727975e-02   3.69032808e-02  -2.37014238e-02  -4.26551625e-02
   -4.07187641e-03  -1.96297280e-02   5.49536906e-02  -6.65506162e-03
   -7.82550350e-02  -1.61137536e-01   1.31171271e-01  -9.12974402e-02
   -1.93527751e-02   7.20514730e-02  -3.57236341e-02  -1.14141710e-01
   -1.66723192e-01   5.65663278e-02  -1.75400209e-02  -1.76987380e-01
   -1.52794877e-02  -5.87601513e-02   2.59820037e-02   5.94539680e-02
   -4.56377212e-03   9.18936133e-02   4.40108664e-02  -1.05601959e-02
   -1.67205900e-01  -1.71567172e-01   9.81767923e-02   2.42595255e-01
   -7.41066635e-02   1.85060576e-02  -1.50341123e-01  -1.02324069e-01
    7.56712258e-03  -2.85922866e-02   1.93454385e-01  -2.50565968e-02
   -1.49704397e-01   6.09835349e-02   5.27000278e-02   1.07378438e-02]]
After layer encoder_birnn_reverse_l0_t9_slice_output1 (1, 256) <class 'numpy.float32'> [[  1.70684293e-01   6.25946149e-02   1.33703783e-01   3.51871252e-02
   -2.70973686e-02   8.88390541e-02   2.20427707e-01  -1.11483097e-01
    4.25437957e-01   2.12562799e-01   1.37079105e-01   1.77053839e-01
    1.51083365e-01  -1.09574683e-02   1.46771818e-01   1.68022186e-01
    9.52348188e-02  -9.93388891e-03  -1.53306916e-01   1.18260607e-01
    1.69575512e-01   3.57715562e-02   5.19214869e-01   8.95798430e-02
    1.34785295e-01   9.74465311e-02   2.02102005e-01   7.36996382e-02
    1.41807333e-01   4.24407125e-02   1.15372539e-01   5.72992563e-02
    2.71431446e-01  -4.85480875e-02  -2.50850618e-03  -2.45639607e-02
   -5.89344166e-02   1.94676429e-01   2.81984694e-02   8.21753815e-02
   -1.32083446e-01   1.29062712e-01   2.10990515e-02   1.23605505e-01
    6.19915053e-02   1.44301131e-01   4.01455127e-02  -1.51112929e-01
   -1.79644730e-02   2.52217427e-03   8.43325853e-02   1.21564113e-01
   -7.88701475e-02   1.79065734e-01   7.94928148e-02   4.45029363e-02
    6.84690773e-02   1.24142438e-01  -2.59101354e-02  -1.26791596e-01
    1.45993531e-01   4.85439450e-02   1.06180713e-01   1.90464035e-02
   -3.77743505e-02   1.79572165e-01   2.43319705e-01   1.11072868e-01
   -1.91751480e-01  -8.12069550e-02   7.93224424e-02   1.60524845e-02
   -7.17180818e-02   5.38050905e-02   1.34717017e-01   1.42569005e-01
    8.33827928e-02   1.00964874e-01   1.25807911e-01   1.27227098e-01
    2.47149900e-01   2.35003203e-01   4.09108549e-02   1.02274325e-02
    2.24334136e-01  -1.96254663e-02   1.21417031e-01   1.63176045e-01
    4.82460707e-02  -2.05051795e-01   3.86206061e-01   7.50815347e-02
    8.59681517e-02   7.79177547e-02  -7.13536516e-02   4.06669080e-03
   -2.88864113e-02  -6.20737672e-03  -2.14316934e-01  -1.90680057e-01
   -1.01491518e-01  -3.88665944e-02   6.92115873e-02   1.32236153e-01
   -5.01910970e-02  -4.02111076e-02  -1.22387134e-01   6.16866611e-02
    1.19145110e-01  -1.72210574e-01   8.14092681e-02  -3.14837918e-02
    8.80372226e-02   2.68959939e-01   1.10291481e-01   2.28957072e-01
    1.69629276e-01   1.48729712e-01   4.78569716e-02   1.22139543e-01
    2.44470015e-01   1.98278964e-01   4.71958145e-02   1.89559907e-02
   -7.03299865e-02  -5.01371175e-03   1.89134747e-01  -1.66999549e-03
    1.13671675e-01  -1.32699579e-01   1.74905345e-01   1.12932622e-01
    2.62803584e-02   2.30908230e-01   4.24329303e-02   2.57505029e-02
    3.28544043e-02   8.09403360e-02   1.78516015e-01   2.80206114e-01
   -6.14807680e-02   2.53639072e-02   1.04449891e-01   5.12466505e-02
    6.93201497e-02   1.30523533e-01   1.42277390e-01   4.39028330e-02
    5.26144207e-02  -4.08770517e-02  -2.50787027e-02   1.13542452e-01
    7.58247972e-02   1.41892955e-01  -4.69924845e-02   1.99575365e-01
    1.17150173e-01  -9.75774080e-02   9.65496451e-02   1.81907505e-01
    2.53644973e-01   1.18088976e-01  -2.78380513e-02   1.12433873e-01
    1.40059739e-01  -3.15593407e-02   3.24680030e-01  -1.86783150e-02
    2.13466585e-04   5.53571433e-03   1.78665705e-02   1.63553789e-01
    5.74281067e-03   2.39591181e-01  -6.84963763e-02   1.67793646e-01
    1.93802297e-01  -4.45070416e-02  -2.43400782e-03   1.31220192e-01
    8.96786749e-02  -8.05560648e-02   2.73178220e-01  -2.55381092e-02
   -9.73705202e-03   7.22262189e-02   2.97769997e-02   2.41772532e-01
   -6.85558319e-02  -8.79223198e-02  -4.46709171e-02   8.16477612e-02
    2.15278119e-01   1.87056780e-01  -2.24360824e-01   1.95210874e-02
    1.02685504e-02  -1.27428286e-02   3.65838669e-02   3.63005474e-02
    9.77401957e-02   2.82196179e-02   9.41458791e-02  -5.98903745e-03
    1.29291981e-01  -1.54215932e-01  -7.69795030e-02   2.06327289e-01
   -1.08220570e-01   1.23567700e-01   8.05147439e-02   1.27653077e-01
   -5.74648939e-02   4.56668586e-02  -3.96060199e-03  -1.35143742e-01
    7.51820654e-02   1.20610759e-01  -4.47259359e-02   1.53837860e-01
   -1.05743937e-01  -1.25426784e-01   3.09415817e-01  -8.62495042e-03
    1.11069314e-01  -5.79010695e-04   4.91906479e-02   8.31273273e-02
    4.77003396e-01   1.78331256e-01   7.52547979e-02  -3.27951103e-01
    1.75332129e-01   4.90485281e-02   1.01558745e-01  -7.63806701e-03
    9.40175913e-03   1.05820000e-01   9.48171839e-02   1.05233647e-01
    4.42517437e-02   8.63832235e-02  -1.64559111e-02   2.39803657e-01
   -1.87632084e-01   6.30818307e-04  -1.07357368e-01  -5.03204763e-02
    1.48273662e-01  -5.17787077e-02   2.16126174e-01  -2.10350022e-01
    1.77759618e-01   1.03793368e-02   1.51655361e-01   7.08424672e-03]]
After layer encoder_birnn_reverse_l0_t9_slice_output2 (1, 256) <class 'numpy.float32'> [[-0.17187017 -0.15549314 -0.05813989  0.07937271 -0.01259405 -0.06551197
  -0.02077015  0.03696847  0.13892692 -0.21094705 -0.09218274  0.26115167
   0.13090381  0.01183338  0.10587293 -0.32165116  0.10481017  0.0342858
   0.12757331  0.07850934  0.33430728 -0.0957384  -0.06770331  0.02196277
  -0.1543991   0.0350258   0.03525871 -0.05303635 -0.17693985 -0.16091657
   0.05396258 -0.11773311  0.01630522 -0.01828434  0.16583973 -0.17231275
  -0.05495547  0.01728963 -0.12957147 -0.14192244  0.00138701 -0.25346613
   0.16183817  0.15668182  0.11932831 -0.16786791  0.11204319 -0.07318526
  -0.04072128 -0.13120517  0.06572875 -0.1888656  -0.04128801  0.29138458
  -0.07420778 -0.00452151  0.00657678  0.28395307  0.17213449 -0.05536657
  -0.18177903 -0.10430811 -0.00599369 -0.06555535  0.12058881 -0.0586595
   0.02795119 -0.13183033 -0.11672531  0.02510822 -0.38208768  0.05646487
  -0.00542659  0.02622177  0.18813056  0.00934931 -0.10130481 -0.31784028
  -0.13482356 -0.09052679 -0.20122467 -0.01590224 -0.14416242 -0.2441788
  -0.39436841 -0.00802603 -0.05464506 -0.02330451 -0.28579244 -0.06465701
  -0.17494982 -0.06036808 -0.04003491  0.03334248 -0.0532943   0.08634272
   0.08389009 -0.02611322 -0.09471394 -0.14269273  0.00153465  0.19220522
  -0.09776807  0.09176303  0.09211628  0.25107798 -0.06116319 -0.01715275
   0.23968995 -0.22742179  0.19541278 -0.04814798  0.16219866  0.19871433
  -0.08313465  0.38556194 -0.24868765 -0.13392261 -0.03533908 -0.0799112
   0.27034     0.05614893  0.02782629 -0.14852488  0.07925338 -0.23819868
  -0.15969566 -0.12085697 -0.06438687 -0.00944158  0.20477268  0.00476279
   0.09436774 -0.01312823 -0.01548142  0.07564107  0.08908172  0.31572744
   0.02089443  0.10836713 -0.01558003 -0.04526686  0.19906417  0.01218097
  -0.12208278  0.16324852  0.14469135 -0.1197143  -0.12651408 -0.17727184
  -0.12108968 -0.03474027 -0.1325919  -0.08529408 -0.02557676  0.14555056
  -0.17361638 -0.03646776  0.06805623  0.11959608 -0.37600398 -0.05652155
   0.00042888  0.17760892  0.05977363  0.10268299 -0.01825622 -0.02977866
  -0.31956661 -0.00715915 -0.15088482  0.14045087 -0.00768337 -0.17316127
  -0.08246112  0.07583304  0.2257348  -0.08792891 -0.05127225 -0.00365714
   0.08528409  0.03843183  0.0972331  -0.06668791 -0.12064368 -0.00488332
   0.06907439 -0.17531142  0.0263823  -0.10389183  0.29476863  0.00718443
  -0.02877256  0.05577823 -0.30199885  0.01124842 -0.31730592 -0.15927178
  -0.02067543  0.15218234 -0.25035411 -0.08077952  0.25416175 -0.0900064
  -0.03261808 -0.04897913  0.09909213  0.02341923  0.16789564 -0.06765369
  -0.25299874  0.00995985  0.06892493 -0.26973754 -0.12837154 -0.12520215
   0.07021318 -0.06651233 -0.0911589   0.20223531 -0.01932824 -0.06876791
   0.18014441  0.04329313  0.04186434 -0.08634885  0.01456161  0.04863676
  -0.05539235  0.06821428 -0.1750226   0.18911411  0.02117739  0.09958437
  -0.08936118  0.02896496 -0.10449373  0.06403342 -0.34125608  0.15380579
  -0.03801448  0.01577997 -0.0047313  -0.08201878 -0.03955686 -0.02551264
  -0.09804709 -0.23942506  0.0518093   0.31632945  0.38231477  0.12667844
   0.00818084 -0.1055384  -0.08732385  0.00365356]]
After layer encoder_birnn_reverse_l0_t9_slice_output3 (1, 256) <class 'numpy.float32'> [[ 0.09036198  0.0833323  -0.00858621  0.08503548  0.01098474  0.21228874
   0.0771594   0.10138355  0.50237018  0.15561461 -0.07427205  0.08763417
   0.18335074 -0.047383    0.06793804  0.15829094 -0.05951239 -0.10058203
   0.05822178  0.00522828 -0.05121896 -0.15774685  0.33916277  0.12238076
   0.02229414  0.10630637 -0.0276879  -0.02940844 -0.13414338  0.00633395
   0.12400825  0.11009148  0.05235688  0.04727288 -0.00752514 -0.07541601
   0.12496449 -0.01067916  0.041258   -0.05599011  0.03298928 -0.02163303
  -0.00090066  0.02058479 -0.02776749  0.04741389  0.04772382 -0.11684091
   0.02615097  0.13295445  0.08610079  0.01310524 -0.14173219  0.06084257
   0.18388547 -0.0993837   0.17704836  0.04724621  0.02504006 -0.11978892
   0.10893784  0.11390266  0.02858572  0.19505247 -0.01074048 -0.04037556
   0.23912477  0.07273522 -0.04675724  0.04078288  0.01411112  0.03200628
  -0.00483469 -0.01891432  0.16672868  0.1654022   0.15307061  0.03704842
   0.15362431  0.23782393  0.21392864  0.21910177  0.1457431   0.09615731
   0.19345614  0.05416226  0.06336281  0.05775118  0.09345551  0.02231397
   0.20046884 -0.05175354 -0.10733145  0.02929347  0.01840185  0.02782327
   0.04713967  0.0330728  -0.15707278 -0.14202081 -0.09018446 -0.16306725
  -0.10426757 -0.10659336 -0.0535908   0.00253604 -0.05021849  0.14546239
   0.07377004  0.07022282  0.04693454  0.06203989 -0.10695834  0.16834924
  -0.00851504  0.17271908 -0.06415786 -0.04080578  0.04305484 -0.05816139
   0.0473573   0.10658871  0.07537611 -0.01839846 -0.08682413  0.04949525
   0.02367702  0.01674358 -0.00662625 -0.13715418  0.03411923  0.17884755
  -0.0200367   0.13810436  0.05300099 -0.10359079  0.16805454  0.04676022
   0.15649152  0.06424227  0.03197829 -0.01310381 -0.05895548  0.11170395
  -0.02156717  0.0465008   0.21417232  0.11475346  0.02504118 -0.02724157
  -0.01383875 -0.02789512  0.11645316  0.15883252 -0.05259772  0.06906713
   0.13987613  0.07130891  0.0388686   0.16889268  0.09465666  0.07475571
   0.02137394  0.14212018  0.10583534 -0.10892221  0.34218335  0.13298109
  -0.16766615  0.03440073 -0.14966598  0.15652993  0.13215199  0.25944561
  -0.0043011   0.20388424  0.16666341 -0.08022929  0.05329683 -0.02782867
  -0.15055484 -0.11949667  0.08303197 -0.11685253 -0.08821587  0.19448964
  -0.04943053  0.13802415 -0.06461503 -0.15558109  0.01128847  0.15774487
   0.07417098  0.04592268 -0.101873    0.08432104 -0.04244678  0.03880029
   0.12802696  0.05275185  0.10055052  0.22775504  0.10441899  0.17798042
   0.10142683  0.09897871 -0.11181983  0.07588446 -0.1387147   0.20073816
   0.01234663  0.34011841  0.0979237   0.18558159  0.13547616 -0.09475977
   0.06155297  0.26205674 -0.03140319 -0.06030537 -0.02515504 -0.20535827
   0.20315769  0.02808844  0.07951714  0.10837121 -0.00367831  0.05855277
   0.41432416  0.14466614  0.01106742 -0.1924108  -0.03196417  0.02246871
  -0.01222157  0.05002576 -0.01598968  0.11040321  0.14255632  0.06979581
  -0.22235736  0.10039952  0.06546223  0.33905426 -0.19772953  0.06888634
  -0.03454658 -0.17182398  0.05075132 -0.04451709  0.13890892 -0.11243328
   0.13928258  0.15781778  0.00097036  0.05830228]]
After layer encoder_birnn_reverse_l0_t9_o_output (1, 256) <class 'numpy.float32'> [[ 0.52257514  0.52082103  0.49785349  0.52124608  0.50274616  0.55287379
   0.51928031  0.52532423  0.62301624  0.53882533  0.48144051  0.52189451
   0.54570967  0.4881565   0.51697803  0.53949034  0.48512629  0.47487566
   0.51455134  0.50130707  0.48719802  0.46064484  0.58398712  0.53055704
   0.50557333  0.5265516   0.49307847  0.49264839  0.46651438  0.50158346
   0.53096241  0.52749509  0.51308626  0.51181602  0.4981187   0.48115492
   0.53120053  0.49733022  0.51031303  0.48600614  0.5082466   0.49459195
   0.49977484  0.50514603  0.49305859  0.51185125  0.51192868  0.47082299
   0.50653738  0.53318971  0.52151191  0.50327629  0.46462616  0.51520592
   0.54584229  0.47517449  0.54414684  0.51180941  0.50625968  0.47008854
   0.52720755  0.52844495  0.50714594  0.54860908  0.49731487  0.4899075
   0.55949795  0.51817578  0.48831284  0.5101943   0.50352776  0.50800091
   0.49879128  0.49527153  0.54158586  0.54125655  0.53819311  0.50926107
   0.53833073  0.55917728  0.55327916  0.55455738  0.53637141  0.52402079
   0.54821378  0.51353729  0.5158354   0.51443374  0.5233469   0.50557828
   0.54995006  0.48706451  0.47319287  0.50732285  0.50460035  0.50695539
   0.51178271  0.50826746  0.46081236  0.46455434  0.47746918  0.45932326
   0.4739567   0.47337684  0.48660553  0.50063401  0.48744801  0.53630161
   0.51843417  0.5175485   0.51173151  0.51550502  0.47328588  0.54198819
   0.49787125  0.54307276  0.48396602  0.48979995  0.51076204  0.48546377
   0.51183712  0.526622    0.51883513  0.49540052  0.47830757  0.5123713
   0.50591898  0.5041858   0.49834344  0.46576509  0.50852895  0.5445931
   0.49499097  0.53447133  0.51324713  0.47412542  0.54191506  0.51168793
   0.53904325  0.51605505  0.50799388  0.4967241   0.48526537  0.52789694
   0.4946084   0.51162314  0.55333936  0.5286569   0.50625998  0.49319002
   0.49654034  0.49302664  0.52908039  0.53962487  0.48685357  0.5172599
   0.53491217  0.51781964  0.50971591  0.54212308  0.52364653  0.51868021
   0.50534326  0.53547037  0.52643412  0.47279635  0.58472079  0.53319639
   0.45818135  0.50859934  0.46265322  0.53905278  0.53298998  0.56450003
   0.49892473  0.5507952   0.54156971  0.47995338  0.5133211   0.49304324
   0.46243227  0.47016132  0.52074605  0.47082004  0.47796032  0.54846978
   0.48764491  0.53445137  0.48385188  0.46118301  0.5028221   0.53935468
   0.5185343   0.51147866  0.47455376  0.5210678   0.48938987  0.50969887
   0.53196311  0.51318491  0.52511644  0.55669391  0.52608103  0.54437804
   0.52533501  0.52472448  0.47207412  0.51896203  0.46537682  0.5500167
   0.50308663  0.58421928  0.52446139  0.54626274  0.53381735  0.47632775
   0.51538342  0.5651418   0.49214989  0.48492819  0.49371159  0.44884011
   0.55061549  0.50702167  0.51986885  0.52706635  0.49908045  0.51463401
   0.60212433  0.53610361  0.50276685  0.4520452   0.49200964  0.50561696
   0.49694467  0.51250386  0.4960027   0.52757281  0.53557885  0.51744187
   0.44463855  0.52507883  0.51635975  0.58396077  0.45072806  0.51721478
   0.49136427  0.45714939  0.51268512  0.48887259  0.53467155  0.47192127
   0.53476447  0.5393728   0.50024259  0.51457149]]
After layer encoder_birnn_reverse_l0_t9_f_output (1, 256) <class 'numpy.float32'> [[ 0.54256779  0.51564354  0.53337628  0.50879586  0.49322611  0.52219516
   0.55488485  0.47215807  0.60478377  0.5529415   0.53421623  0.54414821
   0.53769916  0.49726063  0.53662723  0.54190701  0.52379072  0.49751651
   0.46174815  0.52953076  0.54229259  0.50894195  0.62696415  0.52237999
   0.53364539  0.52434236  0.55035424  0.51841658  0.53539252  0.51060861
   0.52881116  0.51432091  0.56744426  0.48786539  0.4993729   0.49385935
   0.48527065  0.54851598  0.50704914  0.52053231  0.4670271   0.53222096
   0.50527459  0.53086209  0.51549292  0.53601283  0.51003504  0.46229351
   0.49550903  0.5006305   0.52107066  0.53035367  0.48029271  0.54464716
   0.51986271  0.5111239   0.51711059  0.53099585  0.49352282  0.46834448
   0.5364337   0.5121336   0.52652025  0.50476146  0.49055752  0.5447728
   0.56053162  0.5277397   0.45220846  0.47970939  0.51982021  0.50401306
   0.48207819  0.513448    0.5336284   0.53558201  0.52083361  0.5252198
   0.53141057  0.53176391  0.56147492  0.55848187  0.51022631  0.50255686
   0.55584949  0.49509379  0.53031707  0.54070371  0.51205921  0.44891593
   0.59536904  0.51876158  0.52147883  0.51946962  0.48216915  0.50101668
   0.49277887  0.49844819  0.4466249   0.45247394  0.47464886  0.49028456
   0.51729602  0.5330109   0.48745486  0.4899486   0.46944141  0.5154168
   0.52975112  0.45705345  0.5203411   0.49212965  0.52199513  0.56683755
   0.52754492  0.5569905   0.54230589  0.53711402  0.51196194  0.53049701
   0.56081492  0.54940796  0.51179677  0.50473887  0.48242474  0.49874657
   0.54714328  0.49958253  0.52838737  0.46687374  0.54361522  0.52820319
   0.50656968  0.55747193  0.51060659  0.5064373   0.50821286  0.52022409
   0.54451084  0.56959677  0.48463464  0.50634062  0.52608871  0.51280886
   0.51732308  0.53258461  0.53550947  0.51097393  0.51315057  0.48978212
   0.49373063  0.52835512  0.51894712  0.53541386  0.48825407  0.54972893
   0.52925414  0.47562501  0.52411866  0.54535186  0.56307352  0.52948797
   0.49304092  0.52807885  0.53495783  0.49211085  0.58046442  0.4953306
   0.50005335  0.50138396  0.50446653  0.54079753  0.5014357   0.55961287
   0.48288262  0.54185027  0.54829949  0.48887506  0.49939147  0.53275806
   0.52240467  0.4798719   0.567873    0.49361584  0.49756575  0.5180487
   0.50744373  0.56015044  0.48286772  0.4780336   0.48883408  0.52040058
   0.55361265  0.5466283   0.44414389  0.50488013  0.50256711  0.49681434
   0.50914496  0.50907415  0.52441561  0.50705445  0.5235191   0.4985027
   0.532278    0.46152225  0.48076463  0.55139959  0.4729712   0.53085268
   0.52011782  0.53187001  0.48563772  0.51141471  0.49900985  0.46626535
   0.51878667  0.53011614  0.4888204   0.53838384  0.47358862  0.46868435
   0.57674265  0.49784377  0.52773881  0.49985519  0.51229519  0.52076989
   0.61704004  0.54446507  0.51880479  0.41873923  0.54372108  0.51225972
   0.52536792  0.49809051  0.50235045  0.52643037  0.52368653  0.52628422
   0.51106113  0.52158237  0.49588612  0.55966526  0.45322916  0.50015771
   0.4731864   0.48742253  0.53700066  0.48705825  0.55382222  0.44760555
   0.54432327  0.50259483  0.53784132  0.50177103]]
After layer _mul2090_0 (1, 256) <class 'numpy.float32'> [[ -9.53206792e-02  -7.75041878e-02  -2.36691665e-02   3.35119292e-02
    4.22519958e-03  -3.35339718e-02   9.22444742e-04   2.57323999e-02
    7.65979737e-02  -1.04564272e-01  -4.93601076e-02   1.29423901e-01
    6.46675527e-02  -2.69641145e-03   5.09442650e-02  -1.87983856e-01
    4.76793349e-02   1.49414493e-02   5.00710607e-02   3.68045568e-02
    1.68851256e-01  -4.33850698e-02  -2.70382613e-02   1.81162972e-02
   -8.08307454e-02   1.72978956e-02   2.73399968e-02  -2.99749207e-02
   -9.31789279e-02  -7.30353743e-02   2.79105455e-02  -6.15592822e-02
    4.53417376e-03  -2.63363263e-03   7.57246614e-02  -7.47627392e-02
   -2.67099123e-02   5.60856657e-03  -6.22468106e-02  -6.57759681e-02
    5.23091806e-03  -1.29935920e-01   7.26728588e-02   7.10461214e-02
    5.73309921e-02  -8.02709684e-02   4.29659076e-02  -2.95896623e-02
   -1.32741965e-02  -6.15636110e-02   3.85773592e-02  -9.54474732e-02
   -2.73314584e-02   1.39253616e-01  -1.54707711e-02   3.51258367e-03
   -3.90238711e-03   1.37207448e-01   6.96215704e-02  -2.33715605e-02
   -8.70042071e-02  -5.17651513e-02  -7.63240922e-03  -2.36216784e-02
    4.60545719e-02  -2.87313741e-02   2.06342712e-02  -6.78024143e-02
   -4.38322909e-02   6.79626595e-03  -1.82389051e-01   2.16322560e-02
    8.36594496e-03   1.26828589e-02   9.29599926e-02  -6.03994913e-03
   -4.68415208e-02  -1.57422081e-01  -6.12245575e-02  -3.86493281e-02
   -1.04918689e-01  -1.09034672e-03  -6.66328520e-02  -1.07164592e-01
   -2.16401607e-01   1.86465390e-04  -4.40011136e-02  -1.25587080e-03
   -1.25941381e-01  -3.82974409e-02  -1.08333282e-01  -3.20085548e-02
   -1.84942521e-02   9.19405743e-03  -2.69003380e-02   3.73575948e-02
    4.42695916e-02  -2.09380127e-02  -3.85487042e-02  -4.96819690e-02
    2.97185057e-03   8.60947147e-02  -4.58934829e-02   3.89859788e-02
    3.57018113e-02   1.06116615e-01  -2.33836845e-02  -1.48294382e-02
    1.17188238e-01  -9.39252749e-02   8.07330161e-02  -1.51495580e-02
    7.12706745e-02   1.10373154e-01  -4.92619798e-02   2.32680798e-01
   -1.21757112e-01  -6.79779574e-02   2.39908812e-03  -4.21329103e-02
    1.52085349e-01   3.47910486e-02   4.16563498e-03  -6.90006912e-02
    4.16766033e-02  -1.09297633e-01  -7.86045119e-02  -5.40195741e-02
   -3.12732309e-02  -7.91541766e-03   1.00904241e-01  -5.45632187e-03
    4.42653671e-02   6.24726876e-04  -3.23515222e-03   3.76333483e-02
    4.57715429e-02   1.58367023e-01   5.56083582e-03   5.68185560e-02
   -3.36457812e-03  -2.24456154e-02   1.01582229e-01   1.14519428e-02
   -5.54499924e-02   7.72079006e-02   6.56139702e-02  -6.17484152e-02
   -5.96682206e-02  -8.07355121e-02  -4.95649278e-02  -1.68042425e-02
   -5.81550300e-02  -4.32359390e-02  -5.15663251e-03   7.49968290e-02
   -8.76690075e-02  -5.12262480e-03   3.33161019e-02   5.81301227e-02
   -2.14554965e-01  -3.24718468e-02   6.48339931e-03   9.34460387e-02
    2.72515602e-02   4.85205762e-02   6.94283284e-04  -1.60641745e-02
   -1.39222354e-01   2.17968179e-03  -6.74952790e-02   6.09783120e-02
   -1.20806228e-02  -1.09537363e-01  -2.73336861e-02   4.24348451e-02
    1.19377628e-01  -3.26469988e-02  -2.64334213e-02  -6.38426561e-03
    4.52993624e-02   1.37279900e-02   4.60159071e-02  -2.57754922e-02
   -5.10358065e-02   1.08522810e-02   3.21099795e-02  -8.77849460e-02
    2.90962867e-02  -5.72405607e-02   1.22132801e-01  -1.67467108e-03
   -1.42828282e-02   2.92886719e-02  -1.10657647e-01   2.58514332e-03
   -1.46396428e-01  -5.92674613e-02  -1.52120534e-02   6.57688454e-02
   -1.16315864e-01  -3.67282443e-02   1.25222906e-01  -3.90749983e-02
   -1.43051427e-02  -1.83821414e-02   4.16936800e-02   1.03850458e-02
    6.93914518e-02  -4.14023176e-02  -1.19763397e-01   2.47394620e-03
    2.54316442e-02  -1.25988618e-01  -4.95290384e-02  -5.01703545e-02
    2.93037463e-02  -3.19695882e-02  -3.46835218e-02   9.65156704e-02
   -1.06365355e-02  -3.25226635e-02   9.25806314e-02   1.83396414e-02
    1.73204597e-02  -3.90079916e-02   6.42837025e-03   2.08957065e-02
   -9.35622770e-03   2.25901399e-02  -8.64116624e-02   6.21699318e-02
    1.67774893e-02   4.80780862e-02  -4.38210443e-02   1.38049200e-02
   -4.90795635e-02   2.59199888e-02  -1.52751401e-01   7.58878142e-02
   -8.61518923e-03   2.86304043e-03   8.16585030e-03  -4.63145860e-02
   -1.55020840e-02  -2.02678833e-02  -3.47906351e-02  -9.87269953e-02
    2.24658884e-02   1.30231902e-01   1.99608967e-01   4.83874530e-02
    1.23848096e-02  -4.92620245e-02  -4.42405008e-02  -6.30250259e-04]]
After layer encoder_birnn_reverse_l0_t9_i_output (1, 256) <class 'numpy.float32'> [[ 0.49651182  0.49189547  0.48511049  0.49143639  0.48764172  0.48984429
   0.49283016  0.49835771  0.5230912   0.52026999  0.48436829  0.53036273
   0.49929267  0.50262606  0.50007129  0.58576989  0.46316433  0.47354954
   0.50331599  0.49744731  0.53311127  0.4975923   0.45680809  0.48368818
   0.5109176   0.46706912  0.49321759  0.50124145  0.49577224  0.4945915
   0.49664733  0.49733138  0.48345658  0.48905906  0.52503157  0.45335183
   0.49545744  0.49454337  0.47579065  0.47616175  0.44642904  0.50679201
   0.48900482  0.5032742   0.50677055  0.49407086  0.5212571   0.47616369
   0.4826718   0.50552833  0.50948691  0.52993155  0.4460009   0.52474612
   0.54883629  0.534702    0.47877511  0.50411958  0.47303513  0.49864364
   0.52625704  0.47931874  0.54056859  0.4944818   0.47170269  0.48944953
   0.53139526  0.49481148  0.46630546  0.49536932  0.53015578  0.49578929
   0.49219492  0.48960048  0.50601244  0.51026541  0.52833456  0.54615688
   0.51576185  0.52066267  0.50641167  0.51243895  0.52476913  0.49213237
   0.54210627  0.50426412  0.49435133  0.47090977  0.49710381  0.51104051
   0.53178912  0.50429428  0.47757381  0.5169878   0.51883787  0.508066
   0.49173045  0.49746129  0.46521753  0.46276644  0.4604826   0.51829809
   0.50674301  0.47422463  0.45703059  0.50056833  0.49227974  0.47189173
   0.52225065  0.49143761  0.47647759  0.49244803  0.50940168  0.56964344
   0.50670755  0.58131909  0.49707618  0.50147814  0.49883494  0.48165691
   0.55856639  0.46723342  0.4924337   0.52804416  0.47350451  0.52395594
   0.46151593  0.52321047  0.49059549  0.5033896   0.56286246  0.50793153
   0.49787748  0.48550636  0.47510529  0.46422476  0.53252876  0.54295915
   0.49034163  0.49752313  0.48959139  0.46037555  0.52792597  0.51159322
   0.50088763  0.50341874  0.51048833  0.51696217  0.49975681  0.52321565
   0.53340602  0.4801847   0.49905124  0.47704646  0.46437389  0.55215812
   0.50670779  0.49617156  0.49348423  0.49261367  0.5674575   0.49757594
   0.47775775  0.50316727  0.50088876  0.47867417  0.4950276   0.48403504
   0.50676364  0.48717093  0.49407005  0.51219082  0.50202119  0.52411938
   0.50547254  0.44775999  0.51331943  0.46313742  0.48155627  0.49733919
   0.5164153   0.47935352  0.49773923  0.50732893  0.52840805  0.49700716
   0.49511239  0.48817551  0.52464151  0.5068863   0.48369119  0.48708427
   0.50589341  0.48062459  0.47205234  0.52636403  0.53114647  0.45414272
   0.51108813  0.52880424  0.50337565  0.52242827  0.52379948  0.5241341
   0.49912837  0.48574618  0.49397755  0.48818076  0.47622111  0.50807446
   0.51401138  0.53850311  0.50554299  0.50922477  0.49407494  0.48933777
   0.49898201  0.49509275  0.513735    0.49833626  0.48044619  0.45980254
   0.5327459   0.47719148  0.49516195  0.51800507  0.49107006  0.47149548
   0.45841551  0.5141378   0.49561512  0.45586833  0.49618021  0.48531419
   0.50649512  0.51485914  0.49885905  0.52295727  0.51100093  0.49735993
   0.45829567  0.45721313  0.52452451  0.56035316  0.48148185  0.50462639
   0.46248537  0.47444129  0.50189179  0.49285239  0.5482133   0.49373615
   0.46264362  0.51524115  0.51317197  0.50268447]]
After layer encoder_birnn_reverse_l0_t9_c_output (1, 256) <class 'numpy.float32'> [[-0.17019762 -0.15425198 -0.05807447  0.07920645 -0.01259338 -0.06541841
  -0.02076717  0.03695164  0.13803998 -0.20787281 -0.09192251  0.25537241
   0.1301612   0.01183283  0.10547912 -0.31099913  0.10442807  0.03427237
   0.12688571  0.07834844  0.32238573 -0.09544697 -0.06760006  0.02195924
  -0.15318377  0.03501148  0.03524411 -0.05298668 -0.17511615 -0.15954188
   0.05391026 -0.11719214  0.01630377 -0.0182823   0.16433592 -0.17062736
  -0.05490021  0.01728791 -0.12885119 -0.1409772   0.00138701 -0.2481741
   0.16043989  0.15541215  0.11876514 -0.16630867  0.11157669 -0.07305487
  -0.04069879 -0.13045743  0.06563426 -0.18665157 -0.04126457  0.28340867
  -0.07407187 -0.00452148  0.00657669  0.27655977  0.17045428 -0.05531007
  -0.17980294 -0.10393146 -0.00599361 -0.06546161  0.12000767 -0.05859231
   0.02794391 -0.13107191 -0.11619807  0.02510294 -0.36451912  0.05640493
  -0.00542653  0.02621576  0.18594204  0.00934904 -0.10095968 -0.30755278
  -0.13401255 -0.09028031 -0.198552   -0.01590089 -0.14317195 -0.23943889
  -0.37512007 -0.00802586 -0.05459074 -0.02330029 -0.27825758 -0.06456706
  -0.1731865  -0.06029485 -0.04001353  0.03333013 -0.0532439   0.0861288
   0.08369385 -0.02610729 -0.09443174 -0.1417321   0.00153465  0.18987282
  -0.09745775  0.09150634  0.09185661  0.24593171 -0.06108703 -0.01715106
   0.23520286 -0.22358043  0.19296286 -0.04811081  0.16079108  0.19613943
  -0.08294366  0.36752793 -0.24368463 -0.13312767 -0.03532438 -0.07974154
   0.26394117  0.05609     0.02781911 -0.1474423   0.07908786 -0.23379362
  -0.15835181 -0.12027197 -0.06429805 -0.0094413   0.20195772  0.00476276
   0.09408861 -0.01312747 -0.01548018  0.07549714  0.08884683  0.30563855
   0.02089139  0.10794491 -0.01557877 -0.04523596  0.19647579  0.01218036
  -0.12147987  0.16181363  0.14369    -0.11914567 -0.12584339 -0.17543796
  -0.1205013  -0.0347263  -0.13182032 -0.08508784 -0.02557118  0.14453138
  -0.17189275 -0.0364516   0.06795136  0.11902913 -0.35923213 -0.05646143
   0.00042888  0.17576464  0.05970255  0.10232362 -0.01825419 -0.02976986
  -0.30911499 -0.00715902 -0.14975013  0.13953456 -0.00768322 -0.17145105
  -0.08227472  0.07568801  0.22197717 -0.087703   -0.05122737 -0.00365713
   0.08507793  0.03841292  0.09692784 -0.06658923 -0.12006175 -0.00488328
   0.06896474 -0.17353722  0.02637619 -0.10351966  0.28651792  0.00718431
  -0.02876463  0.05572046 -0.29314077  0.01124795 -0.30706888 -0.15793854
  -0.02067248  0.15101831 -0.24525151 -0.08060428  0.24882676 -0.08976414
  -0.03260651 -0.04894001  0.09876906  0.02341495  0.16633564 -0.06755066
  -0.24773544  0.00995952  0.068816   -0.26338059 -0.127671   -0.12455203
   0.07009802 -0.06641442 -0.09090723  0.1995226  -0.01932583 -0.06865972
   0.1782207   0.0432661   0.0418399  -0.08613488  0.01456058  0.04859844
  -0.05533577  0.06810868 -0.17325708  0.18689141  0.02117422  0.09925648
  -0.08912408  0.02895686 -0.10411507  0.06394605 -0.32859829  0.15260434
  -0.03799618  0.01577866 -0.00473126 -0.08183536 -0.03953624 -0.02550711
  -0.09773411 -0.23495263  0.05176299  0.30618423  0.36471602  0.12600514
   0.00818066 -0.1051483  -0.08710257  0.00365354]]
After layer _mul2091_0 (1, 256) <class 'numpy.float32'> [[ -8.45051333e-02  -7.58758485e-02  -2.81725377e-02   3.89249325e-02
   -6.14105863e-03  -3.20448354e-02  -1.02346856e-02   1.84151325e-02
    7.22074956e-02  -1.08149983e-01  -4.45243530e-02   1.35440007e-01
    6.49885312e-02   5.94748789e-03   5.27470782e-02  -1.82173923e-01
    4.83673550e-02   1.62296649e-02   6.38636053e-02   3.89742181e-02
    1.71867460e-01  -4.74936739e-02  -3.08802519e-02   1.06214248e-02
   -7.82642886e-02   1.63527820e-02   1.73830129e-02  -2.65591200e-02
   -8.68177265e-02  -7.89080560e-02   2.67743878e-02  -5.82833290e-02
    7.88216479e-03  -8.94112512e-03   8.62815455e-02  -7.73542225e-02
   -2.72007175e-02   8.54961947e-03  -6.13061897e-02  -6.71279505e-02
    6.19200058e-04  -1.25772655e-01   7.84558803e-02   7.82149285e-02
    6.01866730e-02  -8.21682662e-02   5.81601411e-02  -3.47860791e-02
   -1.96441561e-02  -6.59499243e-02   3.34397964e-02  -9.89125594e-02
   -1.84040368e-02   1.48717597e-01  -4.06533293e-02  -2.41764588e-03
    3.14875320e-03   1.39419198e-01   8.06308612e-02  -2.75800135e-02
   -9.46225598e-02  -4.98162955e-02  -3.23995994e-03  -3.23695727e-02
    5.66079430e-02  -2.86779795e-02   1.48492604e-02  -6.48558885e-02
   -5.41837960e-02   1.24352276e-02  -1.93251923e-01   2.79649626e-02
   -2.67091184e-03   1.28352474e-02   9.40889865e-02   4.77049220e-03
   -5.33404872e-02  -1.67972073e-01  -6.91185594e-02  -4.70055863e-02
   -1.00549050e-01  -8.14823806e-03  -7.51322210e-02  -1.17835626e-01
   -2.03354940e-01  -4.04715398e-03  -2.69870032e-02  -1.09723359e-02
   -1.38322905e-01  -3.29963826e-02  -9.20986980e-02  -3.04063484e-02
   -1.91094130e-02   1.72312707e-02  -2.76249517e-02   4.37591150e-02
    4.11548130e-02  -1.29873659e-02  -4.39312980e-02  -6.55888543e-02
    7.06680818e-04   9.84107181e-02  -4.93860357e-02   4.33945581e-02
    4.19812836e-02   1.23105630e-01  -3.00719067e-02  -8.09344463e-03
    1.22834846e-01  -1.09875835e-01   9.19424742e-02  -2.36920714e-02
    8.19072500e-02   1.11729540e-01  -4.20281775e-02   2.13651001e-01
   -1.21129826e-01  -6.67606145e-02  -1.76210329e-02  -3.84080634e-02
    1.47428662e-01   2.62071211e-02   1.36990678e-02  -7.78560415e-02
    3.74484584e-02  -1.22497551e-01  -7.30818808e-02  -6.29275516e-02
   -3.15443315e-02  -4.75265412e-03   1.13674417e-01   2.41915556e-03
    4.68446016e-02  -6.37347205e-03  -7.35471770e-03   3.50476429e-02
    4.73134927e-02   1.65949255e-01   1.02439206e-02   5.37050925e-02
   -7.62723060e-03  -2.08255313e-02   1.03724673e-01   6.23139180e-03
   -6.08477630e-02   8.14600140e-02   7.33520687e-02  -6.15938045e-02
   -6.28910884e-02  -9.17918831e-02  -6.42761216e-02  -1.66750401e-02
   -6.57850951e-02  -4.05908525e-02  -1.18745882e-02   7.98041746e-02
   -8.70993957e-02  -1.80862471e-02   3.35329250e-02   5.86353764e-02
   -2.03848958e-01  -2.80938521e-02   2.04901444e-04   8.84390101e-02
    2.99043339e-02   4.89796735e-02  -9.03632864e-03  -1.44096538e-02
   -1.56648234e-01  -3.48766893e-03  -7.39870518e-02   7.14683235e-02
   -3.85714066e-03  -8.98608193e-02  -4.15876135e-02   3.38900648e-02
    1.13945194e-01  -4.06185426e-02  -2.46688612e-02  -1.81883271e-03
    4.39355411e-02   1.84133686e-02   4.82447855e-02  -3.37826423e-02
   -6.34415969e-02  -2.42702547e-03   3.41452993e-02  -8.47166255e-02
    1.38380425e-02  -5.24726957e-02   1.38586193e-01   3.49936495e-03
   -1.45518351e-02   2.67806202e-02  -1.38377786e-01   5.92051679e-03
   -1.63098559e-01  -7.17266351e-02  -1.05654607e-02   7.98591226e-02
   -1.23453639e-01  -4.21099551e-02   1.30335331e-01  -4.70484458e-02
   -1.62748359e-02  -2.37724204e-02   4.87896986e-02   1.14307292e-02
    7.92125463e-02  -3.43207642e-02  -1.27338842e-01   5.36323478e-03
    3.47894467e-02  -1.34119913e-01  -6.30790442e-02  -6.09480105e-02
    3.49776521e-02  -3.28813009e-02  -4.67022248e-02   9.94293466e-02
   -9.28502344e-03  -3.15699130e-02   9.49463472e-02   2.06462163e-02
    2.07175259e-02  -4.46183048e-02   7.15026632e-03   2.29139458e-02
   -2.53667738e-02   3.50172445e-02  -8.58688280e-02   8.51978734e-02
    1.05062313e-02   4.81705777e-02  -4.51409109e-02   1.49087049e-02
   -5.19387424e-02   3.34410481e-02  -1.67914033e-01   7.58992881e-02
   -1.74134839e-02   7.21421186e-03  -2.48166290e-03  -4.58567031e-02
   -1.90359820e-02  -1.28715606e-02  -4.52005975e-02  -1.11471228e-01
    2.59794202e-02   1.50903627e-01   1.99942172e-01   6.22132942e-02
    3.78472987e-03  -5.41767292e-02  -4.46985960e-02   1.83657871e-03]]
After layer encoder_birnn_reverse_l0_t9_state_0 (1, 256) <class 'numpy.float32'> [[-0.17982581 -0.15338004 -0.05184171  0.07243686 -0.00191586 -0.0655788
  -0.00931224  0.04414753  0.14880547 -0.21271425 -0.09388446  0.26486391
   0.12965608  0.00325108  0.10369134 -0.37015778  0.09604669  0.03117111
   0.11393467  0.07577877  0.34071872 -0.09087874 -0.05791851  0.02873772
  -0.15909503  0.03365068  0.04472301 -0.05653404 -0.17999665 -0.15194343
   0.05468493 -0.11984261  0.01241634 -0.01157476  0.1620062  -0.15211695
  -0.05391063  0.01415819 -0.123553   -0.13290392  0.00585012 -0.25570858
   0.15112874  0.14926106  0.11751767 -0.16243923  0.10112604 -0.06437574
  -0.03291835 -0.12751353  0.07201716 -0.19436003 -0.04573549  0.2879712
  -0.0561241   0.00109494 -0.00075363  0.27662665  0.15025243 -0.05095157
  -0.18162677 -0.10158145 -0.01087237 -0.05599125  0.10266252 -0.05740935
   0.03548353 -0.1326583  -0.09801608  0.01923149 -0.37564099  0.04959722
   0.00569503  0.02551811  0.18704897 -0.00126946 -0.10018201 -0.32539415
  -0.13034311 -0.08565491 -0.20546773 -0.00923858 -0.14176507 -0.22500022
  -0.41975653 -0.00386069 -0.07098812 -0.01222821 -0.26426429 -0.07129382
  -0.20043197 -0.0624149  -0.03760367  0.02642533 -0.05452529  0.08111671
   0.08542441 -0.03392538 -0.08248    -0.11527082  0.00367853  0.18450543
  -0.09527951  0.08238053  0.07768309  0.22922224 -0.05345559 -0.02292288
   0.24002308 -0.20380111  0.17267549 -0.03884163  0.15317792  0.2221027
  -0.09129016  0.4463318  -0.24288693 -0.13473856 -0.01522195 -0.08054097
   0.299514    0.06099817  0.0178647  -0.14685673  0.07912506 -0.23179519
  -0.1516864  -0.11694713 -0.06281756 -0.01266807  0.21457866 -0.00303717
   0.09110997 -0.00574875 -0.01058987  0.07268099  0.09308504  0.32431626
   0.01580476  0.11052365 -0.01099181 -0.04327115  0.2053069   0.01768333
  -0.11629775  0.15866792  0.13896604 -0.12334222 -0.12255931 -0.1725274
  -0.11384105 -0.03347928 -0.12394013 -0.0838268  -0.01703122  0.15480101
  -0.1747684  -0.02320887  0.06684902  0.1167655  -0.41840392 -0.0605657
   0.0066883   0.18188505  0.05715589  0.09750025 -0.00834205 -0.03047383
  -0.2958706  -0.00130799 -0.14148232  0.13244663 -0.01593776 -0.19939819
  -0.0689213   0.07632491  0.23332283 -0.07326554 -0.05110228 -0.0082031
   0.0892349   0.03214136  0.09426069 -0.05955813 -0.1144774   0.00842526
   0.06625528 -0.17250156  0.04293433 -0.10971326  0.260719    0.00182469
  -0.02883466  0.05606929 -0.24903543  0.00850566 -0.30949497 -0.1309941
  -0.02577752  0.14562798 -0.2397695  -0.0788382   0.25555825 -0.08612344
  -0.03057998 -0.04215456  0.09048338  0.02181577  0.14860401 -0.07572308
  -0.24710223  0.00783718  0.06022109 -0.26010853 -0.11260808 -0.11111836
   0.0642814  -0.06485089 -0.08138575  0.19594502 -0.01992156 -0.06409258
   0.18752697  0.03898586  0.03803799 -0.0836263   0.01357864  0.04380965
  -0.034723    0.05760738 -0.17228049  0.14736781  0.02728372  0.09624866
  -0.08896196  0.02871362 -0.10101831  0.05936104 -0.32066542  0.1517871
  -0.02602867  0.01007725  0.00568419 -0.09217129 -0.03453807 -0.03313944
  -0.07999124 -0.21019822  0.04844531  0.28113553  0.39955115  0.11060075
   0.01616954 -0.10343875 -0.0889391   0.00120633]]
After layer activation1045_output (1, 256) <class 'numpy.float32'> [[-0.17791221 -0.15218848 -0.05179531  0.07231043 -0.00191586 -0.06548496
  -0.00931197  0.04411887  0.14771678 -0.20956303 -0.09360959  0.25883925
   0.1289344   0.00325107  0.10332131 -0.3541297   0.09575243  0.03116102
   0.11344422  0.07563405  0.32811886 -0.09062938 -0.05785384  0.02872981
  -0.15776619  0.03363798  0.04469322 -0.05647389 -0.17807764 -0.15078484
   0.05463049 -0.11927216  0.0124157  -0.01157424  0.16060358 -0.15095441
  -0.05385846  0.01415724 -0.12292813 -0.1321269   0.00585005 -0.25027725
   0.14998858  0.14816239  0.11697965 -0.16102542  0.10078273 -0.06428696
  -0.03290647 -0.12682688  0.07189291 -0.19194908 -0.04570363  0.28026643
  -0.05606525  0.00109494 -0.00075363  0.2697801   0.14913186 -0.05090753
  -0.1796556  -0.10123349 -0.01087194 -0.05593281  0.10230336 -0.05734637
   0.03546865 -0.13188556 -0.0977034   0.01922912 -0.35891593  0.04955659
   0.00569497  0.02551257  0.18489763 -0.00126946 -0.0998482  -0.31437615
  -0.12960994 -0.08544605 -0.20262434 -0.00923832 -0.14082295 -0.22127868
  -0.39672533 -0.00386067 -0.07086912 -0.0122276  -0.25827971 -0.07117328
  -0.19779043 -0.06233398 -0.03758595  0.02641918 -0.05447132  0.08093926
   0.08521722 -0.03391237 -0.08229347 -0.11476298  0.00367851  0.18243989
  -0.09499224  0.08219468  0.0775272   0.22529019 -0.05340473 -0.02291887
   0.23551755 -0.20102561  0.17097951 -0.03882211  0.15199104  0.21852128
  -0.09103741  0.41887909 -0.23822072 -0.13392907 -0.01522077 -0.08036727
   0.29086778  0.06092263  0.0178628  -0.14581001  0.07896034 -0.22773114
  -0.15053365 -0.11641689 -0.06273507 -0.01266739  0.21134485 -0.00303716
   0.09085871 -0.00574868 -0.01058947  0.07255328  0.09281711  0.31340447
   0.01580344  0.11007581 -0.01099137 -0.04324416  0.20247009  0.01768149
  -0.11577626  0.15734969  0.13807835 -0.12272052 -0.12194933 -0.17083575
  -0.11335181 -0.03346678 -0.12330938 -0.083631   -0.01702957  0.15357624
  -0.17301051 -0.0232047   0.06674962  0.11623771 -0.39558497 -0.06049175
   0.0066882   0.17990553  0.05709374  0.09719247 -0.00834185 -0.0304644
  -0.28752911 -0.00130799 -0.1405458   0.13167757 -0.01593642 -0.19679689
  -0.06881238  0.07617705  0.22917904 -0.07313473 -0.05105785 -0.00820291
   0.0889988   0.03213029  0.09398251 -0.05948781 -0.11397994  0.00842506
   0.0661585  -0.17081067  0.04290797 -0.10927516  0.2549679   0.00182469
  -0.02882667  0.05601061 -0.24401174  0.00850546 -0.29997757 -0.13024995
  -0.02577181  0.14460717 -0.23527803 -0.07867527  0.25013635 -0.08591114
  -0.03057045 -0.04212961  0.09023725  0.02181231  0.14751971 -0.07557868
  -0.24219279  0.00783702  0.0601484  -0.25439703 -0.11213451 -0.11066327
   0.064193   -0.06476013 -0.08120653  0.19347522 -0.01991892 -0.06400496
   0.18535925  0.03896612  0.03801965 -0.0834319   0.0135778   0.04378165
  -0.03470905  0.05754374 -0.17059603  0.1463102   0.02727695  0.09595256
  -0.08872801  0.02870574 -0.10067609  0.05929141 -0.31010845  0.15063205
  -0.0260228   0.01007691  0.00568413 -0.09191116 -0.03452434 -0.03312732
  -0.07982107 -0.20715623  0.04840744  0.2739557   0.37956485  0.11015197
   0.01616813 -0.10307141 -0.08870533  0.00120633]]
After layer encoder_birnn_reverse_l0_t9_out_0 (1, 256) <class 'numpy.float32'> [[-0.09297249 -0.07926296 -0.02578648  0.03769153 -0.00096319 -0.03620492
  -0.00483552  0.02317671  0.09202995 -0.11291787 -0.04506745  0.13508679
   0.07036075  0.00158703  0.05341484 -0.19104956  0.04645202  0.01479761
   0.05837287  0.03791589  0.15985887 -0.04174795 -0.03378589  0.0152428
  -0.07976238  0.01771213  0.02203726 -0.02782177 -0.08307578 -0.07563118
   0.02900674 -0.06291547  0.00637033 -0.00592388  0.07999965 -0.07263245
  -0.02860964  0.00704082 -0.06273182 -0.06421448  0.00297327 -0.12378512
   0.07496051  0.07484365  0.05767782 -0.08242106  0.05159357 -0.03026778
  -0.01666836 -0.06762279  0.03749301 -0.09660342 -0.0212351   0.14439492
  -0.03060278  0.00052029 -0.00041009  0.13807599  0.07549945 -0.02393105
  -0.09471579 -0.05349633 -0.00551366 -0.03068525  0.05087698 -0.02809441
   0.01984463 -0.0683399  -0.04770983  0.00981059 -0.18072413  0.02517479
   0.0028406   0.01263565  0.10013794 -0.0006871  -0.05373761 -0.16009954
  -0.06977302 -0.04777949 -0.11210782 -0.00512318 -0.0755334  -0.11595463
  -0.21749029 -0.0019826  -0.0365568  -0.00629029 -0.13516989 -0.03598366
  -0.10877486 -0.03036067 -0.0177854   0.01340305 -0.02748625  0.04103259
   0.0436127  -0.01723655 -0.03792185 -0.05331364  0.00175638  0.08379889
  -0.04502221  0.03890906  0.03772517  0.11278793 -0.02603203 -0.01229143
   0.12210035 -0.1040405   0.0874956  -0.02001299  0.07193521  0.11843596
  -0.04532491  0.22748183 -0.11529074 -0.06559845 -0.00777419 -0.0390154
   0.14887692  0.0320832   0.00926785 -0.07223435  0.03776733 -0.1166829
  -0.07615783 -0.05869574 -0.03126361 -0.00590003  0.10747498 -0.00165401
   0.04497424 -0.00307251 -0.00543502  0.03439936  0.05029899  0.16036528
   0.00851874  0.05680518 -0.00558355 -0.02148042  0.09825172  0.00933401
  -0.05726391  0.08050375  0.07640418 -0.06487706 -0.06173807 -0.08425449
  -0.05628375 -0.01650001 -0.06524058 -0.04512937 -0.00829091  0.07943883
  -0.09254543 -0.01201585  0.03402334  0.06301515 -0.2071467  -0.03137587
   0.00337984  0.09633408  0.03005609  0.04595224 -0.00487765 -0.01624351
  -0.13174048 -0.00066524 -0.06502397  0.07098116 -0.00849395 -0.11109185
  -0.0343322   0.04195795  0.12411643 -0.03510126 -0.02620907 -0.00404439
   0.04115592  0.01510642  0.04894102 -0.02800805 -0.05447789  0.00462089
   0.03226186 -0.09129     0.0207611  -0.05039585  0.1282035   0.00098416
  -0.01494762  0.02864823 -0.11579669  0.00443192 -0.14680599 -0.06638825
  -0.01370965  0.07421022 -0.12354836 -0.04379804  0.13159199 -0.04676814
  -0.01605973 -0.02210644  0.04259867  0.01131976  0.06865225 -0.04156954
  -0.12184396  0.00457854  0.03154551 -0.13896762 -0.05985935 -0.05271199
   0.03308401 -0.03659865 -0.03996579  0.09382159 -0.0098342  -0.02872799
   0.10206167  0.01975667  0.01976523 -0.04397415  0.00677642  0.02253152
  -0.02089917  0.03084941 -0.08577003  0.06613882  0.01342052  0.04851524
  -0.04409291  0.0147118  -0.04993561  0.03128054 -0.16608752  0.07794333
  -0.01157074  0.00529117  0.00293505 -0.05367251 -0.01556109 -0.01713394
  -0.03922122 -0.09470134  0.02481778  0.13392943  0.20294252  0.05198305
   0.00864614 -0.05559391 -0.04437418  0.00062074]]
After layer expand_dims1051_0 (1, 1, 256) <class 'numpy.float32'> [[[-0.09297249 -0.07926296 -0.02578648  0.03769153 -0.00096319 -0.03620492
   -0.00483552  0.02317671  0.09202995 -0.11291787 -0.04506745  0.13508679
    0.07036075  0.00158703  0.05341484 -0.19104956  0.04645202  0.01479761
    0.05837287  0.03791589  0.15985887 -0.04174795 -0.03378589  0.0152428
   -0.07976238  0.01771213  0.02203726 -0.02782177 -0.08307578 -0.07563118
    0.02900674 -0.06291547  0.00637033 -0.00592388  0.07999965 -0.07263245
   -0.02860964  0.00704082 -0.06273182 -0.06421448  0.00297327 -0.12378512
    0.07496051  0.07484365  0.05767782 -0.08242106  0.05159357 -0.03026778
   -0.01666836 -0.06762279  0.03749301 -0.09660342 -0.0212351   0.14439492
   -0.03060278  0.00052029 -0.00041009  0.13807599  0.07549945 -0.02393105
   -0.09471579 -0.05349633 -0.00551366 -0.03068525  0.05087698 -0.02809441
    0.01984463 -0.0683399  -0.04770983  0.00981059 -0.18072413  0.02517479
    0.0028406   0.01263565  0.10013794 -0.0006871  -0.05373761 -0.16009954
   -0.06977302 -0.04777949 -0.11210782 -0.00512318 -0.0755334  -0.11595463
   -0.21749029 -0.0019826  -0.0365568  -0.00629029 -0.13516989 -0.03598366
   -0.10877486 -0.03036067 -0.0177854   0.01340305 -0.02748625  0.04103259
    0.0436127  -0.01723655 -0.03792185 -0.05331364  0.00175638  0.08379889
   -0.04502221  0.03890906  0.03772517  0.11278793 -0.02603203 -0.01229143
    0.12210035 -0.1040405   0.0874956  -0.02001299  0.07193521  0.11843596
   -0.04532491  0.22748183 -0.11529074 -0.06559845 -0.00777419 -0.0390154
    0.14887692  0.0320832   0.00926785 -0.07223435  0.03776733 -0.1166829
   -0.07615783 -0.05869574 -0.03126361 -0.00590003  0.10747498 -0.00165401
    0.04497424 -0.00307251 -0.00543502  0.03439936  0.05029899  0.16036528
    0.00851874  0.05680518 -0.00558355 -0.02148042  0.09825172  0.00933401
   -0.05726391  0.08050375  0.07640418 -0.06487706 -0.06173807 -0.08425449
   -0.05628375 -0.01650001 -0.06524058 -0.04512937 -0.00829091  0.07943883
   -0.09254543 -0.01201585  0.03402334  0.06301515 -0.2071467  -0.03137587
    0.00337984  0.09633408  0.03005609  0.04595224 -0.00487765 -0.01624351
   -0.13174048 -0.00066524 -0.06502397  0.07098116 -0.00849395 -0.11109185
   -0.0343322   0.04195795  0.12411643 -0.03510126 -0.02620907 -0.00404439
    0.04115592  0.01510642  0.04894102 -0.02800805 -0.05447789  0.00462089
    0.03226186 -0.09129     0.0207611  -0.05039585  0.1282035   0.00098416
   -0.01494762  0.02864823 -0.11579669  0.00443192 -0.14680599 -0.06638825
   -0.01370965  0.07421022 -0.12354836 -0.04379804  0.13159199 -0.04676814
   -0.01605973 -0.02210644  0.04259867  0.01131976  0.06865225 -0.04156954
   -0.12184396  0.00457854  0.03154551 -0.13896762 -0.05985935 -0.05271199
    0.03308401 -0.03659865 -0.03996579  0.09382159 -0.0098342  -0.02872799
    0.10206167  0.01975667  0.01976523 -0.04397415  0.00677642  0.02253152
   -0.02089917  0.03084941 -0.08577003  0.06613882  0.01342052  0.04851524
   -0.04409291  0.0147118  -0.04993561  0.03128054 -0.16608752  0.07794333
   -0.01157074  0.00529117  0.00293505 -0.05367251 -0.01556109 -0.01713394
   -0.03922122 -0.09470134  0.02481778  0.13392943  0.20294252  0.05198305
    0.00864614 -0.05559391 -0.04437418  0.00062074]]]
After layer concat5_output (10, 1, 256) <class 'numpy.float32'> [[[-0.02972036 -0.01193881 -0.0151285  ..., -0.0131865   0.01045789
   -0.01747098]]

 [[-0.02630692 -0.01462029  0.0152738  ..., -0.00765535  0.0093059
   -0.03514839]]

 [[-0.0440224  -0.03664438  0.00861667 ..., -0.02057062 -0.00747708
   -0.02040144]]

 ...,
 [[-0.08762206 -0.07496516 -0.01796513 ..., -0.04926956 -0.0371931
   -0.0020475 ]]

 [[-0.09054606 -0.077365   -0.02204476 ..., -0.05254674 -0.04100338
   -0.00064611]]

 [[-0.09297249 -0.07926296 -0.02578648 ..., -0.05559391 -0.04437418
    0.00062074]]]
After layer sequencereverse5_output (10, 1, 256) <class 'numpy.float32'> [[[-0.02630692 -0.01462029  0.0152738  ..., -0.00765535  0.0093059
   -0.03514839]]

 [[-0.02972036 -0.01193881 -0.0151285  ..., -0.0131865   0.01045789
   -0.01747098]]

 [[-0.0440224  -0.03664438  0.00861667 ..., -0.02057062 -0.00747708
   -0.02040144]]

 ...,
 [[-0.08762206 -0.07496516 -0.01796513 ..., -0.04926956 -0.0371931
   -0.0020475 ]]

 [[-0.09054606 -0.077365   -0.02204476 ..., -0.05254674 -0.04100338
   -0.00064611]]

 [[-0.09297249 -0.07926296 -0.02578648 ..., -0.05559391 -0.04437418
    0.00062074]]]
After layer encoder_birnn__rnn_output (10, 1, 512) <class 'numpy.float32'> [[[  3.44843185e-03   2.28170734e-02  -6.56714384e-03 ...,  -7.65535329e-03
     9.30589810e-03  -3.51483934e-02]]

 [[  2.75869574e-02   5.06735183e-02  -5.15802950e-02 ...,  -1.31864967e-02
     1.04578855e-02  -1.74709819e-02]]

 [[  4.40447591e-02   7.92230219e-02  -1.12799339e-01 ...,  -2.05706246e-02
    -7.47707998e-03  -2.04014406e-02]]

 ...,
 [[  6.63714588e-01   5.45868814e-01  -6.80252373e-01 ...,  -4.92695607e-02
    -3.71930972e-02  -2.04749964e-03]]

 [[  8.23300898e-01   6.33265078e-01  -7.52719641e-01 ...,  -5.25467433e-02
    -4.10033800e-02  -6.46106084e-04]]

 [[  9.11624432e-01   7.01876104e-01  -8.03623199e-01 ...,  -5.55939116e-02
    -4.43741828e-02   6.20741921e-04]]]
After layer swapaxes11_output (1, 10, 512) <class 'numpy.float32'> [[[  3.44843185e-03   2.28170734e-02  -6.56714384e-03 ...,  -7.65535329e-03
     9.30589810e-03  -3.51483934e-02]
  [  2.75869574e-02   5.06735183e-02  -5.15802950e-02 ...,  -1.31864967e-02
     1.04578855e-02  -1.74709819e-02]
  [  4.40447591e-02   7.92230219e-02  -1.12799339e-01 ...,  -2.05706246e-02
    -7.47707998e-03  -2.04014406e-02]
  ...,
  [  6.63714588e-01   5.45868814e-01  -6.80252373e-01 ...,  -4.92695607e-02
    -3.71930972e-02  -2.04749964e-03]
  [  8.23300898e-01   6.33265078e-01  -7.52719641e-01 ...,  -5.25467433e-02
    -4.10033800e-02  -6.46106084e-04]
  [  9.11624432e-01   7.01876104e-01  -8.03623199e-01 ...,  -5.55939116e-02
    -4.43741828e-02   6.20741921e-04]]]
After layer zeros_like5_0 (1,) <class 'numpy.float32'> [ 0.]
After layer expand_dims1053_0 (1, 1) <class 'numpy.float32'> [[ 0.]]
After layer expand_dims1054_0 (1, 1, 1) <class 'numpy.float32'> [[[ 0.]]]
After layer broadcast_to2_0 (1, 10, 1) <class 'numpy.float32'> [[[ 0.]
  [ 0.]
  [ 0.]
  [ 0.]
  [ 0.]
  [ 0.]
  [ 0.]
  [ 0.]
  [ 0.]
  [ 0.]]]
After layer zeros_like4_0 (1,) <class 'numpy.float32'> [ 0.]
After layer expand_dims1052_0 (1, 1) <class 'numpy.float32'> [[ 0.]]
After layer tile2_0 (1, 512) <class 'numpy.float32'> [[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
   0.  0.  0.  0.  0.  0.  0.  0.]]
After layer swapaxes12_output (10, 1, 512) <class 'numpy.float32'> [[[  3.44843185e-03   2.28170734e-02  -6.56714384e-03 ...,  -7.65535329e-03
     9.30589810e-03  -3.51483934e-02]]

 [[  2.75869574e-02   5.06735183e-02  -5.15802950e-02 ...,  -1.31864967e-02
     1.04578855e-02  -1.74709819e-02]]

 [[  4.40447591e-02   7.92230219e-02  -1.12799339e-01 ...,  -2.05706246e-02
    -7.47707998e-03  -2.04014406e-02]]

 ...,
 [[  6.63714588e-01   5.45868814e-01  -6.80252373e-01 ...,  -4.92695607e-02
    -3.71930972e-02  -2.04749964e-03]]

 [[  8.23300898e-01   6.33265078e-01  -7.52719641e-01 ...,  -5.25467433e-02
    -4.10033800e-02  -6.46106084e-04]]

 [[  9.11624432e-01   7.01876104e-01  -8.03623199e-01 ...,  -5.55939116e-02
    -4.43741828e-02   6.20741921e-04]]]
After layer sequencelast2_output (1, 512) <class 'numpy.float32'> [[ 0.02758696  0.05067352 -0.05158029 -0.01663     0.05928731 -0.03546434
   0.03702098 -0.0331233   0.02276829 -0.01865645  0.01365109  0.03008797
   0.04462755 -0.05511975  0.02689268 -0.03358052  0.01107924  0.0492439
  -0.01512345  0.02368348 -0.0409143  -0.04112128 -0.07257126  0.03563707
   0.00397431 -0.01179627 -0.08532663 -0.03333309 -0.02603407  0.03121304
   0.01792355 -0.05750624  0.06284095 -0.0058577   0.05628944  0.04538604
   0.02992563 -0.05333969 -0.05615452  0.01676422 -0.04267198  0.04015135
  -0.04607907  0.02892258 -0.02553735 -0.01616411  0.02203694  0.04503017
   0.04508416  0.00096605  0.00553319  0.02166822  0.03878214 -0.02247067
   0.06188027  0.04632847 -0.0217007  -0.01676868  0.05554721 -0.03166346
   0.03765696 -0.02363514  0.03746745  0.07492346 -0.04420747  0.01906084
   0.01330622  0.06218674  0.0225127  -0.06721491  0.01604867 -0.03477257
  -0.09595693  0.03177647  0.04330185  0.03473465  0.05140708 -0.10604271
   0.05666973 -0.05873546  0.05059771 -0.04979826  0.06070265  0.01942953
  -0.02760384 -0.06280298  0.03257427 -0.07126144  0.00632061  0.03762437
   0.02705244  0.03724489 -0.03735551 -0.02903094 -0.06379046  0.00440185
  -0.0015037  -0.09649675  0.0279366   0.06136044 -0.02938816 -0.00945095
  -0.01589378  0.05109256 -0.02093127 -0.04065489  0.01714623  0.05800673
   0.03586307  0.06514163 -0.0333946  -0.05607566  0.07159675  0.07542687
  -0.01459817  0.04600225  0.03903005  0.04333036  0.0407986  -0.00387167
   0.00831607 -0.0782344   0.06439531 -0.02933011  0.09425342 -0.01015867
   0.04758663  0.03726394 -0.04653452 -0.10308192 -0.00587847  0.03748224
   0.02438359 -0.01989255  0.06259575  0.05827288 -0.00563762  0.04826911
  -0.0786775  -0.02355763 -0.02286621  0.06048404 -0.06186247 -0.01824755
   0.0580007   0.02686242  0.04464926 -0.0251728   0.05208122 -0.0350395
   0.04013351 -0.04023178  0.05678146  0.09028109  0.0355165  -0.06972807
   0.05379215 -0.00996709  0.03346585  0.02215277  0.07922234  0.03531419
   0.05613809  0.04135889 -0.0410865   0.02922001 -0.03792449  0.03364135
  -0.05599269 -0.03569081  0.02939742  0.07781686 -0.0363782   0.04453019
  -0.02461324 -0.02952692  0.04604772  0.04658758 -0.04868253 -0.01001075
   0.06346335  0.04858874  0.0356415   0.03602699 -0.0166421  -0.04706815
  -0.02815033  0.07019776  0.02538897 -0.01500779  0.01989698 -0.04794651
  -0.07350598  0.07331237  0.02188345 -0.05676148 -0.00023221 -0.06287498
   0.04969535  0.0131508   0.0451873  -0.05783146 -0.03184023 -0.01131758
  -0.04840171  0.03610859  0.01193958  0.01928276  0.02445959  0.04980856
  -0.02639864  0.06445104  0.04375321  0.00347528  0.06562649 -0.05646896
  -0.03916651 -0.06471146 -0.02157398  0.00757807 -0.03302746  0.02921305
   0.05308366 -0.07812683  0.03817958 -0.10160037 -0.08272609 -0.05377689
   0.01712119 -0.01756216 -0.02946329 -0.05400823 -0.00562969  0.0767308
  -0.02963654 -0.00895078  0.07373441  0.06670626 -0.01433768  0.0648765
   0.03228792  0.04250057 -0.08435337 -0.0462772   0.05617799 -0.04143731
   0.0074911  -0.03487483 -0.06281573  0.04469606 -0.04992564 -0.01421539
  -0.04052442 -0.04180025  0.00665703  0.05025622 -0.02972036 -0.01193881
  -0.0151285  -0.02836049  0.00069946 -0.05084697  0.01520241  0.00743134
  -0.01262894 -0.02926348 -0.00892713  0.0215123   0.01944452 -0.02441785
   0.02237723 -0.01263511  0.01180655  0.01028782  0.01543553 -0.00818657
   0.01702098 -0.02945089  0.00572997  0.02170727  0.00350297 -0.00063438
  -0.05003827 -0.0041713   0.00457098 -0.01955438  0.01312406 -0.01486368
   0.01569128 -0.00918226  0.01121257 -0.00168242 -0.04046974 -0.00548622
  -0.0271799  -0.00129998  0.00836258  0.0065626   0.02973634  0.00282831
   0.0325233  -0.02289932  0.02365089 -0.01884407 -0.00304257 -0.03840168
  -0.03876188 -0.01310304  0.00893535  0.02011474 -0.00271625  0.0137778
  -0.02578983  0.0309145   0.00949841 -0.03233417 -0.02153551 -0.00498526
  -0.01405536 -0.02340435  0.03284904 -0.02373183  0.02368972 -0.00036681
  -0.0301962  -0.01752724 -0.03949749  0.01233599  0.00642096 -0.01828921
   0.00467782 -0.02523236 -0.01780552 -0.02340834 -0.01008676 -0.01079575
  -0.02658223 -0.00647103 -0.01719533 -0.03110186 -0.02228216  0.01877622
  -0.01250377  0.01481159 -0.01006478 -0.03860864  0.02726565  0.00107607
   0.01275591 -0.01413143  0.01476357 -0.00128387  0.01144056  0.0190364
   0.00614701  0.00794415  0.01214546  0.0217392  -0.03644164  0.01467827
  -0.01659137  0.00683047 -0.00529683 -0.03299136  0.02570515 -0.00377658
   0.02754575  0.05659572 -0.00127031  0.01611202 -0.01236641 -0.00540955
  -0.01441913 -0.03133336  0.00042174  0.01967184  0.0108244   0.0205042
  -0.01662106 -0.01066665  0.03078565 -0.02427435 -0.01491891 -0.00466224
   0.02218396  0.03938602  0.02452741  0.0287828   0.00157881  0.02304478
   0.00751847  0.01876433  0.01269723 -0.00427434  0.01747201  0.03392094
  -0.02721227 -0.00717461  0.01521452 -0.02424134 -0.03433834  0.01940665
   0.0425644  -0.02564539  0.0039989  -0.0057736  -0.02062998 -0.00551672
   0.00696677  0.00358115  0.00526468 -0.0273643  -0.03033925  0.0175885
   0.0305201   0.02157643 -0.01197147 -0.0137018   0.01243467  0.01000247
   0.01056114  0.00781583  0.01651376 -0.03192909  0.00062189 -0.02331569
  -0.01066475  0.01901653 -0.01051066 -0.00664841 -0.01656996  0.01315831
   0.06102301 -0.01058824 -0.04370104 -0.01415143 -0.00225248 -0.0042
  -0.02293182 -0.00239285  0.05526    -0.020806    0.00493044 -0.02846489
   0.0166819  -0.0198828   0.00649536  0.03200149 -0.00101315  0.00436961
  -0.01757208  0.01150848 -0.02885254 -0.02717836  0.01145908  0.01248074
  -0.0132782   0.02777532  0.03288406 -0.01378531  0.02513099 -0.00474639
  -0.017749    0.00962295  0.03498261 -0.01861157 -0.00306766  0.00967958
   0.02575789 -0.02363773  0.01308168 -0.01946216  0.00263268 -0.00123264
  -0.01480732  0.03010147  0.03052292 -0.01325256 -0.01642147 -0.00351147
  -0.01005043 -0.006236   -0.00696044  0.02159901 -0.0039634   0.00919465
  -0.0010749   0.02077699  0.02132058  0.0066258  -0.01174076  0.02927459
  -0.02088817 -0.00402945 -0.01185813  0.01911327  0.01039185 -0.01324157
   0.01745545  0.0117179  -0.02797303  0.01062377  0.00388984  0.00206273
  -0.03028844  0.01459072  0.01433031  0.0154703   0.0360424  -0.0131865
   0.01045789 -0.01747098]]
After layer decoder_rnn_enc2decinit_0_output (1, 512) <class 'numpy.float32'> [[-0.01642388 -0.07019246  0.1656809   0.12823099 -0.00950188 -0.04649036
  -0.42640501 -0.09732381  0.12800649  0.11437811 -0.21702914 -0.13718711
  -0.1640027   0.19626756  0.11380328 -0.1383027  -0.11790906  0.21671408
   0.47337255 -0.18149488  0.1383794   0.17019609  0.07202538 -0.22888015
  -0.10694692 -0.15894663  0.14499733  0.10701104 -0.12036688 -0.17642519
  -0.27030015  0.14733689  0.30063167  0.09495117  0.11277589  0.22804739
   0.05276926 -0.0431707  -0.54634124 -0.12338513 -0.04791247  0.25122291
  -0.19681218 -0.65622401 -0.09950314  0.1635699  -0.19001476 -0.50309253
   0.0840054  -0.09017836  0.05627543 -0.15192446  0.22320379 -0.05588605
   0.17230524 -0.00187355 -0.11131284  0.29206389 -0.07814575 -0.23078747
   0.01973692 -0.12458211  0.13275883 -0.35457963 -0.36141106 -0.17576008
  -0.15733188 -0.04801387 -0.19838536  0.07317568 -0.66292334 -0.09965103
   0.23810165 -0.09805041  0.15576899  0.36475629 -0.03661275 -0.08617172
  -0.25304079 -0.06131274 -0.08956984 -0.08827648 -0.23629737  0.4049243
   0.1899979  -0.09856629 -0.08192945 -0.10642361 -0.17395179  0.25052953
  -0.1638834  -0.61133438 -0.30987066  0.08064342 -0.27702811 -0.1637374
   0.13111395 -0.11864392 -0.03395236 -0.16111805 -0.09496604 -0.1071791
   0.29765975 -0.03480171  0.13297643 -0.13346633 -0.10682702 -0.12861761
  -0.19082087  0.2286969   0.32048538  0.22115292 -0.58661914  0.00500567
   0.02614346  0.24868697 -0.10625963 -0.42209125 -0.14386143 -0.09819297
  -0.12844741 -0.47642517  0.1598326   0.07011486  0.15498795  0.21833214
   0.24650235  0.35190189 -0.03512594 -0.17092665 -0.12076375 -0.13069138
  -0.2481706   0.16978663  0.14901838  0.12391986 -0.12463257 -0.60956818
  -0.27801049 -0.05483267 -0.18174152  0.12905258  0.24362051  0.0488441
   0.12820931 -0.27260613  0.25441605  0.13918     0.12903288  0.58713591
   0.36636189 -0.09767769  0.25276494  0.20134386 -0.03318115 -0.06871939
   0.08322362 -0.15046631 -0.01318427 -0.15570755  0.28784606  0.12612402
   0.11586053 -0.13588402 -0.20356625 -0.1271309   0.12547456 -0.07050322
  -0.12925877 -0.07434762  0.12356965  0.10304116 -0.05055147 -0.0443452
  -0.14919728 -0.20658092 -0.15015197 -0.1002798   0.18501608 -0.25272927
   0.12282941  0.13406466 -0.23339529 -0.20434508  0.17753543  0.26157755
  -0.24626529  0.19120619 -0.21371144  0.22733691  0.02832982 -0.14213988
  -0.07964963 -0.0485983   0.12260856 -0.17075135 -0.08106536 -0.21247438
   0.22115095  0.59406185  0.16471231 -0.19959661 -0.07703848 -0.15550196
   0.1453592  -0.10692896 -0.10944057 -0.25791836  0.22620432 -0.26187891
   0.09141831  0.17252778 -0.09400026  0.13888361 -0.21579444 -0.23844045
   0.24434921 -0.17326377  0.16270518  0.17088722  0.03497686 -0.19760902
   0.06821677 -0.18564281  0.09977308 -0.25498733 -0.14726636  0.24449697
  -0.08701668 -0.43268341  0.2513662  -0.4283908   0.14047076  0.10564128
   0.17656568 -0.0491343  -0.39453468  0.19633216  0.19114144 -0.12904692
   0.13754895 -0.071867   -0.2180139  -0.13687009  0.23341516 -0.05796559
  -0.06987009  0.11643744  0.1209124  -0.09495587 -0.1374734   0.25849292
   0.20269153  0.00786546  0.1461259   0.07538532  0.10726555  0.28763029
  -0.13368383  0.25331795  0.09902672  0.20271495  0.19803745  0.10784437
  -0.05161023 -0.03065906  0.26584017  0.17683239  0.16041292  0.32581419
   0.18175425  0.17407188 -0.18785311 -0.16307023  0.13148992 -0.21691425
   0.6090104   0.01917297  0.07471827  0.26020956  0.15246715  0.09959999
  -0.2466653  -0.06738724 -0.42869356 -0.02721137  0.05666856 -0.23050202
  -0.1584259   0.28369924  0.14351922  0.13517576  0.20791531 -0.19690664
   0.10554758  0.02449393  0.13480365  0.26257414 -0.01933627 -0.13888182
  -0.316259    0.03436456 -0.10592055  0.07832138 -0.0480013  -0.17703839
  -0.21655053  0.08328575  0.18722992  0.04639897 -0.21932225 -0.16502081
  -0.16756843 -0.1274555   0.20875396 -0.0600644  -0.06618468 -0.08880029
   0.29574385 -0.18126476  0.22330528  0.27810338  0.14268401  0.01157959
  -0.21553476  0.51799446  0.13863672 -0.09399132 -0.11569326 -0.14032322
   0.13900425 -0.18307783 -0.46345678 -0.1828272  -0.09863593 -0.08052234
  -0.03457469 -0.1459015  -0.12706448 -0.29811209 -0.20883387 -0.18590236
  -0.05661885  0.41330877 -0.03615312 -0.09908742  0.1602197  -0.20173794
   0.20145872  0.59375119  0.309457    0.010215   -0.1599022  -0.11215211
  -0.32963985  0.102888    0.1503147  -0.12923983  0.20568377  0.18117306
  -0.14726229 -0.0967069   0.11618251 -0.14393644 -0.1362645  -0.03710948
   0.09887198 -0.0073533  -0.68454063  0.12269834 -0.14809498  0.20068403
   0.52657807  0.09035021 -0.12985089 -0.07717513 -0.16781327 -0.11246964
   0.13836877 -0.0840154   0.27322757  0.2212851  -0.06968373 -0.10311691
  -0.2144039   0.19803476 -0.07168333 -0.31952786 -0.1281247   0.08663984
  -0.64023799 -0.1870123   0.1257395   0.28103399  0.12920363 -0.45550311
  -0.20762785  0.02597465 -0.022702   -0.20784305  0.35498255 -0.020319
   0.09166592 -0.16794641  0.08166711  0.06167138  0.32107216  0.67518508
   0.11918754 -0.134194   -0.17925832 -0.13350587  0.19153792 -0.00593566
  -0.18139629 -0.01162786 -0.22530058 -0.12736222  0.18459514  0.15409431
  -0.25456336  0.10280468  0.05403788 -0.16506504  0.24204259 -0.11193448
   0.01573375  0.24775378  0.10059083 -0.32158002  0.2300927  -0.06867939
   0.08254759  0.15194565 -0.04183295  0.0977581   0.2728906   0.10022111
  -0.07312656  0.10802079 -0.27292517 -0.11279579 -0.11563531 -0.12158038
  -0.25173184  0.21363059 -0.20507152  0.14374413 -0.05504324  0.06672926
  -0.08007447  0.10416284 -0.18599865  0.0204465  -0.20013291  0.09112889
  -0.24535568 -0.54033345 -0.09568585 -0.17554054  0.19490029  0.23507191
   0.08250331  0.06193027  0.20079361 -0.08940008 -0.22217703  0.12452532
   0.0654559  -0.1059367   0.14848934 -0.07850686  0.52689838  0.2696529
   0.1314614   0.12059219  0.009146    0.17933209 -0.23190196  0.12403528
   0.17821351  0.31642854 -0.11853226  0.33770636  0.24605657 -0.09119248
   0.00713342 -0.13579428 -0.15529007  0.34657061  0.16555399  0.42164251
   0.27578562  0.06343733  0.20223881 -0.16981837  0.17264505 -0.18798231
   0.00685897  0.14510606  0.13526447 -0.28707251 -0.100795    0.01966244
  -0.03996423  0.24268857  0.29245919 -0.11903045  0.46334818  0.06392433
   0.45473343  0.24325688]]
After layer decoder_rnn_enc2dec_inittanh_0_output (1, 512) <class 'numpy.float32'> [[-0.0164224  -0.0700774   0.16418138  0.12753275 -0.00950159 -0.0464569
  -0.40231258 -0.09701769  0.12731189  0.11388193 -0.21368466 -0.13633291
  -0.16254798  0.19378567  0.11331452 -0.1374276  -0.11736567  0.21338397
   0.44092023 -0.17952795  0.13750285  0.16857158  0.07190109 -0.22496545
  -0.10654105 -0.15762149  0.14398965  0.10660443 -0.11978893 -0.17461725
  -0.26390409  0.14627993  0.29189056  0.09466685  0.1123002   0.22417468
   0.05272033 -0.0431439  -0.49777302 -0.12276279 -0.04787585  0.24606787
  -0.19430977 -0.575845   -0.09917605  0.16212657 -0.18776046 -0.46454579
   0.08380836 -0.0899347   0.0562161  -0.1507663   0.21956953 -0.05582794
   0.17062005 -0.00187354 -0.11085536  0.2840333  -0.07798707 -0.22677547
   0.01973436 -0.12394156  0.13198434 -0.34043071 -0.34645632 -0.17397234
  -0.15604645 -0.047977   -0.19582309  0.07304535 -0.58030558 -0.09932248
   0.23370187 -0.0977374   0.15452124  0.34939659 -0.0365964  -0.08595907
  -0.24777491 -0.06123603 -0.08933108 -0.08804789 -0.23199542  0.3841545
   0.18774419 -0.09824833 -0.08174663 -0.10602364 -0.17221823  0.24541636
  -0.16243182 -0.5450657  -0.3003194   0.08046905 -0.2701523  -0.16228966
   0.13036776 -0.11809035 -0.03393932 -0.15973823 -0.09468158 -0.10677058
   0.28916949 -0.03478767  0.13219814 -0.13267945 -0.1064225  -0.12791306
  -0.18853803  0.22479147  0.30994573  0.21761666 -0.52745974  0.00500563
   0.0261375   0.24368399 -0.1058615  -0.39869073 -0.14287712 -0.09787861
  -0.12774564 -0.44337609  0.15848532  0.07000019  0.15375876  0.21492782
   0.24162802  0.33806115 -0.0351115  -0.16928129 -0.12018009 -0.12995236
  -0.24319823  0.16817373  0.14792503  0.12328943 -0.12399124 -0.54382312
  -0.27106273 -0.05477779 -0.17976664  0.12834089  0.23891255  0.04880529
   0.12751141 -0.26604816  0.24906529  0.13828823  0.12832151  0.52783263
   0.3508054  -0.09736823  0.24751598  0.1986665  -0.03316898 -0.06861143
   0.08303201 -0.14934097 -0.0131835  -0.15446128  0.28015113  0.12545949
   0.11534487 -0.13505381 -0.20080023 -0.12645039  0.1248202  -0.07038663
  -0.12854367 -0.07421094  0.12294453  0.10267803 -0.05050846 -0.04431615
  -0.14810002 -0.20369157 -0.14903364 -0.09994501  0.18293351 -0.24748249
   0.12221541  0.13326719 -0.2292477  -0.20154753  0.17569342  0.25577047
  -0.24140479  0.18890962 -0.21051621  0.2234998   0.02832224 -0.14119031
  -0.07948162 -0.04856008  0.12199785 -0.169111   -0.08088825 -0.20933367
   0.21761478  0.53281069  0.16323875 -0.19698763 -0.07688644 -0.15426058
   0.144344   -0.10652328 -0.10900573 -0.25234747  0.22242352 -0.25605211
   0.09116449  0.17083611 -0.09372437  0.13799749 -0.21250604 -0.23402216
   0.23959953 -0.17155054  0.16128446  0.16924298  0.0349626  -0.19507641
   0.06811115 -0.1835392   0.09944332 -0.24960107 -0.14621091  0.23973881
  -0.08679771 -0.40756145  0.24620247 -0.40397561  0.13955407  0.10525005
   0.17475344 -0.0490948  -0.37526295  0.19384784  0.18884718 -0.12833531
   0.13668801 -0.07174353 -0.21462426 -0.13602176  0.22926652 -0.05790076
  -0.06975662  0.11591407  0.12032659 -0.0946715  -0.13661388  0.25288537
   0.19996062  0.0078653   0.14509465  0.07524285  0.10685605  0.27995226
  -0.13289312  0.24803504  0.09870429  0.19998311  0.1954885   0.10742822
  -0.05156446 -0.03064946  0.25974989  0.17501199  0.15905102  0.31475464
   0.17977895  0.17233475 -0.18567416 -0.16164     0.13073732 -0.21357502
   0.54343009  0.01917063  0.07457954  0.25449154  0.1512966   0.09927195
  -0.24178144 -0.06728542 -0.40422893 -0.02720465  0.05660798 -0.22650467
  -0.15711364  0.27632535  0.14254189  0.13435841  0.20497026 -0.19440067
   0.10515738  0.02448903  0.133993    0.25670162 -0.01933386 -0.13799573
  -0.30612037  0.03435104 -0.10552621  0.07816163 -0.04796447 -0.17521168
  -0.21322785  0.08309371  0.18507239  0.0463657  -0.21587199 -0.16353901
  -0.16601746 -0.1267698   0.20577353 -0.05999227 -0.06608821 -0.08856761
   0.28741282 -0.17930524  0.21966614  0.2711488   0.14172354  0.01157907
  -0.21225807  0.47615063  0.1377553  -0.09371551 -0.11517984 -0.13940941
   0.13811582 -0.18105945 -0.43289739 -0.18081704 -0.0983173  -0.08034876
  -0.03456092 -0.14487496 -0.12638503 -0.28958395 -0.20585006 -0.18378998
  -0.05655842  0.39127851 -0.03613738 -0.0987644   0.15886267 -0.19904499
   0.19877681  0.53258812  0.29994303  0.01021465 -0.15855317 -0.11168426
  -0.31819713  0.10252648  0.14919275 -0.12852505  0.20283149  0.17921649
  -0.14620693 -0.09640655  0.11566257 -0.14295061 -0.13542734 -0.03709246
   0.09855106 -0.00735316 -0.59446335  0.12208629 -0.14702173  0.19803262
   0.482761    0.09010517 -0.12912597 -0.07702227 -0.16625555 -0.11199781
   0.13749242 -0.08381828  0.26662552  0.21774258 -0.06957116 -0.10275298
  -0.21117789  0.19548592 -0.0715608  -0.30907995 -0.12742817  0.0864237
  -0.56506157 -0.18486221  0.125081    0.2738618   0.12848945 -0.42641205
  -0.20469485  0.02596881 -0.02269811 -0.20490102  0.3407869  -0.02031621
   0.09141003 -0.16638499  0.08148603  0.06159332  0.31047603  0.58838034
   0.11862636 -0.13339424 -0.17736262 -0.13271829  0.18922949 -0.00593559
  -0.17943254 -0.01162733 -0.22156431 -0.126678    0.18252662  0.15288612
  -0.24920347  0.10244403  0.05398534 -0.16358206  0.23742412 -0.11146933
   0.01573246  0.24280603  0.10025292 -0.31093487  0.22611631 -0.06857161
   0.0823606   0.15078701 -0.04180857  0.09744787  0.26631248  0.09988691
  -0.0729965   0.1076026  -0.26634461 -0.11231986 -0.11512265 -0.12098484
  -0.24654593  0.21043895 -0.20224436  0.14276221 -0.05498772  0.06663039
  -0.07990376  0.10378776 -0.18388303  0.02044365 -0.19750305  0.09087747
  -0.24054798 -0.49324033 -0.09539489 -0.17375943  0.19246939  0.2308356
   0.08231663  0.06185121  0.19813789 -0.08916267 -0.21859205  0.12388563
   0.06536258 -0.10554218  0.14740753 -0.07834598  0.48300663  0.26330182
   0.13070929  0.12001101  0.00914575  0.17743407 -0.22783236  0.12340309
   0.17635049  0.30627403 -0.11798025  0.32542819  0.24120821 -0.09094053
   0.0071333  -0.13496572 -0.15405372  0.33333066  0.16405788  0.39831325
   0.26900011  0.06335237  0.19952597 -0.16820456  0.17094995 -0.1857989
   0.00685887  0.14409614  0.13444552 -0.27943811 -0.10045504  0.01965991
  -0.03994296  0.23803359  0.28439668 -0.11847147  0.43280914  0.06383741
   0.42578211  0.23856965]]
After layer decoder_rnn_enc2decinit_1_output (1, 512) <class 'numpy.float32'> [[ -7.61502460e-02  -1.46312695e-02   6.90493658e-02  -9.18467566e-02
    3.15082043e-01   7.60280713e-02  -5.55795208e-02   4.83760908e-02
    8.24510455e-02   1.44724786e-01   1.62944913e-01  -4.95084412e-02
   -1.52849570e-01   5.18651605e-02  -9.71051678e-02  -6.45403564e-02
   -1.81318045e-01   2.06835181e-01   5.80765545e-01  -8.39336514e-02
    4.99030203e-02   1.50082335e-01   6.47507086e-02   3.59183215e-02
   -3.98593806e-02  -4.57745120e-02   7.31320977e-02   1.88599259e-01
   -1.02952532e-01  -4.60375063e-02  -4.01140712e-02   9.04168636e-02
    1.96908310e-01  -4.68717739e-02   3.66279960e-01   3.36336404e-01
   -2.01607764e-01  -3.85590047e-02   3.66325289e-01  -3.74256194e-01
    2.37785399e-01   2.28311308e-02  -3.04009140e-01  -7.79669136e-02
   -1.77279547e-01   1.57156065e-01  -2.40039304e-01  -5.47073931e-02
   -3.56700383e-02  -2.11038664e-02   4.19733599e-02  -8.43675286e-02
   -4.38643157e-01  -1.49295002e-01   1.21325441e-01  -9.48539972e-02
   -2.12863624e-01   1.77352741e-01  -8.00838843e-02   2.27144919e-02
   -7.03684241e-02  -2.36103055e-03   7.28491098e-02   1.06761903e-01
    4.46284004e-03   8.72327015e-03  -9.05366708e-03   4.82526496e-02
   -2.41498977e-01   1.44861490e-01  -5.15481867e-02   5.17445132e-02
   -7.91108087e-02  -7.70777091e-02   5.37274852e-02   1.42916720e-02
    2.61860073e-01  -6.19306182e-03  -1.16215795e-01  -9.08830166e-02
   -5.38659990e-02  -8.65101442e-02  -1.25263423e-01  -9.45336670e-02
   -1.75362974e-02   1.13955671e-02  -2.11170778e-01  -2.75970668e-01
   -1.21720776e-01   3.72096449e-01  -1.74988329e-01   1.55743629e-01
    1.19090505e-01   1.60394430e-01   2.09953174e-01  -1.24161281e-01
   -1.38261706e-01  -3.53277326e-01  -5.77016324e-02  -1.64779410e-01
   -2.00570017e-01  -1.35946676e-01  -6.06761992e-01   1.39995396e-01
    1.96249023e-01  -6.31132871e-02  -1.53471693e-01  -2.35190779e-01
   -4.28465605e-02   6.13307953e-02   1.66644767e-01  -3.54467243e-01
    5.82523108e-01   5.79387043e-03   7.60889128e-02   1.71970189e-01
   -1.59293279e-01  -4.60159257e-02  -2.94556320e-01   1.45437419e-01
   -4.05271500e-02  -6.71596080e-02   1.97599217e-01   1.02492973e-01
    1.91787198e-01   5.51849976e-02   5.60124964e-02   1.82405293e-01
   -3.34302753e-01  -1.07773002e-02  -2.50568986e-02  -1.93686411e-02
   -3.99572328e-02   1.17668808e-01   1.36261821e-01   1.64937630e-01
   -1.48007020e-01  -4.32809681e-01  -4.33556065e-02  -3.39737050e-02
   -2.16690063e-01   2.77879864e-01  -3.53126109e-01  -8.52069557e-02
    2.47817680e-01  -1.27219781e-01   1.53426751e-02   1.60801306e-01
    2.49100477e-01   1.25016317e-01   2.36942559e-01  -1.95970520e-01
    1.74646303e-01   6.74210340e-02  -1.95910782e-01   1.11144185e-01
    6.39971793e-02  -2.53038228e-01  -4.03544195e-02  -6.26394600e-02
    9.54426005e-02   2.80629635e-01  -7.70461336e-02  -8.08205381e-02
   -6.40126705e-01   7.81214610e-02   1.29445851e-01  -1.02513328e-01
   -1.18090503e-01  -7.24479929e-02  -2.60869324e-01   1.64199442e-01
    1.03564121e-01   9.40347090e-02  -5.66999875e-02  -1.81196705e-02
   -1.89908653e-01  -9.68127847e-02   1.73614129e-01  -3.14055771e-01
    1.21292971e-01   4.40118872e-02  -1.64668620e-01  -8.13557580e-02
    2.99031943e-01   2.05674216e-01  -1.34696543e-01   1.04440562e-01
   -8.69585499e-02   1.54518988e-02   3.17724757e-02  -1.69057399e-01
    8.72102752e-02  -1.40695393e-01   1.67625576e-01  -2.21882179e-01
   -1.00319773e-01  -2.29640082e-01   7.94447586e-02   7.73874894e-02
    3.82086635e-03  -3.05163860e-01   6.10835291e-03  -1.98609501e-01
    1.58988267e-01  -3.07674766e-01   1.26278251e-01  -2.18776271e-01
    1.48696050e-01  -1.01412870e-01   4.63185422e-02  -8.20409283e-02
   -1.75527222e-02  -4.91752103e-02  -1.16073497e-01  -1.14858471e-01
    2.55388290e-01  -5.04163086e-01   7.87536725e-02   1.56601757e-01
    2.14193434e-01  -9.97677892e-02   1.71025321e-01  -6.71362728e-02
    4.28903282e-01  -3.12259346e-01   2.82079726e-02   1.70776039e-01
   -6.73227012e-02  -2.19622284e-01   1.79403335e-01  -5.92628896e-01
    7.19443187e-02   3.41836363e-01   2.86338665e-02  -6.52934238e-02
    1.73594095e-02   1.26006734e-02   1.02102928e-01  -8.64890590e-03
    2.86529541e-01  -5.07582538e-02  -2.84218460e-01  -2.13021636e-01
    1.04469061e-01   1.62183583e-01  -8.55735391e-02   1.32140994e-01
    6.18503988e-02  -1.39915705e-01  -2.27120072e-01   2.16188788e-01
    7.41456300e-02  -4.52429466e-02  -1.34365514e-01   3.06663185e-01
   -3.66799563e-01  -4.73340452e-02  -4.29943949e-02  -2.70276874e-01
    6.71285242e-02   3.63825947e-01   1.63965106e-01   9.22378600e-02
    4.00177576e-03  -1.28093839e-01   3.49489190e-02   1.77943021e-01
   -5.00053316e-02  -1.45078152e-01   2.35530972e-01   1.28618963e-02
   -2.98495829e-01  -5.42721637e-02  -2.10806906e-01  -9.15973857e-02
    6.38078526e-03  -9.72261131e-02  -7.85584562e-03   2.59792209e-01
    1.93516150e-01  -1.91992715e-01   3.35338339e-02  -2.65130997e-01
   -4.66315374e-02   2.02160001e-01  -1.64134443e-01  -3.91690508e-02
   -1.01931483e-01   3.01316231e-01   1.71852231e-01   3.45689505e-01
   -2.05351204e-01  -6.56841695e-02   1.83232069e-01  -1.59187973e-01
    1.13193281e-01   2.56484803e-02  -5.97464666e-02  -1.53397530e-01
   -2.47265711e-01   7.56244808e-02  -1.58830136e-01  -2.85989404e-01
   -5.98614477e-02  -1.84767291e-01   2.78682970e-02   1.87988374e-02
    3.32953893e-02   8.81575644e-02  -1.14843979e-01   1.17245518e-01
   -1.02229171e-01  -4.83321920e-02   4.55718786e-02   1.34352982e-01
   -6.03348762e-02  -7.76319504e-02   1.04210511e-01  -7.20786974e-02
    1.68608516e-01   2.67431915e-01   1.60500288e-01  -2.96882391e-02
   -1.92933902e-01  -3.86776268e-01   3.10974300e-01   3.18173677e-01
   -2.30640456e-01  -7.08204955e-02   2.20898584e-01  -2.73773223e-02
    2.58071348e-04  -1.53899997e-01  -3.51610035e-02  -1.02833457e-01
   -5.00390120e-02  -1.03516690e-01  -1.06037915e-01  -2.96590745e-01
   -8.85885581e-02  -1.93097934e-01  -2.99918093e-03   3.93952131e-01
   -2.59819955e-01  -6.46852851e-02   9.90516916e-02   4.61318903e-02
    1.39904991e-01   5.86832911e-02  -2.83306211e-01  -7.20953196e-02
   -5.64963445e-02   3.33383679e-02   6.36136830e-01   7.44732767e-02
    7.14331567e-02  -6.06957339e-02   2.38959655e-01   1.53346688e-01
    3.22158754e-01  -7.88791105e-02  -1.78057283e-01  -6.93949461e-02
   -2.10378673e-02  -1.19142652e-01   2.49729916e-01  -9.35814008e-02
    4.69561070e-01   9.80790704e-02  -1.03438146e-01   3.37250382e-02
    6.24510273e-02   2.08364904e-01  -1.08824372e-01  -1.71681911e-01
   -4.27821159e-01  -2.36499697e-01   2.82239765e-02  -9.30565223e-02
    1.23684466e-01   6.12136535e-02  -1.25478953e-01  -2.51117945e-01
   -3.00703533e-02   3.06877822e-01  -3.05206925e-01  -6.27996176e-02
   -1.10312432e-01  -8.16216171e-02  -3.34946662e-01   1.31013215e-01
    1.16906762e-01   5.44094592e-02  -4.00900468e-02  -2.65223950e-01
   -5.81121258e-02   2.15661123e-01  -2.25230038e-01  -1.27009273e-01
    2.73950636e-01  -1.59310654e-01  -2.20814329e-02  -1.34924445e-02
   -1.20172717e-01   1.24091506e-01  -2.01615915e-01  -4.18383688e-01
    4.86648791e-02   1.18720755e-01  -1.09729990e-01  -1.29118592e-01
    1.71305969e-01   9.79568288e-02   1.26884148e-01   1.45698011e-01
   -6.46899417e-02  -2.31600612e-01   1.80124596e-01   7.23575056e-02
   -3.92042100e-04   2.18615651e-01   1.19997419e-01  -8.64719599e-02
    9.23972651e-02   2.52808452e-01   1.92457065e-01   2.87626058e-01
    7.70559981e-02   1.37944549e-01   2.71787494e-01  -1.45367309e-01
   -1.34344921e-01  -1.31334923e-03   2.80869484e-01   2.26493664e-02
    2.15775847e-01   3.80853564e-03  -2.58139640e-01   1.04218699e-01
   -1.55343309e-01  -9.28766951e-02   3.82538848e-02  -1.98842451e-01
   -3.26664150e-01  -4.75880280e-02  -2.03363016e-01   1.93529442e-01
   -9.40553322e-02  -2.20068052e-01  -1.83702856e-01   3.26921567e-02
    2.68784370e-02   9.62283090e-03  -2.12184891e-01   3.46942921e-03
   -1.05014883e-01   8.53002369e-02   1.13685280e-01  -1.13285519e-01
    1.39968097e-01   1.74046829e-01  -1.05008423e-01   1.56496480e-01
    1.20123886e-01  -3.38253006e-03  -5.08905500e-02   5.94425686e-02
    5.79777993e-02  -5.42598441e-02   1.13685519e-01  -2.64302909e-01
    4.39678967e-01   5.35402894e-01   3.49167325e-02  -8.30820426e-02
    7.94864148e-02  -2.10824534e-02  -4.34140265e-02   1.64306045e-01
   -7.71296397e-03   3.56710196e-01   1.44491836e-01   1.15797959e-01
    2.26025611e-01  -5.18434793e-02  -7.34931454e-02  -2.36928210e-01
   -5.15218219e-03  -5.59851229e-02   1.51381180e-01   5.01462147e-02
   -6.25667498e-02   8.41169506e-02   6.01499639e-02  -5.02457023e-02
    1.74140379e-01  -7.05733076e-02  -7.52665251e-02  -2.09807605e-03
    3.06365609e-01   3.15693207e-02  -1.91962287e-01   3.71966548e-02
   -1.00337058e-01   8.64099562e-02   2.66562253e-01  -2.03138694e-01
   -2.53223032e-02   4.86211926e-02   2.35736668e-01   1.27545327e-01]]
After layer decoder_rnn_enc2dec_inittanh_1_output (1, 512) <class 'numpy.float32'> [[ -7.60033950e-02  -1.46302255e-02   6.89398348e-02  -9.15893614e-02
    3.05053324e-01   7.58819208e-02  -5.55223636e-02   4.83383909e-02
    8.22647139e-02   1.43722758e-01   1.61517948e-01  -4.94680330e-02
   -1.51670247e-01   5.18187061e-02  -9.68011022e-02  -6.44508898e-02
   -1.79356813e-01   2.03935280e-01   5.23221612e-01  -8.37371051e-02
    4.98616360e-02   1.48965552e-01   6.46603703e-02   3.59028839e-02
   -3.98382843e-02  -4.57425676e-02   7.30020031e-02   1.86394483e-01
   -1.02590330e-01  -4.60050106e-02  -4.00925688e-02   9.01712775e-02
    1.94402277e-01  -4.68374789e-02   3.50733548e-01   3.24202776e-01
   -1.98919967e-01  -3.85399051e-02   3.50773305e-01  -3.57708931e-01
    2.33402878e-01   2.28271652e-02  -2.94977218e-01  -7.78093189e-02
   -1.75445423e-01   1.55874908e-01  -2.35532880e-01  -5.46528809e-02
   -3.56549174e-02  -2.11007334e-02   4.19487283e-02  -8.41679275e-02
   -4.12519127e-01  -1.48195595e-01   1.20733634e-01  -9.45705473e-02
   -2.09705830e-01   1.75516367e-01  -7.99131170e-02   2.27105860e-02
   -7.02525079e-02  -2.36102613e-03   7.27205127e-02   1.06358118e-01
    4.46281023e-03   8.72304849e-03  -9.05341934e-03   4.82152365e-02
   -2.36911088e-01   1.43856630e-01  -5.15025780e-02   5.16983829e-02
   -7.89461806e-02  -7.69254342e-02   5.36758490e-02   1.42906988e-02
    2.56034493e-01  -6.19298266e-03  -1.15695402e-01  -9.06336233e-02
   -5.38139604e-02  -8.62949789e-02  -1.24612346e-01  -9.42530707e-02
   -1.75345000e-02   1.13950735e-02  -2.08086863e-01  -2.69171745e-01
   -1.21123187e-01   3.55824083e-01  -1.73223838e-01   1.54496491e-01
    1.18530683e-01   1.59032986e-01   2.06921682e-01  -1.23527169e-01
   -1.37387380e-01  -3.39278817e-01  -5.76376803e-02  -1.63304061e-01
   -1.97923079e-01  -1.35115325e-01  -5.41843772e-01   1.39087945e-01
    1.93767816e-01  -6.30296245e-02  -1.52278006e-01  -2.30948120e-01
   -4.28203605e-02   6.12540133e-02   1.65119112e-01  -3.40331346e-01
    5.24496853e-01   5.79380570e-03   7.59424120e-02   1.70294747e-01
   -1.57959506e-01  -4.59834747e-02  -2.86323041e-01   1.44420594e-01
   -4.05049771e-02  -6.70588166e-02   1.95066974e-01   1.02135591e-01
    1.89469829e-01   5.51290475e-02   5.59539907e-02   1.80408880e-01
   -3.22381675e-01  -1.07768830e-02  -2.50516552e-02  -1.93662196e-02
   -3.99359800e-02   1.17128722e-01   1.35424703e-01   1.63458064e-01
   -1.46935657e-01  -4.07666743e-01  -4.33284603e-02  -3.39606404e-02
   -2.13361040e-01   2.70941705e-01  -3.39145005e-01  -8.50013494e-02
    2.42866158e-01  -1.26537859e-01   1.53414709e-02   1.59429550e-01
    2.44072914e-01   1.24369070e-01   2.32605800e-01  -1.93499759e-01
    1.72892064e-01   6.73190653e-02  -1.93442255e-01   1.10688783e-01
    6.39099553e-02  -2.47772500e-01  -4.03325297e-02  -6.25576600e-02
    9.51538533e-02   2.73487717e-01  -7.68940449e-02  -8.06450248e-02
   -5.64985812e-01   7.79629275e-02   1.28727660e-01  -1.02155730e-01
   -1.17544614e-01  -7.23215044e-02  -2.55108446e-01   1.62739500e-01
    1.03195444e-01   9.37585235e-02  -5.66393062e-02  -1.81176886e-02
   -1.87658086e-01  -9.65114534e-02   1.71890557e-01  -3.04122269e-01
    1.20701633e-01   4.39834930e-02  -1.63196221e-01  -8.11767429e-02
    2.90426463e-01   2.02822328e-01  -1.33887812e-01   1.04062475e-01
   -8.67400244e-02   1.54506695e-02   3.17617878e-02  -1.67465031e-01
    8.69898498e-02  -1.39774323e-01   1.66073024e-01  -2.18311280e-01
   -9.99845862e-02  -2.25686789e-01   7.92780444e-02   7.72333741e-02
    3.82084772e-03  -2.96031088e-01   6.10827701e-03  -1.96038634e-01
    1.57662079e-01  -2.98320264e-01   1.25611290e-01  -2.15351388e-01
    1.47609740e-01  -1.01066634e-01   4.62854467e-02  -8.18573609e-02
   -1.75509192e-02  -4.91356105e-02  -1.15555003e-01  -1.14356034e-01
    2.49977008e-01  -4.65384901e-01   7.85912648e-02   1.55334026e-01
    2.10976809e-01  -9.94380862e-02   1.69377133e-01  -6.70355856e-02
    4.04404372e-01  -3.02491099e-01   2.82004941e-02   1.69134989e-01
   -6.72211796e-02  -2.16158032e-01   1.77503064e-01  -5.31783700e-01
    7.18204454e-02   3.29115838e-01   2.86260433e-02  -6.52007982e-02
    1.73576660e-02   1.26000065e-02   1.01749599e-01  -8.64868984e-03
    2.78937489e-01  -5.07147089e-02  -2.76804835e-01  -2.09856898e-01
    1.04090668e-01   1.60776392e-01  -8.53652731e-02   1.31377220e-01
    6.17716499e-02  -1.39009789e-01  -2.23293781e-01   2.12882534e-01
    7.40100592e-02  -4.52121012e-02  -1.33562699e-01   2.97398418e-01
   -3.51189166e-01  -4.72987257e-02  -4.29679230e-02  -2.63882428e-01
    6.70278743e-02   3.48579556e-01   1.62511364e-01   9.19771716e-02
    4.00175434e-03  -1.27397820e-01   3.49346958e-02   1.76088408e-01
   -4.99636941e-02  -1.44068807e-01   2.31270149e-01   1.28611876e-02
   -2.89935470e-01  -5.42189404e-02  -2.07738712e-01  -9.13420767e-02
    6.38069864e-03  -9.69209149e-02  -7.85568357e-03   2.54101157e-01
    1.91136166e-01  -1.89667970e-01   3.35212685e-02  -2.59088427e-01
   -4.65977676e-02   1.99450284e-01  -1.62676230e-01  -3.91490310e-02
   -1.01579919e-01   2.92516679e-01   1.70180202e-01   3.32547247e-01
   -2.02512592e-01  -6.55898675e-02   1.81208640e-01  -1.57856822e-01
    1.12712309e-01   2.56428570e-02  -5.96754774e-02  -1.52205572e-01
   -2.42346674e-01   7.54806474e-02  -1.57507882e-01  -2.78439283e-01
   -5.97900487e-02  -1.82693034e-01   2.78610848e-02   1.87966228e-02
    3.32830921e-02   8.79298970e-02  -1.14341736e-01   1.16711222e-01
   -1.01874530e-01  -4.82945926e-02   4.55403589e-02   1.33550391e-01
   -6.02617711e-02  -7.74763748e-02   1.03834912e-01  -7.19541311e-02
    1.67028710e-01   2.61233598e-01   1.59136161e-01  -2.96795201e-02
   -1.90575138e-01  -3.68577749e-01   3.01323175e-01   3.07854593e-01
   -2.26636007e-01  -7.07023293e-02   2.17374355e-01  -2.73704845e-02
    2.58071348e-04  -1.52696356e-01  -3.51465195e-02  -1.02472506e-01
   -4.99972887e-02  -1.03148520e-01  -1.05642267e-01  -2.88189590e-01
   -8.83575380e-02  -1.90733194e-01  -2.99917185e-03   3.74762326e-01
   -2.54127115e-01  -6.45952150e-02   9.87290218e-02   4.60991934e-02
    1.38999283e-01   5.86160198e-02  -2.75962263e-01  -7.19706714e-02
   -5.64363115e-02   3.33260223e-02   5.62263489e-01   7.43359029e-02
    7.13119060e-02  -6.06213100e-02   2.34512866e-01   1.52155906e-01
    3.11457574e-01  -7.87159279e-02  -1.76199123e-01  -6.92837685e-02
   -2.10347641e-02  -1.18582100e-01   2.44664758e-01  -9.33091789e-02
    4.37844604e-01   9.77657884e-02  -1.03070810e-01   3.37122567e-02
    6.23699650e-02   2.05400914e-01  -1.08396806e-01  -1.70014814e-01
   -4.03498828e-01  -2.32186854e-01   2.82164849e-02  -9.27888453e-02
    1.23057604e-01   6.11373112e-02  -1.24824524e-01  -2.45969251e-01
   -3.00612934e-02   2.97594070e-01  -2.96070397e-01  -6.27171919e-02
   -1.09867148e-01  -8.14408436e-02  -3.22958529e-01   1.30268738e-01
    1.16377063e-01   5.43558337e-02  -4.00685817e-02  -2.59175152e-01
   -5.80467992e-02   2.12378725e-01  -2.21497238e-01  -1.26330718e-01
    2.67297059e-01  -1.57976434e-01  -2.20778454e-02  -1.34916259e-02
   -1.19597554e-01   1.23458460e-01  -1.98927790e-01  -3.95567924e-01
    4.86264974e-02   1.18166111e-01  -1.09291695e-01  -1.28405809e-01
    1.69649720e-01   9.76447165e-02   1.26207575e-01   1.44675747e-01
   -6.45998567e-02  -2.27546647e-01   1.78201512e-01   7.22314939e-02
   -3.92042071e-04   2.15198219e-01   1.19424760e-01  -8.62570778e-02
    9.21352208e-02   2.47556821e-01   1.90115571e-01   2.79948354e-01
    7.69038498e-02   1.37076199e-01   2.65287310e-01  -1.44351944e-01
   -1.33542478e-01  -1.31334853e-03   2.73709595e-01   2.26454940e-02
    2.12488279e-01   3.80851724e-03  -2.52554655e-01   1.03843011e-01
   -1.54105708e-01  -9.26105604e-02   3.82352360e-02  -1.96262613e-01
   -3.15520167e-01  -4.75521386e-02  -2.00605169e-01   1.91148981e-01
   -9.37789604e-02  -2.16582924e-01  -1.81663930e-01   3.26805152e-02
    2.68719662e-02   9.62253381e-03  -2.09056854e-01   3.46941524e-03
   -1.04630545e-01   8.50939527e-02   1.13198034e-01  -1.12803377e-01
    1.39061168e-01   1.72310442e-01  -1.04624152e-01   1.55231282e-01
    1.19549416e-01  -3.38251726e-03  -5.08466624e-02   5.93726560e-02
    5.79129234e-02  -5.42066582e-02   1.13198265e-01  -2.58315772e-01
    4.13378328e-01   4.89500225e-01   3.49025503e-02  -8.28914121e-02
    7.93194398e-02  -2.10793298e-02  -4.33867723e-02   1.62843287e-01
   -7.71281123e-03   3.42312992e-01   1.43494606e-01   1.15283139e-01
    2.22253636e-01  -5.17970808e-02  -7.33611137e-02  -2.32592225e-01
   -5.15213655e-03  -5.59267029e-02   1.50235325e-01   5.01042232e-02
   -6.24852367e-02   8.39191154e-02   6.00775294e-02  -5.02034612e-02
    1.72401220e-01  -7.04563782e-02  -7.51247182e-02  -2.09807302e-03
    2.97127157e-01   3.15588377e-02  -1.89638630e-01   3.71795110e-02
   -1.00001693e-01   8.61955360e-02   2.60423124e-01  -2.00389862e-01
   -2.53168922e-02   4.85829152e-02   2.31464833e-01   1.26858175e-01]]
After layer target_embed_embed_0 (20, 256) <class 'numpy.float32'> [[ 0.0609436  -0.04937744 -0.03683472 ...,  0.06219482 -0.08508301
  -0.07885742]
 [ 0.0609436  -0.04937744 -0.03683472 ...,  0.06219482 -0.08508301
  -0.07885742]
 [ 0.0609436  -0.04937744 -0.03683472 ...,  0.06219482 -0.08508301
  -0.07885742]
 ...,
 [ 0.0609436  -0.04937744 -0.03683472 ...,  0.06219482 -0.08508301
  -0.07885742]
 [ 0.0609436  -0.04937744 -0.03683472 ...,  0.06219482 -0.08508301
  -0.07885742]
 [ 0.0609436  -0.04937744 -0.03683472 ...,  0.06219482 -0.08508301
  -0.07885742]]
After layer decoder_rnn_concat_target_context_t0_output (20, 768) <class 'numpy.float32'> [[ 0.0609436  -0.04937744 -0.03683472 ...,  0.          0.          0.        ]
 [ 0.0609436  -0.04937744 -0.03683472 ...,  0.          0.          0.        ]
 [ 0.0609436  -0.04937744 -0.03683472 ...,  0.          0.          0.        ]
 ...,
 [ 0.0609436  -0.04937744 -0.03683472 ...,  0.          0.          0.        ]
 [ 0.0609436  -0.04937744 -0.03683472 ...,  0.          0.          0.        ]
 [ 0.0609436  -0.04937744 -0.03683472 ...,  0.          0.          0.        ]]
After layer decoder_rnn_l0_t0_i2h_output (20, 2048) <class 'numpy.float32'> [[ 0.92035228 -0.1579562   0.1166315  ...,  0.56470966  0.84454948
   0.2729246 ]
 [ 0.92035228 -0.1579562   0.1166315  ...,  0.56470966  0.84454948
   0.2729246 ]
 [ 0.92035228 -0.1579562   0.1166315  ...,  0.56470966  0.84454948
   0.2729246 ]
 ...,
 [ 0.92035228 -0.1579562   0.1166315  ...,  0.56470966  0.84454948
   0.2729246 ]
 [ 0.92035228 -0.1579562   0.1166315  ...,  0.56470966  0.84454948
   0.2729246 ]
 [ 0.92035228 -0.1579562   0.1166315  ...,  0.56470966  0.84454948
   0.2729246 ]]
After layer decoder_rnn_l0_t0_h2h_output (20, 2048) <class 'numpy.float32'> [[ 0.5370332  -0.54047465  0.07322113 ...,  0.28790614  0.30881998
   0.58638823]
 [ 0.5370332  -0.54047465  0.07322113 ...,  0.28790614  0.30881998
   0.58638823]
 [ 0.5370332  -0.54047465  0.07322113 ...,  0.28790614  0.30881998
   0.58638823]
 ...,
 [ 0.5370332  -0.54047465  0.07322113 ...,  0.28790614  0.30881998
   0.58638823]
 [ 0.5370332  -0.54047465  0.07322113 ...,  0.28790614  0.30881998
   0.58638823]
 [ 0.5370332  -0.54047465  0.07322113 ...,  0.28790614  0.30881998
   0.58638823]]
After layer _plus1046_0 (20, 2048) <class 'numpy.float32'> [[ 1.45738554 -0.69843084  0.18985263 ...,  0.85261583  1.15336943
   0.85931283]
 [ 1.45738554 -0.69843084  0.18985263 ...,  0.85261583  1.15336943
   0.85931283]
 [ 1.45738554 -0.69843084  0.18985263 ...,  0.85261583  1.15336943
   0.85931283]
 ...,
 [ 1.45738554 -0.69843084  0.18985263 ...,  0.85261583  1.15336943
   0.85931283]
 [ 1.45738554 -0.69843084  0.18985263 ...,  0.85261583  1.15336943
   0.85931283]
 [ 1.45738554 -0.69843084  0.18985263 ...,  0.85261583  1.15336943
   0.85931283]]
After layer decoder_rnn_l0_t0_slice_output0 (20, 512) <class 'numpy.float32'> [[ 1.45738554 -0.69843084  0.18985263 ..., -0.07039329  1.5423243
   0.29149902]
 [ 1.45738554 -0.69843084  0.18985263 ..., -0.07039329  1.5423243
   0.29149902]
 [ 1.45738554 -0.69843084  0.18985263 ..., -0.07039329  1.5423243
   0.29149902]
 ...,
 [ 1.45738554 -0.69843084  0.18985263 ..., -0.07039329  1.5423243
   0.29149902]
 [ 1.45738554 -0.69843084  0.18985263 ..., -0.07039329  1.5423243
   0.29149902]
 [ 1.45738554 -0.69843084  0.18985263 ..., -0.07039329  1.5423243
   0.29149902]]
After layer decoder_rnn_l0_t0_slice_output1 (20, 512) <class 'numpy.float32'> [[ 1.55378652 -0.91984248  0.62290227 ...,  1.09731567  0.03192897
   1.09701252]
 [ 1.55378652 -0.91984248  0.62290227 ...,  1.09731567  0.03192897
   1.09701252]
 [ 1.55378652 -0.91984248  0.62290227 ...,  1.09731567  0.03192897
   1.09701252]
 ...,
 [ 1.55378652 -0.91984248  0.62290227 ...,  1.09731567  0.03192897
   1.09701252]
 [ 1.55378652 -0.91984248  0.62290227 ...,  1.09731567  0.03192897
   1.09701252]
 [ 1.55378652 -0.91984248  0.62290227 ...,  1.09731567  0.03192897
   1.09701252]]
After layer decoder_rnn_l0_t0_slice_output2 (20, 512) <class 'numpy.float32'> [[-1.69351816 -0.45266998  0.32284659 ...,  1.50102222  1.33193564
   0.6540004 ]
 [-1.69351816 -0.45266998  0.32284659 ...,  1.50102222  1.33193564
   0.6540004 ]
 [-1.69351816 -0.45266998  0.32284659 ...,  1.50102222  1.33193564
   0.6540004 ]
 ...,
 [-1.69351816 -0.45266998  0.32284659 ...,  1.50102222  1.33193564
   0.6540004 ]
 [-1.69351816 -0.45266998  0.32284659 ...,  1.50102222  1.33193564
   0.6540004 ]
 [-1.69351816 -0.45266998  0.32284659 ...,  1.50102222  1.33193564
   0.6540004 ]]
After layer decoder_rnn_l0_t0_slice_output3 (20, 512) <class 'numpy.float32'> [[ 2.3511374  -1.17084527 -0.071518   ...,  0.85261583  1.15336943
   0.85931283]
 [ 2.3511374  -1.17084527 -0.071518   ...,  0.85261583  1.15336943
   0.85931283]
 [ 2.3511374  -1.17084527 -0.071518   ...,  0.85261583  1.15336943
   0.85931283]
 ...,
 [ 2.3511374  -1.17084527 -0.071518   ...,  0.85261583  1.15336943
   0.85931283]
 [ 2.3511374  -1.17084527 -0.071518   ...,  0.85261583  1.15336943
   0.85931283]
 [ 2.3511374  -1.17084527 -0.071518   ...,  0.85261583  1.15336943
   0.85931283]]
After layer decoder_rnn_l0_t0_o_output (20, 512) <class 'numpy.float32'> [[ 0.9130246   0.23670223  0.48212811 ...,  0.70111555  0.76012582
   0.70251703]
 [ 0.9130246   0.23670223  0.48212811 ...,  0.70111555  0.76012582
   0.70251703]
 [ 0.9130246   0.23670223  0.48212811 ...,  0.70111555  0.76012582
   0.70251703]
 ...,
 [ 0.9130246   0.23670223  0.48212811 ...,  0.70111555  0.76012582
   0.70251703]
 [ 0.9130246   0.23670223  0.48212811 ...,  0.70111555  0.76012582
   0.70251703]
 [ 0.9130246   0.23670223  0.48212811 ...,  0.70111555  0.76012582
   0.70251703]]
After layer decoder_rnn_l0_t0_f_output (20, 512) <class 'numpy.float32'> [[ 0.82545996  0.28498998  0.65087837 ...,  0.74975687  0.50798154
   0.74969989]
 [ 0.82545996  0.28498998  0.65087837 ...,  0.74975687  0.50798154
   0.74969989]
 [ 0.82545996  0.28498998  0.65087837 ...,  0.74975687  0.50798154
   0.74969989]
 ...,
 [ 0.82545996  0.28498998  0.65087837 ...,  0.74975687  0.50798154
   0.74969989]
 [ 0.82545996  0.28498998  0.65087837 ...,  0.74975687  0.50798154
   0.74969989]
 [ 0.82545996  0.28498998  0.65087837 ...,  0.74975687  0.50798154
   0.74969989]]
After layer _mul2092_0 (20, 512) <class 'numpy.float32'> [[-0.06273776 -0.00416947  0.04487145 ...,  0.03642537  0.11757986
   0.09510556]
 [-0.06273776 -0.00416947  0.04487145 ...,  0.03642537  0.11757986
   0.09510556]
 [-0.06273776 -0.00416947  0.04487145 ...,  0.03642537  0.11757986
   0.09510556]
 ...,
 [-0.06273776 -0.00416947  0.04487145 ...,  0.03642537  0.11757986
   0.09510556]
 [-0.06273776 -0.00416947  0.04487145 ...,  0.03642537  0.11757986
   0.09510556]
 [-0.06273776 -0.00416947  0.04487145 ...,  0.03642537  0.11757986
   0.09510556]]
After layer decoder_rnn_l0_t0_i_output (20, 512) <class 'numpy.float32'> [[ 0.81113249  0.3321602   0.54732114 ...,  0.482409    0.82380235
   0.57236308]
 [ 0.81113249  0.3321602   0.54732114 ...,  0.482409    0.82380235
   0.57236308]
 [ 0.81113249  0.3321602   0.54732114 ...,  0.482409    0.82380235
   0.57236308]
 ...,
 [ 0.81113249  0.3321602   0.54732114 ...,  0.482409    0.82380235
   0.57236308]
 [ 0.81113249  0.3321602   0.54732114 ...,  0.482409    0.82380235
   0.57236308]
 [ 0.81113249  0.3321602   0.54732114 ...,  0.482409    0.82380235
   0.57236308]]
After layer decoder_rnn_l0_t0_c_output (20, 512) <class 'numpy.float32'> [[-0.93459386 -0.42409128  0.31207854 ...,  0.9053328   0.86972165
   0.57435679]
 [-0.93459386 -0.42409128  0.31207854 ...,  0.9053328   0.86972165
   0.57435679]
 [-0.93459386 -0.42409128  0.31207854 ...,  0.9053328   0.86972165
   0.57435679]
 ...,
 [-0.93459386 -0.42409128  0.31207854 ...,  0.9053328   0.86972165
   0.57435679]
 [-0.93459386 -0.42409128  0.31207854 ...,  0.9053328   0.86972165
   0.57435679]
 [-0.93459386 -0.42409128  0.31207854 ...,  0.9053328   0.86972165
   0.57435679]]
After layer _mul2093_0 (20, 512) <class 'numpy.float32'> [[-0.75807947 -0.14086625  0.17080718 ...,  0.4367407   0.71647877
   0.32874063]
 [-0.75807947 -0.14086625  0.17080718 ...,  0.4367407   0.71647877
   0.32874063]
 [-0.75807947 -0.14086625  0.17080718 ...,  0.4367407   0.71647877
   0.32874063]
 ...,
 [-0.75807947 -0.14086625  0.17080718 ...,  0.4367407   0.71647877
   0.32874063]
 [-0.75807947 -0.14086625  0.17080718 ...,  0.4367407   0.71647877
   0.32874063]
 [-0.75807947 -0.14086625  0.17080718 ...,  0.4367407   0.71647877
   0.32874063]]
After layer decoder_rnn_l0_t0_state_0 (20, 512) <class 'numpy.float32'> [[-0.82081723 -0.14503571  0.21567863 ...,  0.47316608  0.83405864
   0.42384619]
 [-0.82081723 -0.14503571  0.21567863 ...,  0.47316608  0.83405864
   0.42384619]
 [-0.82081723 -0.14503571  0.21567863 ...,  0.47316608  0.83405864
   0.42384619]
 ...,
 [-0.82081723 -0.14503571  0.21567863 ...,  0.47316608  0.83405864
   0.42384619]
 [-0.82081723 -0.14503571  0.21567863 ...,  0.47316608  0.83405864
   0.42384619]
 [-0.82081723 -0.14503571  0.21567863 ...,  0.47316608  0.83405864
   0.42384619]]
After layer activation1046_output (20, 512) <class 'numpy.float32'> [[-0.67551446 -0.14402725  0.21239544 ...,  0.44075391  0.68264925
   0.40016571]
 [-0.67551446 -0.14402725  0.21239544 ...,  0.44075391  0.68264925
   0.40016571]
 [-0.67551446 -0.14402725  0.21239544 ...,  0.44075391  0.68264925
   0.40016571]
 ...,
 [-0.67551446 -0.14402725  0.21239544 ...,  0.44075391  0.68264925
   0.40016571]
 [-0.67551446 -0.14402725  0.21239544 ...,  0.44075391  0.68264925
   0.40016571]
 [-0.67551446 -0.14402725  0.21239544 ...,  0.44075391  0.68264925
   0.40016571]]
After layer decoder_rnn_l0_t0_out_0 (20, 512) <class 'numpy.float32'> [[-0.61676133 -0.03409157  0.10240182 ...,  0.30901942  0.51889932
   0.28112322]
 [-0.61676133 -0.03409157  0.10240182 ...,  0.30901942  0.51889932
   0.28112322]
 [-0.61676133 -0.03409157  0.10240182 ...,  0.30901942  0.51889932
   0.28112322]
 ...,
 [-0.61676133 -0.03409157  0.10240182 ...,  0.30901942  0.51889932
   0.28112322]
 [-0.61676133 -0.03409157  0.10240182 ...,  0.30901942  0.51889932
   0.28112322]
 [-0.61676133 -0.03409157  0.10240182 ...,  0.30901942  0.51889932
   0.28112322]]
After layer expand_dims1055_0 (20, 512, 1) <class 'numpy.float32'> [[[-0.61676133]
  [-0.03409157]
  [ 0.10240182]
  ...,
  [ 0.30901942]
  [ 0.51889932]
  [ 0.28112322]]

 [[-0.61676133]
  [-0.03409157]
  [ 0.10240182]
  ...,
  [ 0.30901942]
  [ 0.51889932]
  [ 0.28112322]]

 [[-0.61676133]
  [-0.03409157]
  [ 0.10240182]
  ...,
  [ 0.30901942]
  [ 0.51889932]
  [ 0.28112322]]

 ...,
 [[-0.61676133]
  [-0.03409157]
  [ 0.10240182]
  ...,
  [ 0.30901942]
  [ 0.51889932]
  [ 0.28112322]]

 [[-0.61676133]
  [-0.03409157]
  [ 0.10240182]
  ...,
  [ 0.30901942]
  [ 0.51889932]
  [ 0.28112322]]

 [[-0.61676133]
  [-0.03409157]
  [ 0.10240182]
  ...,
  [ 0.30901942]
  [ 0.51889932]
  [ 0.28112322]]]
After layer att_batch_dot_0 (20, 10, 1) <class 'numpy.float32'> [[[  0.23449486]
  [  0.8568241 ]
  [  2.1514039 ]
  [  4.49245501]
  [  7.44995642]
  [  9.98604107]
  [ 11.56934834]
  [ 12.40734005]
  [ 12.81686401]
  [ 12.93290615]]

 [[  0.23449486]
  [  0.8568241 ]
  [  2.1514039 ]
  [  4.49245501]
  [  7.44995642]
  [  9.98604107]
  [ 11.56934834]
  [ 12.40734005]
  [ 12.81686401]
  [ 12.93290615]]

 [[  0.23449486]
  [  0.8568241 ]
  [  2.1514039 ]
  [  4.49245501]
  [  7.44995642]
  [  9.98604107]
  [ 11.56934834]
  [ 12.40734005]
  [ 12.81686401]
  [ 12.93290615]]

 [[  0.23449486]
  [  0.8568241 ]
  [  2.1514039 ]
  [  4.49245501]
  [  7.44995642]
  [  9.98604107]
  [ 11.56934834]
  [ 12.40734005]
  [ 12.81686401]
  [ 12.93290615]]

 [[  0.23449486]
  [  0.8568241 ]
  [  2.1514039 ]
  [  4.49245501]
  [  7.44995642]
  [  9.98604107]
  [ 11.56934834]
  [ 12.40734005]
  [ 12.81686401]
  [ 12.93290615]]

 [[  0.23449486]
  [  0.8568241 ]
  [  2.1514039 ]
  [  4.49245501]
  [  7.44995642]
  [  9.98604107]
  [ 11.56934834]
  [ 12.40734005]
  [ 12.81686401]
  [ 12.93290615]]

 [[  0.23449486]
  [  0.8568241 ]
  [  2.1514039 ]
  [  4.49245501]
  [  7.44995642]
  [  9.98604107]
  [ 11.56934834]
  [ 12.40734005]
  [ 12.81686401]
  [ 12.93290615]]

 [[  0.23449486]
  [  0.8568241 ]
  [  2.1514039 ]
  [  4.49245501]
  [  7.44995642]
  [  9.98604107]
  [ 11.56934834]
  [ 12.40734005]
  [ 12.81686401]
  [ 12.93290615]]

 [[  0.23449486]
  [  0.8568241 ]
  [  2.1514039 ]
  [  4.49245501]
  [  7.44995642]
  [  9.98604107]
  [ 11.56934834]
  [ 12.40734005]
  [ 12.81686401]
  [ 12.93290615]]

 [[  0.23449486]
  [  0.8568241 ]
  [  2.1514039 ]
  [  4.49245501]
  [  7.44995642]
  [  9.98604107]
  [ 11.56934834]
  [ 12.40734005]
  [ 12.81686401]
  [ 12.93290615]]

 [[  0.23449486]
  [  0.8568241 ]
  [  2.1514039 ]
  [  4.49245501]
  [  7.44995642]
  [  9.98604107]
  [ 11.56934834]
  [ 12.40734005]
  [ 12.81686401]
  [ 12.93290615]]

 [[  0.23449486]
  [  0.8568241 ]
  [  2.1514039 ]
  [  4.49245501]
  [  7.44995642]
  [  9.98604107]
  [ 11.56934834]
  [ 12.40734005]
  [ 12.81686401]
  [ 12.93290615]]

 [[  0.23449486]
  [  0.8568241 ]
  [  2.1514039 ]
  [  4.49245501]
  [  7.44995642]
  [  9.98604107]
  [ 11.56934834]
  [ 12.40734005]
  [ 12.81686401]
  [ 12.93290615]]

 [[  0.23449486]
  [  0.8568241 ]
  [  2.1514039 ]
  [  4.49245501]
  [  7.44995642]
  [  9.98604107]
  [ 11.56934834]
  [ 12.40734005]
  [ 12.81686401]
  [ 12.93290615]]

 [[  0.23449486]
  [  0.8568241 ]
  [  2.1514039 ]
  [  4.49245501]
  [  7.44995642]
  [  9.98604107]
  [ 11.56934834]
  [ 12.40734005]
  [ 12.81686401]
  [ 12.93290615]]

 [[  0.23449486]
  [  0.8568241 ]
  [  2.1514039 ]
  [  4.49245501]
  [  7.44995642]
  [  9.98604107]
  [ 11.56934834]
  [ 12.40734005]
  [ 12.81686401]
  [ 12.93290615]]

 [[  0.23449486]
  [  0.8568241 ]
  [  2.1514039 ]
  [  4.49245501]
  [  7.44995642]
  [  9.98604107]
  [ 11.56934834]
  [ 12.40734005]
  [ 12.81686401]
  [ 12.93290615]]

 [[  0.23449486]
  [  0.8568241 ]
  [  2.1514039 ]
  [  4.49245501]
  [  7.44995642]
  [  9.98604107]
  [ 11.56934834]
  [ 12.40734005]
  [ 12.81686401]
  [ 12.93290615]]

 [[  0.23449486]
  [  0.8568241 ]
  [  2.1514039 ]
  [  4.49245501]
  [  7.44995642]
  [  9.98604107]
  [ 11.56934834]
  [ 12.40734005]
  [ 12.81686401]
  [ 12.93290615]]

 [[  0.23449486]
  [  0.8568241 ]
  [  2.1514039 ]
  [  4.49245501]
  [  7.44995642]
  [  9.98604107]
  [ 11.56934834]
  [ 12.40734005]
  [ 12.81686401]
  [ 12.93290615]]]
After layer swapaxes13_output (10, 20, 1) <class 'numpy.float32'> [[[  0.23449486]
  [  0.23449486]
  [  0.23449486]
  [  0.23449486]
  [  0.23449486]
  [  0.23449486]
  [  0.23449486]
  [  0.23449486]
  [  0.23449486]
  [  0.23449486]
  [  0.23449486]
  [  0.23449486]
  [  0.23449486]
  [  0.23449486]
  [  0.23449486]
  [  0.23449486]
  [  0.23449486]
  [  0.23449486]
  [  0.23449486]
  [  0.23449486]]

 [[  0.8568241 ]
  [  0.8568241 ]
  [  0.8568241 ]
  [  0.8568241 ]
  [  0.8568241 ]
  [  0.8568241 ]
  [  0.8568241 ]
  [  0.8568241 ]
  [  0.8568241 ]
  [  0.8568241 ]
  [  0.8568241 ]
  [  0.8568241 ]
  [  0.8568241 ]
  [  0.8568241 ]
  [  0.8568241 ]
  [  0.8568241 ]
  [  0.8568241 ]
  [  0.8568241 ]
  [  0.8568241 ]
  [  0.8568241 ]]

 [[  2.1514039 ]
  [  2.1514039 ]
  [  2.1514039 ]
  [  2.1514039 ]
  [  2.1514039 ]
  [  2.1514039 ]
  [  2.1514039 ]
  [  2.1514039 ]
  [  2.1514039 ]
  [  2.1514039 ]
  [  2.1514039 ]
  [  2.1514039 ]
  [  2.1514039 ]
  [  2.1514039 ]
  [  2.1514039 ]
  [  2.1514039 ]
  [  2.1514039 ]
  [  2.1514039 ]
  [  2.1514039 ]
  [  2.1514039 ]]

 [[  4.49245501]
  [  4.49245501]
  [  4.49245501]
  [  4.49245501]
  [  4.49245501]
  [  4.49245501]
  [  4.49245501]
  [  4.49245501]
  [  4.49245501]
  [  4.49245501]
  [  4.49245501]
  [  4.49245501]
  [  4.49245501]
  [  4.49245501]
  [  4.49245501]
  [  4.49245501]
  [  4.49245501]
  [  4.49245501]
  [  4.49245501]
  [  4.49245501]]

 [[  7.44995642]
  [  7.44995642]
  [  7.44995642]
  [  7.44995642]
  [  7.44995642]
  [  7.44995642]
  [  7.44995642]
  [  7.44995642]
  [  7.44995642]
  [  7.44995642]
  [  7.44995642]
  [  7.44995642]
  [  7.44995642]
  [  7.44995642]
  [  7.44995642]
  [  7.44995642]
  [  7.44995642]
  [  7.44995642]
  [  7.44995642]
  [  7.44995642]]

 [[  9.98604107]
  [  9.98604107]
  [  9.98604107]
  [  9.98604107]
  [  9.98604107]
  [  9.98604107]
  [  9.98604107]
  [  9.98604107]
  [  9.98604107]
  [  9.98604107]
  [  9.98604107]
  [  9.98604107]
  [  9.98604107]
  [  9.98604107]
  [  9.98604107]
  [  9.98604107]
  [  9.98604107]
  [  9.98604107]
  [  9.98604107]
  [  9.98604107]]

 [[ 11.56934834]
  [ 11.56934834]
  [ 11.56934834]
  [ 11.56934834]
  [ 11.56934834]
  [ 11.56934834]
  [ 11.56934834]
  [ 11.56934834]
  [ 11.56934834]
  [ 11.56934834]
  [ 11.56934834]
  [ 11.56934834]
  [ 11.56934834]
  [ 11.56934834]
  [ 11.56934834]
  [ 11.56934834]
  [ 11.56934834]
  [ 11.56934834]
  [ 11.56934834]
  [ 11.56934834]]

 [[ 12.40734005]
  [ 12.40734005]
  [ 12.40734005]
  [ 12.40734005]
  [ 12.40734005]
  [ 12.40734005]
  [ 12.40734005]
  [ 12.40734005]
  [ 12.40734005]
  [ 12.40734005]
  [ 12.40734005]
  [ 12.40734005]
  [ 12.40734005]
  [ 12.40734005]
  [ 12.40734005]
  [ 12.40734005]
  [ 12.40734005]
  [ 12.40734005]
  [ 12.40734005]
  [ 12.40734005]]

 [[ 12.81686401]
  [ 12.81686401]
  [ 12.81686401]
  [ 12.81686401]
  [ 12.81686401]
  [ 12.81686401]
  [ 12.81686401]
  [ 12.81686401]
  [ 12.81686401]
  [ 12.81686401]
  [ 12.81686401]
  [ 12.81686401]
  [ 12.81686401]
  [ 12.81686401]
  [ 12.81686401]
  [ 12.81686401]
  [ 12.81686401]
  [ 12.81686401]
  [ 12.81686401]
  [ 12.81686401]]

 [[ 12.93290615]
  [ 12.93290615]
  [ 12.93290615]
  [ 12.93290615]
  [ 12.93290615]
  [ 12.93290615]
  [ 12.93290615]
  [ 12.93290615]
  [ 12.93290615]
  [ 12.93290615]
  [ 12.93290615]
  [ 12.93290615]
  [ 12.93290615]
  [ 12.93290615]
  [ 12.93290615]
  [ 12.93290615]
  [ 12.93290615]
  [ 12.93290615]
  [ 12.93290615]
  [ 12.93290615]]]
After layer sequencemask2_output (10, 20, 1) <class 'numpy.float32'> [[[  2.34494865e-01]
  [  2.34494865e-01]
  [  2.34494865e-01]
  [  2.34494865e-01]
  [  2.34494865e-01]
  [  2.34494865e-01]
  [  2.34494865e-01]
  [  2.34494865e-01]
  [  2.34494865e-01]
  [  2.34494865e-01]
  [  2.34494865e-01]
  [  2.34494865e-01]
  [  2.34494865e-01]
  [  2.34494865e-01]
  [  2.34494865e-01]
  [  2.34494865e-01]
  [  2.34494865e-01]
  [  2.34494865e-01]
  [  2.34494865e-01]
  [  2.34494865e-01]]

 [[  8.56824100e-01]
  [  8.56824100e-01]
  [  8.56824100e-01]
  [  8.56824100e-01]
  [  8.56824100e-01]
  [  8.56824100e-01]
  [  8.56824100e-01]
  [  8.56824100e-01]
  [  8.56824100e-01]
  [  8.56824100e-01]
  [  8.56824100e-01]
  [  8.56824100e-01]
  [  8.56824100e-01]
  [  8.56824100e-01]
  [  8.56824100e-01]
  [  8.56824100e-01]
  [  8.56824100e-01]
  [  8.56824100e-01]
  [  8.56824100e-01]
  [  8.56824100e-01]]

 [[ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]]
After layer swapaxes14_output (20, 10, 1) <class 'numpy.float32'> [[[  2.34494865e-01]
  [  8.56824100e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  2.34494865e-01]
  [  8.56824100e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  2.34494865e-01]
  [  8.56824100e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  2.34494865e-01]
  [  8.56824100e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  2.34494865e-01]
  [  8.56824100e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  2.34494865e-01]
  [  8.56824100e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  2.34494865e-01]
  [  8.56824100e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  2.34494865e-01]
  [  8.56824100e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  2.34494865e-01]
  [  8.56824100e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  2.34494865e-01]
  [  8.56824100e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  2.34494865e-01]
  [  8.56824100e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  2.34494865e-01]
  [  8.56824100e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  2.34494865e-01]
  [  8.56824100e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  2.34494865e-01]
  [  8.56824100e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  2.34494865e-01]
  [  8.56824100e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  2.34494865e-01]
  [  8.56824100e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  2.34494865e-01]
  [  8.56824100e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  2.34494865e-01]
  [  8.56824100e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  2.34494865e-01]
  [  8.56824100e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  2.34494865e-01]
  [  8.56824100e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]]
After layer attention_softmax_0 (20, 10, 1) <class 'numpy.float32'> [[[ 0.34925193]
  [ 0.65074813]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.34925193]
  [ 0.65074813]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.34925193]
  [ 0.65074813]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.34925193]
  [ 0.65074813]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.34925193]
  [ 0.65074813]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.34925193]
  [ 0.65074813]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.34925193]
  [ 0.65074813]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.34925193]
  [ 0.65074813]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.34925193]
  [ 0.65074813]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.34925193]
  [ 0.65074813]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.34925193]
  [ 0.65074813]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.34925193]
  [ 0.65074813]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.34925193]
  [ 0.65074813]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.34925193]
  [ 0.65074813]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.34925193]
  [ 0.65074813]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.34925193]
  [ 0.65074813]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.34925193]
  [ 0.65074813]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.34925193]
  [ 0.65074813]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.34925193]
  [ 0.65074813]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.34925193]
  [ 0.65074813]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]]
After layer batch_dot2_0 (20, 512, 1) <class 'numpy.float32'> [[[ 0.01915653]
  [ 0.04094461]
  [-0.03585937]
  ...,
  [-0.01125474]
  [ 0.01005555]
  [-0.02364485]]

 [[ 0.01915653]
  [ 0.04094461]
  [-0.03585937]
  ...,
  [-0.01125474]
  [ 0.01005555]
  [-0.02364485]]

 [[ 0.01915653]
  [ 0.04094461]
  [-0.03585937]
  ...,
  [-0.01125474]
  [ 0.01005555]
  [-0.02364485]]

 ...,
 [[ 0.01915653]
  [ 0.04094461]
  [-0.03585937]
  ...,
  [-0.01125474]
  [ 0.01005555]
  [-0.02364485]]

 [[ 0.01915653]
  [ 0.04094461]
  [-0.03585937]
  ...,
  [-0.01125474]
  [ 0.01005555]
  [-0.02364485]]

 [[ 0.01915653]
  [ 0.04094461]
  [-0.03585937]
  ...,
  [-0.01125474]
  [ 0.01005555]
  [-0.02364485]]]
After layer reshape4_0 (20, 512) <class 'numpy.float32'> [[ 0.01915653  0.04094461 -0.03585937 ..., -0.01125474  0.01005555
  -0.02364485]
 [ 0.01915653  0.04094461 -0.03585937 ..., -0.01125474  0.01005555
  -0.02364485]
 [ 0.01915653  0.04094461 -0.03585937 ..., -0.01125474  0.01005555
  -0.02364485]
 ...,
 [ 0.01915653  0.04094461 -0.03585937 ..., -0.01125474  0.01005555
  -0.02364485]
 [ 0.01915653  0.04094461 -0.03585937 ..., -0.01125474  0.01005555
  -0.02364485]
 [ 0.01915653  0.04094461 -0.03585937 ..., -0.01125474  0.01005555
  -0.02364485]]
After layer decoder_rnn_hidden_concat_t0_output (20, 1024) <class 'numpy.float32'> [[-0.61676133 -0.03409157  0.10240182 ..., -0.01125474  0.01005555
  -0.02364485]
 [-0.61676133 -0.03409157  0.10240182 ..., -0.01125474  0.01005555
  -0.02364485]
 [-0.61676133 -0.03409157  0.10240182 ..., -0.01125474  0.01005555
  -0.02364485]
 ...,
 [-0.61676133 -0.03409157  0.10240182 ..., -0.01125474  0.01005555
  -0.02364485]
 [-0.61676133 -0.03409157  0.10240182 ..., -0.01125474  0.01005555
  -0.02364485]
 [-0.61676133 -0.03409157  0.10240182 ..., -0.01125474  0.01005555
  -0.02364485]]
After layer decoder_rnn_hidden_fc_t0_output (20, 512) <class 'numpy.float32'> [[-0.10364144  0.18603311  0.17674752 ..., -0.862032    1.18907475
  -1.03758991]
 [-0.10364144  0.18603311  0.17674752 ..., -0.862032    1.18907475
  -1.03758991]
 [-0.10364144  0.18603311  0.17674752 ..., -0.862032    1.18907475
  -1.03758991]
 ...,
 [-0.10364144  0.18603311  0.17674752 ..., -0.862032    1.18907475
  -1.03758991]
 [-0.10364144  0.18603311  0.17674752 ..., -0.862032    1.18907475
  -1.03758991]
 [-0.10364144  0.18603311  0.17674752 ..., -0.862032    1.18907475
  -1.03758991]]
After layer decoder_rnn_next_hidden_t0_output (20, 512) <class 'numpy.float32'> [[-0.10327195  0.18391632  0.17492972 ..., -0.69730306  0.83029169
  -0.77693456]
 [-0.10327195  0.18391632  0.17492972 ..., -0.69730306  0.83029169
  -0.77693456]
 [-0.10327195  0.18391632  0.17492972 ..., -0.69730306  0.83029169
  -0.77693456]
 ...,
 [-0.10327195  0.18391632  0.17492972 ..., -0.69730306  0.83029169
  -0.77693456]
 [-0.10327195  0.18391632  0.17492972 ..., -0.69730306  0.83029169
  -0.77693456]
 [-0.10327195  0.18391632  0.17492972 ..., -0.69730306  0.83029169
  -0.77693456]]
After layer logits_output (20, 16743) <class 'numpy.float32'> [[-1.97590375 -1.57187057 -2.53163433 ..., -2.80288434 -2.45055747
  -2.70916319]
 [-1.97590375 -1.57187057 -2.53163433 ..., -2.80288434 -2.45055747
  -2.70916319]
 [-1.97590375 -1.57187057 -2.53163433 ..., -2.80288434 -2.45055747
  -2.70916319]
 ...,
 [-1.97590375 -1.57187057 -2.53163433 ..., -2.80288434 -2.45055747
  -2.70916319]
 [-1.97590375 -1.57187057 -2.53163433 ..., -2.80288434 -2.45055747
  -2.70916319]
 [-1.97590375 -1.57187057 -2.53163433 ..., -2.80288434 -2.45055747
  -2.70916319]]
After layer softmax_0 (20, 16743) <class 'numpy.float32'> [[  4.05097944e-06   6.06777758e-06   2.32385833e-06 ...,   1.77176844e-06
    2.52011728e-06   1.94585118e-06]
 [  4.05097944e-06   6.06777758e-06   2.32385833e-06 ...,   1.77176844e-06
    2.52011728e-06   1.94585118e-06]
 [  4.05097944e-06   6.06777758e-06   2.32385833e-06 ...,   1.77176844e-06
    2.52011728e-06   1.94585118e-06]
 ...,
 [  4.05097944e-06   6.06777758e-06   2.32385833e-06 ...,   1.77176844e-06
    2.52011728e-06   1.94585118e-06]
 [  4.05097944e-06   6.06777758e-06   2.32385833e-06 ...,   1.77176844e-06
    2.52011728e-06   1.94585118e-06]
 [  4.05097944e-06   6.06777758e-06   2.32385833e-06 ...,   1.77176844e-06
    2.52011728e-06   1.94585118e-06]]
After layer reshape5_0 (20, 10) <class 'numpy.float32'> [[ 0.34925193  0.65074813  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.34925193  0.65074813  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.34925193  0.65074813  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.34925193  0.65074813  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.34925193  0.65074813  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.34925193  0.65074813  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.34925193  0.65074813  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.34925193  0.65074813  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.34925193  0.65074813  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.34925193  0.65074813  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.34925193  0.65074813  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.34925193  0.65074813  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.34925193  0.65074813  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.34925193  0.65074813  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.34925193  0.65074813  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.34925193  0.65074813  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.34925193  0.65074813  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.34925193  0.65074813  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.34925193  0.65074813  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.34925193  0.65074813  0.          0.          0.          0.          0.
   0.          0.          0.        ]]
After layer target_embed_embed_0 (20, 256) <class 'numpy.float32'> [[ 0.14013672  0.20153809 -0.07067871 ..., -0.01544189 -0.08544922
  -0.18017578]
 [-0.09741211  0.03695679 -0.09680176 ...,  0.04989624 -0.08117676
   0.02781677]
 [-0.03533936 -0.15087891 -0.13806152 ...,  0.14208984 -0.02362061
   0.09649658]
 ...,
 [-0.09918213 -0.03604126 -0.10394287 ..., -0.01651001  0.06848145
  -0.00800323]
 [ 0.1050415   0.08380127 -0.09240723 ...,  0.02670288 -0.09100342
   0.01057434]
 [-0.06762695 -0.01657104  0.0635376  ..., -0.02737427  0.04412842
   0.00128555]]
After layer decoder_rnn_concat_target_context_t0_output (20, 768) <class 'numpy.float32'> [[ 0.14013672  0.20153809 -0.07067871 ..., -0.69730306  0.83029169
  -0.77693456]
 [-0.09741211  0.03695679 -0.09680176 ..., -0.69730306  0.83029169
  -0.77693456]
 [-0.03533936 -0.15087891 -0.13806152 ..., -0.69730306  0.83029169
  -0.77693456]
 ...,
 [-0.09918213 -0.03604126 -0.10394287 ..., -0.69730306  0.83029169
  -0.77693456]
 [ 0.1050415   0.08380127 -0.09240723 ..., -0.69730306  0.83029169
  -0.77693456]
 [-0.06762695 -0.01657104  0.0635376  ..., -0.69730306  0.83029169
  -0.77693456]]
After layer decoder_rnn_l0_t0_i2h_output (20, 2048) <class 'numpy.float32'> [[-2.95480585  2.19920254  2.51707435 ..., -2.85153985  3.64953423
  -0.25682396]
 [-2.74819613  1.97088099  2.56212878 ..., -0.43987864  3.90238667
  -0.47362015]
 [-2.70027184  1.82271242  2.55748129 ...,  0.19223723  3.94125152
  -0.80373251]
 ...,
 [-2.70058298  1.99829173  2.53851414 ..., -0.40996388  3.85988355
  -0.74853408]
 [-2.77945232  1.88953412  2.55413127 ..., -0.63203824  3.945925   -0.397237  ]
 [-2.78331542  1.82735574  2.49986935 ..., -0.01384192  3.85845518
  -0.56371439]]
After layer decoder_rnn_l0_t0_h2h_output (20, 2048) <class 'numpy.float32'> [[-0.14801261  0.31590447  1.21134377 ...,  0.20786853  0.58646065
   0.44664007]
 [-0.14801261  0.31590447  1.21134377 ...,  0.20786853  0.58646065
   0.44664007]
 [-0.14801261  0.31590447  1.21134377 ...,  0.20786853  0.58646065
   0.44664007]
 ...,
 [-0.14801261  0.31590447  1.21134377 ...,  0.20786853  0.58646065
   0.44664007]
 [-0.14801261  0.31590447  1.21134377 ...,  0.20786853  0.58646065
   0.44664007]
 [-0.14801261  0.31590447  1.21134377 ...,  0.20786853  0.58646065
   0.44664007]]
After layer _plus1047_0 (20, 2048) <class 'numpy.float32'> [[-3.10281849  2.51510692  3.72841811 ..., -2.64367127  4.23599482
   0.18981612]
 [-2.89620876  2.28678536  3.77347255 ..., -0.23201011  4.48884726
  -0.02698007]
 [-2.84828448  2.1386168   3.76882505 ...,  0.40010577  4.52771235
  -0.35709244]
 ...,
 [-2.84859562  2.31419611  3.7498579  ..., -0.20209534  4.44634438
  -0.30189401]
 [-2.92746496  2.20543861  3.76547503 ..., -0.42416972  4.53238583
   0.04940307]
 [-2.93132806  2.14326024  3.71121311 ...,  0.1940266   4.44491577
  -0.11707431]]
After layer decoder_rnn_l0_t0_slice_output0 (20, 512) <class 'numpy.float32'> [[-3.10281849  2.51510692  3.72841811 ...,  2.26166773  4.3558073
   1.17264843]
 [-2.89620876  2.28678536  3.77347255 ...,  2.2833848   4.42998886
   0.99677277]
 [-2.84828448  2.1386168   3.76882505 ...,  2.26711392  4.48527479
   1.02302527]
 ...,
 [-2.84859562  2.31419611  3.7498579  ...,  2.25483823  4.4711566
   1.00115955]
 [-2.92746496  2.20543861  3.76547503 ...,  2.31313205  4.43733454
   1.09166586]
 [-2.93132806  2.14326024  3.71121311 ...,  2.25249267  4.44570732
   1.05603957]]
After layer decoder_rnn_l0_t0_slice_output1 (20, 512) <class 'numpy.float32'> [[ 0.1912612   0.0356307   2.34597778 ...,  1.50814748 -0.6038335
   1.47797084]
 [-0.63471889  0.33317804  2.28588438 ...,  1.44633043 -1.19416475
   1.2966485 ]
 [-0.59136653  0.17149186  2.35364699 ...,  1.47456086 -1.64621305
   1.24878705]
 ...,
 [-0.62758088  0.4803344   2.31376243 ...,  1.37911797 -1.40619504
   1.21080387]
 [-0.39812839 -0.0314827   2.33037162 ...,  1.55054855 -1.03148973
   1.39369321]
 [-0.63111979  0.18955004  2.29675555 ...,  1.49053836 -1.2734102
   1.34197044]]
After layer decoder_rnn_l0_t0_slice_output2 (20, 512) <class 'numpy.float32'> [[-1.76029754 -2.01554346  2.91351604 ...,  2.63813233 -0.74255705
   1.53105021]
 [-1.86989379 -1.91560411  3.01237106 ...,  2.70457339 -0.7322644
   1.45601487]
 [-1.88448405 -1.9190309   3.04574537 ...,  2.68693113 -0.48326918
   1.40662992]
 ...,
 [-1.82320237 -1.91028404  2.95431805 ...,  2.62104702 -0.87756765
   1.44216704]
 [-1.87173045 -1.96389961  3.00729799 ...,  2.73806286 -0.5520215
   1.48538113]
 [-1.83888316 -1.85292792  2.97997904 ...,  2.6631434  -0.66744816
   1.44744349]]
After layer decoder_rnn_l0_t0_slice_output3 (20, 512) <class 'numpy.float32'> [[ 0.83884448 -2.50003958 -1.55482435 ..., -2.64367127  4.23599482
   0.18981612]
 [ 0.43075407 -1.02097189  0.7303766  ..., -0.23201011  4.48884726
  -0.02698007]
 [ 0.43406916 -0.73655826  1.65450549 ...,  0.40010577  4.52771235
  -0.35709244]
 ...,
 [ 0.31363159 -0.3617906   1.67189217 ..., -0.20209534  4.44634438
  -0.30189401]
 [ 0.56200457 -1.5273329  -0.10206927 ..., -0.42416972  4.53238583
   0.04940307]
 [ 0.40066969 -1.02155018  0.84195495 ...,  0.1940266   4.44491577
  -0.11707431]]
After layer decoder_rnn_l0_t0_o_output (20, 512) <class 'numpy.float32'> [[ 0.69822174  0.0758554   0.17439057 ...,  0.06638015  0.98574084
   0.54731202]
 [ 0.60605377  0.26483813  0.67488796 ...,  0.44225627  0.98889124
   0.49325541]
 [ 0.6068449   0.3237572   0.83949906 ...,  0.59871304  0.98931015
   0.41166359]
 ...,
 [ 0.57777143  0.41052616  0.84182793 ...,  0.44964743  0.98841441
   0.42509452]
 [ 0.63691622  0.17838424  0.4745048  ...,  0.39551941  0.9893595
   0.51234829]
 [ 0.59884852  0.26472557  0.69887674 ...,  0.54835504  0.98839813
   0.47076482]]
After layer decoder_rnn_l0_t0_f_output (20, 512) <class 'numpy.float32'> [[ 0.54767007  0.50890672  0.91261399 ...,  0.8187865   0.35346714
   0.81426591]
 [ 0.3464413   0.58253241  0.90770119 ...,  0.80943304  0.23251492
   0.78527039]
 [ 0.35632136  0.54276818  0.91322368 ...,  0.81374961  0.16162144
   0.77708977]
 ...,
 [ 0.34805927  0.61782682  0.9100104  ...,  0.79884928  0.19683488
   0.77044117]
 [ 0.4017621   0.49212995  0.91136134 ...,  0.8249929   0.26279539
   0.8011812 ]
 [ 0.34725666  0.54724616  0.90860802 ...,  0.81615907  0.21867403
   0.79281378]]
After layer _mul2094_0 (20, 512) <class 'numpy.float32'> [[-0.44953704 -0.07380965  0.19683133 ...,  0.387422    0.29481232
   0.3451235 ]
 [-0.284365   -0.084488    0.19577175 ...,  0.38299626  0.19393107
   0.33283386]
 [-0.29247472 -0.07872077  0.19696283 ...,  0.3850387   0.13480176
   0.32936653]
 ...,
 [-0.28569305 -0.08960696  0.1962698  ...,  0.3779884   0.16417183
   0.32654855]
 [-0.32977325 -0.07137642  0.19656117 ...,  0.39035866  0.21918677
   0.33957759]
 [-0.28503424 -0.07937024  0.19596733 ...,  0.38617879  0.18238696
   0.33603111]]
After layer decoder_rnn_l0_t0_i_output (20, 512) <class 'numpy.float32'> [[ 0.04299115  0.92519408  0.97653311 ...,  0.90565223  0.98733056
   0.76362342]
 [ 0.0523413   0.90777665  0.97754377 ...,  0.90749156  0.9882257
   0.73042357]
 [ 0.05477006  0.89460033  0.97744149 ...,  0.9061166   0.98885196
   0.73556149]
 ...,
 [ 0.05475396  0.91004598  0.97701949 ...,  0.90506709  0.9886952
   0.73128653]
 [ 0.05081246  0.90073681  0.97736746 ...,  0.90995878  0.98831081
   0.74869525]
 [ 0.05062646  0.89503729  0.97613561 ...,  0.90486526  0.98840719
   0.74193299]]
After layer decoder_rnn_l0_t0_c_output (20, 512) <class 'numpy.float32'> [[-0.94253623 -0.96510947  0.9941237  ...,  0.989829   -0.63068759
   0.91060412]
 [-0.95358449 -0.95755357  0.9951753  ...,  0.99108899 -0.62444878
   0.89687586]
 [-0.95488924 -0.9578374   0.99548614 ...,  0.9907704  -0.44885796
   0.88677633]
 ...,
 [-0.94915676 -0.95710927  0.99458295 ...,  0.98947734 -0.70519871
   0.89413309]
 [-0.95375073 -0.96138626  0.99512625 ...,  0.99166387 -0.50203377
   0.9024713 ]
 [-0.95068783 -0.95202094  0.99485326 ...,  0.99032289 -0.58329874
   0.89518619]]
After layer _mul2095_0 (20, 512) <class 'numpy.float32'> [[-0.04052071 -0.89291358  0.97079474 ...,  0.89644086 -0.62269711
   0.69535863]
 [-0.04991185 -0.86924475  0.97282743 ...,  0.89940488 -0.6170963
   0.65509927]
 [-0.05229934 -0.85688168  0.97302943 ...,  0.89775354 -0.44385406
   0.65227854]
 ...,
 [-0.05197009 -0.87101346  0.97172695 ...,  0.8955434  -0.69722658
   0.65386748]
 [-0.04846242 -0.86595601  0.97260404 ...,  0.90237325 -0.49616539
   0.67567599]
 [-0.04812996 -0.85209423  0.97111171 ...,  0.89610881 -0.57653666
   0.66416818]]
After layer decoder_rnn_l0_t0_state_0 (20, 512) <class 'numpy.float32'> [[-0.49005777 -0.9667232   1.16762602 ...,  1.28386283 -0.32788479
   1.04048216]
 [-0.33427685 -0.95373273  1.16859913 ...,  1.28240108 -0.42316523
   0.98793316]
 [-0.34477407 -0.93560243  1.16999221 ...,  1.28279221 -0.30905229
   0.98164511]
 ...,
 [-0.33766314 -0.9606204   1.16799676 ...,  1.27353179 -0.53305477
   0.98041606]
 [-0.37823567 -0.93733245  1.16916525 ...,  1.29273188 -0.27697861
   1.01525354]
 [-0.33316419 -0.93146449  1.16707909 ...,  1.2822876  -0.39414969
   1.00019932]]
After layer activation1047_output (20, 512) <class 'numpy.float32'> [[-0.45426229 -0.74726081  0.82350963 ...,  0.85751069 -0.31661889
   0.77807838]
 [-0.32235846 -0.74146831  0.82382256 ...,  0.85712337 -0.39959362
   0.75647962]
 [-0.33173278 -0.73319525  0.82426965 ...,  0.85722709 -0.29957467
   0.75377721]
 ...,
 [-0.32538953 -0.74455345  0.8236289  ...,  0.854752   -0.48771268
   0.75324595]
 [-0.36117426 -0.73399425  0.82400441 ...,  0.85984033 -0.27010641
   0.76792622]
 [-0.32136106 -0.73127598  0.82333356 ...,  0.85709321 -0.37493211
   0.76167786]]
After layer decoder_rnn_l0_t0_out_0 (20, 512) <class 'numpy.float32'> [[-0.31717581 -0.05668377  0.14361231 ...,  0.05692169 -0.31210417
   0.42585164]
 [-0.19536656 -0.19636908  0.55598789 ...,  0.3790682  -0.39515463
   0.37313765]
 [-0.20131035 -0.23737724  0.69197357 ...,  0.51323301 -0.29637226
   0.31030264]
 ...,
 [-0.18800077 -0.30565867  0.69335383 ...,  0.38433704 -0.48206225
   0.32020071]
 [-0.23003775 -0.130933    0.39099404 ...,  0.34008354 -0.26723233
   0.3934457 ]
 [-0.1924466  -0.19358745  0.5754087  ...,  0.46999139 -0.37058219
   0.35857114]]
After layer expand_dims1056_0 (20, 512, 1) <class 'numpy.float32'> [[[-0.31717581]
  [-0.05668377]
  [ 0.14361231]
  ...,
  [ 0.05692169]
  [-0.31210417]
  [ 0.42585164]]

 [[-0.19536656]
  [-0.19636908]
  [ 0.55598789]
  ...,
  [ 0.3790682 ]
  [-0.39515463]
  [ 0.37313765]]

 [[-0.20131035]
  [-0.23737724]
  [ 0.69197357]
  ...,
  [ 0.51323301]
  [-0.29637226]
  [ 0.31030264]]

 ...,
 [[-0.18800077]
  [-0.30565867]
  [ 0.69335383]
  ...,
  [ 0.38433704]
  [-0.48206225]
  [ 0.32020071]]

 [[-0.23003775]
  [-0.130933  ]
  [ 0.39099404]
  ...,
  [ 0.34008354]
  [-0.26723233]
  [ 0.3934457 ]]

 [[-0.1924466 ]
  [-0.19358745]
  [ 0.5754087 ]
  ...,
  [ 0.46999139]
  [-0.37058219]
  [ 0.35857114]]]
After layer att_batch_dot_0 (20, 10, 1) <class 'numpy.float32'> [[[  0.60316628]
  [  1.16711414]
  [  2.82130003]
  [  5.38747025]
  [  8.14446926]
  [  9.73800468]
  [ 10.15969563]
  [  9.9888773 ]
  [  9.55609989]
  [  8.98670673]]

 [[  0.26209095]
  [ -0.09440913]
  [ -0.12961878]
  [ -0.63381517]
  [ -2.53583384]
  [ -6.44556904]
  [-10.98124218]
  [-14.73106956]
  [-17.39543533]
  [-19.25129509]]

 [[  0.23367357]
  [ -0.33354449]
  [ -0.75984287]
  [ -1.99502802]
  [ -5.09512806]
  [-10.52874279]
  [-16.51457787]
  [-21.35171318]
  [-24.69774628]
  [-26.94365883]]

 [[  0.44806033]
  [  0.67035872]
  [  1.56483293]
  [  2.74169397]
  [  3.27671742]
  [  2.11957526]
  [  0.05450493]
  [ -1.80470467]
  [ -3.13699794]
  [ -4.0762248 ]]

 [[  0.30563295]
  [  0.09405521]
  [  0.34699926]
  [  0.39280647]
  [ -0.58857143]
  [ -3.31087995]
  [ -6.72523546]
  [ -9.6522646 ]
  [-11.8116293 ]
  [-13.3854351 ]]

 [[  0.36263093]
  [  0.31159809]
  [  0.78246182]
  [  1.20973027]
  [  0.68753374]
  [ -1.63566589]
  [ -4.74630499]
  [ -7.42777205]
  [ -9.37061501]
  [-10.75814533]]

 [[  0.30723068]
  [  0.11336882]
  [  0.38538617]
  [  0.50124508]
  [ -0.3334772 ]
  [ -2.84583688]
  [ -6.05177212]
  [ -8.81763077]
  [-10.87462902]
  [-12.38820934]]

 [[  0.5761025 ]
  [  1.04387414]
  [  2.53443694]
  [  4.82839727]
  [  7.25255871]
  [  8.52849388]
  [  8.69771099]
  [  8.35879326]
  [  7.8217063 ]
  [  7.19240332]]

 [[  0.4252139 ]
  [  0.57488012]
  [  1.3899672 ]
  [  2.45669746]
  [  2.89736509]
  [  1.70611298]
  [ -0.36254564]
  [ -2.24306345]
  [ -3.62981486]
  [ -4.64440823]]

 [[  0.47729495]
  [  0.79622549]
  [  1.86840463]
  [  3.39633918]
  [  4.49871826]
  [  4.05432749]
  [  2.65786815]
  [  1.28627276]
  [  0.24418578]
  [ -0.54728204]]

 [[  0.44386566]
  [  0.6824773 ]
  [  1.60457003]
  [  2.85574532]
  [  3.53324986]
  [  2.57722592]
  [  0.70605248]
  [ -1.02035201]
  [ -2.28923392]
  [ -3.2137394 ]]

 [[  0.48178095]
  [  0.87072939]
  [  2.04938316]
  [  3.77943635]
  [  5.19618797]
  [  5.13273573]
  [  4.10165882]
  [  3.03443837]
  [  2.22941232]
  [  1.61949253]]

 [[  0.45541847]
  [  0.69835442]
  [  1.68613887]
  [  3.08872628]
  [  4.09692526]
  [  3.64098001]
  [  2.25232506]
  [  0.83935201]
  [ -0.2961984 ]
  [ -1.20412135]]

 [[  0.31513476]
  [  0.13002667]
  [  0.39686421]
  [  0.48498228]
  [ -0.44961789]
  [ -3.14696693]
  [ -6.55114079]
  [ -9.45740128]
  [-11.58084202]
  [-13.11160755]]

 [[  0.18547006]
  [ -0.48459089]
  [ -1.03920722]
  [ -2.49505472]
  [ -5.8259244 ]
  [-11.40588093]
  [-17.44702721]
  [-22.29692459]
  [-25.66054726]
  [-27.92882156]]

 [[  0.44777194]
  [  0.67722368]
  [  1.60646296]
  [  2.85411763]
  [  3.50553036]
  [  2.49189305]
  [  0.53880209]
  [ -1.28530371]
  [ -2.65190148]
  [ -3.66600299]]

 [[  0.25292033]
  [ -0.14556842]
  [ -0.25767741]
  [ -0.89208955]
  [ -2.96816969]
  [ -7.0553484 ]
  [-11.7383728 ]
  [-15.59304428]
  [-18.32572556]
  [-20.22352409]]

 [[  0.13978912]
  [ -0.76690465]
  [ -1.66609466]
  [ -3.74048686]
  [ -7.97331476]
  [-14.58728218]
  [-21.60077095]
  [-27.26734161]
  [-31.27992821]
  [-34.05604553]]

 [[  0.42086592]
  [  0.56561625]
  [  1.38657308]
  [  2.4528358 ]
  [  2.91867733]
  [  1.79200757]
  [ -0.2114158 ]
  [ -2.06789517]
  [ -3.47984052]
  [ -4.55127764]]

 [[  0.27065808]
  [ -0.06793152]
  [ -0.09593432]
  [ -0.58570534]
  [ -2.4867301 ]
  [ -6.41838312]
  [-10.97236633]
  [-14.70731163]
  [-17.32374763]
  [-19.11522865]]]
After layer swapaxes15_output (10, 20, 1) <class 'numpy.float32'> [[[  0.60316628]
  [  0.26209095]
  [  0.23367357]
  [  0.44806033]
  [  0.30563295]
  [  0.36263093]
  [  0.30723068]
  [  0.5761025 ]
  [  0.4252139 ]
  [  0.47729495]
  [  0.44386566]
  [  0.48178095]
  [  0.45541847]
  [  0.31513476]
  [  0.18547006]
  [  0.44777194]
  [  0.25292033]
  [  0.13978912]
  [  0.42086592]
  [  0.27065808]]

 [[  1.16711414]
  [ -0.09440913]
  [ -0.33354449]
  [  0.67035872]
  [  0.09405521]
  [  0.31159809]
  [  0.11336882]
  [  1.04387414]
  [  0.57488012]
  [  0.79622549]
  [  0.6824773 ]
  [  0.87072939]
  [  0.69835442]
  [  0.13002667]
  [ -0.48459089]
  [  0.67722368]
  [ -0.14556842]
  [ -0.76690465]
  [  0.56561625]
  [ -0.06793152]]

 [[  2.82130003]
  [ -0.12961878]
  [ -0.75984287]
  [  1.56483293]
  [  0.34699926]
  [  0.78246182]
  [  0.38538617]
  [  2.53443694]
  [  1.3899672 ]
  [  1.86840463]
  [  1.60457003]
  [  2.04938316]
  [  1.68613887]
  [  0.39686421]
  [ -1.03920722]
  [  1.60646296]
  [ -0.25767741]
  [ -1.66609466]
  [  1.38657308]
  [ -0.09593432]]

 [[  5.38747025]
  [ -0.63381517]
  [ -1.99502802]
  [  2.74169397]
  [  0.39280647]
  [  1.20973027]
  [  0.50124508]
  [  4.82839727]
  [  2.45669746]
  [  3.39633918]
  [  2.85574532]
  [  3.77943635]
  [  3.08872628]
  [  0.48498228]
  [ -2.49505472]
  [  2.85411763]
  [ -0.89208955]
  [ -3.74048686]
  [  2.4528358 ]
  [ -0.58570534]]

 [[  8.14446926]
  [ -2.53583384]
  [ -5.09512806]
  [  3.27671742]
  [ -0.58857143]
  [  0.68753374]
  [ -0.3334772 ]
  [  7.25255871]
  [  2.89736509]
  [  4.49871826]
  [  3.53324986]
  [  5.19618797]
  [  4.09692526]
  [ -0.44961789]
  [ -5.8259244 ]
  [  3.50553036]
  [ -2.96816969]
  [ -7.97331476]
  [  2.91867733]
  [ -2.4867301 ]]

 [[  9.73800468]
  [ -6.44556904]
  [-10.52874279]
  [  2.11957526]
  [ -3.31087995]
  [ -1.63566589]
  [ -2.84583688]
  [  8.52849388]
  [  1.70611298]
  [  4.05432749]
  [  2.57722592]
  [  5.13273573]
  [  3.64098001]
  [ -3.14696693]
  [-11.40588093]
  [  2.49189305]
  [ -7.0553484 ]
  [-14.58728218]
  [  1.79200757]
  [ -6.41838312]]

 [[ 10.15969563]
  [-10.98124218]
  [-16.51457787]
  [  0.05450493]
  [ -6.72523546]
  [ -4.74630499]
  [ -6.05177212]
  [  8.69771099]
  [ -0.36254564]
  [  2.65786815]
  [  0.70605248]
  [  4.10165882]
  [  2.25232506]
  [ -6.55114079]
  [-17.44702721]
  [  0.53880209]
  [-11.7383728 ]
  [-21.60077095]
  [ -0.2114158 ]
  [-10.97236633]]

 [[  9.9888773 ]
  [-14.73106956]
  [-21.35171318]
  [ -1.80470467]
  [ -9.6522646 ]
  [ -7.42777205]
  [ -8.81763077]
  [  8.35879326]
  [ -2.24306345]
  [  1.28627276]
  [ -1.02035201]
  [  3.03443837]
  [  0.83935201]
  [ -9.45740128]
  [-22.29692459]
  [ -1.28530371]
  [-15.59304428]
  [-27.26734161]
  [ -2.06789517]
  [-14.70731163]]

 [[  9.55609989]
  [-17.39543533]
  [-24.69774628]
  [ -3.13699794]
  [-11.8116293 ]
  [ -9.37061501]
  [-10.87462902]
  [  7.8217063 ]
  [ -3.62981486]
  [  0.24418578]
  [ -2.28923392]
  [  2.22941232]
  [ -0.2961984 ]
  [-11.58084202]
  [-25.66054726]
  [ -2.65190148]
  [-18.32572556]
  [-31.27992821]
  [ -3.47984052]
  [-17.32374763]]

 [[  8.98670673]
  [-19.25129509]
  [-26.94365883]
  [ -4.0762248 ]
  [-13.3854351 ]
  [-10.75814533]
  [-12.38820934]
  [  7.19240332]
  [ -4.64440823]
  [ -0.54728204]
  [ -3.2137394 ]
  [  1.61949253]
  [ -1.20412135]
  [-13.11160755]
  [-27.92882156]
  [ -3.66600299]
  [-20.22352409]
  [-34.05604553]
  [ -4.55127764]
  [-19.11522865]]]
After layer sequencemask3_output (10, 20, 1) <class 'numpy.float32'> [[[  6.03166282e-01]
  [  2.62090951e-01]
  [  2.33673573e-01]
  [  4.48060334e-01]
  [  3.05632949e-01]
  [  3.62630934e-01]
  [  3.07230681e-01]
  [  5.76102495e-01]
  [  4.25213903e-01]
  [  4.77294952e-01]
  [  4.43865657e-01]
  [  4.81780946e-01]
  [  4.55418468e-01]
  [  3.15134764e-01]
  [  1.85470060e-01]
  [  4.47771937e-01]
  [  2.52920330e-01]
  [  1.39789119e-01]
  [  4.20865923e-01]
  [  2.70658076e-01]]

 [[  1.16711414e+00]
  [ -9.44091305e-02]
  [ -3.33544493e-01]
  [  6.70358717e-01]
  [  9.40552130e-02]
  [  3.11598092e-01]
  [  1.13368817e-01]
  [  1.04387414e+00]
  [  5.74880123e-01]
  [  7.96225488e-01]
  [  6.82477295e-01]
  [  8.70729387e-01]
  [  6.98354423e-01]
  [  1.30026668e-01]
  [ -4.84590888e-01]
  [  6.77223682e-01]
  [ -1.45568416e-01]
  [ -7.66904652e-01]
  [  5.65616250e-01]
  [ -6.79315180e-02]]

 [[ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]]
After layer swapaxes16_output (20, 10, 1) <class 'numpy.float32'> [[[  6.03166282e-01]
  [  1.16711414e+00]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  2.62090951e-01]
  [ -9.44091305e-02]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  2.33673573e-01]
  [ -3.33544493e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  4.48060334e-01]
  [  6.70358717e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  3.05632949e-01]
  [  9.40552130e-02]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  3.62630934e-01]
  [  3.11598092e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  3.07230681e-01]
  [  1.13368817e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  5.76102495e-01]
  [  1.04387414e+00]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  4.25213903e-01]
  [  5.74880123e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  4.77294952e-01]
  [  7.96225488e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  4.43865657e-01]
  [  6.82477295e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  4.81780946e-01]
  [  8.70729387e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  4.55418468e-01]
  [  6.98354423e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  3.15134764e-01]
  [  1.30026668e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  1.85470060e-01]
  [ -4.84590888e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  4.47771937e-01]
  [  6.77223682e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  2.52920330e-01]
  [ -1.45568416e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  1.39789119e-01]
  [ -7.66904652e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  4.20865923e-01]
  [  5.65616250e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  2.70658076e-01]
  [ -6.79315180e-02]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]]
After layer attention_softmax_0 (20, 10, 1) <class 'numpy.float32'> [[[ 0.36263448]
  [ 0.63736546]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.58819294]
  [ 0.41180709]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.63812101]
  [ 0.36187899]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.44465315]
  [ 0.55534691]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.55269802]
  [ 0.44730201]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.51275545]
  [ 0.48724455]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.54831421]
  [ 0.45168573]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.38514379]
  [ 0.61485618]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.4626531 ]
  [ 0.5373469 ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.42093638]
  [ 0.57906359]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.44062853]
  [ 0.55937147]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40397045]
  [ 0.59602952]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.43956295]
  [ 0.56043702]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.54614538]
  [ 0.45385468]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.66151679]
  [ 0.33848318]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.44288743]
  [ 0.55711257]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.59832454]
  [ 0.40167546]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.71232313]
  [ 0.28767687]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.46387547]
  [ 0.53612453]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.58384788]
  [ 0.41615212]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]]
After layer batch_dot3_0 (20, 512, 1) <class 'numpy.float32'> [[[ 0.01883349]
  [ 0.04057181]
  [-0.03525697]
  ...,
  [-0.01118071]
  [ 0.01004013]
  [-0.02388142]]

 [[ 0.01338885]
  [ 0.03428856]
  [-0.02510388]
  ...,
  [-0.00993312]
  [ 0.0097803 ]
  [-0.02786871]]

 [[ 0.01218366]
  [ 0.03289774]
  [-0.02285646]
  ...,
  [-0.00965696]
  [ 0.00972278]
  [-0.02875131]]

 ...,
 [[ 0.01039253]
  [ 0.03083073]
  [-0.01951639]
  ...,
  [-0.00924654]
  [ 0.0096373 ]
  [-0.03006301]]

 [[ 0.01638969]
  [ 0.0377516 ]
  [-0.0306998 ]
  ...,
  [-0.01062073]
  [ 0.00992351]
  [-0.0256711 ]]

 [[ 0.01349373]
  [ 0.03440959]
  [-0.02529946]
  ...,
  [-0.00995715]
  [ 0.0097853 ]
  [-0.0277919 ]]]
After layer reshape6_0 (20, 512) <class 'numpy.float32'> [[ 0.01883349  0.04057181 -0.03525697 ..., -0.01118071  0.01004013
  -0.02388142]
 [ 0.01338885  0.03428856 -0.02510388 ..., -0.00993312  0.0097803
  -0.02786871]
 [ 0.01218366  0.03289774 -0.02285646 ..., -0.00965696  0.00972278
  -0.02875131]
 ...,
 [ 0.01039253  0.03083073 -0.01951639 ..., -0.00924654  0.0096373
  -0.03006301]
 [ 0.01638969  0.0377516  -0.0306998  ..., -0.01062073  0.00992351
  -0.0256711 ]
 [ 0.01349373  0.03440959 -0.02529946 ..., -0.00995715  0.0097853
  -0.0277919 ]]
After layer decoder_rnn_hidden_concat_t0_output (20, 1024) <class 'numpy.float32'> [[-0.31717581 -0.05668377  0.14361231 ..., -0.01118071  0.01004013
  -0.02388142]
 [-0.19536656 -0.19636908  0.55598789 ..., -0.00993312  0.0097803
  -0.02786871]
 [-0.20131035 -0.23737724  0.69197357 ..., -0.00965696  0.00972278
  -0.02875131]
 ...,
 [-0.18800077 -0.30565867  0.69335383 ..., -0.00924654  0.0096373
  -0.03006301]
 [-0.23003775 -0.130933    0.39099404 ..., -0.01062073  0.00992351
  -0.0256711 ]
 [-0.1924466  -0.19358745  0.5754087  ..., -0.00995715  0.0097853
  -0.0277919 ]]
After layer decoder_rnn_hidden_fc_t0_output (20, 512) <class 'numpy.float32'> [[ 0.53577262 -1.93685114  1.77029824 ..., -0.66685873  1.57180679
   0.74302113]
 [-0.14553486 -1.57716978  1.62405562 ..., -0.35569447  1.90477037
  -1.31534207]
 [-0.42658344 -1.53758228  1.79190516 ..., -0.43061799  2.12318492
  -2.48886395]
 ...,
 [-0.08507451 -1.83628964  2.00034213 ..., -0.55338472  2.08131075
  -1.89350927]
 [ 0.02199353 -1.57061553  1.49837732 ..., -0.38398492  1.78282583
  -0.52443111]
 [-0.28068095 -1.41578615  1.51710129 ..., -0.3182478   1.93130708
  -1.61654747]]
After layer decoder_rnn_next_hidden_t0_output (20, 512) <class 'numpy.float32'> [[ 0.48978132 -0.95928359  0.94364208 ..., -0.5829097   0.91731268
   0.63096702]
 [-0.14451601 -0.91815877  0.92521036 ..., -0.34141597  0.956644
  -0.86562085]
 [-0.4024621  -0.91171318  0.94596124 ..., -0.40583766  0.9717719
  -0.98631489]
 ...,
 [-0.08486986 -0.95043772  0.96405172 ..., -0.50305271  0.96934384
  -0.95567834]
 [ 0.02198998 -0.91712362  0.9048546  ..., -0.36616313  0.94499826
  -0.48111269]
 [-0.27353519 -0.88871658  0.90819114 ..., -0.30792171  0.95883894
  -0.92412174]]
After layer logits_output (20, 16743) <class 'numpy.float32'> [[-1.93085706 -2.30457473 -1.50976837 ..., -2.54692912 -1.86188662
  -1.71285117]
 [-1.77139151 -3.36214209 -3.17167306 ..., -3.11639476 -3.13865161
  -3.10803986]
 [-1.83100617 -3.56135726 -3.82325864 ..., -3.03621769 -3.55229044
  -3.65023875]
 ...,
 [-1.76797664 -3.54951024 -3.56558228 ..., -2.99566078 -3.32600975
  -3.34458852]
 [-1.86211336 -3.04364872 -2.43579316 ..., -3.11172366 -2.74950528
  -2.60951471]
 [-1.83058274 -3.39698124 -3.40753627 ..., -3.14600492 -3.26423573
  -3.31670642]]
After layer softmax_0 (20, 16743) <class 'numpy.float32'> [[  4.16281000e-06   2.86472664e-06   6.34254093e-06 ...,   2.24817450e-06
    4.46005424e-06   5.17684794e-06]
 [  9.79623678e-07   1.99620445e-07   2.41504353e-07 ...,   2.55230049e-07
    2.49612185e-07   2.57371454e-07]
 [  5.55959581e-08   9.85284210e-09   7.58261542e-09 ...,   1.66581362e-08
    9.94258897e-09   9.01490615e-09]
 ...,
 [  2.02067014e-07   3.40239694e-08   3.34815269e-08 ...,   5.91996354e-08
    4.25451709e-08   4.17620072e-08]
 [  3.43049987e-06   1.05250206e-06   1.93290907e-06 ...,   9.83238124e-07
    1.41243322e-06   1.62466995e-06]
 [  5.22977700e-07   1.09195547e-07   1.08049001e-07 ...,   1.40346827e-07
    1.24696896e-07   1.18322603e-07]]
After layer reshape7_0 (20, 10) <class 'numpy.float32'> [[ 0.36263448  0.63736546  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.58819294  0.41180709  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.63812101  0.36187899  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.44465315  0.55534691  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.55269802  0.44730201  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.51275545  0.48724455  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.54831421  0.45168573  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.38514379  0.61485618  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.4626531   0.5373469   0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.42093638  0.57906359  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.44062853  0.55937147  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40397045  0.59602952  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.43956295  0.56043702  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.54614538  0.45385468  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.66151679  0.33848318  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.44288743  0.55711257  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.59832454  0.40167546  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.71232313  0.28767687  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.46387547  0.53612453  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.58384788  0.41615212  0.          0.          0.          0.          0.
   0.          0.          0.        ]]
After layer target_embed_embed_0 (20, 256) <class 'numpy.float32'> [[ 0.08892822  0.08123779 -0.08746338 ...,  0.04257202  0.08666992
   0.03131104]
 [ 0.08892822  0.08123779 -0.08746338 ...,  0.04257202  0.08666992
   0.03131104]
 [ 0.08892822  0.08123779 -0.08746338 ...,  0.04257202  0.08666992
   0.03131104]
 ...,
 [-0.01300049  0.11682129  0.06750488 ..., -0.10992432 -0.05990601
  -0.10571289]
 [-0.00485992  0.01457214  0.0317688  ..., -0.01901245 -0.00218773
   0.05514526]
 [-0.01300049  0.11682129  0.06750488 ..., -0.10992432 -0.05990601
  -0.10571289]]
After layer decoder_rnn_concat_target_context_t0_output (20, 768) <class 'numpy.float32'> [[ 0.08892822  0.08123779 -0.08746338 ..., -0.40583766  0.9717719
  -0.98631489]
 [ 0.08892822  0.08123779 -0.08746338 ..., -0.34141597  0.956644
  -0.86562085]
 [ 0.08892822  0.08123779 -0.08746338 ..., -0.24254666  0.95015794
  -0.8425715 ]
 ...,
 [-0.01300049  0.11682129  0.06750488 ..., -0.34141597  0.956644
  -0.86562085]
 [-0.00485992  0.01457214  0.0317688  ..., -0.5829097   0.91731268
   0.63096702]
 [-0.01300049  0.11682129  0.06750488 ..., -0.24254666  0.95015794
  -0.8425715 ]]
After layer decoder_rnn_l0_t0_i2h_output (20, 2048) <class 'numpy.float32'> [[-3.22672653  2.67707849  2.53137088 ...,  0.05387528  4.11125469
   1.98174071]
 [-3.20873785  2.72978997  2.24635339 ..., -0.33965459  3.91449165
   1.96271026]
 [-3.38229465  2.74955225  2.54257822 ..., -0.43428952  4.02804375
   1.56145012]
 ...,
 [-3.33188725  2.67775488  2.293679   ..., -0.1573742   3.91396523
   2.04061699]
 [-2.76209068  2.38770199  1.57725108 ..., -2.08087969  3.44421005
   1.10929966]
 [-3.50544405  2.6975174   2.58990407 ..., -0.25200945  4.02751732
   1.63935661]]
After layer decoder_rnn_l0_t0_h2h_output (20, 2048) <class 'numpy.float32'> [[-0.26986334  0.13075519  1.67267108 ...,  0.26095912  1.04054284
   1.1226896 ]
 [-0.30754232  0.17607836  1.60274172 ...,  0.04217031  1.02434039
   0.89024812]
 [-0.27894455  0.22107844  1.64356995 ...,  0.01292353  1.05049968
   0.78198701]
 ...,
 [-0.30754232  0.17607836  1.60274172 ...,  0.04217031  1.02434039
   0.89024812]
 [-0.40386865  0.366193    1.4115175  ..., -0.4735631   1.03939164
   0.56819165]
 [-0.27894455  0.22107844  1.64356995 ...,  0.01292353  1.05049968
   0.78198701]]
After layer _plus1048_0 (20, 2048) <class 'numpy.float32'> [[-3.4965899   2.80783367  4.20404196 ...,  0.31483442  5.15179729
   3.1044302 ]
 [-3.51628017  2.90586829  3.84909511 ..., -0.29748428  4.93883228
   2.85295844]
 [-3.66123915  2.97063065  4.18614817 ..., -0.42136598  5.07854366
   2.34343719]
 ...,
 [-3.63942957  2.8538332   3.89642072 ..., -0.11520389  4.93830585
   2.93086505]
 [-3.16595936  2.75389504  2.98876858 ..., -2.55444288  4.48360157
   1.67749131]
 [-3.78438854  2.91859579  4.23347378 ..., -0.23908593  5.07801723
   2.42134356]]
After layer decoder_rnn_l0_t0_slice_output0 (20, 512) <class 'numpy.float32'> [[-3.4965899   2.80783367  4.20404196 ...,  2.48671246  5.16729832
   1.89395761]
 [-3.51628017  2.90586829  3.84909511 ...,  2.2981813   5.02216387
   1.85063553]
 [-3.66123915  2.97063065  4.18614817 ...,  2.32782078  5.39293003
   1.77181387]
 ...,
 [-3.63942957  2.8538332   3.89642072 ...,  2.33963013  4.92324448
   1.96391928]
 [-3.16595936  2.75389504  2.98876858 ...,  2.21701026  4.83815289
   1.12873423]
 [-3.78438854  2.91859579  4.23347378 ...,  2.36926985  5.29401016
   1.88509762]]
After layer decoder_rnn_l0_t0_slice_output1 (20, 512) <class 'numpy.float32'> [[-2.93617725  2.36144447  2.56294489 ...,  3.02451038 -1.68135381
   2.05479836]
 [-3.08224964  2.29381871  2.34439158 ...,  2.50435972 -1.72712183
   1.86912906]
 [-2.90794897  1.98607588  2.40981627 ...,  2.4507947  -1.58157039
   1.89187002]
 ...,
 [-3.07198071  2.13506389  2.41739964 ...,  2.45202732 -1.72931337
   1.91861594]
 [-2.83815479  1.53868127  2.04842591 ...,  1.20969701 -0.95879704
   1.32508397]
 [-2.89767981  1.82732105  2.48282433 ...,  2.3984623  -1.58376193
   1.94135678]]
After layer decoder_rnn_l0_t0_slice_output2 (20, 512) <class 'numpy.float32'> [[-2.93321848 -4.31508446  3.89704585 ...,  5.28227043  2.44311857
   2.7165451 ]
 [-2.92251801 -3.93668747  3.43794346 ...,  4.94231558  1.01596332
   2.56303787]
 [-2.9336195  -3.75086546  3.3213644  ...,  4.88478565  0.52801108
   2.49524689]
 ...,
 [-2.88846898 -3.91550875  3.46501422 ...,  4.8844862   1.28760731
   2.56207132]
 [-3.10508299 -2.55927658  2.19954443 ...,  3.62512064 -2.64549708
   2.33945894]
 [-2.8995707  -3.72968674  3.34843493 ...,  4.8269558   0.79965478
   2.49428034]]
After layer decoder_rnn_l0_t0_slice_output3 (20, 512) <class 'numpy.float32'> [[-2.62994814  2.13076639 -0.3308413  ...,  0.31483442  5.15179729
   3.1044302 ]
 [-2.71887231  1.99137592 -0.48842636 ..., -0.29748428  4.93883228
   2.85295844]
 [-2.28018761  1.3502208  -0.42593104 ..., -0.42136598  5.07854366
   2.34343719]
 ...,
 [-2.8021102   1.52535963 -1.15280116 ..., -0.11520389  4.93830585
   2.93086505]
 [-1.50349808  0.73830342 -0.18509132 ..., -2.55444288  4.48360157
   1.67749131]
 [-2.36342621  0.8842051  -1.09030449 ..., -0.23908593  5.07801723
   2.42134356]]
After layer decoder_rnn_l0_t0_o_output (20, 512) <class 'numpy.float32'> [[ 0.0672357   0.89385772  0.41803595 ...,  0.57806486  0.99424428
   0.95707506]
 [ 0.06186888  0.87988859  0.38026434 ...,  0.42617258  0.99288803
   0.94547141]
 [ 0.09277716  0.79416573  0.39509836 ...,  0.39618993  0.99380964
   0.91241115]
 ...,
 [ 0.05721026  0.82132638  0.23997782 ...,  0.47123083  0.99288428
   0.94935125]
 [ 0.18190438  0.67662472  0.45385885 ...,  0.07212857  0.98883343
   0.84257209]
 [ 0.08600449  0.70769292  0.25156093 ...,  0.44051161  0.99380636
   0.91844046]]
After layer decoder_rnn_l0_t0_f_output (20, 512) <class 'numpy.float32'> [[ 0.05039389  0.91383958  0.92843837 ...,  0.95366925  0.15691628
   0.88643157]
 [ 0.04384541  0.90836382  0.91248739 ...,  0.92444694  0.15095609
   0.86635745]
 [ 0.05176201  0.87932736  0.91757274 ...,  0.92061955  0.17057319
   0.86896867]
 ...,
 [ 0.04427793  0.89426482  0.91814452 ...,  0.92070955  0.15067543
   0.871984  ]
 [ 0.05529685  0.82327294  0.88578844 ...,  0.77024531  0.27711913
   0.79002625]
 [ 0.05226838  0.86144233  0.92292893 ...,  0.91671002  0.17026336
   0.87450111]]
After layer _mul2096_0 (20, 512) <class 'numpy.float32'> [[-0.01737451 -0.85499054  1.08626568 ...,  1.22335947 -0.04849533
   0.87016124]
 [-0.0146565  -0.86633629  1.06633198 ...,  1.18551171 -0.06387937
   0.85590327]
 [-0.01994394 -0.81164038  1.0726074  ...,  1.18387878 -0.01982114
   0.87604278]
 ...,
 [-0.01480109 -0.8528896   1.07294285 ...,  1.1807189  -0.0637606
   0.86146194]
 [-0.02709865 -0.79587704  1.03426969 ...,  0.98888934 -0.09086315
   0.82200819]
 [-0.02013905 -0.7951321   1.07886863 ...,  1.17885125 -0.01978514
   0.88162023]]
After layer decoder_rnn_l0_t0_i_output (20, 512) <class 'numpy.float32'> [[ 0.02940941  0.94309771  0.98528463 ...,  0.92320508  0.99433231
   0.86920607]
 [ 0.02885254  0.94813573  0.97914517 ...,  0.90872633  0.99345291
   0.86420172]
 [ 0.02505667  0.95122957  0.98502296 ...,  0.9111551   0.99547195
   0.8546831 ]
 ...,
 [ 0.02559501  0.94551647  0.98009002 ...,  0.91210639  0.99277711
   0.87695646]
 [ 0.04046702  0.94013298  0.95206416 ...,  0.90176672  0.99214059
   0.75560522]
 [ 0.0222179   0.94875813  0.98570538 ...,  0.91445374  0.99500352
   0.86819559]]
After layer decoder_rnn_l0_t0_c_output (20, 512) <class 'numpy.float32'> [[-0.99435014 -0.99964279  0.99917603 ...,  0.99994838  0.9850136
   0.99129885]
 [-0.99422824 -0.99923879  0.99793738 ...,  0.99989808  0.76821727
   0.98819047]
 [-0.99435461 -0.99889636  0.99739647 ...,  0.99988568  0.48385927
   0.98648733]
 ...,
 [-0.99382275 -0.99920589  0.99804598 ...,  0.99988562  0.85849857
   0.98816776]
 [-0.99599028 -0.98810184  0.9757213  ...,  0.99858099 -0.989977
   0.98159289]
 [-0.993958   -0.99884862  0.9975335  ...,  0.99987167  0.66384375
   0.98646134]]
After layer _mul2097_0 (20, 512) <class 'numpy.float32'> [[-0.02924325 -0.94276083  0.98447275 ...,  0.92315745  0.97943085
   0.86164296]
 [-0.02868601 -0.94741398  0.97712559 ...,  0.90863371  0.76318765
   0.85399592]
 [-0.02491522 -0.95017976  0.98245841 ...,  0.91105092  0.48166832
   0.84313405]
 ...,
 [-0.0254369  -0.94476563  0.97817492 ...,  0.91200209  0.85229772
   0.86658013]
 [-0.04030476 -0.92894715  0.9289493  ...,  0.90048712 -0.98219639
   0.74169672]
 [-0.02208366 -0.94766575  0.98327416 ...,  0.91433638  0.66052687
   0.85644138]]
After layer decoder_rnn_l0_t0_state_0 (20, 512) <class 'numpy.float32'> [[-0.04661776 -1.79775143  2.07073832 ...,  2.1465168   0.9309355
   1.73180413]
 [-0.04334252 -1.81375027  2.04345751 ...,  2.0941453   0.69930828
   1.70989919]
 [-0.04485916 -1.76182008  2.05506587 ...,  2.0949297   0.46184719
   1.71917677]
 ...,
 [-0.04023799 -1.79765522  2.0511179  ...,  2.09272099  0.78853714
   1.72804213]
 [-0.06740341 -1.72482419  1.96321893 ...,  1.8893764  -1.07305956
   1.56370497]
 [-0.04222271 -1.74279785  2.06214285 ...,  2.09318757  0.64074171
   1.73806167]]
After layer activation1048_output (20, 512) <class 'numpy.float32'> [[-0.04658402 -0.94657266  0.96869898 ...,  0.97304153  0.73102975
   0.93926877]
 [-0.0433154  -0.94821155  0.96697265 ...,  0.97010911  0.60392851
   0.9366352 ]
 [-0.0448291  -0.94270593  0.96771836 ...,  0.9701553   0.43158853
   0.93776381]
 ...,
 [-0.04021629 -0.94656265  0.96746665 ...,  0.97002512  0.65757954
   0.93882412]
 [-0.06730152 -0.93844128  0.96133471 ...,  0.95531869 -0.79061115
   0.91601866]
 [-0.04219764 -0.94055027  0.96816486 ...,  0.97005266  0.56540442
   0.94000143]]
After layer decoder_rnn_l0_t0_out_0 (20, 512) <class 'numpy.float32'> [[-0.00313211 -0.84610128  0.40495101 ...,  0.56248111  0.72682214
   0.8989507 ]
 [-0.00267988 -0.83432055  0.36770523 ...,  0.41343391  0.5996334
   0.88556182]
 [-0.00415912 -0.74866474  0.38234395 ...,  0.38436577  0.42891684
   0.85562617]
 ...,
 [-0.00230078 -0.77743685  0.23217054 ...,  0.45710576  0.6529004
   0.89127386]
 [-0.01224244 -0.63497257  0.43631026 ...,  0.06890577 -0.78178275
   0.77181178]
 [-0.00362919 -0.66562074  0.24355245 ...,  0.42731947  0.56190252
   0.86333537]]
After layer expand_dims1057_0 (20, 512, 1) <class 'numpy.float32'> [[[-0.00313211]
  [-0.84610128]
  [ 0.40495101]
  ...,
  [ 0.56248111]
  [ 0.72682214]
  [ 0.8989507 ]]

 [[-0.00267988]
  [-0.83432055]
  [ 0.36770523]
  ...,
  [ 0.41343391]
  [ 0.5996334 ]
  [ 0.88556182]]

 [[-0.00415912]
  [-0.74866474]
  [ 0.38234395]
  ...,
  [ 0.38436577]
  [ 0.42891684]
  [ 0.85562617]]

 ...,
 [[-0.00230078]
  [-0.77743685]
  [ 0.23217054]
  ...,
  [ 0.45710576]
  [ 0.6529004 ]
  [ 0.89127386]]

 [[-0.01224244]
  [-0.63497257]
  [ 0.43631026]
  ...,
  [ 0.06890577]
  [-0.78178275]
  [ 0.77181178]]

 [[-0.00362919]
  [-0.66562074]
  [ 0.24355245]
  ...,
  [ 0.42731947]
  [ 0.56190252]
  [ 0.86333537]]]
After layer att_batch_dot_0 (20, 10, 1) <class 'numpy.float32'> [[[  5.39641380e-01]
  [  7.81891227e-01]
  [  1.41697788e+00]
  [  2.17156005e+00]
  [  2.00485778e+00]
  [ -5.64656407e-02]
  [ -2.97319794e+00]
  [ -5.46437740e+00]
  [ -7.29050064e+00]
  [ -8.66275978e+00]]

 [[  5.37979066e-01]
  [  7.19032943e-01]
  [  1.36208713e+00]
  [  2.08766556e+00]
  [  1.89608586e+00]
  [ -1.48349941e-01]
  [ -3.00551009e+00]
  [ -5.42057085e+00]
  [ -7.16598701e+00]
  [ -8.46020317e+00]]

 [[  5.15505791e-01]
  [  6.96860969e-01]
  [  1.41769457e+00]
  [  2.23988152e+00]
  [  2.13166881e+00]
  [  1.09938838e-01]
  [ -2.76774311e+00]
  [ -5.21059036e+00]
  [ -6.97527552e+00]
  [ -8.27842522e+00]]

 [[  5.22768795e-01]
  [  7.99433768e-01]
  [  1.47861540e+00]
  [  2.31637096e+00]
  [  2.26352000e+00]
  [  3.31145167e-01]
  [ -2.46708298e+00]
  [ -4.86678648e+00]
  [ -6.62179470e+00]
  [ -7.93382168e+00]]

 [[  5.53075194e-01]
  [  7.59045124e-01]
  [  1.35564959e+00]
  [  2.04257870e+00]
  [  1.82441485e+00]
  [ -2.26414606e-01]
  [ -3.08740687e+00]
  [ -5.51658392e+00]
  [ -7.28678226e+00]
  [ -8.61016655e+00]]

 [[  5.38833320e-01]
  [  7.31070340e-01]
  [  1.38560176e+00]
  [  2.13593745e+00]
  [  1.97990787e+00]
  [ -2.93880273e-02]
  [ -2.86313367e+00]
  [ -5.26712704e+00]
  [ -7.00909281e+00]
  [ -8.30278587e+00]]

 [[  5.31038046e-01]
  [  7.42627859e-01]
  [  1.41546607e+00]
  [  2.20190573e+00]
  [  2.08131504e+00]
  [  8.69203359e-02]
  [ -2.74966359e+00]
  [ -5.16115618e+00]
  [ -6.91128540e+00]
  [ -8.21350002e+00]]

 [[  5.30793488e-01]
  [  6.83636427e-01]
  [  1.36566782e+00]
  [  2.12151003e+00]
  [  1.95213437e+00]
  [ -8.87139812e-02]
  [ -2.95051289e+00]
  [ -5.36619091e+00]
  [ -7.10376310e+00]
  [ -8.38382435e+00]]

 [[  4.43904489e-01]
  [  1.12164885e-01]
  [  2.04984665e-01]
  [ -2.98332512e-01]
  [ -2.37874675e+00]
  [ -6.59186077e+00]
  [ -1.13320904e+01]
  [ -1.50710001e+01]
  [ -1.75892735e+01]
  [ -1.92756805e+01]]

 [[  5.13918400e-01]
  [  6.64430320e-01]
  [  1.37572396e+00]
  [  2.15953088e+00]
  [  2.00243640e+00]
  [ -5.62306829e-02]
  [ -2.95042753e+00]
  [ -5.39595175e+00]
  [ -7.15378094e+00]
  [ -8.44475079e+00]]

 [[  5.30104935e-01]
  [  6.41031623e-01]
  [  1.30680799e+00]
  [  2.00822735e+00]
  [  1.75827277e+00]
  [ -3.71748507e-01]
  [ -3.30699039e+00]
  [ -5.77256203e+00]
  [ -7.54078102e+00]
  [ -8.83971786e+00]]

 [[  9.31374788e-01]
  [  2.41692019e+00]
  [  5.28983402e+00]
  [  1.00351095e+01]
  [  1.58167543e+01]
  [  2.07136879e+01]
  [  2.42102814e+01]
  [  2.66681576e+01]
  [  2.82839565e+01]
  [  2.92190609e+01]]

 [[  5.23455977e-01]
  [  7.00180769e-01]
  [  1.42781878e+00]
  [  2.25935817e+00]
  [  2.19489026e+00]
  [  2.72703856e-01]
  [ -2.48528314e+00]
  [ -4.82804632e+00]
  [ -6.51415348e+00]
  [ -7.75339699e+00]]

 [[  5.13363361e-01]
  [  6.47241890e-01]
  [  1.36606944e+00]
  [  2.14821267e+00]
  [  1.99693489e+00]
  [ -3.71369198e-02]
  [ -2.89224100e+00]
  [ -5.29579926e+00]
  [ -7.01361179e+00]
  [ -8.26914215e+00]]

 [[  5.31245053e-01]
  [  6.56233728e-01]
  [  1.34823358e+00]
  [  2.09105277e+00]
  [  1.91646183e+00]
  [ -9.67196599e-02]
  [ -2.91099906e+00]
  [ -5.28403902e+00]
  [ -6.98372698e+00]
  [ -8.22795105e+00]]

 [[  6.42255962e-01]
  [  9.97664511e-01]
  [  2.44633055e+00]
  [  4.40845966e+00]
  [  6.26285124e+00]
  [  6.90673590e+00]
  [  6.63273954e+00]
  [  6.13101768e+00]
  [  5.59085464e+00]
  [  5.00710535e+00]]

 [[  5.06471336e-01]
  [  6.30861878e-01]
  [  1.34794807e+00]
  [  2.11443400e+00]
  [  1.93302548e+00]
  [ -1.42817408e-01]
  [ -3.04097795e+00]
  [ -5.48222208e+00]
  [ -7.23047876e+00]
  [ -8.50923538e+00]]

 [[  6.93584979e-01]
  [  1.40483963e+00]
  [  2.96219563e+00]
  [  5.33542252e+00]
  [  7.60951757e+00]
  [  8.44261265e+00]
  [  8.19322014e+00]
  [  7.73320580e+00]
  [  7.29798794e+00]
  [  6.84783173e+00]]

 [[  2.62193203e-01]
  [ -5.42968512e-01]
  [ -1.11342049e+00]
  [ -2.76686406e+00]
  [ -6.40481615e+00]
  [ -1.22657614e+01]
  [ -1.84748707e+01]
  [ -2.34391842e+01]
  [ -2.69728775e+01]
  [ -2.94861736e+01]]

 [[  6.73338354e-01]
  [  1.39447844e+00]
  [  3.03066158e+00]
  [  5.50650454e+00]
  [  7.88096094e+00]
  [  8.76797390e+00]
  [  8.53853893e+00]
  [  8.09039497e+00]
  [  7.66772938e+00]
  [  7.23102665e+00]]]
After layer swapaxes17_output (10, 20, 1) <class 'numpy.float32'> [[[  5.39641380e-01]
  [  5.37979066e-01]
  [  5.15505791e-01]
  [  5.22768795e-01]
  [  5.53075194e-01]
  [  5.38833320e-01]
  [  5.31038046e-01]
  [  5.30793488e-01]
  [  4.43904489e-01]
  [  5.13918400e-01]
  [  5.30104935e-01]
  [  9.31374788e-01]
  [  5.23455977e-01]
  [  5.13363361e-01]
  [  5.31245053e-01]
  [  6.42255962e-01]
  [  5.06471336e-01]
  [  6.93584979e-01]
  [  2.62193203e-01]
  [  6.73338354e-01]]

 [[  7.81891227e-01]
  [  7.19032943e-01]
  [  6.96860969e-01]
  [  7.99433768e-01]
  [  7.59045124e-01]
  [  7.31070340e-01]
  [  7.42627859e-01]
  [  6.83636427e-01]
  [  1.12164885e-01]
  [  6.64430320e-01]
  [  6.41031623e-01]
  [  2.41692019e+00]
  [  7.00180769e-01]
  [  6.47241890e-01]
  [  6.56233728e-01]
  [  9.97664511e-01]
  [  6.30861878e-01]
  [  1.40483963e+00]
  [ -5.42968512e-01]
  [  1.39447844e+00]]

 [[  1.41697788e+00]
  [  1.36208713e+00]
  [  1.41769457e+00]
  [  1.47861540e+00]
  [  1.35564959e+00]
  [  1.38560176e+00]
  [  1.41546607e+00]
  [  1.36566782e+00]
  [  2.04984665e-01]
  [  1.37572396e+00]
  [  1.30680799e+00]
  [  5.28983402e+00]
  [  1.42781878e+00]
  [  1.36606944e+00]
  [  1.34823358e+00]
  [  2.44633055e+00]
  [  1.34794807e+00]
  [  2.96219563e+00]
  [ -1.11342049e+00]
  [  3.03066158e+00]]

 [[  2.17156005e+00]
  [  2.08766556e+00]
  [  2.23988152e+00]
  [  2.31637096e+00]
  [  2.04257870e+00]
  [  2.13593745e+00]
  [  2.20190573e+00]
  [  2.12151003e+00]
  [ -2.98332512e-01]
  [  2.15953088e+00]
  [  2.00822735e+00]
  [  1.00351095e+01]
  [  2.25935817e+00]
  [  2.14821267e+00]
  [  2.09105277e+00]
  [  4.40845966e+00]
  [  2.11443400e+00]
  [  5.33542252e+00]
  [ -2.76686406e+00]
  [  5.50650454e+00]]

 [[  2.00485778e+00]
  [  1.89608586e+00]
  [  2.13166881e+00]
  [  2.26352000e+00]
  [  1.82441485e+00]
  [  1.97990787e+00]
  [  2.08131504e+00]
  [  1.95213437e+00]
  [ -2.37874675e+00]
  [  2.00243640e+00]
  [  1.75827277e+00]
  [  1.58167543e+01]
  [  2.19489026e+00]
  [  1.99693489e+00]
  [  1.91646183e+00]
  [  6.26285124e+00]
  [  1.93302548e+00]
  [  7.60951757e+00]
  [ -6.40481615e+00]
  [  7.88096094e+00]]

 [[ -5.64656407e-02]
  [ -1.48349941e-01]
  [  1.09938838e-01]
  [  3.31145167e-01]
  [ -2.26414606e-01]
  [ -2.93880273e-02]
  [  8.69203359e-02]
  [ -8.87139812e-02]
  [ -6.59186077e+00]
  [ -5.62306829e-02]
  [ -3.71748507e-01]
  [  2.07136879e+01]
  [  2.72703856e-01]
  [ -3.71369198e-02]
  [ -9.67196599e-02]
  [  6.90673590e+00]
  [ -1.42817408e-01]
  [  8.44261265e+00]
  [ -1.22657614e+01]
  [  8.76797390e+00]]

 [[ -2.97319794e+00]
  [ -3.00551009e+00]
  [ -2.76774311e+00]
  [ -2.46708298e+00]
  [ -3.08740687e+00]
  [ -2.86313367e+00]
  [ -2.74966359e+00]
  [ -2.95051289e+00]
  [ -1.13320904e+01]
  [ -2.95042753e+00]
  [ -3.30699039e+00]
  [  2.42102814e+01]
  [ -2.48528314e+00]
  [ -2.89224100e+00]
  [ -2.91099906e+00]
  [  6.63273954e+00]
  [ -3.04097795e+00]
  [  8.19322014e+00]
  [ -1.84748707e+01]
  [  8.53853893e+00]]

 [[ -5.46437740e+00]
  [ -5.42057085e+00]
  [ -5.21059036e+00]
  [ -4.86678648e+00]
  [ -5.51658392e+00]
  [ -5.26712704e+00]
  [ -5.16115618e+00]
  [ -5.36619091e+00]
  [ -1.50710001e+01]
  [ -5.39595175e+00]
  [ -5.77256203e+00]
  [  2.66681576e+01]
  [ -4.82804632e+00]
  [ -5.29579926e+00]
  [ -5.28403902e+00]
  [  6.13101768e+00]
  [ -5.48222208e+00]
  [  7.73320580e+00]
  [ -2.34391842e+01]
  [  8.09039497e+00]]

 [[ -7.29050064e+00]
  [ -7.16598701e+00]
  [ -6.97527552e+00]
  [ -6.62179470e+00]
  [ -7.28678226e+00]
  [ -7.00909281e+00]
  [ -6.91128540e+00]
  [ -7.10376310e+00]
  [ -1.75892735e+01]
  [ -7.15378094e+00]
  [ -7.54078102e+00]
  [  2.82839565e+01]
  [ -6.51415348e+00]
  [ -7.01361179e+00]
  [ -6.98372698e+00]
  [  5.59085464e+00]
  [ -7.23047876e+00]
  [  7.29798794e+00]
  [ -2.69728775e+01]
  [  7.66772938e+00]]

 [[ -8.66275978e+00]
  [ -8.46020317e+00]
  [ -8.27842522e+00]
  [ -7.93382168e+00]
  [ -8.61016655e+00]
  [ -8.30278587e+00]
  [ -8.21350002e+00]
  [ -8.38382435e+00]
  [ -1.92756805e+01]
  [ -8.44475079e+00]
  [ -8.83971786e+00]
  [  2.92190609e+01]
  [ -7.75339699e+00]
  [ -8.26914215e+00]
  [ -8.22795105e+00]
  [  5.00710535e+00]
  [ -8.50923538e+00]
  [  6.84783173e+00]
  [ -2.94861736e+01]
  [  7.23102665e+00]]]
After layer sequencemask4_output (10, 20, 1) <class 'numpy.float32'> [[[  5.39641380e-01]
  [  5.37979066e-01]
  [  5.15505791e-01]
  [  5.22768795e-01]
  [  5.53075194e-01]
  [  5.38833320e-01]
  [  5.31038046e-01]
  [  5.30793488e-01]
  [  4.43904489e-01]
  [  5.13918400e-01]
  [  5.30104935e-01]
  [  9.31374788e-01]
  [  5.23455977e-01]
  [  5.13363361e-01]
  [  5.31245053e-01]
  [  6.42255962e-01]
  [  5.06471336e-01]
  [  6.93584979e-01]
  [  2.62193203e-01]
  [  6.73338354e-01]]

 [[  7.81891227e-01]
  [  7.19032943e-01]
  [  6.96860969e-01]
  [  7.99433768e-01]
  [  7.59045124e-01]
  [  7.31070340e-01]
  [  7.42627859e-01]
  [  6.83636427e-01]
  [  1.12164885e-01]
  [  6.64430320e-01]
  [  6.41031623e-01]
  [  2.41692019e+00]
  [  7.00180769e-01]
  [  6.47241890e-01]
  [  6.56233728e-01]
  [  9.97664511e-01]
  [  6.30861878e-01]
  [  1.40483963e+00]
  [ -5.42968512e-01]
  [  1.39447844e+00]]

 [[ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]]
After layer swapaxes18_output (20, 10, 1) <class 'numpy.float32'> [[[  5.39641380e-01]
  [  7.81891227e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  5.37979066e-01]
  [  7.19032943e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  5.15505791e-01]
  [  6.96860969e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  5.22768795e-01]
  [  7.99433768e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  5.53075194e-01]
  [  7.59045124e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  5.38833320e-01]
  [  7.31070340e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  5.31038046e-01]
  [  7.42627859e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  5.30793488e-01]
  [  6.83636427e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  4.43904489e-01]
  [  1.12164885e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  5.13918400e-01]
  [  6.64430320e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  5.30104935e-01]
  [  6.41031623e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  9.31374788e-01]
  [  2.41692019e+00]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  5.23455977e-01]
  [  7.00180769e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  5.13363361e-01]
  [  6.47241890e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  5.31245053e-01]
  [  6.56233728e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  6.42255962e-01]
  [  9.97664511e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  5.06471336e-01]
  [  6.30861878e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  6.93584979e-01]
  [  1.40483963e+00]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  2.62193203e-01]
  [ -5.42968512e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  6.73338354e-01]
  [  1.39447844e+00]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]]
After layer attention_softmax_0 (20, 10, 1) <class 'numpy.float32'> [[[ 0.43973199]
  [ 0.56026798]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.45485976]
  [ 0.54514021]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.45478505]
  [ 0.54521495]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.43127161]
  [ 0.56872839]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.44868875]
  [ 0.55131119]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.45208821]
  [ 0.54791182]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.44729903]
  [ 0.552701  ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.46186349]
  [ 0.53813654]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.58218259]
  [ 0.41781741]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.4624429 ]
  [ 0.53755713]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.47229674]
  [ 0.52770329]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.18459128]
  [ 0.81540877]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.45593345]
  [ 0.54406661]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.46658027]
  [ 0.53341973]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.46879342]
  [ 0.53120655]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.4120715 ]
  [ 0.58792853]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.46894237]
  [ 0.5310576 ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.32932165]
  [ 0.67067832]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.69107753]
  [ 0.30892247]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.32714197]
  [ 0.67285806]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]]
After layer batch_dot4_0 (20, 512, 1) <class 'numpy.float32'> [[[ 0.01697247]
  [ 0.03842415]
  [-0.03178657]
  ...,
  [-0.01075428]
  [ 0.00995132]
  [-0.0252443 ]]

 [[ 0.01660731]
  [ 0.03800274]
  [-0.03110562]
  ...,
  [-0.0106706 ]
  [ 0.00993389]
  [-0.02551172]]

 [[ 0.01660912]
  [ 0.03800482]
  [-0.03110899]
  ...,
  [-0.01067101]
  [ 0.00993398]
  [-0.0255104 ]]

 ...,
 [[ 0.01963762]
  [ 0.04149979]
  [-0.03675649]
  ...,
  [-0.01136497]
  [ 0.01007851]
  [-0.02329254]]

 [[ 0.01090536]
  [ 0.03142256]
  [-0.02047272]
  ...,
  [-0.00936405]
  [ 0.00966177]
  [-0.02968744]]

 [[ 0.01969023]
  [ 0.04156051]
  [-0.03685461]
  ...,
  [-0.01137703]
  [ 0.01008102]
  [-0.02325401]]]
After layer reshape8_0 (20, 512) <class 'numpy.float32'> [[ 0.01697247  0.03842415 -0.03178657 ..., -0.01075428  0.00995132
  -0.0252443 ]
 [ 0.01660731  0.03800274 -0.03110562 ..., -0.0106706   0.00993389
  -0.02551172]
 [ 0.01660912  0.03800482 -0.03110899 ..., -0.01067101  0.00993398
  -0.0255104 ]
 ...,
 [ 0.01963762  0.04149979 -0.03675649 ..., -0.01136497  0.01007851
  -0.02329254]
 [ 0.01090536  0.03142256 -0.02047272 ..., -0.00936405  0.00966177
  -0.02968744]
 [ 0.01969023  0.04156051 -0.03685461 ..., -0.01137703  0.01008102
  -0.02325401]]
After layer decoder_rnn_hidden_concat_t0_output (20, 1024) <class 'numpy.float32'> [[-0.00313211 -0.84610128  0.40495101 ..., -0.01075428  0.00995132
  -0.0252443 ]
 [-0.00267988 -0.83432055  0.36770523 ..., -0.0106706   0.00993389
  -0.02551172]
 [-0.00415912 -0.74866474  0.38234395 ..., -0.01067101  0.00993398
  -0.0255104 ]
 ...,
 [-0.00230078 -0.77743685  0.23217054 ..., -0.01136497  0.01007851
  -0.02329254]
 [-0.01224244 -0.63497257  0.43631026 ..., -0.00936405  0.00966177
  -0.02968744]
 [-0.00362919 -0.66562074  0.24355245 ..., -0.01137703  0.01008102
  -0.02325401]]
After layer decoder_rnn_hidden_fc_t0_output (20, 512) <class 'numpy.float32'> [[-0.89646012 -0.55886674  0.1974113  ...,  0.73509681  2.06902766
  -1.63406789]
 [-0.85842311 -0.49243706  0.12805541 ...,  0.79787397  1.91479921
  -1.3317883 ]
 [-0.84631217 -0.73721921  0.30388331 ...,  0.81455243  1.91283166
  -1.1738503 ]
 ...,
 [-1.02710533  0.03685663 -0.46778712 ...,  1.03302145  1.7096014
  -0.95605654]
 [ 0.18273318 -1.98374462  1.84208238 ..., -0.44553867  1.95818198
  -0.63664174]
 [-1.01714206 -0.18933922 -0.30952853 ...,  1.03913081  1.71240258
  -0.81090832]]
After layer decoder_rnn_next_hidden_t0_output (20, 512) <class 'numpy.float32'> [[-0.71456987 -0.50713611  0.19488621 ...,  0.62617362  0.96859336
  -0.92663872]
 [-0.69544435 -0.45614856  0.12736002 ...,  0.66284651  0.95748663
  -0.86968571]
 [-0.68913794 -0.62746215  0.29486233 ...,  0.67209399  0.9573226
  -0.82550257]
 ...,
 [-0.77274477  0.03683995 -0.43640962 ...,  0.77511728  0.9365986
  -0.7425127 ]
 [ 0.18072608 -0.96286094  0.95099461 ..., -0.4182249   0.96095085
  -0.5626086 ]
 [-0.76869988 -0.18710865 -0.30000812 ...,  0.77754462  0.93694162
  -0.67009103]]
After layer logits_output (20, 16743) <class 'numpy.float32'> [[-1.81186056 -3.19129467 -2.8746717  ..., -2.44691396 -3.5231998
  -3.06332564]
 [-1.71240735 -3.05921388 -2.61624932 ..., -2.33328104 -3.36174655
  -2.89189172]
 [-1.63142431 -3.1286099  -2.50889397 ..., -2.35548306 -3.24887681
  -2.88416815]
 ...,
 [-1.87694311 -2.77214932 -2.16745567 ..., -2.07788873 -3.33791304
  -2.57160449]
 [-1.45822012 -3.23015141 -2.40708137 ..., -2.50978923 -2.79983521
  -2.66282749]
 [-1.81961358 -2.84415102 -2.06078005 ..., -2.1345582  -3.24462152
  -2.56894636]]
After layer softmax_0 (20, 16743) <class 'numpy.float32'> [[  9.78497383e-07   2.46308446e-07   3.38054519e-07 ...,   5.18513161e-07
    1.76739917e-07   2.79933829e-07]
 [  1.53509984e-06   3.99232562e-07   6.21731715e-07 ...,   8.25077450e-07
    2.95010523e-07   4.71946834e-07]
 [  1.89119260e-06   4.23171343e-07   7.86421538e-07 ...,   9.16813292e-07
    3.75219201e-07   5.40350641e-07]
 ...,
 [  3.76114758e-06   1.53651627e-06   2.81288612e-06 ...,   3.07645587e-06
    8.72628050e-07   1.87772696e-06]
 [  2.08226152e-06   3.53993727e-07   8.06213734e-07 ...,   7.27519591e-07
    5.44351508e-07   6.24282450e-07]
 [  4.09287713e-06   1.46918990e-06   3.21581888e-06 ...,   2.98710256e-06
    9.84363851e-07   1.93462756e-06]]
After layer reshape9_0 (20, 10) <class 'numpy.float32'> [[ 0.43973199  0.56026798  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.45485976  0.54514021  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.45478505  0.54521495  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.43127161  0.56872839  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.44868875  0.55131119  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.45208821  0.54791182  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.44729903  0.552701    0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.46186349  0.53813654  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.58218259  0.41781741  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.4624429   0.53755713  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.47229674  0.52770329  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.18459128  0.81540877  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.45593345  0.54406661  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.46658027  0.53341973  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.46879342  0.53120655  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.4120715   0.58792853  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.46894237  0.5310576   0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.32932165  0.67067832  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.69107753  0.30892247  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.32714197  0.67285806  0.          0.          0.          0.          0.
   0.          0.          0.        ]]
After layer target_embed_embed_0 (20, 256) <class 'numpy.float32'> [[-0.05505371 -0.0300293  -0.03598022 ...,  0.08459473 -0.05288696
  -0.01667786]
 [-0.05505371 -0.0300293  -0.03598022 ...,  0.08459473 -0.05288696
  -0.01667786]
 [ 0.08892822  0.08123779 -0.08746338 ...,  0.04257202  0.08666992
   0.03131104]
 ...,
 [-0.05505371 -0.0300293  -0.03598022 ...,  0.08459473 -0.05288696
  -0.01667786]
 [-0.05505371 -0.0300293  -0.03598022 ...,  0.08459473 -0.05288696
  -0.01667786]
 [ 0.20776367  0.12670898  0.05969238 ..., -0.14892578 -0.13439941
  -0.15319824]]
After layer decoder_rnn_concat_target_context_t0_output (20, 768) <class 'numpy.float32'> [[-0.05505371 -0.0300293  -0.03598022 ...,  0.62617362  0.96859336
  -0.92663872]
 [-0.05505371 -0.0300293  -0.03598022 ...,  0.66284651  0.95748663
  -0.86968571]
 [ 0.08892822  0.08123779 -0.08746338 ..., -0.31528223  0.96686369
  -0.92569005]
 ...,
 [-0.05505371 -0.0300293  -0.03598022 ...,  0.6498096   0.95088255
  -0.78739679]
 [-0.05505371 -0.0300293  -0.03598022 ...,  0.66213316  0.94736582
  -0.8122074 ]
 [ 0.20776367  0.12670898  0.05969238 ..., -0.31528223  0.96686369
  -0.92569005]]
After layer decoder_rnn_l0_t0_i2h_output (20, 2048) <class 'numpy.float32'> [[-3.43468666  2.07581282  2.44294691 ..., -0.25287718  4.05588627
   1.18592095]
 [-3.31573391  1.98734808  2.29681659 ..., -0.26869974  3.91974688
   1.20764017]
 [-3.18158531  2.360888    2.14065528 ..., -0.19690289  3.91910887
   2.08824015]
 ...,
 [-3.26754856  2.05468512  2.19884229 ..., -0.34140241  3.81973171
   1.34965205]
 [-3.21251869  1.94278026  2.18538213 ..., -0.25609082  3.79937601
   1.27563334]
 [-3.37827635  2.10064507  2.14973879 ...,  0.45667553  3.99106717
   2.52287722]]
After layer decoder_rnn_l0_t0_h2h_output (20, 2048) <class 'numpy.float32'> [[-0.45453295  0.27787045  1.70836043 ...,  0.43470913  1.13663793
   0.83527482]
 [-0.47172144  0.28060776  1.63006568 ...,  0.29739052  1.09385657
   0.75003862]
 [-0.57311255  0.20507668  1.70573151 ...,  0.05578732  1.15921688
   1.16433728]
 ...,
 [-0.5044474   0.32001847  1.63822794 ...,  0.13816197  1.09537625
   0.66463822]
 [-0.50895387  0.31783786  1.60000384 ...,  0.18108876  1.07005465
   0.6672228 ]
 [-0.57311255  0.20507668  1.70573151 ...,  0.05578732  1.15921688
   1.16433728]]
After layer _plus1049_0 (20, 2048) <class 'numpy.float32'> [[-3.88921952  2.35368323  4.15130711 ...,  0.18183196  5.19252396
   2.02119589]
 [-3.78745532  2.26795578  3.92688227 ...,  0.02869079  5.01360321
   1.95767879]
 [-3.7546978   2.5659647   3.84638691 ..., -0.14111556  5.07832575
   3.2525773 ]
 ...,
 [-3.77199602  2.37470365  3.83707023 ..., -0.20324044  4.91510773
   2.01429033]
 [-3.7214725   2.26061821  3.78538609 ..., -0.07500206  4.86943054
   1.94285607]
 [-3.95138884  2.30572176  3.85547018 ...,  0.51246285  5.15028381
   3.68721437]]
After layer decoder_rnn_l0_t0_slice_output0 (20, 512) <class 'numpy.float32'> [[-3.88921952  2.35368323  4.15130711 ...,  2.13202715  5.04983902
   2.51831198]
 [-3.78745532  2.26795578  3.92688227 ...,  1.9297353   4.84590721
   2.47970343]
 [-3.7546978   2.5659647   3.84638691 ...,  2.19359684  4.77611351
   2.00024271]
 ...,
 [-3.77199602  2.37470365  3.83707023 ...,  1.877828    4.75998878
   2.37197161]
 [-3.7214725   2.26061821  3.78538609 ...,  1.82785046  4.66562653
   2.38574505]
 [-3.95138884  2.30572176  3.85547018 ...,  2.27469492  4.65176058
   2.16015577]]
After layer decoder_rnn_l0_t0_slice_output1 (20, 512) <class 'numpy.float32'> [[-2.37952065  2.32650471  2.63264894 ...,  2.85060787 -1.39098454
   2.15068388]
 [-2.48331046  2.3695538   2.44471741 ...,  2.66737413 -1.37350345
   1.93342304]
 [-2.79745436  2.61622977  2.53570747 ...,  2.60834169 -1.90062141
   1.57549894]
 ...,
 [-2.78433013  2.4526844   2.32537532 ...,  2.53622508 -1.31682146
   1.74528897]
 [-2.65364528  2.40791941  2.29898739 ...,  2.51702523 -1.3376596
   1.66748452]
 [-2.75980282  1.82176948  2.59532309 ...,  2.73738766 -1.56928909
   1.76135767]]
After layer decoder_rnn_l0_t0_slice_output2 (20, 512) <class 'numpy.float32'> [[-2.86766768 -3.30146646  3.05373049 ...,  4.52761602  0.48801401
   2.13185811]
 [-2.70603275 -3.10686827  2.79062176 ...,  4.41862679  0.18703008
   2.04496813]
 [-2.83188581 -3.75744152  3.50935888 ...,  5.05757618  1.44553566
   2.20868921]
 ...,
 [-2.71509409 -3.0444355   2.69846153 ...,  4.49221897 -0.11851746
   2.07380176]
 [-2.58817863 -3.00087595  2.66475201 ...,  4.33505821 -0.05566466
   2.00303984]
 [-2.84917974 -3.68937254  3.51256132 ...,  5.10932922  2.38592243
   2.34668922]]
After layer decoder_rnn_l0_t0_slice_output3 (20, 512) <class 'numpy.float32'> [[-3.44892311  2.12888575 -1.27570009 ...,  0.18183196  5.19252396
   2.02119589]
 [-3.4128654   2.22586536 -1.32242215 ...,  0.02869079  5.01360321
   1.95767879]
 [-3.30580449  2.37184477 -0.68730253 ..., -0.14111556  5.07832575
   3.2525773 ]
 ...,
 [-3.4606452   2.26860714 -1.21401739 ..., -0.20324044  4.91510773
   2.01429033]
 [-3.4261713   2.34698081 -1.26822686 ..., -0.07500206  4.86943054
   1.94285607]
 [-3.35019732  0.92657948 -2.86697054 ...,  0.51246285  5.15028381
   3.68721437]]
After layer decoder_rnn_l0_t0_o_output (20, 512) <class 'numpy.float32'> [[ 0.03080099  0.89367914  0.21828306 ...,  0.54533315  0.99447268
   0.88300461]
 [ 0.0318958   0.90254831  0.21041559 ...,  0.50717223  0.993397    0.8762815 ]
 [ 0.0353726   0.91465497  0.33463341 ...,  0.4647795   0.99380821
   0.96276563]
 ...,
 [ 0.03045298  0.90624356  0.22899097 ...,  0.44936407  0.99271846
   0.88228935]
 [ 0.03148748  0.91269392  0.21956092 ...,  0.48125827  0.99238068
   0.87466556]
 [ 0.03388871  0.71638083  0.05381069 ...,  0.62538368  0.99423569
   0.97557008]]
After layer decoder_rnn_l0_t0_f_output (20, 512) <class 'numpy.float32'> [[ 0.08474773  0.91104847  0.93293351 ...,  0.94535017  0.19925062
   0.89573264]
 [ 0.07703649  0.91447598  0.9201743  ...,  0.93507379  0.20205441
   0.87362778]
 [ 0.05746189  0.93189877  0.92660749 ...,  0.93139654  0.13003816
   0.82856613]
 ...,
 [ 0.05817685  0.92075759  0.91095692 ...,  0.92664266  0.21134761
   0.85135764]
 [ 0.06576469  0.91742915  0.90879315 ...,  0.92532676  0.2078952
   0.84124017]
 [ 0.05953541  0.86077827  0.93055993 ...,  0.93919712  0.17231776
   0.85337961]]
After layer _mul2098_0 (20, 512) <class 'numpy.float32'> [[-0.00395075 -1.63783872  1.93186116 ...,  2.02921009  0.18548948
   1.55123353]
 [-0.00333896 -1.65863109  1.88033712 ...,  1.95818043  0.14129832
   1.49381542]
 [-0.0043576  -1.51850522  1.82266068 ...,  1.77272284 -0.13565202
   1.30346739]
 ...,
 [-0.00279681 -1.62667871  1.86398268 ...,  1.91266346 -0.02401617
   1.45059538]
 [-0.0031558  -1.63742149  1.83214808 ...,  1.88196659 -0.03993336
   1.42552459]
 [-0.00451485 -1.40261614  1.83043528 ...,  1.78756964 -0.17975688
   1.34250307]]
After layer decoder_rnn_l0_t0_i_output (20, 512) <class 'numpy.float32'> [[ 0.02005104  0.9132266   0.98450017 ...,  0.89397728  0.99363047
   0.92541569]
 [ 0.02215138  0.90618813  0.98067576 ...,  0.87322009  0.99220079
   0.9227066 ]
 [ 0.02287214  0.9286387   0.97908974 ...,  0.89967304  0.99164176
   0.8808226 ]
 ...,
 [ 0.02248872  0.91487789  0.97889829 ...,  0.86736143  0.99150711
   0.91466486]
 [ 0.02362658  0.90556252  0.97780377 ...,  0.86150545  0.99067444
   0.91573381]
 [ 0.01886524  0.9093498   0.97927493 ...,  0.9067595   0.99054551
   0.89661402]]
After layer decoder_rnn_l0_t0_c_output (20, 512) <class 'numpy.float32'> [[-0.99356121 -0.99729091  0.99555749 ...,  0.99976647  0.45263875
   0.97225058]
 [-0.9911148  -0.99600452  0.99249256 ...,  0.99970961  0.18487938
   0.96707064]
 [-0.99308521 -0.99891078  0.99821168 ...,  0.99991906  0.89480656
   0.97615606]
 ...,
 [-0.9912737  -0.99547434  0.99097985 ...,  0.99974936 -0.11796565
   0.96888715]
 [-0.98876637 -0.99506336  0.99035382 ...,  0.9996568  -0.05560724
   0.96424174]
 [-0.99331945 -0.998752    0.99822307 ...,  0.99992704  0.98321259
   0.98185474]]
After layer _mul2099_0 (20, 512) <class 'numpy.float32'> [[-0.01992194 -0.91075259  0.9801265  ...,  0.89376849  0.44975564
   0.89973593]
 [-0.02195456 -0.90256745  0.97331339 ...,  0.87296653  0.18343747
   0.89232248]
 [-0.02271399 -0.92762721  0.97733879 ...,  0.89960021  0.88732755
   0.85982031]
 ...,
 [-0.02229248 -0.91073745  0.97006845 ...,  0.86714405 -0.11696377
   0.88620704]
 [-0.02336117 -0.90109211  0.96837169 ...,  0.86120975 -0.05508867
   0.88298875]
 [-0.01873921 -0.90821493  0.97753483 ...,  0.90669334  0.97391683
   0.88034469]]
After layer decoder_rnn_l0_t0_state_0 (20, 512) <class 'numpy.float32'> [[-0.02387268 -2.54859138  2.91198778 ...,  2.92297864  0.63524508
   2.45096946]
 [-0.02529351 -2.56119847  2.85365057 ...,  2.83114696  0.32473579
   2.38613796]
 [-0.02707159 -2.44613242  2.79999948 ...,  2.67232299  0.75167555
   2.16328764]
 ...,
 [-0.02508929 -2.53741622  2.83405113 ...,  2.77980757 -0.14097995
   2.33680248]
 [-0.02651697 -2.53851366  2.8005197  ...,  2.74317646 -0.09502202
   2.3085134 ]
 [-0.02325406 -2.31083107  2.80797005 ...,  2.69426298  0.79415995
   2.2228477 ]]
After layer activation1049_output (20, 512) <class 'numpy.float32'> [[-0.02386815 -0.98784643  0.99410576 ...,  0.99423355  0.56165326
   0.98524535]
 [-0.02528812 -0.98814726  0.99337876 ...,  0.99307501  0.31378275
   0.9832198 ]
 [-0.02706498 -0.98510295  0.99263149 ...,  0.99049807  0.6361475
   0.97391915]
 ...,
 [-0.02508402 -0.98757344  0.99311495 ...,  0.992329   -0.1400533
   0.98149574]
 [-0.02651076 -0.98760051  0.99263912 ...,  0.99174833 -0.09473706
   0.98042911]
 [-0.02324986 -0.98051876  0.9927476  ...,  0.99090415  0.66075921
   0.97681403]]
After layer decoder_rnn_l0_t0_out_0 (20, 512) <class 'numpy.float32'> [[ -7.35162699e-04  -8.82817745e-01   2.16996446e-01 ...,   5.42188525e-01
    5.58548808e-01   8.69976163e-01]
 [ -8.06584721e-04  -8.91850650e-01   2.09022373e-01 ...,   5.03660083e-01
    3.11710835e-01   8.61577332e-01]
 [ -9.57358745e-04  -9.01029289e-01   3.32167655e-01 ...,   4.60363179e-01
    6.32208586e-01   9.37655866e-01]
 ...,
 [ -7.63883232e-04  -8.94982100e-01   2.27414355e-01 ...,   4.45916981e-01
   -1.39033496e-01   8.65963221e-01]
 [ -8.34756996e-04  -9.01376963e-01   2.17944756e-01 ...,   4.77287084e-01
   -9.40152258e-02   8.57547581e-01]
 [ -7.87907804e-04  -7.02424824e-01   5.34204319e-02 ...,   6.19695306e-01
    6.56950414e-01   9.52950537e-01]]
After layer expand_dims1058_0 (20, 512, 1) <class 'numpy.float32'> [[[ -7.35162699e-04]
  [ -8.82817745e-01]
  [  2.16996446e-01]
  ...,
  [  5.42188525e-01]
  [  5.58548808e-01]
  [  8.69976163e-01]]

 [[ -8.06584721e-04]
  [ -8.91850650e-01]
  [  2.09022373e-01]
  ...,
  [  5.03660083e-01]
  [  3.11710835e-01]
  [  8.61577332e-01]]

 [[ -9.57358745e-04]
  [ -9.01029289e-01]
  [  3.32167655e-01]
  ...,
  [  4.60363179e-01]
  [  6.32208586e-01]
  [  9.37655866e-01]]

 ...,
 [[ -7.63883232e-04]
  [ -8.94982100e-01]
  [  2.27414355e-01]
  ...,
  [  4.45916981e-01]
  [ -1.39033496e-01]
  [  8.65963221e-01]]

 [[ -8.34756996e-04]
  [ -9.01376963e-01]
  [  2.17944756e-01]
  ...,
  [  4.77287084e-01]
  [ -9.40152258e-02]
  [  8.57547581e-01]]

 [[ -7.87907804e-04]
  [ -7.02424824e-01]
  [  5.34204319e-02]
  ...,
  [  6.19695306e-01]
  [  6.56950414e-01]
  [  9.52950537e-01]]]
After layer att_batch_dot_0 (20, 10, 1) <class 'numpy.float32'> [[[  0.45088649]
  [  0.72581649]
  [  1.25826836]
  [  1.89594996]
  [  1.45668709]
  [ -1.04843354]
  [ -4.43973827]
  [ -7.34449577]
  [ -9.49201965]
  [-11.08162785]]

 [[  0.45656955]
  [  0.70669901]
  [  1.23215652]
  [  1.84583354]
  [  1.35816753]
  [ -1.21392345]
  [ -4.6674962 ]
  [ -7.61171007]
  [ -9.77279186]
  [-11.35874557]]

 [[  0.53980422]
  [  0.71441174]
  [  1.28835559]
  [  1.88453555]
  [  1.42238331]
  [ -1.01719761]
  [ -4.26540375]
  [ -6.99862766]
  [ -8.98928642]
  [-10.46448803]]

 [[  0.47749415]
  [  0.72059071]
  [  1.29922485]
  [  1.97150016]
  [  1.55914271]
  [ -0.92802262]
  [ -4.29803944]
  [ -7.16129398]
  [ -9.24643135]
  [-10.76947975]]

 [[  0.44397828]
  [  0.72788912]
  [  1.26265192]
  [  1.91151631]
  [  1.47309589]
  [ -1.05213821]
  [ -4.47752333]
  [ -7.41963053]
  [ -9.59620285]
  [-11.2024889 ]]

 [[  0.4424988 ]
  [  0.69968915]
  [  1.1924634 ]
  [  1.76984036]
  [  1.24210882]
  [ -1.36736739]
  [ -4.8563056 ]
  [ -7.84019947]
  [-10.04565048]
  [-11.67374134]]

 [[  0.58527374]
  [  0.70788789]
  [  1.27471328]
  [  1.84376919]
  [  1.41190374]
  [ -0.90233064]
  [ -3.99262571]
  [ -6.60132885]
  [ -8.50180054]
  [ -9.909338  ]]

 [[  0.45420733]
  [  0.7077207 ]
  [  1.23582113]
  [  1.85603821]
  [  1.37835526]
  [ -1.18385756]
  [ -4.63192844]
  [ -7.57574844]
  [ -9.73935795]
  [-11.32837772]]

 [[  0.45598921]
  [  0.71771759]
  [  1.26179612]
  [  1.90855742]
  [  1.46619725]
  [ -1.05951774]
  [ -4.4770565 ]
  [ -7.39802408]
  [ -9.54532146]
  [-11.12348175]]

 [[  0.46837631]
  [  0.70004058]
  [  1.24689722]
  [  1.87174582]
  [  1.3937999 ]
  [ -1.16739357]
  [ -4.60542631]
  [ -7.52454424]
  [ -9.65329933]
  [-11.20785904]]

 [[  0.98218781]
  [  2.4404285 ]
  [  5.30632877]
  [  9.99850464]
  [ 15.66745377]
  [ 20.41321754]
  [ 23.75090599]
  [ 26.05507851]
  [ 27.54443359]
  [ 28.39147377]]

 [[  0.47143281]
  [  0.83125633]
  [  1.65980196]
  [  2.72622061]
  [  2.81794238]
  [  0.8186897 ]
  [ -2.18112803]
  [ -4.82953978]
  [ -6.82062674]
  [ -8.31301117]]

 [[  0.48617291]
  [  0.84059954]
  [  1.71059203]
  [  2.81888723]
  [  2.96922374]
  [  1.0448761 ]
  [ -1.87483287]
  [ -4.4434576 ]
  [ -6.3601141 ]
  [ -7.7916975 ]]

 [[  0.47814947]
  [  0.70237958]
  [  1.2693994 ]
  [  1.90899599]
  [  1.44767785]
  [ -1.09215093]
  [ -4.50383997]
  [ -7.39218855]
  [ -9.4884901 ]
  [-11.01474476]]

 [[  0.48261493]
  [  0.68874842]
  [  1.23809969]
  [  1.84377623]
  [  1.3486191 ]
  [ -1.20996416]
  [ -4.62460852]
  [ -7.50614977]
  [ -9.59416676]
  [-11.11481476]]

 [[  0.68705243]
  [  1.67940474]
  [  3.99608779]
  [  7.51698351]
  [ 11.29819584]
  [ 13.67358971]
  [ 14.64363384]
  [ 14.85145283]
  [ 14.57704067]
  [ 13.97706413]]

 [[  0.45939249]
  [  0.69462937]
  [  1.24209154]
  [  1.8683573 ]
  [  1.37660754]
  [ -1.22010326]
  [ -4.70501852]
  [ -7.67212772]
  [ -9.84001827]
  [-11.42112255]]

 [[  0.4759492 ]
  [  0.68660039]
  [  1.24613011]
  [  1.86433291]
  [  1.37007725]
  [ -1.20655715]
  [ -4.64950705]
  [ -7.5594058 ]
  [ -9.66792202]
  [-11.20013428]]

 [[  0.46235114]
  [  0.67319262]
  [  1.19878149]
  [  1.77487063]
  [  1.21831   ]
  [ -1.43733037]
  [ -4.96124506]
  [ -7.94688272]
  [-10.12150192]
  [-11.7049284 ]]

 [[  0.94099766]
  [  2.4537394 ]
  [  5.32294846]
  [ 10.05268764]
  [ 15.73815346]
  [ 20.45162201]
  [ 23.7438755 ]
  [ 26.01951218]
  [ 27.48245239]
  [ 28.29540825]]]
After layer swapaxes19_output (10, 20, 1) <class 'numpy.float32'> [[[  0.45088649]
  [  0.45656955]
  [  0.53980422]
  [  0.47749415]
  [  0.44397828]
  [  0.4424988 ]
  [  0.58527374]
  [  0.45420733]
  [  0.45598921]
  [  0.46837631]
  [  0.98218781]
  [  0.47143281]
  [  0.48617291]
  [  0.47814947]
  [  0.48261493]
  [  0.68705243]
  [  0.45939249]
  [  0.4759492 ]
  [  0.46235114]
  [  0.94099766]]

 [[  0.72581649]
  [  0.70669901]
  [  0.71441174]
  [  0.72059071]
  [  0.72788912]
  [  0.69968915]
  [  0.70788789]
  [  0.7077207 ]
  [  0.71771759]
  [  0.70004058]
  [  2.4404285 ]
  [  0.83125633]
  [  0.84059954]
  [  0.70237958]
  [  0.68874842]
  [  1.67940474]
  [  0.69462937]
  [  0.68660039]
  [  0.67319262]
  [  2.4537394 ]]

 [[  1.25826836]
  [  1.23215652]
  [  1.28835559]
  [  1.29922485]
  [  1.26265192]
  [  1.1924634 ]
  [  1.27471328]
  [  1.23582113]
  [  1.26179612]
  [  1.24689722]
  [  5.30632877]
  [  1.65980196]
  [  1.71059203]
  [  1.2693994 ]
  [  1.23809969]
  [  3.99608779]
  [  1.24209154]
  [  1.24613011]
  [  1.19878149]
  [  5.32294846]]

 [[  1.89594996]
  [  1.84583354]
  [  1.88453555]
  [  1.97150016]
  [  1.91151631]
  [  1.76984036]
  [  1.84376919]
  [  1.85603821]
  [  1.90855742]
  [  1.87174582]
  [  9.99850464]
  [  2.72622061]
  [  2.81888723]
  [  1.90899599]
  [  1.84377623]
  [  7.51698351]
  [  1.8683573 ]
  [  1.86433291]
  [  1.77487063]
  [ 10.05268764]]

 [[  1.45668709]
  [  1.35816753]
  [  1.42238331]
  [  1.55914271]
  [  1.47309589]
  [  1.24210882]
  [  1.41190374]
  [  1.37835526]
  [  1.46619725]
  [  1.3937999 ]
  [ 15.66745377]
  [  2.81794238]
  [  2.96922374]
  [  1.44767785]
  [  1.3486191 ]
  [ 11.29819584]
  [  1.37660754]
  [  1.37007725]
  [  1.21831   ]
  [ 15.73815346]]

 [[ -1.04843354]
  [ -1.21392345]
  [ -1.01719761]
  [ -0.92802262]
  [ -1.05213821]
  [ -1.36736739]
  [ -0.90233064]
  [ -1.18385756]
  [ -1.05951774]
  [ -1.16739357]
  [ 20.41321754]
  [  0.8186897 ]
  [  1.0448761 ]
  [ -1.09215093]
  [ -1.20996416]
  [ 13.67358971]
  [ -1.22010326]
  [ -1.20655715]
  [ -1.43733037]
  [ 20.45162201]]

 [[ -4.43973827]
  [ -4.6674962 ]
  [ -4.26540375]
  [ -4.29803944]
  [ -4.47752333]
  [ -4.8563056 ]
  [ -3.99262571]
  [ -4.63192844]
  [ -4.4770565 ]
  [ -4.60542631]
  [ 23.75090599]
  [ -2.18112803]
  [ -1.87483287]
  [ -4.50383997]
  [ -4.62460852]
  [ 14.64363384]
  [ -4.70501852]
  [ -4.64950705]
  [ -4.96124506]
  [ 23.7438755 ]]

 [[ -7.34449577]
  [ -7.61171007]
  [ -6.99862766]
  [ -7.16129398]
  [ -7.41963053]
  [ -7.84019947]
  [ -6.60132885]
  [ -7.57574844]
  [ -7.39802408]
  [ -7.52454424]
  [ 26.05507851]
  [ -4.82953978]
  [ -4.4434576 ]
  [ -7.39218855]
  [ -7.50614977]
  [ 14.85145283]
  [ -7.67212772]
  [ -7.5594058 ]
  [ -7.94688272]
  [ 26.01951218]]

 [[ -9.49201965]
  [ -9.77279186]
  [ -8.98928642]
  [ -9.24643135]
  [ -9.59620285]
  [-10.04565048]
  [ -8.50180054]
  [ -9.73935795]
  [ -9.54532146]
  [ -9.65329933]
  [ 27.54443359]
  [ -6.82062674]
  [ -6.3601141 ]
  [ -9.4884901 ]
  [ -9.59416676]
  [ 14.57704067]
  [ -9.84001827]
  [ -9.66792202]
  [-10.12150192]
  [ 27.48245239]]

 [[-11.08162785]
  [-11.35874557]
  [-10.46448803]
  [-10.76947975]
  [-11.2024889 ]
  [-11.67374134]
  [ -9.909338  ]
  [-11.32837772]
  [-11.12348175]
  [-11.20785904]
  [ 28.39147377]
  [ -8.31301117]
  [ -7.7916975 ]
  [-11.01474476]
  [-11.11481476]
  [ 13.97706413]
  [-11.42112255]
  [-11.20013428]
  [-11.7049284 ]
  [ 28.29540825]]]
After layer sequencemask5_output (10, 20, 1) <class 'numpy.float32'> [[[  4.50886488e-01]
  [  4.56569552e-01]
  [  5.39804220e-01]
  [  4.77494150e-01]
  [  4.43978280e-01]
  [  4.42498803e-01]
  [  5.85273743e-01]
  [  4.54207331e-01]
  [  4.55989212e-01]
  [  4.68376309e-01]
  [  9.82187808e-01]
  [  4.71432805e-01]
  [  4.86172915e-01]
  [  4.78149474e-01]
  [  4.82614934e-01]
  [  6.87052429e-01]
  [  4.59392488e-01]
  [  4.75949198e-01]
  [  4.62351143e-01]
  [  9.40997660e-01]]

 [[  7.25816488e-01]
  [  7.06699014e-01]
  [  7.14411736e-01]
  [  7.20590711e-01]
  [  7.27889121e-01]
  [  6.99689150e-01]
  [  7.07887888e-01]
  [  7.07720697e-01]
  [  7.17717588e-01]
  [  7.00040579e-01]
  [  2.44042850e+00]
  [  8.31256330e-01]
  [  8.40599537e-01]
  [  7.02379584e-01]
  [  6.88748419e-01]
  [  1.67940474e+00]
  [  6.94629371e-01]
  [  6.86600387e-01]
  [  6.73192620e-01]
  [  2.45373940e+00]]

 [[ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]]
After layer swapaxes20_output (20, 10, 1) <class 'numpy.float32'> [[[  4.50886488e-01]
  [  7.25816488e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  4.56569552e-01]
  [  7.06699014e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  5.39804220e-01]
  [  7.14411736e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  4.77494150e-01]
  [  7.20590711e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  4.43978280e-01]
  [  7.27889121e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  4.42498803e-01]
  [  6.99689150e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  5.85273743e-01]
  [  7.07887888e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  4.54207331e-01]
  [  7.07720697e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  4.55989212e-01]
  [  7.17717588e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  4.68376309e-01]
  [  7.00040579e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  9.82187808e-01]
  [  2.44042850e+00]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  4.71432805e-01]
  [  8.31256330e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  4.86172915e-01]
  [  8.40599537e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  4.78149474e-01]
  [  7.02379584e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  4.82614934e-01]
  [  6.88748419e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  6.87052429e-01]
  [  1.67940474e+00]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  4.59392488e-01]
  [  6.94629371e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  4.75949198e-01]
  [  6.86600387e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  4.62351143e-01]
  [  6.73192620e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  9.40997660e-01]
  [  2.45373940e+00]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]]
After layer attention_softmax_0 (20, 10, 1) <class 'numpy.float32'> [[[ 0.43169719]
  [ 0.56830281]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.43779165]
  [ 0.56220835]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.45645869]
  [ 0.54354131]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.4395234 ]
  [ 0.56047666]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.42949525]
  [ 0.57050472]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.4360545 ]
  [ 0.56394547]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.46938479]
  [ 0.53061521]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.43695891]
  [ 0.56304103]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.43493885]
  [ 0.56506109]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.44234154]
  [ 0.55765843]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.18873656]
  [ 0.8112635 ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.41100228]
  [ 0.58899772]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.41230941]
  [ 0.58769065]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.4441762 ]
  [ 0.55582386]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.44864833]
  [ 0.55135167]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.27044767]
  [ 0.72955227]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.44146046]
  [ 0.55853951]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.44753107]
  [ 0.5524689 ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.44748402]
  [ 0.55251598]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.18053281]
  [ 0.81946719]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]]
After layer batch_dot5_0 (20, 512, 1) <class 'numpy.float32'> [[[ 0.01716642]
  [ 0.03864797]
  [-0.03214825]
  ...,
  [-0.01079872]
  [ 0.00996058]
  [-0.02510227]]

 [[ 0.01701931]
  [ 0.0384782 ]
  [-0.03187392]
  ...,
  [-0.01076501]
  [ 0.00995355]
  [-0.02521   ]]

 [[ 0.01656872]
  [ 0.0379582 ]
  [-0.03103365]
  ...,
  [-0.01066176]
  [ 0.00993205]
  [-0.02553999]]

 ...,
 [[ 0.01678422]
  [ 0.03820689]
  [-0.03143551]
  ...,
  [-0.01071114]
  [ 0.00994234]
  [-0.02538217]]

 [[ 0.01678535]
  [ 0.03820821]
  [-0.03143763]
  ...,
  [-0.0107114 ]
  [ 0.00994239]
  [-0.02538134]]

 [[ 0.02322916]
  [ 0.04564451]
  [-0.04345394]
  ...,
  [-0.01218794]
  [ 0.01024991]
  [-0.02066233]]]
After layer reshape10_0 (20, 512) <class 'numpy.float32'> [[ 0.01716642  0.03864797 -0.03214825 ..., -0.01079872  0.00996058
  -0.02510227]
 [ 0.01701931  0.0384782  -0.03187392 ..., -0.01076501  0.00995355 -0.02521   ]
 [ 0.01656872  0.0379582  -0.03103365 ..., -0.01066176  0.00993205
  -0.02553999]
 ...,
 [ 0.01678422  0.03820689 -0.03143551 ..., -0.01071114  0.00994234
  -0.02538217]
 [ 0.01678535  0.03820821 -0.03143763 ..., -0.0107114   0.00994239
  -0.02538134]
 [ 0.02322916  0.04564451 -0.04345394 ..., -0.01218794  0.01024991
  -0.02066233]]
After layer decoder_rnn_hidden_concat_t0_output (20, 1024) <class 'numpy.float32'> [[ -7.35162699e-04  -8.82817745e-01   2.16996446e-01 ...,  -1.07987178e-02
    9.96057596e-03  -2.51022708e-02]
 [ -8.06584721e-04  -8.91850650e-01   2.09022373e-01 ...,  -1.07650086e-02
    9.95355472e-03  -2.52100043e-02]
 [ -9.57358745e-04  -9.01029289e-01   3.32167655e-01 ...,  -1.06617585e-02
    9.93205048e-03  -2.55399905e-02]
 ...,
 [ -7.63883232e-04  -8.94982100e-01   2.27414355e-01 ...,  -1.07111372e-02
    9.94233508e-03  -2.53821742e-02]
 [ -8.34756996e-04  -9.01376963e-01   2.17944756e-01 ...,  -1.07113980e-02
    9.94239002e-03  -2.53813416e-02]
 [ -7.87907804e-04  -7.02424824e-01   5.34204319e-02 ...,  -1.21879438e-02
    1.02499137e-02  -2.06623338e-02]]
After layer decoder_rnn_hidden_fc_t0_output (20, 512) <class 'numpy.float32'> [[-1.33925092 -0.09671852 -0.38329229 ...,  1.48771489  1.97043765
  -1.3389957 ]
 [-1.37764001 -0.02220864 -0.46554509 ...,  1.51253152  1.92476428
  -1.32371724]
 [-0.93282419 -0.47252411  0.04728953 ...,  0.86066771  2.00812626
  -1.46408749]
 ...,
 [-1.36324859 -0.07001102 -0.42509145 ...,  1.47193301  1.87342238
  -1.2905587 ]
 [-1.39976454 -0.00629793 -0.49401498 ...,  1.50332403  1.88678086
  -1.32553875]
 [-1.3563962   0.7881813  -1.38440442 ...,  1.25984633  1.55816853
  -0.54789847]]
After layer decoder_rnn_next_hidden_t0_output (20, 512) <class 'numpy.float32'> [[-0.87149221 -0.09641806 -0.36556321 ...,  0.90290338  0.96187836
  -0.87143081]
 [-0.8804217  -0.02220499 -0.43459281 ...,  0.90738726  0.95830804
  -0.86770535]
 [-0.7319079  -0.44023651  0.04725431 ...,  0.69660151  0.96459723
  -0.89844358]
 ...,
 [-0.8771444  -0.06989685 -0.40121102 ...,  0.89994556  0.95390338
  -0.85927278]
 [-0.88530076 -0.00629785 -0.45739725 ...,  0.90574712  0.95509136
  -0.86815476]
 [-0.87555456  0.65737748 -0.88193369 ...,  0.85102177  0.91512322
  -0.49894351]]
After layer logits_output (20, 16743) <class 'numpy.float32'> [[-1.76888323 -2.91732025 -2.36528659 ..., -2.10288239 -3.36203432
  -2.53068447]
 [-1.77791953 -2.85296464 -2.34018183 ..., -2.08249116 -3.3366313
  -2.49988127]
 [-1.75809753 -3.07882142 -2.66559434 ..., -2.32488656 -3.41872621
  -2.88211441]
 ...,
 [-1.74427092 -2.83638215 -2.29529119 ..., -2.07472944 -3.27408314
  -2.51123118]
 [-1.7765125  -2.8176043  -2.32562304 ..., -2.07954979 -3.29828358
  -2.49146819]
 [-2.00305009 -2.33175159 -1.79416633 ..., -1.88718128 -3.13689637
  -2.21904612]]
After layer softmax_0 (20, 16743) <class 'numpy.float32'> [[  1.58536352e-06   5.02769353e-07   8.73200236e-07 ...,   1.13520593e-06
    3.22279078e-07   7.40086591e-07]
 [  1.61107141e-06   5.49830531e-07   9.18178785e-07 ...,   1.18806770e-06
    3.38980868e-07   7.82656400e-07]
 [  1.17903926e-06   3.14735217e-07   4.75781547e-07 ...,   6.68921416e-07
    2.24040534e-07   3.83154543e-07]
 ...,
 [  1.68668544e-06   5.65895789e-07   9.72141038e-07 ...,   1.21204334e-06
    3.65296302e-07   7.83335054e-07]
 [  1.58932710e-06   5.61142031e-07   9.17777129e-07 ...,   1.17383127e-06
    3.46989509e-07   7.77520256e-07]
 [  4.36125174e-06   3.13947976e-06   5.37437563e-06 ...,   4.89702416e-06
    1.40342104e-06   3.51402923e-06]]
After layer reshape11_0 (20, 10) <class 'numpy.float32'> [[ 0.43169719  0.56830281  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.43779165  0.56220835  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.45645869  0.54354131  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.4395234   0.56047666  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.42949525  0.57050472  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.4360545   0.56394547  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.46938479  0.53061521  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.43695891  0.56304103  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.43493885  0.56506109  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.44234154  0.55765843  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.18873656  0.8112635   0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.41100228  0.58899772  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.41230941  0.58769065  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.4441762   0.55582386  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.44864833  0.55135167  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.27044767  0.72955227  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.44146046  0.55853951  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.44753107  0.5524689   0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.44748402  0.55251598  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.18053281  0.81946719  0.          0.          0.          0.          0.
   0.          0.          0.        ]]
After layer target_embed_embed_0 (20, 256) <class 'numpy.float32'> [[-0.05505371 -0.0300293  -0.03598022 ...,  0.08459473 -0.05288696
  -0.01667786]
 [-0.05505371 -0.0300293  -0.03598022 ...,  0.08459473 -0.05288696
  -0.01667786]
 [-0.05505371 -0.0300293  -0.03598022 ...,  0.08459473 -0.05288696
  -0.01667786]
 ...,
 [ 0.14013672  0.20153809 -0.07067871 ..., -0.01544189 -0.08544922
  -0.18017578]
 [ 0.13598633  0.02095032  0.05236816 ..., -0.01808167 -0.03991699
  -0.14160156]
 [ 0.07489014  0.07629395 -0.05102539 ..., -0.04281616 -0.05935669
   0.00090504]]
After layer decoder_rnn_concat_target_context_t0_output (20, 768) <class 'numpy.float32'> [[-0.05505371 -0.0300293  -0.03598022 ...,  0.90290338  0.96187836
  -0.87143081]
 [-0.05505371 -0.0300293  -0.03598022 ...,  0.90738726  0.95830804
  -0.86770535]
 [-0.05505371 -0.0300293  -0.03598022 ...,  0.69660151  0.96459723
  -0.89844358]
 ...,
 [ 0.14013672  0.20153809 -0.07067871 ...,  0.85102177  0.91512322
  -0.49894351]
 [ 0.13598633  0.02095032  0.05236816 ...,  0.71639872  0.92938209
   0.78765088]
 [ 0.07489014  0.07629395 -0.05102539 ...,  0.82456219  0.90445703
  -0.45529756]]
After layer decoder_rnn_l0_t0_i2h_output (20, 2048) <class 'numpy.float32'> [[-3.1602025   1.70883393  2.3033092  ..., -0.19924659  3.84805822
   0.80726635]
 [-3.1091969   1.66427159  2.2849164  ..., -0.16870189  3.80103254
   0.78233206]
 [-3.28722811  1.92045617  2.3106246  ..., -0.23480867  3.9487958
   1.20463121]
 ...,
 [-3.27441168  1.69204092  2.64570594 ..., -3.15322948  3.52027178
  -0.25536039]
 [-2.93644524  1.98287904  1.71467566 ..., -2.18732953  3.28679371
   1.52837133]
 [-3.25828934  1.34888816  2.5550952  ..., -0.78568494  3.55564785
  -0.17546093]]
After layer decoder_rnn_l0_t0_h2h_output (20, 2048) <class 'numpy.float32'> [[-0.41726127  0.3711811   1.72239375 ...,  0.49719486  1.26813912
   0.31670058]
 [-0.43309373  0.38995466  1.68604589 ...,  0.50798672  1.23635161
   0.2934126 ]
 [-0.56486869  0.3220855   1.69480932 ...,  0.38825318  1.16249049
   0.76631761]
 ...,
 [-0.59501159  0.52151185  1.72491133 ...,  0.22551136  1.14864194
   0.01486472]
 [-0.51457429  0.58938956  1.59054959 ..., -0.32211122  1.32806575
   0.03897531]
 [-0.5775367   0.51643109  1.64890599 ...,  0.2189728   1.11109376
   0.01791369]]
After layer _plus1050_0 (20, 2048) <class 'numpy.float32'> [[-3.57746387  2.08001494  4.02570295 ...,  0.29794827  5.11619759
   1.12396693]
 [-3.54229069  2.05422616  3.97096229 ...,  0.33928484  5.03738403
   1.07574463]
 [-3.8520968   2.24254179  4.00543404 ...,  0.15344451  5.11128616
   1.97094882]
 ...,
 [-3.86942339  2.21355271  4.37061739 ..., -2.92771816  4.66891384
  -0.24049567]
 [-3.45101953  2.57226849  3.30522537 ..., -2.50944066  4.61485958
   1.56734669]
 [-3.83582592  1.86531925  4.20400143 ..., -0.56671214  4.66674137
  -0.15754725]]
After layer decoder_rnn_l0_t0_slice_output0 (20, 512) <class 'numpy.float32'> [[-3.57746387  2.08001494  4.02570295 ...,  1.86617255  4.61015987
   2.64748454]
 [-3.54229069  2.05422616  3.97096229 ...,  1.79991555  4.53897667
   2.61279774]
 [-3.8520968   2.24254179  4.00543404 ...,  2.04402113  4.81207848
   2.49333239]
 ...,
 [-3.86942339  2.21355271  4.37061739 ...,  1.7931602   5.10041332
   2.51975441]
 [-3.45101953  2.57226849  3.30522537 ...,  2.01344299  4.31814671
   1.69191861]
 [-3.83582592  1.86531925  4.20400143 ...,  1.60687757  5.04329967
   2.35165763]]
After layer decoder_rnn_l0_t0_slice_output1 (20, 512) <class 'numpy.float32'> [[-2.15320063  2.35710931  2.27185488 ...,  2.97025061 -1.04584527
   2.02526903]
 [-2.15359378  2.33246183  2.25558829 ...,  2.92851377 -1.04139113
   1.92642307]
 [-2.39398193  2.41080904  2.62904263 ...,  2.78865957 -1.4583354
   1.98606992]
 ...,
 [-0.74054456  1.52596772  2.41228175 ...,  2.34013128 -0.2349298
   1.97269499]
 [-2.53036022  1.70211315  1.75221694 ...,  1.97744322  0.31291902
   1.32844663]
 [-1.65083814  1.84408963  2.25711775 ...,  2.0662291  -0.5906741
   1.56984985]]
After layer decoder_rnn_l0_t0_slice_output2 (20, 512) <class 'numpy.float32'> [[-2.79116488 -3.02078223  2.72753453 ...,  4.26429939 -0.18607581
   2.12812424]
 [-2.70883369 -2.98004603  2.68245912 ...,  4.18089771 -0.23408931
   2.09123039]
 [-2.72843218 -3.18101454  2.91867208 ...,  4.39773369  0.22766192
   2.03743482]
 ...,
 [-2.52348256 -2.27249026  1.85289192 ...,  3.57563353 -2.47751212
   1.45298219]
 [-3.08972549 -2.17980003  1.54610741 ...,  3.72278309 -2.85498023
   2.10547113]
 [-2.41638255 -2.07736874  1.81064892 ...,  3.45509958 -2.69367003
   1.3197844 ]]
After layer decoder_rnn_l0_t0_slice_output3 (20, 512) <class 'numpy.float32'> [[-3.41819     2.47120619 -1.46638882 ...,  0.29794827  5.11619759
   1.12396693]
 [-3.36773729  2.5075829  -1.48937047 ...,  0.33928484  5.03738403
   1.07574463]
 [-3.51761198  2.37335348 -1.42859125 ...,  0.15344451  5.11128616
   1.97094882]
 ...,
 [-1.71398473 -0.75676644 -3.11604023 ..., -2.92771816  4.66891384
  -0.24049567]
 [-2.79944301  0.33478177 -2.71267962 ..., -2.50944066  4.61485958
   1.56734669]
 [-2.2814796   0.9346174  -2.14868426 ..., -0.56671214  4.66674137
  -0.15754725]]
After layer decoder_rnn_l0_t0_o_output (20, 512) <class 'numpy.float32'> [[ 0.0317318   0.92209846  0.18749212 ...,  0.57394087  0.99403703
   0.75472379]
 [ 0.03331911  0.92467171  0.18401623 ...,  0.5840168   0.99355114
   0.74568784]
 [ 0.02881525  0.91477269  0.19331828 ...,  0.53828603  0.99400783
   0.87771302]
 ...,
 [ 0.1526476   0.31934872  0.04245044 ...,  0.05080024  0.99070472
   0.44016421]
 [ 0.05735428  0.5829224   0.06222929 ...,  0.075199    0.99019355
   0.82740504]
 [ 0.09266847  0.71801114  0.10445424 ...,  0.36199585  0.99068475
   0.46069443]]
After layer decoder_rnn_l0_t0_f_output (20, 512) <class 'numpy.float32'> [[ 0.10403252  0.91349769  0.90651911 ...,  0.95121187  0.26002371
   0.8834247 ]
 [ 0.10399588  0.91153008  0.90513146 ...,  0.94923812  0.26088166
   0.87285304]
 [ 0.08363276  0.91764784  0.93270749 ...,  0.94205987  0.18872204
   0.8793267 ]
 ...,
 [ 0.32288507  0.8214156   0.91775906 ...,  0.91214657  0.44153619
   0.8779003 ]
 [ 0.07375704  0.84581047  0.85223222 ...,  0.87840831  0.57759756
   0.79058355]
 [ 0.16099571  0.86343163  0.90526271 ...,  0.88757724  0.35648021
   0.82776219]]
After layer _mul2100_0 (20, 512) <class 'numpy.float32'> [[ -2.48353556e-03  -2.32813239e+00   2.63977265e+00 ...,   2.78037190e+00
    1.65178791e-01   2.16524696e+00]
 [ -2.63042096e-03  -2.33460951e+00   2.58292890e+00 ...,   2.68743253e+00
    8.47176164e-02   2.08274770e+00]
 [ -2.26407195e-03  -2.24468803e+00   2.61158037e+00 ...,   2.51748824e+00
    1.41857743e-01   1.90223658e+00]
 ...,
 [ -7.50838732e-03  -1.89815271e+00   2.57703996e+00 ...,   2.45756269e+00
    3.50650370e-01   1.95143867e+00]
 [ -2.49257148e-03  -1.90784597e+00   2.38404775e+00 ...,   2.41805577e+00
   -3.31341594e-01   1.87398016e+00]
 [ -5.13504818e-03  -2.03043890e+00   2.47450233e+00 ...,   2.31657004e+00
    2.61107594e-01   1.79000878e+00]]
After layer decoder_rnn_l0_t0_i_output (20, 512) <class 'numpy.float32'> [[ 0.02718671  0.88894552  0.98246217 ...,  0.86601478  0.99014777
   0.93385577]
 [ 0.02813259  0.886374    0.98149359 ...,  0.85813862  0.98942858
   0.93168068]
 [ 0.02079361  0.90400523  0.98210955 ...,  0.88534212  0.99193466
   0.92367309]
 ...,
 [ 0.02044373  0.90145999  0.98751438 ...,  0.85731435  0.99394268
   0.92551512]
 [ 0.03073847  0.92905533  0.96460766 ...,  0.88220131  0.98685068
   0.84447634]
 [ 0.0211275   0.86591572  0.98528409 ...,  0.83297741  0.99358892
   0.91306585]]
After layer decoder_rnn_l0_t0_c_output (20, 512) <class 'numpy.float32'> [[-0.99250066 -0.99525559  0.99148721 ...,  0.99960464 -0.18395756
   0.97204548]
 [-0.99116421 -0.99485391  0.99068785 ...,  0.99953288 -0.22990514
   0.96993697]
 [-0.9915024  -0.9965542   0.99418378 ...,  0.99969721  0.22380856
   0.96657908]
 ...,
 [-0.98722452 -0.97898245  0.95201755 ...,  0.99843347 -0.9860028   0.896281  ]
 [-0.99586546 -0.9747557   0.91314095 ...,  0.99883264 -0.99339628
   0.97076881]
 [-0.9841969  -0.96910495  0.94789773 ...,  0.99800688 -0.99089342
   0.86673033]]
After layer _mul2101_0 (20, 512) <class 'numpy.float32'> [[-0.02698283 -0.88472801  0.97409868 ...,  0.86567241 -0.18214516
   0.90775031]
 [-0.02788402 -0.88181263  0.97235376 ...,  0.85773778 -0.22747472
   0.9036715 ]
 [-0.02061691 -0.90089023  0.9763974  ...,  0.88507402  0.22200346
   0.89280307]
 ...,
 [-0.02018255 -0.88251352  0.94013101 ...,  0.85597134 -0.98003024
   0.8295216 ]
 [-0.03061138 -0.90560198  0.88082278 ...,  0.88117146 -0.98033381
   0.81979132]
 [-0.02079362 -0.83916318  0.93394858 ...,  0.83131719 -0.98454076
   0.7913819 ]]
After layer decoder_rnn_l0_t0_state_0 (20, 512) <class 'numpy.float32'> [[-0.02946636 -3.21286035  3.61387134 ...,  3.64604425 -0.01696637
   3.07299733]
 [-0.03051444 -3.21642208  3.55528259 ...,  3.54517031 -0.1427571
   2.9864192 ]
 [-0.02288098 -3.14557838  3.58797789 ...,  3.40256214  0.3638612
   2.79503965]
 ...,
 [-0.02769094 -2.78066635  3.51717091 ...,  3.31353402 -0.62937987
   2.78096032]
 [-0.03310395 -2.81344795  3.26487064 ...,  3.29922724 -1.31167543
   2.69377136]
 [-0.02592867 -2.8696022   3.40845084 ...,  3.14788723 -0.72343314
   2.58139062]]
After layer activation1050_output (20, 512) <class 'numpy.float32'> [[-0.02945784 -0.99676651  0.99854875 ...,  0.99863911 -0.01696474
   0.9957251 ]
 [-0.03050497 -0.9967894   0.99836844 ...,  0.99833518 -0.14179517
   0.99491894]
 [-0.02287699 -0.99630159  0.99847168 ...,  0.99778628  0.34861055
   0.9925583 ]
 ...,
 [-0.02768387 -0.99234211  0.99823934 ...,  0.9973554  -0.55762506
   0.99234664]
 [-0.03309186 -0.99282634  0.99708551 ...,  0.99727875 -0.86469877
   0.99089527]
 [-0.02592286 -0.993586    0.99781215 ...,  0.99631864 -0.61903137
   0.98861367]]
After layer decoder_rnn_l0_t0_out_0 (20, 512) <class 'numpy.float32'> [[ -9.34750133e-04  -9.19116855e-01   1.87220022e-01 ...,   5.73159814e-01
   -1.68635845e-02   7.51497388e-01]
 [ -1.01639854e-03  -9.21702981e-01   1.83715999e-01 ...,   5.83044529e-01
   -1.40880749e-01   7.41898954e-01]
 [ -6.59206242e-04  -9.11389470e-01   1.93022832e-01 ...,   5.37094414e-01
    3.46521616e-01   8.71181369e-01]
 ...,
 [ -4.22587572e-03  -3.16903174e-01   4.23757024e-02 ...,   5.06658964e-02
   -5.52441776e-01   4.36795473e-01]
 [ -1.89795997e-03  -5.78740716e-01   6.20479248e-02 ...,   7.49943629e-02
   -8.56219113e-01   8.19871724e-01]
 [ -2.40223180e-03  -7.13405848e-01   1.04225710e-01 ...,   3.60663205e-01
   -6.13264918e-01   4.55448806e-01]]
After layer expand_dims1059_0 (20, 512, 1) <class 'numpy.float32'> [[[ -9.34750133e-04]
  [ -9.19116855e-01]
  [  1.87220022e-01]
  ...,
  [  5.73159814e-01]
  [ -1.68635845e-02]
  [  7.51497388e-01]]

 [[ -1.01639854e-03]
  [ -9.21702981e-01]
  [  1.83715999e-01]
  ...,
  [  5.83044529e-01]
  [ -1.40880749e-01]
  [  7.41898954e-01]]

 [[ -6.59206242e-04]
  [ -9.11389470e-01]
  [  1.93022832e-01]
  ...,
  [  5.37094414e-01]
  [  3.46521616e-01]
  [  8.71181369e-01]]

 ...,
 [[ -4.22587572e-03]
  [ -3.16903174e-01]
  [  4.23757024e-02]
  ...,
  [  5.06658964e-02]
  [ -5.52441776e-01]
  [  4.36795473e-01]]

 [[ -1.89795997e-03]
  [ -5.78740716e-01]
  [  6.20479248e-02]
  ...,
  [  7.49943629e-02]
  [ -8.56219113e-01]
  [  8.19871724e-01]]

 [[ -2.40223180e-03]
  [ -7.13405848e-01]
  [  1.04225710e-01]
  ...,
  [  3.60663205e-01]
  [ -6.13264918e-01]
  [  4.55448806e-01]]]
After layer att_batch_dot_0 (20, 10, 1) <class 'numpy.float32'> [[[  0.48183256]
  [  0.83909076]
  [  1.43976569]
  [  2.23131919]
  [  1.97624993]
  [ -0.36030367]
  [ -3.62211132]
  [ -6.44999313]
  [ -8.55053043]
  [-10.10455704]]

 [[  0.48316121]
  [  0.82721364]
  [  1.42888868]
  [  2.21472168]
  [  1.93780148]
  [ -0.44066027]
  [ -3.74823904]
  [ -6.61161089]
  [ -8.73407841]
  [-10.29879284]]

 [[  0.45320377]
  [  0.7143324 ]
  [  1.2157861 ]
  [  1.79864728]
  [  1.24658144]
  [ -1.42031336]
  [ -4.96253204]
  [ -7.97807312]
  [-10.1933279 ]
  [-11.81497955]]

 [[  0.48907787]
  [  0.82680535]
  [  1.44906425]
  [  2.25758243]
  [  1.99738503]
  [ -0.38230556]
  [ -3.70278931]
  [ -6.57588625]
  [ -8.70034504]
  [-10.26205349]]

 [[  0.48379922]
  [  0.84465998]
  [  1.45311606]
  [  2.25777602]
  [  2.01659441]
  [ -0.31126934]
  [ -3.56976604]
  [ -6.39860964]
  [ -8.50113487]
  [-10.05600071]]

 [[  0.47839373]
  [  0.82945621]
  [  1.41431963]
  [  2.1810863 ]
  [  1.89267659]
  [ -0.47859189]
  [ -3.76875854]
  [ -6.6181283 ]
  [ -8.73443031]
  [-10.29911804]]

 [[  0.45022538]
  [  0.67581666]
  [  1.1204313 ]
  [  1.60605133]
  [  0.91670626]
  [ -1.90226173]
  [ -5.57556391]
  [ -8.68771839]
  [-10.96858406]
  [-12.63179016]]

 [[  0.4829981 ]
  [  0.82914954]
  [  1.43250191]
  [  2.22191262]
  [  1.95178533]
  [ -0.41733477]
  [ -3.71641707]
  [ -6.57392883]
  [ -8.69263268]
  [-10.25490856]]

 [[  0.48521081]
  [  0.83416128]
  [  1.44546294]
  [  2.24758363]
  [  1.99325585]
  [ -0.36137143]
  [ -3.64998627]
  [ -6.50036478]
  [ -8.61405087]
  [-10.17293549]]

 [[  0.4852227 ]
  [  0.8199622 ]
  [  1.42915475]
  [  2.21823335]
  [  1.9351989 ]
  [ -0.4634819 ]
  [ -3.79655027]
  [ -6.67858505]
  [ -8.81002998]
  [-10.37684631]]

 [[  0.5071044 ]
  [  0.82703656]
  [  1.47151446]
  [  2.27168107]
  [  2.00324082]
  [ -0.36219633]
  [ -3.6458292 ]
  [ -6.47544527]
  [ -8.56188583]
  [-10.09833241]]

 [[  0.69278258]
  [  1.68034315]
  [  3.97895932]
  [  7.47095966]
  [ 11.18866253]
  [ 13.46785259]
  [ 14.33636856]
  [ 14.45060921]
  [ 14.09714985]
  [ 13.4402914 ]]

 [[  0.51097065]
  [  0.82336622]
  [  1.48151624]
  [  2.29260302]
  [  2.02892065]
  [ -0.34409297]
  [ -3.64072633]
  [ -6.47702932]
  [ -8.56224442]
  [-10.09390736]]

 [[  0.44668326]
  [  0.66434234]
  [  1.36012101]
  [  2.02580452]
  [  1.25608301]
  [ -2.03445005]
  [ -6.33842087]
  [ -9.98304272]
  [-12.57792377]
  [-14.36468029]]

 [[  0.48713073]
  [  0.81643271]
  [  1.42996037]
  [  2.22015667]
  [  1.93125939]
  [ -0.48283097]
  [ -3.83368349]
  [ -6.72810316]
  [ -8.86569881]
  [-10.43480873]]

 [[  0.51458985]
  [  0.89013308]
  [  2.22278166]
  [  4.0064497 ]
  [  5.29688358]
  [  4.84645653]
  [  3.29798794]
  [  1.67186642]
  [  0.24361864]
  [ -0.99153465]]

 [[  0.48404077]
  [  0.80774033]
  [  1.40924668]
  [  2.17980003]
  [  1.86904311]
  [ -0.56142378]
  [ -3.92144418]
  [ -6.81882143]
  [ -8.95633602]
  [-10.524683  ]]

 [[  0.69130009]
  [  1.70263886]
  [  4.02597904]
  [  7.559062  ]
  [ 11.33212471]
  [ 13.67587757]
  [ 14.61170673]
  [ 14.78807831]
  [ 14.48266792]
  [ 13.85552883]]

 [[  0.70560861]
  [  1.3513236 ]
  [  3.14631534]
  [  5.67311668]
  [  8.16843796]
  [  9.322052  ]
  [  9.39704323]
  [  9.10906601]
  [  8.65215778]
  [  8.0621357 ]]

 [[  0.42244118]
  [  0.59500241]
  [  1.51078904]
  [  2.55180645]
  [  2.64612341]
  [  0.71506745]
  [ -2.20614505]
  [ -4.85417891]
  [ -6.92983294]
  [ -8.53370953]]]
After layer swapaxes21_output (10, 20, 1) <class 'numpy.float32'> [[[  0.48183256]
  [  0.48316121]
  [  0.45320377]
  [  0.48907787]
  [  0.48379922]
  [  0.47839373]
  [  0.45022538]
  [  0.4829981 ]
  [  0.48521081]
  [  0.4852227 ]
  [  0.5071044 ]
  [  0.69278258]
  [  0.51097065]
  [  0.44668326]
  [  0.48713073]
  [  0.51458985]
  [  0.48404077]
  [  0.69130009]
  [  0.70560861]
  [  0.42244118]]

 [[  0.83909076]
  [  0.82721364]
  [  0.7143324 ]
  [  0.82680535]
  [  0.84465998]
  [  0.82945621]
  [  0.67581666]
  [  0.82914954]
  [  0.83416128]
  [  0.8199622 ]
  [  0.82703656]
  [  1.68034315]
  [  0.82336622]
  [  0.66434234]
  [  0.81643271]
  [  0.89013308]
  [  0.80774033]
  [  1.70263886]
  [  1.3513236 ]
  [  0.59500241]]

 [[  1.43976569]
  [  1.42888868]
  [  1.2157861 ]
  [  1.44906425]
  [  1.45311606]
  [  1.41431963]
  [  1.1204313 ]
  [  1.43250191]
  [  1.44546294]
  [  1.42915475]
  [  1.47151446]
  [  3.97895932]
  [  1.48151624]
  [  1.36012101]
  [  1.42996037]
  [  2.22278166]
  [  1.40924668]
  [  4.02597904]
  [  3.14631534]
  [  1.51078904]]

 [[  2.23131919]
  [  2.21472168]
  [  1.79864728]
  [  2.25758243]
  [  2.25777602]
  [  2.1810863 ]
  [  1.60605133]
  [  2.22191262]
  [  2.24758363]
  [  2.21823335]
  [  2.27168107]
  [  7.47095966]
  [  2.29260302]
  [  2.02580452]
  [  2.22015667]
  [  4.0064497 ]
  [  2.17980003]
  [  7.559062  ]
  [  5.67311668]
  [  2.55180645]]

 [[  1.97624993]
  [  1.93780148]
  [  1.24658144]
  [  1.99738503]
  [  2.01659441]
  [  1.89267659]
  [  0.91670626]
  [  1.95178533]
  [  1.99325585]
  [  1.9351989 ]
  [  2.00324082]
  [ 11.18866253]
  [  2.02892065]
  [  1.25608301]
  [  1.93125939]
  [  5.29688358]
  [  1.86904311]
  [ 11.33212471]
  [  8.16843796]
  [  2.64612341]]

 [[ -0.36030367]
  [ -0.44066027]
  [ -1.42031336]
  [ -0.38230556]
  [ -0.31126934]
  [ -0.47859189]
  [ -1.90226173]
  [ -0.41733477]
  [ -0.36137143]
  [ -0.4634819 ]
  [ -0.36219633]
  [ 13.46785259]
  [ -0.34409297]
  [ -2.03445005]
  [ -0.48283097]
  [  4.84645653]
  [ -0.56142378]
  [ 13.67587757]
  [  9.322052  ]
  [  0.71506745]]

 [[ -3.62211132]
  [ -3.74823904]
  [ -4.96253204]
  [ -3.70278931]
  [ -3.56976604]
  [ -3.76875854]
  [ -5.57556391]
  [ -3.71641707]
  [ -3.64998627]
  [ -3.79655027]
  [ -3.6458292 ]
  [ 14.33636856]
  [ -3.64072633]
  [ -6.33842087]
  [ -3.83368349]
  [  3.29798794]
  [ -3.92144418]
  [ 14.61170673]
  [  9.39704323]
  [ -2.20614505]]

 [[ -6.44999313]
  [ -6.61161089]
  [ -7.97807312]
  [ -6.57588625]
  [ -6.39860964]
  [ -6.6181283 ]
  [ -8.68771839]
  [ -6.57392883]
  [ -6.50036478]
  [ -6.67858505]
  [ -6.47544527]
  [ 14.45060921]
  [ -6.47702932]
  [ -9.98304272]
  [ -6.72810316]
  [  1.67186642]
  [ -6.81882143]
  [ 14.78807831]
  [  9.10906601]
  [ -4.85417891]]

 [[ -8.55053043]
  [ -8.73407841]
  [-10.1933279 ]
  [ -8.70034504]
  [ -8.50113487]
  [ -8.73443031]
  [-10.96858406]
  [ -8.69263268]
  [ -8.61405087]
  [ -8.81002998]
  [ -8.56188583]
  [ 14.09714985]
  [ -8.56224442]
  [-12.57792377]
  [ -8.86569881]
  [  0.24361864]
  [ -8.95633602]
  [ 14.48266792]
  [  8.65215778]
  [ -6.92983294]]

 [[-10.10455704]
  [-10.29879284]
  [-11.81497955]
  [-10.26205349]
  [-10.05600071]
  [-10.29911804]
  [-12.63179016]
  [-10.25490856]
  [-10.17293549]
  [-10.37684631]
  [-10.09833241]
  [ 13.4402914 ]
  [-10.09390736]
  [-14.36468029]
  [-10.43480873]
  [ -0.99153465]
  [-10.524683  ]
  [ 13.85552883]
  [  8.0621357 ]
  [ -8.53370953]]]
After layer sequencemask6_output (10, 20, 1) <class 'numpy.float32'> [[[  4.81832564e-01]
  [  4.83161211e-01]
  [  4.53203768e-01]
  [  4.89077866e-01]
  [  4.83799219e-01]
  [  4.78393734e-01]
  [  4.50225383e-01]
  [  4.82998103e-01]
  [  4.85210806e-01]
  [  4.85222697e-01]
  [  5.07104397e-01]
  [  6.92782581e-01]
  [  5.10970652e-01]
  [  4.46683258e-01]
  [  4.87130731e-01]
  [  5.14589846e-01]
  [  4.84040767e-01]
  [  6.91300094e-01]
  [  7.05608606e-01]
  [  4.22441185e-01]]

 [[  8.39090765e-01]
  [  8.27213645e-01]
  [  7.14332402e-01]
  [  8.26805353e-01]
  [  8.44659984e-01]
  [  8.29456210e-01]
  [  6.75816655e-01]
  [  8.29149544e-01]
  [  8.34161282e-01]
  [  8.19962204e-01]
  [  8.27036560e-01]
  [  1.68034315e+00]
  [  8.23366225e-01]
  [  6.64342344e-01]
  [  8.16432714e-01]
  [  8.90133083e-01]
  [  8.07740331e-01]
  [  1.70263886e+00]
  [  1.35132360e+00]
  [  5.95002413e-01]]

 [[ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]]
After layer swapaxes22_output (20, 10, 1) <class 'numpy.float32'> [[[  4.81832564e-01]
  [  8.39090765e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  4.83161211e-01]
  [  8.27213645e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  4.53203768e-01]
  [  7.14332402e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  4.89077866e-01]
  [  8.26805353e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  4.83799219e-01]
  [  8.44659984e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  4.78393734e-01]
  [  8.29456210e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  4.50225383e-01]
  [  6.75816655e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  4.82998103e-01]
  [  8.29149544e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  4.85210806e-01]
  [  8.34161282e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  4.85222697e-01]
  [  8.19962204e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  5.07104397e-01]
  [  8.27036560e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  6.92782581e-01]
  [  1.68034315e+00]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  5.10970652e-01]
  [  8.23366225e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  4.46683258e-01]
  [  6.64342344e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  4.87130731e-01]
  [  8.16432714e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  5.14589846e-01]
  [  8.90133083e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  4.84040767e-01]
  [  8.07740331e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  6.91300094e-01]
  [  1.70263886e+00]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  7.05608606e-01]
  [  1.35132360e+00]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  4.22441185e-01]
  [  5.95002413e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]]
After layer attention_softmax_0 (20, 10, 1) <class 'numpy.float32'> [[[ 0.41162342]
  [ 0.58837652]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.41482544]
  [ 0.58517456]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.43508628]
  [ 0.56491369]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.41636163]
  [ 0.58363843]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.41075119]
  [ 0.58924878]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.4131248 ]
  [ 0.5868752 ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.44384015]
  [ 0.55615985]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.414316  ]
  [ 0.585684  ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.41363692]
  [ 0.58636302]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.41708788]
  [ 0.58291215]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.42069229]
  [ 0.57930773]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.27139419]
  [ 0.72860581]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.42253008]
  [ 0.57746989]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.44579902]
  [ 0.55420095]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.41841048]
  [ 0.58158952]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40720224]
  [ 0.59279776]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.41977441]
  [ 0.58022559]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.26671794]
  [ 0.73328203]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.34395581]
  [ 0.65604424]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.4569664 ]
  [ 0.5430336 ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]]
After layer batch_dot6_0 (20, 512, 1) <class 'numpy.float32'> [[[ 0.01765097]
  [ 0.03920715]
  [-0.03305183]
  ...,
  [-0.01090975]
  [ 0.0099837 ]
  [-0.02474742]]

 [[ 0.01757368]
  [ 0.03911795]
  [-0.03290769]
  ...,
  [-0.01089204]
  [ 0.00998001]
  [-0.02480402]]

 [[ 0.01708462]
  [ 0.03855356]
  [-0.03199569]
  ...,
  [-0.01077997]
  [ 0.00995667]
  [-0.02516218]]

 ...,
 [[ 0.02114878]
  [ 0.0432437 ]
  [-0.03957448]
  ...,
  [-0.01171124]
  [ 0.01015063]
  [-0.02218586]]

 [[ 0.01928437]
  [ 0.04109214]
  [-0.03609776]
  ...,
  [-0.01128403]
  [ 0.01006165]
  [-0.02355123]]

 [[ 0.01655646]
  [ 0.03794406]
  [-0.0310108 ]
  ...,
  [-0.01065895]
  [ 0.00993147]
  [-0.02554897]]]
After layer reshape12_0 (20, 512) <class 'numpy.float32'> [[ 0.01765097  0.03920715 -0.03305183 ..., -0.01090975  0.0099837
  -0.02474742]
 [ 0.01757368  0.03911795 -0.03290769 ..., -0.01089204  0.00998001
  -0.02480402]
 [ 0.01708462  0.03855356 -0.03199569 ..., -0.01077997  0.00995667
  -0.02516218]
 ...,
 [ 0.02114878  0.0432437  -0.03957448 ..., -0.01171124  0.01015063
  -0.02218586]
 [ 0.01928437  0.04109214 -0.03609776 ..., -0.01128403  0.01006165
  -0.02355123]
 [ 0.01655646  0.03794406 -0.0310108  ..., -0.01065895  0.00993147
  -0.02554897]]
After layer decoder_rnn_hidden_concat_t0_output (20, 1024) <class 'numpy.float32'> [[ -9.34750133e-04  -9.19116855e-01   1.87220022e-01 ...,  -1.09097473e-02
    9.98369977e-03  -2.47474164e-02]
 [ -1.01639854e-03  -9.21702981e-01   1.83715999e-01 ...,  -1.08920373e-02
    9.98001173e-03  -2.48040222e-02]
 [ -6.59206242e-04  -9.11389470e-01   1.93022832e-01 ...,  -1.07799713e-02
    9.95667093e-03  -2.51621809e-02]
 ...,
 [ -4.22587572e-03  -3.16903174e-01   4.23757024e-02 ...,  -1.17112407e-02
    1.01506291e-02  -2.21858639e-02]
 [ -1.89795997e-03  -5.78740716e-01   6.20479248e-02 ...,  -1.12840282e-02
    1.00616533e-02  -2.35512313e-02]
 [ -2.40223180e-03  -7.13405848e-01   1.04225710e-01 ...,  -1.06589496e-02
    9.93146561e-03  -2.55489666e-02]]
After layer decoder_rnn_hidden_fc_t0_output (20, 512) <class 'numpy.float32'> [[-1.72143662  0.18277779 -0.71125436 ...,  1.79131186  1.97247124
  -1.47356021]
 [-1.74759305  0.20094794 -0.7419582  ...,  1.80105364  1.97223377
  -1.47823226]
 [-1.42249179  0.01200889 -0.51429009 ...,  1.53454232  1.98128068
  -1.41466033]
 ...,
 [-0.62421501 -1.67395556  1.16496551 ...,  0.98353833  1.68103313
   1.04932678]
 [-0.73612249 -1.0138514   0.32435322 ...,  1.07333994  1.68578231
   0.74477524]
 [-1.30108333  0.0705786  -0.6828813  ...,  1.81038165  1.5705514
  -0.22260228]]
After layer decoder_rnn_next_hidden_t0_output (20, 512) <class 'numpy.float32'> [[-0.93803579  0.18076923 -0.61146283 ...,  0.94589883  0.96203017
  -0.90025443]
 [-0.94110096  0.19828616 -0.63032681 ...,  0.94691503  0.96201247
  -0.90113628]
 [-0.89011759  0.01200831 -0.47328109 ...,  0.91119868  0.96268088
  -0.88847971]
 ...,
 [-0.55405593 -0.93207276  0.82265151 ...,  0.75459355  0.9329955
   0.78154445]
 [-0.62679672 -0.76735032  0.31343779 ...,  0.79071623  0.93360788
   0.63202155]
 [-0.86200178  0.07046164 -0.59338933 ...,  0.94787061  0.91711342
  -0.21899694]]
After layer logits_output (20, 16743) <class 'numpy.float32'> [[-1.89850831 -2.79975533 -2.35671544 ..., -2.07087493 -3.44388151
  -2.50023103]
 [-1.90756333 -2.78375888 -2.36082411 ..., -2.07215858 -3.43681049
  -2.49465704]
 [-1.8105098  -2.8638742  -2.3839314  ..., -2.10236835 -3.3745234
  -2.51722813]
 ...,
 [-1.47220993 -2.96687531 -0.92518073 ..., -2.00790739 -2.44621038
  -1.57378507]
 [-1.49390984 -2.81401134 -0.92815995 ..., -1.74798203 -2.58814812
  -1.68084037]
 [-1.42079675 -2.58898902 -1.54254854 ..., -1.78300428 -2.62327838
  -1.84700918]]
After layer softmax_0 (20, 16743) <class 'numpy.float32'> [[  1.11169652e-06   4.51418799e-07   7.03055207e-07 ...,   9.35681726e-07
    2.37049420e-07   6.09061829e-07]
 [  1.10488668e-06   4.60034812e-07   7.02213583e-07 ...,   9.37205357e-07
    2.39427521e-07   6.14251633e-07]
 [  1.37962638e-06   4.81161635e-07   7.77548848e-07 ...,   1.03040713e-06
    2.88748055e-07   6.80514745e-07]
 ...,
 [  7.37204118e-06   1.65372285e-06   1.27397070e-05 ...,   4.31456829e-06
    2.78345851e-06   6.65999869e-06]
 [  7.21555489e-06   1.92733523e-06   1.27049188e-05 ...,   5.59664295e-06
    2.41572843e-06   5.98531778e-06]
 [  6.37292669e-06   1.98152520e-06   5.64238599e-06 ...,   4.43643648e-06
    1.91473168e-06   4.16137891e-06]]
After layer reshape13_0 (20, 10) <class 'numpy.float32'> [[ 0.41162342  0.58837652  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.41482544  0.58517456  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.43508628  0.56491369  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.41636163  0.58363843  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.41075119  0.58924878  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.4131248   0.5868752   0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.44384015  0.55615985  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.414316    0.585684    0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.41363692  0.58636302  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.41708788  0.58291215  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.42069229  0.57930773  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.27139419  0.72860581  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.42253008  0.57746989  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.44579902  0.55420095  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.41841048  0.58158952  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40720224  0.59279776  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.41977441  0.58022559  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.26671794  0.73328203  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.34395581  0.65604424  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.4569664   0.5430336   0.          0.          0.          0.          0.
   0.          0.          0.        ]]
After layer target_embed_embed_0 (20, 256) <class 'numpy.float32'> [[-0.05505371 -0.0300293  -0.03598022 ...,  0.08459473 -0.05288696
  -0.01667786]
 [-0.05505371 -0.0300293  -0.03598022 ...,  0.08459473 -0.05288696
  -0.01667786]
 [-0.05505371 -0.0300293  -0.03598022 ...,  0.08459473 -0.05288696
  -0.01667786]
 ...,
 [ 0.02738953 -0.07226562 -0.00852966 ...,  0.02572632  0.00955963
  -0.04855347]
 [-0.05505371 -0.0300293  -0.03598022 ...,  0.08459473 -0.05288696
  -0.01667786]
 [ 0.09375     0.03564453  0.10772705 ..., -0.10864258 -0.07653809
  -0.06854248]]
After layer decoder_rnn_concat_target_context_t0_output (20, 768) <class 'numpy.float32'> [[-0.05505371 -0.0300293  -0.03598022 ...,  0.94589883  0.96203017
  -0.90025443]
 [-0.05505371 -0.0300293  -0.03598022 ...,  0.94691503  0.96201247
  -0.90113628]
 [-0.05505371 -0.0300293  -0.03598022 ...,  0.91119868  0.96268088
  -0.88847971]
 ...,
 [ 0.02738953 -0.07226562 -0.00852966 ...,  0.94787061  0.91711342
  -0.21899694]
 [-0.05505371 -0.0300293  -0.03598022 ...,  0.94371843  0.96042728
  -0.89566982]
 [ 0.09375     0.03564453  0.10772705 ...,  0.95046747  0.9003101
   0.29890186]]
After layer decoder_rnn_l0_t0_i2h_output (20, 2048) <class 'numpy.float32'> [[-3.12405443  1.59955215  2.36570787 ..., -0.0950798   3.83084798
   0.63062376]
 [-3.11037111  1.59207726  2.36495209 ..., -0.08637207  3.81671667
   0.62202591]
 [-3.11406589  1.65353751  2.30190444 ..., -0.13826893  3.82699585
   0.78324628]
 ...,
 [-2.68340111  1.55486214  2.00703049 ..., -0.27374738  3.36013365
   0.21431205]
 [-3.09246683  1.5852592   2.3498044  ..., -0.09673558  3.79442406
   0.63999772]
 [-2.92701864  1.51352644  1.83893418 ..., -0.98700655  2.94986773
   0.60024643]]
After layer decoder_rnn_l0_t0_h2h_output (20, 2048) <class 'numpy.float32'> [[-0.36519191  0.44861671  1.74447858 ...,  0.62270552  1.26100767
   0.17974842]
 [-0.37262014  0.46158966  1.73663867 ...,  0.62963855  1.25418484
   0.16824766]
 [-0.45312425  0.41561794  1.74971378 ...,  0.50533295  1.26618838
   0.31643903]
 ...,
 [-0.41520935  0.47133213  1.69528055 ...,  0.21604386  1.19799459
  -0.42575997]
 [-0.40249336  0.47298938  1.73051322 ...,  0.60666466  1.24645865
   0.17692797]
 [-0.42353499  0.51236343  1.66293669 ...,  0.11902877  1.23774087
  -0.52802634]]
After layer _plus1051_0 (20, 2048) <class 'numpy.float32'> [[-3.48924637  2.0481689   4.11018658 ...,  0.52762574  5.09185553
   0.81037217]
 [-3.48299122  2.05366683  4.10159063 ...,  0.54326648  5.07090139
   0.79027355]
 [-3.56719017  2.06915545  4.0516181  ...,  0.367064    5.09318447
   1.09968531]
 ...,
 [-3.0986104   2.02619433  3.70231104 ..., -0.05770352  4.55812836
  -0.21144792]
 [-3.49496031  2.05824852  4.0803175  ...,  0.50992906  5.04088259
   0.8169257 ]
 [-3.35055351  2.02588987  3.50187087 ..., -0.8679778   4.18760872
   0.07222009]]
After layer decoder_rnn_l0_t0_slice_output0 (20, 512) <class 'numpy.float32'> [[-3.48924637  2.0481689   4.11018658 ...,  1.74361479  4.49110031
   2.69980574]
 [-3.48299122  2.05366683  4.10159063 ...,  1.7352792   4.48440266
   2.68715811]
 [-3.56719017  2.06915545  4.0516181  ...,  1.84869683  4.53741455
   2.65137053]
 ...,
 [-3.0986104   2.02619433  3.70231104 ...,  1.59838521  3.93761683
   2.28398991]
 [-3.49496031  2.05824852  4.0803175  ...,  1.72505033  4.47417355
   2.66911697]
 [-3.35055351  2.02588987  3.50187087 ...,  1.49840569  3.69815755
   2.27181911]]
After layer decoder_rnn_l0_t0_slice_output1 (20, 512) <class 'numpy.float32'> [[-1.95275736  2.28141689  2.28716469 ...,  3.07037735 -0.8759551
   1.89860547]
 [-1.95776916  2.27225161  2.29422903 ...,  3.05556965 -0.8674078
   1.8750186 ]
 [-2.10206509  2.33801317  2.34271145 ...,  2.9588623  -1.08207178
   1.97031057]
 ...,
 [-2.227916    2.37348676  1.6663264  ...,  2.38974857 -0.85828602
   1.35354269]
 [-1.99329948  2.28334069  2.28658199 ...,  3.01975083 -0.87984145
   1.84989142]
 [-2.40036273  2.59552002  1.52130377 ...,  2.08319974  0.14334524
   1.23171115]]
After layer decoder_rnn_l0_t0_slice_output2 (20, 512) <class 'numpy.float32'> [[-2.72397947 -2.96803617  2.75975847 ...,  4.1709938  -0.16140765
   2.10978127]
 [-2.70676994 -2.97192907  2.76237631 ...,  4.14062357 -0.17048872
   2.10022306]
 [-2.74671721 -3.00826216  2.7646389  ...,  4.19397783 -0.18604884
   2.09899735]
 ...,
 [-2.76969147 -2.30041909  1.8652693  ...,  3.65185404 -1.93132329
   2.06467247]
 [-2.66936469 -2.95817327  2.73782325 ...,  4.11598396 -0.21089703
   2.08130598]
 [-2.66625237 -1.95888734  1.41403127 ...,  3.32703066 -3.41140175
   2.04477286]]
After layer decoder_rnn_l0_t0_slice_output3 (20, 512) <class 'numpy.float32'> [[-3.30472326  2.50458789 -1.44786251 ...,  0.52762574  5.09185553
   0.81037217]
 [-3.29119778  2.52116394 -1.45690823 ...,  0.54326648  5.07090139
   0.79027355]
 [-3.38768363  2.57203221 -1.51317286 ...,  0.367064    5.09318447
   1.09968531]
 ...,
 [-3.02497506  2.25015044 -1.00100851 ..., -0.05770352  4.55812836
  -0.21144792]
 [-3.29994631  2.5359385  -1.4760195  ...,  0.50992906  5.04088259
   0.8169257 ]
 [-3.07300234  2.01074004 -2.88617253 ..., -0.8679778   4.18760872
   0.07222009]]
After layer decoder_rnn_l0_t0_o_output (20, 512) <class 'numpy.float32'> [[ 0.03540951  0.9244628   0.19033074 ...,  0.6289292   0.993891
   0.69218874]
 [ 0.0358744   0.92561221  0.18894066 ...,  0.632572    0.99376243
   0.68789005]
 [ 0.03268261  0.92903984  0.18046905 ...,  0.59074938  0.99389899
   0.75020111]
 ...,
 [ 0.04631025  0.9046635   0.26874319 ...,  0.48557815  0.989627
   0.44733411]
 [ 0.03557303  0.92662311  0.18602942 ...,  0.62478983  0.99357349
   0.69358337]
 [ 0.04423472  0.8819201   0.05284135 ...,  0.29567525  0.98504454
   0.51804721]]
After layer decoder_rnn_l0_t0_f_output (20, 512) <class 'numpy.float32'> [[ 0.12425301  0.90732628  0.90780842 ...,  0.95565414  0.29401669
   0.86973363]
 [ 0.12370867  0.90655273  0.90839791 ...,  0.95502239  0.29579395
   0.86703789]
 [ 0.10889627  0.9119767   0.9123531  ...,  0.95068073  0.25311416
   0.87764442]
 ...,
 [ 0.09727147  0.91478306  0.84108537 ...,  0.91604221  0.29769757
   0.79470825]
 [ 0.11990823  0.90748793  0.90775967 ...,  0.95345849  0.29321063
   0.86411434]
 [ 0.08314504  0.93057275  0.82073039 ...,  0.88925952  0.53577507
   0.77411789]]
After layer _mul2102_0 (20, 512) <class 'numpy.float32'> [[ -3.66128446e-03  -2.91511273e+00   3.28070283e+00 ...,   3.48435736e+00
   -4.98839654e-03   2.67268920e+00]
 [ -3.77490069e-03  -2.91585612e+00   3.22961140e+00 ...,   3.38571715e+00
   -4.22266871e-02   2.58933854e+00]
 [ -2.49165366e-03  -2.86869407e+00   3.27350283e+00 ...,   3.23475027e+00
    9.20984223e-02   2.45305085e+00]
 ...,
 [ -2.52211979e-03  -2.62506342e+00   2.86679816e+00 ...,   2.88359761e+00
   -2.15364292e-01   2.05145240e+00]
 [ -3.48930107e-03  -2.90356183e+00   3.22866654e+00 ...,   3.34411812e+00
   -6.21755943e-02   2.54199243e+00]
 [ -2.07708566e-03  -2.69582009e+00   2.79172325e+00 ...,   2.78750730e+00
   -3.52777123e-01   2.02666974e+00]]
After layer decoder_rnn_l0_t0_i_output (20, 512) <class 'numpy.float32'> [[ 0.02961976  0.88576245  0.98386002 ...,  0.85114563  0.98891592
   0.93701518]
 [ 0.02980008  0.88631761  0.98372298 ...,  0.85008645  0.98884225
   0.93626463]
 [ 0.02745975  0.88786888  0.98290318 ...,  0.86397403  0.98941225
   0.93409538]
 ...,
 [ 0.04316461  0.88352001  0.97592735 ...,  0.83179253  0.98087811
   0.90754235]
 [ 0.02945597  0.88677841  0.98337883 ...,  0.84877819  0.98872888
   0.93517953]
 [ 0.03387704  0.88348866  0.97074091 ...,  0.81733656  0.9758296
   0.90651608]]
After layer decoder_rnn_l0_t0_c_output (20, 512) <class 'numpy.float32'> [[-0.99142677 -0.99472916  0.99201643 ...,  0.99952352 -0.16002043
   0.97101605]
 [-0.99112785 -0.99476993  0.99205798 ...,  0.99949366 -0.16885588
   0.97046494]
 [-0.99180633 -0.99513561  0.99209368 ...,  0.99954492 -0.18393151
   0.97039348]
 ...,
 [-0.99217284 -0.98011291  0.95316333 ...,  0.99865484 -0.95884025
   0.96832293]
 [-0.99044198 -0.99462444  0.99165988 ...,  0.99946809 -0.20782495
   0.96934354]
 [-0.99038255 -0.96100485  0.88834715 ...,  0.99742573 -0.99782503
   0.967058  ]]
After layer _mul2103_0 (20, 512) <class 'numpy.float32'> [[-0.02936582 -0.88109374  0.97600532 ...,  0.85074008 -0.15824674
   0.9098568 ]
 [-0.02953568 -0.8816821   0.97591025 ...,  0.84965605 -0.16697182
   0.90861201]
 [-0.02723475 -0.88354993  0.97513205 ...,  0.86358088 -0.1819841
   0.90644008]
 ...,
 [-0.04282675 -0.86594939  0.93021816 ...,  0.83067364 -0.94050545
   0.87879407]
 [-0.02917443 -0.88201147  0.97517735 ...,  0.84832674 -0.20548253
   0.90651023]
 [-0.03355123 -0.84903687  0.86235493 ...,  0.81523252 -0.9737072
   0.87665361]]
After layer decoder_rnn_l0_t0_state_0 (20, 512) <class 'numpy.float32'> [[-0.03302711 -3.79620647  4.25670815 ...,  4.33509731 -0.16323514
   3.582546  ]
 [-0.03331058 -3.79753828  4.20552158 ...,  4.23537302 -0.2091985
   3.49795055]
 [-0.02972641 -3.752244    4.24863482 ...,  4.09833097 -0.08988567
   3.35949087]
 ...,
 [-0.04534887 -3.49101281  3.79701638 ...,  3.71427131 -1.15586972
   2.93024635]
 [-0.03266373 -3.78557324  4.20384407 ...,  4.1924448  -0.26765811
   3.44850254]
 [-0.03562832 -3.54485703  3.65407825 ...,  3.60273981 -1.32648432
   2.90332341]]
After layer activation1051_output (20, 512) <class 'numpy.float32'> [[-0.0330151  -0.99899197  0.99959856 ...,  0.9996568  -0.16180059
   0.99845499]
 [-0.03329827 -0.99899465  0.99955529 ...,  0.9995811  -0.20619921
   0.99817044]
 [-0.02971765 -0.9988994   0.99959201 ...,  0.99944901 -0.08964438
   0.99758738]
 ...,
 [-0.04531781 -0.99814487  0.99899364 ...,  0.99881262 -0.81968927
   0.99431652]
 [-0.03265212 -0.99897033  0.9995538  ...,  0.99954355 -0.26144436
   0.99798042]
 [-0.03561325 -0.99833411  0.9986608  ...,  0.99851608 -0.86838746
   0.99400306]]
After layer decoder_rnn_l0_t0_out_0 (20, 512) <class 'numpy.float32'> [[-0.00116905 -0.92353088  0.19025433 ...,  0.62871337 -0.16081215
   0.69111931]
 [-0.00119456 -0.92468166  0.18885663 ...,  0.63230699 -0.20491304
   0.6866315 ]
 [-0.00097125 -0.92801732  0.18039542 ...,  0.59042388 -0.08909746
   0.74839115]
 ...,
 [-0.00209868 -0.90298522  0.26847273 ...,  0.48500159 -0.81118661
   0.4447917 ]
 [-0.00116153 -0.92566901  0.18594642 ...,  0.62450463 -0.25976419
   0.6921826 ]
 [-0.00157534 -0.8804509   0.05277059 ...,  0.2952365  -0.85540032
   0.5149405 ]]
After layer expand_dims1060_0 (20, 512, 1) <class 'numpy.float32'> [[[-0.00116905]
  [-0.92353088]
  [ 0.19025433]
  ...,
  [ 0.62871337]
  [-0.16081215]
  [ 0.69111931]]

 [[-0.00119456]
  [-0.92468166]
  [ 0.18885663]
  ...,
  [ 0.63230699]
  [-0.20491304]
  [ 0.6866315 ]]

 [[-0.00097125]
  [-0.92801732]
  [ 0.18039542]
  ...,
  [ 0.59042388]
  [-0.08909746]
  [ 0.74839115]]

 ...,
 [[-0.00209868]
  [-0.90298522]
  [ 0.26847273]
  ...,
  [ 0.48500159]
  [-0.81118661]
  [ 0.4447917 ]]

 [[-0.00116153]
  [-0.92566901]
  [ 0.18594642]
  ...,
  [ 0.62450463]
  [-0.25976419]
  [ 0.6921826 ]]

 [[-0.00157534]
  [-0.8804509 ]
  [ 0.05277059]
  ...,
  [ 0.2952365 ]
  [-0.85540032]
  [ 0.5149405 ]]]
After layer att_batch_dot_0 (20, 10, 1) <class 'numpy.float32'> [[[  0.50090522]
  [  0.87722445]
  [  1.50664604]
  [  2.35575008]
  [  2.15172553]
  [ -0.16939025]
  [ -3.4408164 ]
  [ -6.29428053]
  [ -8.42654037]
  [-10.00939846]]

 [[  0.50277644]
  [  0.87296611]
  [  1.50824678]
  [  2.36190009]
  [  2.15672565]
  [ -0.17553481]
  [ -3.46114016]
  [ -6.32480764]
  [ -8.46211147]
  [-10.04599953]]

 [[  0.48006436]
  [  0.82248729]
  [  1.40268862]
  [  2.15432   ]
  [  1.81570637]
  [ -0.64788383]
  [ -4.03516674]
  [ -6.96064568]
  [ -9.12906361]
  [-10.72579575]]

 [[  0.50687313]
  [  0.8778131 ]
  [  1.53119671]
  [  2.41036987]
  [  2.22858381]
  [ -0.09498262]
  [ -3.38377023]
  [ -6.2523737 ]
  [ -8.39166927]
  [ -9.97466183]]

 [[  0.50226307]
  [  0.87908816]
  [  1.51322699]
  [  2.36898041]
  [  2.17220807]
  [ -0.14452846]
  [ -3.4144578 ]
  [ -6.26823378]
  [ -8.40139961]
  [ -9.98504639]]

 [[  0.60160577]
  [  1.01472509]
  [  1.81669223]
  [  2.88395   ]
  [  2.99226022]
  [  1.03542912]
  [ -1.88529742]
  [ -4.44019651]
  [ -6.35966825]
  [ -7.82414913]]

 [[  0.49868828]
  [  0.87033993]
  [  1.48876262]
  [  2.31966782]
  [  2.09355927]
  [ -0.24685057]
  [ -3.53097129]
  [ -6.39199734]
  [ -8.52899456]
  [-10.11485291]]

 [[  0.47598046]
  [  0.80528754]
  [  1.35973036]
  [  2.0680294 ]
  [  1.67275608]
  [ -0.84640503]
  [ -4.27373219]
  [ -7.22319031]
  [ -9.40543747]
  [-11.00963402]]

 [[  0.50256634]
  [  0.87369293]
  [  1.50886798]
  [  2.36299014]
  [  2.15954185]
  [ -0.16962822]
  [ -3.4523108 ]
  [ -6.31409645]
  [ -8.45028782]
  [-10.03342056]]

 [[  0.50425041]
  [  0.87706101]
  [  1.5174464 ]
  [  2.38008809]
  [  2.18664289]
  [ -0.13450737]
  [ -3.41250253]
  [ -6.2718854 ]
  [ -8.40675259]
  [ -9.98915672]]

 [[  0.50452149]
  [  0.8725087 ]
  [  1.51606429]
  [  2.37956142]
  [  2.17977166]
  [ -0.15776892]
  [ -3.45472574]
  [ -6.32799816]
  [ -8.47035789]
  [-10.05542946]]

 [[  0.51247549]
  [  0.87294215]
  [  1.52661574]
  [  2.39334846]
  [  2.19430375]
  [ -0.14429966]
  [ -3.44283319]
  [ -6.31587172]
  [ -8.45711136]
  [-10.04282761]]

 [[  0.52224392]
  [  0.76938862]
  [  1.46065629]
  [  2.18675971]
  [  1.61062276]
  [ -1.31318498]
  [ -5.20893955]
  [ -8.53147507]
  [-10.9081831 ]
  [-12.5670166 ]]

 [[  0.51418352]
  [  0.87373519]
  [  1.53762174]
  [  2.4168427 ]
  [  2.22647953]
  [ -0.11441609]
  [ -3.42161179]
  [ -6.30133533]
  [ -8.44497871]
  [-10.03005505]]

 [[  0.70082122]
  [  1.34449613]
  [  3.11959624]
  [  5.6244154 ]
  [  8.086092  ]
  [  9.19762611]
  [  9.23065281]
  [  8.89707375]
  [  8.39238739]
  [  7.76178265]]

 [[  0.50571525]
  [  0.87275749]
  [  1.52165389]
  [  2.3918848 ]
  [  2.19572687]
  [ -0.14557873]
  [ -3.45010042]
  [ -6.32962275]
  [ -8.47555923]
  [-10.06218529]]

 [[  0.44640282]
  [  0.18269274]
  [  0.19053349]
  [ -0.42224747]
  [ -2.85019732]
  [ -7.73786211]
  [-13.27101898]
  [-17.73353195]
  [-20.85237503]
  [-23.00996399]]

 [[  0.52366155]
  [  0.75603449]
  [  1.32214344]
  [  1.88631701]
  [  1.08952618]
  [ -2.08012509]
  [ -6.18927622]
  [ -9.65553188]
  [-12.11327648]
  [-13.81620121]]

 [[  0.50303483]
  [  0.867356  ]
  [  1.50858641]
  [  2.36612964]
  [  2.15525007]
  [ -0.19697578]
  [ -3.5072279 ]
  [ -6.38861752]
  [ -8.53444195]
  [-10.12028885]]

 [[  0.5379411 ]
  [  0.95578885]
  [  2.30329561]
  [  4.13828897]
  [  5.55573654]
  [  5.35024452]
  [  4.08631134]
  [  2.68461275]
  [  1.40877461]
  [  0.28129101]]]
After layer swapaxes23_output (10, 20, 1) <class 'numpy.float32'> [[[  0.50090522]
  [  0.50277644]
  [  0.48006436]
  [  0.50687313]
  [  0.50226307]
  [  0.60160577]
  [  0.49868828]
  [  0.47598046]
  [  0.50256634]
  [  0.50425041]
  [  0.50452149]
  [  0.51247549]
  [  0.52224392]
  [  0.51418352]
  [  0.70082122]
  [  0.50571525]
  [  0.44640282]
  [  0.52366155]
  [  0.50303483]
  [  0.5379411 ]]

 [[  0.87722445]
  [  0.87296611]
  [  0.82248729]
  [  0.8778131 ]
  [  0.87908816]
  [  1.01472509]
  [  0.87033993]
  [  0.80528754]
  [  0.87369293]
  [  0.87706101]
  [  0.8725087 ]
  [  0.87294215]
  [  0.76938862]
  [  0.87373519]
  [  1.34449613]
  [  0.87275749]
  [  0.18269274]
  [  0.75603449]
  [  0.867356  ]
  [  0.95578885]]

 [[  1.50664604]
  [  1.50824678]
  [  1.40268862]
  [  1.53119671]
  [  1.51322699]
  [  1.81669223]
  [  1.48876262]
  [  1.35973036]
  [  1.50886798]
  [  1.5174464 ]
  [  1.51606429]
  [  1.52661574]
  [  1.46065629]
  [  1.53762174]
  [  3.11959624]
  [  1.52165389]
  [  0.19053349]
  [  1.32214344]
  [  1.50858641]
  [  2.30329561]]

 [[  2.35575008]
  [  2.36190009]
  [  2.15432   ]
  [  2.41036987]
  [  2.36898041]
  [  2.88395   ]
  [  2.31966782]
  [  2.0680294 ]
  [  2.36299014]
  [  2.38008809]
  [  2.37956142]
  [  2.39334846]
  [  2.18675971]
  [  2.4168427 ]
  [  5.6244154 ]
  [  2.3918848 ]
  [ -0.42224747]
  [  1.88631701]
  [  2.36612964]
  [  4.13828897]]

 [[  2.15172553]
  [  2.15672565]
  [  1.81570637]
  [  2.22858381]
  [  2.17220807]
  [  2.99226022]
  [  2.09355927]
  [  1.67275608]
  [  2.15954185]
  [  2.18664289]
  [  2.17977166]
  [  2.19430375]
  [  1.61062276]
  [  2.22647953]
  [  8.086092  ]
  [  2.19572687]
  [ -2.85019732]
  [  1.08952618]
  [  2.15525007]
  [  5.55573654]]

 [[ -0.16939025]
  [ -0.17553481]
  [ -0.64788383]
  [ -0.09498262]
  [ -0.14452846]
  [  1.03542912]
  [ -0.24685057]
  [ -0.84640503]
  [ -0.16962822]
  [ -0.13450737]
  [ -0.15776892]
  [ -0.14429966]
  [ -1.31318498]
  [ -0.11441609]
  [  9.19762611]
  [ -0.14557873]
  [ -7.73786211]
  [ -2.08012509]
  [ -0.19697578]
  [  5.35024452]]

 [[ -3.4408164 ]
  [ -3.46114016]
  [ -4.03516674]
  [ -3.38377023]
  [ -3.4144578 ]
  [ -1.88529742]
  [ -3.53097129]
  [ -4.27373219]
  [ -3.4523108 ]
  [ -3.41250253]
  [ -3.45472574]
  [ -3.44283319]
  [ -5.20893955]
  [ -3.42161179]
  [  9.23065281]
  [ -3.45010042]
  [-13.27101898]
  [ -6.18927622]
  [ -3.5072279 ]
  [  4.08631134]]

 [[ -6.29428053]
  [ -6.32480764]
  [ -6.96064568]
  [ -6.2523737 ]
  [ -6.26823378]
  [ -4.44019651]
  [ -6.39199734]
  [ -7.22319031]
  [ -6.31409645]
  [ -6.2718854 ]
  [ -6.32799816]
  [ -6.31587172]
  [ -8.53147507]
  [ -6.30133533]
  [  8.89707375]
  [ -6.32962275]
  [-17.73353195]
  [ -9.65553188]
  [ -6.38861752]
  [  2.68461275]]

 [[ -8.42654037]
  [ -8.46211147]
  [ -9.12906361]
  [ -8.39166927]
  [ -8.40139961]
  [ -6.35966825]
  [ -8.52899456]
  [ -9.40543747]
  [ -8.45028782]
  [ -8.40675259]
  [ -8.47035789]
  [ -8.45711136]
  [-10.9081831 ]
  [ -8.44497871]
  [  8.39238739]
  [ -8.47555923]
  [-20.85237503]
  [-12.11327648]
  [ -8.53444195]
  [  1.40877461]]

 [[-10.00939846]
  [-10.04599953]
  [-10.72579575]
  [ -9.97466183]
  [ -9.98504639]
  [ -7.82414913]
  [-10.11485291]
  [-11.00963402]
  [-10.03342056]
  [ -9.98915672]
  [-10.05542946]
  [-10.04282761]
  [-12.5670166 ]
  [-10.03005505]
  [  7.76178265]
  [-10.06218529]
  [-23.00996399]
  [-13.81620121]
  [-10.12028885]
  [  0.28129101]]]
After layer sequencemask7_output (10, 20, 1) <class 'numpy.float32'> [[[  5.00905216e-01]
  [  5.02776444e-01]
  [  4.80064362e-01]
  [  5.06873131e-01]
  [  5.02263069e-01]
  [  6.01605773e-01]
  [  4.98688281e-01]
  [  4.75980461e-01]
  [  5.02566338e-01]
  [  5.04250407e-01]
  [  5.04521489e-01]
  [  5.12475491e-01]
  [  5.22243917e-01]
  [  5.14183521e-01]
  [  7.00821221e-01]
  [  5.05715251e-01]
  [  4.46402818e-01]
  [  5.23661554e-01]
  [  5.03034830e-01]
  [  5.37941098e-01]]

 [[  8.77224445e-01]
  [  8.72966111e-01]
  [  8.22487295e-01]
  [  8.77813101e-01]
  [  8.79088163e-01]
  [  1.01472509e+00]
  [  8.70339930e-01]
  [  8.05287540e-01]
  [  8.73692930e-01]
  [  8.77061009e-01]
  [  8.72508705e-01]
  [  8.72942150e-01]
  [  7.69388616e-01]
  [  8.73735189e-01]
  [  1.34449613e+00]
  [  8.72757494e-01]
  [  1.82692736e-01]
  [  7.56034493e-01]
  [  8.67356002e-01]
  [  9.55788851e-01]]

 [[ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]]
After layer swapaxes24_output (20, 10, 1) <class 'numpy.float32'> [[[  5.00905216e-01]
  [  8.77224445e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  5.02776444e-01]
  [  8.72966111e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  4.80064362e-01]
  [  8.22487295e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  5.06873131e-01]
  [  8.77813101e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  5.02263069e-01]
  [  8.79088163e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  6.01605773e-01]
  [  1.01472509e+00]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  4.98688281e-01]
  [  8.70339930e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  4.75980461e-01]
  [  8.05287540e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  5.02566338e-01]
  [  8.73692930e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  5.04250407e-01]
  [  8.77061009e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  5.04521489e-01]
  [  8.72508705e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  5.12475491e-01]
  [  8.72942150e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  5.22243917e-01]
  [  7.69388616e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  5.14183521e-01]
  [  8.73735189e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  7.00821221e-01]
  [  1.34449613e+00]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  5.05715251e-01]
  [  8.72757494e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  4.46402818e-01]
  [  1.82692736e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  5.23661554e-01]
  [  7.56034493e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  5.03034830e-01]
  [  8.67356002e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  5.37941098e-01]
  [  9.55788851e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]]
After layer attention_softmax_0 (20, 10, 1) <class 'numpy.float32'> [[[ 0.40701494]
  [ 0.59298503]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40849519]
  [ 0.59150481]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.41522104]
  [ 0.58477896]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.4083139 ]
  [ 0.59168607]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40689284]
  [ 0.59310716]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.39816439]
  [ 0.60183561]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40814197]
  [ 0.59185797]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.4184092 ]
  [ 0.58159077]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40826881]
  [ 0.59173113]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40786207]
  [ 0.59213793]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40902749]
  [ 0.59097254]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.41084662]
  [ 0.58915341]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.43852642]
  [ 0.56147361]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.41106808]
  [ 0.58893186]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.34441629]
  [ 0.65558374]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40925592]
  [ 0.59074408]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.56554812]
  [ 0.43445191]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.44216678]
  [ 0.55783325]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.4099139 ]
  [ 0.59008604]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.39703187]
  [ 0.6029681 ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]]
After layer batch_dot7_0 (20, 512, 1) <class 'numpy.float32'> [[[ 0.01776222]
  [ 0.03933553]
  [-0.03325927]
  ...,
  [-0.01093524]
  [ 0.00998901]
  [-0.02466595]]

 [[ 0.01772649]
  [ 0.0392943 ]
  [-0.03319264]
  ...,
  [-0.01092705]
  [ 0.0099873 ]
  [-0.02469212]]

 [[ 0.01756413]
  [ 0.03910694]
  [-0.03288989]
  ...,
  [-0.01088985]
  [ 0.00997956]
  [-0.02481101]]

 ...,
 [[ 0.0169137 ]
  [ 0.03835633]
  [-0.03167698]
  ...,
  [-0.01074081]
  [ 0.00994852]
  [-0.02528735]]

 [[ 0.01769224]
  [ 0.03925477]
  [-0.03312878]
  ...,
  [-0.0109192 ]
  [ 0.00998567]
  [-0.0247172 ]]

 [[ 0.01800319]
  [ 0.03961362]
  [-0.03370864]
  ...,
  [-0.01099046]
  [ 0.01000051]
  [-0.02448948]]]
After layer reshape14_0 (20, 512) <class 'numpy.float32'> [[ 0.01776222  0.03933553 -0.03325927 ..., -0.01093524  0.00998901
  -0.02466595]
 [ 0.01772649  0.0392943  -0.03319264 ..., -0.01092705  0.0099873
  -0.02469212]
 [ 0.01756413  0.03910694 -0.03288989 ..., -0.01088985  0.00997956
  -0.02481101]
 ...,
 [ 0.0169137   0.03835633 -0.03167698 ..., -0.01074081  0.00994852
  -0.02528735]
 [ 0.01769224  0.03925477 -0.03312878 ..., -0.0109192   0.00998567
  -0.0247172 ]
 [ 0.01800319  0.03961362 -0.03370864 ..., -0.01099046  0.01000051
  -0.02448948]]
After layer decoder_rnn_hidden_concat_t0_output (20, 1024) <class 'numpy.float32'> [[-0.00116905 -0.92353088  0.19025433 ..., -0.01093524  0.00998901
  -0.02466595]
 [-0.00119456 -0.92468166  0.18885663 ..., -0.01092705  0.0099873
  -0.02469212]
 [-0.00097125 -0.92801732  0.18039542 ..., -0.01088985  0.00997956
  -0.02481101]
 ...,
 [-0.00209868 -0.90298522  0.26847273 ..., -0.01074081  0.00994852
  -0.02528735]
 [-0.00116153 -0.92566901  0.18594642 ..., -0.0109192   0.00998567
  -0.0247172 ]
 [-0.00157534 -0.8804509   0.05277059 ..., -0.01099046  0.01000051
  -0.02448948]]
After layer decoder_rnn_hidden_fc_t0_output (20, 512) <class 'numpy.float32'> [[-1.86888456  0.20581296 -0.785577   ...,  1.88897228  2.03643632
  -1.54879141]
 [-1.879264    0.20868786 -0.79587513 ...,  1.8931669   2.04006624
  -1.54811275]
 [-1.75741208  0.21029016 -0.75389194 ...,  1.80793464  2.00466299
  -1.52136397]
 ...,
 [-2.08674073 -0.11114122 -0.34334964 ...,  1.68717623  2.14740205
  -2.38618851]
 [-1.86818337  0.21749905 -0.79849643 ...,  1.88841403  2.02780199
  -1.53586161]
 [-1.40447211  0.59666824 -1.36775327 ...,  1.98366857  1.41315818
   0.14423831]]
After layer decoder_rnn_next_hidden_t0_output (20, 512) <class 'numpy.float32'> [[-0.95349288  0.20295537 -0.65589607 ...,  0.95528334  0.9665134
  -0.91358584]
 [-0.95442659  0.20571023 -0.66172445 ...,  0.95564866  0.96675164
  -0.91347355]
 [-0.9422133   0.20724422 -0.63746512 ...,  0.94762158  0.96435553
  -0.90893507]
 ...,
 [-0.96966994 -0.11068586 -0.33046451 ...,  0.93378663  0.97308856
  -0.98322147]
 [-0.95342916  0.21413307 -0.66319531 ...,  0.95523453  0.96594006
  -0.91142231]
 [-0.88631451  0.53467453 -0.87817913 ...,  0.9628554   0.88816291
   0.14324629]]
After layer logits_output (20, 16743) <class 'numpy.float32'> [[-1.96003711 -2.808496   -2.3954401  ..., -2.09500718 -3.47843313
  -2.53583026]
 [-1.96358907 -2.80222201 -2.39553022 ..., -2.09468007 -3.47340202
  -2.53413486]
 [-1.91774356 -2.79951572 -2.38440156 ..., -2.08631063 -3.45067096
  -2.51307368]
 ...,
 [-1.89667165 -3.10090709 -2.88289976 ..., -2.29000807 -3.52675033
  -3.09694314]
 [-1.95434487 -2.79219413 -2.38365912 ..., -2.08763337 -3.45944214
  -2.52615094]
 [-1.35233676 -2.29504395 -1.21587443 ..., -1.3201952  -2.45046759
  -1.4676193 ]]
After layer softmax_0 (20, 16743) <class 'numpy.float32'> [[  9.16406691e-07   3.92289849e-07   5.92918752e-07 ...,   8.00703390e-07
    2.00750705e-07   5.15257625e-07]
 [  9.18306455e-07   3.96984632e-07   5.96208281e-07 ...,   8.05481250e-07
    2.02900907e-07   5.19042089e-07]
 [  1.04204105e-06   4.31455589e-07   6.53458414e-07 ...,   8.80394339e-07
    2.24979445e-07   5.74561057e-07]
 ...,
 [  7.18003861e-08   2.15344684e-08   2.67801497e-08 ...,   4.84509854e-08
    1.40667051e-08   2.16199876e-08]
 [  9.61243018e-07   4.15872051e-07   6.25725932e-07 ...,   8.41292035e-07
    2.13391786e-07   5.42626537e-07]
 [  7.68999962e-06   2.99580711e-06   8.81436608e-06 ...,   7.94118478e-06
    2.56456678e-06   6.85267241e-06]]
After layer reshape15_0 (20, 10) <class 'numpy.float32'> [[ 0.40701494  0.59298503  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40849519  0.59150481  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.41522104  0.58477896  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.4083139   0.59168607  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40689284  0.59310716  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.39816439  0.60183561  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40814197  0.59185797  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.4184092   0.58159077  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40826881  0.59173113  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40786207  0.59213793  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40902749  0.59097254  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.41084662  0.58915341  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.43852642  0.56147361  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.41106808  0.58893186  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.34441629  0.65558374  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40925592  0.59074408  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.56554812  0.43445191  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.44216678  0.55783325  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.4099139   0.59008604  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.39703187  0.6029681   0.          0.          0.          0.          0.
   0.          0.          0.        ]]
After layer target_embed_embed_0 (20, 256) <class 'numpy.float32'> [[-0.05505371 -0.0300293  -0.03598022 ...,  0.08459473 -0.05288696
  -0.01667786]
 [-0.05505371 -0.0300293  -0.03598022 ...,  0.08459473 -0.05288696
  -0.01667786]
 [-0.05505371 -0.0300293  -0.03598022 ...,  0.08459473 -0.05288696
  -0.01667786]
 ...,
 [ 0.02738953 -0.07226562 -0.00852966 ...,  0.02572632  0.00955963
  -0.04855347]
 [-0.05505371 -0.0300293  -0.03598022 ...,  0.08459473 -0.05288696
  -0.01667786]
 [ 0.13598633  0.02095032  0.05236816 ..., -0.01808167 -0.03991699
  -0.14160156]]
After layer decoder_rnn_concat_target_context_t0_output (20, 768) <class 'numpy.float32'> [[-0.05505371 -0.0300293  -0.03598022 ...,  0.95528334  0.9665134
  -0.91358584]
 [-0.05505371 -0.0300293  -0.03598022 ...,  0.95564866  0.96675164
  -0.91347355]
 [-0.05505371 -0.0300293  -0.03598022 ...,  0.94762158  0.96435553
  -0.90893507]
 ...,
 [ 0.02738953 -0.07226562 -0.00852966 ...,  0.79986376  0.9352262
   0.6249094 ]
 [-0.05505371 -0.0300293  -0.03598022 ...,  0.95554942  0.96615779
  -0.91202223]
 [ 0.13598633  0.02095032  0.05236816 ...,  0.79986376  0.9352262
   0.6249094 ]]
After layer decoder_rnn_l0_t0_i2h_output (20, 2048) <class 'numpy.float32'> [[-3.1537962   1.60689878  2.40509033 ..., -0.07363112  3.8524971
   0.60321623]
 [-3.14928484  1.60436988  2.40446734 ..., -0.07201958  3.84527731
   0.6017465 ]
 [-3.11936069  1.59729767  2.371104   ..., -0.0757234   3.83230948
   0.63586211]
 ...,
 [-2.60814023  1.59153056  1.59566426 ..., -0.72266966  3.27287388
   1.20637512]
 [-3.13945389  1.59822917  2.40284419 ..., -0.07429402  3.83248425
   0.60256231]
 [-2.90014791  1.66030943  1.57949793 ..., -1.6747613   3.106493
   1.66617441]]
After layer decoder_rnn_l0_t0_h2h_output (20, 2048) <class 'numpy.float32'> [[-0.33724502  0.4656111   1.77852893 ...,  0.68437576  1.28386259
   0.15805078]
 [-0.34027523  0.47261715  1.77501583 ...,  0.68191016  1.28069901
   0.15362267]
 [-0.37807608  0.46782511  1.76715386 ...,  0.62734854  1.2800107
   0.18554237]
 ...,
 [-0.55304015  0.53271306  1.51732433 ..., -0.1254251   1.26733017
   0.24962978]
 [-0.35428926  0.49052018  1.77466154 ...,  0.66812247  1.28308272
   0.14381054]
 [-0.55304015  0.53271306  1.51732433 ..., -0.1254251   1.26733017
   0.24962978]]
After layer _plus1052_0 (20, 2048) <class 'numpy.float32'> [[-3.49104118  2.07250977  4.1836195  ...,  0.61074466  5.13635969
   0.76126701]
 [-3.48956013  2.07698703  4.17948341 ...,  0.60989058  5.12597656
   0.75536919]
 [-3.49743676  2.06512284  4.13825798 ...,  0.55162513  5.11231995
   0.82140446]
 ...,
 [-3.1611805   2.12424374  3.11298847 ..., -0.84809476  4.54020405
   1.45600486]
 [-3.49374318  2.08874941  4.17750549 ...,  0.59382844  5.11556721
   0.74637282]
 [-3.45318794  2.19302249  3.09682226 ..., -1.8001864   4.37382317
   1.91580415]]
After layer decoder_rnn_l0_t0_slice_output0 (20, 512) <class 'numpy.float32'> [[-3.49104118  2.07250977  4.1836195  ...,  1.75254714  4.52378845
   2.73659134]
 [-3.48956013  2.07698703  4.17948341 ...,  1.74862385  4.52725887
   2.73230362]
 [-3.49743676  2.06512284  4.13825798 ...,  1.76211083  4.48673773
   2.70986009]
 ...,
 [-3.1611805   2.12424374  3.11298847 ...,  1.76832354  3.88772488
   2.05655885]
 [-3.49374318  2.08874941  4.17750549 ...,  1.73635316  4.52300692
   2.7242465 ]
 [-3.45318794  2.19302249  3.09682226 ...,  1.77603829  3.70576501
   2.07825851]]
After layer decoder_rnn_l0_t0_slice_output1 (20, 512) <class 'numpy.float32'> [[-1.9069407   2.28051281  2.35399628 ...,  3.1288352  -0.80875152
   1.91812491]
 [-1.91022015  2.27776074  2.35761356 ...,  3.11938429 -0.79806983
   1.91121781]
 [-1.94176877  2.28105378  2.34166861 ...,  3.06870842 -0.88793302
   1.90974855]
 ...,
 [-2.28137231  1.88644171  1.75149822 ...,  1.90331721 -0.6300723
   1.02162421]
 [-1.92505729  2.28216553  2.3532095  ...,  3.10104465 -0.78983772
   1.89622855]
 [-2.22724986  1.93353212  1.66274893 ...,  1.89937925 -0.0894483
   1.04703569]]
After layer decoder_rnn_l0_t0_slice_output2 (20, 512) <class 'numpy.float32'> [[-2.76464295 -3.03442407  2.82495761 ...,  4.20786476 -0.0959225
   2.13808417]
 [-2.75879908 -3.03445101  2.82506943 ...,  4.19631195 -0.10262838
   2.13510418]
 [-2.74441695 -3.00262713  2.80632496 ...,  4.1581049  -0.14906806
   2.1202569 ]
 ...,
 [-2.87022161 -2.04795384  1.71458292 ...,  3.63581061 -2.36408734
   1.78153121]
 [-2.73934698 -3.02942181  2.81825304 ...,  4.17629576 -0.12909749
   2.12655783]
 [-2.79660177 -2.05570364  1.62027311 ...,  3.55590177 -2.55923295
   1.81706655]]
After layer decoder_rnn_l0_t0_slice_output3 (20, 512) <class 'numpy.float32'> [[-3.27503252  2.49175024 -1.42303538 ...,  0.61074466  5.13635969
   0.76126701]
 [-3.27412319  2.49897242 -1.42851794 ...,  0.60989058  5.12597656
   0.75536919]
 [-3.30116463  2.55088902 -1.46974349 ...,  0.55162513  5.11231995
   0.82140446]
 ...,
 [-2.9927907   1.37423348 -0.80794019 ..., -0.84809476  4.54020405
   1.45600486]
 [-3.27664828  2.50776434 -1.4409306  ...,  0.59382844  5.11556721
   0.74637282]
 [-3.09084797  1.01673341 -2.79272437 ..., -1.8001864   4.37382317
   1.91580415]]
After layer decoder_rnn_l0_t0_o_output (20, 512) <class 'numpy.float32'> [[ 0.03643772  0.92356145  0.19418617 ...,  0.64811069  0.99415529
   0.68162876]
 [ 0.03646966  0.9240697   0.19332971 ...,  0.64791584  0.99409467
   0.68034744]
 [ 0.03553126  0.92763329  0.1869816  ...,  0.63451254  0.99401397
   0.69453442]
 ...,
 [ 0.04775263  0.79806322  0.30832958 ...,  0.29983267  0.98944139
   0.81092083]
 [ 0.03638104  0.92468435  0.19140129 ...,  0.64424306  0.99403328
   0.67838788]
 [ 0.04348635  0.73433578  0.0577186  ...,  0.14182837  0.98755395
   0.87166983]]
After layer decoder_rnn_l0_t0_f_output (20, 512) <class 'numpy.float32'> [[ 0.12932494  0.90725023  0.91325134 ...,  0.95806658  0.30815658
   0.87192923]
 [ 0.12895612  0.9070183   0.91353744 ...,  0.95768529  0.31043854
   0.87115592]
 [ 0.12545367  0.90729576  0.91226965 ...,  0.95558339  0.29153657
   0.87099087]
 ...,
 [ 0.09267749  0.86834925  0.85214168 ...,  0.87026656  0.34749416
   0.7352888 ]
 [ 0.12729868  0.90738916  0.91318899 ...,  0.95693576  0.3122035
   0.8694641 ]
 [ 0.09732999  0.87363988  0.84060663 ...,  0.86982119  0.47765285
   0.74020529]]
After layer _mul2104_0 (20, 512) <class 'numpy.float32'> [[ -4.27122833e-03  -3.44410920e+00   3.88744450e+00 ...,   4.15331173e+00
   -5.03019840e-02   3.12372661e+00]
 [ -4.29560384e-03  -3.44443679e+00   3.84190154e+00 ...,   4.05615425e+00
   -6.49432763e-02   3.04726028e+00]
 [ -3.72928660e-03  -3.40439510e+00   3.87590051e+00 ...,   3.91629696e+00
   -2.62049604e-02   2.92608595e+00]
 ...,
 [ -3.08910478e-03  -2.83241439e+00   3.23686838e+00 ...,   3.21091413e+00
   -4.73086536e-01   2.13056135e+00]
 [ -4.17730259e-03  -3.43993378e+00   3.82981205e+00 ...,   4.00243139e+00
   -8.77127349e-02   2.99354887e+00]
 [ -3.24418093e-03  -2.84967160e+00   3.19305229e+00 ...,   3.20927095e+00
   -6.50287569e-01   2.14480734e+00]]
After layer decoder_rnn_l0_t0_i_output (20, 512) <class 'numpy.float32'> [[ 0.02956821  0.88820237  0.98498559 ...,  0.85227382  0.9892686
   0.93915159]
 [ 0.02961074  0.88864625  0.98492438 ...,  0.85177916  0.98930538
   0.93890613]
 [ 0.02938525  0.88746685  0.98429984 ...,  0.85347378  0.988868
   0.93760598]
 ...,
 [ 0.04065299  0.89323735  0.9574253  ...,  0.85424906  0.97991955
   0.88660866]
 [ 0.02949078  0.8898049   0.98489493 ...,  0.85022324  0.9892602
   0.93844229]
 [ 0.03067393  0.89962119  0.95676148 ...,  0.85520697  0.9760083
   0.88877201]]
After layer decoder_rnn_l0_t0_c_output (20, 512) <class 'numpy.float32'> [[-0.99209374 -0.99538302  0.99298906 ...,  0.99955738 -0.09562938
   0.97258931]
 [-0.99200118 -0.99538326  0.99299061 ...,  0.99954706 -0.10226958
   0.97242767]
 [-0.99176872 -0.99508059  0.99272382 ...,  0.99951106 -0.14797363
   0.97160846]
 ...,
 [-0.99359387 -0.96726346  0.9372074  ...,  0.99861097 -0.9824698
   0.94485962]
 [-0.99168515 -0.99533671  0.99289471 ...,  0.99952853 -0.12838505
   0.97195899]
 [-0.99258143 -0.96775883  0.92466384 ...,  0.99837047 -0.98810083
   0.9485451 ]]
After layer _mul2105_0 (20, 512) <class 'numpy.float32'> [[-0.02933444 -0.88410157  0.97807992 ...,  0.85189658 -0.09460314
   0.91340882]
 [-0.02937389 -0.8845436   0.97802067 ...,  0.85139334 -0.10117584
   0.91301829]
 [-0.02914337 -0.88310105  0.97713792 ...,  0.85305649 -0.14632638
   0.91098589]
 ...,
 [-0.04039256 -0.86399585  0.89730608 ...,  0.85306251 -0.96274137
   0.83772075]
 [-0.02924557 -0.88565546  0.97789699 ...,  0.8498224  -0.12700622
   0.91212744]
 [-0.03044637 -0.87061638  0.88468277 ...,  0.85381335 -0.96439463
   0.84304035]]
After layer decoder_rnn_l0_t0_state_0 (20, 512) <class 'numpy.float32'> [[-0.03360567 -4.32821083  4.86552429 ...,  5.00520849 -0.14490512
   4.0371356 ]
 [-0.03366949 -4.32898045  4.81992245 ...,  4.90754747 -0.16611913
   3.96027851]
 [-0.03287266 -4.28749609  4.85303831 ...,  4.76935339 -0.17253134
   3.8370719 ]
 ...,
 [-0.04348167 -3.69641018  4.13417435 ...,  4.06397676 -1.43582797
   2.96828222]
 [-0.03342287 -4.32558918  4.80770922 ...,  4.85225391 -0.21471895
   3.90567636]
 [-0.03369055 -3.72028804  4.07773495 ...,  4.06308413 -1.6146822
   2.98784781]]
After layer activation1052_output (20, 512) <class 'numpy.float32'> [[-0.03359303 -0.99965203  0.99988121 ...,  0.99991012 -0.14389935
   0.99937731]
 [-0.03365678 -0.99965256  0.99986982 ...,  0.99989074 -0.16460776
   0.99927384]
 [-0.03286082 -0.99962252  0.99987817 ...,  0.999856   -0.17083956
   0.99907106]
 ...,
 [-0.04345429 -0.99876946  0.9994871  ...,  0.99940985 -0.89285475
   0.99473172]
 [-0.03341043 -0.99965024  0.9998666  ...,  0.99987799 -0.21147887
   0.99919009]
 [-0.03367781 -0.9988268   0.99942583 ...,  0.99940878 -0.92384899
   0.99493343]]
After layer decoder_rnn_l0_t0_out_0 (20, 512) <class 'numpy.float32'> [[-0.00122405 -0.92324007  0.1941631  ...,  0.64805245 -0.1430583
   0.68120432]
 [-0.00122745 -0.92374867  0.19330454 ...,  0.64784503 -0.1636357
   0.67985338]
 [-0.00116759 -0.92728311  0.18695882 ...,  0.63442117 -0.16981691
   0.69388926]
 ...,
 [-0.00207506 -0.79708117  0.30817145 ...,  0.29965574 -0.88342744
   0.80664867]
 [-0.00121551 -0.92436093  0.19137576 ...,  0.64416444 -0.21021704
   0.67783844]
 [-0.00146453 -0.73347425  0.05768546 ...,  0.14174452 -0.91235071
   0.86725342]]
After layer expand_dims1061_0 (20, 512, 1) <class 'numpy.float32'> [[[-0.00122405]
  [-0.92324007]
  [ 0.1941631 ]
  ...,
  [ 0.64805245]
  [-0.1430583 ]
  [ 0.68120432]]

 [[-0.00122745]
  [-0.92374867]
  [ 0.19330454]
  ...,
  [ 0.64784503]
  [-0.1636357 ]
  [ 0.67985338]]

 [[-0.00116759]
  [-0.92728311]
  [ 0.18695882]
  ...,
  [ 0.63442117]
  [-0.16981691]
  [ 0.69388926]]

 ...,
 [[-0.00207506]
  [-0.79708117]
  [ 0.30817145]
  ...,
  [ 0.29965574]
  [-0.88342744]
  [ 0.80664867]]

 [[-0.00121551]
  [-0.92436093]
  [ 0.19137576]
  ...,
  [ 0.64416444]
  [-0.21021704]
  [ 0.67783844]]

 [[-0.00146453]
  [-0.73347425]
  [ 0.05768546]
  ...,
  [ 0.14174452]
  [-0.91235071]
  [ 0.86725342]]]
After layer att_batch_dot_0 (20, 10, 1) <class 'numpy.float32'> [[[  5.15552819e-01]
  [  9.03315008e-01]
  [  1.56328321e+00]
  [  2.46437788e+00]
  [  2.32019329e+00]
  [  4.51573208e-02]
  [ -3.19557905e+00]
  [ -6.03116989e+00]
  [ -8.15645409e+00]
  [ -9.73990345e+00]]

 [[  5.17024279e-01]
  [  9.01328146e-01]
  [  1.56616461e+00]
  [  2.47191739e+00]
  [  2.33008289e+00]
  [  5.17780147e-02]
  [ -3.19460750e+00]
  [ -6.03394413e+00]
  [ -8.16023350e+00]
  [ -9.74261856e+00]]

 [[  5.02064586e-01]
  [  8.70244622e-01]
  [  1.49201727e+00]
  [  2.32262945e+00]
  [  2.07692456e+00]
  [ -3.10447067e-01]
  [ -3.64751005e+00]
  [ -6.55085087e+00]
  [ -8.71731853e+00]
  [ -1.03220215e+01]]

 [[  5.19737005e-01]
  [  9.05421197e-01]
  [  1.58209336e+00]
  [  2.50547361e+00]
  [  2.37903285e+00]
  [  1.04565039e-01]
  [ -3.14703608e+00]
  [ -5.99323702e+00]
  [ -8.12419415e+00]
  [ -9.70844746e+00]]

 [[  5.95291555e-01]
  [  1.00441396e+00]
  [  1.78266239e+00]
  [  2.84793401e+00]
  [  2.91369772e+00]
  [  8.42998266e-01]
  [ -2.22990561e+00]
  [ -4.94392586e+00]
  [ -7.00711584e+00]
  [ -8.58474541e+00]]

 [[  5.16112864e-01]
  [  9.04069185e-01]
  [  1.56719077e+00]
  [  2.47236490e+00]
  [  2.33264828e+00]
  [  6.02135509e-02]
  [ -3.17979336e+00]
  [ -6.01558161e+00]
  [ -8.14134312e+00]
  [ -9.72526264e+00]]

 [[  5.19842148e-01]
  [  8.74834061e-01]
  [  1.50594366e+00]
  [  2.33441925e+00]
  [  2.07770061e+00]
  [ -3.34860802e-01]
  [ -3.69474173e+00]
  [ -6.60156822e+00]
  [ -8.76518917e+00]
  [ -1.03694324e+01]]

 [[  5.14208674e-01]
  [  8.99088800e-01]
  [  1.55226398e+00]
  [  2.44188714e+00]
  [  2.28500915e+00]
  [  8.33775557e-04]
  [ -3.24411726e+00]
  [ -6.08072710e+00]
  [ -8.20582104e+00]
  [ -9.78878212e+00]]

 [[  6.06055915e-01]
  [  9.41574454e-01]
  [  1.64350581e+00]
  [  2.53306055e+00]
  [  2.41703963e+00]
  [  2.44602740e-01]
  [ -2.83547926e+00]
  [ -5.49038601e+00]
  [ -7.47498989e+00]
  [ -8.98496056e+00]]

 [[  4.98245627e-01]
  [  8.57579768e-01]
  [  1.46093309e+00]
  [  2.26048970e+00]
  [  1.97696137e+00]
  [ -4.43379492e-01]
  [ -3.80106926e+00]
  [ -6.71429825e+00]
  [ -8.88486385e+00]
  [ -1.04908504e+01]]

 [[  5.85480988e-01]
  [  1.00690222e+00]
  [  1.76532865e+00]
  [  2.81740785e+00]
  [  2.86813569e+00]
  [  7.82335341e-01]
  [ -2.29947925e+00]
  [ -5.01295853e+00]
  [ -7.06788397e+00]
  [ -8.63173103e+00]]

 [[  5.16875625e-01]
  [  9.01863873e-01]
  [  1.56645870e+00]
  [  2.47234869e+00]
  [  2.33129001e+00]
  [  5.45301400e-02]
  [ -3.19034362e+00]
  [ -6.02872419e+00]
  [ -8.15449142e+00]
  [ -9.73650551e+00]]

 [[  5.17990172e-01]
  [  9.04066026e-01]
  [  1.57199693e+00]
  [  2.48349476e+00]
  [  2.34869194e+00]
  [  7.62765408e-02]
  [ -3.16674185e+00]
  [ -6.00476885e+00]
  [ -8.13073158e+00]
  [ -9.71305466e+00]]

 [[  5.18449724e-01]
  [  9.02278960e-01]
  [  1.57280421e+00]
  [  2.48622203e+00]
  [  2.34913111e+00]
  [  6.78184703e-02]
  [ -3.18632722e+00]
  [ -6.03285217e+00]
  [ -8.16348743e+00]
  [ -9.74742317e+00]]

 [[  5.20474911e-01]
  [  9.02760863e-01]
  [  1.58031261e+00]
  [  2.50077224e+00]
  [  2.36703920e+00]
  [  8.13124031e-02]
  [ -3.18143797e+00]
  [ -6.03588581e+00]
  [ -8.17279816e+00]
  [ -9.76218796e+00]]

 [[  5.16113102e-01]
  [  7.61249065e-01]
  [  1.41968262e+00]
  [  2.14457130e+00]
  [  1.55596638e+00]
  [ -1.42125988e+00]
  [ -5.41543293e+00]
  [ -8.87604237e+00]
  [ -1.14138174e+01]
  [ -1.32233915e+01]]

 [[  5.21261334e-01]
  [  9.03981388e-01]
  [  1.58797967e+00]
  [  2.51735711e+00]
  [  2.38911247e+00]
  [  9.97588485e-02]
  [ -3.17218852e+00]
  [ -6.03527164e+00]
  [ -8.17768288e+00]
  [ -9.76948166e+00]]

 [[  5.48713446e-01]
  [  6.77705467e-01]
  [  1.23805070e+00]
  [  1.69484198e+00]
  [  7.78884411e-01]
  [ -2.47621322e+00]
  [ -6.62963581e+00]
  [ -1.01207457e+01]
  [ -1.26169882e+01]
  [ -1.43776855e+01]]

 [[  5.19134343e-01]
  [  9.02654350e-01]
  [  1.57659900e+00]
  [  2.49469948e+00]
  [  2.35984564e+00]
  [  7.50352591e-02]
  [ -3.18568420e+00]
  [ -6.03817081e+00]
  [ -8.17290306e+00]
  [ -9.75915432e+00]]

 [[  6.82399392e-01]
  [  1.36892414e+00]
  [  3.15228963e+00]
  [  5.73988199e+00]
  [  8.28917408e+00]
  [  9.42243576e+00]
  [  9.39163876e+00]
  [  8.93417645e+00]
  [  8.29112244e+00]
  [  7.54603910e+00]]]
After layer swapaxes25_output (10, 20, 1) <class 'numpy.float32'> [[[  5.15552819e-01]
  [  5.17024279e-01]
  [  5.02064586e-01]
  [  5.19737005e-01]
  [  5.95291555e-01]
  [  5.16112864e-01]
  [  5.19842148e-01]
  [  5.14208674e-01]
  [  6.06055915e-01]
  [  4.98245627e-01]
  [  5.85480988e-01]
  [  5.16875625e-01]
  [  5.17990172e-01]
  [  5.18449724e-01]
  [  5.20474911e-01]
  [  5.16113102e-01]
  [  5.21261334e-01]
  [  5.48713446e-01]
  [  5.19134343e-01]
  [  6.82399392e-01]]

 [[  9.03315008e-01]
  [  9.01328146e-01]
  [  8.70244622e-01]
  [  9.05421197e-01]
  [  1.00441396e+00]
  [  9.04069185e-01]
  [  8.74834061e-01]
  [  8.99088800e-01]
  [  9.41574454e-01]
  [  8.57579768e-01]
  [  1.00690222e+00]
  [  9.01863873e-01]
  [  9.04066026e-01]
  [  9.02278960e-01]
  [  9.02760863e-01]
  [  7.61249065e-01]
  [  9.03981388e-01]
  [  6.77705467e-01]
  [  9.02654350e-01]
  [  1.36892414e+00]]

 [[  1.56328321e+00]
  [  1.56616461e+00]
  [  1.49201727e+00]
  [  1.58209336e+00]
  [  1.78266239e+00]
  [  1.56719077e+00]
  [  1.50594366e+00]
  [  1.55226398e+00]
  [  1.64350581e+00]
  [  1.46093309e+00]
  [  1.76532865e+00]
  [  1.56645870e+00]
  [  1.57199693e+00]
  [  1.57280421e+00]
  [  1.58031261e+00]
  [  1.41968262e+00]
  [  1.58797967e+00]
  [  1.23805070e+00]
  [  1.57659900e+00]
  [  3.15228963e+00]]

 [[  2.46437788e+00]
  [  2.47191739e+00]
  [  2.32262945e+00]
  [  2.50547361e+00]
  [  2.84793401e+00]
  [  2.47236490e+00]
  [  2.33441925e+00]
  [  2.44188714e+00]
  [  2.53306055e+00]
  [  2.26048970e+00]
  [  2.81740785e+00]
  [  2.47234869e+00]
  [  2.48349476e+00]
  [  2.48622203e+00]
  [  2.50077224e+00]
  [  2.14457130e+00]
  [  2.51735711e+00]
  [  1.69484198e+00]
  [  2.49469948e+00]
  [  5.73988199e+00]]

 [[  2.32019329e+00]
  [  2.33008289e+00]
  [  2.07692456e+00]
  [  2.37903285e+00]
  [  2.91369772e+00]
  [  2.33264828e+00]
  [  2.07770061e+00]
  [  2.28500915e+00]
  [  2.41703963e+00]
  [  1.97696137e+00]
  [  2.86813569e+00]
  [  2.33129001e+00]
  [  2.34869194e+00]
  [  2.34913111e+00]
  [  2.36703920e+00]
  [  1.55596638e+00]
  [  2.38911247e+00]
  [  7.78884411e-01]
  [  2.35984564e+00]
  [  8.28917408e+00]]

 [[  4.51573208e-02]
  [  5.17780147e-02]
  [ -3.10447067e-01]
  [  1.04565039e-01]
  [  8.42998266e-01]
  [  6.02135509e-02]
  [ -3.34860802e-01]
  [  8.33775557e-04]
  [  2.44602740e-01]
  [ -4.43379492e-01]
  [  7.82335341e-01]
  [  5.45301400e-02]
  [  7.62765408e-02]
  [  6.78184703e-02]
  [  8.13124031e-02]
  [ -1.42125988e+00]
  [  9.97588485e-02]
  [ -2.47621322e+00]
  [  7.50352591e-02]
  [  9.42243576e+00]]

 [[ -3.19557905e+00]
  [ -3.19460750e+00]
  [ -3.64751005e+00]
  [ -3.14703608e+00]
  [ -2.22990561e+00]
  [ -3.17979336e+00]
  [ -3.69474173e+00]
  [ -3.24411726e+00]
  [ -2.83547926e+00]
  [ -3.80106926e+00]
  [ -2.29947925e+00]
  [ -3.19034362e+00]
  [ -3.16674185e+00]
  [ -3.18632722e+00]
  [ -3.18143797e+00]
  [ -5.41543293e+00]
  [ -3.17218852e+00]
  [ -6.62963581e+00]
  [ -3.18568420e+00]
  [  9.39163876e+00]]

 [[ -6.03116989e+00]
  [ -6.03394413e+00]
  [ -6.55085087e+00]
  [ -5.99323702e+00]
  [ -4.94392586e+00]
  [ -6.01558161e+00]
  [ -6.60156822e+00]
  [ -6.08072710e+00]
  [ -5.49038601e+00]
  [ -6.71429825e+00]
  [ -5.01295853e+00]
  [ -6.02872419e+00]
  [ -6.00476885e+00]
  [ -6.03285217e+00]
  [ -6.03588581e+00]
  [ -8.87604237e+00]
  [ -6.03527164e+00]
  [ -1.01207457e+01]
  [ -6.03817081e+00]
  [  8.93417645e+00]]

 [[ -8.15645409e+00]
  [ -8.16023350e+00]
  [ -8.71731853e+00]
  [ -8.12419415e+00]
  [ -7.00711584e+00]
  [ -8.14134312e+00]
  [ -8.76518917e+00]
  [ -8.20582104e+00]
  [ -7.47498989e+00]
  [ -8.88486385e+00]
  [ -7.06788397e+00]
  [ -8.15449142e+00]
  [ -8.13073158e+00]
  [ -8.16348743e+00]
  [ -8.17279816e+00]
  [ -1.14138174e+01]
  [ -8.17768288e+00]
  [ -1.26169882e+01]
  [ -8.17290306e+00]
  [  8.29112244e+00]]

 [[ -9.73990345e+00]
  [ -9.74261856e+00]
  [ -1.03220215e+01]
  [ -9.70844746e+00]
  [ -8.58474541e+00]
  [ -9.72526264e+00]
  [ -1.03694324e+01]
  [ -9.78878212e+00]
  [ -8.98496056e+00]
  [ -1.04908504e+01]
  [ -8.63173103e+00]
  [ -9.73650551e+00]
  [ -9.71305466e+00]
  [ -9.74742317e+00]
  [ -9.76218796e+00]
  [ -1.32233915e+01]
  [ -9.76948166e+00]
  [ -1.43776855e+01]
  [ -9.75915432e+00]
  [  7.54603910e+00]]]
After layer sequencemask8_output (10, 20, 1) <class 'numpy.float32'> [[[  5.15552819e-01]
  [  5.17024279e-01]
  [  5.02064586e-01]
  [  5.19737005e-01]
  [  5.95291555e-01]
  [  5.16112864e-01]
  [  5.19842148e-01]
  [  5.14208674e-01]
  [  6.06055915e-01]
  [  4.98245627e-01]
  [  5.85480988e-01]
  [  5.16875625e-01]
  [  5.17990172e-01]
  [  5.18449724e-01]
  [  5.20474911e-01]
  [  5.16113102e-01]
  [  5.21261334e-01]
  [  5.48713446e-01]
  [  5.19134343e-01]
  [  6.82399392e-01]]

 [[  9.03315008e-01]
  [  9.01328146e-01]
  [  8.70244622e-01]
  [  9.05421197e-01]
  [  1.00441396e+00]
  [  9.04069185e-01]
  [  8.74834061e-01]
  [  8.99088800e-01]
  [  9.41574454e-01]
  [  8.57579768e-01]
  [  1.00690222e+00]
  [  9.01863873e-01]
  [  9.04066026e-01]
  [  9.02278960e-01]
  [  9.02760863e-01]
  [  7.61249065e-01]
  [  9.03981388e-01]
  [  6.77705467e-01]
  [  9.02654350e-01]
  [  1.36892414e+00]]

 [[ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]]
After layer swapaxes26_output (20, 10, 1) <class 'numpy.float32'> [[[  5.15552819e-01]
  [  9.03315008e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  5.17024279e-01]
  [  9.01328146e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  5.02064586e-01]
  [  8.70244622e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  5.19737005e-01]
  [  9.05421197e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  5.95291555e-01]
  [  1.00441396e+00]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  5.16112864e-01]
  [  9.04069185e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  5.19842148e-01]
  [  8.74834061e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  5.14208674e-01]
  [  8.99088800e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  6.06055915e-01]
  [  9.41574454e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  4.98245627e-01]
  [  8.57579768e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  5.85480988e-01]
  [  1.00690222e+00]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  5.16875625e-01]
  [  9.01863873e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  5.17990172e-01]
  [  9.04066026e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  5.18449724e-01]
  [  9.02278960e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  5.20474911e-01]
  [  9.02760863e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  5.16113102e-01]
  [  7.61249065e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  5.21261334e-01]
  [  9.03981388e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  5.48713446e-01]
  [  6.77705467e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  5.19134343e-01]
  [  9.02654350e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  6.82399392e-01]
  [  1.36892414e+00]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]]
After layer attention_softmax_0 (20, 10, 1) <class 'numpy.float32'> [[[ 0.40425614]
  [ 0.59574389]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40508929]
  [ 0.59491074]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40898088]
  [ 0.59101915]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40475667]
  [ 0.59524333]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.39912257]
  [ 0.6008774 ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40420935]
  [ 0.59579062]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.41217244]
  [ 0.58782762]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40495041]
  [ 0.59504956]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.41689849]
  [ 0.58310151]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.41112074]
  [ 0.58887923]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.3961767 ]
  [ 0.6038233 ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40492436]
  [ 0.59507567]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40466231]
  [ 0.59533769]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40520364]
  [ 0.59479636]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40557569]
  [ 0.59442437]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.43902105]
  [ 0.56097895]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.405471  ]
  [ 0.59452897]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.46779665]
  [ 0.53220338]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40527818]
  [ 0.59472179]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.33480662]
  [ 0.66519344]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]]
After layer batch_dot8_0 (20, 512, 1) <class 'numpy.float32'> [[[ 0.01782881]
  [ 0.03941238]
  [-0.03338346]
  ...,
  [-0.0109505 ]
  [ 0.00999219]
  [-0.02461718]]

 [[ 0.0178087 ]
  [ 0.03938917]
  [-0.03334595]
  ...,
  [-0.01094589]
  [ 0.00999123]
  [-0.02463191]]

 [[ 0.01771476]
  [ 0.03928077]
  [-0.03317078]
  ...,
  [-0.01092437]
  [ 0.00998675]
  [-0.0247007 ]]

 ...,
 [[ 0.01629504]
  [ 0.03764237]
  [-0.03052329]
  ...,
  [-0.01059905]
  [ 0.00991899]
  [-0.02574042]]

 [[ 0.01780414]
  [ 0.03938391]
  [-0.03333744]
  ...,
  [-0.01094484]
  [ 0.00999101]
  [-0.02463525]]

 [[ 0.01950522]
  [ 0.041347  ]
  [-0.0365096 ]
  ...,
  [-0.01133463]
  [ 0.01007219]
  [-0.0233895 ]]]
After layer reshape16_0 (20, 512) <class 'numpy.float32'> [[ 0.01782881  0.03941238 -0.03338346 ..., -0.0109505   0.00999219
  -0.02461718]
 [ 0.0178087   0.03938917 -0.03334595 ..., -0.01094589  0.00999123
  -0.02463191]
 [ 0.01771476  0.03928077 -0.03317078 ..., -0.01092437  0.00998675
  -0.0247007 ]
 ...,
 [ 0.01629504  0.03764237 -0.03052329 ..., -0.01059905  0.00991899
  -0.02574042]
 [ 0.01780414  0.03938391 -0.03333744 ..., -0.01094484  0.00999101
  -0.02463525]
 [ 0.01950522  0.041347   -0.0365096  ..., -0.01133463  0.01007219
  -0.0233895 ]]
After layer decoder_rnn_hidden_concat_t0_output (20, 1024) <class 'numpy.float32'> [[-0.00122405 -0.92324007  0.1941631  ..., -0.0109505   0.00999219
  -0.02461718]
 [-0.00122745 -0.92374867  0.19330454 ..., -0.01094589  0.00999123
  -0.02463191]
 [-0.00116759 -0.92728311  0.18695882 ..., -0.01092437  0.00998675
  -0.0247007 ]
 ...,
 [-0.00207506 -0.79708117  0.30817145 ..., -0.01059905  0.00991899
  -0.02574042]
 [-0.00121551 -0.92436093  0.19137576 ..., -0.01094484  0.00999101
  -0.02463525]
 [-0.00146453 -0.73347425  0.05768546 ..., -0.01133463  0.01007219
  -0.0233895 ]]
After layer decoder_rnn_hidden_fc_t0_output (20, 512) <class 'numpy.float32'> [[-1.91733384  0.20252652 -0.80180895 ...,  1.9241066   2.07246208
  -1.57765961]
 [-1.92171252  0.20247144 -0.80549008 ...,  1.92644513  2.07515979
  -1.57522452]
 [-1.87895536  0.21738224 -0.80347699 ...,  1.89353836  2.05503225
  -1.57049334]
 ...,
 [-1.54492331 -0.9657498   0.51359254 ...,  1.2054913   2.31625652
  -1.89997578]
 [-1.92347777  0.20791966 -0.81234974 ...,  1.92814434  2.06943274
  -1.5704515 ]
 [-0.97308266 -0.49460268 -0.23187591 ...,  1.40920877  1.673401
   0.58626962]]
After layer decoder_rnn_next_hidden_t0_output (20, 512) <class 'numpy.float32'> [[-0.95769709  0.1998022  -0.66504687 ...,  0.95825434  0.96880502
  -0.9182356 ]
 [-0.95805818  0.19974932 -0.66709483 ...,  0.95844507  0.96897024
  -0.91785282]
 [-0.95439911  0.21402161 -0.66597611 ...,  0.95568085  0.96771622
  -0.91710418]
 ...,
 [-0.91294396 -0.74683058  0.47273958 ...,  0.8353219   0.98072696
  -0.95623541]
 [-0.9582029   0.20497441 -0.67088449 ...,  0.95858312  0.96861839
  -0.91709757]
 [-0.75005585 -0.45786187 -0.22780767 ...,  0.887326    0.93199992
   0.52720737]]
After layer logits_output (20, 16743) <class 'numpy.float32'> [[-1.98443842 -2.81766868 -2.40821362 ..., -2.10066748 -3.49304676
  -2.55918074]
 [-1.98571408 -2.8141191  -2.40665317 ..., -2.09933305 -3.48921227
  -2.55785441]
 [-1.96580255 -2.81125307 -2.40532804 ..., -2.10139298 -3.47907996
  -2.5451436 ]
 ...,
 [-1.68135095 -3.2246201  -2.78804684 ..., -2.32136297 -3.37439942
  -3.17517877]
 [-1.98195565 -2.80836296 -2.40062571 ..., -2.0965476  -3.48024559
  -2.55632925]
 [-1.53921473 -2.69541907 -0.92632276 ..., -1.54638648 -2.60524178
  -1.61014175]]
After layer softmax_0 (20, 16743) <class 'numpy.float32'> [[  8.57473310e-07   3.72694501e-07   5.61276863e-07 ...,   7.63383071e-07
    1.89688095e-07   4.82628252e-07]
 [  8.61519197e-07   3.76264381e-07   5.65526932e-07 ...,   7.68990446e-07
    1.91559664e-07   4.86169199e-07]
 [  9.06069602e-07   3.89033204e-07   5.83818746e-07 ...,   7.91180014e-07
    1.99504754e-07   5.07640834e-07]
 ...,
 [  8.25184401e-08   1.76326704e-08   2.72847114e-08 ...,   4.35108731e-08
    1.51799160e-08   1.85263467e-08]
 [  8.83623386e-07   3.86690061e-07   5.81354243e-07 ...,   7.87953695e-07
    1.97500441e-07   4.97530948e-07]
 [  7.00740975e-06   2.20508014e-06   1.29340087e-05 ...,   6.95733479e-06
    2.41317048e-06   6.52761400e-06]]
After layer reshape17_0 (20, 10) <class 'numpy.float32'> [[ 0.40425614  0.59574389  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40508929  0.59491074  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40898088  0.59101915  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40475667  0.59524333  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.39912257  0.6008774   0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40420935  0.59579062  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.41217244  0.58782762  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40495041  0.59504956  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.41689849  0.58310151  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.41112074  0.58887923  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.3961767   0.6038233   0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40492436  0.59507567  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40466231  0.59533769  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40520364  0.59479636  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40557569  0.59442437  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.43902105  0.56097895  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.405471    0.59452897  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.46779665  0.53220338  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40527818  0.59472179  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.33480662  0.66519344  0.          0.          0.          0.          0.
   0.          0.          0.        ]]
After layer target_embed_embed_0 (20, 256) <class 'numpy.float32'> [[-0.05505371 -0.0300293  -0.03598022 ...,  0.08459473 -0.05288696
  -0.01667786]
 [-0.05505371 -0.0300293  -0.03598022 ...,  0.08459473 -0.05288696
  -0.01667786]
 [-0.05505371 -0.0300293  -0.03598022 ...,  0.08459473 -0.05288696
  -0.01667786]
 ...,
 [-0.05505371 -0.0300293  -0.03598022 ...,  0.08459473 -0.05288696
  -0.01667786]
 [ 0.02738953 -0.07226562 -0.00852966 ...,  0.02572632  0.00955963
  -0.04855347]
 [-0.05505371 -0.0300293  -0.03598022 ...,  0.08459473 -0.05288696
  -0.01667786]]
After layer decoder_rnn_concat_target_context_t0_output (20, 768) <class 'numpy.float32'> [[-0.05505371 -0.0300293  -0.03598022 ...,  0.95825434  0.96880502
  -0.9182356 ]
 [-0.05505371 -0.0300293  -0.03598022 ...,  0.95844507  0.96897024
  -0.91785282]
 [-0.05505371 -0.0300293  -0.03598022 ...,  0.95568085  0.96771622
  -0.91710418]
 ...,
 [-0.05505371 -0.0300293  -0.03598022 ...,  0.95881933  0.96846616
  -0.91711652]
 [ 0.02738953 -0.07226562 -0.00852966 ...,  0.887326    0.93199992
   0.52720737]
 [-0.05505371 -0.0300293  -0.03598022 ...,  0.95858312  0.96861839
  -0.91709757]]
After layer decoder_rnn_l0_t0_i2h_output (20, 2048) <class 'numpy.float32'> [[-3.17434859  1.61248064  2.42261815 ..., -0.07334859  3.86388779
   0.60057729]
 [-3.17201948  1.61094975  2.42161226 ..., -0.07330644  3.85908389
   0.60077858]
 [-3.15441513  1.60711634  2.40664339 ..., -0.06812942  3.85387707
   0.61150181]
 ...,
 [-3.16272545  1.60421085  2.42212224 ..., -0.07436764  3.84561396
   0.60333145]
 [-2.59746242  1.37308455  1.65689147 ..., -0.57287073  3.24912071
   0.87009627]
 [-3.16569757  1.60695148  2.42137742 ..., -0.07413152  3.85054851
   0.60048884]]
After layer decoder_rnn_l0_t0_h2h_output (20, 2048) <class 'numpy.float32'> [[-0.32626143  0.47139141  1.80198205 ...,  0.6966756   1.29289818
   0.16495377]
 [-0.32821935  0.47484776  1.79999566 ...,  0.69330245  1.29037833
   0.16258644]
 [-0.34596258  0.47929341  1.79062498 ...,  0.67780256  1.2992512
   0.16210283]
 ...,
 [-0.34358644  0.49744329  1.80279589 ...,  0.68240249  1.29656696
   0.15180872]
 [-0.53531063  0.55291837  1.47181976 ...,  0.04070716  1.24849367
   0.10231215]
 [-0.33643001  0.48785341  1.79946876 ...,  0.68422979  1.2941184
   0.15313108]]
After layer _plus1053_0 (20, 2048) <class 'numpy.float32'> [[-3.50061011  2.08387208  4.22460032 ...,  0.62332702  5.15678596
   0.76553106]
 [-3.5002389   2.08579755  4.22160816 ...,  0.61999601  5.14946222
   0.76336503]
 [-3.50037766  2.08640981  4.19726849 ...,  0.60967314  5.15312815
   0.77360463]
 ...,
 [-3.50631189  2.10165405  4.22491837 ...,  0.60803485  5.14218092
   0.75514019]
 [-3.13277292  1.92600298  3.12871122 ..., -0.53216356  4.49761438
   0.97240841]
 [-3.50212765  2.09480476  4.22084618 ...,  0.61009824  5.14466667
   0.75361991]]
After layer decoder_rnn_l0_t0_slice_output0 (20, 512) <class 'numpy.float32'> [[-3.50061011  2.08387208  4.22460032 ...,  1.75682557  4.56046009
   2.76228762]
 [-3.5002389   2.08579755  4.22160816 ...,  1.75318682  4.56452084
   2.75930262]
 [-3.50037766  2.08640981  4.19726849 ...,  1.7617805   4.52573395
   2.74588251]
 ...,
 [-3.50631189  2.10165405  4.22491837 ...,  1.73774445  4.56334782
   2.75308704]
 [-3.13277292  1.92600298  3.12871122 ...,  1.68088806  3.74545097
   2.13021159]
 [-3.50212765  2.09480476  4.22084618 ...,  1.74432266  4.56024647
   2.7535398 ]]
After layer decoder_rnn_l0_t0_slice_output1 (20, 512) <class 'numpy.float32'> [[-1.88411188  2.28978181  2.39240074 ...,  3.14911222 -0.76630783
   1.94566548]
 [-1.88533318  2.28941607  2.39335966 ...,  3.14337349 -0.7583881
   1.94235158]
 [-1.90429139  2.28406382  2.38578987 ...,  3.12344837 -0.80785024
   1.92950082]
 ...,
 [-1.89840937  2.296731    2.39361429 ...,  3.1271584  -0.74121916
   1.92756176]
 [-2.00152349  1.83696723  1.72043145 ...,  2.01443744 -0.4510341
   1.0039103 ]
 [-1.89562833  2.29191637  2.38995171 ...,  3.13142729 -0.75165755
   1.93279517]]
After layer decoder_rnn_l0_t0_slice_output2 (20, 512) <class 'numpy.float32'> [[-2.79150271 -3.06074429  2.8449626  ...,  4.23944283 -0.07144293
   2.15299416]
 [-2.78849173 -3.05956411  2.84305048 ...,  4.23345852 -0.07778975
   2.15087485]
 [-2.78259373 -3.05387831  2.85072517 ...,  4.20352268 -0.09664935
   2.14660645]
 ...,
 [-2.77025223 -3.06074953  2.84063554 ...,  4.21346045 -0.10788611
   2.14042664]
 [-2.64027929 -1.90806746  1.59300303 ...,  3.41146421 -2.50162005
   1.69101548]
 [-2.77720642 -3.05753827  2.84054327 ...,  4.2192688  -0.09567311
   2.14698601]]
After layer decoder_rnn_l0_t0_slice_output3 (20, 512) <class 'numpy.float32'> [[-3.26914835  2.47159648 -1.41308153 ...,  0.62332702  5.15678596
   0.76553106]
 [-3.27062774  2.47558594 -1.41602099 ...,  0.61999601  5.14946222
   0.76336503]
 [-3.27808094  2.51658368 -1.4392302  ...,  0.60967314  5.15312815
   0.77360463]
 ...,
 [-3.27420282  2.48150444 -1.43074059 ...,  0.60803485  5.14218092
   0.75514019]
 [-2.87642288  1.49274051 -0.93935603 ..., -0.53216356  4.49761438
   0.97240841]
 [-3.27299666  2.4821527  -1.42479873 ...,  0.61009824  5.14466667
   0.75361991]]
After layer decoder_rnn_l0_t0_o_output (20, 512) <class 'numpy.float32'> [[ 0.03664488  0.92212653  0.19574846 ...,  0.65097487  0.99427277
   0.68255341]
 [ 0.03659269  0.92241246  0.19528614 ...,  0.65021765  0.99423099
   0.6820839 ]
 [ 0.03633085  0.92529625  0.19166458 ...,  0.64786619  0.99425197
   0.68430012]
 ...,
 [ 0.03646687  0.92283499  0.19298331 ...,  0.64749241  0.99418902
   0.68029767]
 [ 0.05333145  0.81648922  0.28103045 ...,  0.37001243  0.98898703
   0.72559929]
 [ 0.03650927  0.92288119  0.19391039 ...,  0.64796323  0.99420339
   0.67996693]]
After layer decoder_rnn_l0_t0_f_output (20, 512) <class 'numpy.float32'> [[ 0.1319173   0.90802723  0.916246   ...,  0.95887375  0.31727833
   0.87497324]
 [ 0.1317775   0.90799665  0.91631961 ...,  0.95864677  0.31899634
   0.87461025]
 [ 0.12962355  0.90754861  0.91573733 ...,  0.95784968  0.3083488
   0.87319416]
 ...,
 [ 0.13028862  0.90860593  0.9163391  ...,  0.95799923  0.3227376
   0.87297928]
 [ 0.11904306  0.8625896   0.84818441 ...,  0.88230461  0.38911492
   0.73182666]
 [ 0.13060406  0.90820539  0.91605783 ...,  0.95817065  0.32046023
   0.87355846]]
After layer _mul2106_0 (20, 512) <class 'numpy.float32'> [[ -4.43316903e-03  -3.93013334e+00   4.45801735e+00 ...,   4.79936314e+00
   -4.59752530e-02   3.53238559e+00]
 [ -4.43688175e-03  -3.93069983e+00   4.41658926e+00 ...,   4.70460463e+00
   -5.29913940e-02   3.46370006e+00]
 [ -4.26107040e-03  -3.89111114e+00   4.44410849e+00 ...,   4.56832361e+00
   -5.31998314e-02   3.35050869e+00]
 ...,
 [ -4.30538971e-03  -3.91553140e+00   4.37361526e+00 ...,   4.65196276e+00
   -8.24064091e-02   3.36449742e+00]
 [ -4.01062658e-03  -3.20908165e+00   3.45867109e+00 ...,   3.58487797e+00
   -6.28296912e-01   2.18658662e+00]
 [ -4.36516292e-03  -3.92852330e+00   4.40413952e+00 ...,   4.64928722e+00
   -6.88088834e-02   3.41183662e+00]]
After layer decoder_rnn_l0_t0_i_output (20, 512) <class 'numpy.float32'> [[ 0.02929488  0.8893258   0.98557985 ...,  0.85281157  0.98965096
   0.94060355]
 [ 0.02930543  0.8895151   0.98553723 ...,  0.85235435  0.98969251
   0.9404366 ]
 [ 0.02930149  0.88957524  0.98518616 ...,  0.85343248  0.98928928
   0.93968046]
 ...,
 [ 0.02913317  0.89106387  0.98558432 ...,  0.85040033  0.98968047
   0.94008744]
 [ 0.04177547  0.87280631  0.9580617  ...,  0.84302211  0.97692025
   0.89380515]
 [ 0.02925175  0.89039719  0.98552632 ...,  0.85123527  0.98964882
   0.94011295]]
After layer decoder_rnn_l0_t0_c_output (20, 512) <class 'numpy.float32'> [[-0.99250567 -0.99561924  0.99326307 ...,  0.99958444 -0.07132163
   0.9733839 ]
 [-0.99246061 -0.99560893  0.99323738 ...,  0.99957949 -0.07763322
   0.97327232]
 [-0.9923715  -0.9955588   0.99334002 ...,  0.9995535  -0.09634954
   0.9730463 ]
 ...,
 [-0.9921816  -0.9956193   0.99320471 ...,  0.99956232 -0.10746947
   0.97271568]
 [-0.9898724  -0.95692283  0.92060852 ...,  0.99782532 -0.98665732
   0.9342764 ]
 [-0.99228919 -0.9955911   0.99320346 ...,  0.99956739 -0.09538227
   0.97306645]]
After layer _mul2107_0 (20, 512) <class 'numpy.float32'> [[-0.02907533 -0.88542986  0.97894007 ...,  0.85245717 -0.07058352
   0.91556835]
 [-0.02908449 -0.88560915  0.97887242 ...,  0.85199594 -0.07683302
   0.91530091]
 [-0.02907796 -0.88562447  0.97862482 ...,  0.85305142 -0.09531756
   0.9143526 ]
 ...,
 [-0.0289054  -0.88716036  0.97888696 ...,  0.85002816 -0.10636044
   0.91443777]
 [-0.04135238 -0.8352083   0.88199973 ...,  0.84118879 -0.96388549
   0.83506107]
 [-0.0290262  -0.88647151  0.97882813 ...,  0.85086703 -0.09439495
   0.91479236]]
After layer decoder_rnn_l0_t0_state_0 (20, 512) <class 'numpy.float32'> [[-0.0335085  -4.8155632   5.43695736 ...,  5.65182018 -0.11655878
   4.44795418]
 [-0.03352137 -4.81630898  5.39546156 ...,  5.55660057 -0.12982441
   4.37900114]
 [-0.03333903 -4.77673578  5.42273331 ...,  5.42137527 -0.1485174
   4.26486111]
 ...,
 [-0.03321078 -4.80269194  5.35250235 ...,  5.5019908  -0.18876684
   4.27893543]
 [-0.04536301 -4.04429007  4.34067059 ...,  4.42606688 -1.5921824
   3.02164769]
 [-0.03339136 -4.81499481  5.38296747 ...,  5.5001545  -0.16320384
   4.32662916]]
After layer activation1053_output (20, 512) <class 'numpy.float32'> [[-0.03349596 -0.99986869  0.99996209 ...,  0.99997532 -0.11603378
   0.99972612]
 [-0.03350882 -0.99986887  0.99995881 ...,  0.9999702  -0.12909994
   0.99968565]
 [-0.03332669 -0.99985808  0.99996102 ...,  0.9999609  -0.14743498
   0.99960506]
 ...,
 [-0.03319858 -0.99986529  0.99995512 ...,  0.99996674 -0.18655623
   0.99961603]
 [-0.04533191 -0.99938613  0.99966061 ...,  0.9997139  -0.92048329
   0.99526381]
 [-0.03337895 -0.99986857  0.9999578  ...,  0.99996662 -0.16177011
   0.99965096]]
After layer decoder_rnn_l0_t0_out_0 (20, 512) <class 'numpy.float32'> [[-0.00122746 -0.92200547  0.19574104 ...,  0.65095878 -0.11536922
   0.68236649]
 [-0.00122618 -0.92229152  0.19527809 ...,  0.65019828 -0.12835516
   0.68186951]
 [-0.00121079 -0.92516494  0.19165711 ...,  0.64784086 -0.14658752
   0.68402988]
 ...,
 [-0.00121065 -0.92271066  0.19297466 ...,  0.64747089 -0.18547216
   0.68003649]
 [-0.00241762 -0.815988    0.28093508 ...,  0.36990657 -0.91034603
   0.72216272]
 [-0.00121864 -0.92275989  0.19390221 ...,  0.64794159 -0.16083239
   0.67972958]]
After layer expand_dims1062_0 (20, 512, 1) <class 'numpy.float32'> [[[-0.00122746]
  [-0.92200547]
  [ 0.19574104]
  ...,
  [ 0.65095878]
  [-0.11536922]
  [ 0.68236649]]

 [[-0.00122618]
  [-0.92229152]
  [ 0.19527809]
  ...,
  [ 0.65019828]
  [-0.12835516]
  [ 0.68186951]]

 [[-0.00121079]
  [-0.92516494]
  [ 0.19165711]
  ...,
  [ 0.64784086]
  [-0.14658752]
  [ 0.68402988]]

 ...,
 [[-0.00121065]
  [-0.92271066]
  [ 0.19297466]
  ...,
  [ 0.64747089]
  [-0.18547216]
  [ 0.68003649]]

 [[-0.00241762]
  [-0.815988  ]
  [ 0.28093508]
  ...,
  [ 0.36990657]
  [-0.91034603]
  [ 0.72216272]]

 [[-0.00121864]
  [-0.92275989]
  [ 0.19390221]
  ...,
  [ 0.64794159]
  [-0.16083239]
  [ 0.67972958]]]
After layer att_batch_dot_0 (20, 10, 1) <class 'numpy.float32'> [[[  0.52264464]
  [  0.91408318]
  [  1.59161615]
  [  2.52052402]
  [  2.40674353]
  [  0.15161826]
  [ -3.07905149]
  [ -5.9101882 ]
  [ -8.03540325]
  [ -9.62234974]]

 [[  0.52367812]
  [  0.91290116]
  [  1.59403837]
  [  2.52644897]
  [  2.41515231]
  [  0.15930861]
  [ -3.07370138]
  [ -5.90620565]
  [ -8.03121948]
  [ -9.61678505]]

 [[  0.51593363]
  [  0.89754879]
  [  1.55112708]
  [  2.43716145]
  [  2.26091886]
  [ -0.06370907]
  [ -3.35407233]
  [ -6.22824907]
  [ -8.3805275 ]
  [ -9.98156166]]

 [[  0.52559811]
  [  0.91628838]
  [  1.60516262]
  [  2.54950905]
  [  2.44846892]
  [  0.19469039]
  [ -3.04264355]
  [ -5.88082838]
  [ -8.01006031]
  [ -9.59773827]]

 [[  0.52675295]
  [  0.89806706]
  [  1.56208062]
  [  2.45200944]
  [  2.27011061]
  [ -0.07971668]
  [ -3.3944602 ]
  [ -6.2735815 ]
  [ -8.42361832]
  [-10.02244377]]

 [[  0.52268708]
  [  0.91410577]
  [  1.59356439]
  [  2.52456784]
  [  2.4126544 ]
  [  0.15779737]
  [ -3.073874  ]
  [ -5.9063797 ]
  [ -8.03285313]
  [ -9.62078667]]

 [[  0.52268577]
  [  0.90687257]
  [  1.5767101 ]
  [  2.48542237]
  [  2.33342481]
  [  0.02430105]
  [ -3.25976229]
  [ -6.1283865 ]
  [ -8.27521515]
  [ -9.87276268]]

 [[  0.52175152]
  [  0.91122878]
  [  1.58452702]
  [  2.50609946]
  [  2.38460016]
  [  0.12465926]
  [ -3.10741496]
  [ -5.93791962]
  [ -8.06190395]
  [ -9.64770603]]

 [[  0.60869598]
  [  1.03917253]
  [  1.86388743]
  [  3.01593924]
  [  3.20255733]
  [  1.26089346]
  [ -1.70053661]
  [ -4.33512354]
  [ -6.34699297]
  [ -7.89100647]]

 [[  0.49163958]
  [  0.81860054]
  [  1.39019144]
  [  2.12170339]
  [  1.72258115]
  [ -0.85665643]
  [ -4.36405897]
  [ -7.3799839 ]
  [ -9.61968803]
  [-11.27481556]]

 [[  0.51377612]
  [  0.89003372]
  [  1.5325228 ]
  [  2.39962029]
  [  2.20249414]
  [ -0.13678367]
  [ -3.43295979]
  [ -6.30684614]
  [ -8.45654202]
  [-10.05462742]]

 [[  0.59882689]
  [  0.95151639]
  [  1.67842472]
  [  2.6201942 ]
  [  2.54429078]
  [  0.36643738]
  [ -2.75462961]
  [ -5.46658897]
  [ -7.51039124]
  [ -9.06926727]]

 [[  0.52658129]
  [  0.90013808]
  [  1.55613172]
  [  2.43778777]
  [  2.25063205]
  [ -0.09640004]
  [ -3.40298057]
  [ -6.27427673]
  [ -8.41941833]
  [-10.01635456]]

 [[  0.52356374]
  [  0.91329944]
  [  1.59418678]
  [  2.52662706]
  [  2.41566253]
  [  0.16050304]
  [ -3.07184267]
  [ -5.90398407]
  [ -8.02887058]
  [ -9.61432934]]

 [[  0.52430964]
  [  0.91480345]
  [  1.59781742]
  [  2.53394318]
  [  2.42697859]
  [  0.17433465]
  [ -3.05727792]
  [ -5.88967896]
  [ -8.0151186 ]
  [ -9.60112381]]

 [[  0.52479559]
  [  0.91416752]
  [  1.59907293]
  [  2.53690648]
  [  2.42914581]
  [  0.17151262]
  [ -3.06666708]
  [ -5.90420198]
  [ -8.03248501]
  [ -9.61935997]]

 [[  0.52555245]
  [  0.91478992]
  [  1.60446596]
  [  2.54795289]
  [  2.4432888 ]
  [  0.18281792]
  [ -3.06155348]
  [ -5.90524578]
  [ -8.03865337]
  [ -9.62997627]]

 [[  0.5261302 ]
  [  0.91630155]
  [  1.61021698]
  [  2.56002545]
  [  2.45907211]
  [  0.19549601]
  [ -3.05626535]
  [ -5.90736818]
  [ -8.04606628]
  [ -9.64021587]]

 [[  0.53676939]
  [  0.69852453]
  [  1.27026594]
  [  1.79290092]
  [  0.95966542]
  [ -2.22654605]
  [ -6.34950686]
  [ -9.86222649]
  [-12.41534138]
  [-14.23705292]]

 [[  0.52526206]
  [  0.9146226 ]
  [  1.60172653]
  [  2.54268789]
  [  2.43628907]
  [  0.17597307]
  [ -3.06710339]
  [ -5.90927601]
  [ -8.04092216]
  [ -9.62985992]]]
After layer swapaxes27_output (10, 20, 1) <class 'numpy.float32'> [[[  0.52264464]
  [  0.52367812]
  [  0.51593363]
  [  0.52559811]
  [  0.52675295]
  [  0.52268708]
  [  0.52268577]
  [  0.52175152]
  [  0.60869598]
  [  0.49163958]
  [  0.51377612]
  [  0.59882689]
  [  0.52658129]
  [  0.52356374]
  [  0.52430964]
  [  0.52479559]
  [  0.52555245]
  [  0.5261302 ]
  [  0.53676939]
  [  0.52526206]]

 [[  0.91408318]
  [  0.91290116]
  [  0.89754879]
  [  0.91628838]
  [  0.89806706]
  [  0.91410577]
  [  0.90687257]
  [  0.91122878]
  [  1.03917253]
  [  0.81860054]
  [  0.89003372]
  [  0.95151639]
  [  0.90013808]
  [  0.91329944]
  [  0.91480345]
  [  0.91416752]
  [  0.91478992]
  [  0.91630155]
  [  0.69852453]
  [  0.9146226 ]]

 [[  1.59161615]
  [  1.59403837]
  [  1.55112708]
  [  1.60516262]
  [  1.56208062]
  [  1.59356439]
  [  1.5767101 ]
  [  1.58452702]
  [  1.86388743]
  [  1.39019144]
  [  1.5325228 ]
  [  1.67842472]
  [  1.55613172]
  [  1.59418678]
  [  1.59781742]
  [  1.59907293]
  [  1.60446596]
  [  1.61021698]
  [  1.27026594]
  [  1.60172653]]

 [[  2.52052402]
  [  2.52644897]
  [  2.43716145]
  [  2.54950905]
  [  2.45200944]
  [  2.52456784]
  [  2.48542237]
  [  2.50609946]
  [  3.01593924]
  [  2.12170339]
  [  2.39962029]
  [  2.6201942 ]
  [  2.43778777]
  [  2.52662706]
  [  2.53394318]
  [  2.53690648]
  [  2.54795289]
  [  2.56002545]
  [  1.79290092]
  [  2.54268789]]

 [[  2.40674353]
  [  2.41515231]
  [  2.26091886]
  [  2.44846892]
  [  2.27011061]
  [  2.4126544 ]
  [  2.33342481]
  [  2.38460016]
  [  3.20255733]
  [  1.72258115]
  [  2.20249414]
  [  2.54429078]
  [  2.25063205]
  [  2.41566253]
  [  2.42697859]
  [  2.42914581]
  [  2.4432888 ]
  [  2.45907211]
  [  0.95966542]
  [  2.43628907]]

 [[  0.15161826]
  [  0.15930861]
  [ -0.06370907]
  [  0.19469039]
  [ -0.07971668]
  [  0.15779737]
  [  0.02430105]
  [  0.12465926]
  [  1.26089346]
  [ -0.85665643]
  [ -0.13678367]
  [  0.36643738]
  [ -0.09640004]
  [  0.16050304]
  [  0.17433465]
  [  0.17151262]
  [  0.18281792]
  [  0.19549601]
  [ -2.22654605]
  [  0.17597307]]

 [[ -3.07905149]
  [ -3.07370138]
  [ -3.35407233]
  [ -3.04264355]
  [ -3.3944602 ]
  [ -3.073874  ]
  [ -3.25976229]
  [ -3.10741496]
  [ -1.70053661]
  [ -4.36405897]
  [ -3.43295979]
  [ -2.75462961]
  [ -3.40298057]
  [ -3.07184267]
  [ -3.05727792]
  [ -3.06666708]
  [ -3.06155348]
  [ -3.05626535]
  [ -6.34950686]
  [ -3.06710339]]

 [[ -5.9101882 ]
  [ -5.90620565]
  [ -6.22824907]
  [ -5.88082838]
  [ -6.2735815 ]
  [ -5.9063797 ]
  [ -6.1283865 ]
  [ -5.93791962]
  [ -4.33512354]
  [ -7.3799839 ]
  [ -6.30684614]
  [ -5.46658897]
  [ -6.27427673]
  [ -5.90398407]
  [ -5.88967896]
  [ -5.90420198]
  [ -5.90524578]
  [ -5.90736818]
  [ -9.86222649]
  [ -5.90927601]]

 [[ -8.03540325]
  [ -8.03121948]
  [ -8.3805275 ]
  [ -8.01006031]
  [ -8.42361832]
  [ -8.03285313]
  [ -8.27521515]
  [ -8.06190395]
  [ -6.34699297]
  [ -9.61968803]
  [ -8.45654202]
  [ -7.51039124]
  [ -8.41941833]
  [ -8.02887058]
  [ -8.0151186 ]
  [ -8.03248501]
  [ -8.03865337]
  [ -8.04606628]
  [-12.41534138]
  [ -8.04092216]]

 [[ -9.62234974]
  [ -9.61678505]
  [ -9.98156166]
  [ -9.59773827]
  [-10.02244377]
  [ -9.62078667]
  [ -9.87276268]
  [ -9.64770603]
  [ -7.89100647]
  [-11.27481556]
  [-10.05462742]
  [ -9.06926727]
  [-10.01635456]
  [ -9.61432934]
  [ -9.60112381]
  [ -9.61935997]
  [ -9.62997627]
  [ -9.64021587]
  [-14.23705292]
  [ -9.62985992]]]
After layer sequencemask9_output (10, 20, 1) <class 'numpy.float32'> [[[  5.22644639e-01]
  [  5.23678124e-01]
  [  5.15933633e-01]
  [  5.25598109e-01]
  [  5.26752949e-01]
  [  5.22687078e-01]
  [  5.22685766e-01]
  [  5.21751523e-01]
  [  6.08695984e-01]
  [  4.91639584e-01]
  [  5.13776124e-01]
  [  5.98826885e-01]
  [  5.26581287e-01]
  [  5.23563743e-01]
  [  5.24309635e-01]
  [  5.24795592e-01]
  [  5.25552452e-01]
  [  5.26130199e-01]
  [  5.36769390e-01]
  [  5.25262058e-01]]

 [[  9.14083183e-01]
  [  9.12901163e-01]
  [  8.97548795e-01]
  [  9.16288376e-01]
  [  8.98067057e-01]
  [  9.14105773e-01]
  [  9.06872571e-01]
  [  9.11228776e-01]
  [  1.03917253e+00]
  [  8.18600535e-01]
  [  8.90033722e-01]
  [  9.51516390e-01]
  [  9.00138080e-01]
  [  9.13299441e-01]
  [  9.14803445e-01]
  [  9.14167523e-01]
  [  9.14789915e-01]
  [  9.16301548e-01]
  [  6.98524535e-01]
  [  9.14622605e-01]]

 [[ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]]
After layer swapaxes28_output (20, 10, 1) <class 'numpy.float32'> [[[  5.22644639e-01]
  [  9.14083183e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  5.23678124e-01]
  [  9.12901163e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  5.15933633e-01]
  [  8.97548795e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  5.25598109e-01]
  [  9.16288376e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  5.26752949e-01]
  [  8.98067057e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  5.22687078e-01]
  [  9.14105773e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  5.22685766e-01]
  [  9.06872571e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  5.21751523e-01]
  [  9.11228776e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  6.08695984e-01]
  [  1.03917253e+00]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  4.91639584e-01]
  [  8.18600535e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  5.13776124e-01]
  [  8.90033722e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  5.98826885e-01]
  [  9.51516390e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  5.26581287e-01]
  [  9.00138080e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  5.23563743e-01]
  [  9.13299441e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  5.24309635e-01]
  [  9.14803445e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  5.24795592e-01]
  [  9.14167523e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  5.25552452e-01]
  [  9.14789915e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  5.26130199e-01]
  [  9.16301548e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  5.36769390e-01]
  [  6.98524535e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  5.25262058e-01]
  [  9.14622605e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]]
After layer attention_softmax_0 (20, 10, 1) <class 'numpy.float32'> [[[ 0.40337107]
  [ 0.59662896]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40390435]
  [ 0.59609568]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.4057374 ]
  [ 0.5942626 ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40355113]
  [ 0.59644884]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40822354]
  [ 0.59177649]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40337583]
  [ 0.5966242 ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40511748]
  [ 0.59488249]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40384313]
  [ 0.5961569 ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.39401254]
  [ 0.60598743]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.41898027]
  [ 0.5810197 ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40702981]
  [ 0.59297019]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.41273037]
  [ 0.58726966]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40768185]
  [ 0.59231812]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40378094]
  [ 0.59621906]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40359843]
  [ 0.59640157]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.4038685 ]
  [ 0.59613156]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40390086]
  [ 0.59609914]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40367603]
  [ 0.59632397]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.45964915]
  [ 0.54035085]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40387121]
  [ 0.59612876]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]]
After layer batch_dot9_0 (20, 512, 1) <class 'numpy.float32'> [[[ 0.01785018]
  [ 0.03943704]
  [-0.03342329]
  ...,
  [-0.01095539]
  [ 0.00999321]
  [-0.02460154]]

 [[ 0.0178373 ]
  [ 0.03942218]
  [-0.03339929]
  ...,
  [-0.01095244]
  [ 0.00999259]
  [-0.02461097]]

 [[ 0.01779306]
  [ 0.03937112]
  [-0.03331678]
  ...,
  [-0.01094231]
  [ 0.00999048]
  [-0.02464337]]

 ...,
 [[ 0.01784281]
  [ 0.03942854]
  [-0.03340957]
  ...,
  [-0.01095371]
  [ 0.00999286]
  [-0.02460693]]

 [[ 0.01649171]
  [ 0.03786933]
  [-0.03089004]
  ...,
  [-0.01064411]
  [ 0.00992838]
  [-0.02559639]]

 [[ 0.0178381 ]
  [ 0.0394231 ]
  [-0.03340078]
  ...,
  [-0.01095263]
  [ 0.00999263]
  [-0.02461038]]]
After layer reshape18_0 (20, 512) <class 'numpy.float32'> [[ 0.01785018  0.03943704 -0.03342329 ..., -0.01095539  0.00999321
  -0.02460154]
 [ 0.0178373   0.03942218 -0.03339929 ..., -0.01095244  0.00999259
  -0.02461097]
 [ 0.01779306  0.03937112 -0.03331678 ..., -0.01094231  0.00999048
  -0.02464337]
 ...,
 [ 0.01784281  0.03942854 -0.03340957 ..., -0.01095371  0.00999286
  -0.02460693]
 [ 0.01649171  0.03786933 -0.03089004 ..., -0.01064411  0.00992838
  -0.02559639]
 [ 0.0178381   0.0394231  -0.03340078 ..., -0.01095263  0.00999263
  -0.02461038]]
After layer decoder_rnn_hidden_concat_t0_output (20, 1024) <class 'numpy.float32'> [[-0.00122746 -0.92200547  0.19574104 ..., -0.01095539  0.00999321
  -0.02460154]
 [-0.00122618 -0.92229152  0.19527809 ..., -0.01095244  0.00999259
  -0.02461097]
 [-0.00121079 -0.92516494  0.19165711 ..., -0.01094231  0.00999048
  -0.02464337]
 ...,
 [-0.00121065 -0.92271066  0.19297466 ..., -0.01095371  0.00999286
  -0.02460693]
 [-0.00241762 -0.815988    0.28093508 ..., -0.01064411  0.00992838
  -0.02559639]
 [-0.00121864 -0.92275989  0.19390221 ..., -0.01095263  0.00999263
  -0.02461038]]
After layer decoder_rnn_hidden_fc_t0_output (20, 512) <class 'numpy.float32'> [[-1.93566072  0.2001666  -0.80395442 ...,  1.9427737   2.0895915
  -1.58606005]
 [-1.93815565  0.199696   -0.80561298 ...,  1.94435883  2.09153867
  -1.58405805]
 [-1.91999328  0.21122655 -0.81296355 ...,  1.92591691  2.08137727
  -1.58853257]
 ...,
 [-1.94620788  0.20894775 -0.81657016 ...,  1.95025384  2.08477521
  -1.58159626]
 [-1.71454215 -0.79177761  0.29760537 ...,  1.35930288  2.32382107
  -1.9340421 ]
 [-1.94026458  0.20392478 -0.81175578 ...,  1.94564855  2.08783674
  -1.58170974]]
After layer decoder_rnn_next_hidden_t0_output (20, 512) <class 'numpy.float32'> [[-0.95918846  0.19753543 -0.66624171 ...,  0.95975333  0.96983975
  -0.91954303]
 [-0.95938748  0.19708316 -0.66716307 ...,  0.95987821  0.96995521
  -0.91923326]
 [-0.95791674  0.20814022 -0.67122185 ...,  0.9584021   0.96934783
  -0.91992402]
 ...,
 [-0.96002334  0.20595911 -0.67319876 ...,  0.96033913  0.96955228
  -0.91885084]
 [-0.93720245 -0.65941489  0.28911966 ...,  0.87623131  0.9810136
  -0.95905888]
 [-0.95955497  0.20114426 -0.67055768 ...,  0.95997947  0.96973532
  -0.91886848]]
After layer logits_output (20, 16743) <class 'numpy.float32'> [[-1.99396193 -2.82249379 -2.40997624 ..., -2.09959722 -3.49772549
  -2.56986094]
 [-1.99469662 -2.82015038 -2.40848637 ..., -2.09821296 -3.49516058
  -2.56885242]
 [-1.98549187 -2.81929398 -2.41067886 ..., -2.103297   -3.49119353
  -2.56443119]
 ...,
 [-1.99160159 -2.81336021 -2.4007113  ..., -2.09465337 -3.48546314
  -2.56919336]
 [-1.73511803 -3.19847798 -2.78586626 ..., -2.3069396  -3.36963272
  -3.12058306]
 [-1.99228346 -2.81642699 -2.40474582 ..., -2.0966711  -3.48917818
  -2.56838298]]
After layer softmax_0 (20, 16743) <class 'numpy.float32'> [[  8.43862949e-07   3.68506676e-07   5.56672035e-07 ...,   7.59268403e-07
    1.87584021e-07   4.74419039e-07]
 [  8.47053286e-07   3.71039988e-07   5.60020794e-07 ...,   7.63754940e-07
    1.88915550e-07   4.77043557e-07]
 [  8.63887180e-07   3.75267859e-07   5.64677748e-07 ...,   7.67882568e-07
    1.91663318e-07   4.84202360e-07]
 ...,
 [  8.71833379e-07   3.83308503e-07   5.79108189e-07 ...,   7.86464227e-07
    1.95730223e-07   4.89315426e-07]
 [  8.20887109e-08   1.90000300e-08   2.87044344e-08 ...,   4.63387799e-08
    1.60111693e-08   2.05391917e-08]
 [  8.61127091e-07   3.77699422e-07   5.70081852e-07 ...,   7.75769024e-07
    1.92740998e-07   4.84027964e-07]]
After layer reshape19_0 (20, 10) <class 'numpy.float32'> [[ 0.40337107  0.59662896  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40390435  0.59609568  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.4057374   0.5942626   0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40355113  0.59644884  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40822354  0.59177649  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40337583  0.5966242   0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40511748  0.59488249  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40384313  0.5961569   0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.39401254  0.60598743  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.41898027  0.5810197   0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40702981  0.59297019  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.41273037  0.58726966  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40768185  0.59231812  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40378094  0.59621906  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40359843  0.59640157  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.4038685   0.59613156  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40390086  0.59609914  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40367603  0.59632397  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.45964915  0.54035085  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40387121  0.59612876  0.          0.          0.          0.          0.
   0.          0.          0.        ]]
After layer target_embed_embed_0 (20, 256) <class 'numpy.float32'> [[-0.05505371 -0.0300293  -0.03598022 ...,  0.08459473 -0.05288696
  -0.01667786]
 [-0.05505371 -0.0300293  -0.03598022 ...,  0.08459473 -0.05288696
  -0.01667786]
 [-0.05505371 -0.0300293  -0.03598022 ...,  0.08459473 -0.05288696
  -0.01667786]
 ...,
 [-0.05505371 -0.0300293  -0.03598022 ...,  0.08459473 -0.05288696
  -0.01667786]
 [-0.05505371 -0.0300293  -0.03598022 ...,  0.08459473 -0.05288696
  -0.01667786]
 [-0.05505371 -0.0300293  -0.03598022 ...,  0.08459473 -0.05288696
  -0.01667786]]
After layer decoder_rnn_concat_target_context_t0_output (20, 768) <class 'numpy.float32'> [[-0.05505371 -0.0300293  -0.03598022 ...,  0.95975333  0.96983975
  -0.91954303]
 [-0.05505371 -0.0300293  -0.03598022 ...,  0.95987821  0.96995521
  -0.91923326]
 [-0.05505371 -0.0300293  -0.03598022 ...,  0.9584021   0.96934783
  -0.91992402]
 ...,
 [-0.05505371 -0.0300293  -0.03598022 ...,  0.96038187  0.96981865
  -0.91906667]
 [-0.05505371 -0.0300293  -0.03598022 ...,  0.96033913  0.96955228
  -0.91885084]
 [-0.05505371 -0.0300293  -0.03598022 ...,  0.95997947  0.96973532
  -0.91886848]]
After layer decoder_rnn_l0_t0_i2h_output (20, 2048) <class 'numpy.float32'> [[-3.18406987  1.61391115  2.42924905 ..., -0.07592518  3.86658955
   0.60106599]
 [-3.18262672  1.61276674  2.42842722 ..., -0.07599974  3.86333966
   0.60139877]
 [-3.17421126  1.61186123  2.42245889 ..., -0.07151888  3.86369753
   0.60703593]
 ...,
 [-3.17899394  1.60911417  2.42944193 ..., -0.0758564   3.85731006
   0.60095513]
 [-3.17580032  1.60745442  2.4297998  ..., -0.07576036  3.85373235
   0.60088587]
 [-3.17843485  1.61008239  2.42872572 ..., -0.07617678  3.85778856
   0.60124576]]
After layer decoder_rnn_l0_t0_h2h_output (20, 2048) <class 'numpy.float32'> [[-0.32279095  0.47229248  1.81812191 ...,  0.69992667  1.29629993
   0.17055975]
 [-0.32425255  0.47403911  1.81705463 ...,  0.69724417  1.2942071
   0.1689152 ]
 [-0.33351976  0.48187572  1.80802584 ...,  0.69084883  1.30468535
   0.16467097]
 ...,
 [-0.32893386  0.48317927  1.82008767 ...,  0.69365489  1.29681957
   0.16285098]
 [-0.33281583  0.49088722  1.81880248 ...,  0.68905622  1.30061221
   0.15666096]
 [-0.32945251  0.48356885  1.81609929 ...,  0.6910044   1.2978431
   0.16167867]]
After layer _plus1054_0 (20, 2048) <class 'numpy.float32'> [[-3.50686073  2.08620358  4.24737072 ...,  0.6240015   5.16288948
   0.77162576]
 [-3.50687933  2.08680582  4.24548197 ...,  0.62124443  5.157547
   0.77031398]
 [-3.50773096  2.09373689  4.23048496 ...,  0.61932993  5.16838264
   0.77170694]
 ...,
 [-3.50792789  2.0922935   4.24952984 ...,  0.61779851  5.15412951
   0.7638061 ]
 [-3.50861621  2.0983417   4.24860239 ...,  0.61329585  5.15434456
   0.75754684]
 [-3.50788736  2.09365129  4.24482489 ...,  0.61482763  5.15563154
   0.76292443]]
After layer decoder_rnn_l0_t0_slice_output0 (20, 512) <class 'numpy.float32'> [[-3.50686073  2.08620358  4.24737072 ...,  1.75503922  4.58113766
   2.77458239]
 [-3.50687933  2.08680582  4.24548197 ...,  1.75212181  4.58474493
   2.77214384]
 [-3.50773096  2.09373689  4.23048496 ...,  1.76063108  4.55932808
   2.76668811]
 ...,
 [-3.50792789  2.0922935   4.24952984 ...,  1.74410439  4.58267593
   2.7704525 ]
 [-3.50861621  2.0983417   4.24860239 ...,  1.74045372  4.57955742
   2.76662683]
 [-3.50788736  2.09365129  4.24482489 ...,  1.74603784  4.5813098
   2.76796651]]
After layer decoder_rnn_l0_t0_slice_output1 (20, 512) <class 'numpy.float32'> [[-1.87263918  2.3000598   2.40986085 ...,  3.15798187 -0.73975927
   1.96222758]
 [-1.87282252  2.30038667  2.40993547 ...,  3.1544075  -0.73432982
   1.96018589]
 [-1.88515925  2.29257488  2.41198826 ...,  3.14430285 -0.76346111
   1.95093763]
 ...,
 [-1.87736666  2.30361843  2.41039538 ...,  3.14776516 -0.72387278
   1.95536995]
 [-1.88277507  2.3043623   2.40874743 ...,  3.14161158 -0.72252846
   1.95068383]
 [-1.87973821  2.30178428  2.40826368 ...,  3.14597034 -0.72993368
   1.9538219 ]]
After layer decoder_rnn_l0_t0_slice_output2 (20, 512) <class 'numpy.float32'> [[-2.80574727 -3.07116199  2.84784079 ...,  4.25503254 -0.07065523
   2.16004539]
 [-2.80377698 -3.07023835  2.84572983 ...,  4.25132561 -0.07529482
   2.15823507]
 [-2.80398726 -3.07270527  2.8621428  ...,  4.23388243 -0.07872096
   2.15751767]
 ...,
 [-2.79756975 -3.07035565  2.84566879 ...,  4.24195385 -0.08911115
   2.15521026]
 [-2.79274273 -3.07071686  2.84599161 ...,  4.23400784 -0.09860265
   2.15290451]
 [-2.79703879 -3.0699811   2.84538078 ...,  4.2412324  -0.08672845
   2.15589833]]
After layer decoder_rnn_l0_t0_slice_output3 (20, 512) <class 'numpy.float32'> [[-3.26943588  2.45702291 -1.40894437 ...,  0.6240015   5.16288948
   0.77162576]
 [-3.27096128  2.45958734 -1.41026592 ...,  0.62124443  5.157547
   0.77031398]
 [-3.27084541  2.48816371 -1.42601466 ...,  0.61932993  5.16838264
   0.77170694]
 ...,
 [-3.27266908  2.46008754 -1.41642022 ...,  0.61779851  5.15412951
   0.7638061 ]
 [-3.27387261  2.46370029 -1.42171001 ...,  0.61329585  5.15434456
   0.75754684]
 [-3.27247405  2.4645319  -1.41666222 ...,  0.61482763  5.15563154
   0.76292443]]
After layer decoder_rnn_l0_t0_o_output (20, 512) <class 'numpy.float32'> [[ 0.03663473  0.9210735   0.1964006  ...,  0.65112805  0.99430746
   0.68387246]
 [ 0.03658094  0.92125976  0.19619213 ...,  0.65050149  0.99427718
   0.6835888 ]
 [ 0.03658502  0.92330784  0.1937204  ...,  0.65006614  0.99433845
   0.68389004]
 ...,
 [ 0.03652079  0.92129594  0.19522339 ...,  0.64971769  0.99425769
   0.68217951]
 [ 0.03647847  0.92155761  0.19439365 ...,  0.64869225  0.99425888
   0.68082088]
 [ 0.03652766  0.92161763  0.19518538 ...,  0.6490413   0.99426621
   0.68198836]]
After layer decoder_rnn_l0_t0_f_output (20, 512) <class 'numpy.float32'> [[ 0.13323665  0.90888196  0.91757619 ...,  0.95922208  0.32305682
   0.87677383]
 [ 0.13321547  0.90890908  0.9175818  ...,  0.95908201  0.3242453
   0.87655312]
 [ 0.1317974   0.90826023  0.91773689 ...,  0.95868361  0.31789529
   0.87554884]
 ...,
 [ 0.13269164  0.90917629  0.91761655 ...,  0.95882058  0.32654074
   0.87603098]
 [ 0.13207044  0.90923768  0.91749185 ...,  0.95857692  0.32683644
   0.87552112]
 [ 0.13241895  0.90902472  0.91745526 ...,  0.95874965  0.32520929
   0.87586278]]
After layer _mul2108_0 (20, 512) <class 'numpy.float32'> [[ -4.46455972e-03  -4.37677860e+00   4.98882246e+00 ...,   5.42135048e+00
   -3.76551077e-02   3.89984989e+00]
 [ -4.46556509e-03  -4.37758684e+00   4.95077753e+00 ...,   5.32923555e+00
   -4.20949571e-02   3.83842707e+00]
 [ -4.39399760e-03  -4.33851910e+00   4.97664261e+00 ...,   5.19738340e+00
   -4.72129807e-02   3.73409414e+00]
 ...,
 [ -4.42267768e-03  -4.36907291e+00   4.91095018e+00 ...,   5.28289223e+00
   -5.34195490e-02   3.75885034e+00]
 [ -4.38616285e-03  -4.36678839e+00   4.91087723e+00 ...,   5.27408123e+00
   -6.16958812e-02   3.74629831e+00]
 [ -4.42164857e-03  -4.37694931e+00   4.93863201e+00 ...,   5.27327108e+00
   -5.30754030e-02   3.78953338e+00]]
After layer decoder_rnn_l0_t0_i_output (20, 512) <class 'numpy.float32'> [[ 0.02911765  0.88955504  0.98589987 ...,  0.85258728  0.98986065
   0.94128674]
 [ 0.02911712  0.88961416  0.98587358 ...,  0.85222018  0.98989677
   0.94115186]
 [ 0.02909306  0.89029294  0.98566324 ...,  0.85328871  0.9896394
   0.94084889]
 ...,
 [ 0.0290875   0.89015186  0.98592991 ...,  0.85120767  0.98987609
   0.9410581 ]
 [ 0.02906806  0.89074188  0.98591703 ...,  0.85074466  0.9898448
   0.94084555]
 [ 0.02908864  0.8902846   0.9858644  ...,  0.85145235  0.98986232
   0.94092005]]
After layer decoder_rnn_l0_t0_c_output (20, 512) <class 'numpy.float32'> [[-0.99271542 -0.99570936  0.99330163 ...,  0.99959719 -0.07053789
   0.97375172]
 [-0.99268675 -0.99570149  0.99327338 ...,  0.99959421 -0.07515286
   0.97365779]
 [-0.99268985 -0.99572259  0.99348986 ...,  0.99957985 -0.07855875
   0.97362041]
 ...,
 [-0.99259573 -0.99570245  0.99327254 ...,  0.99958652 -0.08887602
   0.97350001]
 [-0.99252421 -0.99570554  0.99327689 ...,  0.99957991 -0.09828434
   0.97337919]
 [-0.99258792 -0.99569929  0.99326867 ...,  0.99958593 -0.08651166
   0.97353601]]
After layer _mul2109_0 (20, 512) <class 'numpy.float32'> [[-0.02890554 -0.88573825  0.97929597 ...,  0.85224384 -0.06982268
   0.9165796 ]
 [-0.02890418 -0.88579017  0.97924197 ...,  0.85187435 -0.07439357
   0.91635984]
 [-0.02888038 -0.8864848   0.97924644 ...,  0.85293019 -0.07774483
   0.91602969]
 ...,
 [-0.02887212 -0.88632637  0.9792971  ...,  0.85085571 -0.08797625
   0.91612005]
 [-0.02885076 -0.88691664  0.97928858 ...,  0.85038728 -0.09728625
   0.9157995 ]
 [-0.02887304 -0.88645571  0.9792282  ...,  0.85109979 -0.08563463
   0.91601956]]
After layer decoder_rnn_l0_t0_state_0 (20, 512) <class 'numpy.float32'> [[-0.0333701  -5.26251698  5.96811867 ...,  6.27359438 -0.10747778
   4.81642962]
 [-0.03336975 -5.26337719  5.93001938 ...,  6.18110991 -0.11648853
   4.75478697]
 [-0.03327438 -5.22500372  5.95588923 ...,  6.05031347 -0.12495781
   4.6501236 ]
 ...,
 [-0.0332948  -5.25539923  5.89024734 ...,  6.13374805 -0.14139581
   4.67497063]
 [-0.03323692 -5.25370502  5.89016581 ...,  6.12446833 -0.15898213
   4.66209793]
 [-0.03329469 -5.26340485  5.91786003 ...,  6.12437105 -0.13871002
   4.70555305]]
After layer activation1054_output (20, 512) <class 'numpy.float32'> [[-0.03335772 -0.9999463   0.99998689 ...,  0.99999291 -0.10706585
   0.99986893]
 [-0.03335737 -0.99994636  0.99998587 ...,  0.99999142 -0.11596448
   0.99985176]
 [-0.03326211 -0.99994212  0.99998659 ...,  0.99998891 -0.12431147
   0.99981719]
 ...,
 [-0.03328251 -0.99994552  0.99998468 ...,  0.99999058 -0.14046098
   0.99982607]
 [-0.03322469 -0.99994534  0.99998468 ...,  0.9999904  -0.1576561
   0.99982154]
 [-0.03328239 -0.99994636  0.99998552 ...,  0.9999904  -0.1378272
   0.99983639]]
After layer decoder_rnn_l0_t0_out_0 (20, 512) <class 'numpy.float32'> [[-0.00122205 -0.92102402  0.19639802 ...,  0.65112346 -0.10645637
   0.68378282]
 [-0.00122024 -0.92121035  0.19618936 ...,  0.65049589 -0.11530083
   0.68348747]
 [-0.00121689 -0.92325437  0.19371781 ...,  0.65005893 -0.12360767
   0.68376505]
 ...,
 [-0.0012155  -0.92124575  0.1952204  ...,  0.64971155 -0.13965441
   0.68206084]
 [-0.00121199 -0.92150724  0.19439067 ...,  0.64868605 -0.15675098
   0.68069941]
 [-0.00121573 -0.92156821  0.19518255 ...,  0.6490351  -0.13703693
   0.68187678]]
After layer expand_dims1063_0 (20, 512, 1) <class 'numpy.float32'> [[[-0.00122205]
  [-0.92102402]
  [ 0.19639802]
  ...,
  [ 0.65112346]
  [-0.10645637]
  [ 0.68378282]]

 [[-0.00122024]
  [-0.92121035]
  [ 0.19618936]
  ...,
  [ 0.65049589]
  [-0.11530083]
  [ 0.68348747]]

 [[-0.00121689]
  [-0.92325437]
  [ 0.19371781]
  ...,
  [ 0.65005893]
  [-0.12360767]
  [ 0.68376505]]

 ...,
 [[-0.0012155 ]
  [-0.92124575]
  [ 0.1952204 ]
  ...,
  [ 0.64971155]
  [-0.13965441]
  [ 0.68206084]]

 [[-0.00121199]
  [-0.92150724]
  [ 0.19439067]
  ...,
  [ 0.64868605]
  [-0.15675098]
  [ 0.68069941]]

 [[-0.00121573]
  [-0.92156821]
  [ 0.19518255]
  ...,
  [ 0.6490351 ]
  [-0.13703693]
  [ 0.68187678]]]
After layer att_batch_dot_0 (20, 10, 1) <class 'numpy.float32'> [[[  0.5264383 ]
  [  0.91906321]
  [  1.60796285]
  [  2.55312109]
  [  2.45605421]
  [  0.21029171]
  [ -3.01718163]
  [ -5.84787893]
  [ -7.97459078]
  [ -9.56490993]]

 [[  0.52714044]
  [  0.91820997]
  [  1.6096971 ]
  [  2.55730748]
  [  2.46220827]
  [  0.21651231]
  [ -3.01198363]
  [ -5.84316778]
  [ -7.96939278]
  [ -9.55847454]]

 [[  0.52245831]
  [  0.90950298]
  [  1.58173835]
  [  2.49838567]
  [  2.35886765]
  [  0.0644365 ]
  [ -3.20593739]
  [ -6.06876278]
  [ -8.21666908]
  [ -9.81867313]]

 [[  0.52834004]
  [  0.92064005]
  [  1.61686265]
  [  2.57203221]
  [  2.48295665]
  [  0.23728305]
  [ -2.9956398 ]
  [ -5.83213997]
  [ -7.96248055]
  [ -9.55393791]]

 [[  0.52510762]
  [  0.90937525]
  [  1.59202003]
  [  2.52088737]
  [  2.39031339]
  [  0.09313104]
  [ -3.18749285]
  [ -6.05794191]
  [ -8.20991611]
  [ -9.8140974 ]]

 [[  0.52628016]
  [  0.91887397]
  [  1.60903549]
  [  2.55531001]
  [  2.45884705]
  [  0.21228613]
  [ -3.0169158 ]
  [ -5.84947014]
  [ -7.97774029]
  [ -9.5692358 ]]

 [[  0.52383143]
  [  0.91263461]
  [  1.59308493]
  [  2.52068806]
  [  2.38388205]
  [  0.0756518 ]
  [ -3.21887732]
  [ -6.10568333]
  [ -8.27249813]
  [ -9.88777542]]

 [[  0.52592164]
  [  0.91720796]
  [  1.60366929]
  [  2.54440236]
  [  2.44300151]
  [  0.19518031]
  [ -3.03204322]
  [ -5.86126804]
  [ -7.98629427]
  [ -9.57515812]]

 [[  0.53044534]
  [  0.90296966]
  [  1.58201075]
  [  2.49552298]
  [  2.34308124]
  [  0.01932447]
  [ -3.27699852]
  [ -6.14548683]
  [ -8.29064369]
  [ -9.88825035]]

 [[  0.50689834]
  [  0.87756383]
  [  1.51624477]
  [  2.3725915 ]
  [  2.14298368]
  [ -0.2554597 ]
  [ -3.61692667]
  [ -6.5422678 ]
  [ -8.72809887]
  [-10.35125446]]

 [[  0.52128702]
  [  0.90470225]
  [  1.57035458]
  [  2.47539926]
  [  2.32409859]
  [  0.02327806]
  [ -3.24746418]
  [ -6.10708332]
  [ -8.25091171]
  [ -9.84922695]]

 [[  0.50573957]
  [  0.84904212]
  [  1.47119379]
  [  2.28132153]
  [  1.98267746]
  [ -0.49712503]
  [ -3.92362666]
  [ -6.88228369]
  [ -9.08454132]
  [-10.71660137]]

 [[  0.52560973]
  [  0.91135323]
  [  1.5896585 ]
  [  2.51397347]
  [  2.38139796]
  [  0.08813621]
  [ -3.18482018]
  [ -6.0478406 ]
  [ -8.19453907]
  [ -9.79570675]]

 [[  0.60887623]
  [  0.98344612]
  [  1.74676752]
  [  2.7595787 ]
  [  2.77747321]
  [  0.69303977]
  [ -2.35626292]
  [ -5.02739811]
  [ -7.05281496]
  [ -8.60433197]]

 [[  0.5270642 ]
  [  0.91853464]
  [  1.60982406]
  [  2.55745268]
  [  2.46251059]
  [  0.21711671]
  [ -3.01110911]
  [ -5.84220648]
  [ -7.96845484]
  [ -9.55755234]]

 [[  0.52754921]
  [  0.91955686]
  [  1.61215317]
  [  2.5621469 ]
  [  2.46969414]
  [  0.22566108]
  [ -3.0024519 ]
  [ -5.83409977]
  [ -7.96103954]
  [ -9.55074501]]

 [[  0.52789479]
  [  0.91926223]
  [  1.61305022]
  [  2.56413507]
  [  2.47106743]
  [  0.22360866]
  [ -3.00902462]
  [ -5.84427595]
  [ -7.97332001]
  [ -9.56374264]]

 [[  0.52817816]
  [  0.91944623]
  [  1.61599362]
  [  2.57017374]
  [  2.47798371]
  [  0.22698863]
  [ -3.0114615 ]
  [ -5.85236645]
  [ -7.98607731]
  [ -9.5803957 ]]

 [[  0.52846009]
  [  0.92069745]
  [  1.6197511 ]
  [  2.57794309]
  [  2.48753881]
  [  0.23310165]
  [ -3.01198602]
  [ -5.85958815]
  [ -7.99838018]
  [ -9.59574509]]

 [[  0.52812254]
  [  0.91954565]
  [  1.61455321]
  [  2.56741762]
  [  2.474684  ]
  [  0.22456382]
  [ -3.01228642]
  [ -5.85155249]
  [ -7.98362541]
  [ -9.57600975]]]
After layer swapaxes29_output (10, 20, 1) <class 'numpy.float32'> [[[  0.5264383 ]
  [  0.52714044]
  [  0.52245831]
  [  0.52834004]
  [  0.52510762]
  [  0.52628016]
  [  0.52383143]
  [  0.52592164]
  [  0.53044534]
  [  0.50689834]
  [  0.52128702]
  [  0.50573957]
  [  0.52560973]
  [  0.60887623]
  [  0.5270642 ]
  [  0.52754921]
  [  0.52789479]
  [  0.52817816]
  [  0.52846009]
  [  0.52812254]]

 [[  0.91906321]
  [  0.91820997]
  [  0.90950298]
  [  0.92064005]
  [  0.90937525]
  [  0.91887397]
  [  0.91263461]
  [  0.91720796]
  [  0.90296966]
  [  0.87756383]
  [  0.90470225]
  [  0.84904212]
  [  0.91135323]
  [  0.98344612]
  [  0.91853464]
  [  0.91955686]
  [  0.91926223]
  [  0.91944623]
  [  0.92069745]
  [  0.91954565]]

 [[  1.60796285]
  [  1.6096971 ]
  [  1.58173835]
  [  1.61686265]
  [  1.59202003]
  [  1.60903549]
  [  1.59308493]
  [  1.60366929]
  [  1.58201075]
  [  1.51624477]
  [  1.57035458]
  [  1.47119379]
  [  1.5896585 ]
  [  1.74676752]
  [  1.60982406]
  [  1.61215317]
  [  1.61305022]
  [  1.61599362]
  [  1.6197511 ]
  [  1.61455321]]

 [[  2.55312109]
  [  2.55730748]
  [  2.49838567]
  [  2.57203221]
  [  2.52088737]
  [  2.55531001]
  [  2.52068806]
  [  2.54440236]
  [  2.49552298]
  [  2.3725915 ]
  [  2.47539926]
  [  2.28132153]
  [  2.51397347]
  [  2.7595787 ]
  [  2.55745268]
  [  2.5621469 ]
  [  2.56413507]
  [  2.57017374]
  [  2.57794309]
  [  2.56741762]]

 [[  2.45605421]
  [  2.46220827]
  [  2.35886765]
  [  2.48295665]
  [  2.39031339]
  [  2.45884705]
  [  2.38388205]
  [  2.44300151]
  [  2.34308124]
  [  2.14298368]
  [  2.32409859]
  [  1.98267746]
  [  2.38139796]
  [  2.77747321]
  [  2.46251059]
  [  2.46969414]
  [  2.47106743]
  [  2.47798371]
  [  2.48753881]
  [  2.474684  ]]

 [[  0.21029171]
  [  0.21651231]
  [  0.0644365 ]
  [  0.23728305]
  [  0.09313104]
  [  0.21228613]
  [  0.0756518 ]
  [  0.19518031]
  [  0.01932447]
  [ -0.2554597 ]
  [  0.02327806]
  [ -0.49712503]
  [  0.08813621]
  [  0.69303977]
  [  0.21711671]
  [  0.22566108]
  [  0.22360866]
  [  0.22698863]
  [  0.23310165]
  [  0.22456382]]

 [[ -3.01718163]
  [ -3.01198363]
  [ -3.20593739]
  [ -2.9956398 ]
  [ -3.18749285]
  [ -3.0169158 ]
  [ -3.21887732]
  [ -3.03204322]
  [ -3.27699852]
  [ -3.61692667]
  [ -3.24746418]
  [ -3.92362666]
  [ -3.18482018]
  [ -2.35626292]
  [ -3.01110911]
  [ -3.0024519 ]
  [ -3.00902462]
  [ -3.0114615 ]
  [ -3.01198602]
  [ -3.01228642]]

 [[ -5.84787893]
  [ -5.84316778]
  [ -6.06876278]
  [ -5.83213997]
  [ -6.05794191]
  [ -5.84947014]
  [ -6.10568333]
  [ -5.86126804]
  [ -6.14548683]
  [ -6.5422678 ]
  [ -6.10708332]
  [ -6.88228369]
  [ -6.0478406 ]
  [ -5.02739811]
  [ -5.84220648]
  [ -5.83409977]
  [ -5.84427595]
  [ -5.85236645]
  [ -5.85958815]
  [ -5.85155249]]

 [[ -7.97459078]
  [ -7.96939278]
  [ -8.21666908]
  [ -7.96248055]
  [ -8.20991611]
  [ -7.97774029]
  [ -8.27249813]
  [ -7.98629427]
  [ -8.29064369]
  [ -8.72809887]
  [ -8.25091171]
  [ -9.08454132]
  [ -8.19453907]
  [ -7.05281496]
  [ -7.96845484]
  [ -7.96103954]
  [ -7.97332001]
  [ -7.98607731]
  [ -7.99838018]
  [ -7.98362541]]

 [[ -9.56490993]
  [ -9.55847454]
  [ -9.81867313]
  [ -9.55393791]
  [ -9.8140974 ]
  [ -9.5692358 ]
  [ -9.88777542]
  [ -9.57515812]
  [ -9.88825035]
  [-10.35125446]
  [ -9.84922695]
  [-10.71660137]
  [ -9.79570675]
  [ -8.60433197]
  [ -9.55755234]
  [ -9.55074501]
  [ -9.56374264]
  [ -9.5803957 ]
  [ -9.59574509]
  [ -9.57600975]]]
After layer sequencemask10_output (10, 20, 1) <class 'numpy.float32'> [[[  5.26438296e-01]
  [  5.27140439e-01]
  [  5.22458315e-01]
  [  5.28340042e-01]
  [  5.25107622e-01]
  [  5.26280165e-01]
  [  5.23831427e-01]
  [  5.25921643e-01]
  [  5.30445337e-01]
  [  5.06898344e-01]
  [  5.21287024e-01]
  [  5.05739570e-01]
  [  5.25609732e-01]
  [  6.08876228e-01]
  [  5.27064204e-01]
  [  5.27549207e-01]
  [  5.27894795e-01]
  [  5.28178155e-01]
  [  5.28460085e-01]
  [  5.28122544e-01]]

 [[  9.19063210e-01]
  [  9.18209970e-01]
  [  9.09502983e-01]
  [  9.20640051e-01]
  [  9.09375250e-01]
  [  9.18873966e-01]
  [  9.12634611e-01]
  [  9.17207956e-01]
  [  9.02969658e-01]
  [  8.77563834e-01]
  [  9.04702246e-01]
  [  8.49042118e-01]
  [  9.11353230e-01]
  [  9.83446121e-01]
  [  9.18534636e-01]
  [  9.19556856e-01]
  [  9.19262230e-01]
  [  9.19446230e-01]
  [  9.20697451e-01]
  [  9.19545650e-01]]

 [[ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]]
After layer swapaxes30_output (20, 10, 1) <class 'numpy.float32'> [[[  5.26438296e-01]
  [  9.19063210e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  5.27140439e-01]
  [  9.18209970e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  5.22458315e-01]
  [  9.09502983e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  5.28340042e-01]
  [  9.20640051e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  5.25107622e-01]
  [  9.09375250e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  5.26280165e-01]
  [  9.18873966e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  5.23831427e-01]
  [  9.12634611e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  5.25921643e-01]
  [  9.17207956e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  5.30445337e-01]
  [  9.02969658e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  5.06898344e-01]
  [  8.77563834e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  5.21287024e-01]
  [  9.04702246e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  5.05739570e-01]
  [  8.49042118e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  5.25609732e-01]
  [  9.11353230e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  6.08876228e-01]
  [  9.83446121e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  5.27064204e-01]
  [  9.18534636e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  5.27549207e-01]
  [  9.19556856e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  5.27894795e-01]
  [  9.19262230e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  5.28178155e-01]
  [  9.19446230e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  5.28460085e-01]
  [  9.20697451e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  5.28122544e-01]
  [  9.19545650e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]]
After layer attention_softmax_0 (20, 10, 1) <class 'numpy.float32'> [[[ 0.40308556]
  [ 0.59691441]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40345985]
  [ 0.59654015]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40442893]
  [ 0.5955711 ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40316376]
  [ 0.59683627]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40509799]
  [ 0.59490204]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40309304]
  [ 0.59690696]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40400544]
  [ 0.59599459]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40340766]
  [ 0.59659231]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40793118]
  [ 0.59206879]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40838024]
  [ 0.59161979]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40530345]
  [ 0.59469658]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.41500747]
  [ 0.58499253]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40474236]
  [ 0.59525764]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40743721]
  [ 0.59256279]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40336338]
  [ 0.59663659]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40323406]
  [ 0.59676588]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40338814]
  [ 0.5966118 ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40341207]
  [ 0.5965879 ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40317878]
  [ 0.59682119]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40337473]
  [ 0.59662521]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]]
After layer batch_dot10_0 (20, 512, 1) <class 'numpy.float32'> [[[ 0.01785707]
  [ 0.03944499]
  [-0.03343614]
  ...,
  [-0.01095697]
  [ 0.00999354]
  [-0.02459649]]

 [[ 0.01784803]
  [ 0.03943456]
  [-0.0334193 ]
  ...,
  [-0.0109549 ]
  [ 0.00999311]
  [-0.02460311]]

 [[ 0.01782464]
  [ 0.03940757]
  [-0.03337568]
  ...,
  [-0.01094954]
  [ 0.00999199]
  [-0.02462024]]

 ...,
 [[ 0.01784918]
  [ 0.03943589]
  [-0.03342145]
  ...,
  [-0.01095517]
  [ 0.00999316]
  [-0.02460226]]

 [[ 0.01785482]
  [ 0.03944239]
  [-0.03343195]
  ...,
  [-0.01095646]
  [ 0.00999343]
  [-0.02459814]]

 [[ 0.01785008]
  [ 0.03943693]
  [-0.03342313]
  ...,
  [-0.01095537]
  [ 0.0099932 ]
  [-0.0246016 ]]]
After layer reshape20_0 (20, 512) <class 'numpy.float32'> [[ 0.01785707  0.03944499 -0.03343614 ..., -0.01095697  0.00999354
  -0.02459649]
 [ 0.01784803  0.03943456 -0.0334193  ..., -0.0109549   0.00999311
  -0.02460311]
 [ 0.01782464  0.03940757 -0.03337568 ..., -0.01094954  0.00999199
  -0.02462024]
 ...,
 [ 0.01784918  0.03943589 -0.03342145 ..., -0.01095517  0.00999316
  -0.02460226]
 [ 0.01785482  0.03944239 -0.03343195 ..., -0.01095646  0.00999343
  -0.02459814]
 [ 0.01785008  0.03943693 -0.03342313 ..., -0.01095537  0.0099932
  -0.0246016 ]]
After layer decoder_rnn_hidden_concat_t0_output (20, 1024) <class 'numpy.float32'> [[-0.00122205 -0.92102402  0.19639802 ..., -0.01095697  0.00999354
  -0.02459649]
 [-0.00122024 -0.92121035  0.19618936 ..., -0.0109549   0.00999311
  -0.02460311]
 [-0.00121689 -0.92325437  0.19371781 ..., -0.01094954  0.00999199
  -0.02462024]
 ...,
 [-0.0012155  -0.92124575  0.1952204  ..., -0.01095517  0.00999316
  -0.02460226]
 [-0.00121199 -0.92150724  0.19439067 ..., -0.01095646  0.00999343
  -0.02459814]
 [-0.00121573 -0.92156821  0.19518255 ..., -0.01095537  0.0099932
  -0.0246016 ]]
After layer decoder_rnn_hidden_fc_t0_output (20, 512) <class 'numpy.float32'> [[-1.94647682  0.20145269 -0.80578464 ...,  1.95569384  2.09802723
  -1.58946884]
 [-1.94809723  0.20079501 -0.80657434 ...,  1.95675826  2.09963584
  -1.58812976]
 [-1.93709719  0.20816752 -0.81365854 ...,  1.94369519  2.09391069
  -1.59386909]
 ...,
 [-1.95361555  0.20577647 -0.8122105  ...,  1.96136737  2.09771919
  -1.58809066]
 [-1.95489514  0.20877808 -0.81672269 ...,  1.96081054  2.09455585
  -1.58771753]
 [-1.94978082  0.20413662 -0.81160289 ...,  1.95726144  2.0970881
  -1.58710599]]
After layer decoder_rnn_next_hidden_t0_output (20, 512) <class 'numpy.float32'> [[-0.96004438  0.19877101 -0.66725826 ...,  0.96075988  0.97033685
  -0.92006785]
 [-0.9601711   0.19813925 -0.66769618 ...,  0.96084172  0.97043073
  -0.91986209]
 [-0.9593032   0.20521186 -0.67160356 ...,  0.95982599  0.97009528
  -0.92074049]
 ...,
 [-0.96059966  0.20292038 -0.6708079  ...,  0.96119404  0.97031885
  -0.91985607]
 [-0.96069837  0.20579663 -0.67328215 ...,  0.96115166  0.9701333
  -0.91979861]
 [-0.96030235  0.20134753 -0.67047358 ...,  0.96088028  0.9702819
  -0.91970444]]
After layer logits_output (20, 16743) <class 'numpy.float32'> [[-1.99899185 -2.82397699 -2.40886092 ..., -2.0971992  -3.4995594
  -2.57498813]
 [-1.99962866 -2.82243896 -2.40780568 ..., -2.09608865 -3.49791026
  -2.57431221]
 [-1.9939369  -2.82335782 -2.41015482 ..., -2.10127759 -3.49577856
  -2.57358098]
 ...,
 [-1.99910319 -2.8198297  -2.40441775 ..., -2.0944097  -3.49419928
  -2.57505965]
 [-1.99748111 -2.81788397 -2.40291238 ..., -2.09421682 -3.49104452
  -2.57529831]
 [-1.99794722 -2.82006073 -2.40554523 ..., -2.09529042 -3.49383259
  -2.57440495]]
After layer softmax_0 (20, 16743) <class 'numpy.float32'> [[  8.41194606e-07   3.68646624e-07   5.58332033e-07 ...,   7.62509899e-07
    1.87589407e-07   4.72872898e-07]
 [  8.43193732e-07   3.70327058e-07   5.60607077e-07 ...,   7.65659365e-07
    1.88465549e-07   4.74619583e-07]
 [  8.53267068e-07   3.72281932e-07   5.62760363e-07 ...,   7.66421067e-07
    1.90039302e-07   4.77912806e-07]
 ...,
 [  8.51884579e-07   3.74924468e-07   5.68008602e-07 ...,   7.74443436e-07
    1.91015545e-07   4.78901427e-07]
 [  8.60450996e-07   3.78817447e-07   5.73653665e-07 ...,   7.81114522e-07
    1.93232481e-07   4.82817995e-07]
 [  8.52949768e-07   3.74873110e-07   5.67421921e-07 ...,   7.73834586e-07
    1.91103624e-07   4.79260223e-07]]
After layer reshape21_0 (20, 10) <class 'numpy.float32'> [[ 0.40308556  0.59691441  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40345985  0.59654015  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40442893  0.5955711   0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40316376  0.59683627  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40509799  0.59490204  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40309304  0.59690696  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40400544  0.59599459  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40340766  0.59659231  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40793118  0.59206879  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40838024  0.59161979  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40530345  0.59469658  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.41500747  0.58499253  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40474236  0.59525764  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40743721  0.59256279  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40336338  0.59663659  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40323406  0.59676588  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40338814  0.5966118   0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40341207  0.5965879   0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40317878  0.59682119  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40337473  0.59662521  0.          0.          0.          0.          0.
   0.          0.          0.        ]]
After layer target_embed_embed_0 (20, 256) <class 'numpy.float32'> [[-0.05505371 -0.0300293  -0.03598022 ...,  0.08459473 -0.05288696
  -0.01667786]
 [-0.05505371 -0.0300293  -0.03598022 ...,  0.08459473 -0.05288696
  -0.01667786]
 [-0.05505371 -0.0300293  -0.03598022 ...,  0.08459473 -0.05288696
  -0.01667786]
 ...,
 [-0.05505371 -0.0300293  -0.03598022 ...,  0.08459473 -0.05288696
  -0.01667786]
 [-0.05505371 -0.0300293  -0.03598022 ...,  0.08459473 -0.05288696
  -0.01667786]
 [-0.05505371 -0.0300293  -0.03598022 ...,  0.08459473 -0.05288696
  -0.01667786]]
After layer decoder_rnn_concat_target_context_t0_output (20, 768) <class 'numpy.float32'> [[-0.05505371 -0.0300293  -0.03598022 ...,  0.96075988  0.97033685
  -0.92006785]
 [-0.05505371 -0.0300293  -0.03598022 ...,  0.96084172  0.97043073
  -0.91986209]
 [-0.05505371 -0.0300293  -0.03598022 ...,  0.95982599  0.97009528
  -0.92074049]
 ...,
 [-0.05505371 -0.0300293  -0.03598022 ...,  0.96119404  0.97031885
  -0.91985607]
 [-0.05505371 -0.0300293  -0.03598022 ...,  0.96115166  0.9701333
  -0.91979861]
 [-0.05505371 -0.0300293  -0.03598022 ...,  0.96088028  0.9702819
  -0.91970444]]
After layer decoder_rnn_l0_t0_i2h_output (20, 2048) <class 'numpy.float32'> [[-3.1885128   1.61279476  2.43228364 ..., -0.07732911  3.86621046
   0.60067517]
 [-3.18763304  1.6119988   2.43173194 ..., -0.07734493  3.86406183
   0.60096282]
 [-3.18346024  1.61273038  2.42925763 ..., -0.0748658   3.86624146
   0.60565341]
 ...,
 [-3.18496132  1.60926318  2.43273044 ..., -0.07683478  3.85984659
   0.60053158]
 [-3.18263793  1.60817385  2.43329597 ..., -0.07652315  3.85751367
   0.6004625 ]
 [-3.18472767  1.6102463   2.43223071 ..., -0.07724125  3.86048937
   0.60100293]]
After layer decoder_rnn_l0_t0_h2h_output (20, 2048) <class 'numpy.float32'> [[-0.32189378  0.47259435  1.82943881 ...,  0.70170027  1.2972405
   0.17350073]
 [-0.32294559  0.47340775  1.82890868 ...,  0.69985491  1.29552531
   0.1723066 ]
 [-0.32872364  0.48142534  1.8212564  ...,  0.69614619  1.30582535
   0.16783747]
 ...,
 [-0.32572514  0.48001993  1.83061552 ...,  0.69762456  1.29794586
   0.16721064]
 [-0.32822546  0.48598817  1.82926476 ...,  0.69440854  1.30153966
   0.16232719]
 [-0.32641715  0.48045877  1.82783842 ...,  0.69553632  1.29884863
   0.16678335]]
After layer _plus1055_0 (20, 2048) <class 'numpy.float32'> [[-3.51040649  2.08538914  4.26172256 ...,  0.62437117  5.16345119
   0.77417588]
 [-3.51057863  2.08540654  4.26064062 ...,  0.62250996  5.15958691
   0.77326941]
 [-3.5121839   2.09415579  4.25051403 ...,  0.62128037  5.17206669
   0.77349091]
 ...,
 [-3.5106864   2.08928299  4.26334572 ...,  0.62078977  5.15779257
   0.76774222]
 [-3.5108633   2.09416199  4.26256084 ...,  0.61788535  5.15905333
   0.76278967]
 [-3.51114488  2.09070516  4.26006889 ...,  0.61829507  5.159338
   0.76778626]]
After layer decoder_rnn_l0_t0_slice_output0 (20, 512) <class 'numpy.float32'> [[-3.51040649  2.08538914  4.26172256 ...,  1.75053346  4.59253311
   2.78016281]
 [-3.51057863  2.08540654  4.26064062 ...,  1.74847674  4.59567642
   2.77822113]
 [-3.5121839   2.09415579  4.25051403 ...,  1.75707936  4.57868052
   2.77631974]
 ...,
 [-3.5106864   2.08928299  4.26334572 ...,  1.74252033  4.59296608
   2.77627754]
 [-3.5108633   2.09416199  4.26256084 ...,  1.74020982  4.59016895
   2.7733283 ]
 [-3.51114488  2.09070516  4.26006889 ...,  1.74462104  4.59282875
   2.77511978]]
After layer decoder_rnn_l0_t0_slice_output1 (20, 512) <class 'numpy.float32'> [[-1.86601543  2.3080225   2.41862822 ...,  3.1616888  -0.72265303
   1.97074556]
 [-1.86580086  2.30848265  2.41856575 ...,  3.15949965 -0.71896088
   1.96955657]
 [-1.87538457  2.30115652  2.4241395  ...,  3.15394878 -0.7371093
   1.96404994]
 ...,
 [-1.86914718  2.31051755  2.4191308  ...,  3.15446901 -0.71227992
   1.9662528 ]
 [-1.87314868  2.31072521  2.4186976  ...,  3.14972067 -0.71174502
   1.96305168]
 [-1.87066925  2.30918789  2.41802692 ...,  3.15343142 -0.716429
   1.96538687]]
After layer decoder_rnn_l0_t0_slice_output2 (20, 512) <class 'numpy.float32'> [[-2.81168914 -3.07599449  2.84704971 ...,  4.26087189 -0.0745576
   2.1625123 ]
 [-2.81041098 -3.07560396  2.84536171 ...,  4.25857258 -0.07764286
   2.16106319]
 [-2.81441784 -3.07993197  2.86274862 ...,  4.24837065 -0.07832623
   2.16179132]
 ...,
 [-2.80666041 -3.07670569  2.84656119 ...,  4.25096798 -0.08712381
   2.15913177]
 [-2.80395389 -3.07794857  2.84783483 ...,  4.24470997 -0.09357673
   2.15772676]
 [-2.80653644 -3.07642221  2.84614038 ...,  4.25109863 -0.08530754
   2.15957165]]
After layer decoder_rnn_l0_t0_slice_output3 (20, 512) <class 'numpy.float32'> [[-3.27080393  2.44751763 -1.4063046  ...,  0.62437117  5.16345119
   0.77417588]
 [-3.27204943  2.44919586 -1.40672445 ...,  0.62250996  5.15958691
   0.77326941]
 [-3.26908541  2.46919203 -1.41930628 ...,  0.62128037  5.17206669
   0.77349091]
 ...,
 [-3.27331161  2.4495852  -1.4110955  ...,  0.62078977  5.15779257
   0.76774222]
 [-3.27395582  2.45237184 -1.41565681 ...,  0.61788535  5.15905333
   0.76278967]
 [-3.27289438  2.45286584 -1.41174054 ...,  0.61829507  5.159338
   0.76778626]]
After layer decoder_rnn_l0_t0_o_output (20, 512) <class 'numpy.float32'> [[ 0.03658648  0.92037976  0.19681759 ...,  0.6512121   0.99431062
   0.68442351]
 [ 0.03654261  0.92050266  0.19675121 ...,  0.6507892   0.99428868
   0.68422771]
 [ 0.0366471   0.92195362  0.19477037 ...,  0.65050972  0.9943592
   0.68427557]
 ...,
 [ 0.03649819  0.92053115  0.19606133 ...,  0.65039819  0.99427855
   0.68303233]
 [ 0.03647555  0.92073476  0.19534336 ...,  0.64973742  0.99428576
   0.68195909]
 [ 0.03651287  0.9207707   0.19595967 ...,  0.6498307   0.99428731
   0.68304181]]
After layer decoder_rnn_l0_t0_f_output (20, 512) <class 'numpy.float32'> [[ 0.13400345  0.90953928  0.91823685 ...,  0.95936686  0.32680902
   0.87769115]
 [ 0.13402835  0.90957713  0.91823214 ...,  0.95928138  0.32762185
   0.87756348]
 [ 0.13291991  0.9089728   0.91864967 ...,  0.95906401  0.32363656
   0.87697059]
 ...,
 [ 0.13364042  0.90974432  0.91827458 ...,  0.95908445  0.32909527
   0.87720805]
 [ 0.13317782  0.90976143  0.91824198 ...,  0.95889771  0.32921338
   0.87686282]
 [ 0.13346429  0.90963513  0.91819161 ...,  0.95904374  0.32817984
   0.87711477]]
After layer _mul2110_0 (20, 512) <class 'numpy.float32'> [[ -4.47170855e-03  -4.78646612e+00   5.48014641e+00 ...,   6.01867867e+00
   -3.51247080e-02   4.22733784e+00]
 [ -4.47249226e-03  -4.78744745e+00   5.44513464e+00 ...,   5.92942381e+00
   -3.81641872e-02   4.17262745e+00]
 [ -4.42282762e-03  -4.74938631e+00   5.47137547e+00 ...,   5.80263805e+00
   -4.04409170e-02   4.07802153e+00]
 ...,
 [ -4.44953190e-03  -4.78106976e+00   5.40886450e+00 ...,   5.88278246e+00
   -4.65326905e-02   4.10092211e+00]
 [ -4.42642067e-03  -4.77961826e+00   5.40859747e+00 ...,   5.87273884e+00
   -5.23390435e-02   4.08802032e+00]
 [ -4.44365153e-03  -4.78777790e+00   5.43372965e+00 ...,   5.87353992e+00
   -4.55218330e-02   4.12731028e+00]]
After layer decoder_rnn_l0_t0_i_output (20, 512) <class 'numpy.float32'> [[ 0.02901758  0.88947493  0.98609793 ...,  0.85202008  0.98997432
   0.94159442]
 [ 0.02901273  0.88947666  0.98608309 ...,  0.85176057  0.99000555
   0.94148755]
 [ 0.02896754  0.89033383  0.98594344 ...,  0.85284352  0.98983592
   0.94138265]
 ...,
 [ 0.02900969  0.88985717  0.98612022 ...,  0.85100687  0.98997867
   0.94138032]
 [ 0.02900471  0.89033443  0.98610955 ...,  0.85071373  0.98995084
   0.94121742]
 [ 0.02899678  0.88999641  0.98607534 ...,  0.85127306  0.98997724
   0.94131643]]
After layer decoder_rnn_l0_t0_c_output (20, 512) <class 'numpy.float32'> [[-0.99280119 -0.99575055  0.99329102 ...,  0.9996019  -0.07441976
   0.97387922]
 [-0.99278283 -0.99574727  0.99326843 ...,  0.99960005 -0.07748722
   0.97380441]
 [-0.99284023 -0.99578381  0.99349773 ...,  0.99959183 -0.07816644
   0.97384202]
 ...,
 [-0.99272865 -0.99575657  0.99328452 ...,  0.99959391 -0.08690404
   0.97370434]
 [-0.99268937 -0.99576712  0.99330151 ...,  0.99958885 -0.09330454
   0.97363132]
 [-0.99272686 -0.99575418  0.99327886 ...,  0.99959403 -0.0851012
   0.97372717]]
After layer _mul2111_0 (20, 512) <class 'numpy.float32'> [[-0.02880869 -0.88569516  0.97948223 ...,  0.85168087 -0.07367365
   0.91699922]
 [-0.02880334 -0.88569397  0.97944522 ...,  0.85141993 -0.07671277
   0.91682476]
 [-0.02876014 -0.88657999  0.97953254 ...,  0.85249543 -0.07737195
   0.916758  ]
 ...,
 [-0.02879875 -0.8860811   0.97949797 ...,  0.85066128 -0.08603315
   0.9166261 ]
 [-0.02879267 -0.88656574  0.97950411 ...,  0.85036397 -0.09236691
   0.91639876]
 [-0.02878589 -0.88621765  0.97944778 ...,  0.85092747 -0.08424825
   0.91658539]]
After layer decoder_rnn_l0_t0_state_0 (20, 512) <class 'numpy.float32'> [[-0.03328039 -5.6721611   6.45962858 ...,  6.87035942 -0.10879835
   5.14433718]
 [-0.03327584 -5.67314148  6.42457962 ...,  6.78084373 -0.11487696
   5.08945227]
 [-0.03318297 -5.6359663   6.45090818 ...,  6.65513325 -0.11781286
   4.99477959]
 ...,
 [-0.03324829 -5.66715097  6.38836241 ...,  6.73344374 -0.13256584
   5.01754808]
 [-0.03321909 -5.66618395  6.38810158 ...,  6.72310257 -0.14470595
   5.00441933]
 [-0.03322954 -5.67399549  6.41317749 ...,  6.72446728 -0.12977009
   5.04389572]]
After layer activation1055_output (20, 512) <class 'numpy.float32'> [[-0.03326811 -0.99997634  0.99999511 ...,  0.99999785 -0.10837109
   0.99993199]
 [-0.03326356 -0.9999764   0.99999475 ...,  0.99999744 -0.11437428
   0.99992406]
 [-0.03317079 -0.99997455  0.99999499 ...,  0.99999666 -0.1172708
   0.99990827]
 ...,
 [-0.03323604 -0.9999761   0.99999434 ...,  0.99999714 -0.13179471
   0.99991232]
 [-0.03320687 -0.99997604  0.99999434 ...,  0.99999708 -0.14370431  0.99991   ]
 [-0.03321731 -0.9999764   0.99999464 ...,  0.99999714 -0.12904651
   0.99991685]]
After layer decoder_rnn_l0_t0_out_0 (20, 512) <class 'numpy.float32'> [[-0.00121716 -0.920358    0.19681662 ...,  0.65121073 -0.10775453
   0.68437696]
 [-0.00121554 -0.92048091  0.19675018 ...,  0.65078753 -0.11372105
   0.68417573]
 [-0.00121561 -0.92193013  0.1947694  ...,  0.65050757 -0.11660931
   0.6842128 ]
 ...,
 [-0.00121306 -0.92050916  0.19606021 ...,  0.65039635 -0.13104065
   0.68297243]
 [-0.00121124 -0.92071271  0.19534226 ...,  0.64973551 -0.14288315
   0.6818977 ]
 [-0.00121286 -0.92074895  0.19595861 ...,  0.64982885 -0.12830931
   0.68298501]]
After layer expand_dims1064_0 (20, 512, 1) <class 'numpy.float32'> [[[-0.00121716]
  [-0.920358  ]
  [ 0.19681662]
  ...,
  [ 0.65121073]
  [-0.10775453]
  [ 0.68437696]]

 [[-0.00121554]
  [-0.92048091]
  [ 0.19675018]
  ...,
  [ 0.65078753]
  [-0.11372105]
  [ 0.68417573]]

 [[-0.00121561]
  [-0.92193013]
  [ 0.1947694 ]
  ...,
  [ 0.65050757]
  [-0.11660931]
  [ 0.6842128 ]]

 ...,
 [[-0.00121306]
  [-0.92050916]
  [ 0.19606021]
  ...,
  [ 0.65039635]
  [-0.13104065]
  [ 0.68297243]]

 [[-0.00121124]
  [-0.92071271]
  [ 0.19534226]
  ...,
  [ 0.64973551]
  [-0.14288315]
  [ 0.6818977 ]]

 [[-0.00121286]
  [-0.92074895]
  [ 0.19595861]
  ...,
  [ 0.64982885]
  [-0.12830931]
  [ 0.68298501]]]
After layer att_batch_dot_0 (20, 10, 1) <class 'numpy.float32'> [[[  0.52843094]
  [  0.92116112]
  [  1.61740971]
  [  2.57193184]
  [  2.48341918]
  [  0.24070843]
  [ -2.98763132]
  [ -5.82035732]
  [ -7.94961309]
  [ -9.54319477]]

 [[  0.52892536]
  [  0.92051572]
  [  1.6186353 ]
  [  2.57488203]
  [  2.48791122]
  [  0.24561562]
  [ -2.98304582]
  [ -5.81578302]
  [ -7.9444418 ]
  [ -9.53692532]]

 [[  0.5258373 ]
  [  0.91526943]
  [  1.59947681]
  [  2.53421068]
  [  2.41542053]
  [  0.13672423]
  [ -3.12428188]
  [ -5.98232365]
  [ -8.12901211]
  [ -9.73277664]]

 [[  0.52961403]
  [  0.92223197]
  [  1.6231631 ]
  [  2.58410382]
  [  2.50038338]
  [  0.25682873]
  [ -2.97623992]
  [ -5.81392622]
  [ -7.94651508]
  [ -9.54147911]]

 [[  0.52621585]
  [  0.91383922]
  [  1.6045748 ]
  [  2.54561162]
  [  2.42413688]
  [  0.12719746]
  [ -3.16049123]
  [ -6.04357386]
  [ -8.20917225]
  [ -9.8252697 ]]

 [[  0.52819884]
  [  0.92094529]
  [  1.61803901]
  [  2.57314849]
  [  2.48460793]
  [  0.2406272 ]
  [ -2.98970032]
  [ -5.82442808]
  [ -7.95533323]
  [ -9.55012989]]

 [[  0.52657849]
  [  0.9183563 ]
  [  1.60852265]
  [  2.55105352]
  [  2.43291593]
  [  0.1418914 ]
  [ -3.13896346]
  [ -6.01690531]
  [ -8.1794548 ]
  [ -9.79421997]]

 [[  0.5281781 ]
  [  0.91995358]
  [  1.61488044]
  [  2.56680679]
  [  2.47604418]
  [  0.23288418]
  [ -2.99434304]
  [ -5.82522726]
  [ -7.95263338]
  [ -9.54467583]]

 [[  0.53000975]
  [  0.91387844]
  [  1.60869086]
  [  2.55506063]
  [  2.45025182]
  [  0.18211925]
  [ -3.07217741]
  [ -5.92176485]
  [ -8.0590477 ]
  [ -9.65437698]]

 [[  0.51596731]
  [  0.89573967]
  [  1.55760109]
  [  2.45214939]
  [  2.26764727]
  [ -0.09293921]
  [ -3.43104672]
  [ -6.34890032]
  [ -8.53655434]
  [-10.16529751]]

 [[  0.5253911 ]
  [  0.91232938]
  [  1.59304857]
  [  2.52119565]
  [  2.39663148]
  [  0.11664203]
  [ -3.14160109]
  [ -5.99493933]
  [ -8.13683033]
  [ -9.73654366]]

 [[  0.51348019]
  [  0.88608027]
  [  1.54746151]
  [  2.43653393]
  [  2.24180841]
  [ -0.13349906]
  [ -3.48545957]
  [ -6.4096818 ]
  [ -8.59806347]
  [-10.22518349]]

 [[  0.5262028 ]
  [  0.91471297]
  [  1.60267913]
  [  2.54071093]
  [  2.41766047]
  [  0.12268319]
  [ -3.16069913]
  [ -6.0394311 ]
  [ -8.20190811]
  [ -9.81626797]]

 [[  0.51241249]
  [  0.86157036]
  [  1.50232482]
  [  2.34348583]
  [  2.08308101]
  [ -0.36210933]
  [ -3.76414466]
  [ -6.70979929]
  [ -8.90708637]
  [-10.53851604]]

 [[  0.52887392]
  [  0.92078024]
  [  1.61874843]
  [  2.57500482]
  [  2.48808908]
  [  0.24587627]
  [ -2.9827435 ]
  [ -5.81555223]
  [ -7.94433022]
  [ -9.53691006]]

 [[  0.52918059]
  [  0.92148697]
  [  1.62024236]
  [  2.57801533]
  [  2.49263597]
  [  0.25109738]
  [ -2.97773504]
  [ -5.81120586]
  [ -7.94070053]
  [ -9.53387737]]

 [[  0.52939963]
  [  0.92131788]
  [  1.62078524]
  [  2.57917261]
  [  2.49316335]
  [  0.24901925]
  [ -2.98317552]
  [ -5.81938171]
  [ -7.95053864]
  [ -9.54438972]]

 [[  0.52941239]
  [  0.92124325]
  [  1.62222099]
  [  2.5821023 ]
  [  2.49560404]
  [  0.24760346]
  [ -2.98998642]
  [ -5.83129644]
  [ -7.96665335]
  [ -9.56392097]]

 [[  0.52944988]
  [  0.92218274]
  [  1.62450624]
  [  2.5867548 ]
  [  2.50063992]
  [  0.24888328]
  [ -2.99485636]
  [ -5.84231615]
  [ -7.98250103]
  [ -9.58290195]]

 [[  0.5294584 ]
  [  0.92146242]
  [  1.62151408]
  [  2.58080316]
  [  2.49444842]
  [  0.24768063]
  [ -2.98825336]
  [ -5.82800531]
  [ -7.96191692]
  [ -9.55761528]]]
After layer swapaxes31_output (10, 20, 1) <class 'numpy.float32'> [[[  0.52843094]
  [  0.52892536]
  [  0.5258373 ]
  [  0.52961403]
  [  0.52621585]
  [  0.52819884]
  [  0.52657849]
  [  0.5281781 ]
  [  0.53000975]
  [  0.51596731]
  [  0.5253911 ]
  [  0.51348019]
  [  0.5262028 ]
  [  0.51241249]
  [  0.52887392]
  [  0.52918059]
  [  0.52939963]
  [  0.52941239]
  [  0.52944988]
  [  0.5294584 ]]

 [[  0.92116112]
  [  0.92051572]
  [  0.91526943]
  [  0.92223197]
  [  0.91383922]
  [  0.92094529]
  [  0.9183563 ]
  [  0.91995358]
  [  0.91387844]
  [  0.89573967]
  [  0.91232938]
  [  0.88608027]
  [  0.91471297]
  [  0.86157036]
  [  0.92078024]
  [  0.92148697]
  [  0.92131788]
  [  0.92124325]
  [  0.92218274]
  [  0.92146242]]

 [[  1.61740971]
  [  1.6186353 ]
  [  1.59947681]
  [  1.6231631 ]
  [  1.6045748 ]
  [  1.61803901]
  [  1.60852265]
  [  1.61488044]
  [  1.60869086]
  [  1.55760109]
  [  1.59304857]
  [  1.54746151]
  [  1.60267913]
  [  1.50232482]
  [  1.61874843]
  [  1.62024236]
  [  1.62078524]
  [  1.62222099]
  [  1.62450624]
  [  1.62151408]]

 [[  2.57193184]
  [  2.57488203]
  [  2.53421068]
  [  2.58410382]
  [  2.54561162]
  [  2.57314849]
  [  2.55105352]
  [  2.56680679]
  [  2.55506063]
  [  2.45214939]
  [  2.52119565]
  [  2.43653393]
  [  2.54071093]
  [  2.34348583]
  [  2.57500482]
  [  2.57801533]
  [  2.57917261]
  [  2.5821023 ]
  [  2.5867548 ]
  [  2.58080316]]

 [[  2.48341918]
  [  2.48791122]
  [  2.41542053]
  [  2.50038338]
  [  2.42413688]
  [  2.48460793]
  [  2.43291593]
  [  2.47604418]
  [  2.45025182]
  [  2.26764727]
  [  2.39663148]
  [  2.24180841]
  [  2.41766047]
  [  2.08308101]
  [  2.48808908]
  [  2.49263597]
  [  2.49316335]
  [  2.49560404]
  [  2.50063992]
  [  2.49444842]]

 [[  0.24070843]
  [  0.24561562]
  [  0.13672423]
  [  0.25682873]
  [  0.12719746]
  [  0.2406272 ]
  [  0.1418914 ]
  [  0.23288418]
  [  0.18211925]
  [ -0.09293921]
  [  0.11664203]
  [ -0.13349906]
  [  0.12268319]
  [ -0.36210933]
  [  0.24587627]
  [  0.25109738]
  [  0.24901925]
  [  0.24760346]
  [  0.24888328]
  [  0.24768063]]

 [[ -2.98763132]
  [ -2.98304582]
  [ -3.12428188]
  [ -2.97623992]
  [ -3.16049123]
  [ -2.98970032]
  [ -3.13896346]
  [ -2.99434304]
  [ -3.07217741]
  [ -3.43104672]
  [ -3.14160109]
  [ -3.48545957]
  [ -3.16069913]
  [ -3.76414466]
  [ -2.9827435 ]
  [ -2.97773504]
  [ -2.98317552]
  [ -2.98998642]
  [ -2.99485636]
  [ -2.98825336]]

 [[ -5.82035732]
  [ -5.81578302]
  [ -5.98232365]
  [ -5.81392622]
  [ -6.04357386]
  [ -5.82442808]
  [ -6.01690531]
  [ -5.82522726]
  [ -5.92176485]
  [ -6.34890032]
  [ -5.99493933]
  [ -6.4096818 ]
  [ -6.0394311 ]
  [ -6.70979929]
  [ -5.81555223]
  [ -5.81120586]
  [ -5.81938171]
  [ -5.83129644]
  [ -5.84231615]
  [ -5.82800531]]

 [[ -7.94961309]
  [ -7.9444418 ]
  [ -8.12901211]
  [ -7.94651508]
  [ -8.20917225]
  [ -7.95533323]
  [ -8.1794548 ]
  [ -7.95263338]
  [ -8.0590477 ]
  [ -8.53655434]
  [ -8.13683033]
  [ -8.59806347]
  [ -8.20190811]
  [ -8.90708637]
  [ -7.94433022]
  [ -7.94070053]
  [ -7.95053864]
  [ -7.96665335]
  [ -7.98250103]
  [ -7.96191692]]

 [[ -9.54319477]
  [ -9.53692532]
  [ -9.73277664]
  [ -9.54147911]
  [ -9.8252697 ]
  [ -9.55012989]
  [ -9.79421997]
  [ -9.54467583]
  [ -9.65437698]
  [-10.16529751]
  [ -9.73654366]
  [-10.22518349]
  [ -9.81626797]
  [-10.53851604]
  [ -9.53691006]
  [ -9.53387737]
  [ -9.54438972]
  [ -9.56392097]
  [ -9.58290195]
  [ -9.55761528]]]
After layer sequencemask11_output (10, 20, 1) <class 'numpy.float32'> [[[  5.28430939e-01]
  [  5.28925359e-01]
  [  5.25837302e-01]
  [  5.29614031e-01]
  [  5.26215851e-01]
  [  5.28198838e-01]
  [  5.26578486e-01]
  [  5.28178096e-01]
  [  5.30009747e-01]
  [  5.15967309e-01]
  [  5.25391102e-01]
  [  5.13480186e-01]
  [  5.26202798e-01]
  [  5.12412488e-01]
  [  5.28873920e-01]
  [  5.29180586e-01]
  [  5.29399633e-01]
  [  5.29412389e-01]
  [  5.29449880e-01]
  [  5.29458404e-01]]

 [[  9.21161115e-01]
  [  9.20515716e-01]
  [  9.15269434e-01]
  [  9.22231972e-01]
  [  9.13839221e-01]
  [  9.20945287e-01]
  [  9.18356299e-01]
  [  9.19953585e-01]
  [  9.13878441e-01]
  [  8.95739675e-01]
  [  9.12329376e-01]
  [  8.86080265e-01]
  [  9.14712965e-01]
  [  8.61570358e-01]
  [  9.20780241e-01]
  [  9.21486974e-01]
  [  9.21317875e-01]
  [  9.21243250e-01]
  [  9.22182739e-01]
  [  9.21462417e-01]]

 [[ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]]
After layer swapaxes32_output (20, 10, 1) <class 'numpy.float32'> [[[  5.28430939e-01]
  [  9.21161115e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  5.28925359e-01]
  [  9.20515716e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  5.25837302e-01]
  [  9.15269434e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  5.29614031e-01]
  [  9.22231972e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  5.26215851e-01]
  [  9.13839221e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  5.28198838e-01]
  [  9.20945287e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  5.26578486e-01]
  [  9.18356299e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  5.28178096e-01]
  [  9.19953585e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  5.30009747e-01]
  [  9.13878441e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  5.15967309e-01]
  [  8.95739675e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  5.25391102e-01]
  [  9.12329376e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  5.13480186e-01]
  [  8.86080265e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  5.26202798e-01]
  [  9.14712965e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  5.12412488e-01]
  [  8.61570358e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  5.28873920e-01]
  [  9.20780241e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  5.29180586e-01]
  [  9.21486974e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  5.29399633e-01]
  [  9.21317875e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  5.29412389e-01]
  [  9.21243250e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  5.29449880e-01]
  [  9.22182739e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  5.29458404e-01]
  [  9.21462417e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]]
After layer attention_softmax_0 (20, 10, 1) <class 'numpy.float32'> [[[ 0.40306023]
  [ 0.59693974]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.4033345 ]
  [ 0.5966655 ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40385401]
  [ 0.59614599]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40308723]
  [ 0.59691274]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40428954]
  [ 0.59571046]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40305632]
  [ 0.59694368]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40328941]
  [ 0.59671062]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40328994]
  [ 0.59671003]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40519416]
  [ 0.5948059 ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40618178]
  [ 0.59381819]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40445459]
  [ 0.59554547]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40791288]
  [ 0.59208709]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40407598]
  [ 0.59592402]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.41358668]
  [ 0.58641338]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40325847]
  [ 0.5967415 ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40316221]
  [ 0.59683782]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40325564]
  [ 0.59674442]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40327665]
  [ 0.59672338]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.4030596 ]
  [ 0.5969404 ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40323496]
  [ 0.59676504]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]]
After layer batch_dot11_0 (20, 512, 1) <class 'numpy.float32'> [[[ 0.01785768]
  [ 0.03944569]
  [-0.03343728]
  ...,
  [-0.01095711]
  [ 0.00999357]
  [-0.02459604]]

 [[ 0.01785106]
  [ 0.03943805]
  [-0.03342494]
  ...,
  [-0.0109556 ]
  [ 0.00999325]
  [-0.02460089]]

 [[ 0.01783852]
  [ 0.03942358]
  [-0.03340155]
  ...,
  [-0.01095272]
  [ 0.00999265]
  [-0.02461008]]

 ...,
 [[ 0.01785246]
  [ 0.03943967]
  [-0.03342754]
  ...,
  [-0.01095592]
  [ 0.00999332]
  [-0.02459987]]

 [[ 0.01785769]
  [ 0.03944571]
  [-0.03343731]
  ...,
  [-0.01095712]
  [ 0.00999357]
  [-0.02459603]]

 [[ 0.01785346]
  [ 0.03944083]
  [-0.03342942]
  ...,
  [-0.01095615]
  [ 0.00999336]
  [-0.02459913]]]
After layer reshape22_0 (20, 512) <class 'numpy.float32'> [[ 0.01785768  0.03944569 -0.03343728 ..., -0.01095711  0.00999357
  -0.02459604]
 [ 0.01785106  0.03943805 -0.03342494 ..., -0.0109556   0.00999325
  -0.02460089]
 [ 0.01783852  0.03942358 -0.03340155 ..., -0.01095272  0.00999265
  -0.02461008]
 ...,
 [ 0.01785246  0.03943967 -0.03342754 ..., -0.01095592  0.00999332
  -0.02459987]
 [ 0.01785769  0.03944571 -0.03343731 ..., -0.01095712  0.00999357
  -0.02459603]
 [ 0.01785346  0.03944083 -0.03342942 ..., -0.01095615  0.00999336
  -0.02459913]]
After layer decoder_rnn_hidden_concat_t0_output (20, 1024) <class 'numpy.float32'> [[-0.00121716 -0.920358    0.19681662 ..., -0.01095711  0.00999357
  -0.02459604]
 [-0.00121554 -0.92048091  0.19675018 ..., -0.0109556   0.00999325
  -0.02460089]
 [-0.00121561 -0.92193013  0.1947694  ..., -0.01095272  0.00999265
  -0.02461008]
 ...,
 [-0.00121306 -0.92050916  0.19606021 ..., -0.01095592  0.00999332
  -0.02459987]
 [-0.00121124 -0.92071271  0.19534226 ..., -0.01095712  0.00999357
  -0.02459603]
 [-0.00121286 -0.92074895  0.19595861 ..., -0.01095615  0.00999336
  -0.02459913]]
After layer decoder_rnn_hidden_fc_t0_output (20, 512) <class 'numpy.float32'> [[-1.95437336  0.2037968  -0.80795848 ...,  1.96505189  2.103158
  -1.59192026]
 [-1.95544243  0.20303182 -0.80828148 ...,  1.96571648  2.10455036
  -1.5910635 ]
 [-1.94745803  0.20840004 -0.81449014 ...,  1.95588052  2.10021853
  -1.59614444]
 ...,
 [-1.9597708   0.20718923 -0.81311119 ...,  1.96867836  2.1031208
  -1.59180415]
 [-1.960904    0.20993702 -0.81706434 ...,  1.96805251  2.10065055
  -1.59188902]
 [-1.9567126   0.20584559 -0.81243587 ...,  1.96570253  2.10259938
  -1.59074831]]
After layer decoder_rnn_next_hidden_t0_output (20, 512) <class 'numpy.float32'> [[-0.96065813  0.20102146 -0.66846251 ...,  0.96147346  0.97063524
  -0.92044324]
 [-0.96074051  0.20028728 -0.66864109 ...,  0.96152365  0.9707157
  -0.92031223]
 [-0.96012115  0.20543458 -0.67205977 ...,  0.96077424  0.97046465
  -0.92108613]
 ...,
 [-0.96107233  0.20427458 -0.67130297 ...,  0.96174657  0.97063309
  -0.92042547]
 [-0.96115875  0.20690621 -0.67346889 ...,  0.96169955  0.9704898
  -0.92043847]
 [-0.9608382   0.20298666 -0.67093182 ...,  0.96152258  0.97060287
  -0.92026401]]
After layer logits_output (20, 16743) <class 'numpy.float32'> [[-2.00247622 -2.82428336 -2.40769601 ..., -2.09527349 -3.50045371
  -2.57804728]
 [-2.00308084 -2.82328868 -2.40700293 ..., -2.09442902 -3.49940848
  -2.57761431]
 [-1.99869621 -2.824754   -2.40843749 ..., -2.09882045 -3.4978714
  -2.57818508]
 ...,
 [-2.00281978 -2.82156634 -2.40496802 ..., -2.09348083 -3.49688482
  -2.57858896]
 [-2.00154924 -2.82022762 -2.40409017 ..., -2.09355474 -3.49460816
  -2.57903028]
 [-2.00182772 -2.82173777 -2.40561366 ..., -2.09406137 -3.49656677
  -2.5779593 ]]
After layer softmax_0 (20, 16743) <class 'numpy.float32'> [[  8.40431028e-07   3.69483814e-07   5.60424667e-07 ...,   7.65949778e-07
    1.87905016e-07   4.72644615e-07]
 [  8.41539077e-07   3.70563185e-07   5.61891909e-07 ...,   7.68072312e-07
    1.88463460e-07   4.73759172e-07]
 [  8.50342644e-07   3.72256039e-07   5.64476068e-07 ...,   7.69326164e-07
    1.89893669e-07   4.76348902e-07]
 ...,
 [  8.47619049e-07   3.73786492e-07   5.66956771e-07 ...,   7.74153534e-07
    1.90255122e-07   4.76592959e-07]
 [  8.54205098e-07   3.76716315e-07   5.71137662e-07 ...,   7.79120398e-07
    1.91926461e-07   4.79474238e-07]
 [  8.48795423e-07   3.73869966e-07   5.66814151e-07 ...,   7.74009720e-07
    1.90390764e-07   4.77081016e-07]]
After layer reshape23_0 (20, 10) <class 'numpy.float32'> [[ 0.40306023  0.59693974  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.4033345   0.5966655   0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40385401  0.59614599  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40308723  0.59691274  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40428954  0.59571046  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40305632  0.59694368  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40328941  0.59671062  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40328994  0.59671003  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40519416  0.5948059   0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40618178  0.59381819  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40445459  0.59554547  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40791288  0.59208709  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40407598  0.59592402  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.41358668  0.58641338  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40325847  0.5967415   0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40316221  0.59683782  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40325564  0.59674442  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40327665  0.59672338  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.4030596   0.5969404   0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40323496  0.59676504  0.          0.          0.          0.          0.
   0.          0.          0.        ]]
After layer target_embed_embed_0 (20, 256) <class 'numpy.float32'> [[-0.05505371 -0.0300293  -0.03598022 ...,  0.08459473 -0.05288696
  -0.01667786]
 [-0.05505371 -0.0300293  -0.03598022 ...,  0.08459473 -0.05288696
  -0.01667786]
 [-0.05505371 -0.0300293  -0.03598022 ...,  0.08459473 -0.05288696
  -0.01667786]
 ...,
 [-0.05505371 -0.0300293  -0.03598022 ...,  0.08459473 -0.05288696
  -0.01667786]
 [-0.05505371 -0.0300293  -0.03598022 ...,  0.08459473 -0.05288696
  -0.01667786]
 [-0.05505371 -0.0300293  -0.03598022 ...,  0.08459473 -0.05288696
  -0.01667786]]
After layer decoder_rnn_concat_target_context_t0_output (20, 768) <class 'numpy.float32'> [[-0.05505371 -0.0300293  -0.03598022 ...,  0.96147346  0.97063524
  -0.92044324]
 [-0.05505371 -0.0300293  -0.03598022 ...,  0.96152365  0.9707157
  -0.92031223]
 [-0.05505371 -0.0300293  -0.03598022 ...,  0.96077424  0.97046465
  -0.92108613]
 ...,
 [-0.05505371 -0.0300293  -0.03598022 ...,  0.96174657  0.97063309
  -0.92042547]
 [-0.05505371 -0.0300293  -0.03598022 ...,  0.96169955  0.9704898
  -0.92043847]
 [-0.05505371 -0.0300293  -0.03598022 ...,  0.96152258  0.97060287
  -0.92026401]]
After layer decoder_rnn_l0_t0_i2h_output (20, 2048) <class 'numpy.float32'> [[-3.19084001  1.61121082  2.43420315 ..., -0.07779398  3.86527872
   0.59981626]
 [-3.19033289  1.6106813   2.43385553 ..., -0.0777816   3.8638711
   0.60007244]
 [-3.18786621  1.6116457   2.43270683 ..., -0.07652749  3.8661871
   0.60428655]
 ...,
 [-3.18837404  1.60870671  2.43489742 ..., -0.07715598  3.8610878
   0.59977502]
 [-3.18660092  1.60796237  2.43548107 ..., -0.07678224  3.85955071
   0.59974515]
 [-3.1882236   1.6094954   2.43439698 ..., -0.07754751  3.86155176
   0.60019761]]
After layer decoder_rnn_l0_t0_h2h_output (20, 2048) <class 'numpy.float32'> [[-0.32165894  0.47260636  1.8375026  ...,  0.70371705  1.29733884
   0.17493883]
 [-0.32242611  0.47289506  1.83726537 ...,  0.70247585  1.29589891
   0.17409447]
 [-0.32666078  0.48074731  1.83111107 ...,  0.69961029  1.30540085
   0.1697153 ]
 ...,
 [-0.324265    0.47790226  1.83818793 ...,  0.70115972  1.29818463
   0.17002998]
 [-0.32593155  0.48267162  1.83693004 ...,  0.69882286  1.30148113
   0.16610882]
 [-0.32482764  0.47829705  1.83623838 ...,  0.69942999  1.29886973
   0.16975118]]
After layer _plus1056_0 (20, 2048) <class 'numpy.float32'> [[-3.51249886  2.08381724  4.27170563 ...,  0.6259231   5.16261768
   0.77475512]
 [-3.51275897  2.08357644  4.27112103 ...,  0.62469423  5.15977001
   0.77416694]
 [-3.51452708  2.09239292  4.26381779 ...,  0.62308282  5.17158794
   0.77400184]
 ...,
 [-3.51263905  2.08660889  4.27308559 ...,  0.62400371  5.15927219
   0.76980501]
 [-3.51253247  2.09063387  4.27241135 ...,  0.62204063  5.16103172
   0.765854  ]
 [-3.51305127  2.0877924   4.2706356  ...,  0.6218825   5.16042137
   0.76994878]]
After layer decoder_rnn_l0_t0_slice_output0 (20, 512) <class 'numpy.float32'> [[-3.51249886  2.08381724  4.27170563 ...,  1.74631739  4.59969616
   2.78245926]
 [-3.51275897  2.08357644  4.27112103 ...,  1.74494469  4.60240173
   2.7809689 ]
 [-3.51452708  2.09239292  4.26381779 ...,  1.75251317  4.58982038
   2.7806499 ]
 ...,
 [-3.51263905  2.08660889  4.27308559 ...,  1.74090719  4.59991264
   2.77915192]
 [-3.51253247  2.09063387  4.27241135 ...,  1.73947191  4.59728765
   2.77686167]
 [-3.51305127  2.0877924   4.2706356  ...,  1.74255359  4.59986687
   2.77863622]]
After layer decoder_rnn_l0_t0_slice_output1 (20, 512) <class 'numpy.float32'> [[-1.86192429  2.31360435  2.42424488 ...,  3.16358566 -0.71132529
   1.97564101]
 [-1.86156034  2.3140223   2.42421484 ...,  3.162292   -0.70876193
   1.97502613]
 [-1.8698014   2.30789518  2.43028831 ...,  3.15842152 -0.72060776
   1.97126698]
 ...,
 [-1.86400914  2.31518555  2.42531061 ...,  3.15852404 -0.70458651
   1.97291362]
 [-1.86708462  2.31510615  2.42549324 ...,  3.15476966 -0.70459056
   1.9707154 ]
 [-1.8651464   2.31429553  2.42429352 ...,  3.15778351 -0.70745933
   1.97225976]]
After layer decoder_rnn_l0_t0_slice_output2 (20, 512) <class 'numpy.float32'> [[-2.8141892  -3.07970905  2.84650087 ...,  4.26283789 -0.07798719
   2.16321683]
 [-2.81338525 -3.07966185  2.84526157 ...,  4.26143837 -0.07996491
   2.1620543 ]
 [-2.81839895 -3.08337402  2.86137176 ...,  4.25431299 -0.08125463
   2.16283178]
 ...,
 [-2.81131554 -3.08162498  2.84729719 ...,  4.2552309  -0.0863772
   2.16058445]
 [-2.8098824  -3.0832119   2.84897852 ...,  4.250072   -0.09111953
   2.15966558]
 [-2.81121707 -3.08096313  2.84663558 ...,  4.25556946 -0.08542138
   2.1610117 ]]
After layer decoder_rnn_l0_t0_slice_output3 (20, 512) <class 'numpy.float32'> [[-3.27216363  2.44097948 -1.40448451 ...,  0.6259231   5.16261768
   0.77475512]
 [-3.27313137  2.44209051 -1.40440035 ...,  0.62469423  5.15977001
   0.77416694]
 [-3.26922369  2.45687795 -1.41477752 ...,  0.62308282  5.17158794
   0.77400184]
 ...,
 [-3.27394176  2.44232416 -1.40786588 ...,  0.62400371  5.15927219
   0.76980501]
 [-3.2742672   2.44444299 -1.41185486 ...,  0.62204063  5.16103172
   0.765854  ]
 [-3.27355623  2.44482636 -1.40848255 ...,  0.6218825   5.16042137
   0.76994878]]
After layer decoder_rnn_l0_t0_o_output (20, 512) <class 'numpy.float32'> [[ 0.03653858  0.91989934  0.19710545 ...,  0.65156442  0.99430591
   0.68454862]
 [ 0.03650453  0.91998112  0.19711877 ...,  0.65128541  0.99428976
   0.6844216 ]
 [ 0.03664222  0.92106301  0.19548161 ...,  0.65091938  0.99435645
   0.68438596]
 ...,
 [ 0.03647604  0.91999829  0.19657087 ...,  0.65112859  0.99428695
   0.68347871]
 [ 0.03646461  0.92015409  0.19594166 ...,  0.65068251  0.99429697
   0.68262333]
 [ 0.03648959  0.92018229  0.19647351 ...,  0.65064657  0.99429339
   0.68350983]]
After layer decoder_rnn_l0_t0_f_output (20, 512) <class 'numpy.float32'> [[ 0.13447891  0.90999746  0.91865748 ...,  0.95944071  0.32930607
   0.87821573]
 [ 0.13452129  0.91003174  0.91865528 ...,  0.95939034  0.32987249
   0.87814993]
 [ 0.1335647   0.90952885  0.91910791 ...,  0.9592393   0.32725915
   0.87774712]
 ...,
 [ 0.13423644  0.91012692  0.91873711 ...,  0.95924324  0.33079612
   0.87792373]
 [ 0.13387942  0.91012043  0.91875076 ...,  0.95909625  0.33079523
   0.87768793]
 [ 0.13410433  0.91005403  0.91866112 ...,  0.95921427  0.3301605
   0.87785363]]
After layer _mul2112_0 (20, 512) <class 'numpy.float32'> [[ -4.47551114e-03  -5.16165209e+00   5.93418598e+00 ...,   6.59170246e+00
   -3.58279571e-02   4.51783800e+00]
 [ -4.47630836e-03  -5.16273880e+00   5.90197420e+00 ...,   6.50547600e+00
   -3.78947482e-02   4.46930218e+00]
 [ -4.43207286e-03  -5.12607384e+00   5.92908096e+00 ...,   6.38386536e+00
   -3.85553390e-02   4.38415337e+00]
 ...,
 [ -4.46313154e-03  -5.15782690e+00   5.86922550e+00 ...,   6.45901060e+00
   -4.38522659e-02   4.40502453e+00]
 [ -4.44735214e-03  -5.15690994e+00   5.86907339e+00 ...,   6.44810247e+00
   -4.78680395e-02   4.39231825e+00]
 [ -4.45622485e-03  -5.16364241e+00   5.89153671e+00 ...,   6.45020485e+00
   -4.28449549e-02   4.42780209e+00]]
After layer decoder_rnn_l0_t0_i_output (20, 512) <class 'numpy.float32'> [[ 0.02895869  0.88932031  0.98623419 ...,  0.8514877   0.99004513
   0.9417206 ]
 [ 0.02895137  0.88929665  0.98622626 ...,  0.85131407  0.99007177
   0.94163871]
 [ 0.02890171  0.89016163  0.98612672 ...,  0.85226953  0.98994738
   0.94162112]
 ...,
 [ 0.02895474  0.88959485  0.98625296 ...,  0.85080224  0.9900474
   0.94153881]
 [ 0.02895774  0.88998955  0.98624378 ...,  0.85061991  0.99002141
   0.94141263]
 [ 0.02894315  0.88971096  0.98621964 ...,  0.8510111   0.99004692
   0.94151038]]
After layer decoder_rnn_l0_t0_c_output (20, 512) <class 'numpy.float32'> [[-0.99283695 -0.99578196  0.99328369 ...,  0.99960345 -0.07782947
   0.97391552]
 [-0.99282545 -0.99578154  0.99326712 ...,  0.99960232 -0.0797949
   0.97385561]
 [-0.9928968  -0.99581271  0.99347985 ...,  0.99959666 -0.08107628
   0.97389567]
 ...,
 [-0.99279583 -0.99579805  0.99329436 ...,  0.99959737 -0.08616302
   0.97377962]
 [-0.9927752  -0.99581134  0.99331677 ...,  0.9995932  -0.09086818
   0.97373205]
 [-0.99279439 -0.99579251  0.99328548 ...,  0.99959767 -0.08521422
   0.97380173]]
After layer _mul2113_0 (20, 512) <class 'numpy.float32'> [[-0.02875126 -0.8855691   0.97961032 ...,  0.85115004 -0.07705469
   0.91715634]
 [-0.02874366 -0.88554519  0.97958612 ...,  0.85097551 -0.07900268
   0.91702014]
 [-0.02869641 -0.88643426  0.97969705 ...,  0.85192579 -0.08026125
   0.91704071]
 ...,
 [-0.02874615 -0.88585681  0.97963953 ...,  0.85045969 -0.08530547
   0.91685128]
 [-0.02874853 -0.8862617   0.97965246 ...,  0.85027391 -0.08996145
   0.91668367]
 [-0.0287346  -0.88596749  0.97959763 ...,  0.85066873 -0.08436608
   0.91684443]]
After layer decoder_rnn_l0_t0_state_0 (20, 512) <class 'numpy.float32'> [[-0.03322677 -6.04722118  6.91379642 ...,  7.4428525  -0.11288264
   5.43499422]
 [-0.03321997 -6.04828405  6.88156033 ...,  7.35645151 -0.11689743
   5.3863225 ]
 [-0.03312849 -6.01250792  6.90877819 ...,  7.23579121 -0.11881659
   5.30119419]
 ...,
 [-0.03320928 -6.04368353  6.84886503 ...,  7.30947018 -0.12915774
   5.32187557]
 [-0.03319588 -6.04317188  6.8487258  ...,  7.29837656 -0.13782948
   5.30900192]
 [-0.03319083 -6.04961014  6.87113428 ...,  7.30087376 -0.12721103
   5.34464645]]
After layer activation1056_output (20, 512) <class 'numpy.float32'> [[-0.03321454 -0.99998879  0.99999803 ...,  0.99999928 -0.11240561
   0.99996197]
 [-0.03320775 -0.99998885  0.99999791 ...,  0.99999917 -0.11636785
   0.9999581 ]
 [-0.03311637 -0.99998802  0.99999803 ...,  0.99999899 -0.11826061
   0.99995029]
 ...,
 [-0.03319708 -0.99998873  0.99999774 ...,  0.99999911 -0.12844431
   0.99995232]
 [-0.03318369 -0.99998873  0.99999774 ...,  0.99999911 -0.13696329
   0.99995106]
 [-0.03317865 -0.99998885  0.99999785 ...,  0.99999911 -0.12652925
   0.9999544 ]]
After layer decoder_rnn_l0_t0_out_0 (20, 512) <class 'numpy.float32'> [[-0.00121361 -0.91988903  0.19710506 ...,  0.65156394 -0.11176556
   0.68452257]
 [-0.00121223 -0.91997087  0.19711836 ...,  0.65128487 -0.11570337
   0.68439293]
 [-0.00121346 -0.92105198  0.19548123 ...,  0.65091872 -0.1175932
   0.68435192]
 ...,
 [-0.0012109  -0.91998792  0.19657043 ...,  0.65112799 -0.12771051
   0.68344611]
 [-0.00121003 -0.92014372  0.19594121 ...,  0.65068191 -0.13618219
   0.68258995]
 [-0.00121068 -0.92017204  0.19647309 ...,  0.65064597 -0.1258072
   0.68347865]]
After layer expand_dims1065_0 (20, 512, 1) <class 'numpy.float32'> [[[-0.00121361]
  [-0.91988903]
  [ 0.19710506]
  ...,
  [ 0.65156394]
  [-0.11176556]
  [ 0.68452257]]

 [[-0.00121223]
  [-0.91997087]
  [ 0.19711836]
  ...,
  [ 0.65128487]
  [-0.11570337]
  [ 0.68439293]]

 [[-0.00121346]
  [-0.92105198]
  [ 0.19548123]
  ...,
  [ 0.65091872]
  [-0.1175932 ]
  [ 0.68435192]]

 ...,
 [[-0.0012109 ]
  [-0.91998792]
  [ 0.19657043]
  ...,
  [ 0.65112799]
  [-0.12771051]
  [ 0.68344611]]

 [[-0.00121003]
  [-0.92014372]
  [ 0.19594121]
  ...,
  [ 0.65068191]
  [-0.13618219]
  [ 0.68258995]]

 [[-0.00121068]
  [-0.92017204]
  [ 0.19647309]
  ...,
  [ 0.65064597]
  [-0.1258072 ]
  [ 0.68347865]]]
After layer att_batch_dot_0 (20, 10, 1) <class 'numpy.float32'> [[[  5.29521585e-01]
  [  9.22042608e-01]
  [  1.62323773e+00]
  [  2.58337784e+00]
  [  2.49930453e+00]
  [  2.56921977e-01]
  [ -2.97365022e+00]
  [ -5.80899763e+00]
  [ -7.94081163e+00]
  [ -9.53716183e+00]]

 [[  5.29889584e-01]
  [  9.21550512e-01]
  [  1.62411153e+00]
  [  2.58548832e+00]
  [  2.50264215e+00]
  [  2.60830045e-01]
  [ -2.96966863e+00]
  [ -5.80477047e+00]
  [ -7.93594027e+00]
  [ -9.53133583e+00]]

 [[  5.27626634e-01]
  [  9.18027222e-01]
  [  1.61000943e+00]
  [  2.55551267e+00]
  [  2.44834185e+00]
  [  1.77480027e-01]
  [ -3.07970428e+00]
  [ -5.93634415e+00]
  [ -8.08333397e+00]
  [ -9.68901443e+00]]

 [[  5.30228913e-01]
  [  9.22751606e-01]
  [  1.62689888e+00]
  [  2.59110332e+00]
  [  2.50971270e+00]
  [  2.65851974e-01]
  [ -2.96897578e+00]
  [ -5.80869246e+00]
  [ -7.94358397e+00]
  [ -9.54146862e+00]]

 [[  5.28311014e-01]
  [  9.18100059e-01]
  [  1.61537647e+00]
  [  2.56580853e+00]
  [  2.45618749e+00]
  [  1.70732364e-01]
  [ -3.10733485e+00]
  [ -5.98389339e+00]
  [ -8.14605331e+00]
  [ -9.76149273e+00]]

 [[  5.29275358e-01]
  [  9.21879232e-01]
  [  1.62365603e+00]
  [  2.58410335e+00]
  [  2.49971294e+00]
  [  2.55907267e-01]
  [ -2.97667193e+00]
  [ -5.81398344e+00]
  [ -7.94740057e+00]
  [ -9.54494858e+00]]

 [[  5.27569234e-01]
  [  9.19634879e-01]
  [  1.61420822e+00]
  [  2.56272364e+00]
  [  2.45160055e+00]
  [  1.66009024e-01]
  [ -3.11114931e+00]
  [ -5.98690844e+00]
  [ -8.14903450e+00]
  [ -9.76528835e+00]]

 [[  5.29446006e-01]
  [  9.21262264e-01]
  [  1.62181640e+00]
  [  2.58050466e+00]
  [  2.49546719e+00]
  [  2.53569186e-01]
  [ -2.97542715e+00]
  [ -5.80879688e+00]
  [ -7.93873119e+00]
  [ -9.53353214e+00]]

 [[  5.29874146e-01]
  [  9.15674508e-01]
  [  1.61493373e+00]
  [  2.56722856e+00]
  [  2.46298742e+00]
  [  1.86147302e-01]
  [ -3.08298326e+00]
  [ -5.95068884e+00]
  [ -8.10479927e+00]
  [ -9.71346283e+00]]

 [[  5.22435486e-01]
  [  9.07901168e-01]
  [  1.58609438e+00]
  [  2.50657916e+00]
  [  2.35688233e+00]
  [  3.18776369e-02]
  [ -3.27679825e+00]
  [ -6.17434692e+00]
  [ -8.34992313e+00]
  [ -9.97312641e+00]]

 [[  5.27648747e-01]
  [  9.16251957e-01]
  [  1.60664284e+00]
  [  2.54866028e+00]
  [  2.43930197e+00]
  [  1.69961855e-01]
  [ -3.08293676e+00]
  [ -5.93427515e+00]
  [ -8.07629776e+00]
  [ -9.67789555e+00]]

 [[  5.20353496e-01]
  [  9.01530027e-01]
  [  1.57984459e+00]
  [  2.49779630e+00]
  [  2.33863401e+00]
  [ -4.29614726e-03]
  [ -3.33370447e+00]
  [ -6.24828339e+00]
  [ -8.43528271e+00]
  [ -1.00648994e+01]]

 [[  5.28016329e-01]
  [  9.18524086e-01]
  [  1.61411285e+00]
  [  2.56277394e+00]
  [  2.45247340e+00]
  [  1.68860257e-01]
  [ -3.10577369e+00]
  [ -5.97891283e+00]
  [ -8.13859081e+00]
  [ -9.75261497e+00]]

 [[  5.18286645e-01]
  [  8.92512202e-01]
  [  1.56598401e+00]
  [  2.47360945e+00]
  [  2.30319023e+00]
  [ -4.81918752e-02]
  [ -3.38137078e+00]
  [ -6.29336548e+00]
  [ -8.47511673e+00]
  [ -1.00997639e+01]]

 [[  5.29851913e-01]
  [  9.21765864e-01]
  [  1.62421107e+00]
  [  2.58559394e+00]
  [  2.50274014e+00]
  [  2.60889173e-01]
  [ -2.96969366e+00]
  [ -5.80495548e+00]
  [ -7.93630362e+00]
  [ -9.53183556e+00]]

 [[  5.30037284e-01]
  [  9.22262371e-01]
  [  1.62516940e+00]
  [  2.58752704e+00]
  [  2.50560451e+00]
  [  2.64013201e-01]
  [ -2.96695614e+00]
  [ -5.80290413e+00]
  [ -7.93494797e+00]
  [ -9.53104019e+00]]

 [[  5.30163705e-01]
  [  9.22138691e-01]
  [  1.62543368e+00]
  [  2.58806610e+00]
  [  2.50545573e+00]
  [  2.61725157e-01]
  [ -2.97191072e+00]
  [ -5.81006956e+00]
  [ -7.94352341e+00]
  [ -9.54026508e+00]]

 [[  5.30014992e-01]
  [  9.21936035e-01]
  [  1.62596679e+00]
  [  2.58913827e+00]
  [  2.50528026e+00]
  [  2.57628471e-01]
  [ -2.98099971e+00]
  [ -5.82378674e+00]
  [ -7.96103382e+00]
  [ -9.56084633e+00]]

 [[  5.29874504e-01]
  [  9.22602832e-01]
  [  1.62721610e+00]
  [  2.59162998e+00]
  [  2.50719070e+00]
  [  2.55563021e-01]
  [ -2.98885679e+00]
  [ -5.83735847e+00]
  [ -7.97918272e+00]
  [ -9.58210278e+00]]

 [[  5.30111611e-01]
  [  9.22179759e-01]
  [  1.62565649e+00]
  [  2.58861852e+00]
  [  2.50523257e+00]
  [  2.58924246e-01]
  [ -2.97810006e+00]
  [ -5.81944704e+00]
  [ -7.95541620e+00]
  [ -9.55391979e+00]]]
After layer swapaxes33_output (10, 20, 1) <class 'numpy.float32'> [[[  5.29521585e-01]
  [  5.29889584e-01]
  [  5.27626634e-01]
  [  5.30228913e-01]
  [  5.28311014e-01]
  [  5.29275358e-01]
  [  5.27569234e-01]
  [  5.29446006e-01]
  [  5.29874146e-01]
  [  5.22435486e-01]
  [  5.27648747e-01]
  [  5.20353496e-01]
  [  5.28016329e-01]
  [  5.18286645e-01]
  [  5.29851913e-01]
  [  5.30037284e-01]
  [  5.30163705e-01]
  [  5.30014992e-01]
  [  5.29874504e-01]
  [  5.30111611e-01]]

 [[  9.22042608e-01]
  [  9.21550512e-01]
  [  9.18027222e-01]
  [  9.22751606e-01]
  [  9.18100059e-01]
  [  9.21879232e-01]
  [  9.19634879e-01]
  [  9.21262264e-01]
  [  9.15674508e-01]
  [  9.07901168e-01]
  [  9.16251957e-01]
  [  9.01530027e-01]
  [  9.18524086e-01]
  [  8.92512202e-01]
  [  9.21765864e-01]
  [  9.22262371e-01]
  [  9.22138691e-01]
  [  9.21936035e-01]
  [  9.22602832e-01]
  [  9.22179759e-01]]

 [[  1.62323773e+00]
  [  1.62411153e+00]
  [  1.61000943e+00]
  [  1.62689888e+00]
  [  1.61537647e+00]
  [  1.62365603e+00]
  [  1.61420822e+00]
  [  1.62181640e+00]
  [  1.61493373e+00]
  [  1.58609438e+00]
  [  1.60664284e+00]
  [  1.57984459e+00]
  [  1.61411285e+00]
  [  1.56598401e+00]
  [  1.62421107e+00]
  [  1.62516940e+00]
  [  1.62543368e+00]
  [  1.62596679e+00]
  [  1.62721610e+00]
  [  1.62565649e+00]]

 [[  2.58337784e+00]
  [  2.58548832e+00]
  [  2.55551267e+00]
  [  2.59110332e+00]
  [  2.56580853e+00]
  [  2.58410335e+00]
  [  2.56272364e+00]
  [  2.58050466e+00]
  [  2.56722856e+00]
  [  2.50657916e+00]
  [  2.54866028e+00]
  [  2.49779630e+00]
  [  2.56277394e+00]
  [  2.47360945e+00]
  [  2.58559394e+00]
  [  2.58752704e+00]
  [  2.58806610e+00]
  [  2.58913827e+00]
  [  2.59162998e+00]
  [  2.58861852e+00]]

 [[  2.49930453e+00]
  [  2.50264215e+00]
  [  2.44834185e+00]
  [  2.50971270e+00]
  [  2.45618749e+00]
  [  2.49971294e+00]
  [  2.45160055e+00]
  [  2.49546719e+00]
  [  2.46298742e+00]
  [  2.35688233e+00]
  [  2.43930197e+00]
  [  2.33863401e+00]
  [  2.45247340e+00]
  [  2.30319023e+00]
  [  2.50274014e+00]
  [  2.50560451e+00]
  [  2.50545573e+00]
  [  2.50528026e+00]
  [  2.50719070e+00]
  [  2.50523257e+00]]

 [[  2.56921977e-01]
  [  2.60830045e-01]
  [  1.77480027e-01]
  [  2.65851974e-01]
  [  1.70732364e-01]
  [  2.55907267e-01]
  [  1.66009024e-01]
  [  2.53569186e-01]
  [  1.86147302e-01]
  [  3.18776369e-02]
  [  1.69961855e-01]
  [ -4.29614726e-03]
  [  1.68860257e-01]
  [ -4.81918752e-02]
  [  2.60889173e-01]
  [  2.64013201e-01]
  [  2.61725157e-01]
  [  2.57628471e-01]
  [  2.55563021e-01]
  [  2.58924246e-01]]

 [[ -2.97365022e+00]
  [ -2.96966863e+00]
  [ -3.07970428e+00]
  [ -2.96897578e+00]
  [ -3.10733485e+00]
  [ -2.97667193e+00]
  [ -3.11114931e+00]
  [ -2.97542715e+00]
  [ -3.08298326e+00]
  [ -3.27679825e+00]
  [ -3.08293676e+00]
  [ -3.33370447e+00]
  [ -3.10577369e+00]
  [ -3.38137078e+00]
  [ -2.96969366e+00]
  [ -2.96695614e+00]
  [ -2.97191072e+00]
  [ -2.98099971e+00]
  [ -2.98885679e+00]
  [ -2.97810006e+00]]

 [[ -5.80899763e+00]
  [ -5.80477047e+00]
  [ -5.93634415e+00]
  [ -5.80869246e+00]
  [ -5.98389339e+00]
  [ -5.81398344e+00]
  [ -5.98690844e+00]
  [ -5.80879688e+00]
  [ -5.95068884e+00]
  [ -6.17434692e+00]
  [ -5.93427515e+00]
  [ -6.24828339e+00]
  [ -5.97891283e+00]
  [ -6.29336548e+00]
  [ -5.80495548e+00]
  [ -5.80290413e+00]
  [ -5.81006956e+00]
  [ -5.82378674e+00]
  [ -5.83735847e+00]
  [ -5.81944704e+00]]

 [[ -7.94081163e+00]
  [ -7.93594027e+00]
  [ -8.08333397e+00]
  [ -7.94358397e+00]
  [ -8.14605331e+00]
  [ -7.94740057e+00]
  [ -8.14903450e+00]
  [ -7.93873119e+00]
  [ -8.10479927e+00]
  [ -8.34992313e+00]
  [ -8.07629776e+00]
  [ -8.43528271e+00]
  [ -8.13859081e+00]
  [ -8.47511673e+00]
  [ -7.93630362e+00]
  [ -7.93494797e+00]
  [ -7.94352341e+00]
  [ -7.96103382e+00]
  [ -7.97918272e+00]
  [ -7.95541620e+00]]

 [[ -9.53716183e+00]
  [ -9.53133583e+00]
  [ -9.68901443e+00]
  [ -9.54146862e+00]
  [ -9.76149273e+00]
  [ -9.54494858e+00]
  [ -9.76528835e+00]
  [ -9.53353214e+00]
  [ -9.71346283e+00]
  [ -9.97312641e+00]
  [ -9.67789555e+00]
  [ -1.00648994e+01]
  [ -9.75261497e+00]
  [ -1.00997639e+01]
  [ -9.53183556e+00]
  [ -9.53104019e+00]
  [ -9.54026508e+00]
  [ -9.56084633e+00]
  [ -9.58210278e+00]
  [ -9.55391979e+00]]]
After layer sequencemask12_output (10, 20, 1) <class 'numpy.float32'> [[[  5.29521585e-01]
  [  5.29889584e-01]
  [  5.27626634e-01]
  [  5.30228913e-01]
  [  5.28311014e-01]
  [  5.29275358e-01]
  [  5.27569234e-01]
  [  5.29446006e-01]
  [  5.29874146e-01]
  [  5.22435486e-01]
  [  5.27648747e-01]
  [  5.20353496e-01]
  [  5.28016329e-01]
  [  5.18286645e-01]
  [  5.29851913e-01]
  [  5.30037284e-01]
  [  5.30163705e-01]
  [  5.30014992e-01]
  [  5.29874504e-01]
  [  5.30111611e-01]]

 [[  9.22042608e-01]
  [  9.21550512e-01]
  [  9.18027222e-01]
  [  9.22751606e-01]
  [  9.18100059e-01]
  [  9.21879232e-01]
  [  9.19634879e-01]
  [  9.21262264e-01]
  [  9.15674508e-01]
  [  9.07901168e-01]
  [  9.16251957e-01]
  [  9.01530027e-01]
  [  9.18524086e-01]
  [  8.92512202e-01]
  [  9.21765864e-01]
  [  9.22262371e-01]
  [  9.22138691e-01]
  [  9.21936035e-01]
  [  9.22602832e-01]
  [  9.22179759e-01]]

 [[ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]]
After layer swapaxes34_output (20, 10, 1) <class 'numpy.float32'> [[[  5.29521585e-01]
  [  9.22042608e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  5.29889584e-01]
  [  9.21550512e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  5.27626634e-01]
  [  9.18027222e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  5.30228913e-01]
  [  9.22751606e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  5.28311014e-01]
  [  9.18100059e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  5.29275358e-01]
  [  9.21879232e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  5.27569234e-01]
  [  9.19634879e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  5.29446006e-01]
  [  9.21262264e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  5.29874146e-01]
  [  9.15674508e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  5.22435486e-01]
  [  9.07901168e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  5.27648747e-01]
  [  9.16251957e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  5.20353496e-01]
  [  9.01530027e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  5.28016329e-01]
  [  9.18524086e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  5.18286645e-01]
  [  8.92512202e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  5.29851913e-01]
  [  9.21765864e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  5.30037284e-01]
  [  9.22262371e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  5.30163705e-01]
  [  9.22138691e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  5.30014992e-01]
  [  9.21936035e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  5.29874504e-01]
  [  9.22602832e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  5.30111611e-01]
  [  9.22179759e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]]
After layer attention_softmax_0 (20, 10, 1) <class 'numpy.float32'> [[[ 0.40311059]
  [ 0.59688944]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40331751]
  [ 0.59668249]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40362087]
  [ 0.5963791 ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40311018]
  [ 0.59688985]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40376809]
  [ 0.59623194]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40309063]
  [ 0.5969094 ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40322015]
  [ 0.59677988]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40328017]
  [ 0.59671986]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40472868]
  [ 0.59527129]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40480933]
  [ 0.5951907 ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40405357]
  [ 0.59594643]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40584314]
  [ 0.59415686]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40359506]
  [ 0.59640491]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40752038]
  [ 0.59247965]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40325665]
  [ 0.5967434 ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40318176]
  [ 0.59681821]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40324196]
  [ 0.59675807]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40325496]
  [ 0.59674507]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40306067]
  [ 0.59693933]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40321955]
  [ 0.59678048]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]]
After layer batch_dot12_0 (20, 512, 1) <class 'numpy.float32'> [[[ 0.01785646]
  [ 0.03944429]
  [-0.03343502]
  ...,
  [-0.01095684]
  [ 0.00999351]
  [-0.02459694]]

 [[ 0.01785147]
  [ 0.03943853]
  [-0.0334257 ]
  ...,
  [-0.01095569]
  [ 0.00999327]
  [-0.02460059]]

 [[ 0.01784414]
  [ 0.03943007]
  [-0.03341205]
  ...,
  [-0.01095401]
  [ 0.00999292]
  [-0.02460595]]

 ...,
 [[ 0.01785298]
  [ 0.03944027]
  [-0.03342852]
  ...,
  [-0.01095604]
  [ 0.00999334]
  [-0.02459949]]

 [[ 0.01785767]
  [ 0.03944568]
  [-0.03343726]
  ...,
  [-0.01095711]
  [ 0.00999356]
  [-0.02459605]]

 [[ 0.01785383]
  [ 0.03944126]
  [-0.03343011]
  ...,
  [-0.01095623]
  [ 0.00999338]
  [-0.02459886]]]
After layer reshape24_0 (20, 512) <class 'numpy.float32'> [[ 0.01785646  0.03944429 -0.03343502 ..., -0.01095684  0.00999351
  -0.02459694]
 [ 0.01785147  0.03943853 -0.0334257  ..., -0.01095569  0.00999327
  -0.02460059]
 [ 0.01784414  0.03943007 -0.03341205 ..., -0.01095401  0.00999292
  -0.02460595]
 ...,
 [ 0.01785298  0.03944027 -0.03342852 ..., -0.01095604  0.00999334
  -0.02459949]
 [ 0.01785767  0.03944568 -0.03343726 ..., -0.01095711  0.00999356
  -0.02459605]
 [ 0.01785383  0.03944126 -0.03343011 ..., -0.01095623  0.00999338
  -0.02459886]]
After layer decoder_rnn_hidden_concat_t0_output (20, 1024) <class 'numpy.float32'> [[-0.00121361 -0.91988903  0.19710506 ..., -0.01095684  0.00999351
  -0.02459694]
 [-0.00121223 -0.91997087  0.19711836 ..., -0.01095569  0.00999327
  -0.02460059]
 [-0.00121346 -0.92105198  0.19548123 ..., -0.01095401  0.00999292
  -0.02460595]
 ...,
 [-0.0012109  -0.91998792  0.19657043 ..., -0.01095604  0.00999334
  -0.02459949]
 [-0.00121003 -0.92014372  0.19594121 ..., -0.01095711  0.00999356
  -0.02459605]
 [-0.00121068 -0.92017204  0.19647309 ..., -0.01095623  0.00999338
  -0.02459886]]
After layer decoder_rnn_hidden_fc_t0_output (20, 512) <class 'numpy.float32'> [[-1.96037745  0.2061128  -0.81011117 ...,  1.97171378  2.10689998
  -1.59418321]
 [-1.96105886  0.2052999  -0.81015629 ...,  1.97208893  2.10810709
  -1.59363031]
 [-1.95493531  0.20972863 -0.81573665 ...,  1.964571    2.10419369
  -1.59787726]
 ...,
 [-1.96440458  0.20880558 -0.81422168 ...,  1.97392631  2.10695314
  -1.59469879]
 [-1.96540534  0.21138185 -0.81769586 ...,  1.97330678  2.10487437
  -1.59501672]
 [-1.96204078  0.20776896 -0.81365877 ...,  1.97180533  2.10648203
  -1.59370482]]
After layer decoder_rnn_next_hidden_t0_output (20, 512) <class 'numpy.float32'> [[-0.96111864  0.20324284 -0.66965163 ...,  0.96197367  0.970851
  -0.92078829]
 [-0.96117055  0.20246339 -0.66967642 ...,  0.96200168  0.97092026
  -0.92070413]
 [-0.96070147  0.20670675 -0.67274272 ...,  0.96143711  0.97069514
  -0.92134839]
 ...,
 [-0.96142453  0.20582296 -0.67191255 ...,  0.96213841  0.97085404
  -0.92086667]
 [-0.96150017  0.20828879 -0.67381382 ...,  0.96209234  0.97073442
  -0.92091501]
 [-0.96124524  0.20483005 -0.67160368 ...,  0.96198052  0.97082698
  -0.92071545]]
After layer logits_output (20, 16743) <class 'numpy.float32'> [[-2.00521898 -2.82428384 -2.4069705  ..., -2.09396553 -3.50103545
  -2.58025789]
 [-2.00578952 -2.82365966 -2.4065249  ..., -2.09333086 -3.50037146
  -2.57998514]
 [-2.00207734 -2.82513285 -2.40713716 ..., -2.0969491  -3.49903274
  -2.58097863]
 ...,
 [-2.00564051 -2.82253003 -2.40530467 ..., -2.09283757 -3.49861217
  -2.58102083]
 [-2.00458312 -2.82156873 -2.40478015 ..., -2.09304929 -3.49691439
  -2.58153772]
 [-2.00480604 -2.82261658 -2.40564942 ..., -2.09322381 -3.49833632
  -2.58043551]]
After layer softmax_0 (20, 16743) <class 'numpy.float32'> [[  8.39724521e-07   3.70187536e-07   5.61899697e-07 ...,   7.68413372e-07
    1.88153422e-07   4.72498698e-07]
 [  8.40242592e-07   3.70858459e-07   5.62817718e-07 ...,   7.69814790e-07
    1.88501957e-07   4.73189374e-07]
 [  8.48720163e-07   3.72662839e-07   5.66042786e-07 ...,   7.71902194e-07
    1.89952402e-07   4.75719389e-07]
 ...,
 [  8.44846113e-07   3.73256427e-07   5.66507595e-07 ...,   7.74298996e-07
    1.89840250e-07   4.75218201e-07]
 [  8.50194283e-07   3.75583085e-07   5.69790018e-07 ...,   7.78212154e-07
    1.91164503e-07   4.77474657e-07]
 [  8.45918407e-07   3.73385660e-07   5.66557901e-07 ...,   7.74335206e-07
    1.89975012e-07   4.75702535e-07]]
After layer reshape25_0 (20, 10) <class 'numpy.float32'> [[ 0.40311059  0.59688944  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40331751  0.59668249  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40362087  0.5963791   0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40311018  0.59688985  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40376809  0.59623194  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40309063  0.5969094   0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40322015  0.59677988  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40328017  0.59671986  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40472868  0.59527129  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40480933  0.5951907   0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40405357  0.59594643  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40584314  0.59415686  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40359506  0.59640491  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40752038  0.59247965  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40325665  0.5967434   0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40318176  0.59681821  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40324196  0.59675807  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40325496  0.59674507  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40306067  0.59693933  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40321955  0.59678048  0.          0.          0.          0.          0.
   0.          0.          0.        ]]
After layer target_embed_embed_0 (20, 256) <class 'numpy.float32'> [[-0.05505371 -0.0300293  -0.03598022 ...,  0.08459473 -0.05288696
  -0.01667786]
 [-0.05505371 -0.0300293  -0.03598022 ...,  0.08459473 -0.05288696
  -0.01667786]
 [-0.05505371 -0.0300293  -0.03598022 ...,  0.08459473 -0.05288696
  -0.01667786]
 ...,
 [-0.05505371 -0.0300293  -0.03598022 ...,  0.08459473 -0.05288696
  -0.01667786]
 [-0.05505371 -0.0300293  -0.03598022 ...,  0.08459473 -0.05288696
  -0.01667786]
 [-0.05505371 -0.0300293  -0.03598022 ...,  0.08459473 -0.05288696
  -0.01667786]]
After layer decoder_rnn_concat_target_context_t0_output (20, 768) <class 'numpy.float32'> [[-0.05505371 -0.0300293  -0.03598022 ...,  0.96197367  0.970851
  -0.92078829]
 [-0.05505371 -0.0300293  -0.03598022 ...,  0.96200168  0.97092026
  -0.92070413]
 [-0.05505371 -0.0300293  -0.03598022 ...,  0.96143711  0.97069514
  -0.92134839]
 ...,
 [-0.05505371 -0.0300293  -0.03598022 ...,  0.96213841  0.97085404
  -0.92086667]
 [-0.05505371 -0.0300293  -0.03598022 ...,  0.96209234  0.97073442
  -0.92091501]
 [-0.05505371 -0.0300293  -0.03598022 ...,  0.96198052  0.97082698
  -0.92071545]]
After layer decoder_rnn_l0_t0_i2h_output (20, 2048) <class 'numpy.float32'> [[-3.19233251  1.60984802  2.43573499 ..., -0.07783184  3.86455822
   0.59891164]
 [-3.19206285  1.60950541  2.43551397 ..., -0.0778209   3.86364079
   0.59915668]
 [-3.19025779  1.61023259  2.43490982 ..., -0.07713539  3.86558938
   0.60293746]
 ...,
 [-3.19059706  1.60808182  2.43651724 ..., -0.07720817  3.86182404
   0.59896904]
 [-3.18918419  1.60753644  2.43705821 ..., -0.07681525  3.86078882
   0.5989511 ]
 [-3.19046521  1.60866368  2.43603444 ..., -0.07752585  3.86211467
   0.59931022]]
After layer decoder_rnn_l0_t0_h2h_output (20, 2048) <class 'numpy.float32'> [[-0.32162896  0.47248992  1.84337294 ...,  0.70577347  1.29712796
   0.17568934]
 [-0.32220781  0.47248647  1.84329557 ...,  0.70493948  1.29589379
   0.17511128]
 [-0.32558075  0.47997111  1.83836043 ...,  0.70270032  1.30449927
   0.17079893]
 ...,
 [-0.32348895  0.47646233  1.84378016 ...,  0.70413828  1.29805148
   0.17177022]
 [-0.32461485  0.48038709  1.8426528  ...,  0.7024231   1.30104423
   0.16853167]
 [-0.32390863  0.47676307  1.84235072 ...,  0.7027747   1.2985388
   0.17158838]]
After layer _plus1057_0 (20, 2048) <class 'numpy.float32'> [[-3.51396155  2.08233786  4.27910805 ...,  0.62794161  5.16168594
   0.77460098]
 [-3.51427078  2.08199191  4.27880955 ...,  0.62711859  5.15953445
   0.77426797]
 [-3.51583862  2.09020376  4.27327013 ...,  0.62556493  5.17008877
   0.77373636]
 ...,
 [-3.51408601  2.08454418  4.28029728 ...,  0.62693012  5.15987539
   0.77073926]
 [-3.51379895  2.08792353  4.27971077 ...,  0.62560785  5.16183281
   0.76748276]
 [-3.51437378  2.08542681  4.27838516 ...,  0.62524885  5.16065359
   0.77089858]]
After layer decoder_rnn_l0_t0_slice_output0 (20, 512) <class 'numpy.float32'> [[-3.51396155  2.08233786  4.27910805 ...,  1.74315965  4.60484028
   2.7832284 ]
 [-3.51427078  2.08199191  4.27880955 ...,  1.74227762  4.60714293
   2.78210783]
 [-3.51583862  2.09020376  4.27327013 ...,  1.74860168  4.59699392
   2.78238773]
 ...,
 [-3.51408601  2.08454418  4.28029728 ...,  1.73962557  4.60485506
   2.78051162]
 [-3.51379895  2.08792353  4.27971077 ...,  1.73872924  4.60232687
   2.77868867]
 [-3.51437378  2.08542681  4.27838516 ...,  1.74080706  4.60478687
   2.78031039]]
After layer decoder_rnn_l0_t0_slice_output1 (20, 512) <class 'numpy.float32'> [[-1.85913789  2.31733966  2.42854548 ...,  3.16480207 -0.70359945
   1.97901034]
 [-1.85875547  2.31767702  2.42855835 ...,  3.16408968 -0.70176637
   1.97875214]
 [-1.86622691  2.3127346   2.43422174 ...,  3.16086245 -0.70988965
   1.97569823]
 ...,
 [-1.86068726  2.31826591  2.42992306 ...,  3.1612196  -0.6991688
   1.9774642 ]
 [-1.8631494   2.31803322  2.43041563 ...,  3.15817595 -0.69949627
   1.97589731]
 [-1.86153245  2.31769204  2.42896271 ...,  3.16063499 -0.70121801
   1.97684979]]
After layer decoder_rnn_l0_t0_slice_output2 (20, 512) <class 'numpy.float32'> [[-2.81537533 -3.08313394  2.84671545 ...,  4.2633357  -0.08020371
   2.16315389]
 [-2.81487751 -3.08326364  2.84583211 ...,  4.26251221 -0.08144793
   2.1622076 ]
 [-2.81974363 -3.08619881  2.86035347 ...,  4.25670576 -0.08361971
   2.16270399]
 ...,
 [-2.81389904 -3.0856185   2.84829092 ...,  4.25733328 -0.08605969
   2.16102839]
 [-2.8132081  -3.08731031  2.85014296 ...,  4.25291729 -0.08974242
   2.16038704]
 [-2.81372595 -3.08475399  2.84751558 ...,  4.25769854 -0.08552715
   2.16142273]]
After layer decoder_rnn_l0_t0_slice_output3 (20, 512) <class 'numpy.float32'> [[-3.27330422  2.436167   -1.40320098 ...,  0.62794161  5.16168594
   0.77460098]
 [-3.27404451  2.43692064 -1.40283442 ...,  0.62711859  5.15953445
   0.77426797]
 [-3.26994085  2.44842243 -1.41150832 ...,  0.62556493  5.17008877
   0.77373636]
 ...,
 [-3.2745738   2.43701673 -1.40574861 ...,  0.62693012  5.15987539
   0.77073926]
 [-3.27470684  2.43863845 -1.40926433 ...,  0.62560785  5.16183281
   0.76748276]
 [-3.27420688  2.43899608 -1.40623641 ...,  0.62524885  5.16065359
   0.77089858]]
After layer decoder_rnn_l0_t0_o_output (20, 512) <class 'numpy.float32'> [[ 0.03649845  0.91954398  0.19730864 ...,  0.65202254  0.9943006
   0.6845153 ]
 [ 0.03647243  0.91959971  0.19736671 ...,  0.6518358   0.99428844
   0.68444347]
 [ 0.03661691  0.92044598  0.19599627 ...,  0.65148318  0.99434811
   0.68432862]
 ...,
 [ 0.03645383  0.9196068   0.19690548 ...,  0.65179306  0.99429035
   0.68368077]
 [ 0.03644916  0.91972667  0.19635011 ...,  0.65149289  0.99430144
   0.68297613]
 [ 0.03646673  0.91975296  0.19682835 ...,  0.65141135  0.99429482
   0.68371528]]
After layer decoder_rnn_l0_t0_f_output (20, 512) <class 'numpy.float32'> [[ 0.13480356  0.91030294  0.91897833 ...,  0.95948803  0.33101466
   0.87857556]
 [ 0.13484818  0.91033047  0.91897923 ...,  0.95946038  0.33142069
   0.87854809]
 [ 0.1339789   0.90992624  0.91939998 ...,  0.95933461  0.32962322
   0.87822181]
 ...,
 [ 0.13462296  0.91037858  0.91908085 ...,  0.95934856  0.33199656
   0.87841064]
 [ 0.1343364   0.9103595   0.91911739 ...,  0.95922965  0.33192393
   0.87824315]
 [ 0.13452452  0.91033179  0.91900933 ...,  0.95932573  0.33154222
   0.87834495]]
After layer _mul2114_0 (20, 512) <class 'numpy.float32'> [[ -4.47908649e-03  -5.50480318e+00   6.35362911e+00 ...,   7.14132786e+00
   -3.73658091e-02   4.77505302e+00]
 [ -4.47965181e-03  -5.50593710e+00   6.32401085e+00 ...,   7.05822372e+00
   -3.87422256e-02   4.73214340e+00]
 [ -4.43851808e-03  -5.47093868e+00   6.35193062e+00 ...,   6.94154501e+00
   -3.91647071e-02   4.65562439e+00]
 ...,
 [ -4.47073160e-03  -5.50203991e+00   6.29466057e+00 ...,   7.01232958e+00
   -4.28799242e-02   4.67479229e+00]
 [ -4.45941463e-03  -5.50145912e+00   6.29478312e+00 ...,   7.00081921e+00
   -4.57489043e-02   4.66259480e+00]
 [ -4.46498021e-03  -5.50715256e+00   6.31463671e+00 ...,   7.00391626e+00
   -4.21758294e-02   4.69444323e+00]]
After layer decoder_rnn_l0_t0_i_output (20, 512) <class 'numpy.float32'> [[ 0.02891758  0.88917464  0.98633438 ...,  0.85108793  0.99009573
   0.9417628 ]
 [ 0.0289089   0.88914055  0.98633027 ...,  0.85097617  0.99011832
   0.94170129]
 [ 0.02886492  0.88994735  0.98625541 ...,  0.85177636  0.99001849
   0.94171661]
 ...,
 [ 0.02891409  0.88939184  0.98635036 ...,  0.85063952  0.99009585
   0.94161355]
 [ 0.02892215  0.88972384  0.98634249 ...,  0.85052562  0.99007112
   0.94151324]
 [ 0.02890601  0.88947862  0.98632461 ...,  0.85078955  0.99009526
   0.94160253]]
After layer decoder_rnn_l0_t0_c_output (20, 512) <class 'numpy.float32'> [[-0.99285388 -0.99581069  0.99328655 ...,  0.99960387 -0.08003218
   0.9739123 ]
 [-0.99284679 -0.99581176  0.99327475 ...,  0.99960321 -0.0812683
   0.97386348]
 [-0.99291581 -0.99583626  0.99346662 ...,  0.99959856 -0.08342537
   0.97388911]
 ...,
 [-0.99283278 -0.99583143  0.99330765 ...,  0.99959904 -0.08584786
   0.97380257]
 [-0.99282295 -0.99584544  0.99333227 ...,  0.99959552 -0.08950227
   0.97376943]
 [-0.99283034 -0.99582422  0.99329728 ...,  0.99959934 -0.08531922
   0.97382295]]
After layer _mul2115_0 (20, 512) <class 'numpy.float32'> [[-0.02871094 -0.88544959  0.97971267 ...,  0.8507508  -0.07923952
   0.91719437]
 [-0.02870211 -0.88541663  0.97969693 ...,  0.85063851 -0.08046523
   0.91708851]
 [-0.02866043 -0.88624185  0.97981185 ...,  0.85143441 -0.08259265
   0.91712755]
 ...,
 [-0.02870685 -0.88568437  0.97974938 ...,  0.85029846 -0.08499761
   0.9169457 ]
 [-0.02871457 -0.8860274   0.97976583 ...,  0.85018158 -0.08861361
   0.91681683]
 [-0.02869876 -0.88576436  0.97971356 ...,  0.85044867 -0.08447415
   0.91695416]]
After layer decoder_rnn_l0_t0_state_0 (20, 512) <class 'numpy.float32'> [[-0.03319002 -6.39025259  7.3333416  ...,  7.99207878 -0.11660533
   5.69224739]
 [-0.03318176 -6.39135361  7.3037076  ...,  7.90886211 -0.11920746
   5.64923191]
 [-0.03309895 -6.3571806   7.33174229 ...,  7.79297924 -0.12175736
   5.572752  ]
 ...,
 [-0.03317758 -6.3877244   7.27440977 ...,  7.86262798 -0.12787753
   5.59173775]
 [-0.03317399 -6.38748646  7.27454901 ...,  7.85100079 -0.13436252
   5.57941151]
 [-0.03316374 -6.39291668  7.29435015 ...,  7.85436487 -0.12664998
   5.61139727]]
After layer activation1057_output (20, 512) <class 'numpy.float32'> [[-0.03317784 -0.9999944   0.99999917 ...,  0.99999976 -0.11607971
   0.99997723]
 [-0.03316959 -0.9999944   0.99999911 ...,  0.9999997  -0.11864599
   0.9999752 ]
 [-0.03308687 -0.99999398  0.99999917 ...,  0.99999964 -0.12115923
   0.99997109]
 ...,
 [-0.03316542 -0.99999434  0.99999905 ...,  0.9999997  -0.12718502
   0.99997222]
 [-0.03316183 -0.99999434  0.99999905 ...,  0.9999997  -0.13355976
   0.99997151]
 [-0.03315159 -0.9999944   0.99999911 ...,  0.9999997  -0.12597713
   0.9999733 ]]
After layer decoder_rnn_l0_t0_out_0 (20, 512) <class 'numpy.float32'> [[-0.00121094 -0.91953886  0.19730848 ...,  0.65202236 -0.11541813
   0.68449974]
 [-0.00120978 -0.91959459  0.19736654 ...,  0.65183562 -0.11796834
   0.68442649]
 [-0.00121154 -0.92044044  0.19599611 ...,  0.65148294 -0.12047446
   0.68430883]
 ...,
 [-0.00120901 -0.91960162  0.19690529 ...,  0.65179288 -0.12645884
   0.68366176]
 [-0.00120872 -0.91972148  0.19634992 ...,  0.65149271 -0.13279867
   0.6829567 ]
 [-0.00120893 -0.91974783  0.19682817 ...,  0.65141118 -0.1252584
   0.68369704]]
After layer expand_dims1066_0 (20, 512, 1) <class 'numpy.float32'> [[[-0.00121094]
  [-0.91953886]
  [ 0.19730848]
  ...,
  [ 0.65202236]
  [-0.11541813]
  [ 0.68449974]]

 [[-0.00120978]
  [-0.91959459]
  [ 0.19736654]
  ...,
  [ 0.65183562]
  [-0.11796834]
  [ 0.68442649]]

 [[-0.00121154]
  [-0.92044044]
  [ 0.19599611]
  ...,
  [ 0.65148294]
  [-0.12047446]
  [ 0.68430883]]

 ...,
 [[-0.00120901]
  [-0.91960162]
  [ 0.19690529]
  ...,
  [ 0.65179288]
  [-0.12645884]
  [ 0.68366176]]

 [[-0.00120872]
  [-0.91972148]
  [ 0.19634992]
  ...,
  [ 0.65149271]
  [-0.13279867]
  [ 0.6829567 ]]

 [[-0.00120893]
  [-0.91974783]
  [ 0.19682817]
  ...,
  [ 0.65141118]
  [-0.1252584 ]
  [ 0.68369704]]]
After layer att_batch_dot_0 (20, 10, 1) <class 'numpy.float32'> [[[ 0.53014374]
  [ 0.92242712]
  [ 1.62705505]
  [ 2.5906899 ]
  [ 2.50889659]
  [ 0.26568252]
  [-2.96745086]
  [-5.80540276]
  [-7.93951273]
  [-9.53815651]]

 [[ 0.53043729]
  [ 0.9220587 ]
  [ 1.62769854]
  [ 2.59224391]
  [ 2.5114615 ]
  [ 0.26888657]
  [-2.96394181]
  [-5.80150318]
  [-7.93496847]
  [-9.53277016]]

 [[ 0.52864546]
  [ 0.9194451 ]
  [ 1.61668229]
  [ 2.56889701]
  [ 2.4685626 ]
  [ 0.20172837]
  [-3.05401564]
  [-5.91052055]
  [-8.05823994]
  [-9.66557026]]

 [[ 0.53054786]
  [ 0.92289984]
  [ 1.62935555]
  [ 2.5955255 ]
  [ 2.51507068]
  [ 0.27000704]
  [-2.96699667]
  [-5.80884886]
  [-7.94582367]
  [-9.54603863]]

 [[ 0.52921259]
  [ 0.91945225]
  [ 1.61962688]
  [ 2.5738554 ]
  [ 2.4689033 ]
  [ 0.187492  ]
  [-3.08739257]
  [-5.96171188]
  [-8.12295628]
  [-9.73909473]]

 [[ 0.52991152]
  [ 0.92234063]
  [ 1.62737966]
  [ 2.59117961]
  [ 2.50895047]
  [ 0.26430708]
  [-2.97074604]
  [-5.81056452]
  [-7.94619036]
  [-9.54596043]]

 [[ 0.52811337]
  [ 0.92026323]
  [ 1.61799443]
  [ 2.57041264]
  [ 2.46378183]
  [ 0.1816067 ]
  [-3.09321904]
  [-5.96751833]
  [-8.12933922]
  [-9.74668694]]

 [[ 0.5301832 ]
  [ 0.92192894]
  [ 1.62632561]
  [ 2.58922005]
  [ 2.50724626]
  [ 0.26504976]
  [-2.96629119]
  [-5.8022418 ]
  [-7.93452787]
  [-9.5316658 ]]

 [[ 0.53159636]
  [ 0.91966265]
  [ 1.62420321]
  [ 2.58395648]
  [ 2.48901105]
  [ 0.22122878]
  [-3.04020643]
  [-5.90264416]
  [-8.05385685]
  [-9.66178608]]

 [[ 0.52532452]
  [ 0.91292369]
  [ 1.59949124]
  [ 2.53289843]
  [ 2.39990878]
  [ 0.09056662]
  [-3.20619607]
  [-6.09593916]
  [-8.26746178]
  [-9.88984394]]

 [[ 0.52896571]
  [ 0.91841978]
  [ 1.61521256]
  [ 2.5658536 ]
  [ 2.46547437]
  [ 0.20172484]
  [-3.04900622]
  [-5.9000411 ]
  [-8.04282665]
  [-9.64617157]]

 [[ 0.52516872]
  [ 0.91072714]
  [ 1.59950352]
  [ 2.53440404]
  [ 2.39940023]
  [ 0.08297274]
  [-3.22315812]
  [-6.12102079]
  [-8.29781151]
  [-9.92261314]]

 [[ 0.52882916]
  [ 0.9196471 ]
  [ 1.61878467]
  [ 2.57195401]
  [ 2.46686554]
  [ 0.18727051]
  [-3.0846405 ]
  [-5.95605946]
  [-8.11516762]
  [-9.73005104]]

 [[ 0.52314234]
  [ 0.90428668]
  [ 1.5904274 ]
  [ 2.51946068]
  [ 2.37456942]
  [ 0.04520481]
  [-3.27389336]
  [-6.18161297]
  [-8.36468315]
  [-9.99284267]]

 [[ 0.53040707]
  [ 0.9222337 ]
  [ 1.62778342]
  [ 2.59233212]
  [ 2.5115056 ]
  [ 0.2688219 ]
  [-2.96416712]
  [-5.80192375]
  [-7.93558836]
  [-9.53353977]]

 [[ 0.53051054]
  [ 0.92258865]
  [ 1.62839758]
  [ 2.59357047]
  [ 2.5132935 ]
  [ 0.2706165 ]
  [-2.9628427 ]
  [-5.80128431]
  [-7.93560171]
  [-9.53409767]]

 [[ 0.53057641]
  [ 0.92248309]
  [ 1.62846875]
  [ 2.59369469]
  [ 2.51268601]
  [ 0.26818085]
  [-2.96748376]
  [-5.80776739]
  [-7.94332981]
  [-9.54244137]]

 [[ 0.53035104]
  [ 0.92224556]
  [ 1.62850225]
  [ 2.59371471]
  [ 2.5110991 ]
  [ 0.26279649]
  [-2.9774437 ]
  [-5.82191515]
  [-7.96089458]
  [-9.56275177]]

 [[ 0.53009266]
  [ 0.92270011]
  [ 1.62905073]
  [ 2.59475636]
  [ 2.51092625]
  [ 0.2585566 ]
  [-2.98715377]
  [-5.8369627 ]
  [-7.98026752]
  [-9.58514977]]

 [[ 0.53045678]
  [ 0.92245591]
  [ 1.62837076]
  [ 2.59356928]
  [ 2.51154113]
  [ 0.26453906]
  [-2.97422695]
  [-5.81742001]
  [-7.9552803 ]
  [-9.55605888]]]
After layer swapaxes35_output (10, 20, 1) <class 'numpy.float32'> [[[ 0.53014374]
  [ 0.53043729]
  [ 0.52864546]
  [ 0.53054786]
  [ 0.52921259]
  [ 0.52991152]
  [ 0.52811337]
  [ 0.5301832 ]
  [ 0.53159636]
  [ 0.52532452]
  [ 0.52896571]
  [ 0.52516872]
  [ 0.52882916]
  [ 0.52314234]
  [ 0.53040707]
  [ 0.53051054]
  [ 0.53057641]
  [ 0.53035104]
  [ 0.53009266]
  [ 0.53045678]]

 [[ 0.92242712]
  [ 0.9220587 ]
  [ 0.9194451 ]
  [ 0.92289984]
  [ 0.91945225]
  [ 0.92234063]
  [ 0.92026323]
  [ 0.92192894]
  [ 0.91966265]
  [ 0.91292369]
  [ 0.91841978]
  [ 0.91072714]
  [ 0.9196471 ]
  [ 0.90428668]
  [ 0.9222337 ]
  [ 0.92258865]
  [ 0.92248309]
  [ 0.92224556]
  [ 0.92270011]
  [ 0.92245591]]

 [[ 1.62705505]
  [ 1.62769854]
  [ 1.61668229]
  [ 1.62935555]
  [ 1.61962688]
  [ 1.62737966]
  [ 1.61799443]
  [ 1.62632561]
  [ 1.62420321]
  [ 1.59949124]
  [ 1.61521256]
  [ 1.59950352]
  [ 1.61878467]
  [ 1.5904274 ]
  [ 1.62778342]
  [ 1.62839758]
  [ 1.62846875]
  [ 1.62850225]
  [ 1.62905073]
  [ 1.62837076]]

 [[ 2.5906899 ]
  [ 2.59224391]
  [ 2.56889701]
  [ 2.5955255 ]
  [ 2.5738554 ]
  [ 2.59117961]
  [ 2.57041264]
  [ 2.58922005]
  [ 2.58395648]
  [ 2.53289843]
  [ 2.5658536 ]
  [ 2.53440404]
  [ 2.57195401]
  [ 2.51946068]
  [ 2.59233212]
  [ 2.59357047]
  [ 2.59369469]
  [ 2.59371471]
  [ 2.59475636]
  [ 2.59356928]]

 [[ 2.50889659]
  [ 2.5114615 ]
  [ 2.4685626 ]
  [ 2.51507068]
  [ 2.4689033 ]
  [ 2.50895047]
  [ 2.46378183]
  [ 2.50724626]
  [ 2.48901105]
  [ 2.39990878]
  [ 2.46547437]
  [ 2.39940023]
  [ 2.46686554]
  [ 2.37456942]
  [ 2.5115056 ]
  [ 2.5132935 ]
  [ 2.51268601]
  [ 2.5110991 ]
  [ 2.51092625]
  [ 2.51154113]]

 [[ 0.26568252]
  [ 0.26888657]
  [ 0.20172837]
  [ 0.27000704]
  [ 0.187492  ]
  [ 0.26430708]
  [ 0.1816067 ]
  [ 0.26504976]
  [ 0.22122878]
  [ 0.09056662]
  [ 0.20172484]
  [ 0.08297274]
  [ 0.18727051]
  [ 0.04520481]
  [ 0.2688219 ]
  [ 0.2706165 ]
  [ 0.26818085]
  [ 0.26279649]
  [ 0.2585566 ]
  [ 0.26453906]]

 [[-2.96745086]
  [-2.96394181]
  [-3.05401564]
  [-2.96699667]
  [-3.08739257]
  [-2.97074604]
  [-3.09321904]
  [-2.96629119]
  [-3.04020643]
  [-3.20619607]
  [-3.04900622]
  [-3.22315812]
  [-3.0846405 ]
  [-3.27389336]
  [-2.96416712]
  [-2.9628427 ]
  [-2.96748376]
  [-2.9774437 ]
  [-2.98715377]
  [-2.97422695]]

 [[-5.80540276]
  [-5.80150318]
  [-5.91052055]
  [-5.80884886]
  [-5.96171188]
  [-5.81056452]
  [-5.96751833]
  [-5.8022418 ]
  [-5.90264416]
  [-6.09593916]
  [-5.9000411 ]
  [-6.12102079]
  [-5.95605946]
  [-6.18161297]
  [-5.80192375]
  [-5.80128431]
  [-5.80776739]
  [-5.82191515]
  [-5.8369627 ]
  [-5.81742001]]

 [[-7.93951273]
  [-7.93496847]
  [-8.05823994]
  [-7.94582367]
  [-8.12295628]
  [-7.94619036]
  [-8.12933922]
  [-7.93452787]
  [-8.05385685]
  [-8.26746178]
  [-8.04282665]
  [-8.29781151]
  [-8.11516762]
  [-8.36468315]
  [-7.93558836]
  [-7.93560171]
  [-7.94332981]
  [-7.96089458]
  [-7.98026752]
  [-7.9552803 ]]

 [[-9.53815651]
  [-9.53277016]
  [-9.66557026]
  [-9.54603863]
  [-9.73909473]
  [-9.54596043]
  [-9.74668694]
  [-9.5316658 ]
  [-9.66178608]
  [-9.88984394]
  [-9.64617157]
  [-9.92261314]
  [-9.73005104]
  [-9.99284267]
  [-9.53353977]
  [-9.53409767]
  [-9.54244137]
  [-9.56275177]
  [-9.58514977]
  [-9.55605888]]]
After layer sequencemask13_output (10, 20, 1) <class 'numpy.float32'> [[[  5.30143738e-01]
  [  5.30437291e-01]
  [  5.28645456e-01]
  [  5.30547857e-01]
  [  5.29212594e-01]
  [  5.29911518e-01]
  [  5.28113365e-01]
  [  5.30183196e-01]
  [  5.31596363e-01]
  [  5.25324523e-01]
  [  5.28965712e-01]
  [  5.25168717e-01]
  [  5.28829157e-01]
  [  5.23142338e-01]
  [  5.30407071e-01]
  [  5.30510545e-01]
  [  5.30576408e-01]
  [  5.30351043e-01]
  [  5.30092657e-01]
  [  5.30456781e-01]]

 [[  9.22427118e-01]
  [  9.22058702e-01]
  [  9.19445097e-01]
  [  9.22899842e-01]
  [  9.19452250e-01]
  [  9.22340631e-01]
  [  9.20263231e-01]
  [  9.21928942e-01]
  [  9.19662654e-01]
  [  9.12923694e-01]
  [  9.18419778e-01]
  [  9.10727143e-01]
  [  9.19647098e-01]
  [  9.04286683e-01]
  [  9.22233701e-01]
  [  9.22588646e-01]
  [  9.22483087e-01]
  [  9.22245562e-01]
  [  9.22700107e-01]
  [  9.22455907e-01]]

 [[ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]]
After layer swapaxes36_output (20, 10, 1) <class 'numpy.float32'> [[[  5.30143738e-01]
  [  9.22427118e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  5.30437291e-01]
  [  9.22058702e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  5.28645456e-01]
  [  9.19445097e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  5.30547857e-01]
  [  9.22899842e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  5.29212594e-01]
  [  9.19452250e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  5.29911518e-01]
  [  9.22340631e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  5.28113365e-01]
  [  9.20263231e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  5.30183196e-01]
  [  9.21928942e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  5.31596363e-01]
  [  9.19662654e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  5.25324523e-01]
  [  9.12923694e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  5.28965712e-01]
  [  9.18419778e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  5.25168717e-01]
  [  9.10727143e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  5.28829157e-01]
  [  9.19647098e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  5.23142338e-01]
  [  9.04286683e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  5.30407071e-01]
  [  9.22233701e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  5.30510545e-01]
  [  9.22588646e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  5.30576408e-01]
  [  9.22483087e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  5.30351043e-01]
  [  9.22245562e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  5.30092657e-01]
  [  9.22700107e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  5.30456781e-01]
  [  9.22455907e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]]
After layer attention_softmax_0 (20, 10, 1) <class 'numpy.float32'> [[[ 0.40316775]
  [ 0.59683228]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40332702]
  [ 0.59667295]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40352482]
  [ 0.59647518]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40315124]
  [ 0.59684879]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40365958]
  [ 0.59634036]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40313268]
  [ 0.59686732]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40319985]
  [ 0.59680009]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40329716]
  [ 0.59670287]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40418285]
  [ 0.59581709]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40429538]
  [ 0.59570467]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40384871]
  [ 0.59615129]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40478697]
  [ 0.59521306]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40352041]
  [ 0.59647959]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40585095]
  [ 0.59414911]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40327767]
  [ 0.5967223 ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40321714]
  [ 0.59678286]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40325838]
  [ 0.59674162]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.4032613 ]
  [ 0.5967387 ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40308976]
  [ 0.59691024]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40323615]
  [ 0.59676385]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]]
After layer batch_dot13_0 (20, 512, 1) <class 'numpy.float32'> [[[ 0.01785508]
  [ 0.0394427 ]
  [-0.03343245]
  ...,
  [-0.01095652]
  [ 0.00999344]
  [-0.02459794]]

 [[ 0.01785124]
  [ 0.03943826]
  [-0.03342528]
  ...,
  [-0.01095564]
  [ 0.00999326]
  [-0.02460076]]

 [[ 0.01784646]
  [ 0.03943275]
  [-0.03341637]
  ...,
  [-0.01095454]
  [ 0.00999303]
  [-0.02460426]]

 ...,
 [[ 0.01785282]
  [ 0.03944009]
  [-0.03342823]
  ...,
  [-0.010956  ]
  [ 0.00999333]
  [-0.0245996 ]]

 [[ 0.01785696]
  [ 0.03944487]
  [-0.03343596]
  ...,
  [-0.01095695]
  [ 0.00999353]
  [-0.02459657]]

 [[ 0.01785343]
  [ 0.03944079]
  [-0.03342937]
  ...,
  [-0.01095614]
  [ 0.00999336]
  [-0.02459915]]]
After layer reshape26_0 (20, 512) <class 'numpy.float32'> [[ 0.01785508  0.0394427  -0.03343245 ..., -0.01095652  0.00999344
  -0.02459794]
 [ 0.01785124  0.03943826 -0.03342528 ..., -0.01095564  0.00999326
  -0.02460076]
 [ 0.01784646  0.03943275 -0.03341637 ..., -0.01095454  0.00999303
  -0.02460426]
 ...,
 [ 0.01785282  0.03944009 -0.03342823 ..., -0.010956    0.00999333
  -0.0245996 ]
 [ 0.01785696  0.03944487 -0.03343596 ..., -0.01095695  0.00999353
  -0.02459657]
 [ 0.01785343  0.03944079 -0.03342937 ..., -0.01095614  0.00999336
  -0.02459915]]
After layer decoder_rnn_hidden_concat_t0_output (20, 1024) <class 'numpy.float32'> [[-0.00121094 -0.91953886  0.19730848 ..., -0.01095652  0.00999344
  -0.02459794]
 [-0.00120978 -0.91959459  0.19736654 ..., -0.01095564  0.00999326
  -0.02460076]
 [-0.00121154 -0.92044044  0.19599611 ..., -0.01095454  0.00999303
  -0.02460426]
 ...,
 [-0.00120901 -0.91960162  0.19690529 ..., -0.010956    0.00999333
  -0.0245996 ]
 [-0.00120872 -0.91972148  0.19634992 ..., -0.01095695  0.00999353
  -0.02459657]
 [-0.00120893 -0.91974783  0.19682817 ..., -0.01095614  0.00999336
  -0.02459915]]
After layer decoder_rnn_hidden_fc_t0_output (20, 512) <class 'numpy.float32'> [[-1.96488774  0.20809144 -0.81203467 ...,  1.97634566  2.10988426
  -1.5963155 ]
 [-1.96529496  0.20727503 -0.81191564 ...,  1.97652423  2.1109271
  -1.59594941]
 [-1.96056414  0.21121487 -0.8170687  ...,  1.97070467  2.10723329
  -1.59953415]
 ...,
 [-1.96791375  0.21030092 -0.81538296 ...,  1.97764516  2.10989141
  -1.59712899]
 [-1.96882296  0.21273528 -0.81846559 ...,  1.9770782   2.10807204
  -1.59757054]
 [-1.9660939   0.20949057 -0.81492364 ...,  1.97612703  2.10950303
  -1.59624183]]
After layer decoder_rnn_next_hidden_t0_output (20, 512) <class 'numpy.float32'> [[-0.96146107  0.20513898 -0.67071116 ...,  0.96231771  0.97102195
  -0.92111206]
 [-0.96149182  0.20435679 -0.67064559 ...,  0.96233094  0.97108144
  -0.92105657]
 [-0.96113288  0.20812905 -0.67347127 ...,  0.96189833  0.97087014
  -0.92159837]
 ...,
 [-0.96168911  0.20725451 -0.67254907 ...,  0.96241367  0.97102237
  -0.92123526]
 [-0.96175742  0.20958313 -0.67423385 ...,  0.96237183  0.97091824
  -0.92130202]
 [-0.96155214  0.20647883 -0.67229748 ...,  0.96230155  0.97100013
  -0.92110085]]
After layer logits_output (20, 16743) <class 'numpy.float32'> [[-2.00746632 -2.82427478 -2.40663481 ..., -2.09313512 -3.5014658
  -2.58203149]
 [-2.00799227 -2.82389975 -2.40635014 ..., -2.09265804 -3.50105143
  -2.58185887]
 [-2.00477028 -2.8252027  -2.40643454 ..., -2.0956707  -3.49982643
  -2.58298302]
 ...,
 [-2.00787735 -2.8231461  -2.40560484 ..., -2.09245157 -3.49977446
  -2.58287168]
 [-2.00697017 -2.82243443 -2.40528846 ..., -2.09273696 -3.49846983
  -2.58341122]
 [-2.0071907  -2.82318449 -2.40578628 ..., -2.09271359 -3.4995501
  -2.58234978]]
After layer softmax_0 (20, 16743) <class 'numpy.float32'> [[  8.38915071e-07   3.70665759e-07   5.62809134e-07 ...,   7.70038810e-07
    1.88313862e-07   4.72267033e-07]
 [  8.39051722e-07   3.71060054e-07   5.63357275e-07 ...,   7.70936595e-07
    1.88521710e-07   4.72673833e-07]
 [  8.47133094e-07   3.72942822e-07   5.66905726e-07 ...,   7.73524505e-07
    1.89957731e-07   4.75156895e-07]
 ...,
 [  8.42750694e-07   3.72934466e-07   5.66197684e-07 ...,   7.74406942e-07
    1.89572887e-07   4.74222730e-07]
 [  8.47230751e-07   3.74843665e-07   5.68871656e-07 ...,   7.77595403e-07
    1.90656479e-07   4.76054481e-07]
 [  8.43637395e-07   3.73056366e-07   5.66301708e-07 ...,   7.74486409e-07
    1.89684769e-07   4.74643400e-07]]
After layer reshape27_0 (20, 10) <class 'numpy.float32'> [[ 0.40316775  0.59683228  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40332702  0.59667295  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40352482  0.59647518  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40315124  0.59684879  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40365958  0.59634036  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40313268  0.59686732  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40319985  0.59680009  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40329716  0.59670287  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40418285  0.59581709  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40429538  0.59570467  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40384871  0.59615129  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40478697  0.59521306  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40352041  0.59647959  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40585095  0.59414911  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40327767  0.5967223   0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40321714  0.59678286  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40325838  0.59674162  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.4032613   0.5967387   0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40308976  0.59691024  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40323615  0.59676385  0.          0.          0.          0.          0.
   0.          0.          0.        ]]
After layer target_embed_embed_0 (20, 256) <class 'numpy.float32'> [[-0.05505371 -0.0300293  -0.03598022 ...,  0.08459473 -0.05288696
  -0.01667786]
 [-0.05505371 -0.0300293  -0.03598022 ...,  0.08459473 -0.05288696
  -0.01667786]
 [-0.05505371 -0.0300293  -0.03598022 ...,  0.08459473 -0.05288696
  -0.01667786]
 ...,
 [-0.05505371 -0.0300293  -0.03598022 ...,  0.08459473 -0.05288696
  -0.01667786]
 [-0.05505371 -0.0300293  -0.03598022 ...,  0.08459473 -0.05288696
  -0.01667786]
 [-0.05505371 -0.0300293  -0.03598022 ...,  0.08459473 -0.05288696
  -0.01667786]]
After layer decoder_rnn_concat_target_context_t0_output (20, 768) <class 'numpy.float32'> [[-0.05505371 -0.0300293  -0.03598022 ...,  0.96231771  0.97102195
  -0.92111206]
 [-0.05505371 -0.0300293  -0.03598022 ...,  0.96233094  0.97108144
  -0.92105657]
 [-0.05505371 -0.0300293  -0.03598022 ...,  0.96189833  0.97087014
  -0.92159837]
 ...,
 [-0.05505371 -0.0300293  -0.03598022 ...,  0.96241367  0.97102237
  -0.92123526]
 [-0.05505371 -0.0300293  -0.03598022 ...,  0.96237183  0.97091824
  -0.92130202]
 [-0.05505371 -0.0300293  -0.03598022 ...,  0.96230155  0.97100013
  -0.92110085]]
After layer decoder_rnn_l0_t0_i2h_output (20, 2048) <class 'numpy.float32'> [[-3.19345164  1.60884941  2.43705463 ..., -0.07772041  3.8641715
   0.59813261]
 [-3.19333506  1.60863173  2.43691683 ..., -0.07772294  3.86357784
   0.59837455]
 [-3.19180703  1.60903811  2.43658996 ..., -0.07725985  3.86510849
   0.60174382]
 ...,
 [-3.19219995  1.60757673  2.43783092 ..., -0.07715672  3.86238337
   0.59826398]
 [-3.19103694  1.60715008  2.43832111 ..., -0.07676376  3.86167574
   0.59824365]
 [-3.19208336  1.60800397  2.43739438 ..., -0.07740451  3.8625598
   0.59853309]]
After layer decoder_rnn_l0_t0_h2h_output (20, 2048) <class 'numpy.float32'> [[-0.32170162  0.47233421  1.84774804 ...,  0.70765805  1.29680514
   0.17610711]
 [-0.32215559  0.47217521  1.8477571  ...,  0.70709574  1.29573071
   0.17572749]
 [-0.32495677  0.47918621  1.84373939 ...,  0.70542943  1.30348372
   0.17149369]
 ...,
 [-0.32308236  0.47546282  1.84796393 ...,  0.70659006  1.29774547
   0.17290869]
 [-0.32384229  0.47877207  1.84696138 ...,  0.70532918  1.30046546
   0.17017193]
 [-0.32338199  0.47566175  1.84689438 ...,  0.70555109  1.29809904
   0.17280057]]
After layer _plus1058_0 (20, 2048) <class 'numpy.float32'> [[-3.51515317  2.08118367  4.28480244 ...,  0.62993765  5.16097641
   0.77423972]
 [-3.51549053  2.08080697  4.28467369 ...,  0.62937278  5.15930843
   0.77410203]
 [-3.51676369  2.08822441  4.28032923 ...,  0.6281696   5.16859245
   0.77323753]
 ...,
 [-3.51528239  2.08303952  4.28579473 ...,  0.62943333  5.16012859
   0.77117264]
 [-3.51487923  2.08592224  4.28528261 ...,  0.62856543  5.16214132
   0.76841557]
 [-3.51546526  2.08366585  4.28428888 ...,  0.62814659  5.16065884
   0.77133369]]
After layer decoder_rnn_l0_t0_slice_output0 (20, 512) <class 'numpy.float32'> [[-3.51515317  2.08118367  4.28480244 ...,  1.74104452  4.60882521
   2.78326511]
 [-3.51549053  2.08080697  4.28467369 ...,  1.7404983   4.61077166
   2.78243637]
 [-3.51676369  2.08822441  4.28032923 ...,  1.74573457  4.60217953
   2.78289247]
 ...,
 [-3.51528239  2.08303952  4.28579473 ...,  1.73874843  4.60860872
   2.78104234]
 [-3.51487923  2.08592224  4.28528261 ...,  1.73818564  4.60617208
   2.77955461]
 [-3.51546526  2.08366585  4.28428888 ...,  1.7396059   4.60855484
   2.78101778]]
After layer decoder_rnn_l0_t0_slice_output1 (20, 512) <class 'numpy.float32'> [[-1.85714746  2.31976342  2.43209863 ...,  3.16573215 -0.69822133
   1.98166823]
 [-1.8568089   2.32002378  2.43214369 ...,  3.16539693 -0.6968652
   1.98161983]
 [-1.86365712  2.31606555  2.43723488 ...,  3.16244316 -0.70270145
   1.97889268]
 ...,
 [-1.85843563  2.32023811  2.43359518 ...,  3.16314793 -0.69526541
   1.98082042]
 [-1.86047328  2.31992507  2.43425179 ...,  3.16062355 -0.6957671
   1.97965801]
 [-1.85905194  2.3198874   2.43272638 ...,  3.16267395 -0.6967603
   1.98025608]]
After layer decoder_rnn_l0_t0_slice_output2 (20, 512) <class 'numpy.float32'> [[-2.81605124 -3.08637643  2.84750605 ...,  4.26329708 -0.08148661
   2.16275215]
 [-2.81574106 -3.08657336  2.8468895  ...,  4.26284885 -0.08224753
   2.16197038]
 [-2.8201251  -3.08897781  2.85995102 ...,  4.25763941 -0.08493063
   2.16214705]
 ...,
 [-2.81541014 -3.08902121  2.8495214  ...,  4.25842333 -0.08573532
   2.16097355]
 [-2.8151567  -3.09071636  2.85142851 ...,  4.25455189 -0.08869624
   2.16050291]
 [-2.81519747 -3.08810925  2.84872103 ...,  4.25878096 -0.0854091
   2.16134453]]
After layer decoder_rnn_l0_t0_slice_output3 (20, 512) <class 'numpy.float32'> [[-3.27422643  2.43246436 -1.40229917 ...,  0.62993765  5.16097641
   0.77423972]
 [-3.27478743  2.43299294 -1.4017812  ...,  0.62937278  5.15930843
   0.77410203]
 [-3.27078199  2.44225168 -1.40910006 ...,  0.6281696   5.16859245
   0.77323753]
 ...,
 [-3.2751267   2.43301821 -1.40429032 ...,  0.62943333  5.16012859
   0.77117264]
 [-3.27513933  2.4342742  -1.40741253 ...,  0.62856543  5.16214132
   0.76841557]
 [-3.27478433  2.43459678 -1.40466595 ...,  0.62814659  5.16065884
   0.77133369]]
After layer decoder_rnn_l0_t0_o_output (20, 512) <class 'numpy.float32'> [[ 0.03646604  0.91926956  0.19745153 ...,  0.65247536  0.99429661
   0.68443733]
 [ 0.03644633  0.91930878  0.19753362 ...,  0.65234721  0.99428719
   0.68440759]
 [ 0.03658725  0.91999298  0.19637604 ...,  0.65207434  0.99433964
   0.68422079]
 ...,
 [ 0.03643442  0.91931069  0.19713619 ...,  0.65236098  0.99429178
   0.68377453]
 [ 0.03643398  0.91940379  0.19664249 ...,  0.6521641   0.99430323
   0.68317807]
 [ 0.03644644  0.91942769  0.19707675 ...,  0.65206909  0.99429482
   0.68380934]]
After layer decoder_rnn_l0_t0_f_output (20, 512) <class 'numpy.float32'> [[ 0.13503589  0.91050065  0.9192425  ...,  0.95952415  0.33220667
   0.87885892]
 [ 0.13507544  0.91052186  0.91924584 ...,  0.95951116  0.33250761
   0.87885374]
 [ 0.13427736  0.91019893  0.9196229  ...,  0.9593963   0.33121356
   0.87856305]
 ...,
 [ 0.1348855   0.91053939  0.91935349 ...,  0.95942372  0.33286276
   0.87876856]
 [ 0.13464789  0.91051388  0.91940218 ...,  0.95932531  0.33275139
   0.8786447 ]
 [ 0.13481359  0.91051078  0.91928905 ...,  0.95940518  0.33253089
   0.87870848]]
After layer _mul2116_0 (20, 512) <class 'numpy.float32'> [[ -4.48184414e-03  -5.81832933e+00   6.74111938e+00 ...,   7.66859245e+00
   -3.87370698e-02   5.00268221e+00]
 [ -4.48204065e-03  -5.81946707e+00   6.71390295e+00 ...,   7.58864164e+00
   -3.96373868e-02   4.96484852e+00]
 [ -4.44443990e-03  -5.78629875e+00   6.74243832e+00 ...,   7.47655535e+00
   -4.03276868e-02   4.89601374e+00]
 ...,
 [ -4.47517540e-03  -5.81627464e+00   6.68775415e+00 ...,   7.54359198e+00
   -4.25656699e-02   4.91384315e+00]
 [ -4.46680794e-03  -5.81589508e+00   6.68823624e+00 ...,   7.53166389e+00
   -4.47093137e-02   4.90232038e+00]
 [ -4.47092298e-03  -5.82081938e+00   6.70561600e+00 ...,   7.53551817e+00
   -4.21150289e-02   4.93078232e+00]]
After layer decoder_rnn_l0_t0_i_output (20, 512) <class 'numpy.float32'> [[ 0.02888414  0.8890608   0.98641092 ...,  0.85081965  0.99013478
   0.94176483]
 [ 0.02887468  0.88902372  0.98640919 ...,  0.85075039  0.99015373
   0.94171935]
 [ 0.028839    0.88975334  0.98635083 ...,  0.85141402  0.99006969
   0.94174427]
 ...,
 [ 0.02888051  0.88924372  0.98642415 ...,  0.850528    0.99013269
   0.9416427 ]
 [ 0.02889182  0.88952738  0.98641729 ...,  0.85045642  0.99010885
   0.94156092]
 [ 0.02887539  0.88930541  0.98640394 ...,  0.85063702  0.99013209
   0.94164145]]
After layer decoder_rnn_l0_t0_c_output (20, 512) <class 'numpy.float32'> [[-0.99286348 -0.99583769  0.99329716 ...,  0.99960381 -0.08130673
   0.97389156]
 [-0.99285907 -0.99583936  0.99328887 ...,  0.99960345 -0.08206257
   0.97385126]
 [-0.99292117 -0.99585927  0.99346137 ...,  0.99959934 -0.08472701
   0.97386038]
 ...,
 [-0.99285436 -0.99585962  0.99332404 ...,  0.99959993 -0.08552587
   0.97379977]
 [-0.99285072 -0.99587363  0.99334937 ...,  0.99959683 -0.08846438
   0.97377539]
 [-0.99285132 -0.99585205  0.99331337 ...,  0.99960023 -0.08520203
   0.97381896]]
After layer _mul2117_0 (20, 512) <class 'numpy.float32'> [[-0.02867801 -0.88536024  0.97979915 ...,  0.85048258 -0.08050463
   0.91717684]
 [-0.02866849 -0.88532484  0.97978926 ...,  0.85041302 -0.08125456
   0.91709459]
 [-0.02863485 -0.88606912  0.97990143 ...,  0.85107291 -0.08388565
   0.91712743]
 ...,
 [-0.02867414 -0.88556194  0.97983885 ...,  0.85018772 -0.08468196
   0.91697145]
 [-0.02868527 -0.88585687  0.97985703 ...,  0.85011357 -0.08758937
   0.91686887]
 [-0.02866897 -0.8856166   0.97980821 ...,  0.85029697 -0.08436126
   0.91698831]]
After layer decoder_rnn_l0_t0_state_0 (20, 512) <class 'numpy.float32'> [[-0.03315985 -6.70368958  7.72091866 ...,  8.51907539 -0.1192417
   5.91985893]
 [-0.03315053 -6.70479202  7.69369221 ...,  8.43905449 -0.12089195
   5.88194323]
 [-0.03307929 -6.67236805  7.72233963 ...,  8.32762814 -0.12421334
   5.81314135]
 ...,
 [-0.03314932 -6.70183659  7.667593   ...,  8.39377975 -0.12724763
   5.83081436]
 [-0.03315207 -6.70175171  7.6680932  ...,  8.38177776 -0.13229868
   5.81918907]
 [-0.03313989 -6.70643616  7.68542433 ...,  8.38581467 -0.12647629
   5.84777069]]
After layer activation1058_output (20, 512) <class 'numpy.float32'> [[-0.0331477  -0.99999702  0.99999958 ...,  0.99999994 -0.11867975
   0.99998558]
 [-0.03313839 -0.99999702  0.99999958 ...,  0.99999988 -0.12030644
   0.99998444]
 [-0.03306723 -0.99999678  0.99999958 ...,  0.99999988 -0.12357844
   0.99998212]
 ...,
 [-0.03313718 -0.99999696  0.99999958 ...,  0.99999988 -0.12656526
   0.99998277]
 [-0.03313993 -0.99999696  0.99999958 ...,  0.99999988 -0.13153218
   0.99998236]
 [-0.03312777 -0.99999702  0.99999958 ...,  0.99999988 -0.1258062
   0.99998331]]
After layer decoder_rnn_l0_t0_out_0 (20, 512) <class 'numpy.float32'> [[-0.00120877 -0.91926682  0.19745144 ...,  0.6524753  -0.11800287
   0.68442744]
 [-0.00120777 -0.91930604  0.19753353 ...,  0.65234715 -0.11961915
   0.68439692]
 [-0.00120984 -0.91999     0.19637597 ...,  0.65207428 -0.12287894
   0.68420857]
 ...,
 [-0.00120733 -0.91930789  0.1971361  ...,  0.65236092 -0.12584279
   0.68376273]
 [-0.00120742 -0.91940099  0.1966424  ...,  0.65216404 -0.13078287
   0.68316603]
 [-0.00120739 -0.91942495  0.19707666 ...,  0.65206903 -0.12508845
   0.68379796]]
After layer expand_dims1067_0 (20, 512, 1) <class 'numpy.float32'> [[[-0.00120877]
  [-0.91926682]
  [ 0.19745144]
  ...,
  [ 0.6524753 ]
  [-0.11800287]
  [ 0.68442744]]

 [[-0.00120777]
  [-0.91930604]
  [ 0.19753353]
  ...,
  [ 0.65234715]
  [-0.11961915]
  [ 0.68439692]]

 [[-0.00120984]
  [-0.91999   ]
  [ 0.19637597]
  ...,
  [ 0.65207428]
  [-0.12287894]
  [ 0.68420857]]

 ...,
 [[-0.00120733]
  [-0.91930789]
  [ 0.1971361 ]
  ...,
  [ 0.65236092]
  [-0.12584279]
  [ 0.68376273]]

 [[-0.00120742]
  [-0.91940099]
  [ 0.1966424 ]
  ...,
  [ 0.65216404]
  [-0.13078287]
  [ 0.68316603]]

 [[-0.00120739]
  [-0.91942495]
  [ 0.19707666]
  ...,
  [ 0.65206903]
  [-0.12508845]
  [ 0.68379796]]]
After layer att_batch_dot_0 (20, 10, 1) <class 'numpy.float32'> [[[ 0.53052908]
  [ 0.9226563 ]
  [ 1.62976122]
  [ 2.59567833]
  [ 2.51507616]
  [ 0.27062517]
  [-2.96497011]
  [-5.80528975]
  [-7.94140816]
  [-9.54190922]]

 [[ 0.53077775]
  [ 0.92238957]
  [ 1.63025463]
  [ 2.59687471]
  [ 2.5171206 ]
  [ 0.27334267]
  [-2.96182108]
  [-5.80166483]
  [-7.93715477]
  [-9.53693199]]

 [[ 0.52927613]
  [ 0.92027521]
  [ 1.62120247]
  [ 2.57780409]
  [ 2.48170257]
  [ 0.21701427]
  [-3.0383234 ]
  [-5.89515352]
  [-8.04362392]
  [-9.65228939]]

 [[ 0.53074163]
  [ 0.9229818 ]
  [ 1.63117945]
  [ 2.59864879]
  [ 2.51851964]
  [ 0.27204296]
  [-2.96709657]
  [-5.8109231 ]
  [-7.94968128]
  [-9.55179214]]

 [[ 0.52974737]
  [ 0.92034817]
  [ 1.62261379]
  [ 2.57946873]
  [ 2.47771811]
  [ 0.19904809]
  [-3.0736835 ]
  [-5.94645309]
  [-8.10707188]
  [-9.72381115]]

 [[ 0.53032029]
  [ 0.92264932]
  [ 1.63005733]
  [ 2.5960753 ]
  [ 2.51499963]
  [ 0.26918423]
  [-2.96820903]
  [-5.81025314]
  [-7.94778204]
  [-9.54937172]]

 [[ 0.52843767]
  [ 0.92058438]
  [ 1.62068486]
  [ 2.57575512]
  [ 2.47202849]
  [ 0.19189203]
  [-3.0816772 ]
  [-5.95525885]
  [-8.11705685]
  [-9.73532486]]

 [[ 0.53064048]
  [ 0.92234975]
  [ 1.62946498]
  [ 2.59509158]
  [ 2.51477742]
  [ 0.27163708]
  [-2.96208954]
  [-5.80043745]
  [-7.93480396]
  [-9.53391647]]

 [[ 0.53229249]
  [ 0.92098784]
  [ 1.62749648]
  [ 2.58973742]
  [ 2.4976716 ]
  [ 0.23213023]
  [-3.02762532]
  [-5.88891697]
  [-8.03982353]
  [-9.64855862]]

 [[ 0.52696019]
  [ 0.91586703]
  [ 1.60809362]
  [ 2.54986048]
  [ 2.42746925]
  [ 0.12777491]
  [-3.16182876]
  [-6.0469017 ]
  [-8.21606731]
  [-9.83823395]]

 [[ 0.52977848]
  [ 0.91973716]
  [ 1.62089992]
  [ 2.57710099]
  [ 2.48222518]
  [ 0.22144571]
  [-3.02860546]
  [-5.880023  ]
  [-8.02372932]
  [-9.62855911]]

 [[ 0.52735883]
  [ 0.91465354]
  [ 1.60854793]
  [ 2.551507  ]
  [ 2.42792225]
  [ 0.12349091]
  [-3.17244506]
  [-6.06300306]
  [-8.2356596 ]
  [-9.85923767]]

 [[ 0.52934742]
  [ 0.92041796]
  [ 1.62206793]
  [ 2.57831168]
  [ 2.47676659]
  [ 0.19989586]
  [-3.07016778]
  [-5.94036388]
  [-8.09907913]
  [-9.71463203]]

 [[ 0.52716446]
  [ 0.91226703]
  [ 1.60682178]
  [ 2.54938936]
  [ 2.42412996]
  [ 0.11678555]
  [-3.18251467]
  [-6.07565022]
  [-8.24948215]
  [-9.8729372 ]]

 [[ 0.53075117]
  [ 0.92253208]
  [ 1.63032889]
  [ 2.59694839]
  [ 2.51712775]
  [ 0.27319703]
  [-2.96216416]
  [-5.80222559]
  [-7.93791962]
  [-9.53784847]]

 [[ 0.53079981]
  [ 0.9227891 ]
  [ 1.63071835]
  [ 2.59772992]
  [ 2.5182128 ]
  [ 0.27414018]
  [-2.96172428]
  [-5.80244112]
  [-7.9387517 ]
  [-9.53918457]]

 [[ 0.53082806]
  [ 0.92269498]
  [ 1.63066506]
  [ 2.59759045]
  [ 2.51733327]
  [ 0.27165645]
  [-2.9660871 ]
  [-5.80838919]
  [-7.94579935]
  [-9.54683113]]

 [[ 0.53057522]
  [ 0.92246354]
  [ 1.63042271]
  [ 2.59702635]
  [ 2.51501012]
  [ 0.26573235]
  [-2.97619081]
  [-5.82228518]
  [-7.9627924 ]
  [-9.56630421]]

 [[ 0.5302434 ]
  [ 0.92276144]
  [ 1.63051057]
  [ 2.5971067 ]
  [ 2.51348877]
  [ 0.26016319]
  [-2.98692465]
  [-5.83798981]
  [-7.98255301]
  [-9.5889864 ]]

 [[ 0.53066975]
  [ 0.92262226]
  [ 1.63037145]
  [ 2.59704447]
  [ 2.51563692]
  [ 0.26757342]
  [-2.97302699]
  [-5.81797409]
  [-7.95751095]
  [-9.56009197]]]
After layer swapaxes37_output (10, 20, 1) <class 'numpy.float32'> [[[ 0.53052908]
  [ 0.53077775]
  [ 0.52927613]
  [ 0.53074163]
  [ 0.52974737]
  [ 0.53032029]
  [ 0.52843767]
  [ 0.53064048]
  [ 0.53229249]
  [ 0.52696019]
  [ 0.52977848]
  [ 0.52735883]
  [ 0.52934742]
  [ 0.52716446]
  [ 0.53075117]
  [ 0.53079981]
  [ 0.53082806]
  [ 0.53057522]
  [ 0.5302434 ]
  [ 0.53066975]]

 [[ 0.9226563 ]
  [ 0.92238957]
  [ 0.92027521]
  [ 0.9229818 ]
  [ 0.92034817]
  [ 0.92264932]
  [ 0.92058438]
  [ 0.92234975]
  [ 0.92098784]
  [ 0.91586703]
  [ 0.91973716]
  [ 0.91465354]
  [ 0.92041796]
  [ 0.91226703]
  [ 0.92253208]
  [ 0.9227891 ]
  [ 0.92269498]
  [ 0.92246354]
  [ 0.92276144]
  [ 0.92262226]]

 [[ 1.62976122]
  [ 1.63025463]
  [ 1.62120247]
  [ 1.63117945]
  [ 1.62261379]
  [ 1.63005733]
  [ 1.62068486]
  [ 1.62946498]
  [ 1.62749648]
  [ 1.60809362]
  [ 1.62089992]
  [ 1.60854793]
  [ 1.62206793]
  [ 1.60682178]
  [ 1.63032889]
  [ 1.63071835]
  [ 1.63066506]
  [ 1.63042271]
  [ 1.63051057]
  [ 1.63037145]]

 [[ 2.59567833]
  [ 2.59687471]
  [ 2.57780409]
  [ 2.59864879]
  [ 2.57946873]
  [ 2.5960753 ]
  [ 2.57575512]
  [ 2.59509158]
  [ 2.58973742]
  [ 2.54986048]
  [ 2.57710099]
  [ 2.551507  ]
  [ 2.57831168]
  [ 2.54938936]
  [ 2.59694839]
  [ 2.59772992]
  [ 2.59759045]
  [ 2.59702635]
  [ 2.5971067 ]
  [ 2.59704447]]

 [[ 2.51507616]
  [ 2.5171206 ]
  [ 2.48170257]
  [ 2.51851964]
  [ 2.47771811]
  [ 2.51499963]
  [ 2.47202849]
  [ 2.51477742]
  [ 2.4976716 ]
  [ 2.42746925]
  [ 2.48222518]
  [ 2.42792225]
  [ 2.47676659]
  [ 2.42412996]
  [ 2.51712775]
  [ 2.5182128 ]
  [ 2.51733327]
  [ 2.51501012]
  [ 2.51348877]
  [ 2.51563692]]

 [[ 0.27062517]
  [ 0.27334267]
  [ 0.21701427]
  [ 0.27204296]
  [ 0.19904809]
  [ 0.26918423]
  [ 0.19189203]
  [ 0.27163708]
  [ 0.23213023]
  [ 0.12777491]
  [ 0.22144571]
  [ 0.12349091]
  [ 0.19989586]
  [ 0.11678555]
  [ 0.27319703]
  [ 0.27414018]
  [ 0.27165645]
  [ 0.26573235]
  [ 0.26016319]
  [ 0.26757342]]

 [[-2.96497011]
  [-2.96182108]
  [-3.0383234 ]
  [-2.96709657]
  [-3.0736835 ]
  [-2.96820903]
  [-3.0816772 ]
  [-2.96208954]
  [-3.02762532]
  [-3.16182876]
  [-3.02860546]
  [-3.17244506]
  [-3.07016778]
  [-3.18251467]
  [-2.96216416]
  [-2.96172428]
  [-2.9660871 ]
  [-2.97619081]
  [-2.98692465]
  [-2.97302699]]

 [[-5.80528975]
  [-5.80166483]
  [-5.89515352]
  [-5.8109231 ]
  [-5.94645309]
  [-5.81025314]
  [-5.95525885]
  [-5.80043745]
  [-5.88891697]
  [-6.0469017 ]
  [-5.880023  ]
  [-6.06300306]
  [-5.94036388]
  [-6.07565022]
  [-5.80222559]
  [-5.80244112]
  [-5.80838919]
  [-5.82228518]
  [-5.83798981]
  [-5.81797409]]

 [[-7.94140816]
  [-7.93715477]
  [-8.04362392]
  [-7.94968128]
  [-8.10707188]
  [-7.94778204]
  [-8.11705685]
  [-7.93480396]
  [-8.03982353]
  [-8.21606731]
  [-8.02372932]
  [-8.2356596 ]
  [-8.09907913]
  [-8.24948215]
  [-7.93791962]
  [-7.9387517 ]
  [-7.94579935]
  [-7.9627924 ]
  [-7.98255301]
  [-7.95751095]]

 [[-9.54190922]
  [-9.53693199]
  [-9.65228939]
  [-9.55179214]
  [-9.72381115]
  [-9.54937172]
  [-9.73532486]
  [-9.53391647]
  [-9.64855862]
  [-9.83823395]
  [-9.62855911]
  [-9.85923767]
  [-9.71463203]
  [-9.8729372 ]
  [-9.53784847]
  [-9.53918457]
  [-9.54683113]
  [-9.56630421]
  [-9.5889864 ]
  [-9.56009197]]]
After layer sequencemask14_output (10, 20, 1) <class 'numpy.float32'> [[[  5.30529082e-01]
  [  5.30777752e-01]
  [  5.29276133e-01]
  [  5.30741632e-01]
  [  5.29747367e-01]
  [  5.30320287e-01]
  [  5.28437674e-01]
  [  5.30640483e-01]
  [  5.32292485e-01]
  [  5.26960194e-01]
  [  5.29778481e-01]
  [  5.27358830e-01]
  [  5.29347420e-01]
  [  5.27164459e-01]
  [  5.30751169e-01]
  [  5.30799806e-01]
  [  5.30828059e-01]
  [  5.30575216e-01]
  [  5.30243397e-01]
  [  5.30669749e-01]]

 [[  9.22656298e-01]
  [  9.22389567e-01]
  [  9.20275211e-01]
  [  9.22981799e-01]
  [  9.20348167e-01]
  [  9.22649324e-01]
  [  9.20584381e-01]
  [  9.22349751e-01]
  [  9.20987844e-01]
  [  9.15867031e-01]
  [  9.19737160e-01]
  [  9.14653540e-01]
  [  9.20417964e-01]
  [  9.12267029e-01]
  [  9.22532082e-01]
  [  9.22789097e-01]
  [  9.22694981e-01]
  [  9.22463536e-01]
  [  9.22761440e-01]
  [  9.22622263e-01]]

 [[ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]]
After layer swapaxes38_output (20, 10, 1) <class 'numpy.float32'> [[[  5.30529082e-01]
  [  9.22656298e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  5.30777752e-01]
  [  9.22389567e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  5.29276133e-01]
  [  9.20275211e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  5.30741632e-01]
  [  9.22981799e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  5.29747367e-01]
  [  9.20348167e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  5.30320287e-01]
  [  9.22649324e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  5.28437674e-01]
  [  9.20584381e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  5.30640483e-01]
  [  9.22349751e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  5.32292485e-01]
  [  9.20987844e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  5.26960194e-01]
  [  9.15867031e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  5.29778481e-01]
  [  9.19737160e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  5.27358830e-01]
  [  9.14653540e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  5.29347420e-01]
  [  9.20417964e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  5.27164459e-01]
  [  9.12267029e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  5.30751169e-01]
  [  9.22532082e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  5.30799806e-01]
  [  9.22789097e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  5.30828059e-01]
  [  9.22694981e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  5.30575216e-01]
  [  9.22463536e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  5.30243397e-01]
  [  9.22761440e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  5.30669749e-01]
  [  9.22622263e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]]
After layer attention_softmax_0 (20, 10, 1) <class 'numpy.float32'> [[[ 0.40320534]
  [ 0.59679466]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40332937]
  [ 0.59667063]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.4034768 ]
  [ 0.59652317]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40317813]
  [ 0.59682184]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40357268]
  [ 0.59642732]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40315679]
  [ 0.59684324]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40320063]
  [ 0.59679937]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40330589]
  [ 0.59669411]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.4040314 ]
  [ 0.5959686 ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40398049]
  [ 0.59601957]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40372723]
  [ 0.59627277]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.4043687 ]
  [ 0.5956313 ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40345958]
  [ 0.59654039]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.4048968 ]
  [ 0.5951032 ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40328866]
  [ 0.59671134]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40323851]
  [ 0.59676147]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40326795]
  [ 0.59673208]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40326282]
  [ 0.59673721]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40311128]
  [ 0.59688866]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40324736]
  [ 0.59675264]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]]
After layer batch_dot14_0 (20, 512, 1) <class 'numpy.float32'> [[[ 0.01785417]
  [ 0.03944165]
  [-0.03343075]
  ...,
  [-0.01095631]
  [ 0.0099934 ]
  [-0.02459861]]

 [[ 0.01785118]
  [ 0.0394382 ]
  [-0.03342517]
  ...,
  [-0.01095562]
  [ 0.00999326]
  [-0.0246008 ]]

 [[ 0.01784762]
  [ 0.03943409]
  [-0.03341853]
  ...,
  [-0.01095481]
  [ 0.00999308]
  [-0.02460341]]

 ...,
 [[ 0.01785279]
  [ 0.03944005]
  [-0.03342817]
  ...,
  [-0.01095599]
  [ 0.00999333]
  [-0.02459962]]

 [[ 0.01785644]
  [ 0.03944427]
  [-0.03343498]
  ...,
  [-0.01095683]
  [ 0.00999351]
  [-0.02459694]]

 [[ 0.01785316]
  [ 0.03944048]
  [-0.03342886]
  ...,
  [-0.01095608]
  [ 0.00999335]
  [-0.02459935]]]
After layer reshape28_0 (20, 512) <class 'numpy.float32'> [[ 0.01785417  0.03944165 -0.03343075 ..., -0.01095631  0.0099934
  -0.02459861]
 [ 0.01785118  0.0394382  -0.03342517 ..., -0.01095562  0.00999326
  -0.0246008 ]
 [ 0.01784762  0.03943409 -0.03341853 ..., -0.01095481  0.00999308
  -0.02460341]
 ...,
 [ 0.01785279  0.03944005 -0.03342817 ..., -0.01095599  0.00999333
  -0.02459962]
 [ 0.01785644  0.03944427 -0.03343498 ..., -0.01095683  0.00999351
  -0.02459694]
 [ 0.01785316  0.03944048 -0.03342886 ..., -0.01095608  0.00999335
  -0.02459935]]
After layer decoder_rnn_hidden_concat_t0_output (20, 1024) <class 'numpy.float32'> [[-0.00120877 -0.91926682  0.19745144 ..., -0.01095631  0.0099934
  -0.02459861]
 [-0.00120777 -0.91930604  0.19753353 ..., -0.01095562  0.00999326
  -0.0246008 ]
 [-0.00120984 -0.91999     0.19637597 ..., -0.01095481  0.00999308
  -0.02460341]
 ...,
 [-0.00120733 -0.91930789  0.1971361  ..., -0.01095599  0.00999333
  -0.02459962]
 [-0.00120742 -0.91940099  0.1966424  ..., -0.01095683  0.00999351
  -0.02459694]
 [-0.00120739 -0.91942495  0.19707666 ..., -0.01095608  0.00999335
  -0.02459935]]
After layer decoder_rnn_hidden_fc_t0_output (20, 512) <class 'numpy.float32'> [[-1.96823311  0.20973319 -0.81372052 ...,  1.97950578  2.11235189
  -1.5983032 ]
 [-1.96844435  0.20893876 -0.81350553 ...,  1.97955585  2.11324954
  -1.59805381]
 [-1.96479201  0.21254689 -0.8183018  ...,  1.97496974  2.10977602
  -1.60112345]
 ...,
 [-1.97053552  0.21159707 -0.81651092 ...,  1.98021591  2.11227107
  -1.59924829]
 [-1.97137952  0.21389546 -0.819269   ...,  1.97972322  2.11064434
  -1.59975505]
 [-1.96912205  0.21094775 -0.81612599 ...,  1.97913027  2.11196876
  -1.59846175]]
After layer decoder_rnn_next_hidden_t0_output (20, 512) <class 'numpy.float32'> [[-0.96171314  0.20671111 -0.67163754 ...,  0.9625507   0.97116256
  -0.92141277]
 [-0.96172899  0.2059505  -0.67151952 ...,  0.96255434  0.97121352
  -0.9213751 ]
 [-0.9614538   0.20940301 -0.67414451 ...,  0.96221584  0.97101575
  -0.92183751]
 ...,
 [-0.96188569  0.20849466 -0.67316639 ...,  0.96260285  0.97115797
  -0.92155534]
 [-0.96194875  0.21069208 -0.67467177 ...,  0.96256667  0.97106534
  -0.92163169]
 [-0.96177983  0.20787348 -0.67295581 ...,  0.96252304  0.97114074
  -0.92143667]]
After layer logits_output (20, 16743) <class 'numpy.float32'> [[-2.0093317  -2.82432365 -2.40657187 ..., -2.09263802 -3.50180435
  -2.58352017]
 [-2.00980997 -2.82411957 -2.40638733 ..., -2.0922823  -3.5015471
  -2.58341789]
 [-2.00699806 -2.82522607 -2.40618134 ..., -2.09483171 -3.50043058
  -2.58457041]
 ...,
 [-2.00970125 -2.82361078 -2.40592766 ..., -2.09226203 -3.50058746
  -2.58437896]
 [-2.00890779 -2.82306671 -2.40574121 ..., -2.09258509 -3.49956012
  -2.58491898]
 [-2.00914264 -2.8236196  -2.4060173  ..., -2.09243488 -3.50040817
  -2.58391833]]
After layer softmax_0 (20, 16743) <class 'numpy.float32'> [[  8.38072424e-07   3.70966802e-07   5.63329593e-07 ...,   7.71084785e-07
    1.88412159e-07   4.71970424e-07]
 [  8.37977780e-07   3.71178260e-07   5.63639446e-07 ...,   7.71641226e-07
    1.88529640e-07   4.72191260e-07]
 [  8.45530963e-07   3.73059152e-07   5.67239397e-07 ...,   7.74433204e-07
    1.89906658e-07   4.74561858e-07]
 ...,
 [  8.41054543e-07   3.72689982e-07   5.65906930e-07 ...,   7.74404953e-07
    1.89382675e-07   4.73417685e-07]
 [  8.44883232e-07   3.74293023e-07   5.68138319e-07 ...,   7.77062780e-07
    1.90289271e-07   4.74939156e-07]
 [  8.41764120e-07   3.72792840e-07   5.66017775e-07 ...,   7.74492378e-07
    1.89470711e-07   4.73771053e-07]]
After layer reshape29_0 (20, 10) <class 'numpy.float32'> [[ 0.40320534  0.59679466  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40332937  0.59667063  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.4034768   0.59652317  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40317813  0.59682184  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40357268  0.59642732  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40315679  0.59684324  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40320063  0.59679937  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40330589  0.59669411  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.4040314   0.5959686   0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40398049  0.59601957  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40372723  0.59627277  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.4043687   0.5956313   0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40345958  0.59654039  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.4048968   0.5951032   0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40328866  0.59671134  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40323851  0.59676147  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40326795  0.59673208  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40326282  0.59673721  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40311128  0.59688866  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40324736  0.59675264  0.          0.          0.          0.          0.
   0.          0.          0.        ]]
After layer target_embed_embed_0 (20, 256) <class 'numpy.float32'> [[-0.05505371 -0.0300293  -0.03598022 ...,  0.08459473 -0.05288696
  -0.01667786]
 [-0.05505371 -0.0300293  -0.03598022 ...,  0.08459473 -0.05288696
  -0.01667786]
 [-0.05505371 -0.0300293  -0.03598022 ...,  0.08459473 -0.05288696
  -0.01667786]
 ...,
 [-0.05505371 -0.0300293  -0.03598022 ...,  0.08459473 -0.05288696
  -0.01667786]
 [-0.05505371 -0.0300293  -0.03598022 ...,  0.08459473 -0.05288696
  -0.01667786]
 [-0.05505371 -0.0300293  -0.03598022 ...,  0.08459473 -0.05288696
  -0.01667786]]
After layer decoder_rnn_concat_target_context_t0_output (20, 768) <class 'numpy.float32'> [[-0.05505371 -0.0300293  -0.03598022 ...,  0.9625507   0.97116256
  -0.92141277]
 [-0.05505371 -0.0300293  -0.03598022 ...,  0.96255434  0.97121352
  -0.9213751 ]
 [-0.05505371 -0.0300293  -0.03598022 ...,  0.96221584  0.97101575
  -0.92183751]
 ...,
 [-0.05505371 -0.0300293  -0.03598022 ...,  0.96260285  0.97115797
  -0.92155534]
 [-0.05505371 -0.0300293  -0.03598022 ...,  0.96256667  0.97106534
  -0.92163169]
 [-0.05505371 -0.0300293  -0.03598022 ...,  0.96252304  0.97114074
  -0.92143667]]
After layer decoder_rnn_l0_t0_i2h_output (20, 2048) <class 'numpy.float32'> [[-3.19437218  1.60817468  2.43822575 ..., -0.07757477  3.86407232
   0.59749895]
 [-3.19434881  1.60804057  2.43813801 ..., -0.07759329  3.86369133
   0.59774143]
 [-3.19296098  1.60817266  2.43798494 ..., -0.07719796  3.86487651
   0.60074639]
 ...,
 [-3.19344282  1.60723662  2.43895531 ..., -0.07708057  3.86290503
   0.59768456]
 [-3.19246459  1.60688734  2.4393971  ..., -0.07669877  3.86241388
   0.59765941]
 [-3.19334054  1.60755122  2.43857098 ..., -0.0772728   3.86300588
   0.59789765]]
After layer decoder_rnn_l0_t0_h2h_output (20, 2048) <class 'numpy.float32'> [[-0.32185203  0.47220555  1.85107982 ...,  0.70928401  1.29644859
   0.1763479 ]
 [-0.32222202  0.47197023  1.85113168 ...,  0.70890313  1.29550326
   0.17611475]
 [-0.32459807  0.47845447  1.8478061  ...,  0.70773542  1.30248511
   0.17198111]
 ...,
 [-0.32291448  0.47477254  1.85114765 ...,  0.70857662  1.29738355
   0.17369619]
 [-0.32342118  0.47761798  1.8502574  ...,  0.70764971  1.29986489
   0.17134303]
 [-0.32312     0.47488284  1.85034585 ...,  0.70779806  1.29763889
   0.17363675]]
After layer _plus1059_0 (20, 2048) <class 'numpy.float32'> [[-3.51622415  2.0803802   4.28930569 ...,  0.63170922  5.16052103
   0.77384686]
 [-3.51657081  2.08001089  4.28926945 ...,  0.63130987  5.15919447
   0.77385616]
 [-3.51755905  2.08662701  4.28579092 ...,  0.63053745  5.16736174
   0.77272749]
 ...,
 [-3.51635742  2.08200908  4.29010296 ...,  0.63149607  5.16028881
   0.77138078]
 [-3.51588583  2.08450532  4.28965473 ...,  0.63095093  5.16227865
   0.76900244]
 [-3.51646042  2.08243418  4.28891659 ...,  0.63052529  5.16064453
   0.77153438]]
After layer decoder_rnn_l0_t0_slice_output0 (20, 512) <class 'numpy.float32'> [[-3.51622415  2.0803802   4.28930569 ...,  1.73973835  4.61203098
   2.78294277]
 [-3.51657081  2.08001089  4.28926945 ...,  1.73941946  4.61367416
   2.78233814]
 [-3.51755905  2.08662701  4.28579092 ...,  1.74380267  4.60620499
   2.78280067]
 ...,
 [-3.51635742  2.08200908  4.29010296 ...,  1.73826087  4.61162186
   2.78111172]
 [-3.51588583  2.08450532  4.28965473 ...,  1.73791003  4.60929108
   2.77987146]
 [-3.51646042  2.08243418  4.28891659 ...,  1.73889458  4.61159515
   2.78119349]]
After layer decoder_rnn_l0_t0_slice_output1 (20, 512) <class 'numpy.float32'> [[-1.8556962   2.32126713  2.43513966 ...,  3.16649818 -0.6944207
   1.98391891]
 [-1.85542762  2.32146764  2.43520713 ...,  3.16640663 -0.69338286
   1.98398781]
 [-1.86169577  2.31829548  2.43974018 ...,  3.16361213 -0.69775832
   1.98148179]
 ...,
 [-1.85686862  2.32143855  2.43666649 ...,  3.1645937  -0.69241625
   1.98346579]
 [-1.85860074  2.32108998  2.43740988 ...,  3.1624651  -0.69299984
   1.98257637]
 [-1.85730755  2.32125044  2.43588305 ...,  3.1642065  -0.69352376
   1.98296964]]
After layer decoder_rnn_l0_t0_slice_output2 (20, 512) <class 'numpy.float32'> [[-2.81648707 -3.08940744  2.84865141 ...,  4.26307201 -0.08215329
   2.16219711]
 [-2.81628871 -3.08961344  2.84823465 ...,  4.26286793 -0.08259481
   2.16154194]
 [-2.82017183 -3.09171581  2.86000562 ...,  4.25797462 -0.0854674
   2.16145754]
 ...,
 [-2.81633687 -3.09201527  2.85090542 ...,  4.25902271 -0.0853208   2.160671  ]
 [-2.81634998 -3.09366512  2.85280442 ...,  4.25558186 -0.0877614
   2.16031361]
 [-2.81611729 -3.09112     2.85011339 ...,  4.25936222 -0.08511418
   2.16102123]]
After layer decoder_rnn_l0_t0_slice_output3 (20, 512) <class 'numpy.float32'> [[-3.2749517   2.4295454  -1.40167856 ...,  0.63170922  5.16052103
   0.77384686]
 [-3.2753737   2.42993259 -1.40108585 ...,  0.63130987  5.15919447
   0.77385616]
 [-3.27159715  2.43754482 -1.40731549 ...,  0.63053745  5.16736174
   0.77272749]
 ...,
 [-3.2755723   2.42993307 -1.40328646 ...,  0.63149607  5.16028881
   0.77138078]
 [-3.27550983  2.43091154 -1.40607738 ...,  0.63095093  5.16227865
   0.76900244]
 [-3.27526736  2.43119144 -1.40357101 ...,  0.63052529  5.16064453
   0.77153438]]
After layer decoder_rnn_l0_t0_o_output (20, 512) <class 'numpy.float32'> [[ 0.03644056  0.91905272  0.19754989 ...,  0.65287691  0.99429399
   0.68435246]
 [ 0.03642575  0.91908157  0.19764386 ...,  0.65278637  0.99428648
   0.68435448]
 [ 0.03655853  0.91964579  0.19665781 ...,  0.65261126  0.99433267
   0.68411058]
 ...,
 [ 0.03641878  0.91908157  0.19729511 ...,  0.65282863  0.99429274
   0.68381947]
 [ 0.03642097  0.91915423  0.19685349 ...,  0.65270501  0.994304
   0.68330503]
 [ 0.03642948  0.91917509  0.19725007 ...,  0.65260851  0.9942947
   0.68385273]]
After layer decoder_rnn_l0_t0_f_output (20, 512) <class 'numpy.float32'> [[ 0.13520549  0.91062307  0.91946787 ...,  0.9595539   0.3330504
   0.8790983 ]
 [ 0.13523689  0.91063941  0.91947293 ...,  0.95955038  0.33328098
   0.87910563]
 [ 0.13450553  0.91038096  0.91980797 ...,  0.95944172  0.33230942
   0.87883902]
 ...,
 [ 0.13506846  0.91063702  0.91958088 ...,  0.95947987  0.33349577
   0.87905008]
 [ 0.13486624  0.91060877  0.91963589 ...,  0.95939702  0.33336607
   0.8789556 ]
 [ 0.13501719  0.91062182  0.91952294 ...,  0.95946485  0.33324963
   0.87899739]]
After layer _mul2118_0 (20, 512) <class 'numpy.float32'> [[ -4.48339432e-03  -6.10453463e+00   7.09913683e+00 ...,   8.17451191e+00
   -3.97134945e-02   5.20413780e+00]
 [ -4.48317407e-03  -6.10564804e+00   7.07414150e+00 ...,   8.09769821e+00
   -4.02909890e-02   5.17084932e+00]
 [ -4.44934750e-03  -6.07439661e+00   7.10306931e+00 ...,   7.98987389e+00
   -4.12772633e-02   5.10881519e+00]
 ...,
 [ -4.47742734e-03  -6.10294056e+00   7.05097198e+00 ...,   8.05366230e+00
   -4.24365476e-02   5.12557793e+00]
 [ -4.47109528e-03  -6.10267401e+00   7.05185366e+00 ...,   8.04145241e+00
   -4.41038907e-02   5.11480904e+00]
 [ -4.47445503e-03  -6.10702705e+00   7.06692410e+00 ...,   8.04589462e+00
   -4.21481766e-02   5.14017534e+00]]
After layer decoder_rnn_l0_t0_i_output (20, 512) <class 'numpy.float32'> [[ 0.02885411  0.88898158  0.98647112 ...,  0.85065383  0.99016601
   0.94174707]
 [ 0.0288444   0.8889451   0.98647064 ...,  0.8506133   0.99018198
   0.94171393]
 [ 0.02881673  0.88959664  0.98642415 ...,  0.85116947  0.99010921
   0.94173932]
 ...,
 [ 0.02885038  0.88914222  0.98648179 ...,  0.85046601  0.99016201
   0.94164664]
 [ 0.0288636   0.88938802  0.98647577 ...,  0.85042143  0.99013937
   0.94157833]
 [ 0.02884749  0.88918406  0.98646587 ...,  0.85054666  0.99016178
   0.94165105]]
After layer decoder_rnn_l0_t0_c_output (20, 512) <class 'numpy.float32'> [[-0.99286968 -0.99586278  0.99331242 ...,  0.99960363 -0.08196897
   0.97386295]
 [-0.99286687 -0.99586451  0.99330688 ...,  0.99960351 -0.0824075
   0.97382915]
 [-0.99292183 -0.99588186  0.99346209 ...,  0.99959958 -0.0852599
   0.9738248 ]
 ...,
 [-0.99286753 -0.9958843   0.9933424  ...,  0.99960041 -0.08511437
   0.97378409]
 [-0.99286771 -0.99589783  0.99336755 ...,  0.99959767 -0.08753678
   0.97376561]
 [-0.99286443 -0.99587691  0.99333191 ...,  0.99960071 -0.08490925
   0.97380221]]
After layer _mul2119_0 (20, 512) <class 'numpy.float32'> [[-0.02864837 -0.88530368  0.97987401 ...,  0.85031664 -0.08116288
   0.91713256]
 [-0.02863865 -0.88526887  0.97986805 ...,  0.85027605 -0.08159842
   0.91706848]
 [-0.02861276 -0.88593316  0.97997499 ...,  0.85082865 -0.08441661
   0.9170891 ]
 ...,
 [-0.0286446  -0.88548279  0.97991419 ...,  0.85012615 -0.08427701
   0.91696054]
 [-0.02865773 -0.88573962  0.97993302 ...,  0.8500793  -0.08667362
   0.91687661]
 [-0.02864165 -0.8855179   0.97988802 ...,  0.85020703 -0.08407389
   0.91698188]]
After layer decoder_rnn_l0_t0_state_0 (20, 512) <class 'numpy.float32'> [[-0.03313177 -6.98983812  8.07901096 ...,  9.02482891 -0.12087638
   6.12127018]
 [-0.03312182 -6.99091673  8.05400944 ...,  8.94797421 -0.12188941
   6.0879178 ]
 [-0.03306211 -6.96033001  8.08304405 ...,  8.84070206 -0.12569387
   6.02590418]
 ...,
 [-0.03312203 -6.98842335  8.0308857  ...,  8.90378857 -0.12671356
   6.04253864]
 [-0.03312883 -6.98841381  8.03178692 ...,  8.89153194 -0.13077751
   6.03168583]
 [-0.03311611 -6.99254513  8.04681206 ...,  8.89610195 -0.12622206
   6.05715704]]
After layer activation1059_output (20, 512) <class 'numpy.float32'> [[-0.03311965 -0.99999833  0.99999982 ...,  1.         -0.12029109
   0.99999034]
 [-0.03310972 -0.99999833  0.99999982 ...,  0.99999994 -0.12128934
   0.99998969]
 [-0.03305007 -0.99999821  0.99999982 ...,  0.99999994 -0.12503609
   0.99998832]
 ...,
 [-0.03310993 -0.99999827  0.99999976 ...,  0.99999994 -0.12603971
   0.99998873]
 [-0.03311671 -0.99999827  0.99999976 ...,  0.99999994 -0.13003702
   0.99998844]
 [-0.03310401 -0.99999833  0.99999982 ...,  0.99999994 -0.12555598
   0.99998903]]
After layer decoder_rnn_l0_t0_out_0 (20, 512) <class 'numpy.float32'> [[-0.0012069  -0.91905117  0.19754986 ...,  0.65287691 -0.11960471
   0.68434584]
 [-0.00120605 -0.91908002  0.19764383 ...,  0.65278631 -0.12059636
   0.68434745]
 [-0.00120826 -0.91964412  0.19665778 ...,  0.6526112  -0.12432747
   0.68410259]
 ...,
 [-0.00120582 -0.91907996  0.19729507 ...,  0.65282857 -0.12532037
   0.68381178]
 [-0.00120614 -0.91915262  0.19685344 ...,  0.65270495 -0.12929633
   0.6832971 ]
 [-0.00120596 -0.91917354  0.19725004 ...,  0.65260845 -0.12483964
   0.68384522]]
After layer expand_dims1068_0 (20, 512, 1) <class 'numpy.float32'> [[[-0.0012069 ]
  [-0.91905117]
  [ 0.19754986]
  ...,
  [ 0.65287691]
  [-0.11960471]
  [ 0.68434584]]

 [[-0.00120605]
  [-0.91908002]
  [ 0.19764383]
  ...,
  [ 0.65278631]
  [-0.12059636]
  [ 0.68434745]]

 [[-0.00120826]
  [-0.91964412]
  [ 0.19665778]
  ...,
  [ 0.6526112 ]
  [-0.12432747]
  [ 0.68410259]]

 ...,
 [[-0.00120582]
  [-0.91907996]
  [ 0.19729507]
  ...,
  [ 0.65282857]
  [-0.12532037]
  [ 0.68381178]]

 [[-0.00120614]
  [-0.91915262]
  [ 0.19685344]
  ...,
  [ 0.65270495]
  [-0.12929633]
  [ 0.6832971 ]]

 [[-0.00120596]
  [-0.91917354]
  [ 0.19725004]
  ...,
  [ 0.65260845]
  [-0.12483964]
  [ 0.68384522]]]
After layer att_batch_dot_0 (20, 10, 1) <class 'numpy.float32'> [[[ 0.53079647]
  [ 0.92288458]
  [ 1.63185704]
  [ 2.59937358]
  [ 2.51941013]
  [ 0.27366737]
  [-2.96415329]
  [-5.80655098]
  [-7.9443965 ]
  [-9.54646778]]

 [[ 0.53101844]
  [ 0.92269993]
  [ 1.63225591]
  [ 2.60032988]
  [ 2.52110386]
  [ 0.27603751]
  [-2.96128345]
  [-5.80316019]
  [-7.94040298]
  [-9.54183197]]

 [[ 0.5297119 ]
  [ 0.92087293]
  [ 1.62450874]
  [ 2.58415198]
  [ 2.49085617]
  [ 0.22738971]
  [-3.02795815]
  [-5.8852272 ]
  [-8.03437614]
  [-9.64409256]]

 [[ 0.53088993]
  [ 0.92311925]
  [ 1.63270402]
  [ 2.6011281 ]
  [ 2.52110195]
  [ 0.27328065]
  [-2.96778893]
  [-5.81335974]
  [-7.95364141]
  [-9.5572691 ]]

 [[ 0.53009647]
  [ 0.92100835]
  [ 1.62492776]
  [ 2.5837214 ]
  [ 2.48424506]
  [ 0.20741965]
  [-3.06397605]
  [-5.93582344]
  [-8.09616852]
  [-9.71347141]]

 [[ 0.53061461]
  [ 0.92294759]
  [ 1.63215733]
  [ 2.59974551]
  [ 2.51932621]
  [ 0.27231675]
  [-2.96716332]
  [-5.8111515 ]
  [-7.95030594]
  [-9.55337906]]

 [[ 0.52870858]
  [ 0.9208892 ]
  [ 1.6229316 ]
  [ 2.58005071]
  [ 2.47853804]
  [ 0.19995978]
  [-3.07267761]
  [-5.94570017]
  [-8.10745716]
  [-9.72636795]]

 [[ 0.53095204]
  [ 0.92270744]
  [ 1.63183248]
  [ 2.59933925]
  [ 2.51994324]
  [ 0.27565572]
  [-2.9602983 ]
  [-5.80080795]
  [-7.93700123]
  [-9.5377636 ]]

 [[ 0.53271234]
  [ 0.92201388]
  [ 1.62997711]
  [ 2.5940361 ]
  [ 2.50407696]
  [ 0.24015661]
  [-3.01840043]
  [-5.87884665]
  [-8.02954388]
  [-9.63898087]]

 [[ 0.52794933]
  [ 0.91766632]
  [ 1.61384737]
  [ 2.56115341]
  [ 2.44560599]
  [ 0.15190071]
  [-3.13345718]
  [-6.0158577 ]
  [-8.18378544]
  [-9.80611229]]

 [[ 0.53032041]
  [ 0.9206596 ]
  [ 1.62492764]
  [ 2.5848906 ]
  [ 2.49356556]
  [ 0.23440488]
  [-3.01562953]
  [-5.86765814]
  [-8.01225281]
  [-9.61832523]]

 [[ 0.52858865]
  [ 0.91703576]
  [ 1.61443365]
  [ 2.56265998]
  [ 2.44637275]
  [ 0.14939174]
  [-3.14035702]
  [-6.02651787]
  [-8.19675732]
  [-9.81991386]]

 [[ 0.5297004 ]
  [ 0.92100275]
  [ 1.62458158]
  [ 2.5830586 ]
  [ 2.48400497]
  [ 0.2089334 ]
  [-3.0600183 ]
  [-5.92955351]
  [-8.08814716]
  [-9.70434952]]

 [[ 0.52902609]
  [ 0.91574788]
  [ 1.61415243]
  [ 2.56281638]
  [ 2.44647932]
  [ 0.14883997]
  [-3.14192533]
  [-6.02872419]
  [-8.19878483]
  [-9.82095623]]

 [[ 0.5309931 ]
  [ 0.92281604]
  [ 1.63231981]
  [ 2.60038781]
  [ 2.52108812]
  [ 0.27585122]
  [-2.96168017]
  [-5.80379486]
  [-7.94124556]
  [-9.54282379]]

 [[ 0.53100544]
  [ 0.92300433]
  [ 1.63255858]
  [ 2.60086989]
  [ 2.52170706]
  [ 0.27624416]
  [-2.96180558]
  [-5.80453396]
  [-7.94254255]
  [-9.54459476]]

 [[ 0.53101134]
  [ 0.92291844]
  [ 1.63242805]
  [ 2.60056949]
  [ 2.52067924]
  [ 0.27378729]
  [-2.96588874]
  [-5.81000662]
  [-7.94901991]
  [-9.55162621]]

 [[ 0.53075707]
  [ 0.9227137 ]
  [ 1.63204968]
  [ 2.59969974]
  [ 2.51802564]
  [ 0.267766  ]
  [-2.97573185]
  [-5.82329559]
  [-7.9651289 ]
  [-9.56997776]]

 [[ 0.53038442]
  [ 0.92289925]
  [ 1.63183403]
  [ 2.59916306]
  [ 2.51566243]
  [ 0.2614446 ]
  [-2.9869051 ]
  [-5.83910322]
  [-7.98473406]
  [-9.59236813]]

 [[ 0.53083301]
  [ 0.9228186 ]
  [ 1.63201714]
  [ 2.59977937]
  [ 2.51868343]
  [ 0.26952538]
  [-2.97277832]
  [-5.81932211]
  [-7.96027899]
  [-9.56436157]]]
After layer swapaxes39_output (10, 20, 1) <class 'numpy.float32'> [[[ 0.53079647]
  [ 0.53101844]
  [ 0.5297119 ]
  [ 0.53088993]
  [ 0.53009647]
  [ 0.53061461]
  [ 0.52870858]
  [ 0.53095204]
  [ 0.53271234]
  [ 0.52794933]
  [ 0.53032041]
  [ 0.52858865]
  [ 0.5297004 ]
  [ 0.52902609]
  [ 0.5309931 ]
  [ 0.53100544]
  [ 0.53101134]
  [ 0.53075707]
  [ 0.53038442]
  [ 0.53083301]]

 [[ 0.92288458]
  [ 0.92269993]
  [ 0.92087293]
  [ 0.92311925]
  [ 0.92100835]
  [ 0.92294759]
  [ 0.9208892 ]
  [ 0.92270744]
  [ 0.92201388]
  [ 0.91766632]
  [ 0.9206596 ]
  [ 0.91703576]
  [ 0.92100275]
  [ 0.91574788]
  [ 0.92281604]
  [ 0.92300433]
  [ 0.92291844]
  [ 0.9227137 ]
  [ 0.92289925]
  [ 0.9228186 ]]

 [[ 1.63185704]
  [ 1.63225591]
  [ 1.62450874]
  [ 1.63270402]
  [ 1.62492776]
  [ 1.63215733]
  [ 1.6229316 ]
  [ 1.63183248]
  [ 1.62997711]
  [ 1.61384737]
  [ 1.62492764]
  [ 1.61443365]
  [ 1.62458158]
  [ 1.61415243]
  [ 1.63231981]
  [ 1.63255858]
  [ 1.63242805]
  [ 1.63204968]
  [ 1.63183403]
  [ 1.63201714]]

 [[ 2.59937358]
  [ 2.60032988]
  [ 2.58415198]
  [ 2.6011281 ]
  [ 2.5837214 ]
  [ 2.59974551]
  [ 2.58005071]
  [ 2.59933925]
  [ 2.5940361 ]
  [ 2.56115341]
  [ 2.5848906 ]
  [ 2.56265998]
  [ 2.5830586 ]
  [ 2.56281638]
  [ 2.60038781]
  [ 2.60086989]
  [ 2.60056949]
  [ 2.59969974]
  [ 2.59916306]
  [ 2.59977937]]

 [[ 2.51941013]
  [ 2.52110386]
  [ 2.49085617]
  [ 2.52110195]
  [ 2.48424506]
  [ 2.51932621]
  [ 2.47853804]
  [ 2.51994324]
  [ 2.50407696]
  [ 2.44560599]
  [ 2.49356556]
  [ 2.44637275]
  [ 2.48400497]
  [ 2.44647932]
  [ 2.52108812]
  [ 2.52170706]
  [ 2.52067924]
  [ 2.51802564]
  [ 2.51566243]
  [ 2.51868343]]

 [[ 0.27366737]
  [ 0.27603751]
  [ 0.22738971]
  [ 0.27328065]
  [ 0.20741965]
  [ 0.27231675]
  [ 0.19995978]
  [ 0.27565572]
  [ 0.24015661]
  [ 0.15190071]
  [ 0.23440488]
  [ 0.14939174]
  [ 0.2089334 ]
  [ 0.14883997]
  [ 0.27585122]
  [ 0.27624416]
  [ 0.27378729]
  [ 0.267766  ]
  [ 0.2614446 ]
  [ 0.26952538]]

 [[-2.96415329]
  [-2.96128345]
  [-3.02795815]
  [-2.96778893]
  [-3.06397605]
  [-2.96716332]
  [-3.07267761]
  [-2.9602983 ]
  [-3.01840043]
  [-3.13345718]
  [-3.01562953]
  [-3.14035702]
  [-3.0600183 ]
  [-3.14192533]
  [-2.96168017]
  [-2.96180558]
  [-2.96588874]
  [-2.97573185]
  [-2.9869051 ]
  [-2.97277832]]

 [[-5.80655098]
  [-5.80316019]
  [-5.8852272 ]
  [-5.81335974]
  [-5.93582344]
  [-5.8111515 ]
  [-5.94570017]
  [-5.80080795]
  [-5.87884665]
  [-6.0158577 ]
  [-5.86765814]
  [-6.02651787]
  [-5.92955351]
  [-6.02872419]
  [-5.80379486]
  [-5.80453396]
  [-5.81000662]
  [-5.82329559]
  [-5.83910322]
  [-5.81932211]]

 [[-7.9443965 ]
  [-7.94040298]
  [-8.03437614]
  [-7.95364141]
  [-8.09616852]
  [-7.95030594]
  [-8.10745716]
  [-7.93700123]
  [-8.02954388]
  [-8.18378544]
  [-8.01225281]
  [-8.19675732]
  [-8.08814716]
  [-8.19878483]
  [-7.94124556]
  [-7.94254255]
  [-7.94901991]
  [-7.9651289 ]
  [-7.98473406]
  [-7.96027899]]

 [[-9.54646778]
  [-9.54183197]
  [-9.64409256]
  [-9.5572691 ]
  [-9.71347141]
  [-9.55337906]
  [-9.72636795]
  [-9.5377636 ]
  [-9.63898087]
  [-9.80611229]
  [-9.61832523]
  [-9.81991386]
  [-9.70434952]
  [-9.82095623]
  [-9.54282379]
  [-9.54459476]
  [-9.55162621]
  [-9.56997776]
  [-9.59236813]
  [-9.56436157]]]
After layer sequencemask15_output (10, 20, 1) <class 'numpy.float32'> [[[  5.30796468e-01]
  [  5.31018436e-01]
  [  5.29711902e-01]
  [  5.30889928e-01]
  [  5.30096471e-01]
  [  5.30614614e-01]
  [  5.28708577e-01]
  [  5.30952036e-01]
  [  5.32712340e-01]
  [  5.27949333e-01]
  [  5.30320406e-01]
  [  5.28588653e-01]
  [  5.29700398e-01]
  [  5.29026091e-01]
  [  5.30993104e-01]
  [  5.31005442e-01]
  [  5.31011343e-01]
  [  5.30757070e-01]
  [  5.30384421e-01]
  [  5.30833006e-01]]

 [[  9.22884583e-01]
  [  9.22699928e-01]
  [  9.20872927e-01]
  [  9.23119247e-01]
  [  9.21008348e-01]
  [  9.22947586e-01]
  [  9.20889199e-01]
  [  9.22707438e-01]
  [  9.22013879e-01]
  [  9.17666316e-01]
  [  9.20659602e-01]
  [  9.17035758e-01]
  [  9.21002746e-01]
  [  9.15747881e-01]
  [  9.22816038e-01]
  [  9.23004329e-01]
  [  9.22918439e-01]
  [  9.22713697e-01]
  [  9.22899246e-01]
  [  9.22818601e-01]]

 [[ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]]
After layer swapaxes40_output (20, 10, 1) <class 'numpy.float32'> [[[  5.30796468e-01]
  [  9.22884583e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  5.31018436e-01]
  [  9.22699928e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  5.29711902e-01]
  [  9.20872927e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  5.30889928e-01]
  [  9.23119247e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  5.30096471e-01]
  [  9.21008348e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  5.30614614e-01]
  [  9.22947586e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  5.28708577e-01]
  [  9.20889199e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  5.30952036e-01]
  [  9.22707438e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  5.32712340e-01]
  [  9.22013879e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  5.27949333e-01]
  [  9.17666316e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  5.30320406e-01]
  [  9.20659602e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  5.28588653e-01]
  [  9.17035758e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  5.29700398e-01]
  [  9.21002746e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  5.29026091e-01]
  [  9.15747881e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  5.30993104e-01]
  [  9.22816038e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  5.31005442e-01]
  [  9.23004329e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  5.31011343e-01]
  [  9.22918439e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  5.30757070e-01]
  [  9.22713697e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  5.30384421e-01]
  [  9.22899246e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  5.30833006e-01]
  [  9.22818601e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]]
After layer attention_softmax_0 (20, 10, 1) <class 'numpy.float32'> [[[ 0.40321472]
  [ 0.59678525]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40331259]
  [ 0.59668744]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40343785]
  [ 0.59656221]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40318075]
  [ 0.59681928]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40349776]
  [ 0.59650218]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.4031558 ]
  [ 0.5968442 ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40319246]
  [ 0.59680748]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40329477]
  [ 0.5967052 ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40388545]
  [ 0.59611458]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40378541]
  [ 0.59621459]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40363565]
  [ 0.59636438]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40409118]
  [ 0.59590876]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40340385]
  [ 0.59659618]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40450671]
  [ 0.59549332]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40327856]
  [ 0.59672147]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40323618]
  [ 0.59676379]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40325826]
  [ 0.59674168]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40324637]
  [ 0.5967536 ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40311202]
  [ 0.59688795]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.4032394 ]
  [ 0.59676063]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]]
After layer batch_dot15_0 (20, 512, 1) <class 'numpy.float32'> [[[ 0.01785395]
  [ 0.03944139]
  [-0.03343033]
  ...,
  [-0.01095626]
  [ 0.00999339]
  [-0.02459877]]

 [[ 0.01785159]
  [ 0.03943866]
  [-0.03342593]
  ...,
  [-0.01095572]
  [ 0.00999327]
  [-0.0246005 ]]

 [[ 0.01784856]
  [ 0.03943518]
  [-0.03342029]
  ...,
  [-0.01095502]
  [ 0.00999313]
  [-0.02460272]]

 ...,
 [[ 0.01785318]
  [ 0.03944051]
  [-0.0334289 ]
  ...,
  [-0.01095608]
  [ 0.00999335]
  [-0.02459933]]

 [[ 0.01785643]
  [ 0.03944425]
  [-0.03343495]
  ...,
  [-0.01095683]
  [ 0.0099935 ]
  [-0.02459696]]

 [[ 0.01785335]
  [ 0.0394407 ]
  [-0.03342922]
  ...,
  [-0.01095612]
  [ 0.00999336]
  [-0.02459921]]]
After layer reshape30_0 (20, 512) <class 'numpy.float32'> [[ 0.01785395  0.03944139 -0.03343033 ..., -0.01095626  0.00999339
  -0.02459877]
 [ 0.01785159  0.03943866 -0.03342593 ..., -0.01095572  0.00999327
  -0.0246005 ]
 [ 0.01784856  0.03943518 -0.03342029 ..., -0.01095502  0.00999313
  -0.02460272]
 ...,
 [ 0.01785318  0.03944051 -0.0334289  ..., -0.01095608  0.00999335
  -0.02459933]
 [ 0.01785643  0.03944425 -0.03343495 ..., -0.01095683  0.0099935
  -0.02459696]
 [ 0.01785335  0.0394407  -0.03342922 ..., -0.01095612  0.00999336
  -0.02459921]]
After layer decoder_rnn_hidden_concat_t0_output (20, 1024) <class 'numpy.float32'> [[-0.0012069  -0.91905117  0.19754986 ..., -0.01095626  0.00999339
  -0.02459877]
 [-0.00120605 -0.91908002  0.19764383 ..., -0.01095572  0.00999327
  -0.0246005 ]
 [-0.00120826 -0.91964412  0.19665778 ..., -0.01095502  0.00999313
  -0.02460272]
 ...,
 [-0.00120582 -0.91907996  0.19729507 ..., -0.01095608  0.00999335
  -0.02459933]
 [-0.00120614 -0.91915262  0.19685344 ..., -0.01095683  0.0099935
  -0.02459696]
 [-0.00120596 -0.91917354  0.19725004 ..., -0.01095612  0.00999336
  -0.02459921]]
After layer decoder_rnn_hidden_fc_t0_output (20, 512) <class 'numpy.float32'> [[-1.97069061  0.21110275 -0.81521142 ...,  1.98161626  2.11442351
  -1.6001482 ]
 [-1.97076201  0.21034405 -0.81494474 ...,  1.98158455  2.11519527
  -1.59997177]
 [-1.96794343  0.21367511 -0.81940866 ...,  1.97789431  2.11197042
  -1.60262072]
 ...,
 [-1.97245991  0.21270633 -0.81758398 ...,  1.98194873  2.11425805
  -1.60113513]
 [-1.97325039  0.21486977 -0.82006651 ...,  1.98152983  2.11278749
  -1.60167205]
 [-1.97135293  0.2121734  -0.81725037 ...,  1.98116982  2.11402607
  -1.60043347]]
After layer decoder_rnn_next_hidden_t0_output (20, 512) <class 'numpy.float32'> [[-0.96189725  0.20802177 -0.67245507 ...,  0.96270549  0.97128004
  -0.92169088]
 [-0.96190262  0.20729579 -0.67230898 ...,  0.96270317  0.97132373
  -0.9216643 ]
 [-0.96169138  0.21048149 -0.67474794 ...,  0.96243203  0.97114086
  -0.9220621 ]
 ...,
 [-0.96202928  0.20955545 -0.67375273 ...,  0.96272981  0.97127068
  -0.92183924]
 [-0.96208817  0.21162294 -0.67510605 ...,  0.96269917  0.97118729
  -0.92191988]
 [-0.96194673  0.20904587 -0.67357051 ...,  0.96267277  0.97125757
  -0.9217338 ]]
After layer logits_output (20, 16743) <class 'numpy.float32'> [[-2.01089668 -2.82443595 -2.40667892 ..., -2.09237504 -3.50206971
  -2.5848105 ]
 [-2.01132536 -2.82434773 -2.40656018 ..., -2.09210563 -3.50191402
  -2.58475089]
 [-2.00886559 -2.825279   -2.40621209 ..., -2.09430075 -3.5009017
  -2.58589029]
 ...,
 [-2.01121187 -2.82400489 -2.40627694 ..., -2.09220862 -3.50117326
  -2.58565331]
 [-2.01050949 -2.82358122 -2.40617251 ..., -2.09254622 -3.50034404
  -2.58618236]
 [-2.01075554 -2.82399487 -2.40631199 ..., -2.09231973 -3.50103164
  -2.58524656]]
After layer softmax_0 (20, 16743) <class 'numpy.float32'> [[  8.37279856e-07   3.71154641e-07   5.63617562e-07 ...,   7.71765087e-07
    1.88478808e-07   4.71653578e-07]
 [  8.37041739e-07   3.71240958e-07   5.63765866e-07 ...,   7.72083752e-07
    1.88535211e-07   4.71749331e-07]
 [  8.44006308e-07   3.73062534e-07   5.67257530e-07 ...,   7.74893067e-07
    1.89829080e-07   4.73965457e-07]
 ...,
 [  8.39668644e-07   3.72491655e-07   5.65631638e-07 ...,   7.74339924e-07
    1.89245810e-07   4.72749889e-07]
 [  8.42990460e-07   3.73860729e-07   5.67529241e-07 ...,   7.76594675e-07
    1.90018383e-07   4.74035630e-07]
 [  8.40237817e-07   3.72577773e-07   5.65736457e-07 ...,   7.74425075e-07
    1.89314278e-07   4.73046356e-07]]
After layer reshape31_0 (20, 10) <class 'numpy.float32'> [[ 0.40321472  0.59678525  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40331259  0.59668744  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40343785  0.59656221  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40318075  0.59681928  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40349776  0.59650218  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.4031558   0.5968442   0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40319246  0.59680748  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40329477  0.5967052   0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40388545  0.59611458  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40378541  0.59621459  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40363565  0.59636438  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40409118  0.59590876  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40340385  0.59659618  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40450671  0.59549332  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40327856  0.59672147  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40323618  0.59676379  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40325826  0.59674168  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40324637  0.5967536   0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40311202  0.59688795  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.4032394   0.59676063  0.          0.          0.          0.          0.
   0.          0.          0.        ]]
After layer target_embed_embed_0 (20, 256) <class 'numpy.float32'> [[-0.05505371 -0.0300293  -0.03598022 ...,  0.08459473 -0.05288696
  -0.01667786]
 [-0.05505371 -0.0300293  -0.03598022 ...,  0.08459473 -0.05288696
  -0.01667786]
 [-0.05505371 -0.0300293  -0.03598022 ...,  0.08459473 -0.05288696
  -0.01667786]
 ...,
 [-0.05505371 -0.0300293  -0.03598022 ...,  0.08459473 -0.05288696
  -0.01667786]
 [-0.05505371 -0.0300293  -0.03598022 ...,  0.08459473 -0.05288696
  -0.01667786]
 [-0.05505371 -0.0300293  -0.03598022 ...,  0.08459473 -0.05288696
  -0.01667786]]
After layer decoder_rnn_concat_target_context_t0_output (20, 768) <class 'numpy.float32'> [[-0.05505371 -0.0300293  -0.03598022 ...,  0.96270549  0.97128004
  -0.92169088]
 [-0.05505371 -0.0300293  -0.03598022 ...,  0.96270317  0.97132373
  -0.9216643 ]
 [-0.05505371 -0.0300293  -0.03598022 ...,  0.96243203  0.97114086
  -0.9220621 ]
 ...,
 [-0.05505371 -0.0300293  -0.03598022 ...,  0.96272981  0.97127068
  -0.92183924]
 [-0.05505371 -0.0300293  -0.03598022 ...,  0.96269917  0.97118729
  -0.92191988]
 [-0.05505371 -0.0300293  -0.03598022 ...,  0.96267277  0.97125757
  -0.9217338 ]]
After layer decoder_rnn_l0_t0_i2h_output (20, 2048) <class 'numpy.float32'> [[-3.19516611  1.60775328  2.43927574 ..., -0.07743927  3.86418033
   0.59698921]
 [-3.19520283  1.60767365  2.439219   ..., -0.07747168  3.86394215
   0.59723222]
 [-3.19390392  1.60759842  2.43918371 ..., -0.07708009  3.86485863
   0.59992707]
 ...,
 [-3.19446039  1.6070472   2.43994737 ..., -0.07701357  3.86342669
   0.59721529]
 [-3.1936245   1.60675192  2.44034529 ..., -0.07664876  3.86308503
   0.59718621]
 [-3.19437265  1.60727882  2.43960953 ..., -0.07716203  3.86347628
   0.59738481]]
After layer decoder_rnn_l0_t0_h2h_output (20, 2048) <class 'numpy.float32'> [[-0.32206684  0.47213623  1.85366416 ...,  0.71064037  1.29610109
   0.17649063]
 [-0.32237816  0.47186938  1.85373449 ...,  0.71038061  1.29526687
   0.17636524]
 [-0.32442024  0.47781837  1.85093057 ...,  0.70962316  1.30155516
   0.1723492 ]
 ...,
 [-0.32291007  0.47431353  1.85362196 ...,  0.71016473  1.29702175
   0.17426607]
 [-0.32323983  0.4767983   1.85282743 ...,  0.70948333  1.29929388
   0.17221469]
 [-0.3230449   0.47435167  1.85301626 ...,  0.70958859  1.29720497
   0.17423517]]
After layer _plus1060_0 (20, 2048) <class 'numpy.float32'> [[-3.51723289  2.07988954  4.29294014 ...,  0.63320112  5.16028118
   0.77347982]
 [-3.51758099  2.07954311  4.29295349 ...,  0.63290894  5.15920925
   0.77359748]
 [-3.51832414  2.08541679  4.2901144  ...,  0.63254309  5.16641378
   0.77227628]
 ...,
 [-3.51737046  2.08136082  4.29356956 ...,  0.63315117  5.16044855
   0.77148139]
 [-3.5168643   2.08355021  4.29317284 ...,  0.63283455  5.16237879
   0.76940089]
 [-3.51741743  2.08163047  4.2926259  ...,  0.63242656  5.16068125
   0.77161998]]
After layer decoder_rnn_l0_t0_slice_output0 (20, 512) <class 'numpy.float32'> [[-3.51723289  2.07988954  4.29294014 ...,  1.73901713  4.61467505
   2.78243971]
 [-3.51758099  2.07954311  4.29295349 ...,  1.73884952  4.61606979
   2.7820065 ]
 [-3.51832414  2.08541679  4.2901144  ...,  1.74257743  4.60946178
   2.78241634]
 ...,
 [-3.51737046  2.08136082  4.29356956 ...,  1.73808753  4.61412764
   2.78091908]
 [-3.5168643   2.08355021  4.29317284 ...,  1.73787284  4.61192322
   2.77986574]
 [-3.51741743  2.08163047  4.2926259  ...,  1.73856091  4.61412621
   2.78106499]]
After layer decoder_rnn_l0_t0_slice_output1 (20, 512) <class 'numpy.float32'> [[-1.85464609  2.32213092  2.43780184 ...,  3.16714287 -0.69170082
   1.98588634]
 [-1.85444903  2.32228804  2.43788242 ...,  3.16720819 -0.69087732
   1.98601735]
 [-1.86016536  2.31974173  2.44190121 ...,  3.16453457 -0.69428945
   1.98370433]
 ...,
 [-1.85576737  2.32210279  2.43931532 ...,  3.1657095  -0.69031578
   1.98565733]
 [-1.85727155  2.32174277  2.44009757 ...,  3.16388702 -0.69092405
   1.98495734]
 [-1.85606909  2.32202983  2.43859959 ...,  3.16539383 -0.69114816
   1.98522484]]
After layer decoder_rnn_l0_t0_slice_output2 (20, 512) <class 'numpy.float32'> [[-2.81676912 -3.09221029  2.84999895 ...,  4.26280022 -0.08242366
   2.16158295]
 [-2.81663847 -3.09239268  2.84972954 ...,  4.26276159 -0.08265111
   2.16102791]
 [-2.82008648 -3.0943315   2.86035585 ...,  4.25806904 -0.08551982
   2.160748  ]
 ...,
 [-2.81691408 -3.09468317  2.85236192 ...,  4.25938511 -0.08483678
   2.16025639]
 [-2.81708384 -3.09626365  2.85421491 ...,  4.25629854 -0.08688772
   2.15997696]
 [-2.81670117 -3.09383368  2.85159349 ...,  4.25969219 -0.08470666
   2.1605835 ]]
After layer decoder_rnn_l0_t0_slice_output3 (20, 512) <class 'numpy.float32'> [[-3.27550507  2.42720842 -1.40127552 ...,  0.63320112  5.16028118
   0.77347982]
 [-3.27582026  2.42750716 -1.4006536  ...,  0.63290894  5.15920925
   0.77359748]
 [-3.27233267  2.4338603  -1.40599167 ...,  0.63254309  5.16641378
   0.77227628]
 ...,
 [-3.27591538  2.42750454 -1.40261352 ...,  0.63315117  5.16044855
   0.77148139]
 [-3.27580357  2.4282732  -1.40512574 ...,  0.63283455  5.16237879
   0.76940089]
 [-3.27565098  2.428509   -1.40282214 ...,  0.63242656  5.16068125
   0.77161998]]
After layer decoder_rnn_l0_t0_o_output (20, 512) <class 'numpy.float32'> [[ 0.03642114  0.91887867  0.19761381 ...,  0.65321493  0.99429274
   0.68427318]
 [ 0.03641007  0.91890091  0.19771242 ...,  0.65314877  0.9942866
   0.68429857]
 [ 0.03653264  0.91937315  0.19686705 ...,  0.65306592  0.99432737
   0.68401307]
 ...,
 [ 0.03640674  0.91890073  0.19740172 ...,  0.65320361  0.99429363
   0.68384123]
 [ 0.03641066  0.91895801  0.19700399 ...,  0.6531319   0.9943046
   0.68339127]
 [ 0.03641602  0.91897565  0.19736867 ...,  0.65303946  0.99429494
   0.68387121]]
After layer decoder_rnn_l0_t0_f_output (20, 512) <class 'numpy.float32'> [[ 0.13532832  0.91069341  0.91966486 ...,  0.95957887  0.33365482
   0.87930727]
 [ 0.13535137  0.91070622  0.91967082 ...,  0.95958143  0.33383796
   0.87932116]
 [ 0.13468377  0.91049886  0.91996723 ...,  0.9594776   0.33307955
   0.87907553]
 ...,
 [ 0.13519716  0.91069108  0.91977656 ...,  0.95952326  0.33396283
   0.87928295]
 [ 0.13502139  0.91066182  0.91983426 ...,  0.95945245  0.33382753
   0.87920862]
 [ 0.13516189  0.91068518  0.91972375 ...,  0.95951104  0.3337777
   0.87923706]]
After layer _mul2120_0 (20, 512) <class 'numpy.float32'> [[ -4.48366674e-03  -6.36559963e+00   7.42998266e+00 ...,   8.66003513e+00
   -4.03309874e-02   5.38247728e+00]
 [ -4.48308466e-03  -6.36667156e+00   7.40703726e+00 ...,   8.58631039e+00
   -4.06913124e-02   5.35323477e+00]
 [ -4.45292937e-03  -6.33737230e+00   7.43613577e+00 ...,   8.48245525e+00
   -4.18660566e-02   5.29722500e+00]
 ...,
 [ -4.47800476e-03  -6.36429501e+00   7.38662052e+00 ...,   8.54339218e+00
   -4.23176177e-02   5.31310129e+00]
 [ -4.47310042e-03  -6.36408138e+00   7.38791275e+00 ...,   8.53100204e+00
   -4.36571315e-02   5.30311012e+00]
 [ -4.47603548e-03  -6.36800718e+00   7.40084410e+00 ...,   8.53590775e+00
   -4.21301089e-02   5.32567692e+00]]
After layer decoder_rnn_l0_t0_i_output (20, 512) <class 'numpy.float32'> [[ 0.02882586  0.88893318  0.98651946 ...,  0.85056216  0.9901917
   0.94171947]
 [ 0.02881612  0.88889885  0.98651969 ...,  0.85054088  0.99020523
   0.94169569]
 [ 0.02879532  0.88947767  0.9864819  ...,  0.85101414  0.99014097
   0.94171816]
 ...,
 [ 0.02882201  0.88907832  0.98652786 ...,  0.85044402  0.99018645
   0.94163597]
 [ 0.02883618  0.88929397  0.98652261 ...,  0.85041666  0.99016494
   0.94157803]
 [ 0.02882069  0.8891049   0.98651528 ...,  0.85050422  0.99018645
   0.94164395]]
After layer decoder_rnn_l0_t0_c_output (20, 512) <class 'numpy.float32'> [[-0.99287367 -0.99588591  0.99333036 ...,  0.99960345 -0.08223751
   0.97383124]
 [-0.99287182 -0.9958874   0.99332678 ...,  0.99960339 -0.08246342
   0.97380257]
 [-0.99292064 -0.99590325  0.99346668 ...,  0.99959964 -0.08531194
   0.97378808]
 ...,
 [-0.99287575 -0.99590617  0.99336171 ...,  0.99960071 -0.08463383
   0.97376263]
 [-0.99287814 -0.99591905  0.99338621 ...,  0.99959826 -0.08666973
   0.97374815]
 [-0.99287271 -0.9958992   0.99335152 ...,  0.99960095 -0.08450465
   0.97377956]]
After layer _mul2121_0 (20, 512) <class 'numpy.float32'> [[-0.02862044 -0.88527602  0.9799397  ...,  0.85022485 -0.0814309
   0.91707581]
 [-0.02861071 -0.88524318  0.97993642 ...,  0.85020357 -0.08165571
   0.91702569]
 [-0.02859147 -0.88583368  0.98003691 ...,  0.85067344 -0.08447085
   0.91703391]
 ...,
 [-0.02861668 -0.88543856  0.97997898 ...,  0.85010445 -0.08380327
   0.9169299 ]
 [-0.02863081 -0.88566482  0.97999793 ...,  0.85007501 -0.08581732
   0.91685987]
 [-0.02861528 -0.88545889  0.97995645 ...,  0.85016483 -0.08367536
   0.91695362]]
After layer decoder_rnn_l0_t0_state_0 (20, 512) <class 'numpy.float32'> [[-0.0331041  -7.25087547  8.4099226  ...,  9.51025963 -0.12176189
   6.29955292]
 [-0.0330938  -7.25191498  8.38697338 ...,  9.4365139  -0.12234703
   6.27026033]
 [-0.0330444  -7.22320604  8.41617298 ...,  9.33312893 -0.1263369
   6.21425915]
 ...,
 [-0.03309468 -7.24973345  8.36659908 ...,  9.39349651 -0.1261209
   6.23003101]
 [-0.03310391 -7.24974632  8.36791039 ...,  9.38107681 -0.12947446
   6.21996975]
 [-0.03309132 -7.25346613  8.38080025 ...,  9.38607216 -0.12580547
   6.24263048]]
After layer activation1060_output (20, 512) <class 'numpy.float32'> [[-0.03309201 -0.99999899  0.99999988 ...,  1.         -0.1211637
   0.99999326]
 [-0.03308172 -0.99999899  0.99999988 ...,  1.         -0.1217402
   0.99999285]
 [-0.03303238 -0.99999893  0.99999988 ...,  1.         -0.12566902
   0.99999201]
 ...,
 [-0.0330826  -0.99999899  0.99999988 ...,  1.         -0.12545641
   0.99999225]
 [-0.03309182 -0.99999899  0.99999988 ...,  1.         -0.12875579
   0.99999207]
 [-0.03307924 -0.99999899  0.99999988 ...,  1.         -0.12514594
   0.99999243]]
After layer decoder_rnn_l0_t0_out_0 (20, 512) <class 'numpy.float32'> [[-0.00120525 -0.91887772  0.19761378 ...,  0.65321493 -0.12047219
   0.68426859]
 [-0.00120451 -0.91889995  0.19771239 ...,  0.65314877 -0.12104465
   0.68429369]
 [-0.00120676 -0.91937214  0.19686702 ...,  0.65306592 -0.12495615
   0.68400759]
 ...,
 [-0.00120443 -0.91889977  0.19740169 ...,  0.65320361 -0.1247405
   0.68383592]
 [-0.0012049  -0.91895705  0.19700396 ...,  0.6531319  -0.12802248
   0.68338585]
 [-0.00120461 -0.9189747   0.19736864 ...,  0.65303946 -0.12443198
   0.68386602]]
After layer expand_dims1069_0 (20, 512, 1) <class 'numpy.float32'> [[[-0.00120525]
  [-0.91887772]
  [ 0.19761378]
  ...,
  [ 0.65321493]
  [-0.12047219]
  [ 0.68426859]]

 [[-0.00120451]
  [-0.91889995]
  [ 0.19771239]
  ...,
  [ 0.65314877]
  [-0.12104465]
  [ 0.68429369]]

 [[-0.00120676]
  [-0.91937214]
  [ 0.19686702]
  ...,
  [ 0.65306592]
  [-0.12495615]
  [ 0.68400759]]

 ...,
 [[-0.00120443]
  [-0.91889977]
  [ 0.19740169]
  ...,
  [ 0.65320361]
  [-0.1247405 ]
  [ 0.68383592]]

 [[-0.0012049 ]
  [-0.91895705]
  [ 0.19700396]
  ...,
  [ 0.6531319 ]
  [-0.12802248]
  [ 0.68338585]]

 [[-0.00120461]
  [-0.9189747 ]
  [ 0.19736864]
  ...,
  [ 0.65303946]
  [-0.12443198]
  [ 0.68386602]]]
After layer att_batch_dot_0 (20, 10, 1) <class 'numpy.float32'> [[[ 0.5310086 ]
  [ 0.92317438]
  [ 1.63362241]
  [ 2.60234761]
  [ 2.52276897]
  [ 0.27583364]
  [-2.96394277]
  [-5.80815792]
  [-7.94748783]
  [-9.55089188]]

 [[ 0.53121376]
  [ 0.92305553]
  [ 1.6339581 ]
  [ 2.60314369]
  [ 2.52422023]
  [ 0.27795094]
  [-2.96128488]
  [-5.8049798 ]
  [-7.94374943]
  [-9.5465498 ]]

 [[ 0.5300498 ]
  [ 0.92140359]
  [ 1.62712228]
  [ 2.58900428]
  [ 2.4977181 ]
  [ 0.23501961]
  [-3.02048612]
  [-5.87818718]
  [-8.02790642]
  [-9.63846207]]

 [[ 0.53102976]
  [ 0.92335379]
  [ 1.63410246]
  [ 2.60331559]
  [ 2.52335286]
  [ 0.2743555 ]
  [-2.9683938 ]
  [-5.81550074]
  [-7.95707846]
  [-9.56197357]]

 [[ 0.53038484]
  [ 0.92162442]
  [ 1.62698615]
  [ 2.58739972]
  [ 2.48980832]
  [ 0.21448976]
  [-3.05584455]
  [-5.92699003]
  [-8.08711433]
  [-9.70481586]]

 [[ 0.53085381]
  [ 0.92329901]
  [ 1.63394427]
  [ 2.60273743]
  [ 2.5227437 ]
  [ 0.27465048]
  [-2.9666419 ]
  [-5.81232595]
  [-7.95287704]
  [-9.55719662]]

 [[ 0.52896947]
  [ 0.92125273]
  [ 1.62494874]
  [ 2.5837729 ]
  [ 2.48410749]
  [ 0.20685104]
  [-3.06497908]
  [-5.93751431]
  [-8.09915257]
  [-9.71847153]]

 [[ 0.5311904 ]
  [ 0.92308599]
  [ 1.63376951]
  [ 2.60265946]
  [ 2.52380943]
  [ 0.27838117]
  [-2.9595747 ]
  [-5.80200434]
  [-7.93979549]
  [-9.54195881]]

 [[ 0.53296244]
  [ 0.92281193]
  [ 1.63193631]
  [ 2.5973525 ]
  [ 2.50885057]
  [ 0.24589942]
  [-3.0120945 ]
  [-5.87225533]
  [-8.02310276]
  [-9.633255  ]]

 [[ 0.52863955]
  [ 0.91895735]
  [ 1.61811376]
  [ 2.56940413]
  [ 2.45872068]
  [ 0.16920714]
  [-3.11323428]
  [-5.99381018]
  [-8.16088676]
  [-9.78335381]]

 [[ 0.53071582]
  [ 0.92140818]
  [ 1.627985  ]
  [ 2.59063435]
  [ 2.50173402]
  [ 0.24349089]
  [-3.00680542]
  [-5.85950804]
  [-8.00491333]
  [-9.61203003]]

 [[ 0.52935642]
  [ 0.91861629]
  [ 1.61859989]
  [ 2.57048535]
  [ 2.45913529]
  [ 0.16702542]
  [-3.11881685]
  [-6.0022769 ]
  [-8.17112541]
  [-9.79419136]]

 [[ 0.53000093]
  [ 0.92157096]
  [ 1.6267767 ]
  [ 2.58708286]
  [ 2.49003911]
  [ 0.21642815]
  [-3.05165029]
  [-5.9206686 ]
  [-8.07916641]
  [-9.69582939]]

 [[ 0.53012198]
  [ 0.91802728]
  [ 1.6191287 ]
  [ 2.57190967]
  [ 2.4615097 ]
  [ 0.17018318]
  [-3.11512566]
  [-5.99789667]
  [-8.16563225]
  [-9.78719997]]

 [[ 0.53118944]
  [ 0.92315018]
  [ 1.63401449]
  [ 2.60319281]
  [ 2.52418947]
  [ 0.2777411 ]
  [-2.9617157 ]
  [-5.80563641]
  [-7.94460201]
  [-9.54757404]]

 [[ 0.53117758]
  [ 0.92329001]
  [ 1.63415551]
  [ 2.60347176]
  [ 2.52450657]
  [ 0.27778134]
  [-2.96217942]
  [-5.80667257]
  [-7.94616699]
  [-9.54955387]]

 [[ 0.53117067]
  [ 0.92321205]
  [ 1.63397872]
  [ 2.60307956]
  [ 2.52341366]
  [ 0.27540588]
  [-2.96599412]
  [-5.8117137 ]
  [-7.95210552]
  [-9.55603313]]

 [[ 0.53092849]
  [ 0.92304099]
  [ 1.63354266]
  [ 2.60207224]
  [ 2.52066326]
  [ 0.26953059]
  [-2.97535825]
  [-5.82422972]
  [-7.96719933]
  [-9.57315254]]

 [[ 0.53053546]
  [ 0.923145  ]
  [ 1.6331352 ]
  [ 2.60114241]
  [ 2.51780152]
  [ 0.26285225]
  [-2.98658347]
  [-5.83976698]
  [-7.9862752 ]
  [-9.59488678]]

 [[ 0.53098464]
  [ 0.92309642]
  [ 1.6335026 ]
  [ 2.60214806]
  [ 2.52126813]
  [ 0.27112558]
  [-2.97268915]
  [-5.82064009]
  [-7.96284151]
  [-9.56812572]]]
After layer swapaxes41_output (10, 20, 1) <class 'numpy.float32'> [[[ 0.5310086 ]
  [ 0.53121376]
  [ 0.5300498 ]
  [ 0.53102976]
  [ 0.53038484]
  [ 0.53085381]
  [ 0.52896947]
  [ 0.5311904 ]
  [ 0.53296244]
  [ 0.52863955]
  [ 0.53071582]
  [ 0.52935642]
  [ 0.53000093]
  [ 0.53012198]
  [ 0.53118944]
  [ 0.53117758]
  [ 0.53117067]
  [ 0.53092849]
  [ 0.53053546]
  [ 0.53098464]]

 [[ 0.92317438]
  [ 0.92305553]
  [ 0.92140359]
  [ 0.92335379]
  [ 0.92162442]
  [ 0.92329901]
  [ 0.92125273]
  [ 0.92308599]
  [ 0.92281193]
  [ 0.91895735]
  [ 0.92140818]
  [ 0.91861629]
  [ 0.92157096]
  [ 0.91802728]
  [ 0.92315018]
  [ 0.92329001]
  [ 0.92321205]
  [ 0.92304099]
  [ 0.923145  ]
  [ 0.92309642]]

 [[ 1.63362241]
  [ 1.6339581 ]
  [ 1.62712228]
  [ 1.63410246]
  [ 1.62698615]
  [ 1.63394427]
  [ 1.62494874]
  [ 1.63376951]
  [ 1.63193631]
  [ 1.61811376]
  [ 1.627985  ]
  [ 1.61859989]
  [ 1.6267767 ]
  [ 1.6191287 ]
  [ 1.63401449]
  [ 1.63415551]
  [ 1.63397872]
  [ 1.63354266]
  [ 1.6331352 ]
  [ 1.6335026 ]]

 [[ 2.60234761]
  [ 2.60314369]
  [ 2.58900428]
  [ 2.60331559]
  [ 2.58739972]
  [ 2.60273743]
  [ 2.5837729 ]
  [ 2.60265946]
  [ 2.5973525 ]
  [ 2.56940413]
  [ 2.59063435]
  [ 2.57048535]
  [ 2.58708286]
  [ 2.57190967]
  [ 2.60319281]
  [ 2.60347176]
  [ 2.60307956]
  [ 2.60207224]
  [ 2.60114241]
  [ 2.60214806]]

 [[ 2.52276897]
  [ 2.52422023]
  [ 2.4977181 ]
  [ 2.52335286]
  [ 2.48980832]
  [ 2.5227437 ]
  [ 2.48410749]
  [ 2.52380943]
  [ 2.50885057]
  [ 2.45872068]
  [ 2.50173402]
  [ 2.45913529]
  [ 2.49003911]
  [ 2.4615097 ]
  [ 2.52418947]
  [ 2.52450657]
  [ 2.52341366]
  [ 2.52066326]
  [ 2.51780152]
  [ 2.52126813]]

 [[ 0.27583364]
  [ 0.27795094]
  [ 0.23501961]
  [ 0.2743555 ]
  [ 0.21448976]
  [ 0.27465048]
  [ 0.20685104]
  [ 0.27838117]
  [ 0.24589942]
  [ 0.16920714]
  [ 0.24349089]
  [ 0.16702542]
  [ 0.21642815]
  [ 0.17018318]
  [ 0.2777411 ]
  [ 0.27778134]
  [ 0.27540588]
  [ 0.26953059]
  [ 0.26285225]
  [ 0.27112558]]

 [[-2.96394277]
  [-2.96128488]
  [-3.02048612]
  [-2.9683938 ]
  [-3.05584455]
  [-2.9666419 ]
  [-3.06497908]
  [-2.9595747 ]
  [-3.0120945 ]
  [-3.11323428]
  [-3.00680542]
  [-3.11881685]
  [-3.05165029]
  [-3.11512566]
  [-2.9617157 ]
  [-2.96217942]
  [-2.96599412]
  [-2.97535825]
  [-2.98658347]
  [-2.97268915]]

 [[-5.80815792]
  [-5.8049798 ]
  [-5.87818718]
  [-5.81550074]
  [-5.92699003]
  [-5.81232595]
  [-5.93751431]
  [-5.80200434]
  [-5.87225533]
  [-5.99381018]
  [-5.85950804]
  [-6.0022769 ]
  [-5.9206686 ]
  [-5.99789667]
  [-5.80563641]
  [-5.80667257]
  [-5.8117137 ]
  [-5.82422972]
  [-5.83976698]
  [-5.82064009]]

 [[-7.94748783]
  [-7.94374943]
  [-8.02790642]
  [-7.95707846]
  [-8.08711433]
  [-7.95287704]
  [-8.09915257]
  [-7.93979549]
  [-8.02310276]
  [-8.16088676]
  [-8.00491333]
  [-8.17112541]
  [-8.07916641]
  [-8.16563225]
  [-7.94460201]
  [-7.94616699]
  [-7.95210552]
  [-7.96719933]
  [-7.9862752 ]
  [-7.96284151]]

 [[-9.55089188]
  [-9.5465498 ]
  [-9.63846207]
  [-9.56197357]
  [-9.70481586]
  [-9.55719662]
  [-9.71847153]
  [-9.54195881]
  [-9.633255  ]
  [-9.78335381]
  [-9.61203003]
  [-9.79419136]
  [-9.69582939]
  [-9.78719997]
  [-9.54757404]
  [-9.54955387]
  [-9.55603313]
  [-9.57315254]
  [-9.59488678]
  [-9.56812572]]]
After layer sequencemask16_output (10, 20, 1) <class 'numpy.float32'> [[[  5.31008601e-01]
  [  5.31213760e-01]
  [  5.30049801e-01]
  [  5.31029761e-01]
  [  5.30384839e-01]
  [  5.30853808e-01]
  [  5.28969467e-01]
  [  5.31190395e-01]
  [  5.32962441e-01]
  [  5.28639555e-01]
  [  5.30715823e-01]
  [  5.29356420e-01]
  [  5.30000925e-01]
  [  5.30121982e-01]
  [  5.31189442e-01]
  [  5.31177580e-01]
  [  5.31170666e-01]
  [  5.30928493e-01]
  [  5.30535460e-01]
  [  5.30984640e-01]]

 [[  9.23174381e-01]
  [  9.23055530e-01]
  [  9.21403587e-01]
  [  9.23353791e-01]
  [  9.21624422e-01]
  [  9.23299015e-01]
  [  9.21252728e-01]
  [  9.23085988e-01]
  [  9.22811925e-01]
  [  9.18957353e-01]
  [  9.21408176e-01]
  [  9.18616295e-01]
  [  9.21570957e-01]
  [  9.18027282e-01]
  [  9.23150182e-01]
  [  9.23290014e-01]
  [  9.23212051e-01]
  [  9.23040986e-01]
  [  9.23144996e-01]
  [  9.23096418e-01]]

 [[ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]]
After layer swapaxes42_output (20, 10, 1) <class 'numpy.float32'> [[[  5.31008601e-01]
  [  9.23174381e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  5.31213760e-01]
  [  9.23055530e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  5.30049801e-01]
  [  9.21403587e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  5.31029761e-01]
  [  9.23353791e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  5.30384839e-01]
  [  9.21624422e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  5.30853808e-01]
  [  9.23299015e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  5.28969467e-01]
  [  9.21252728e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  5.31190395e-01]
  [  9.23085988e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  5.32962441e-01]
  [  9.22811925e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  5.28639555e-01]
  [  9.18957353e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  5.30715823e-01]
  [  9.21408176e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  5.29356420e-01]
  [  9.18616295e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  5.30000925e-01]
  [  9.21570957e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  5.30121982e-01]
  [  9.18027282e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  5.31189442e-01]
  [  9.23150182e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  5.31177580e-01]
  [  9.23290014e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  5.31170666e-01]
  [  9.23212051e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  5.30928493e-01]
  [  9.23040986e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  5.30535460e-01]
  [  9.23144996e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  5.30984640e-01]
  [  9.23096418e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]]
After layer attention_softmax_0 (20, 10, 1) <class 'numpy.float32'> [[[ 0.40319604]
  [ 0.59680396]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40327403]
  [ 0.596726  ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40339145]
  [ 0.59660858]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40315798]
  [ 0.59684205]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40341893]
  [ 0.5965811 ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.4031288 ]
  [ 0.5968712 ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40316778]
  [ 0.59683222]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40326107]
  [ 0.59673899]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40375352]
  [ 0.59624642]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40364081]
  [ 0.59635919]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40355062]
  [ 0.59644938]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40389547]
  [ 0.5961045 ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40333942]
  [ 0.59666061]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40422165]
  [ 0.59577835]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40324536]
  [ 0.59675461]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40320885]
  [ 0.59679109]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40322599]
  [ 0.59677404]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40320885]
  [ 0.59679115]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40308926]
  [ 0.59691072]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40320903]
  [ 0.59679091]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]]
After layer batch_dot16_0 (20, 512, 1) <class 'numpy.float32'> [[[ 0.0178544 ]
  [ 0.03944191]
  [-0.03343117]
  ...,
  [-0.01095636]
  [ 0.00999341]
  [-0.02459844]]

 [[ 0.01785252]
  [ 0.03943974]
  [-0.03342766]
  ...,
  [-0.01095593]
  [ 0.00999332]
  [-0.02459982]]

 [[ 0.01784968]
  [ 0.03943647]
  [-0.03342238]
  ...,
  [-0.01095528]
  [ 0.00999318]
  [-0.0246019 ]]

 ...,
 [[ 0.01785409]
  [ 0.03944155]
  [-0.03343059]
  ...,
  [-0.01095629]
  [ 0.00999339]
  [-0.02459867]]

 [[ 0.01785698]
  [ 0.03944488]
  [-0.03343597]
  ...,
  [-0.01095695]
  [ 0.00999353]
  [-0.02459656]]

 [[ 0.01785409]
  [ 0.03944154]
  [-0.03343058]
  ...,
  [-0.01095629]
  [ 0.00999339]
  [-0.02459867]]]
After layer reshape32_0 (20, 512) <class 'numpy.float32'> [[ 0.0178544   0.03944191 -0.03343117 ..., -0.01095636  0.00999341
  -0.02459844]
 [ 0.01785252  0.03943974 -0.03342766 ..., -0.01095593  0.00999332
  -0.02459982]
 [ 0.01784968  0.03943647 -0.03342238 ..., -0.01095528  0.00999318
  -0.0246019 ]
 ...,
 [ 0.01785409  0.03944155 -0.03343059 ..., -0.01095629  0.00999339
  -0.02459867]
 [ 0.01785698  0.03944488 -0.03343597 ..., -0.01095695  0.00999353
  -0.02459656]
 [ 0.01785409  0.03944154 -0.03343058 ..., -0.01095629  0.00999339
  -0.02459867]]
After layer decoder_rnn_hidden_concat_t0_output (20, 1024) <class 'numpy.float32'> [[-0.00120525 -0.91887772  0.19761378 ..., -0.01095636  0.00999341
  -0.02459844]
 [-0.00120451 -0.91889995  0.19771239 ..., -0.01095593  0.00999332
  -0.02459982]
 [-0.00120676 -0.91937214  0.19686702 ..., -0.01095528  0.00999318
  -0.0246019 ]
 ...,
 [-0.00120443 -0.91889977  0.19740169 ..., -0.01095629  0.00999339
  -0.02459867]
 [-0.0012049  -0.91895705  0.19700396 ..., -0.01095695  0.00999353
  -0.02459656]
 [-0.00120461 -0.9189747   0.19736864 ..., -0.01095629  0.00999339
  -0.02459867]]
After layer decoder_rnn_hidden_fc_t0_output (20, 512) <class 'numpy.float32'> [[-1.97247624  0.21226528 -0.81655222 ...,  1.98298442  2.11617899
  -1.60186076]
 [-1.97244835  0.21154855 -0.81626147 ...,  1.98290122  2.11684728
  -1.6017288 ]
 [-1.97027743  0.21462518 -0.82040554 ...,  1.97987199  2.11387873
  -1.6040231 ]
 ...,
 [-1.97384691  0.21366455 -0.81860292 ...,  1.98307252  2.11594534
  -1.60283768]
 [-1.97458804  0.21569502 -0.82084972 ...,  1.98272049  2.11460829
  -1.60338032]
 [-1.97297454  0.21321805 -0.81830764 ...,  1.982517    2.11577535
  -1.60220671]]
After layer decoder_rnn_next_hidden_t0_output (20, 512) <class 'numpy.float32'> [[-0.96203053  0.20913373 -0.67318892 ...,  0.96280551  0.97137928
  -0.92194819]
 [-0.96202844  0.20844825 -0.6730299  ...,  0.96279943  0.97141695
  -0.92192835]
 [-0.96186638  0.2113893  -0.67529058 ...,  0.96257758  0.97124922
  -0.92227191]
 ...,
 [-0.96213251  0.21047141 -0.67430878 ...,  0.96281195  0.97136611
  -0.92209458]
 [-0.96218753  0.21241111 -0.6755321  ...,  0.9627862   0.97129053
  -0.92217577]
 [-0.9620676   0.21004465 -0.67414773 ...,  0.96277136  0.97135651
  -0.92200005]]
After layer logits_output (20, 16743) <class 'numpy.float32'> [[-2.01221704 -2.82459879 -2.40689301 ..., -2.09227109 -3.50227833
  -2.58594584]
 [-2.01259947 -2.8245914  -2.40681267 ..., -2.09206867 -3.50218558
  -2.5859201 ]
 [-2.01044226 -2.82537079 -2.40641189 ..., -2.09397817 -3.50127435
  -2.58702397]
 ...,
 [-2.01247835 -2.82435918 -2.40664315 ..., -2.09225106 -3.50159431
  -2.58676195]
 [-2.01185083 -2.82402301 -2.40659142 ..., -2.09259462 -3.50091577
  -2.58727551]
 [-2.01210642 -2.82433867 -2.40664244 ..., -2.09231639 -3.50148392
  -2.58640313]]
After layer softmax_0 (20, 16743) <class 'numpy.float32'> [[  8.36569939e-07   3.71269607e-07   5.63763592e-07 ...,   7.72210228e-07
    1.88528531e-07   4.71340940e-07]
 [  8.36248034e-07   3.71271113e-07   5.63806736e-07 ...,   7.72363705e-07
    1.88545314e-07   4.71351399e-07]
 [  8.42614497e-07   3.73000745e-07   5.67101949e-07 ...,   7.75085539e-07
    1.89744256e-07   4.73393754e-07]
 ...,
 [  8.38531093e-07   3.72326639e-07   5.65374023e-07 ...,   7.74238288e-07
    1.89149162e-07   4.72183700e-07]
 [  8.41450174e-07   3.73513757e-07   5.67015491e-07 ...,   7.76178922e-07
    1.89817399e-07   4.73287258e-07]
 [  8.38984590e-07   3.72396585e-07   5.65468895e-07 ...,   7.74317300e-07
    1.89201842e-07   4.72432760e-07]]
After layer reshape33_0 (20, 10) <class 'numpy.float32'> [[ 0.40319604  0.59680396  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40327403  0.596726    0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40339145  0.59660858  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40315798  0.59684205  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40341893  0.5965811   0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.4031288   0.5968712   0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40316778  0.59683222  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40326107  0.59673899  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40375352  0.59624642  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40364081  0.59635919  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40355062  0.59644938  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40389547  0.5961045   0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40333942  0.59666061  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40422165  0.59577835  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40324536  0.59675461  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40320885  0.59679109  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40322599  0.59677404  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40320885  0.59679115  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40308926  0.59691072  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40320903  0.59679091  0.          0.          0.          0.          0.
   0.          0.          0.        ]]
After layer target_embed_embed_0 (20, 256) <class 'numpy.float32'> [[-0.05505371 -0.0300293  -0.03598022 ...,  0.08459473 -0.05288696
  -0.01667786]
 [-0.05505371 -0.0300293  -0.03598022 ...,  0.08459473 -0.05288696
  -0.01667786]
 [-0.05505371 -0.0300293  -0.03598022 ...,  0.08459473 -0.05288696
  -0.01667786]
 ...,
 [-0.05505371 -0.0300293  -0.03598022 ...,  0.08459473 -0.05288696
  -0.01667786]
 [-0.05505371 -0.0300293  -0.03598022 ...,  0.08459473 -0.05288696
  -0.01667786]
 [-0.05505371 -0.0300293  -0.03598022 ...,  0.08459473 -0.05288696
  -0.01667786]]
After layer decoder_rnn_concat_target_context_t0_output (20, 768) <class 'numpy.float32'> [[-0.05505371 -0.0300293  -0.03598022 ...,  0.96280551  0.97137928
  -0.92194819]
 [-0.05505371 -0.0300293  -0.03598022 ...,  0.96279943  0.97141695
  -0.92192835]
 [-0.05505371 -0.0300293  -0.03598022 ...,  0.96257758  0.97124922
  -0.92227191]
 ...,
 [-0.05505371 -0.0300293  -0.03598022 ...,  0.96281195  0.97136611
  -0.92209458]
 [-0.05505371 -0.0300293  -0.03598022 ...,  0.9627862   0.97129053
  -0.92217577]
 [-0.05505371 -0.0300293  -0.03598022 ...,  0.96277136  0.97135651
  -0.92200005]]
After layer decoder_rnn_l0_t0_i2h_output (20, 2048) <class 'numpy.float32'> [[-3.19586849  1.6075207   2.44022512 ..., -0.07732934  3.86443138
   0.59657615]
 [-3.19594169  1.60747862  2.44018817 ..., -0.07737298  3.86428857
   0.59681892]
 [-3.1947124   1.60725212  2.44023275 ..., -0.07696192  3.86500168
   0.5992505 ]
 ...,
 [-3.19532275  1.60698104  2.44083834 ..., -0.07696635  3.86395741
   0.59683174]
 [-3.19459796  1.6067251   2.44119692 ..., -0.07662236  3.86371708
   0.59680074]
 [-3.19524431  1.60714936  2.44053888 ..., -0.07707984  3.86397076
   0.59696817]]
After layer decoder_rnn_l0_t0_h2h_output (20, 2048) <class 'numpy.float32'> [[-0.32233045  0.47213578  1.85570097 ...,  0.71174949  1.29578722
   0.17658348]
 [-0.3225998   0.47186273  1.85577333 ...,  0.71157259  1.29504216
   0.17653638]
 [-0.32437277  0.4772962   1.85337138 ...,  0.71113795  1.30071199
   0.17264913]
 ...,
 [-0.32301897  0.47403032  1.85557711 ...,  0.71142298  1.2966851
   0.17469813]
 [-0.32322431  0.47622612  1.85486507 ...,  0.71092075  1.29876935
   0.17288963]
 [-0.32310179  0.47401375  1.85511613 ...,  0.71100277  1.29681194
   0.17468138]]
After layer _plus1061_0 (20, 2048) <class 'numpy.float32'> [[-3.51819897  2.0796566   4.29592609 ...,  0.63442016  5.16021872
   0.77315962]
 [-3.51854157  2.07934141  4.29596138 ...,  0.63419962  5.15933084
   0.77335531]
 [-3.51908517  2.08454823  4.2936039  ...,  0.63417602  5.16571379
   0.77189964]
 ...,
 [-3.51834178  2.0810113   4.29641533 ...,  0.63445663  5.16064262
   0.77152985]
 [-3.51782227  2.08295131  4.29606199 ...,  0.63429838  5.16248655
   0.76969039]
 [-3.51834607  2.08116317  4.29565525 ...,  0.63392293  5.16078281
   0.77164954]]
After layer decoder_rnn_l0_t0_slice_output0 (20, 512) <class 'numpy.float32'> [[-3.51819897  2.0796566   4.29592609 ...,  1.73870361  4.61690235
   2.78184938]
 [-3.51854157  2.07934141  4.29596138 ...,  1.73863828  4.61809158
   2.78154731]
 [-3.51908517  2.08454823  4.2936039  ...,  1.7418555   4.61217165
   2.78188896]
 ...,
 [-3.51834178  2.0810113   4.29641533 ...,  1.73814547  4.61627102
   2.78057814]
 [-3.51782227  2.08295131  4.29606199 ...,  1.73802185  4.61419582
   2.77966666]
 [-3.51834607  2.08116317  4.29565525 ...,  1.73850262  4.61628532
   2.78075838]]
After layer decoder_rnn_l0_t0_slice_output1 (20, 512) <class 'numpy.float32'> [[-1.85389948  2.3225503   2.44017172 ...,  3.16768909 -0.68973178
   1.98763502]
 [-1.85377121  2.3226738   2.44025803 ...,  3.16785097 -0.68905592
   1.9877969 ]
 [-1.85896778  2.32062745  2.44381452 ...,  3.16529226 -0.69181025
   1.9856596 ]
 ...,
 [-1.85499859  2.32239199  2.44164419 ...,  3.16658711 -0.68875176
   1.98753428]
 [-1.85632658  2.32203913  2.44243693 ...,  3.1650064  -0.68935239
   1.9869709 ]
 [-1.85519612  2.32240224  2.44098616 ...,  3.16632652 -0.68938595
   1.98716211]]
After layer decoder_rnn_l0_t0_slice_output2 (20, 512) <class 'numpy.float32'> [[-2.81694412 -3.09478331  2.85145164 ...,  4.26254368 -0.08243623
   2.16096449]
 [-2.81685615 -3.09493256  2.85128784 ...,  4.26261854 -0.08252043
   2.16049004]
 [-2.81993723 -3.09677172  2.86089516 ...,  4.25807953 -0.08528411
   2.16006947]
 ...,
 [-2.81725717 -3.09707975  2.85383749 ...,  4.25962877 -0.08431047
   2.15979958]
 [-2.817523   -3.09857893  2.85562038 ...,  4.25684452 -0.08606246
   2.15957642]
 [-2.81705475 -3.09628534  2.85309649 ...,  4.25990534 -0.08423266
   2.16010427]]
After layer decoder_rnn_l0_t0_slice_output3 (20, 512) <class 'numpy.float32'> [[-3.27591276  2.425318   -1.40104651 ...,  0.63442016  5.16021872
   0.77315962]
 [-3.27614594  2.42555857 -1.40042424 ...,  0.63419962  5.15933084
   0.77335531]
 [-3.27296019  2.43092346 -1.40502179 ...,  0.63417602  5.16571379
   0.77189964]
 ...,
 [-3.27616525  2.4255631  -1.40219069 ...,  0.63445663  5.16064262
   0.77152985]
 [-3.27602887  2.42617035 -1.40446436 ...,  0.63429838  5.16248655
   0.76969039]
 [-3.27594113  2.42636895 -1.402336   ...,  0.63392293  5.16078281
   0.77164954]]
After layer decoder_rnn_l0_t0_o_output (20, 512) <class 'numpy.float32'> [[ 0.03640683  0.91873771  0.1976501  ...,  0.65349102  0.99429238
   0.68420398]
 [ 0.03639865  0.91875559  0.19774881 ...,  0.65344113  0.99428731
   0.6842463 ]
 [ 0.03651055  0.91915518  0.19702043 ...,  0.65343571  0.99432349
   0.68393165]
 ...,
 [ 0.03639797  0.91875601  0.19746873 ...,  0.65349931  0.9942947
   0.68385172]
 [ 0.03640275  0.91880131  0.19710864 ...,  0.65346348  0.99430519
   0.68345392]
 [ 0.03640584  0.91881609  0.19744569 ...,  0.65337843  0.99429554
   0.68387759]]
After layer decoder_rnn_l0_t0_f_output (20, 512) <class 'numpy.float32'> [[ 0.1354157   0.9107275   0.91983974 ...,  0.95960009  0.33409277
   0.87949276]
 [ 0.13543072  0.91073757  0.91984606 ...,  0.95960635  0.33424312
   0.87950993]
 [ 0.13482341  0.91057098  0.92010802 ...,  0.95950711  0.3336305
   0.87928319]
 ...,
 [ 0.13528708  0.91071463  0.91994828 ...,  0.95955735  0.33431083
   0.87948203]
 [ 0.13513179  0.91068596  0.92000657 ...,  0.9594959   0.33417717
   0.87942231]
 [ 0.13526396  0.9107154   0.91989976 ...,  0.95954728  0.33416969
   0.87944257]]
After layer _mul2122_0 (20, 512) <class 'numpy.float32'> [[ -4.48281551e-03  -6.60357189e+00   7.73578119e+00 ...,   9.12604618e+00
   -4.06797677e-02   5.54041100e+00]
 [ -4.48191678e-03  -6.60459137e+00   7.71472454e+00 ...,   9.05533886e+00
   -4.08936515e-02   5.51475620e+00]
 [ -4.45515895e-03  -6.57724190e+00   7.74378824e+00 ...,   8.95520401e+00
   -4.21498455e-02   5.46409369e+00]
 ...,
 [ -4.47728252e-03  -6.60243845e+00   7.69683838e+00 ...,   9.01359844e+00
   -4.21635807e-02   5.47920036e+00]
 [ -4.47339099e-03  -6.60224199e+00   7.69853258e+00 ...,   9.00110435e+00
   -4.32674102e-02   5.46998024e+00]
 [ -4.47606295e-03  -6.60584354e+00   7.70949602e+00 ...,   9.00638008e+00
   -4.20403741e-02   5.49003506e+00]]
After layer decoder_rnn_l0_t0_i_output (20, 512) <class 'numpy.float32'> [[ 0.02879883  0.88891017  0.98655915 ...,  0.85052234  0.99021333
   0.94168711]
 [ 0.02878924  0.888879    0.98655963 ...,  0.85051405  0.9902249
   0.94167048]
 [ 0.02877405  0.88939226  0.98652828 ...,  0.85092264  0.99016738
   0.94168919]
 ...,
 [ 0.02879483  0.88904387  0.98656565 ...,  0.85045135  0.99020725
   0.94161725]
 [ 0.02880937  0.88923508  0.986561   ...,  0.85043567  0.99018717
   0.94156712]
 [ 0.02879472  0.88905883  0.98655558 ...,  0.85049677  0.99020737
   0.94162714]]
After layer decoder_rnn_l0_t0_c_output (20, 512) <class 'numpy.float32'> [[-0.99287617 -0.99590695  0.99334967 ...,  0.99960321 -0.08225001
   0.97379929]
 [-0.99287492 -0.9959082   0.99334747 ...,  0.99960327 -0.08233362
   0.97377473]
 [-0.99291855 -0.99592316  0.99347365 ...,  0.9995997  -0.08507795
   0.97375298]
 ...,
 [-0.99288058 -0.99592566  0.9933812  ...,  0.99960089 -0.08411127
   0.97373897]
 [-0.9928844  -0.99593782  0.99340469 ...,  0.99959868 -0.08585061
   0.97372741]
 [-0.99287772 -0.99591923  0.99337143 ...,  0.99960113 -0.08403401
   0.97375476]]
After layer _mul2123_0 (20, 512) <class 'numpy.float32'> [[-0.02859367 -0.88527185  0.97999823 ...,  0.85018486 -0.08144505
   0.91701424]
 [-0.02858412 -0.88524187  0.9799965  ...,  0.85017663 -0.08152881
   0.9169749 ]
 [-0.02857029 -0.88576633  0.98008984 ...,  0.850582   -0.08424141
   0.91697264]
 ...,
 [-0.02858983 -0.88542163  0.98003578 ...,  0.8501119  -0.0832876
   0.91688943]
 [-0.02860437 -0.88562286  0.98005432 ...,  0.85009438 -0.08500817
   0.91682971]
 [-0.02858963 -0.88543075  0.98001611 ...,  0.8501575  -0.08321109
   0.91691393]]
After layer decoder_rnn_l0_t0_state_0 (20, 512) <class 'numpy.float32'> [[-0.03307648 -7.48884392  8.7157793  ...,  9.97623062 -0.12212482
   6.45742512]
 [-0.03306603 -7.48983335  8.69472122 ...,  9.90551567 -0.12242246
   6.43173122]
 [-0.03302545 -7.4630084   8.72387791 ...,  9.80578613 -0.12639126
   6.38106632]
 ...,
 [-0.03306711 -7.4878602   8.67687416 ...,  9.8637104  -0.12545118
   6.39608955]
 [-0.03307776 -7.48786497  8.67858696 ...,  9.85119915 -0.12827559
   6.38680983]
 [-0.03306569 -7.49127436  8.68951225 ...,  9.85653782 -0.12525147
   6.40694904]]
After layer activation1061_output (20, 512) <class 'numpy.float32'> [[-0.03306442 -0.9999994   0.99999994 ...,  1.         -0.12152129
   0.99999505]
 [-0.03305399 -0.9999994   0.99999994 ...,  1.         -0.12181451
   0.99999481]
 [-0.03301344 -0.99999934  0.99999994 ...,  1.         -0.12572251
   0.99999428]
 ...,
 [-0.03305506 -0.99999934  0.99999994 ...,  1.         -0.12479718
   0.99999446]
 [-0.0330657  -0.99999934  0.99999994 ...,  1.         -0.12757662
   0.99999434]
 [-0.03305365 -0.9999994   0.99999994 ...,  1.         -0.12460058
   0.99999458]]
After layer decoder_rnn_l0_t0_out_0 (20, 512) <class 'numpy.float32'> [[-0.00120377 -0.91873717  0.19765009 ...,  0.65349102 -0.12082769
   0.68420058]
 [-0.00120312 -0.91875505  0.1977488  ...,  0.65344113 -0.12111862
   0.68424273]
 [-0.00120534 -0.91915458  0.19702041 ...,  0.65343571 -0.12500885
   0.68392771]
 ...,
 [-0.00120314 -0.91875541  0.19746871 ...,  0.65349931 -0.12408517
   0.6838479 ]
 [-0.00120368 -0.91880071  0.19710863 ...,  0.65346348 -0.1268501
   0.68345004]
 [-0.00120335 -0.91881555  0.19744568 ...,  0.65337843 -0.1238898
   0.68387389]]
After layer expand_dims1070_0 (20, 512, 1) <class 'numpy.float32'> [[[-0.00120377]
  [-0.91873717]
  [ 0.19765009]
  ...,
  [ 0.65349102]
  [-0.12082769]
  [ 0.68420058]]

 [[-0.00120312]
  [-0.91875505]
  [ 0.1977488 ]
  ...,
  [ 0.65344113]
  [-0.12111862]
  [ 0.68424273]]

 [[-0.00120534]
  [-0.91915458]
  [ 0.19702041]
  ...,
  [ 0.65343571]
  [-0.12500885]
  [ 0.68392771]]

 ...,
 [[-0.00120314]
  [-0.91875541]
  [ 0.19746871]
  ...,
  [ 0.65349931]
  [-0.12408517]
  [ 0.6838479 ]]

 [[-0.00120368]
  [-0.91880071]
  [ 0.19710863]
  ...,
  [ 0.65346348]
  [-0.1268501 ]
  [ 0.68345004]]

 [[-0.00120335]
  [-0.91881555]
  [ 0.19744568]
  ...,
  [ 0.65337843]
  [-0.1238898 ]
  [ 0.68387389]]]
After layer att_batch_dot_0 (20, 10, 1) <class 'numpy.float32'> [[[ 0.53119874]
  [ 0.92354512]
  [ 1.63521409]
  [ 2.60493135]
  [ 2.52563787]
  [ 0.2776624 ]
  [-2.96380711]
  [-5.80960894]
  [-7.95025444]
  [-9.55476379]]

 [[ 0.53139174]
  [ 0.92347801]
  [ 1.63550985]
  [ 2.60561061]
  [ 2.52691579]
  [ 0.2795862 ]
  [-2.96132922]
  [-5.80662155]
  [-7.94672394]
  [-9.55072117]]

 [[ 0.5303393 ]
  [ 0.92193919]
  [ 1.62933683]
  [ 2.59297705]
  [ 2.50325036]
  [ 0.24110919]
  [-3.0145843 ]
  [-5.87268114]
  [-8.02286243]
  [-9.6340704 ]]

 [[ 0.53117692]
  [ 0.92369139]
  [ 1.63545871]
  [ 2.60538673]
  [ 2.52552485]
  [ 0.27555695]
  [-2.96863437]
  [-5.8170681 ]
  [-7.95979548]
  [-9.56571293]]

 [[ 0.53064841]
  [ 0.92224556]
  [ 1.62890542]
  [ 2.59075642]
  [ 2.49481535]
  [ 0.22083093]
  [-3.04859471]
  [-5.91914988]
  [-8.07905293]
  [-9.69702244]]

 [[ 0.53106868]
  [ 0.92372024]
  [ 1.63556516]
  [ 2.60535645]
  [ 2.52570486]
  [ 0.27668089]
  [-2.96616912]
  [-5.81331778]
  [-7.95508099]
  [-9.56044006]]

 [[ 0.5292365 ]
  [ 0.92169893]
  [ 1.62685549]
  [ 2.58717632]
  [ 2.48916125]
  [ 0.21313305]
  [-3.05793571]
  [-5.92999458]
  [-8.09143066]
  [-9.71098042]]

 [[ 0.53139377]
  [ 0.92351907]
  [ 1.63547003]
  [ 2.60545349]
  [ 2.52697849]
  [ 0.28050503]
  [-2.95921254]
  [-5.80334473]
  [-7.94253826]
  [-9.54591751]]

 [[ 0.53315252]
  [ 0.923545  ]
  [ 1.63371921]
  [ 2.60031962]
  [ 2.51304626]
  [ 0.25086111]
  [-3.00676799]
  [-5.86681032]
  [-8.01784134]
  [-9.62861919]]

 [[ 0.52917123]
  [ 0.92000049]
  [ 1.62150228]
  [ 2.57583523]
  [ 2.46884537]
  [ 0.18250293]
  [-3.09774756]
  [-5.97693539]
  [-8.14334488]
  [-9.76583958]]

 [[ 0.53103054]
  [ 0.92209315]
  [ 1.63046956]
  [ 2.59514236]
  [ 2.50802016]
  [ 0.25033322]
  [-3.00033402]
  [-5.85368347]
  [-7.99982309]
  [-9.6077795 ]]

 [[ 0.52991617]
  [ 0.91983473]
  [ 1.62189066]
  [ 2.57657146]
  [ 2.46892047]
  [ 0.18039538]
  [-3.10262942]
  [-5.98417425]
  [-8.15203571]
  [-9.77505493]]

 [[ 0.53027904]
  [ 0.92216355]
  [ 1.62878919]
  [ 2.59066439]
  [ 2.49536228]
  [ 0.2230283 ]
  [-3.0442884 ]
  [-5.91286707]
  [-8.07125854]
  [-9.6882391 ]]

 [[ 0.53082764]
  [ 0.91962624]
  [ 1.62276351]
  [ 2.57849002]
  [ 2.47220993]
  [ 0.18512459]
  [-3.0966382 ]
  [-5.97686863]
  [-8.14322281]
  [-9.76455975]]

 [[ 0.53136849]
  [ 0.92355579]
  [ 1.63555968]
  [ 2.60565424]
  [ 2.52687621]
  [ 0.27937064]
  [-2.96176481]
  [-5.80727148]
  [-7.94757223]
  [-9.55171204]]

 [[ 0.53133994]
  [ 0.92366093]
  [ 1.63563359]
  [ 2.6058023 ]
  [ 2.52699709]
  [ 0.27919164]
  [-2.96242905]
  [-5.8084693 ]
  [-7.94925451]
  [-9.55377483]]

 [[ 0.53132677]
  [ 0.92359042]
  [ 1.63543165]
  [ 2.60536003]
  [ 2.52588534]
  [ 0.2769213 ]
  [-2.96597242]
  [-5.81311512]
  [-7.95471573]
  [-9.55975533]]

 [[ 0.53110224]
  [ 0.92345262]
  [ 1.63498187]
  [ 2.60431051]
  [ 2.52317238]
  [ 0.27132037]
  [-2.97476935]
  [-5.82479572]
  [-7.96874189]
  [-9.57562733]]

 [[ 0.53070337]
  [ 0.92349929]
  [ 1.63445687]
  [ 2.60314155]
  [ 2.52004647]
  [ 0.26454744]
  [-2.98579526]
  [-5.8398242 ]
  [-7.98708439]
  [-9.59645557]]

 [[ 0.53113991]
  [ 0.92346597]
  [ 1.63492477]
  [ 2.60435796]
  [ 2.52369308]
  [ 0.27272689]
  [-2.97240114]
  [-5.82158852]
  [-7.96486235]
  [-9.57115364]]]
After layer swapaxes43_output (10, 20, 1) <class 'numpy.float32'> [[[ 0.53119874]
  [ 0.53139174]
  [ 0.5303393 ]
  [ 0.53117692]
  [ 0.53064841]
  [ 0.53106868]
  [ 0.5292365 ]
  [ 0.53139377]
  [ 0.53315252]
  [ 0.52917123]
  [ 0.53103054]
  [ 0.52991617]
  [ 0.53027904]
  [ 0.53082764]
  [ 0.53136849]
  [ 0.53133994]
  [ 0.53132677]
  [ 0.53110224]
  [ 0.53070337]
  [ 0.53113991]]

 [[ 0.92354512]
  [ 0.92347801]
  [ 0.92193919]
  [ 0.92369139]
  [ 0.92224556]
  [ 0.92372024]
  [ 0.92169893]
  [ 0.92351907]
  [ 0.923545  ]
  [ 0.92000049]
  [ 0.92209315]
  [ 0.91983473]
  [ 0.92216355]
  [ 0.91962624]
  [ 0.92355579]
  [ 0.92366093]
  [ 0.92359042]
  [ 0.92345262]
  [ 0.92349929]
  [ 0.92346597]]

 [[ 1.63521409]
  [ 1.63550985]
  [ 1.62933683]
  [ 1.63545871]
  [ 1.62890542]
  [ 1.63556516]
  [ 1.62685549]
  [ 1.63547003]
  [ 1.63371921]
  [ 1.62150228]
  [ 1.63046956]
  [ 1.62189066]
  [ 1.62878919]
  [ 1.62276351]
  [ 1.63555968]
  [ 1.63563359]
  [ 1.63543165]
  [ 1.63498187]
  [ 1.63445687]
  [ 1.63492477]]

 [[ 2.60493135]
  [ 2.60561061]
  [ 2.59297705]
  [ 2.60538673]
  [ 2.59075642]
  [ 2.60535645]
  [ 2.58717632]
  [ 2.60545349]
  [ 2.60031962]
  [ 2.57583523]
  [ 2.59514236]
  [ 2.57657146]
  [ 2.59066439]
  [ 2.57849002]
  [ 2.60565424]
  [ 2.6058023 ]
  [ 2.60536003]
  [ 2.60431051]
  [ 2.60314155]
  [ 2.60435796]]

 [[ 2.52563787]
  [ 2.52691579]
  [ 2.50325036]
  [ 2.52552485]
  [ 2.49481535]
  [ 2.52570486]
  [ 2.48916125]
  [ 2.52697849]
  [ 2.51304626]
  [ 2.46884537]
  [ 2.50802016]
  [ 2.46892047]
  [ 2.49536228]
  [ 2.47220993]
  [ 2.52687621]
  [ 2.52699709]
  [ 2.52588534]
  [ 2.52317238]
  [ 2.52004647]
  [ 2.52369308]]

 [[ 0.2776624 ]
  [ 0.2795862 ]
  [ 0.24110919]
  [ 0.27555695]
  [ 0.22083093]
  [ 0.27668089]
  [ 0.21313305]
  [ 0.28050503]
  [ 0.25086111]
  [ 0.18250293]
  [ 0.25033322]
  [ 0.18039538]
  [ 0.2230283 ]
  [ 0.18512459]
  [ 0.27937064]
  [ 0.27919164]
  [ 0.2769213 ]
  [ 0.27132037]
  [ 0.26454744]
  [ 0.27272689]]

 [[-2.96380711]
  [-2.96132922]
  [-3.0145843 ]
  [-2.96863437]
  [-3.04859471]
  [-2.96616912]
  [-3.05793571]
  [-2.95921254]
  [-3.00676799]
  [-3.09774756]
  [-3.00033402]
  [-3.10262942]
  [-3.0442884 ]
  [-3.0966382 ]
  [-2.96176481]
  [-2.96242905]
  [-2.96597242]
  [-2.97476935]
  [-2.98579526]
  [-2.97240114]]

 [[-5.80960894]
  [-5.80662155]
  [-5.87268114]
  [-5.8170681 ]
  [-5.91914988]
  [-5.81331778]
  [-5.92999458]
  [-5.80334473]
  [-5.86681032]
  [-5.97693539]
  [-5.85368347]
  [-5.98417425]
  [-5.91286707]
  [-5.97686863]
  [-5.80727148]
  [-5.8084693 ]
  [-5.81311512]
  [-5.82479572]
  [-5.8398242 ]
  [-5.82158852]]

 [[-7.95025444]
  [-7.94672394]
  [-8.02286243]
  [-7.95979548]
  [-8.07905293]
  [-7.95508099]
  [-8.09143066]
  [-7.94253826]
  [-8.01784134]
  [-8.14334488]
  [-7.99982309]
  [-8.15203571]
  [-8.07125854]
  [-8.14322281]
  [-7.94757223]
  [-7.94925451]
  [-7.95471573]
  [-7.96874189]
  [-7.98708439]
  [-7.96486235]]

 [[-9.55476379]
  [-9.55072117]
  [-9.6340704 ]
  [-9.56571293]
  [-9.69702244]
  [-9.56044006]
  [-9.71098042]
  [-9.54591751]
  [-9.62861919]
  [-9.76583958]
  [-9.6077795 ]
  [-9.77505493]
  [-9.6882391 ]
  [-9.76455975]
  [-9.55171204]
  [-9.55377483]
  [-9.55975533]
  [-9.57562733]
  [-9.59645557]
  [-9.57115364]]]
After layer sequencemask17_output (10, 20, 1) <class 'numpy.float32'> [[[  5.31198740e-01]
  [  5.31391740e-01]
  [  5.30339301e-01]
  [  5.31176925e-01]
  [  5.30648410e-01]
  [  5.31068683e-01]
  [  5.29236495e-01]
  [  5.31393766e-01]
  [  5.33152521e-01]
  [  5.29171228e-01]
  [  5.31030536e-01]
  [  5.29916167e-01]
  [  5.30279040e-01]
  [  5.30827641e-01]
  [  5.31368494e-01]
  [  5.31339943e-01]
  [  5.31326771e-01]
  [  5.31102240e-01]
  [  5.30703366e-01]
  [  5.31139910e-01]]

 [[  9.23545122e-01]
  [  9.23478007e-01]
  [  9.21939194e-01]
  [  9.23691392e-01]
  [  9.22245562e-01]
  [  9.23720241e-01]
  [  9.21698928e-01]
  [  9.23519075e-01]
  [  9.23545003e-01]
  [  9.20000494e-01]
  [  9.22093153e-01]
  [  9.19834733e-01]
  [  9.22163546e-01]
  [  9.19626236e-01]
  [  9.23555791e-01]
  [  9.23660934e-01]
  [  9.23590422e-01]
  [  9.23452616e-01]
  [  9.23499286e-01]
  [  9.23465967e-01]]

 [[ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]]
After layer swapaxes44_output (20, 10, 1) <class 'numpy.float32'> [[[  5.31198740e-01]
  [  9.23545122e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  5.31391740e-01]
  [  9.23478007e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  5.30339301e-01]
  [  9.21939194e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  5.31176925e-01]
  [  9.23691392e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  5.30648410e-01]
  [  9.22245562e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  5.31068683e-01]
  [  9.23720241e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  5.29236495e-01]
  [  9.21698928e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  5.31393766e-01]
  [  9.23519075e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  5.33152521e-01]
  [  9.23545003e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  5.29171228e-01]
  [  9.20000494e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  5.31030536e-01]
  [  9.22093153e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  5.29916167e-01]
  [  9.19834733e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  5.30279040e-01]
  [  9.22163546e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  5.30827641e-01]
  [  9.19626236e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  5.31368494e-01]
  [  9.23555791e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  5.31339943e-01]
  [  9.23660934e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  5.31326771e-01]
  [  9.23590422e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  5.31102240e-01]
  [  9.23452616e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  5.30703366e-01]
  [  9.23499286e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  5.31139910e-01]
  [  9.23465967e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]]
After layer attention_softmax_0 (20, 10, 1) <class 'numpy.float32'> [[[ 0.40315259]
  [ 0.59684741]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40321517]
  [ 0.59678483]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.4033322 ]
  [ 0.59666777]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40311211]
  [ 0.59688783]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40333289]
  [ 0.59666711]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40307915]
  [ 0.59692085]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40312469]
  [ 0.59687537]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40320578]
  [ 0.59679425]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40362284]
  [ 0.59637719]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40351769]
  [ 0.59648234]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40346152]
  [ 0.59653848]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40373689]
  [ 0.59626311]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40326372]
  [ 0.59673625]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40400654]
  [ 0.59599346]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40319085]
  [ 0.59680909]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40315869]
  [ 0.59684128]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40317249]
  [ 0.59682751]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.4031516 ]
  [ 0.59684837]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.4030444 ]
  [ 0.5969556 ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40315747]
  [ 0.59684247]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]]
After layer batch_dot17_0 (20, 512, 1) <class 'numpy.float32'> [[[ 0.01785545]
  [ 0.03944312]
  [-0.03343313]
  ...,
  [-0.0109566 ]
  [ 0.00999346]
  [-0.02459768]]

 [[ 0.01785394]
  [ 0.03944138]
  [-0.03343031]
  ...,
  [-0.01095626]
  [ 0.00999339]
  [-0.02459878]]

 [[ 0.01785111]
  [ 0.03943811]
  [-0.03342504]
  ...,
  [-0.01095561]
  [ 0.00999325]
  [-0.02460085]]

 ...,
 [[ 0.01785547]
  [ 0.03944315]
  [-0.03343317]
  ...,
  [-0.01095661]
  [ 0.00999346]
  [-0.02459766]]

 [[ 0.01785806]
  [ 0.03944613]
  [-0.033438  ]
  ...,
  [-0.0109572 ]
  [ 0.00999358]
  [-0.02459576]]

 [[ 0.01785533]
  [ 0.03944298]
  [-0.0334329 ]
  ...,
  [-0.01095657]
  [ 0.00999345]
  [-0.02459776]]]
After layer reshape34_0 (20, 512) <class 'numpy.float32'> [[ 0.01785545  0.03944312 -0.03343313 ..., -0.0109566   0.00999346
  -0.02459768]
 [ 0.01785394  0.03944138 -0.03343031 ..., -0.01095626  0.00999339
  -0.02459878]
 [ 0.01785111  0.03943811 -0.03342504 ..., -0.01095561  0.00999325
  -0.02460085]
 ...,
 [ 0.01785547  0.03944315 -0.03343317 ..., -0.01095661  0.00999346
  -0.02459766]
 [ 0.01785806  0.03944613 -0.033438   ..., -0.0109572   0.00999358
  -0.02459576]
 [ 0.01785533  0.03944298 -0.0334329  ..., -0.01095657  0.00999345
  -0.02459776]]
After layer decoder_rnn_hidden_concat_t0_output (20, 1024) <class 'numpy.float32'> [[-0.00120377 -0.91873717  0.19765009 ..., -0.0109566   0.00999346
  -0.02459768]
 [-0.00120312 -0.91875505  0.1977488  ..., -0.01095626  0.00999339
  -0.02459878]
 [-0.00120534 -0.91915458  0.19702041 ..., -0.01095561  0.00999325
  -0.02460085]
 ...,
 [-0.00120314 -0.91875541  0.19746871 ..., -0.01095661  0.00999346
  -0.02459766]
 [-0.00120368 -0.91880071  0.19710863 ..., -0.0109572   0.00999358
  -0.02459576]
 [-0.00120335 -0.91881555  0.19744568 ..., -0.01095657  0.00999345
  -0.02459776]]
After layer decoder_rnn_hidden_fc_t0_output (20, 512) <class 'numpy.float32'> [[-1.97375703  0.21327336 -0.81777996 ...,  1.98382831  2.11768436
  -1.6034528 ]
 [-1.97365725  0.21260041 -0.81748205 ...,  1.98371243  2.11826324
  -1.60334671]
 [-1.97198963  0.21543473 -0.82131815 ...,  1.98118019  2.11554313
  -1.60533214]
 ...,
 [-1.97482491  0.21450756 -0.81957752 ...,  1.98375821  2.11739993
  -1.60438967]
 [-1.97552037  0.21640819 -0.82161957 ...,  1.98346364  2.11617851
  -1.60492337]
 [-1.97413015  0.21412572 -0.81931025 ...,  1.98336697  2.11727691
  -1.60381794]]
After layer decoder_rnn_next_hidden_t0_output (20, 512) <class 'numpy.float32'> [[-0.96212584  0.21009752 -0.67385972 ...,  0.96286702  0.9714641
  -0.92218661]
 [-0.96211839  0.20945418 -0.67369711 ...,  0.96285862  0.97149664
  -0.92217076]
 [-0.96199423  0.21216254 -0.67578673 ...,  0.96267354  0.9713434
  -0.92246723]
 ...,
 [-0.96220511  0.21127693 -0.67483985 ...,  0.96286196  0.97144806
  -0.92232662]
 [-0.96225661  0.213092   -0.67595041 ...,  0.96284044  0.97137928
  -0.92240632]
 [-0.96215355  0.21091211 -0.6746943  ...,  0.9628334   0.97144115
  -0.92224121]]
After layer logits_output (20, 16743) <class 'numpy.float32'> [[-2.01334238 -2.82480073 -2.40717173 ..., -2.09228206 -3.50243235
  -2.58696461]
 [-2.01368213 -2.82484865 -2.4071157  ..., -2.09213138 -3.50238347
  -2.58695889]
 [-2.01178265 -2.82550526 -2.40670347 ..., -2.09380841 -3.50156832
  -2.58801532]
 ...,
 [-2.01355553 -2.82469749 -2.40701723 ..., -2.09236288 -3.50189996
  -2.58774567]
 [-2.01298904 -2.82442379 -2.40699673 ..., -2.09269857 -3.50132775
  -2.58823729]
 [-2.0132494  -2.82466841 -2.40699339 ..., -2.09239173 -3.50181341
  -2.58742499]]
After layer softmax_0 (20, 16743) <class 'numpy.float32'> [[  8.35950004e-07   3.71337393e-07   5.63822425e-07 ...,   7.72497799e-07
    1.88571775e-07   4.71041858e-07]
 [  8.35580806e-07   3.71281402e-07   5.63796561e-07 ...,   7.72535373e-07
    1.88561870e-07   4.70996468e-07]
 [  8.41391341e-07   3.72908886e-07   5.66873098e-07 ...,   7.75130388e-07
    1.89667304e-07   4.72871591e-07]
 ...,
 [  8.37596531e-07   3.72186349e-07   5.65140510e-07 ...,   7.74122157e-07
    1.89084176e-07   4.71701554e-07]
 [  8.40190864e-07   3.73229796e-07   5.66581775e-07 ...,   7.75818876e-07
    1.89670928e-07   4.72661895e-07]
 [  8.37968173e-07   3.72248110e-07   5.65231630e-07 ...,   7.74205603e-07
    1.89126396e-07   4.71917531e-07]]
After layer reshape35_0 (20, 10) <class 'numpy.float32'> [[ 0.40315259  0.59684741  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40321517  0.59678483  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.4033322   0.59666777  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40311211  0.59688783  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40333289  0.59666711  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40307915  0.59692085  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40312469  0.59687537  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40320578  0.59679425  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40362284  0.59637719  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40351769  0.59648234  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40346152  0.59653848  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40373689  0.59626311  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40326372  0.59673625  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40400654  0.59599346  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40319085  0.59680909  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40315869  0.59684128  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40317249  0.59682751  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.4031516   0.59684837  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.4030444   0.5969556   0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40315747  0.59684247  0.          0.          0.          0.          0.
   0.          0.          0.        ]]
After layer target_embed_embed_0 (20, 256) <class 'numpy.float32'> [[-0.05505371 -0.0300293  -0.03598022 ...,  0.08459473 -0.05288696
  -0.01667786]
 [-0.05505371 -0.0300293  -0.03598022 ...,  0.08459473 -0.05288696
  -0.01667786]
 [-0.05505371 -0.0300293  -0.03598022 ...,  0.08459473 -0.05288696
  -0.01667786]
 ...,
 [-0.05505371 -0.0300293  -0.03598022 ...,  0.08459473 -0.05288696
  -0.01667786]
 [-0.05505371 -0.0300293  -0.03598022 ...,  0.08459473 -0.05288696
  -0.01667786]
 [-0.05505371 -0.0300293  -0.03598022 ...,  0.08459473 -0.05288696
  -0.01667786]]
After layer decoder_rnn_concat_target_context_t0_output (20, 768) <class 'numpy.float32'> [[-0.05505371 -0.0300293  -0.03598022 ...,  0.96286702  0.9714641
  -0.92218661]
 [-0.05505371 -0.0300293  -0.03598022 ...,  0.96285862  0.97149664
  -0.92217076]
 [-0.05505371 -0.0300293  -0.03598022 ...,  0.96267354  0.9713434
  -0.92246723]
 ...,
 [-0.05505371 -0.0300293  -0.03598022 ...,  0.96286196  0.97144806
  -0.92232662]
 [-0.05505371 -0.0300293  -0.03598022 ...,  0.96284044  0.97137928
  -0.92240632]
 [-0.05505371 -0.0300293  -0.03598022 ...,  0.9628334   0.97144115
  -0.92224121]]
After layer decoder_rnn_l0_t0_i2h_output (20, 2048) <class 'numpy.float32'> [[-3.19650316  1.60742903  2.44108987 ..., -0.07724949  3.86477661
   0.59623516]
 [-3.19659877  1.60741031  2.44106603 ..., -0.07730059  3.86469984
   0.59647703]
 [-3.19542837  1.60707736  2.44116378 ..., -0.07686426  3.86525512
   0.5986852 ]
 ...,
 [-3.19607401  1.60700989  2.44164467 ..., -0.07694113  3.86449194
   0.59651202]
 [-3.19543982  1.60678399  2.44197035 ..., -0.07661849  3.86432505
   0.59648079]
 [-3.19600534  1.60712981  2.44138026 ..., -0.07702605  3.86448169
   0.59662354]]
After layer decoder_rnn_l0_t0_h2h_output (20, 2048) <class 'numpy.float32'> [[-0.32262871  0.47220033  1.85733378 ...,  0.71264488  1.29551065
   0.17665698]
 [-0.32286632  0.47193545  1.85740244 ...,  0.71252352  1.29484797
   0.1766661 ]
 [-0.32441884  0.4768877   1.855304   ...,  0.71233666  1.29996896
   0.17291419]
 ...,
 [-0.32320467  0.47388032  1.85715103 ...,  0.7124148   1.29638278
   0.17504407]
 [-0.32332218  0.47584036  1.85650885 ...,  0.71204489  1.29830194
   0.1734342 ]
 [-0.3232502   0.47382361  1.85679555 ...,  0.71211404  1.29646575
   0.17503202]]
After layer _plus1062_0 (20, 2048) <class 'numpy.float32'> [[-3.5191319   2.07962942  4.29842377 ...,  0.63539541  5.16028738
   0.77289212]
 [-3.51946497  2.0793457   4.29846859 ...,  0.63522291  5.15954781
   0.77314311]
 [-3.51984715  2.08396506  4.29646778 ...,  0.63547242  5.16522408
   0.77159941]
 ...,
 [-3.51927876  2.08089018  4.2987957  ...,  0.63547367  5.16087484
   0.77155608]
 [-3.51876211  2.08262444  4.29847908 ...,  0.6354264   5.16262722
   0.76991498]
 [-3.51925564  2.08095336  4.29817581 ...,  0.63508797  5.16094732
   0.77165556]]
After layer decoder_rnn_l0_t0_slice_output0 (20, 512) <class 'numpy.float32'> [[-3.5191319   2.07962942  4.29842377 ...,  1.73867285  4.61881447
   2.78122163]
 [-3.51946497  2.0793457   4.29846859 ...,  1.73867631  4.61983633
   2.78101635]
 [-3.51984715  2.08396506  4.29646778 ...,  1.74148452  4.61447763
   2.78129482]
 ...,
 [-3.51927876  2.08089018  4.2987957  ...,  1.73836851  4.61813736
   2.78014898]
 [-3.51876211  2.08262444  4.29847908 ...,  1.73830497  4.61619663
   2.77935076]
 [-3.51925564  2.08095336  4.29817581 ...,  1.73863804  4.61816216
   2.78034735]]
After layer decoder_rnn_l0_t0_slice_output1 (20, 512) <class 'numpy.float32'> [[-1.85338545  2.32265759  2.44231534 ...,  3.16815042 -0.68828726
   1.98921132]
 [-1.85331631  2.32275987  2.44240379 ...,  3.16837168 -0.68771631
   1.9893831 ]
 [-1.85803747  2.32111597  2.4455409  ...,  3.16592574 -0.69000542
   1.98740327]
 ...,
 [-1.85447097  2.32242155  2.44373059 ...,  3.16728568 -0.6875754
   1.98918164]
 [-1.85565603  2.32208014  2.44451118 ...,  3.16589856 -0.6881519
   1.98872113]
 [-1.85459006  2.32248974  2.44311953 ...,  3.16706991 -0.6880641
   1.98885822]]
After layer decoder_rnn_l0_t0_slice_output2 (20, 512) <class 'numpy.float32'> [[-2.81703138 -3.09714198  2.85294175 ...,  4.26233292 -0.08227941
   2.16037154]
 [-2.81696439 -3.09725237  2.85285807 ...,  4.26248217 -0.08226761
   2.15996408]
 [-2.81974721 -3.09901786  2.86155128 ...,  4.25808811 -0.08487993
   2.15944529]
 ...,
 [-2.81743693 -3.09924555  2.8552947  ...,  4.2598238  -0.08376166
   2.15934372]
 [-2.81775641 -3.10065985  2.85699224 ...,  4.25729561 -0.08527961
   2.15916061]
 [-2.81725025 -3.09851146  2.85458708 ...,  4.26006413 -0.08371952
   2.15962124]]
After layer decoder_rnn_l0_t0_slice_output3 (20, 512) <class 'numpy.float32'> [[-3.27619886  2.42377019 -1.40095961 ...,  0.63539541  5.16028738
   0.77289212]
 [-3.27637124  2.42397475 -1.40035439 ...,  0.63522291  5.15954781
   0.77314311]
 [-3.27348304  2.42855191 -1.40432966 ...,  0.63547242  5.16522408
   0.77159941]
 ...,
 [-3.27633286  2.42398667 -1.40196252 ...,  0.63547367  5.16087484
   0.77155608]
 [-3.27618337  2.4244709  -1.40402949 ...,  0.6354264   5.16262722
   0.76991498]
 [-3.2761507   2.42463827 -1.40205598 ...,  0.63508797  5.16094732
   0.77165556]]
After layer decoder_rnn_l0_t0_o_output (20, 512) <class 'numpy.float32'> [[ 0.03639679  0.91862202  0.19766389 ...,  0.65371186  0.99429274
   0.68414623]
 [ 0.03639075  0.91863728  0.19775988 ...,  0.65367281  0.99428844
   0.68420047]
 [ 0.03649217  0.91897875  0.19712996 ...,  0.65372926  0.99432063
   0.6838668 ]
 ...,
 [ 0.0363921   0.91863817  0.19750488 ...,  0.65372956  0.99429601
   0.68385738]
 [ 0.03639734  0.91867441  0.19717747 ...,  0.65371889  0.99430603
   0.6835025 ]
 [ 0.03639849  0.91868687  0.19749007 ...,  0.65364224  0.99429649
   0.6838789 ]]
After layer decoder_rnn_l0_t0_f_output (20, 512) <class 'numpy.float32'> [[ 0.1354759   0.9107362   0.91999769 ...,  0.95961797  0.33441418
   0.87965965]
 [ 0.135484    0.91074449  0.92000413 ...,  0.95962656  0.33454129
   0.87967783]
 [ 0.13493195  0.91061085  0.92023474 ...,  0.95953172  0.33403188
   0.87946814]
 ...,
 [ 0.13534881  0.91071701  0.92010176 ...,  0.95958447  0.33457267
   0.87965655]
 [ 0.13521019  0.91068923  0.92015916 ...,  0.95953059  0.33444431
   0.87960774]
 [ 0.13533486  0.91072255  0.92005682 ...,  0.95957607  0.33446386
   0.87962234]]
After layer _mul2124_0 (20, 512) <class 'numpy.float32'> [[ -4.48106648e-03  -6.82036114e+00   8.01849651e+00 ...,   9.57336998e+00
   -4.08402719e-02   5.68033648e+00]
 [ -4.47991863e-03  -6.82132435e+00   7.99917936e+00 ...,   9.50559616e+00
   -4.09553684e-02   5.65785122e+00]
 [ -4.45618806e-03  -6.79589653e+00   8.02801514e+00 ...,   9.40896320e+00
   -4.22187112e-02   5.61194468e+00]
 ...,
 [ -4.47559403e-03  -6.81932163e+00   7.98360729e+00 ...,   9.46506310e+00
   -4.19725366e-02   5.62636232e+00]
 [ -4.47245035e-03  -6.81911802e+00   7.98568153e+00 ...,   9.45252705e+00
   -4.29010428e-02   5.61788750e+00]
 [ -4.47494071e-03  -6.82247257e+00   7.99484491e+00 ...,   9.45809746e+00
   -4.18920927e-02   5.63569546e+00]]
After layer decoder_rnn_l0_t0_i_output (20, 512) <class 'numpy.float32'> [[ 0.02877274  0.88890743  0.98659223 ...,  0.85051841  0.99023193
   0.94165266]
 [ 0.02876344  0.88887948  0.98659283 ...,  0.85051888  0.99024171
   0.94164133]
 [ 0.02875276  0.88933492  0.98656636 ...,  0.8508755   0.99018985
   0.94165665]
 ...,
 [ 0.02876864  0.88903189  0.98659724 ...,  0.85047972  0.99022537
   0.94159365]
 [ 0.02878308  0.88920283  0.98659295 ...,  0.85047162  0.99020654
   0.94154972]
 [ 0.02876929  0.88903809  0.98658895 ...,  0.85051405  0.99022561
   0.94160455]]
After layer decoder_rnn_l0_t0_c_output (20, 512) <class 'numpy.float32'> [[-0.99287742 -0.9959262   0.9933694  ...,  0.99960303 -0.08209424
   0.97376859]
 [-0.99287647 -0.9959271   0.99336827 ...,  0.99960315 -0.08208252
   0.97374749]
 [-0.99291587 -0.9959414   0.99348223 ...,  0.9995997  -0.08467668
   0.97372061]
 ...,
 [-0.99288315 -0.99594325  0.99340039 ...,  0.99960107 -0.08356632
   0.97371531]
 [-0.99288768 -0.99595469  0.99342269 ...,  0.99959904 -0.08507348
   0.97370583]
 [-0.99288052 -0.99593729  0.9933911  ...,  0.99960124 -0.08352447
   0.97372973]]
After layer _mul2125_0 (20, 512) <class 'numpy.float32'> [[-0.02856781 -0.88528621  0.98005056 ...,  0.8501808  -0.08129235
   0.91695178]
 [-0.02855854 -0.88525915  0.98005003 ...,  0.85018134 -0.08128154
   0.9169209 ]
 [-0.02854908 -0.88572544  0.98013616 ...,  0.85053492 -0.083846
   0.91691047]
 ...,
 [-0.0285639  -0.88542533  0.98008609 ...,  0.85014045 -0.08274949
   0.91684413]
 [-0.02857837 -0.88560575  0.98010379 ...,  0.85013062 -0.08424032
   0.91679245]
 [-0.02856447 -0.88542616  0.98006868 ...,  0.8501749  -0.08270808
   0.91686833]]
After layer decoder_rnn_l0_t0_state_0 (20, 512) <class 'numpy.float32'> [[ -0.03304888  -7.70564747   8.9985466  ...,  10.42355061  -0.12213261
    6.59728813]
 [ -0.03303846  -7.7065835    8.97922897 ...,  10.35577774  -0.12223691
    6.57477188]
 [ -0.03300526  -7.68162203   9.00815105 ...,  10.2594986   -0.1260647
    6.52885532]
 ...,
 [ -0.0330395   -7.7047472    8.96369362 ...,  10.31520367  -0.12472203
    6.54320621]
 [ -0.03305082  -7.70472383   8.96578503 ...,  10.30265808  -0.12714136
    6.53467989]
 [ -0.03303941  -7.70789862   8.9749136  ...,  10.30827236  -0.12460017
    6.55256367]]
After layer activation1062_output (20, 512) <class 'numpy.float32'> [[-0.03303685 -0.99999958  0.99999994 ...,  1.         -0.12152896
   0.9999963 ]
 [-0.03302645 -0.99999958  0.99999994 ...,  1.         -0.12163171
   0.99999613]
 [-0.03299328 -0.99999958  0.99999994 ...,  1.         -0.12540111
   0.99999571]
 ...,
 [-0.03302748 -0.99999958  0.99999994 ...,  1.         -0.12407933
   0.99999583]
 [-0.03303879 -0.99999958  0.99999994 ...,  1.         -0.12646069
   0.99999577]
 [-0.03302739 -0.99999958  0.99999994 ...,  1.         -0.12395934
   0.99999595]]
After layer decoder_rnn_l0_t0_out_0 (20, 512) <class 'numpy.float32'> [[-0.00120244 -0.91862166  0.19766387 ...,  0.65371186 -0.12083536
   0.68414372]
 [-0.00120186 -0.91863692  0.19775987 ...,  0.65367281 -0.120937
   0.68419784]
 [-0.001204   -0.91897839  0.19712995 ...,  0.65372926 -0.12468891
   0.68386388]
 ...,
 [-0.00120194 -0.91863781  0.19750486 ...,  0.65372956 -0.12337159
   0.68385452]
 [-0.00120252 -0.91867405  0.19717745 ...,  0.65371889 -0.12574062
   0.68349957]
 [-0.00120215 -0.91868651  0.19749005 ...,  0.65364224 -0.12325234
   0.6838761 ]]
After layer expand_dims1071_0 (20, 512, 1) <class 'numpy.float32'> [[[-0.00120244]
  [-0.91862166]
  [ 0.19766387]
  ...,
  [ 0.65371186]
  [-0.12083536]
  [ 0.68414372]]

 [[-0.00120186]
  [-0.91863692]
  [ 0.19775987]
  ...,
  [ 0.65367281]
  [-0.120937  ]
  [ 0.68419784]]

 [[-0.001204  ]
  [-0.91897839]
  [ 0.19712995]
  ...,
  [ 0.65372926]
  [-0.12468891]
  [ 0.68386388]]

 ...,
 [[-0.00120194]
  [-0.91863781]
  [ 0.19750486]
  ...,
  [ 0.65372956]
  [-0.12337159]
  [ 0.68385452]]

 [[-0.00120252]
  [-0.91867405]
  [ 0.19717745]
  ...,
  [ 0.65371889]
  [-0.12574062]
  [ 0.68349957]]

 [[-0.00120215]
  [-0.91868651]
  [ 0.19749005]
  ...,
  [ 0.65364224]
  [-0.12325234]
  [ 0.6838761 ]]]
After layer att_batch_dot_0 (20, 10, 1) <class 'numpy.float32'> [[[ 0.5313822 ]
  [ 0.92399532]
  [ 1.63672185]
  [ 2.60730672]
  [ 2.52828288]
  [ 0.27943385]
  [-2.96349072]
  [-5.81069708]
  [-7.95248413]
  [-9.55795956]]

 [[ 0.5315659 ]
  [ 0.92396963]
  [ 1.63698375]
  [ 2.60790253]
  [ 2.52942824]
  [ 0.28120112]
  [-2.96118021]
  [-5.80786848]
  [-7.94917202]
  [-9.55415154]]

 [[ 0.53060514]
  [ 0.92250967]
  [ 1.63131809]
  [ 2.59642839]
  [ 2.50799847]
  [ 0.24632055]
  [-3.00953841]
  [-5.86798382]
  [-8.01857281]
  [-9.63028526]]

 [[ 0.53133488]
  [ 0.92412364]
  [ 1.63681161]
  [ 2.60743403]
  [ 2.52774215]
  [ 0.27700162]
  [-2.96842718]
  [-5.81802559]
  [-7.9617219 ]
  [-9.5685339 ]]

 [[ 0.53090143]
  [ 0.9228934 ]
  [ 1.63074839]
  [ 2.59392285]
  [ 2.49950147]
  [ 0.22675645]
  [-3.04182935]
  [-5.91183138]
  [-8.07149315]
  [-9.68959332]]

 [[ 0.53127342]
  [ 0.92421287]
  [ 1.63710284]
  [ 2.60778022]
  [ 2.52845526]
  [ 0.27866414]
  [-2.96551847]
  [-5.81394529]
  [-7.9567647 ]
  [-9.56302643]]

 [[ 0.52951235]
  [ 0.92222518]
  [ 1.62870157]
  [ 2.59040403]
  [ 2.49392176]
  [ 0.21907562]
  [-3.05124664]
  [-5.92280102]
  [-8.08400917]
  [-9.70364094]]

 [[ 0.53158182]
  [ 0.92401218]
  [ 1.63703847]
  [ 2.60795307]
  [ 2.52978587]
  [ 0.28240445]
  [-2.95886374]
  [-5.8044939 ]
  [-7.94494152]
  [-9.54936314]]

 [[ 0.53331292]
  [ 0.92425078]
  [ 1.63540018]
  [ 2.60307622]
  [ 2.51689625]
  [ 0.25537661]
  [-3.00198078]
  [-5.86197758]
  [-8.01322556]
  [-9.62449074]]

 [[ 0.52961272]
  [ 0.92092514]
  [ 1.62435973]
  [ 2.58114552]
  [ 2.47713375]
  [ 0.19336545]
  [-3.08509231]
  [-5.96312094]
  [-8.12892818]
  [-9.75139332]]

 [[ 0.53129959]
  [ 0.92276394]
  [ 1.63260937]
  [ 2.59890437]
  [ 2.51316833]
  [ 0.25585631]
  [-2.99519658]
  [-5.84915495]
  [-7.99592543]
  [-9.60459805]]

 [[ 0.5303632 ]
  [ 0.92086911]
  [ 1.62466741]
  [ 2.58161616]
  [ 2.47692823]
  [ 0.19124454]
  [-3.0895927 ]
  [-5.96962833]
  [-8.13668633]
  [-9.75962639]]

 [[ 0.53054786]
  [ 0.92279351]
  [ 1.6306982 ]
  [ 2.59399295]
  [ 2.50025773]
  [ 0.22910015]
  [-3.03751063]
  [-5.90567827]
  [-8.06392765]
  [-9.68109131]]

 [[ 0.53134888]
  [ 0.92089748]
  [ 1.62572646]
  [ 2.58377528]
  [ 2.48067307]
  [ 0.19679236]
  [-3.08236647]
  [-5.96075535]
  [-8.12610531]
  [-9.74731064]]

 [[ 0.53154266]
  [ 0.92403406]
  [ 1.63703036]
  [ 2.60794306]
  [ 2.52938819]
  [ 0.28099227]
  [-2.96159339]
  [-5.80849648]
  [-7.9499712 ]
  [-9.55510044]]

 [[ 0.53150451]
  [ 0.92411441]
  [ 1.63706148]
  [ 2.60800481]
  [ 2.52938294]
  [ 0.28067634]
  [-2.96236968]
  [-5.80976629]
  [-7.9516902 ]
  [-9.55717468]]

 [[ 0.53148806]
  [ 0.9240495 ]
  [ 1.63684833]
  [ 2.60753822]
  [ 2.52828264]
  [ 0.27852932]
  [-2.96566534]
  [-5.81404829]
  [-7.95671463]
  [-9.56269264]]

 [[ 0.53128231]
  [ 0.92394251]
  [ 1.63640809]
  [ 2.60649991]
  [ 2.5256803 ]
  [ 0.27326304]
  [-2.97386026]
  [-5.82489109]
  [-7.96970987]
  [-9.5773735 ]]

 [[ 0.53088814]
  [ 0.92395014]
  [ 1.63581681]
  [ 2.60519719]
  [ 2.52244234]
  [ 0.2665709 ]
  [-2.98451877]
  [-5.83926153]
  [-7.98716593]
  [-9.59715939]]

 [[ 0.53130549]
  [ 0.92392141]
  [ 1.63632679]
  [ 2.60650802]
  [ 2.52610779]
  [ 0.27447855]
  [-2.97177553]
  [-5.82204819]
  [-7.96624994]
  [-9.57338524]]]
After layer swapaxes45_output (10, 20, 1) <class 'numpy.float32'> [[[ 0.5313822 ]
  [ 0.5315659 ]
  [ 0.53060514]
  [ 0.53133488]
  [ 0.53090143]
  [ 0.53127342]
  [ 0.52951235]
  [ 0.53158182]
  [ 0.53331292]
  [ 0.52961272]
  [ 0.53129959]
  [ 0.5303632 ]
  [ 0.53054786]
  [ 0.53134888]
  [ 0.53154266]
  [ 0.53150451]
  [ 0.53148806]
  [ 0.53128231]
  [ 0.53088814]
  [ 0.53130549]]

 [[ 0.92399532]
  [ 0.92396963]
  [ 0.92250967]
  [ 0.92412364]
  [ 0.9228934 ]
  [ 0.92421287]
  [ 0.92222518]
  [ 0.92401218]
  [ 0.92425078]
  [ 0.92092514]
  [ 0.92276394]
  [ 0.92086911]
  [ 0.92279351]
  [ 0.92089748]
  [ 0.92403406]
  [ 0.92411441]
  [ 0.9240495 ]
  [ 0.92394251]
  [ 0.92395014]
  [ 0.92392141]]

 [[ 1.63672185]
  [ 1.63698375]
  [ 1.63131809]
  [ 1.63681161]
  [ 1.63074839]
  [ 1.63710284]
  [ 1.62870157]
  [ 1.63703847]
  [ 1.63540018]
  [ 1.62435973]
  [ 1.63260937]
  [ 1.62466741]
  [ 1.6306982 ]
  [ 1.62572646]
  [ 1.63703036]
  [ 1.63706148]
  [ 1.63684833]
  [ 1.63640809]
  [ 1.63581681]
  [ 1.63632679]]

 [[ 2.60730672]
  [ 2.60790253]
  [ 2.59642839]
  [ 2.60743403]
  [ 2.59392285]
  [ 2.60778022]
  [ 2.59040403]
  [ 2.60795307]
  [ 2.60307622]
  [ 2.58114552]
  [ 2.59890437]
  [ 2.58161616]
  [ 2.59399295]
  [ 2.58377528]
  [ 2.60794306]
  [ 2.60800481]
  [ 2.60753822]
  [ 2.60649991]
  [ 2.60519719]
  [ 2.60650802]]

 [[ 2.52828288]
  [ 2.52942824]
  [ 2.50799847]
  [ 2.52774215]
  [ 2.49950147]
  [ 2.52845526]
  [ 2.49392176]
  [ 2.52978587]
  [ 2.51689625]
  [ 2.47713375]
  [ 2.51316833]
  [ 2.47692823]
  [ 2.50025773]
  [ 2.48067307]
  [ 2.52938819]
  [ 2.52938294]
  [ 2.52828264]
  [ 2.5256803 ]
  [ 2.52244234]
  [ 2.52610779]]

 [[ 0.27943385]
  [ 0.28120112]
  [ 0.24632055]
  [ 0.27700162]
  [ 0.22675645]
  [ 0.27866414]
  [ 0.21907562]
  [ 0.28240445]
  [ 0.25537661]
  [ 0.19336545]
  [ 0.25585631]
  [ 0.19124454]
  [ 0.22910015]
  [ 0.19679236]
  [ 0.28099227]
  [ 0.28067634]
  [ 0.27852932]
  [ 0.27326304]
  [ 0.2665709 ]
  [ 0.27447855]]

 [[-2.96349072]
  [-2.96118021]
  [-3.00953841]
  [-2.96842718]
  [-3.04182935]
  [-2.96551847]
  [-3.05124664]
  [-2.95886374]
  [-3.00198078]
  [-3.08509231]
  [-2.99519658]
  [-3.0895927 ]
  [-3.03751063]
  [-3.08236647]
  [-2.96159339]
  [-2.96236968]
  [-2.96566534]
  [-2.97386026]
  [-2.98451877]
  [-2.97177553]]

 [[-5.81069708]
  [-5.80786848]
  [-5.86798382]
  [-5.81802559]
  [-5.91183138]
  [-5.81394529]
  [-5.92280102]
  [-5.8044939 ]
  [-5.86197758]
  [-5.96312094]
  [-5.84915495]
  [-5.96962833]
  [-5.90567827]
  [-5.96075535]
  [-5.80849648]
  [-5.80976629]
  [-5.81404829]
  [-5.82489109]
  [-5.83926153]
  [-5.82204819]]

 [[-7.95248413]
  [-7.94917202]
  [-8.01857281]
  [-7.9617219 ]
  [-8.07149315]
  [-7.9567647 ]
  [-8.08400917]
  [-7.94494152]
  [-8.01322556]
  [-8.12892818]
  [-7.99592543]
  [-8.13668633]
  [-8.06392765]
  [-8.12610531]
  [-7.9499712 ]
  [-7.9516902 ]
  [-7.95671463]
  [-7.96970987]
  [-7.98716593]
  [-7.96624994]]

 [[-9.55795956]
  [-9.55415154]
  [-9.63028526]
  [-9.5685339 ]
  [-9.68959332]
  [-9.56302643]
  [-9.70364094]
  [-9.54936314]
  [-9.62449074]
  [-9.75139332]
  [-9.60459805]
  [-9.75962639]
  [-9.68109131]
  [-9.74731064]
  [-9.55510044]
  [-9.55717468]
  [-9.56269264]
  [-9.5773735 ]
  [-9.59715939]
  [-9.57338524]]]
After layer sequencemask18_output (10, 20, 1) <class 'numpy.float32'> [[[  5.31382203e-01]
  [  5.31565905e-01]
  [  5.30605137e-01]
  [  5.31334877e-01]
  [  5.30901432e-01]
  [  5.31273425e-01]
  [  5.29512346e-01]
  [  5.31581819e-01]
  [  5.33312917e-01]
  [  5.29612720e-01]
  [  5.31299591e-01]
  [  5.30363202e-01]
  [  5.30547857e-01]
  [  5.31348884e-01]
  [  5.31542659e-01]
  [  5.31504512e-01]
  [  5.31488061e-01]
  [  5.31282306e-01]
  [  5.30888140e-01]
  [  5.31305492e-01]]

 [[  9.23995316e-01]
  [  9.23969626e-01]
  [  9.22509670e-01]
  [  9.24123645e-01]
  [  9.22893405e-01]
  [  9.24212873e-01]
  [  9.22225177e-01]
  [  9.24012184e-01]
  [  9.24250782e-01]
  [  9.20925140e-01]
  [  9.22763944e-01]
  [  9.20869112e-01]
  [  9.22793508e-01]
  [  9.20897484e-01]
  [  9.24034059e-01]
  [  9.24114406e-01]
  [  9.24049497e-01]
  [  9.23942506e-01]
  [  9.23950136e-01]
  [  9.23921406e-01]]

 [[ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]]
After layer swapaxes46_output (20, 10, 1) <class 'numpy.float32'> [[[  5.31382203e-01]
  [  9.23995316e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  5.31565905e-01]
  [  9.23969626e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  5.30605137e-01]
  [  9.22509670e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  5.31334877e-01]
  [  9.24123645e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  5.30901432e-01]
  [  9.22893405e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  5.31273425e-01]
  [  9.24212873e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  5.29512346e-01]
  [  9.22225177e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  5.31581819e-01]
  [  9.24012184e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  5.33312917e-01]
  [  9.24250782e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  5.29612720e-01]
  [  9.20925140e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  5.31299591e-01]
  [  9.22763944e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  5.30363202e-01]
  [  9.20869112e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  5.30547857e-01]
  [  9.22793508e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  5.31348884e-01]
  [  9.20897484e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  5.31542659e-01]
  [  9.24034059e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  5.31504512e-01]
  [  9.24114406e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  5.31488061e-01]
  [  9.24049497e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  5.31282306e-01]
  [  9.23942506e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  5.30888140e-01]
  [  9.23950136e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  5.31305492e-01]
  [  9.23921406e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]]
After layer attention_softmax_0 (20, 10, 1) <class 'numpy.float32'> [[[ 0.40308842]
  [ 0.59691161]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40313879]
  [ 0.59686118]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40325889]
  [ 0.59674108]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40304616]
  [ 0.59695387]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40323788]
  [ 0.59676218]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40300989]
  [ 0.59699011]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40306443]
  [ 0.59693557]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40313238]
  [ 0.59686762]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40349156]
  [ 0.5965085 ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40340137]
  [ 0.59659857]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40336484]
  [ 0.59663516]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40359551]
  [ 0.59640449]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40317684]
  [ 0.59682316]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40382597]
  [ 0.596174  ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40311772]
  [ 0.59688234]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.4030892 ]
  [ 0.59691083]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40310082]
  [ 0.59689915]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40307707]
  [ 0.59692293]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40298042]
  [ 0.59701961]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40308774]
  [ 0.59691226]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]]
After layer batch_dot18_0 (20, 512, 1) <class 'numpy.float32'> [[[ 0.017857  ]
  [ 0.03944491]
  [-0.03343602]
  ...,
  [-0.01095696]
  [ 0.00999353]
  [-0.02459654]]

 [[ 0.01785578]
  [ 0.0394435 ]
  [-0.03343375]
  ...,
  [-0.01095668]
  [ 0.00999347]
  [-0.02459743]]

 [[ 0.01785288]
  [ 0.03944016]
  [-0.03342834]
  ...,
  [-0.01095601]
  [ 0.00999334]
  [-0.02459955]]

 ...,
 [[ 0.01785727]
  [ 0.03944523]
  [-0.03343653]
  ...,
  [-0.01095702]
  [ 0.00999355]
  [-0.02459634]]

 [[ 0.01785961]
  [ 0.03944792]
  [-0.03344088]
  ...,
  [-0.01095755]
  [ 0.00999366]
  [-0.02459463]]

 [[ 0.01785701]
  [ 0.03944493]
  [-0.03343605]
  ...,
  [-0.01095696]
  [ 0.00999353]
  [-0.02459653]]]
After layer reshape36_0 (20, 512) <class 'numpy.float32'> [[ 0.017857    0.03944491 -0.03343602 ..., -0.01095696  0.00999353
  -0.02459654]
 [ 0.01785578  0.0394435  -0.03343375 ..., -0.01095668  0.00999347
  -0.02459743]
 [ 0.01785288  0.03944016 -0.03342834 ..., -0.01095601  0.00999334
  -0.02459955]
 ...,
 [ 0.01785727  0.03944523 -0.03343653 ..., -0.01095702  0.00999355
  -0.02459634]
 [ 0.01785961  0.03944792 -0.03344088 ..., -0.01095755  0.00999366
  -0.02459463]
 [ 0.01785701  0.03944493 -0.03343605 ..., -0.01095696  0.00999353
  -0.02459653]]
After layer decoder_rnn_hidden_concat_t0_output (20, 1024) <class 'numpy.float32'> [[-0.00120244 -0.91862166  0.19766387 ..., -0.01095696  0.00999353
  -0.02459654]
 [-0.00120186 -0.91863692  0.19775987 ..., -0.01095668  0.00999347
  -0.02459743]
 [-0.001204   -0.91897839  0.19712995 ..., -0.01095601  0.00999334
  -0.02459955]
 ...,
 [-0.00120194 -0.91863781  0.19750486 ..., -0.01095702  0.00999355
  -0.02459634]
 [-0.00120252 -0.91867405  0.19717745 ..., -0.01095755  0.00999366
  -0.02459463]
 [-0.00120215 -0.91868651  0.19749005 ..., -0.01095696  0.00999353
  -0.02459653]]
After layer decoder_rnn_hidden_fc_t0_output (20, 512) <class 'numpy.float32'> [[-1.97465837  0.2141664  -0.81892067 ...,  1.98430336  2.11898756
  -1.60493934]
 [-1.9745096   0.21353681 -0.81862509 ...,  1.98416758  2.11949301
  -1.60484779]
 [-1.97323     0.21613848 -0.82216644 ...,  1.98201799  2.11700344
  -1.60655916]
 ...,
 [-1.97548974  0.2152645  -0.82051384 ...,  1.98413265  2.11867237
  -1.60582018]
 [-1.97614157  0.21704078 -0.8223781  ...,  1.98388445  2.11755204
  -1.6063354 ]
 [-1.97493577  0.21493161 -0.82026857 ...,  1.9838599   2.11858439
  -1.60529709]]
After layer decoder_rnn_next_hidden_t0_output (20, 512) <class 'numpy.float32'> [[-0.96219271  0.21095099 -0.67448199 ...,  0.96290165  0.97153729
  -0.9224087 ]
 [-0.96218169  0.21034932 -0.67432082 ...,  0.96289176  0.97156566
  -0.92239505]
 [-0.96208662  0.21283451 -0.6762473  ...,  0.96273488  0.97142577
  -0.92264992]
 ...,
 [-0.96225435  0.21199997 -0.67534947 ...,  0.96288919  0.97151965
  -0.92253995]
 [-0.96230263  0.21369576 -0.67636216 ...,  0.96287113  0.97145665
  -0.92261666]
 [-0.96221334  0.21168201 -0.67521608 ...,  0.96286935  0.9715147
  -0.92246205]]
After layer logits_output (20, 16743) <class 'numpy.float32'> [[-2.01430774 -2.82502842 -2.40748525 ..., -2.09237218 -3.50254726
  -2.58789015]
 [-2.01461124 -2.82511234 -2.40744328 ..., -2.09225893 -3.50252247
  -2.58790064]
 [-2.01292872 -2.82567048 -2.40704298 ..., -2.09374237 -3.50179291
  -2.58889937]
 ...,
 [-2.01447678 -2.82501864 -2.40739059 ..., -2.09251952 -3.50211596
  -2.58863187]
 [-2.01396513 -2.82479429 -2.40739131 ..., -2.09284377 -3.50163054
  -2.58909988]
 [-2.01422358 -2.82498741 -2.40735435 ..., -2.09252524 -3.50205112
  -2.58834171]]
After layer softmax_0 (20, 16743) <class 'numpy.float32'> [[  8.35423464e-07   3.71377240e-07   5.63835044e-07 ...,   7.72687599e-07
    1.88613427e-07   4.70764093e-07]
 [  8.35035053e-07   3.71286006e-07   5.63767514e-07 ...,   7.72650310e-07
    1.88587578e-07   4.70683005e-07]
 [  8.40327743e-07   3.72803157e-07   5.66613437e-07 ...,   7.75089575e-07
    1.89602162e-07   4.72397716e-07]
 ...,
 [  8.36838637e-07   3.72072691e-07   5.64938830e-07 ...,   7.74012676e-07
    1.89046261e-07   4.71291372e-07]
 [  8.39156030e-07   3.72995942e-07   5.66212748e-07 ...,   7.75507260e-07
    1.89564730e-07   4.72133365e-07]
 [  8.37127970e-07   3.72118905e-07   5.65011817e-07 ...,   7.74080149e-07
    1.89076104e-07   4.71471765e-07]]
After layer reshape37_0 (20, 10) <class 'numpy.float32'> [[ 0.40308842  0.59691161  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40313879  0.59686118  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40325889  0.59674108  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40304616  0.59695387  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40323788  0.59676218  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40300989  0.59699011  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40306443  0.59693557  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40313238  0.59686762  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40349156  0.5965085   0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40340137  0.59659857  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40336484  0.59663516  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40359551  0.59640449  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40317684  0.59682316  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40382597  0.596174    0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40311772  0.59688234  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.4030892   0.59691083  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40310082  0.59689915  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40307707  0.59692293  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40298042  0.59701961  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40308774  0.59691226  0.          0.          0.          0.          0.
   0.          0.          0.        ]]
After layer target_embed_embed_0 (20, 256) <class 'numpy.float32'> [[-0.05505371 -0.0300293  -0.03598022 ...,  0.08459473 -0.05288696
  -0.01667786]
 [-0.05505371 -0.0300293  -0.03598022 ...,  0.08459473 -0.05288696
  -0.01667786]
 [-0.05505371 -0.0300293  -0.03598022 ...,  0.08459473 -0.05288696
  -0.01667786]
 ...,
 [-0.05505371 -0.0300293  -0.03598022 ...,  0.08459473 -0.05288696
  -0.01667786]
 [-0.05505371 -0.0300293  -0.03598022 ...,  0.08459473 -0.05288696
  -0.01667786]
 [-0.05505371 -0.0300293  -0.03598022 ...,  0.08459473 -0.05288696
  -0.01667786]]
After layer decoder_rnn_concat_target_context_t0_output (20, 768) <class 'numpy.float32'> [[-0.05505371 -0.0300293  -0.03598022 ...,  0.96290165  0.97153729
  -0.9224087 ]
 [-0.05505371 -0.0300293  -0.03598022 ...,  0.96289176  0.97156566
  -0.92239505]
 [-0.05505371 -0.0300293  -0.03598022 ...,  0.96273488  0.97142577
  -0.92264992]
 ...,
 [-0.05505371 -0.0300293  -0.03598022 ...,  0.96288919  0.97151965
  -0.92253995]
 [-0.05505371 -0.0300293  -0.03598022 ...,  0.96287113  0.97145665
  -0.92261666]
 [-0.05505371 -0.0300293  -0.03598022 ...,  0.96286935  0.9715147
  -0.92246205]]
After layer decoder_rnn_l0_t0_i2h_output (20, 2048) <class 'numpy.float32'> [[-3.19708729  1.60744023  2.44188523 ..., -0.0771978   3.86518145
   0.59594679]
 [-3.19719362  1.6074388   2.44186926 ..., -0.07725444  3.86514974
   0.59618729]
 [-3.19607687  1.60702991  2.44199824 ..., -0.07679492  3.86558008
   0.59820533]
 ...,
 [-3.19674301  1.60711074  2.44238544 ..., -0.07693581  3.8650279
   0.59623814]
 [-3.19618154  1.60690975  2.44268322 ..., -0.07663467  3.86491013
   0.59620798]
 [-3.19668055  1.6071943   2.44215083 ..., -0.07699814  3.86500072
   0.59633076]]
After layer decoder_rnn_l0_t0_h2h_output (20, 2048) <class 'numpy.float32'> [[-0.32294801  0.47232085  1.85866737 ...,  0.71336055  1.29527521
   0.17673005]
 [-0.32316127  0.47207087  1.85872662 ...,  0.71327752  1.29467988
   0.17677833]
 [-0.32453176  0.47658288  1.8568604  ...,  0.71327591  1.29931676
   0.17316674]
 ...,
 [-0.32343996  0.47383064  1.8584404  ...,  0.71319473  1.29611814
   0.17533764]
 [-0.32349598  0.47559375  1.8578577  ...,  0.71292144  1.29788601
   0.173893  ]
 [-0.32345876  0.47374558  1.85816312 ...,  0.71298397  1.29616559
   0.17532466]]
After layer _plus1063_0 (20, 2048) <class 'numpy.float32'> [[-3.52003527  2.07976103  4.30055237 ...,  0.63616276  5.16045666
   0.77267683]
 [-3.52035499  2.07950974  4.30059576 ...,  0.6360231   5.15982962
   0.77296561]
 [-3.52060866  2.08361292  4.29885864 ...,  0.63648099  5.16489697
   0.77137208]
 ...,
 [-3.52018309  2.08094144  4.30082607 ...,  0.6362589   5.16114616
   0.77157581]
 [-3.51967764  2.08250356  4.30054092 ...,  0.6362868   5.16279602
   0.77010095]
 [-3.52013922  2.08093977  4.30031395 ...,  0.63598585  5.16116619
   0.77165544]]
After layer decoder_rnn_l0_t0_slice_output0 (20, 512) <class 'numpy.float32'> [[-3.52003527  2.07976103  4.30055237 ...,  1.73883545  4.62048769
   2.78058553]
 [-3.52035499  2.07950974  4.30059576 ...,  1.73888361  4.62137079
   2.78045273]
 [-3.52060866  2.08361292  4.29885864 ...,  1.74135756  4.61648178
   2.78067827]
 ...,
 [-3.52018309  2.08094144  4.30082607 ...,  1.73870564  4.61979294
   2.77967262]
 [-3.51967764  2.08250356  4.30054092 ...,  1.73868227  4.61798286
   2.77896547]
 [-3.52013922  2.08093977  4.30031395 ...,  1.73890817  4.61982536
   2.77987695]]
After layer decoder_rnn_l0_t0_slice_output1 (20, 512) <class 'numpy.float32'> [[-1.85304809  2.32254791  2.44427395 ...,  3.16853905 -0.68721581
   1.9906441 ]
 [-1.85302973  2.32263517  2.44436121 ...,  3.16879654 -0.68672085
   1.99081659]
 [-1.8573221   2.32131815  2.44712114 ...,  3.16646576 -0.68866676
   1.988976  ]
 ...,
 [-1.85411954  2.32226777  2.44562078 ...,  3.16784739 -0.68668342
   1.99065471]
 [-1.85518634  2.32194185  2.44638062 ...,  3.16661978 -0.68722689
   1.99027431]
 [-1.854182    2.32237673  2.44505024 ...,  3.16766715 -0.68706417
   1.9903717 ]]
After layer decoder_rnn_l0_t0_slice_output2 (20, 512) <class 'numpy.float32'> [[-2.81704235 -3.09930515  2.85442829 ...,  4.26217937 -0.08201015
   2.15982389]
 [-2.81699371 -3.09937763  2.85440111 ...,  4.26237679 -0.08193561
   2.15946913]
 [-2.81952739 -3.10107088  2.86227894 ...,  4.25812626 -0.08438095
   2.15888166]
 ...,
 [-2.81749487 -3.10121918  2.85671186 ...,  4.25999928 -0.08320296
   2.15891075]
 [-2.81784368 -3.10254478  2.85831928 ...,  4.2576952  -0.08453307
   2.15875673]
 [-2.81732798 -3.10053992  2.85603857 ...,  4.26020527 -0.08318564
   2.15916157]]
After layer decoder_rnn_l0_t0_slice_output3 (20, 512) <class 'numpy.float32'> [[-3.27638841  2.42248583 -1.40099359 ...,  0.63616276  5.16045666
   0.77267683]
 [-3.27651548  2.42266679 -1.40041387 ...,  0.6360231   5.15982962
   0.77296561]
 [-3.27390242  2.4266119  -1.40386009 ...,  0.63648099  5.16489697
   0.77137208]
 ...,
 [-3.27643704  2.42268753 -1.4018873  ...,  0.6362589   5.16114616
   0.77157581]
 [-3.27628326  2.42307615 -1.40377462 ...,  0.6362868   5.16279602
   0.77010095]
 [-3.2762897   2.42321968 -1.40193701 ...,  0.63598585  5.16116619
   0.77165544]]
After layer decoder_rnn_l0_t0_o_output (20, 512) <class 'numpy.float32'> [[ 0.03639015  0.91852593  0.19765849 ...,  0.65388554  0.99429363
   0.68409967]
 [ 0.03638569  0.91853952  0.19775045 ...,  0.65385389  0.99429011
   0.68416202]
 [ 0.03647742  0.91883421  0.19720428 ...,  0.65395755  0.99431878
   0.68381763]
 ...,
 [ 0.03638844  0.91854101  0.1975168  ...,  0.6539073   0.99429756
   0.68386167]
 [ 0.03639384  0.9185701   0.19721782 ...,  0.65391362  0.99430698
   0.68354273]
 [ 0.03639361  0.91858083  0.19750893 ...,  0.65384555  0.99429768
   0.6838789 ]]
After layer decoder_rnn_l0_t0_f_output (20, 512) <class 'numpy.float32'> [[ 0.13551542  0.91072732  0.9201417  ...,  0.95963299  0.33465272
   0.87981129]
 [ 0.13551757  0.91073442  0.92014813 ...,  0.95964301  0.33476293
   0.87982953]
 [ 0.13501549  0.91062725  0.92035067 ...,  0.95955265  0.33432972
   0.8796348 ]
 ...,
 [ 0.13538994  0.91070455  0.92024064 ...,  0.95960623  0.33477128
   0.87981236]
 [ 0.13526511  0.91067803  0.92029637 ...,  0.95955861  0.33465025
   0.87977213]
 [ 0.13538262  0.91071337  0.92019874 ...,  0.9595992   0.33468649
   0.8797825 ]]
After layer _mul2126_0 (20, 512) <class 'numpy.float32'> [[ -4.47863247e-03  -7.01774359e+00   8.27993774e+00 ...,   1.00027828e+01
   -4.08720113e-02   5.80436850e+00]
 [ -4.47729183e-03  -7.01865101e+00   8.26222038e+00 ...,   9.93785000e+00
   -4.09203842e-02   5.78467846e+00]
 [ -4.45622159e-03  -6.99509430e+00   8.29065800e+00 ...,   9.84452915e+00
   -4.21471782e-02   5.74300814e+00]
 ...,
 [ -4.47321543e-03  -7.01674843e+00   8.24875546e+00 ...,   9.89853382e+00
   -4.17533554e-02   5.75679350e+00]
 [ -4.47062217e-03  -7.01652288e+00   8.25117970e+00 ...,   9.88600445e+00
   -4.25478853e-02   5.74902916e+00]
 [ -4.47296165e-03  -7.01968622e+00   8.25870419e+00 ...,   9.89180946e+00
   -4.17019948e-02   5.76483107e+00]]
After layer decoder_rnn_l0_t0_i_output (20, 512) <class 'numpy.float32'> [[ 0.02874751  0.88892043  0.98662043 ...,  0.85053915  0.99024802
   0.94161767]
 [ 0.02873858  0.88889569  0.9866209  ...,  0.85054523  0.99025655
   0.94161034]
 [ 0.0287315   0.88930023  0.98659801 ...,  0.85085946  0.99020922
   0.94162273]
 ...,
 [ 0.02874338  0.88903695  0.986624   ...,  0.85052258  0.99024135
   0.94156742]
 [ 0.0287575   0.88919097  0.98662019 ...,  0.85051966  0.99022382
   0.94152856]
 [ 0.02874461  0.88903677  0.98661721 ...,  0.85054833  0.99024159
   0.94157863]]
After layer decoder_rnn_l0_t0_c_output (20, 512) <class 'numpy.float32'> [[-0.99287754 -0.99594373  0.99338901 ...,  0.99960291 -0.08182678
   0.97374022]
 [-0.99287689 -0.99594432  0.99338865 ...,  0.99960309 -0.08175275
   0.97372186]
 [-0.99291277 -0.99595803  0.99349165 ...,  0.9995997  -0.08418126
   0.97369134]
 ...,
 [-0.99288398 -0.99595922  0.99341905 ...,  0.99960119 -0.08301149
   0.97369289]
 [-0.99288893 -0.99596989  0.99344009 ...,  0.99959934 -0.08433229
   0.97368485]
 [-0.9928816  -0.99595374  0.99341017 ...,  0.99960136 -0.0829943
   0.97370589]]
After layer _mul2127_0 (20, 512) <class 'numpy.float32'> [[-0.02854276 -0.8853147   0.98009789 ...,  0.85020143 -0.08102881
   0.91689098]
 [-0.02853388 -0.88529062  0.98009801 ...,  0.85020763 -0.08095619
   0.91686654]
 [-0.02852788 -0.88570571  0.98017687 ...,  0.85051888 -0.08335706
   0.91684991]
 ...,
 [-0.02853885 -0.88544458  0.98013109 ...,  0.85018337 -0.08220141
   0.91679752]
 [-0.028553   -0.88560742  0.98014808 ...,  0.8501789  -0.08350784
   0.9167521 ]
 [-0.02853999 -0.88543952  0.98011559 ...,  0.8502093  -0.0821844
   0.91682065]]
After layer decoder_rnn_l0_t0_state_0 (20, 512) <class 'numpy.float32'> [[ -0.03302139  -7.90305805   9.26003551 ...,  10.85298443  -0.12190083
    6.72125959]
 [ -0.03301117  -7.90394163   9.24231815 ...,  10.78805733  -0.12187658
    6.70154476]
 [ -0.0329841   -7.88080025   9.27083492 ...,  10.69504833  -0.12550424
    6.65985823]
 ...,
 [ -0.03301206  -7.90219307   9.2288866  ...,  10.74871731  -0.12395477
    6.67359114]
 [ -0.03302363  -7.90213013   9.23132801 ...,  10.73618317  -0.12605573
    6.66578102]
 [ -0.03301295  -7.90512562   9.23882008 ...,  10.7420187   -0.1238864
    6.68165159]]
After layer activation1063_output (20, 512) <class 'numpy.float32'> [[-0.0330094  -0.9999997   1.         ...,  1.         -0.12130059
   0.99999708]
 [-0.03299918 -0.9999997   1.         ...,  1.         -0.1212767
   0.99999696]
 [-0.03297214 -0.9999997   1.         ...,  1.         -0.12484942
   0.99999672]
 ...,
 [-0.03300007 -0.9999997   1.         ...,  1.         -0.12332381
   0.99999678]
 [-0.03301163 -0.9999997   1.         ...,  1.         -0.12539227
   0.99999678]
 [-0.03300096 -0.9999997   1.         ...,  1.         -0.12325647
   0.99999684]]
After layer decoder_rnn_l0_t0_out_0 (20, 512) <class 'numpy.float32'> [[-0.00120122 -0.91852564  0.19765849 ...,  0.65388554 -0.1206084
   0.68409765]
 [-0.0012007  -0.91853923  0.19775045 ...,  0.65385389 -0.12058422
   0.68415993]
 [-0.00120274 -0.91883391  0.19720428 ...,  0.65395755 -0.12414012
   0.68381536]
 ...,
 [-0.00120082 -0.91854072  0.1975168  ...,  0.6539073  -0.12262056
   0.68385947]
 [-0.00120142 -0.9185698   0.19721782 ...,  0.65391362 -0.12467841
   0.68354052]
 [-0.00120102 -0.91858053  0.19750893 ...,  0.65384555 -0.12255362
   0.68387675]]
After layer expand_dims1072_0 (20, 512, 1) <class 'numpy.float32'> [[[-0.00120122]
  [-0.91852564]
  [ 0.19765849]
  ...,
  [ 0.65388554]
  [-0.1206084 ]
  [ 0.68409765]]

 [[-0.0012007 ]
  [-0.91853923]
  [ 0.19775045]
  ...,
  [ 0.65385389]
  [-0.12058422]
  [ 0.68415993]]

 [[-0.00120274]
  [-0.91883391]
  [ 0.19720428]
  ...,
  [ 0.65395755]
  [-0.12414012]
  [ 0.68381536]]

 ...,
 [[-0.00120082]
  [-0.91854072]
  [ 0.1975168 ]
  ...,
  [ 0.6539073 ]
  [-0.12262056]
  [ 0.68385947]]

 [[-0.00120142]
  [-0.9185698 ]
  [ 0.19721782]
  ...,
  [ 0.65391362]
  [-0.12467841]
  [ 0.68354052]]

 [[-0.00120102]
  [-0.91858053]
  [ 0.19750893]
  ...,
  [ 0.65384555]
  [-0.12255362]
  [ 0.68387675]]]
After layer att_batch_dot_0 (20, 10, 1) <class 'numpy.float32'> [[[ 0.53156549]
  [ 0.92451859]
  [ 1.6381861 ]
  [ 2.60957551]
  [ 2.53084612]
  [ 0.28128159]
  [-2.96289968]
  [-5.81132269]
  [-7.95413351]
  [-9.56044006]]

 [[ 0.53174126]
  [ 0.92452216]
  [ 1.63842762]
  [ 2.61010957]
  [ 2.53188825]
  [ 0.28292298]
  [-2.96072721]
  [-5.80866241]
  [-7.9509902 ]
  [-9.55688286]]

 [[ 0.53085834]
  [ 0.92312187]
  [ 1.63316202]
  [ 2.59955525]
  [ 2.51227283]
  [ 0.25102589]
  [-3.00495958]
  [-5.86370039]
  [-8.01462364]
  [-9.62673378]]

 [[ 0.53150487]
  [ 0.92463619]
  [ 1.63818312]
  [ 2.60949659]
  [ 2.53005552]
  [ 0.27871487]
  [-2.96775365]
  [-5.81836939]
  [-7.96292925]
  [-9.57048416]]

 [[ 0.53114784]
  [ 0.92357093]
  [ 1.63254654]
  [ 2.59696746]
  [ 2.5039866 ]
  [ 0.23241782]
  [-3.03537893]
  [-5.90486526]
  [-8.06427383]
  [-9.68240643]]

 [[ 0.5314756 ]
  [ 0.92476791]
  [ 1.63859832]
  [ 2.61010075]
  [ 2.53112364]
  [ 0.2807233 ]
  [-2.96459985]
  [-5.81414461]
  [-7.95788383]
  [-9.56492519]]

 [[ 0.52979451]
  [ 0.92282099]
  [ 1.63051569]
  [ 2.59351754]
  [ 2.49850225]
  [ 0.22480892]
  [-3.04476857]
  [-5.91583395]
  [-8.0767622 ]
  [-9.69639301]]

 [[ 0.53176475]
  [ 0.92456454]
  [ 1.63854134]
  [ 2.61029029]
  [ 2.5324254 ]
  [ 0.28427553]
  [-2.9583416 ]
  [-5.80530787]
  [-7.94685888]
  [-9.55218983]]

 [[ 0.53345889]
  [ 0.92495376]
  [ 1.63702297]
  [ 2.60571408]
  [ 2.52055836]
  [ 0.25965688]
  [-2.99747086]
  [-5.85745907]
  [-8.00887203]
  [-9.62054539]]

 [[ 0.5299983 ]
  [ 0.92179364]
  [ 1.62688208]
  [ 2.5857358 ]
  [ 2.48424578]
  [ 0.20267123]
  [-3.07424927]
  [-5.95126343]
  [-8.11649227]
  [-9.73882771]]

 [[ 0.53154355]
  [ 0.92344511]
  [ 1.63453639]
  [ 2.60219765]
  [ 2.51761913]
  [ 0.2605994 ]
  [-2.99082398]
  [-5.84533691]
  [-7.99267292]
  [-9.60194683]]

 [[ 0.53074276]
  [ 0.92181021]
  [ 1.62712264]
  [ 2.58600593]
  [ 2.48383021]
  [ 0.20053139]
  [-3.07848024]
  [-5.95726013]
  [-8.12360668]
  [-9.74638557]]

 [[ 0.53081125]
  [ 0.92346138]
  [ 1.63254058]
  [ 2.59714532]
  [ 2.50487757]
  [ 0.23483001]
  [-3.03111172]
  [-5.89888048]
  [-8.05695915]
  [-9.67420864]]

 [[ 0.53176391]
  [ 0.92198634]
  [ 1.62827766]
  [ 2.58826375]
  [ 2.48775959]
  [ 0.20645739]
  [-3.07064819]
  [-5.94760084]
  [-8.11216831]
  [-9.73320675]]

 [[ 0.53171915]
  [ 0.92457771]
  [ 1.63847041]
  [ 2.61014557]
  [ 2.53185153]
  [ 0.28272319]
  [-2.96112299]
  [-5.80925846]
  [-7.95176172]
  [-9.5577879 ]]

 [[ 0.53167456]
  [ 0.92464054]
  [ 1.63847244]
  [ 2.61015201]
  [ 2.53176403]
  [ 0.28233361]
  [-2.96193957]
  [-5.81052828]
  [-7.95343685]
  [-9.55976963]]

 [[ 0.53165674]
  [ 0.92458069]
  [ 1.63825655]
  [ 2.60968232]
  [ 2.53070164]
  [ 0.28031093]
  [-2.96499681]
  [-5.81448746]
  [-7.95807648]
  [-9.5648756 ]]

 [[ 0.53147012]
  [ 0.92450035]
  [ 1.6378392 ]
  [ 2.60868478]
  [ 2.5282402 ]
  [ 0.27540001]
  [-2.97260284]
  [-5.82450533]
  [-7.9701004 ]
  [-9.57842255]]

 [[ 0.53108639]
  [ 0.92448139]
  [ 1.63721371]
  [ 2.60732102]
  [ 2.52499986]
  [ 0.26889998]
  [-2.98279643]
  [-5.83815575]
  [-7.98660755]
  [-9.59712124]]

 [[ 0.53148085]
  [ 0.92445099]
  [ 1.6377368 ]
  [ 2.60865283]
  [ 2.52857161]
  [ 0.27644062]
  [-2.97077131]
  [-5.82199287]
  [-7.96700954]
  [-9.57488155]]]
After layer swapaxes47_output (10, 20, 1) <class 'numpy.float32'> [[[ 0.53156549]
  [ 0.53174126]
  [ 0.53085834]
  [ 0.53150487]
  [ 0.53114784]
  [ 0.5314756 ]
  [ 0.52979451]
  [ 0.53176475]
  [ 0.53345889]
  [ 0.5299983 ]
  [ 0.53154355]
  [ 0.53074276]
  [ 0.53081125]
  [ 0.53176391]
  [ 0.53171915]
  [ 0.53167456]
  [ 0.53165674]
  [ 0.53147012]
  [ 0.53108639]
  [ 0.53148085]]

 [[ 0.92451859]
  [ 0.92452216]
  [ 0.92312187]
  [ 0.92463619]
  [ 0.92357093]
  [ 0.92476791]
  [ 0.92282099]
  [ 0.92456454]
  [ 0.92495376]
  [ 0.92179364]
  [ 0.92344511]
  [ 0.92181021]
  [ 0.92346138]
  [ 0.92198634]
  [ 0.92457771]
  [ 0.92464054]
  [ 0.92458069]
  [ 0.92450035]
  [ 0.92448139]
  [ 0.92445099]]

 [[ 1.6381861 ]
  [ 1.63842762]
  [ 1.63316202]
  [ 1.63818312]
  [ 1.63254654]
  [ 1.63859832]
  [ 1.63051569]
  [ 1.63854134]
  [ 1.63702297]
  [ 1.62688208]
  [ 1.63453639]
  [ 1.62712264]
  [ 1.63254058]
  [ 1.62827766]
  [ 1.63847041]
  [ 1.63847244]
  [ 1.63825655]
  [ 1.6378392 ]
  [ 1.63721371]
  [ 1.6377368 ]]

 [[ 2.60957551]
  [ 2.61010957]
  [ 2.59955525]
  [ 2.60949659]
  [ 2.59696746]
  [ 2.61010075]
  [ 2.59351754]
  [ 2.61029029]
  [ 2.60571408]
  [ 2.5857358 ]
  [ 2.60219765]
  [ 2.58600593]
  [ 2.59714532]
  [ 2.58826375]
  [ 2.61014557]
  [ 2.61015201]
  [ 2.60968232]
  [ 2.60868478]
  [ 2.60732102]
  [ 2.60865283]]

 [[ 2.53084612]
  [ 2.53188825]
  [ 2.51227283]
  [ 2.53005552]
  [ 2.5039866 ]
  [ 2.53112364]
  [ 2.49850225]
  [ 2.5324254 ]
  [ 2.52055836]
  [ 2.48424578]
  [ 2.51761913]
  [ 2.48383021]
  [ 2.50487757]
  [ 2.48775959]
  [ 2.53185153]
  [ 2.53176403]
  [ 2.53070164]
  [ 2.5282402 ]
  [ 2.52499986]
  [ 2.52857161]]

 [[ 0.28128159]
  [ 0.28292298]
  [ 0.25102589]
  [ 0.27871487]
  [ 0.23241782]
  [ 0.2807233 ]
  [ 0.22480892]
  [ 0.28427553]
  [ 0.25965688]
  [ 0.20267123]
  [ 0.2605994 ]
  [ 0.20053139]
  [ 0.23483001]
  [ 0.20645739]
  [ 0.28272319]
  [ 0.28233361]
  [ 0.28031093]
  [ 0.27540001]
  [ 0.26889998]
  [ 0.27644062]]

 [[-2.96289968]
  [-2.96072721]
  [-3.00495958]
  [-2.96775365]
  [-3.03537893]
  [-2.96459985]
  [-3.04476857]
  [-2.9583416 ]
  [-2.99747086]
  [-3.07424927]
  [-2.99082398]
  [-3.07848024]
  [-3.03111172]
  [-3.07064819]
  [-2.96112299]
  [-2.96193957]
  [-2.96499681]
  [-2.97260284]
  [-2.98279643]
  [-2.97077131]]

 [[-5.81132269]
  [-5.80866241]
  [-5.86370039]
  [-5.81836939]
  [-5.90486526]
  [-5.81414461]
  [-5.91583395]
  [-5.80530787]
  [-5.85745907]
  [-5.95126343]
  [-5.84533691]
  [-5.95726013]
  [-5.89888048]
  [-5.94760084]
  [-5.80925846]
  [-5.81052828]
  [-5.81448746]
  [-5.82450533]
  [-5.83815575]
  [-5.82199287]]

 [[-7.95413351]
  [-7.9509902 ]
  [-8.01462364]
  [-7.96292925]
  [-8.06427383]
  [-7.95788383]
  [-8.0767622 ]
  [-7.94685888]
  [-8.00887203]
  [-8.11649227]
  [-7.99267292]
  [-8.12360668]
  [-8.05695915]
  [-8.11216831]
  [-7.95176172]
  [-7.95343685]
  [-7.95807648]
  [-7.9701004 ]
  [-7.98660755]
  [-7.96700954]]

 [[-9.56044006]
  [-9.55688286]
  [-9.62673378]
  [-9.57048416]
  [-9.68240643]
  [-9.56492519]
  [-9.69639301]
  [-9.55218983]
  [-9.62054539]
  [-9.73882771]
  [-9.60194683]
  [-9.74638557]
  [-9.67420864]
  [-9.73320675]
  [-9.5577879 ]
  [-9.55976963]
  [-9.5648756 ]
  [-9.57842255]
  [-9.59712124]
  [-9.57488155]]]
After layer sequencemask19_output (10, 20, 1) <class 'numpy.float32'> [[[  5.31565487e-01]
  [  5.31741261e-01]
  [  5.30858338e-01]
  [  5.31504869e-01]
  [  5.31147838e-01]
  [  5.31475604e-01]
  [  5.29794514e-01]
  [  5.31764746e-01]
  [  5.33458889e-01]
  [  5.29998302e-01]
  [  5.31543553e-01]
  [  5.30742764e-01]
  [  5.30811250e-01]
  [  5.31763911e-01]
  [  5.31719148e-01]
  [  5.31674564e-01]
  [  5.31656742e-01]
  [  5.31470120e-01]
  [  5.31086385e-01]
  [  5.31480849e-01]]

 [[  9.24518585e-01]
  [  9.24522161e-01]
  [  9.23121870e-01]
  [  9.24636185e-01]
  [  9.23570931e-01]
  [  9.24767911e-01]
  [  9.22820985e-01]
  [  9.24564540e-01]
  [  9.24953759e-01]
  [  9.21793640e-01]
  [  9.23445106e-01]
  [  9.21810210e-01]
  [  9.23461378e-01]
  [  9.21986341e-01]
  [  9.24577713e-01]
  [  9.24640536e-01]
  [  9.24580693e-01]
  [  9.24500346e-01]
  [  9.24481392e-01]
  [  9.24450994e-01]]

 [[ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]]
After layer swapaxes48_output (20, 10, 1) <class 'numpy.float32'> [[[  5.31565487e-01]
  [  9.24518585e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  5.31741261e-01]
  [  9.24522161e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  5.30858338e-01]
  [  9.23121870e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  5.31504869e-01]
  [  9.24636185e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  5.31147838e-01]
  [  9.23570931e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  5.31475604e-01]
  [  9.24767911e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  5.29794514e-01]
  [  9.22820985e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  5.31764746e-01]
  [  9.24564540e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  5.33458889e-01]
  [  9.24953759e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  5.29998302e-01]
  [  9.21793640e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  5.31543553e-01]
  [  9.23445106e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  5.30742764e-01]
  [  9.21810210e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  5.30811250e-01]
  [  9.23461378e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  5.31763911e-01]
  [  9.21986341e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  5.31719148e-01]
  [  9.24577713e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  5.31674564e-01]
  [  9.24640536e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  5.31656742e-01]
  [  9.24580693e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  5.31470120e-01]
  [  9.24500346e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  5.31086385e-01]
  [  9.24481392e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  5.31480849e-01]
  [  9.24450994e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]]
After layer attention_softmax_0 (20, 10, 1) <class 'numpy.float32'> [[[ 0.40300661]
  [ 0.59699339]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40304807]
  [ 0.59695196]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40317249]
  [ 0.59682751]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40296373]
  [ 0.5970363 ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40313411]
  [ 0.59686589]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40292501]
  [ 0.59707505]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40298894]
  [ 0.59701103]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40304348]
  [ 0.59695655]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40335751]
  [ 0.59664249]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40328518]
  [ 0.59671479]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40325963]
  [ 0.59674037]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40346035]
  [ 0.59653962]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40307951]
  [ 0.59692049]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40366375]
  [ 0.59633625]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40302935]
  [ 0.59697068]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40300348]
  [ 0.59699649]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40301365]
  [ 0.59698641]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40298808]
  [ 0.59701198]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40290028]
  [ 0.59709966]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40300253]
  [ 0.5969975 ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]]
After layer batch_dot19_0 (20, 512, 1) <class 'numpy.float32'> [[[ 0.01785897]
  [ 0.03944718]
  [-0.0334397 ]
  ...,
  [-0.01095741]
  [ 0.00999363]
  [-0.02459509]]

 [[ 0.01785797]
  [ 0.03944603]
  [-0.03343783]
  ...,
  [-0.01095718]
  [ 0.00999358]
  [-0.02459583]]

 [[ 0.01785497]
  [ 0.03944257]
  [-0.03343223]
  ...,
  [-0.01095649]
  [ 0.00999344]
  [-0.02459803]]

 ...,
 [[ 0.01785942]
  [ 0.03944771]
  [-0.03344053]
  ...,
  [-0.01095751]
  [ 0.00999365]
  [-0.02459477]]

 [[ 0.01786154]
  [ 0.03945015]
  [-0.03344448]
  ...,
  [-0.010958  ]
  [ 0.00999375]
  [-0.02459322]]

 [[ 0.01785907]
  [ 0.0394473 ]
  [-0.03343988]
  ...,
  [-0.01095743]
  [ 0.00999363]
  [-0.02459502]]]
After layer reshape38_0 (20, 512) <class 'numpy.float32'> [[ 0.01785897  0.03944718 -0.0334397  ..., -0.01095741  0.00999363
  -0.02459509]
 [ 0.01785797  0.03944603 -0.03343783 ..., -0.01095718  0.00999358
  -0.02459583]
 [ 0.01785497  0.03944257 -0.03343223 ..., -0.01095649  0.00999344
  -0.02459803]
 ...,
 [ 0.01785942  0.03944771 -0.03344053 ..., -0.01095751  0.00999365
  -0.02459477]
 [ 0.01786154  0.03945015 -0.03344448 ..., -0.010958    0.00999375
  -0.02459322]
 [ 0.01785907  0.0394473  -0.03343988 ..., -0.01095743  0.00999363
  -0.02459502]]
After layer decoder_rnn_hidden_concat_t0_output (20, 1024) <class 'numpy.float32'> [[-0.00120122 -0.91852564  0.19765849 ..., -0.01095741  0.00999363
  -0.02459509]
 [-0.0012007  -0.91853923  0.19775045 ..., -0.01095718  0.00999358
  -0.02459583]
 [-0.00120274 -0.91883391  0.19720428 ..., -0.01095649  0.00999344
  -0.02459803]
 ...,
 [-0.00120082 -0.91854072  0.1975168  ..., -0.01095751  0.00999365
  -0.02459477]
 [-0.00120142 -0.9185698   0.19721782 ..., -0.010958    0.00999375
  -0.02459322]
 [-0.00120102 -0.91858053  0.19750893 ..., -0.01095743  0.00999363
  -0.02459502]]
After layer decoder_rnn_hidden_fc_t0_output (20, 512) <class 'numpy.float32'> [[-1.97527134  0.21497419 -0.81999141 ...,  1.98451459  2.12013054
  -1.60633099]
 [-1.97508943  0.21438625 -0.81970572 ...,  1.98436928  2.12057328
  -1.60624564]
 [-1.97411382  0.21676487 -0.82296783 ...,  1.98251951  2.11829352
  -1.6077137 ]
 ...,
 [-1.97592199  0.21595858 -0.82141966 ...,  1.9842819   2.11979723
  -1.607149  ]
 [-1.97653198  0.21761626 -0.82312799 ...,  1.98407257  2.11876965
  -1.60764194]
 [-1.97547579  0.21566272 -0.82119119 ...,  1.984097    2.11973596
  -1.60666764]]
After layer decoder_rnn_next_hidden_t0_output (20, 512) <class 'numpy.float32'> [[-0.96223819  0.21172269 -0.67506522 ...,  0.96291703  0.97160137
  -0.922616  ]
 [-0.96222472  0.21116103 -0.67490971 ...,  0.96290648  0.97162616
  -0.92260331]
 [-0.9621523   0.21343245 -0.676682   ...,  0.96277153  0.97149837
  -0.92282146]
 ...,
 [-0.96228635  0.21266276 -0.67584181 ...,  0.9629001   0.97158271
  -0.9227376 ]
 [-0.96233147  0.2142449  -0.67676878 ...,  0.96288484  0.97152507
  -0.92281079]
 [-0.96225333  0.21238026 -0.67571771 ...,  0.96288663  0.97157931
  -0.92266607]]
After layer logits_output (20, 16743) <class 'numpy.float32'> [[-2.0151453  -2.82527208 -2.40781689 ..., -2.09251928 -3.50262356
  -2.58873963]
 [-2.01541376 -2.82538295 -2.40778518 ..., -2.09243393 -3.50261736
  -2.58876181]
 [-2.01391673 -2.82585835 -2.4074018  ..., -2.09375191 -3.501966
  -2.58969712]
 ...,
 [-2.01527882 -2.82532763 -2.40775919 ..., -2.09271002 -3.50226784
  -2.58943987]
 [-2.01481342 -2.82514405 -2.40777373 ..., -2.09302115 -3.50184846
  -2.58988523]
 [-2.01506877 -2.82529354 -2.40771294 ..., -2.09269619 -3.50221801
  -2.58917689]]
After layer softmax_0 (20, 16743) <class 'numpy.float32'> [[  8.34976163e-07   3.71398983e-07   5.63818048e-07 ...,   7.72806516e-07
    1.88655946e-07   4.70506166e-07]
 [  8.34581954e-07   3.71281715e-07   5.63720675e-07 ...,   7.72715055e-07
    1.88618671e-07   4.70399328e-07]
 [  8.39411996e-07   3.72695041e-07   5.66352469e-07 ...,   7.75002832e-07
    1.89549866e-07   4.71972982e-07]
 ...,
 [  8.36214440e-07   3.71978501e-07   5.64761933e-07 ...,   7.73909051e-07
    1.89028171e-07   4.70936641e-07]
 [  8.38300366e-07   3.72801509e-07   5.65899143e-07 ...,   7.75236856e-07
    1.89491018e-07   4.71681631e-07]
 [  8.36444769e-07   3.72015620e-07   5.64825314e-07 ...,   7.73970044e-07
    1.89049942e-07   4.71091482e-07]]
After layer reshape39_0 (20, 10) <class 'numpy.float32'> [[ 0.40300661  0.59699339  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40304807  0.59695196  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40317249  0.59682751  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40296373  0.5970363   0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40313411  0.59686589  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40292501  0.59707505  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40298894  0.59701103  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40304348  0.59695655  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40335751  0.59664249  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40328518  0.59671479  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40325963  0.59674037  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40346035  0.59653962  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40307951  0.59692049  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40366375  0.59633625  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40302935  0.59697068  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40300348  0.59699649  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40301365  0.59698641  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40298808  0.59701198  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40290028  0.59709966  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40300253  0.5969975   0.          0.          0.          0.          0.
   0.          0.          0.        ]]
After layer target_embed_embed_0 (20, 256) <class 'numpy.float32'> [[-0.05505371 -0.0300293  -0.03598022 ...,  0.08459473 -0.05288696
  -0.01667786]
 [-0.05505371 -0.0300293  -0.03598022 ...,  0.08459473 -0.05288696
  -0.01667786]
 [-0.05505371 -0.0300293  -0.03598022 ...,  0.08459473 -0.05288696
  -0.01667786]
 ...,
 [-0.05505371 -0.0300293  -0.03598022 ...,  0.08459473 -0.05288696
  -0.01667786]
 [-0.05505371 -0.0300293  -0.03598022 ...,  0.08459473 -0.05288696
  -0.01667786]
 [-0.05505371 -0.0300293  -0.03598022 ...,  0.08459473 -0.05288696
  -0.01667786]]
After layer decoder_rnn_concat_target_context_t0_output (20, 768) <class 'numpy.float32'> [[-0.05505371 -0.0300293  -0.03598022 ...,  0.96291703  0.97160137
  -0.922616  ]
 [-0.05505371 -0.0300293  -0.03598022 ...,  0.96290648  0.97162616
  -0.92260331]
 [-0.05505371 -0.0300293  -0.03598022 ...,  0.96277153  0.97149837
  -0.92282146]
 ...,
 [-0.05505371 -0.0300293  -0.03598022 ...,  0.9629001   0.97158271
  -0.9227376 ]
 [-0.05505371 -0.0300293  -0.03598022 ...,  0.96288484  0.97152507
  -0.92281079]
 [-0.05505371 -0.0300293  -0.03598022 ...,  0.96288663  0.97157931
  -0.92266607]]
After layer decoder_rnn_l0_t0_i2h_output (20, 2048) <class 'numpy.float32'> [[-3.19762826  1.6075294   2.44262004 ..., -0.0771717   3.86562681
   0.59569699]
 [-3.19774008  1.60753775  2.44260907 ..., -0.07723048  3.86562252
   0.59593385]
 [-3.19667339  1.60707688  2.44275498 ..., -0.07675471  3.86595345
   0.59779102]
 ...,
 [-3.19734883  1.60726655  2.44307089 ..., -0.07694785  3.86556149
   0.59599584]
 [-3.19684768  1.60708499  2.44334435 ..., -0.07666744  3.86547804
   0.59596789]
 [-3.19729185  1.6073215   2.44286036 ..., -0.0769927   3.86551905
   0.59607476]]
After layer decoder_rnn_l0_t0_h2h_output (20, 2048) <class 'numpy.float32'> [[-0.32327789  0.47248477  1.85977411 ...,  0.71393049  1.2950778
   0.17681396]
 [-0.32347074  0.47225285  1.85982203 ...,  0.71387333  1.29454243
   0.17688827]
 [-0.32468951  0.47636676  1.85813344 ...,  0.71400648  1.29875183
   0.1734198 ]
 ...,
 [-0.32370454  0.47385573  1.85951638 ...,  0.71380597  1.2958864
   0.17560074]
 [-0.32371747  0.47545183  1.85898674 ...,  0.71360534  1.2975179
   0.17429569]
 [-0.32370546  0.47375143  1.85929537 ...,  0.71366352  1.29590988
   0.17558424]]
After layer _plus1064_0 (20, 2048) <class 'numpy.float32'> [[-3.52090621  2.08001423  4.30239391 ...,  0.6367588   5.16070461
   0.77251095]
 [-3.52121091  2.07979059  4.30243111 ...,  0.63664287  5.16016483
   0.77282214]
 [-3.52136278  2.08344364  4.30088854 ...,  0.63725179  5.16470528
   0.77121079]
 ...,
 [-3.52105331  2.0811224   4.30258751 ...,  0.63685811  5.161448
   0.77159655]
 [-3.52056503  2.0825367   4.30233097 ...,  0.63693792  5.16299582
   0.77026355]
 [-3.52099729  2.08107281  4.30215549 ...,  0.63667083  5.16142893
   0.77165902]]
After layer decoder_rnn_l0_t0_slice_output0 (20, 512) <class 'numpy.float32'> [[-3.52090621  2.08001423  4.30239391 ...,  1.73912811  4.62197351
   2.77995324]
 [-3.52121091  2.07979059  4.30243111 ...,  1.73920619  4.62274361
   2.77987623]
 [-3.52136278  2.08344364  4.30088854 ...,  1.74139857  4.61825371
   2.78006124]
 ...,
 [-3.52105331  2.0811224   4.30258751 ...,  1.73911965  4.62128258
   2.77916956]
 [-3.52056503  2.0825367   4.30233097 ...,  1.73912239  4.61959791
   2.77853632]
 [-3.52099729  2.08107281  4.30215549 ...,  1.73927057  4.62131929
   2.77937484]]
After layer decoder_rnn_l0_t0_slice_output1 (20, 512) <class 'numpy.float32'> [[-1.85284519  2.32228661  2.44608545 ...,  3.16886854 -0.68641126
   1.9919616 ]
 [-1.85286498  2.32236266  2.44616723 ...,  3.16914272 -0.68597269
   1.99212992]
 [-1.85677791  2.32131577  2.44859004 ...,  3.16692638 -0.68765628
   1.99040771]
 ...,
 [-1.85389471  2.32198286  2.44735837 ...,  3.16830373 -0.68600035
   1.99199533]
 [-1.85486376  2.3216753   2.44808793 ...,  3.16720819 -0.68650818
   1.99167478]
 [-1.85391521  2.32212019  2.44682169 ...,  3.16815305 -0.68629974
   1.99174356]]
After layer decoder_rnn_l0_t0_slice_output2 (20, 512) <class 'numpy.float32'> [[-2.81699443 -3.10129309  2.85588646 ...,  4.26208401 -0.08166677
   2.15932584]
 [-2.81694818 -3.10133147  2.8558979  ...,  4.26231241 -0.08155128
   2.15901566]
 [-2.81927919 -3.10294294  2.86304712 ...,  4.25820732 -0.08383086
   2.15838265]
 ...,
 [-2.81746149 -3.10302544  2.85807657 ...,  4.2601757  -0.08264187
   2.15851188]
 [-2.81781936 -3.10426688  2.85959005 ...,  4.25806761 -0.08381838
   2.15838003]
 [-2.81730843 -3.1024003   2.85743833 ...,  4.26034832 -0.08264238
   2.15873575]]
After layer decoder_rnn_l0_t0_slice_output3 (20, 512) <class 'numpy.float32'> [[-3.27650094  2.42140579 -1.40112758 ...,  0.6367588   5.16070461
   0.77251095]
 [-3.27659464  2.42157006 -1.40057683 ...,  0.63664287  5.16016483
   0.77282214]
 [-3.27423334  2.42500353 -1.40357268 ...,  0.63725179  5.16470528
   0.77121079]
 ...,
 [-3.27648926  2.42159891 -1.40193522 ...,  0.63685811  5.161448
   0.77159655]
 [-3.27633834  2.42191267 -1.40366411 ...,  0.63693792  5.16299582
   0.77026355]
 [-3.27637386  2.42203569 -1.40194976 ...,  0.63667083  5.16142893
   0.77165902]]
After layer decoder_rnn_l0_t0_o_output (20, 512) <class 'numpy.float32'> [[ 0.0363862   0.91844505  0.19763725 ...,  0.65402037  0.99429506
   0.68406379]
 [ 0.03638292  0.91845745  0.19772458 ...,  0.6539942   0.99429202
   0.68413109]
 [ 0.03646579  0.91871417  0.1972498  ...,  0.65413195  0.99431771
   0.68378276]
 ...,
 [ 0.03638661  0.91845953  0.19750921 ...,  0.6540429   0.99429929
   0.68386614]
 [ 0.0363919   0.91848308  0.19723532 ...,  0.65406096  0.99430805
   0.6835779 ]
 [ 0.03639066  0.91849226  0.1975069  ...,  0.65400052  0.99429917
   0.68387967]]
After layer decoder_rnn_l0_t0_f_output (20, 512) <class 'numpy.float32'> [[ 0.13553919  0.91070604  0.92027473 ...,  0.95964575  0.33483189
   0.87995052]
 [ 0.13553686  0.91071224  0.92028069 ...,  0.95965642  0.33492956
   0.87996823]
 [ 0.13507906  0.91062707  0.92045832 ...,  0.95957053  0.33455461
   0.87978625]
 ...,
 [ 0.13541627  0.91068131  0.92036802 ...,  0.95962387  0.33492339
   0.87995404]
 [ 0.13530284  0.91065633  0.92042154 ...,  0.95958143  0.33481032
   0.87992018]
 [ 0.13541386  0.91069251  0.92032874 ...,  0.95961809  0.33485672
   0.87992746]]
After layer _mul2128_0 (20, 512) <class 'numpy.float32'> [[ -4.47569275e-03  -7.19736290e+00   8.52177715e+00 ...,   1.04150200e+01
   -4.08162847e-02   5.91437578e+00]
 [ -4.47423011e-03  -7.19821644e+00   8.50552654e+00 ...,   1.03528280e+01
   -4.08200659e-02   5.89714622e+00]
 [ -4.45546117e-03  -7.17646980e+00   8.53341675e+00 ...,   1.02626534e+01
   -4.19880226e-02   5.85925150e+00]
 ...,
 [ -4.47037024e-03  -7.19637966e+00   8.49397182e+00 ...,   1.03147259e+01
   -4.15153541e-02   5.87245369e+00]
 [ -4.46819048e-03  -7.19612503e+00   8.49671268e+00 ...,   1.03022423e+01
   -4.22047600e-02   5.86535549e+00]
 [ -4.47041122e-03  -7.19913864e+00   8.50275135e+00 ...,   1.03082352e+01
   -4.14841920e-02   5.87936878e+00]]
After layer decoder_rnn_l0_t0_i_output (20, 512) <class 'numpy.float32'> [[ 0.0287232   0.8889454   0.98664469 ...,  0.85057628  0.99026239
   0.94158286]
 [ 0.0287147   0.88892335  0.98664516 ...,  0.85058624  0.99026978
   0.94157863]
 [ 0.02871047  0.88928354  0.98662484 ...,  0.85086465  0.99022639
   0.94158882]
 ...,
 [ 0.0287191   0.88905478  0.98664725 ...,  0.85057515  0.99025577
   0.94153976]
 [ 0.02873272  0.88919419  0.98664385 ...,  0.85057551  0.9902395
   0.9415049 ]
 [ 0.02872066  0.88904989  0.98664153 ...,  0.8505944   0.99025613
   0.94155109]]
After layer decoder_rnn_l0_t0_c_output (20, 512) <class 'numpy.float32'> [[-0.99287689 -0.99595982  0.9934082  ...,  0.99960285 -0.0814857
   0.97371441]
 [-0.99287623 -0.99596012  0.99340832 ...,  0.99960303 -0.08137098
   0.97369832]
 [-0.99290925 -0.99597311  0.9935016  ...,  0.99959975 -0.08363504
   0.97366542]
 ...,
 [-0.9928835  -0.99597377  0.99343693 ...,  0.99960136 -0.08245424
   0.97367215]
 [-0.99288857 -0.99598372  0.99345666 ...,  0.99959964 -0.08362264
   0.9736653 ]
 [-0.99288136 -0.9959687   0.99342853 ...,  0.99960148 -0.08245475
   0.97368377]]
After layer _mul2129_0 (20, 512) <class 'numpy.float32'> [[-0.0285186  -0.88535392  0.98014092 ...,  0.8502385  -0.08069222
   0.9168328 ]
 [-0.02851015 -0.88533223  0.98014152 ...,  0.85024858 -0.08057922
   0.91681355]
 [-0.02850689 -0.88570249  0.98021334 ...,  0.85052407 -0.08281762
   0.91679245]
 ...,
 [-0.02851472 -0.88547522  0.9801718  ...,  0.85023606 -0.08165079
   0.91675103]
 [-0.02852839 -0.88562292  0.98018789 ...,  0.85023499 -0.08280645
   0.91671062]
 [-0.02851621 -0.88546586  0.98015785 ...,  0.85025543 -0.08165132
   0.91677302]]
After layer decoder_rnn_l0_t0_state_0 (20, 512) <class 'numpy.float32'> [[ -0.0329943   -8.08271694   9.50191784 ...,  11.26525879  -0.1215085
    6.83120871]
 [ -0.03298438  -8.08354855   9.48566818 ...,  11.20307636  -0.12139928
    6.8139596 ]
 [ -0.03296235  -8.06217194   9.51362991 ...,  11.1131773   -0.12480564
    6.77604389]
 ...,
 [ -0.03298509  -8.08185482   9.47414398 ...,  11.16496181  -0.12316614
    6.7892046 ]
 [ -0.03299658  -8.08174801   9.4769001  ...,  11.15247726  -0.12501121
    6.78206635]
 [ -0.03298662  -8.08460426   9.4829092  ...,  11.15849018  -0.12313551
    6.79614162]]
After layer activation1064_output (20, 512) <class 'numpy.float32'> [[-0.03298233 -0.99999982  1.         ...,  1.         -0.12091402
   0.99999768]
 [-0.03297242 -0.99999982  1.         ...,  1.         -0.1208064
   0.99999762]
 [-0.03295042 -0.99999982  1.         ...,  1.         -0.12416165
   0.99999738]
 ...,
 [-0.03297313 -0.99999982  1.         ...,  1.         -0.1225471
   0.99999744]
 [-0.03298461 -0.99999982  1.         ...,  1.         -0.12436404
   0.99999744]
 [-0.03297466 -0.99999982  1.         ...,  1.         -0.12251693
   0.9999975 ]]
After layer decoder_rnn_l0_t0_out_0 (20, 512) <class 'numpy.float32'> [[-0.0012001  -0.91844487  0.19763725 ...,  0.65402037 -0.12022422
   0.68406218]
 [-0.00119963 -0.91845727  0.19772458 ...,  0.6539942  -0.12011684
   0.68412948]
 [-0.00120156 -0.91871399  0.1972498  ...,  0.65413195 -0.12345613
   0.68378097]
 ...,
 [-0.00119978 -0.91845936  0.19750921 ...,  0.6540429  -0.12184849
   0.68386441]
 [-0.00120037 -0.9184829   0.19723532 ...,  0.65406096 -0.12365617
   0.68357617]
 [-0.00119997 -0.91849208  0.1975069  ...,  0.65400052 -0.12181848
   0.68387794]]
After layer expand_dims1073_0 (20, 512, 1) <class 'numpy.float32'> [[[-0.0012001 ]
  [-0.91844487]
  [ 0.19763725]
  ...,
  [ 0.65402037]
  [-0.12022422]
  [ 0.68406218]]

 [[-0.00119963]
  [-0.91845727]
  [ 0.19772458]
  ...,
  [ 0.6539942 ]
  [-0.12011684]
  [ 0.68412948]]

 [[-0.00120156]
  [-0.91871399]
  [ 0.1972498 ]
  ...,
  [ 0.65413195]
  [-0.12345613]
  [ 0.68378097]]

 ...,
 [[-0.00119978]
  [-0.91845936]
  [ 0.19750921]
  ...,
  [ 0.6540429 ]
  [-0.12184849]
  [ 0.68386441]]

 [[-0.00120037]
  [-0.9184829 ]
  [ 0.19723532]
  ...,
  [ 0.65406096]
  [-0.12365617]
  [ 0.68357617]]

 [[-0.00119997]
  [-0.91849208]
  [ 0.1975069 ]
  ...,
  [ 0.65400052]
  [-0.12181848]
  [ 0.68387794]]]
After layer att_batch_dot_0 (20, 10, 1) <class 'numpy.float32'> [[[ 0.53175098]
  [ 0.9251011 ]
  [ 1.63963616]
  [ 2.61179686]
  [ 2.53340077]
  [ 0.28327101]
  [-2.96199036]
  [-5.81149197]
  [-7.95519733]
  [-9.56224823]]

 [[ 0.53191864]
  [ 0.92512786]
  [ 1.63985765]
  [ 2.61227775]
  [ 2.53435493]
  [ 0.28479695]
  [-2.95994401]
  [-5.80898523]
  [-7.95224571]
  [-9.55888653]]

 [[ 0.53110397]
  [ 0.92377383]
  [ 1.63492119]
  [ 2.60248494]
  [ 2.51625872]
  [ 0.25544012]
  [-3.00063443]
  [-5.85961485]
  [-8.01081562]
  [-9.62325287]]

 [[ 0.53168434]
  [ 0.92521328]
  [ 1.63957655]
  [ 2.61159396]
  [ 2.53248262]
  [ 0.28069532]
  [-2.96666074]
  [-5.81816101]
  [-7.96348858]
  [-9.57168674]]

 [[ 0.53138804]
  [ 0.9242757 ]
  [ 1.63430858]
  [ 2.59992671]
  [ 2.50832796]
  [ 0.23789459]
  [-3.02915406]
  [-5.8981452 ]
  [-8.05727577]
  [-9.67539501]]

 [[ 0.53167731]
  [ 0.92537719]
  [ 1.64007664]
  [ 2.61237311]
  [ 2.53378272]
  [ 0.28291583]
  [-2.96337724]
  [-5.81390476]
  [-7.95846939]
  [-9.5661726 ]]

 [[ 0.53007931]
  [ 0.92347306]
  [ 1.63231051]
  [ 2.59655786]
  [ 2.50296116]
  [ 0.230406  ]
  [-3.03843951]
  [-5.90901184]
  [-8.0696373 ]
  [-9.68918705]]

 [[ 0.53194624]
  [ 0.92516726]
  [ 1.64000738]
  [ 2.61254358]
  [ 2.53499866]
  [ 0.28621939]
  [-2.95757461]
  [-5.80571413]
  [-7.9482522 ]
  [-9.55439091]]

 [[ 0.53359562]
  [ 0.92566067]
  [ 1.63860977]
  [ 2.60827541]
  [ 2.52410626]
  [ 0.26380047]
  [-2.99311614]
  [-5.85309124]
  [-8.00467205]
  [-9.61665249]]

 [[ 0.53034604]
  [ 0.92263746]
  [ 1.62918329]
  [ 2.58984971]
  [ 2.49056792]
  [ 0.21094055]
  [-3.06460881]
  [-5.94069576]
  [-8.10537815]
  [-9.72753429]]

 [[ 0.53177083]
  [ 0.92414272]
  [ 1.63633668]
  [ 2.60519814]
  [ 2.52163863]
  [ 0.26487386]
  [-2.98687553]
  [-5.84189177]
  [-7.98973227]
  [-9.59949112]]

 [[ 0.53107768]
  [ 0.92270005]
  [ 1.62937105]
  [ 2.58997273]
  [ 2.48999405]
  [ 0.20878682]
  [-3.0686326 ]
  [-5.94630766]
  [-8.11201096]
  [-9.73460007]]

 [[ 0.5310688 ]
  [ 0.92416239]
  [ 1.63433886]
  [ 2.60018349]
  [ 2.50930452]
  [ 0.24032946]
  [-3.02497125]
  [-5.89234877]
  [-8.05024433]
  [-9.66751289]]

 [[ 0.53210968]
  [ 0.92297089]
  [ 1.63057053]
  [ 2.59225059]
  [ 2.49397278]
  [ 0.21485481]
  [-3.06054163]
  [-5.93630171]
  [-8.10018921]
  [-9.72105694]]

 [[ 0.53189689]
  [ 0.92517543]
  [ 1.63990211]
  [ 2.61231709]
  [ 2.53432536]
  [ 0.28461698]
  [-2.9603138 ]
  [-5.80953455]
  [-7.95295334]
  [-9.55972672]]

 [[ 0.53184962]
  [ 0.92522562]
  [ 1.63988352]
  [ 2.61228466]
  [ 2.5341897 ]
  [ 0.28419176]
  [-2.96114016]
  [-5.81077385]
  [-7.954566  ]
  [-9.56163406]]

 [[ 0.53183198]
  [ 0.92517006]
  [ 1.6396687 ]
  [ 2.61182213]
  [ 2.53317165]
  [ 0.28229514]
  [-2.96397114]
  [-5.8144269 ]
  [-7.95885611]
  [-9.56634903]]

 [[ 0.5316627 ]
  [ 0.92511159]
  [ 1.63928068]
  [ 2.61088157]
  [ 2.53086829]
  [ 0.27773386]
  [-2.97100425]
  [-5.82369471]
  [-7.96994638]
  [-9.57885075]]

 [[ 0.53129327]
  [ 0.92507613]
  [ 1.63864887]
  [ 2.60950947]
  [ 2.52769136]
  [ 0.27149627]
  [-2.98068857]
  [-5.83658075]
  [-7.98548365]
  [-9.59642124]]

 [[ 0.53166449]
  [ 0.92504102]
  [ 1.63915801]
  [ 2.61080933]
  [ 2.53111935]
  [ 0.27861723]
  [-2.96940541]
  [-5.82146311]
  [-7.96720934]
  [-9.57569408]]]
After layer swapaxes49_output (10, 20, 1) <class 'numpy.float32'> [[[ 0.53175098]
  [ 0.53191864]
  [ 0.53110397]
  [ 0.53168434]
  [ 0.53138804]
  [ 0.53167731]
  [ 0.53007931]
  [ 0.53194624]
  [ 0.53359562]
  [ 0.53034604]
  [ 0.53177083]
  [ 0.53107768]
  [ 0.5310688 ]
  [ 0.53210968]
  [ 0.53189689]
  [ 0.53184962]
  [ 0.53183198]
  [ 0.5316627 ]
  [ 0.53129327]
  [ 0.53166449]]

 [[ 0.9251011 ]
  [ 0.92512786]
  [ 0.92377383]
  [ 0.92521328]
  [ 0.9242757 ]
  [ 0.92537719]
  [ 0.92347306]
  [ 0.92516726]
  [ 0.92566067]
  [ 0.92263746]
  [ 0.92414272]
  [ 0.92270005]
  [ 0.92416239]
  [ 0.92297089]
  [ 0.92517543]
  [ 0.92522562]
  [ 0.92517006]
  [ 0.92511159]
  [ 0.92507613]
  [ 0.92504102]]

 [[ 1.63963616]
  [ 1.63985765]
  [ 1.63492119]
  [ 1.63957655]
  [ 1.63430858]
  [ 1.64007664]
  [ 1.63231051]
  [ 1.64000738]
  [ 1.63860977]
  [ 1.62918329]
  [ 1.63633668]
  [ 1.62937105]
  [ 1.63433886]
  [ 1.63057053]
  [ 1.63990211]
  [ 1.63988352]
  [ 1.6396687 ]
  [ 1.63928068]
  [ 1.63864887]
  [ 1.63915801]]

 [[ 2.61179686]
  [ 2.61227775]
  [ 2.60248494]
  [ 2.61159396]
  [ 2.59992671]
  [ 2.61237311]
  [ 2.59655786]
  [ 2.61254358]
  [ 2.60827541]
  [ 2.58984971]
  [ 2.60519814]
  [ 2.58997273]
  [ 2.60018349]
  [ 2.59225059]
  [ 2.61231709]
  [ 2.61228466]
  [ 2.61182213]
  [ 2.61088157]
  [ 2.60950947]
  [ 2.61080933]]

 [[ 2.53340077]
  [ 2.53435493]
  [ 2.51625872]
  [ 2.53248262]
  [ 2.50832796]
  [ 2.53378272]
  [ 2.50296116]
  [ 2.53499866]
  [ 2.52410626]
  [ 2.49056792]
  [ 2.52163863]
  [ 2.48999405]
  [ 2.50930452]
  [ 2.49397278]
  [ 2.53432536]
  [ 2.5341897 ]
  [ 2.53317165]
  [ 2.53086829]
  [ 2.52769136]
  [ 2.53111935]]

 [[ 0.28327101]
  [ 0.28479695]
  [ 0.25544012]
  [ 0.28069532]
  [ 0.23789459]
  [ 0.28291583]
  [ 0.230406  ]
  [ 0.28621939]
  [ 0.26380047]
  [ 0.21094055]
  [ 0.26487386]
  [ 0.20878682]
  [ 0.24032946]
  [ 0.21485481]
  [ 0.28461698]
  [ 0.28419176]
  [ 0.28229514]
  [ 0.27773386]
  [ 0.27149627]
  [ 0.27861723]]

 [[-2.96199036]
  [-2.95994401]
  [-3.00063443]
  [-2.96666074]
  [-3.02915406]
  [-2.96337724]
  [-3.03843951]
  [-2.95757461]
  [-2.99311614]
  [-3.06460881]
  [-2.98687553]
  [-3.0686326 ]
  [-3.02497125]
  [-3.06054163]
  [-2.9603138 ]
  [-2.96114016]
  [-2.96397114]
  [-2.97100425]
  [-2.98068857]
  [-2.96940541]]

 [[-5.81149197]
  [-5.80898523]
  [-5.85961485]
  [-5.81816101]
  [-5.8981452 ]
  [-5.81390476]
  [-5.90901184]
  [-5.80571413]
  [-5.85309124]
  [-5.94069576]
  [-5.84189177]
  [-5.94630766]
  [-5.89234877]
  [-5.93630171]
  [-5.80953455]
  [-5.81077385]
  [-5.8144269 ]
  [-5.82369471]
  [-5.83658075]
  [-5.82146311]]

 [[-7.95519733]
  [-7.95224571]
  [-8.01081562]
  [-7.96348858]
  [-8.05727577]
  [-7.95846939]
  [-8.0696373 ]
  [-7.9482522 ]
  [-8.00467205]
  [-8.10537815]
  [-7.98973227]
  [-8.11201096]
  [-8.05024433]
  [-8.10018921]
  [-7.95295334]
  [-7.954566  ]
  [-7.95885611]
  [-7.96994638]
  [-7.98548365]
  [-7.96720934]]

 [[-9.56224823]
  [-9.55888653]
  [-9.62325287]
  [-9.57168674]
  [-9.67539501]
  [-9.5661726 ]
  [-9.68918705]
  [-9.55439091]
  [-9.61665249]
  [-9.72753429]
  [-9.59949112]
  [-9.73460007]
  [-9.66751289]
  [-9.72105694]
  [-9.55972672]
  [-9.56163406]
  [-9.56634903]
  [-9.57885075]
  [-9.59642124]
  [-9.57569408]]]
After layer sequencemask20_output (10, 20, 1) <class 'numpy.float32'> [[[  5.31750977e-01]
  [  5.31918645e-01]
  [  5.31103969e-01]
  [  5.31684339e-01]
  [  5.31388044e-01]
  [  5.31677306e-01]
  [  5.30079305e-01]
  [  5.31946242e-01]
  [  5.33595622e-01]
  [  5.30346036e-01]
  [  5.31770825e-01]
  [  5.31077683e-01]
  [  5.31068802e-01]
  [  5.32109678e-01]
  [  5.31896889e-01]
  [  5.31849623e-01]
  [  5.31831980e-01]
  [  5.31662703e-01]
  [  5.31293273e-01]
  [  5.31664491e-01]]

 [[  9.25101101e-01]
  [  9.25127864e-01]
  [  9.23773825e-01]
  [  9.25213277e-01]
  [  9.24275696e-01]
  [  9.25377190e-01]
  [  9.23473060e-01]
  [  9.25167263e-01]
  [  9.25660670e-01]
  [  9.22637463e-01]
  [  9.24142718e-01]
  [  9.22700047e-01]
  [  9.24162388e-01]
  [  9.22970891e-01]
  [  9.25175428e-01]
  [  9.25225616e-01]
  [  9.25170064e-01]
  [  9.25111592e-01]
  [  9.25076127e-01]
  [  9.25041020e-01]]

 [[ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]]
After layer swapaxes50_output (20, 10, 1) <class 'numpy.float32'> [[[  5.31750977e-01]
  [  9.25101101e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  5.31918645e-01]
  [  9.25127864e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  5.31103969e-01]
  [  9.23773825e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  5.31684339e-01]
  [  9.25213277e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  5.31388044e-01]
  [  9.24275696e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  5.31677306e-01]
  [  9.25377190e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  5.30079305e-01]
  [  9.23473060e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  5.31946242e-01]
  [  9.25167263e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  5.33595622e-01]
  [  9.25660670e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  5.30346036e-01]
  [  9.22637463e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  5.31770825e-01]
  [  9.24142718e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  5.31077683e-01]
  [  9.22700047e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  5.31068802e-01]
  [  9.24162388e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  5.32109678e-01]
  [  9.22970891e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  5.31896889e-01]
  [  9.25175428e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  5.31849623e-01]
  [  9.25225616e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  5.31831980e-01]
  [  9.25170064e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  5.31662703e-01]
  [  9.25111592e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  5.31293273e-01]
  [  9.25076127e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  5.31664491e-01]
  [  9.25041020e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]]
After layer attention_softmax_0 (20, 10, 1) <class 'numpy.float32'> [[[ 0.40291107]
  [ 0.59708887]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40294498]
  [ 0.59705502]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40307474]
  [ 0.5969252 ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40286806]
  [ 0.59713197]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40302232]
  [ 0.59697765]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40282691]
  [ 0.59717304]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40290061]
  [ 0.59709942]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40294218]
  [ 0.59705788]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40322027]
  [ 0.5967797 ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40316579]
  [ 0.59683418]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40314645]
  [ 0.59685355]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40332681]
  [ 0.59667319]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40297279]
  [ 0.59702718]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40350997]
  [ 0.59648997]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40292832]
  [ 0.59707165]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40290487]
  [ 0.59709513]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40291396]
  [ 0.59708601]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40288734]
  [ 0.59711266]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.402807  ]
  [ 0.597193  ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40290475]
  [ 0.59709525]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]]
After layer batch_dot20_0 (20, 512, 1) <class 'numpy.float32'> [[[ 0.01786128]
  [ 0.03944984]
  [-0.03344399]
  ...,
  [-0.01095794]
  [ 0.00999374]
  [-0.02459341]]

 [[ 0.01786046]
  [ 0.0394489 ]
  [-0.03344247]
  ...,
  [-0.01095775]
  [ 0.0099937 ]
  [-0.02459401]]

 [[ 0.01785733]
  [ 0.03944528]
  [-0.03343663]
  ...,
  [-0.01095703]
  [ 0.00999355]
  [-0.0245963 ]]

 ...,
 [[ 0.01786185]
  [ 0.03945051]
  [-0.03344507]
  ...,
  [-0.01095807]
  [ 0.00999376]
  [-0.02459299]]

 [[ 0.01786379]
  [ 0.03945275]
  [-0.03344868]
  ...,
  [-0.01095851]
  [ 0.00999386]
  [-0.02459157]]

 [[ 0.01786143]
  [ 0.03945002]
  [-0.03344428]
  ...,
  [-0.01095797]
  [ 0.00999374]
  [-0.0245933 ]]]
After layer reshape40_0 (20, 512) <class 'numpy.float32'> [[ 0.01786128  0.03944984 -0.03344399 ..., -0.01095794  0.00999374
  -0.02459341]
 [ 0.01786046  0.0394489  -0.03344247 ..., -0.01095775  0.0099937
  -0.02459401]
 [ 0.01785733  0.03944528 -0.03343663 ..., -0.01095703  0.00999355
  -0.0245963 ]
 ...,
 [ 0.01786185  0.03945051 -0.03344507 ..., -0.01095807  0.00999376
  -0.02459299]
 [ 0.01786379  0.03945275 -0.03344868 ..., -0.01095851  0.00999386
  -0.02459157]
 [ 0.01786143  0.03945002 -0.03344428 ..., -0.01095797  0.00999374
  -0.0245933 ]]
After layer decoder_rnn_hidden_concat_t0_output (20, 1024) <class 'numpy.float32'> [[-0.0012001  -0.91844487  0.19763725 ..., -0.01095794  0.00999374
  -0.02459341]
 [-0.00119963 -0.91845727  0.19772458 ..., -0.01095775  0.0099937
  -0.02459401]
 [-0.00120156 -0.91871399  0.1972498  ..., -0.01095703  0.00999355
  -0.0245963 ]
 ...,
 [-0.00119978 -0.91845936  0.19750921 ..., -0.01095807  0.00999376
  -0.02459299]
 [-0.00120037 -0.9184829   0.19723532 ..., -0.01095851  0.00999386
  -0.02459157]
 [-0.00119997 -0.91849208  0.1975069  ..., -0.01095797  0.00999374
  -0.0245933 ]]
After layer decoder_rnn_hidden_fc_t0_output (20, 512) <class 'numpy.float32'> [[-1.97566938  0.21571873 -0.82100731 ...,  1.98454452  2.12114501
  -1.60764015]
 [-1.97546589  0.2151707  -0.82073539 ...,  1.98439348  2.12153602
  -1.60755777]
 [-1.97472441  0.21733573 -0.82373142 ...,  1.98278546  2.11943793
  -1.60880661]
 ...,
 [-1.97617781  0.21660689 -0.82229769 ...,  1.9842726   2.12080359
  -1.60839272]
 [-1.97674561  0.218153   -0.82386678 ...,  1.98409247  2.11985898
  -1.60886049]
 [-1.97581589  0.2163392  -0.82208318 ...,  1.98415267  2.12076235
  -1.6079483 ]]
After layer decoder_rnn_next_hidden_t0_output (20, 512) <class 'numpy.float32'> [[-0.9622677   0.21243374 -0.67561781 ...,  0.96291924  0.97165811
  -0.92281055]
 [-0.96225262  0.21191038 -0.67546993 ...,  0.96290821  0.97167999
  -0.92279834]
 [-0.96219766  0.21397723 -0.67709571 ...,  0.96279097  0.97156256
  -0.92298347]
 ...,
 [-0.96230531  0.21328166 -0.67631853 ...,  0.96289939  0.97163904
  -0.92292213]
 [-0.96234727  0.21475695 -0.67716897 ...,  0.96288627  0.97158617
  -0.92299145]
 [-0.96227849  0.21302614 -0.67620218 ...,  0.96289068  0.97163677
  -0.92285627]]
After layer logits_output (20, 16743) <class 'numpy.float32'> [[-2.01587939 -2.82553172 -2.40815592 ..., -2.09270191 -3.50267029
  -2.58952856]
 [-2.01611948 -2.82565594 -2.40812874 ..., -2.09263897 -3.50267434
  -2.58955598]
 [-2.01477742 -2.82606387 -2.40776396 ..., -2.09381723 -3.50208688
  -2.59042835]
 ...,
 [-2.0159831  -2.82562923 -2.40812325 ..., -2.0929234  -3.5023706
  -2.59018612]
 [-2.01555586 -2.82547331 -2.40814543 ..., -2.09321785 -3.50200367
  -2.59060788]
 [-2.01580691 -2.82559323 -2.40807128 ..., -2.0928936  -3.50233173
  -2.58994961]]
After layer softmax_0 (20, 16743) <class 'numpy.float32'> [[  8.34593607e-07   3.71404781e-07   5.63782237e-07 ...,   7.72879048e-07
    1.88699204e-07   4.70265007e-07]
 [  8.34207981e-07   3.71276059e-07   5.63672302e-07 ...,   7.72755527e-07
    1.88656443e-07   4.70147313e-07]
 [  8.38628523e-07   3.72590847e-07   5.66106110e-07 ...,   7.74894829e-07
    1.89513131e-07   4.71593125e-07]
 ...,
 [  8.35692219e-07   3.71896220e-07   5.64601976e-07 ...,   7.73805766e-07
    1.89023837e-07   4.70623263e-07]
 [  8.37592268e-07   3.72640386e-07   5.65630899e-07 ...,   7.75004594e-07
    1.89442019e-07   4.71292623e-07]
 [  8.35882531e-07   3.71928706e-07   5.64659956e-07 ...,   7.73868180e-07
    1.89040918e-07   4.70758664e-07]]
After layer reshape41_0 (20, 10) <class 'numpy.float32'> [[ 0.40291107  0.59708887  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40294498  0.59705502  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40307474  0.5969252   0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40286806  0.59713197  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40302232  0.59697765  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40282691  0.59717304  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40290061  0.59709942  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40294218  0.59705788  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40322027  0.5967797   0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40316579  0.59683418  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40314645  0.59685355  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40332681  0.59667319  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40297279  0.59702718  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40350997  0.59648997  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40292832  0.59707165  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40290487  0.59709513  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40291396  0.59708601  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40288734  0.59711266  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.402807    0.597193    0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40290475  0.59709525  0.          0.          0.          0.          0.
   0.          0.          0.        ]]
After layer target_embed_embed_0 (20, 256) <class 'numpy.float32'> [[-0.05505371 -0.0300293  -0.03598022 ...,  0.08459473 -0.05288696
  -0.01667786]
 [-0.05505371 -0.0300293  -0.03598022 ...,  0.08459473 -0.05288696
  -0.01667786]
 [-0.05505371 -0.0300293  -0.03598022 ...,  0.08459473 -0.05288696
  -0.01667786]
 ...,
 [-0.05505371 -0.0300293  -0.03598022 ...,  0.08459473 -0.05288696
  -0.01667786]
 [-0.05505371 -0.0300293  -0.03598022 ...,  0.08459473 -0.05288696
  -0.01667786]
 [-0.05505371 -0.0300293  -0.03598022 ...,  0.08459473 -0.05288696
  -0.01667786]]
After layer decoder_rnn_concat_target_context_t0_output (20, 768) <class 'numpy.float32'> [[-0.05505371 -0.0300293  -0.03598022 ...,  0.96291924  0.97165811
  -0.92281055]
 [-0.05505371 -0.0300293  -0.03598022 ...,  0.96290821  0.97167999
  -0.92279834]
 [-0.05505371 -0.0300293  -0.03598022 ...,  0.96279097  0.97156256
  -0.92298347]
 ...,
 [-0.05505371 -0.0300293  -0.03598022 ...,  0.96289939  0.97163904
  -0.92292213]
 [-0.05505371 -0.0300293  -0.03598022 ...,  0.96288627  0.97158617
  -0.92299145]
 [-0.05505371 -0.0300293  -0.03598022 ...,  0.96289068  0.97163677
  -0.92285627]]
After layer decoder_rnn_l0_t0_i2h_output (20, 2048) <class 'numpy.float32'> [[-3.1981349   1.60767472  2.44330239 ..., -0.07716646  3.86609268
   0.59547329]
 [-3.19824743  1.60769033  2.44329357 ..., -0.07722582  3.86610794
   0.5957064 ]
 [-3.197227    1.60719311  2.44344378 ..., -0.07674138  3.86635637
   0.59742624]
 ...,
 [-3.19790506  1.60746288  2.44371057 ..., -0.07697419  3.86608601
   0.59577578]
 [-3.19745684  1.60729933  2.44396257 ..., -0.07671291  3.86603022
   0.5957498 ]
 [-3.1978507   1.60749614  2.44352078 ..., -0.07700551  3.86603761
   0.59584475]]
After layer decoder_rnn_l0_t0_h2h_output (20, 2048) <class 'numpy.float32'> [[-0.32360873  0.47268119  1.86070907 ...,  0.71438175  1.29491389
   0.17691381]
 [-0.32378459  0.4724679   1.86074495 ...,  0.71434259  1.29442942
   0.17700496]
 [-0.32487607  0.47622508  1.85919261 ...,  0.7145716   1.29826164
   0.17368084]
 ...,
 [-0.32398406  0.47393468  1.86043239 ...,  0.71428657  1.29568481
   0.17584766]
 [-0.32396746  0.4753876   1.85994685 ...,  0.7141394   1.297194
   0.17466204]
 [-0.32397288  0.47381863  1.86024988 ...,  0.71419472  1.29568851
   0.17582597]]
After layer _plus1065_0 (20, 2048) <class 'numpy.float32'> [[-3.52174354  2.08035588  4.30401134 ...,  0.63721532  5.16100645
   0.77238709]
 [-3.52203202  2.08015823  4.30403852 ...,  0.63711679  5.16053724
   0.7727114 ]
 [-3.52210307  2.08341813  4.30263615 ...,  0.6378302   5.16461802
   0.77110708]
 ...,
 [-3.52188921  2.08139753  4.30414295 ...,  0.63731235  5.16177082
   0.77162343]
 [-3.52142429  2.0826869   4.3039093  ...,  0.6374265   5.16322422
   0.77041185]
 [-3.52182364  2.0813148   4.30377054 ...,  0.63718921  5.161726    0.7716707 ]]
After layer decoder_rnn_l0_t0_slice_output0 (20, 512) <class 'numpy.float32'> [[-3.52174354  2.08035588  4.30401134 ...,  1.7395072   4.62331724
   2.77933264]
 [-3.52203202  2.08015823  4.30403852 ...,  1.739604    4.62399101
   2.77929688]
 [-3.52210307  2.08341813  4.30263615 ...,  1.74155664  4.61984301
   2.77945375]
 ...,
 [-3.52188921  2.08139753  4.30414295 ...,  1.7395823   4.62264109
   2.77865648]
 [-3.52142429  2.0826869   4.3039093  ...,  1.73960292  4.62107754
   2.7780838 ]
 [-3.52182364  2.0813148   4.30377054 ...,  1.73969269  4.62267876
   2.77885818]]
After layer decoder_rnn_l0_t0_slice_output1 (20, 512) <class 'numpy.float32'> [[-1.85273862  2.32191658  2.44777155 ...,  3.16914749 -0.68579912
   1.99318779]
 [-1.85279071  2.32198763  2.44784689 ...,  3.16943097 -0.6854049
   1.99334598]
 [-1.8563683   2.32116294  2.44996691 ...,  3.16732931 -0.6868794
   1.99172342]
 ...,
 [-1.85376251  2.32160687  2.44896817 ...,  3.168679   -0.68547243
   1.99323225]
 [-1.85464728  2.32131886  2.44966269 ...,  3.16769552 -0.68594277
   1.9929601 ]
 [-1.85375392  2.32176399  2.44846296 ...,  3.16855335 -0.68571007
   1.99300385]]
After layer decoder_rnn_l0_t0_slice_output2 (20, 512) <class 'numpy.float32'> [[-2.81689286 -3.10312748  2.8572979  ...,  4.26204205 -0.08127418
   2.15888119]
 [-2.81685138 -3.10313606  2.85733604 ...,  4.26228857 -0.08113447
   2.15860653]
 [-2.81900668 -3.10465574  2.86383343 ...,  4.25833607 -0.08325738
   2.15794659]
 ...,
 [-2.81735563 -3.10469365  2.85938096 ...,  4.26035976 -0.08208361
   2.15815306]
 [-2.81771135 -3.10585356  2.86080122 ...,  4.25842381 -0.08313343
   2.15803814]
 [-2.81721926 -3.10411453  2.85877609 ...,  4.26050472 -0.08209717
   2.15835118]]
After layer decoder_rnn_l0_t0_slice_output3 (20, 512) <class 'numpy.float32'> [[-3.2765584   2.42048097 -1.4013443  ...,  0.63721532  5.16100645
   0.77238709]
 [-3.27662563  2.42063379 -1.40082633 ...,  0.63711679  5.16053724
   0.7727114 ]
 [-3.27449083  2.42365265 -1.4034338  ...,  0.6378302   5.16461802
   0.77110708]
 ...,
 [-3.27650166  2.42066646 -1.4020834  ...,  0.63731235  5.16177082
   0.77162343]
 [-3.27635574  2.42092395 -1.40367246 ...,  0.6374265   5.16322422
   0.77041185]
 [-3.27641129  2.42103004 -1.40206873 ...,  0.63718921  5.161726    0.7716707 ]]
After layer decoder_rnn_l0_t0_o_output (20, 512) <class 'numpy.float32'> [[ 0.03638419  0.91837579  0.19760287 ...,  0.65412372  0.99429685
   0.68403709]
 [ 0.03638183  0.91838723  0.19768503 ...,  0.65410143  0.99429411
   0.68410712]
 [ 0.03645675  0.91861326  0.19727179 ...,  0.65426278  0.99431723
   0.68376029]
 ...,
 [ 0.03638618  0.91838968  0.19748572 ...,  0.65414566  0.99430108
   0.68387198]
 [ 0.0363913   0.91840899  0.19723399 ...,  0.65417153  0.99430931
   0.68360996]
 [ 0.03638934  0.91841692  0.19748804 ...,  0.65411776  0.99430084
   0.68388218]]
After layer decoder_rnn_l0_t0_f_output (20, 512) <class 'numpy.float32'> [[ 0.13555168  0.910676    0.92039835 ...,  0.9596566   0.33496824
   0.88007998]
 [ 0.13554557  0.91068172  0.9204039  ...,  0.95966762  0.33505604
   0.88009667]
 [ 0.13512692  0.91061467  0.92055905 ...,  0.95958614  0.33472764
   0.87992531]
 ...,
 [ 0.13543174  0.91065079  0.92048597 ...,  0.95963848  0.33504102
   0.88008469]
 [ 0.13532817  0.91062737  0.92053682 ...,  0.95960033  0.33493623
   0.88005596]
 [ 0.13543275  0.91066355  0.92044896 ...,  0.95963359  0.33498809
   0.88006055]]
After layer _mul2130_0 (20, 512) <class 'numpy.float32'> [[ -4.47243219e-03  -7.36073637e+00   8.74554920e+00 ...,   1.08107796e+01
   -4.07014899e-02   6.01201010e+00]
 [ -4.47088573e-03  -7.36153984e+00   8.73064613e+00 ...,   1.07512293e+01
   -4.06755619e-02   5.99694300e+00]
 [ -4.45410097e-03  -7.34153223e+00   8.75785828e+00 ...,   1.06640511e+01
   -4.17759009e-02   5.96241236e+00]
 ...,
 [ -4.46722796e-03  -7.35974741e+00   8.72081661e+00 ...,   1.07143269e+01
   -4.12657112e-02   5.97507524e+00]
 [ -4.46536765e-03  -7.35946083e+00   8.72383499e+00 ...,   1.07019205e+01
   -4.18707803e-02   5.96859789e+00]
 [ -4.46746917e-03  -7.36235428e+00   8.72853374e+00 ...,   1.07080622e+01
   -4.12489288e-02   5.98101616e+00]]
After layer decoder_rnn_l0_t0_i_output (20, 512) <class 'numpy.float32'> [[ 0.02869985  0.88897914  0.9866659  ...,  0.85062444  0.99027526
   0.94154876]
 [ 0.02869181  0.88895965  0.98666626 ...,  0.85063678  0.99028182
   0.94154674]
 [ 0.02868983  0.88928109  0.98664784 ...,  0.85088468  0.99024183
   0.94155538]
 ...,
 [ 0.02869579  0.88908195  0.98666763 ...,  0.85063398  0.99026883
   0.94151157]
 [ 0.02870875  0.88920909  0.98666465 ...,  0.85063666  0.99025375
   0.94147992]
 [ 0.02869762  0.88907373  0.98666281 ...,  0.85064805  0.99026918
   0.94152266]]
After layer decoder_rnn_l0_t0_c_output (20, 512) <class 'numpy.float32'> [[-0.99287546 -0.99597454  0.99342668 ...,  0.99960285 -0.0810957
   0.97369134]
 [-0.99287486 -0.99597466  0.99342722 ...,  0.99960303 -0.08095691
   0.97367704]
 [-0.99290538 -0.99598682  0.9935118  ...,  0.99959987 -0.08306554
   0.97364277]
 ...,
 [-0.99288201 -0.99598712  0.99345392 ...,  0.99960148 -0.08189975
   0.9736535 ]
 [-0.99288708 -0.99599642  0.99347246 ...,  0.99959993 -0.08294244
   0.97364753]
 [-0.99288005 -0.99598247  0.99344605 ...,  0.9996016  -0.08191323
   0.97366381]]
After layer _mul2131_0 (20, 512) <class 'numpy.float32'> [[-0.02849538 -0.88540059  0.98018026 ...,  0.8502866  -0.08030707
   0.91677791]
 [-0.02848738 -0.88538128  0.9801811  ...,  0.85029912 -0.08017015
   0.91676241]
 [-0.02848629 -0.88571227  0.98024625 ...,  0.85054421 -0.08225497
   0.91673857]
 ...,
 [-0.02849154 -0.8855142   0.98020881 ...,  0.85029501 -0.08110277
   0.91670603]
 [-0.02850455 -0.88564909  0.98022413 ...,  0.85029638 -0.08213406
   0.91666961]
 [-0.02849329 -0.88550186  0.9801963  ...,  0.85030913 -0.08111614
   0.91672653]]
After layer decoder_rnn_l0_t0_state_0 (20, 512) <class 'numpy.float32'> [[ -0.03296781  -8.24613667   9.72572899 ...,  11.66106606  -0.12100856
    6.92878819]
 [ -0.03295827  -8.24692154   9.71082687 ...,  11.60152817  -0.12084572
    6.91370535]
 [ -0.03294039  -8.22724438   9.73810482 ...,  11.51459503  -0.12403087
    6.87915087]
 ...,
 [ -0.03295876  -8.24526119   9.70102501 ...,  11.56462193  -0.12236848
    6.89178133]
 [ -0.03296991  -8.24510956   9.7040596  ...,  11.55221653  -0.12400484
    6.88526726]
 [ -0.03296076  -8.24785614   9.70872974 ...,  11.55837154  -0.12236507
    6.89774275]]
After layer activation1065_output (20, 512) <class 'numpy.float32'> [[-0.03295587 -0.99999988  1.         ...,  1.         -0.12042136
   0.99999809]
 [-0.03294634 -0.99999988  1.         ...,  1.         -0.12026088
   0.99999803]
 [-0.03292848 -0.99999988  1.         ...,  1.         -0.12339875
   0.99999785]
 ...,
 [-0.03294684 -0.99999988  1.         ...,  1.         -0.12176134
   0.99999791]
 [-0.03295797 -0.99999988  1.         ...,  1.         -0.12337311
   0.99999791]
 [-0.03294883 -0.99999988  1.         ...,  1.         -0.12175798
   0.99999797]]
After layer decoder_rnn_l0_t0_out_0 (20, 512) <class 'numpy.float32'> [[-0.00119907 -0.91837567  0.19760287 ...,  0.65412372 -0.11973458
   0.68403578]
 [-0.00119865 -0.91838712  0.19768503 ...,  0.65410143 -0.11957468
   0.68410575]
 [-0.00120047 -0.91861314  0.19727179 ...,  0.65426278 -0.1226975
   0.6837588 ]
 ...,
 [-0.00119881 -0.91838956  0.19748572 ...,  0.65414566 -0.12106743
   0.68387055]
 [-0.00119938 -0.91840887  0.19723399 ...,  0.65417153 -0.12267104
   0.68360853]
 [-0.00119899 -0.9184168   0.19748804 ...,  0.65411776 -0.12106406
   0.68388081]]
After layer expand_dims1074_0 (20, 512, 1) <class 'numpy.float32'> [[[-0.00119907]
  [-0.91837567]
  [ 0.19760287]
  ...,
  [ 0.65412372]
  [-0.11973458]
  [ 0.68403578]]

 [[-0.00119865]
  [-0.91838712]
  [ 0.19768503]
  ...,
  [ 0.65410143]
  [-0.11957468]
  [ 0.68410575]]

 [[-0.00120047]
  [-0.91861314]
  [ 0.19727179]
  ...,
  [ 0.65426278]
  [-0.1226975 ]
  [ 0.6837588 ]]

 ...,
 [[-0.00119881]
  [-0.91838956]
  [ 0.19748572]
  ...,
  [ 0.65414566]
  [-0.12106743]
  [ 0.68387055]]

 [[-0.00119938]
  [-0.91840887]
  [ 0.19723399]
  ...,
  [ 0.65417153]
  [-0.12267104]
  [ 0.68360853]]

 [[-0.00119899]
  [-0.9184168 ]
  [ 0.19748804]
  ...,
  [ 0.65411776]
  [-0.12106406]
  [ 0.68388081]]]
After layer att_batch_dot_0 (20, 10, 1) <class 'numpy.float32'> [[[ 0.53193849]
  [ 0.92573106]
  [ 1.64108264]
  [ 2.61399794]
  [ 2.53598547]
  [ 0.2854203 ]
  [-2.96076775]
  [-5.81123066]
  [-7.95573282]
  [-9.56342316]]

 [[ 0.53209871]
  [ 0.92577505]
  [ 1.64128792]
  [ 2.61444044]
  [ 2.53686833]
  [ 0.28684899]
  [-2.95884228]
  [-5.80885696]
  [-7.95294189]
  [-9.56026459]]

 [[ 0.53134465]
  [ 0.92446095]
  [ 1.63662767]
  [ 2.60528374]
  [ 2.52006221]
  [ 0.25968173]
  [-2.99643874]
  [-5.85561943]
  [-8.00705242]
  [-9.61974716]]

 [[ 0.53187048]
  [ 0.92584199]
  [ 1.64098918]
  [ 2.61372757]
  [ 2.53501105]
  [ 0.28291336]
  [-2.96518779]
  [-5.81748152]
  [-7.96346951]
  [-9.57222939]]

 [[ 0.53162241]
  [ 0.92500269]
  [ 1.63604999]
  [ 2.60282755]
  [ 2.51256657]
  [ 0.24323846]
  [-3.02308869]
  [-5.89159822]
  [-8.05046368]
  [-9.66850758]]

 [[ 0.53187859]
  [ 0.92602795]
  [ 1.64154768]
  [ 2.6146183 ]
  [ 2.53646755]
  [ 0.28525165]
  [-2.96186709]
  [-5.81325579]
  [-7.95854473]
  [-9.56683254]]

 [[ 0.53036362]
  [ 0.92416972]
  [ 1.63409221]
  [ 2.59954572]
  [ 2.50733161]
  [ 0.23589583]
  [-3.03222275]
  [-5.90230274]
  [-8.06261539]
  [-9.68204784]]

 [[ 0.53212792]
  [ 0.92581177]
  [ 1.64145732]
  [ 2.61475587]
  [ 2.53756499]
  [ 0.28828195]
  [-2.95652843]
  [-5.80572367]
  [-7.94914913]
  [-9.55599117]]

 [[ 0.53372437]
  [ 0.92637527]
  [ 1.64017379]
  [ 2.61079073]
  [ 2.52758288]
  [ 0.26786682]
  [-2.98884988]
  [-5.84882784]
  [-8.00052261]
  [-9.6127615 ]]

 [[ 0.5306657 ]
  [ 0.92346805]
  [ 1.63133311]
  [ 2.59362936]
  [ 2.4963448 ]
  [ 0.21848319]
  [-3.05581045]
  [-5.93104267]
  [-8.095191  ]
  [-9.71711922]]

 [[ 0.53198743]
  [ 0.92485791]
  [ 1.63804913]
  [ 2.60800624]
  [ 2.52538204]
  [ 0.26887295]
  [-2.9831655 ]
  [-5.83861637]
  [-7.98690653]
  [-9.59711838]]

 [[ 0.53137869]
  [ 0.92356068]
  [ 1.63147664]
  [ 2.59364009]
  [ 2.49565649]
  [ 0.21632774]
  [-3.05967331]
  [-5.93634892]
  [-8.10144043]
  [-9.7237711 ]]

 [[ 0.53132021]
  [ 0.92488831]
  [ 1.63610816]
  [ 2.60313654]
  [ 2.513592  ]
  [ 0.24565437]
  [-3.01902342]
  [-5.88601732]
  [-8.04370499]
  [-9.66095543]]

 [[ 0.5324074 ]
  [ 0.92389083]
  [ 1.63268507]
  [ 2.59589362]
  [ 2.4995997 ]
  [ 0.22239393]
  [-3.05152655]
  [-5.92625093]
  [-8.08953094]
  [-9.71018505]]

 [[ 0.53207797]
  [ 0.92581707]
  [ 1.64133132]
  [ 2.61448002]
  [ 2.53684831]
  [ 0.28668731]
  [-2.95917392]
  [-5.80936241]
  [-7.95360661]
  [-9.56104755]]

 [[ 0.53202957]
  [ 0.92585826]
  [ 1.64130306]
  [ 2.61442685]
  [ 2.53668618]
  [ 0.28625447]
  [-2.9599812 ]
  [-5.81054783]
  [-7.95512962]
  [-9.56283092]]

 [[ 0.53201222]
  [ 0.92580652]
  [ 1.64109123]
  [ 2.61397576]
  [ 2.53571415]
  [ 0.28447601]
  [-2.96261168]
  [-5.81392527]
  [-7.95909023]
  [-9.5671854 ]]

 [[ 0.5318588 ]
  [ 0.92576587]
  [ 1.64073551]
  [ 2.61309576]
  [ 2.53357649]
  [ 0.2802549 ]
  [-2.96910858]
  [-5.82247734]
  [-7.96932793]
  [-9.57873726]]

 [[ 0.53150666]
  [ 0.92572027]
  [ 1.64011168]
  [ 2.6117444 ]
  [ 2.53050089]
  [ 0.27431825]
  [-2.97824478]
  [-5.83458424]
  [-7.98389864]
  [-9.59519577]]

 [[ 0.53185338]
  [ 0.92567933]
  [ 1.64059412]
  [ 2.61299467]
  [ 2.53374791]
  [ 0.28099787]
  [-2.96771455]
  [-5.82051229]
  [-7.96688175]
  [-9.57590866]]]
After layer swapaxes51_output (10, 20, 1) <class 'numpy.float32'> [[[ 0.53193849]
  [ 0.53209871]
  [ 0.53134465]
  [ 0.53187048]
  [ 0.53162241]
  [ 0.53187859]
  [ 0.53036362]
  [ 0.53212792]
  [ 0.53372437]
  [ 0.5306657 ]
  [ 0.53198743]
  [ 0.53137869]
  [ 0.53132021]
  [ 0.5324074 ]
  [ 0.53207797]
  [ 0.53202957]
  [ 0.53201222]
  [ 0.5318588 ]
  [ 0.53150666]
  [ 0.53185338]]

 [[ 0.92573106]
  [ 0.92577505]
  [ 0.92446095]
  [ 0.92584199]
  [ 0.92500269]
  [ 0.92602795]
  [ 0.92416972]
  [ 0.92581177]
  [ 0.92637527]
  [ 0.92346805]
  [ 0.92485791]
  [ 0.92356068]
  [ 0.92488831]
  [ 0.92389083]
  [ 0.92581707]
  [ 0.92585826]
  [ 0.92580652]
  [ 0.92576587]
  [ 0.92572027]
  [ 0.92567933]]

 [[ 1.64108264]
  [ 1.64128792]
  [ 1.63662767]
  [ 1.64098918]
  [ 1.63604999]
  [ 1.64154768]
  [ 1.63409221]
  [ 1.64145732]
  [ 1.64017379]
  [ 1.63133311]
  [ 1.63804913]
  [ 1.63147664]
  [ 1.63610816]
  [ 1.63268507]
  [ 1.64133132]
  [ 1.64130306]
  [ 1.64109123]
  [ 1.64073551]
  [ 1.64011168]
  [ 1.64059412]]

 [[ 2.61399794]
  [ 2.61444044]
  [ 2.60528374]
  [ 2.61372757]
  [ 2.60282755]
  [ 2.6146183 ]
  [ 2.59954572]
  [ 2.61475587]
  [ 2.61079073]
  [ 2.59362936]
  [ 2.60800624]
  [ 2.59364009]
  [ 2.60313654]
  [ 2.59589362]
  [ 2.61448002]
  [ 2.61442685]
  [ 2.61397576]
  [ 2.61309576]
  [ 2.6117444 ]
  [ 2.61299467]]

 [[ 2.53598547]
  [ 2.53686833]
  [ 2.52006221]
  [ 2.53501105]
  [ 2.51256657]
  [ 2.53646755]
  [ 2.50733161]
  [ 2.53756499]
  [ 2.52758288]
  [ 2.4963448 ]
  [ 2.52538204]
  [ 2.49565649]
  [ 2.513592  ]
  [ 2.4995997 ]
  [ 2.53684831]
  [ 2.53668618]
  [ 2.53571415]
  [ 2.53357649]
  [ 2.53050089]
  [ 2.53374791]]

 [[ 0.2854203 ]
  [ 0.28684899]
  [ 0.25968173]
  [ 0.28291336]
  [ 0.24323846]
  [ 0.28525165]
  [ 0.23589583]
  [ 0.28828195]
  [ 0.26786682]
  [ 0.21848319]
  [ 0.26887295]
  [ 0.21632774]
  [ 0.24565437]
  [ 0.22239393]
  [ 0.28668731]
  [ 0.28625447]
  [ 0.28447601]
  [ 0.2802549 ]
  [ 0.27431825]
  [ 0.28099787]]

 [[-2.96076775]
  [-2.95884228]
  [-2.99643874]
  [-2.96518779]
  [-3.02308869]
  [-2.96186709]
  [-3.03222275]
  [-2.95652843]
  [-2.98884988]
  [-3.05581045]
  [-2.9831655 ]
  [-3.05967331]
  [-3.01902342]
  [-3.05152655]
  [-2.95917392]
  [-2.9599812 ]
  [-2.96261168]
  [-2.96910858]
  [-2.97824478]
  [-2.96771455]]

 [[-5.81123066]
  [-5.80885696]
  [-5.85561943]
  [-5.81748152]
  [-5.89159822]
  [-5.81325579]
  [-5.90230274]
  [-5.80572367]
  [-5.84882784]
  [-5.93104267]
  [-5.83861637]
  [-5.93634892]
  [-5.88601732]
  [-5.92625093]
  [-5.80936241]
  [-5.81054783]
  [-5.81392527]
  [-5.82247734]
  [-5.83458424]
  [-5.82051229]]

 [[-7.95573282]
  [-7.95294189]
  [-8.00705242]
  [-7.96346951]
  [-8.05046368]
  [-7.95854473]
  [-8.06261539]
  [-7.94914913]
  [-8.00052261]
  [-8.095191  ]
  [-7.98690653]
  [-8.10144043]
  [-8.04370499]
  [-8.08953094]
  [-7.95360661]
  [-7.95512962]
  [-7.95909023]
  [-7.96932793]
  [-7.98389864]
  [-7.96688175]]

 [[-9.56342316]
  [-9.56026459]
  [-9.61974716]
  [-9.57222939]
  [-9.66850758]
  [-9.56683254]
  [-9.68204784]
  [-9.55599117]
  [-9.6127615 ]
  [-9.71711922]
  [-9.59711838]
  [-9.7237711 ]
  [-9.66095543]
  [-9.71018505]
  [-9.56104755]
  [-9.56283092]
  [-9.5671854 ]
  [-9.57873726]
  [-9.59519577]
  [-9.57590866]]]
After layer sequencemask21_output (10, 20, 1) <class 'numpy.float32'> [[[  5.31938493e-01]
  [  5.32098711e-01]
  [  5.31344652e-01]
  [  5.31870484e-01]
  [  5.31622410e-01]
  [  5.31878591e-01]
  [  5.30363619e-01]
  [  5.32127917e-01]
  [  5.33724368e-01]
  [  5.30665696e-01]
  [  5.31987429e-01]
  [  5.31378686e-01]
  [  5.31320214e-01]
  [  5.32407403e-01]
  [  5.32077968e-01]
  [  5.32029569e-01]
  [  5.32012224e-01]
  [  5.31858802e-01]
  [  5.31506658e-01]
  [  5.31853378e-01]]

 [[  9.25731063e-01]
  [  9.25775051e-01]
  [  9.24460948e-01]
  [  9.25841987e-01]
  [  9.25002694e-01]
  [  9.26027954e-01]
  [  9.24169719e-01]
  [  9.25811768e-01]
  [  9.26375270e-01]
  [  9.23468053e-01]
  [  9.24857914e-01]
  [  9.23560679e-01]
  [  9.24888313e-01]
  [  9.23890829e-01]
  [  9.25817072e-01]
  [  9.25858259e-01]
  [  9.25806522e-01]
  [  9.25765872e-01]
  [  9.25720274e-01]
  [  9.25679326e-01]]

 [[ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]]
After layer swapaxes52_output (20, 10, 1) <class 'numpy.float32'> [[[  5.31938493e-01]
  [  9.25731063e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  5.32098711e-01]
  [  9.25775051e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  5.31344652e-01]
  [  9.24460948e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  5.31870484e-01]
  [  9.25841987e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  5.31622410e-01]
  [  9.25002694e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  5.31878591e-01]
  [  9.26027954e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  5.30363619e-01]
  [  9.24169719e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  5.32127917e-01]
  [  9.25811768e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  5.33724368e-01]
  [  9.26375270e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  5.30665696e-01]
  [  9.23468053e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  5.31987429e-01]
  [  9.24857914e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  5.31378686e-01]
  [  9.23560679e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  5.31320214e-01]
  [  9.24888313e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  5.32407403e-01]
  [  9.23890829e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  5.32077968e-01]
  [  9.25817072e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  5.32029569e-01]
  [  9.25858259e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  5.32012224e-01]
  [  9.25806522e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  5.31858802e-01]
  [  9.25765872e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  5.31506658e-01]
  [  9.25720274e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]

 [[  5.31853378e-01]
  [  9.25679326e-01]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]
  [ -3.40282002e+38]]]
After layer attention_softmax_0 (20, 10, 1) <class 'numpy.float32'> [[[ 0.40280464]
  [ 0.59719533]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.4028326 ]
  [ 0.59716737]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40296733]
  [ 0.59703267]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40276161]
  [ 0.59723842]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40290385]
  [ 0.5970962 ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40271884]
  [ 0.59728116]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40280139]
  [ 0.59719861]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40283081]
  [ 0.59716922]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40307933]
  [ 0.59692073]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40304288]
  [ 0.59695715]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40302649]
  [ 0.59697354]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40319213]
  [ 0.59680784]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40285864]
  [ 0.59714133]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40336022]
  [ 0.59663975]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40281752]
  [ 0.59718251]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40279597]
  [ 0.59720403]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40280426]
  [ 0.59719574]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40277711]
  [ 0.59722286]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40270334]
  [ 0.5972966 ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40279663]
  [ 0.59720337]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]]
After layer batch_dot21_0 (20, 512, 1) <class 'numpy.float32'> [[[ 0.01786385]
  [ 0.03945281]
  [-0.03344879]
  ...,
  [-0.01095853]
  [ 0.00999386]
  [-0.02459152]]

 [[ 0.01786317]
  [ 0.03945203]
  [-0.03344753]
  ...,
  [-0.01095837]
  [ 0.00999383]
  [-0.02459202]]

 [[ 0.01785992]
  [ 0.03944828]
  [-0.03344147]
  ...,
  [-0.01095763]
  [ 0.00999367]
  [-0.0245944 ]]

 ...,
 [[ 0.01786451]
  [ 0.03945358]
  [-0.03345003]
  ...,
  [-0.01095868]
  [ 0.00999389]
  [-0.02459104]]

 [[ 0.01786629]
  [ 0.03945563]
  [-0.03345335]
  ...,
  [-0.01095909]
  [ 0.00999398]
  [-0.02458973]]

 [[ 0.01786404]
  [ 0.03945304]
  [-0.03344915]
  ...,
  [-0.01095857]
  [ 0.00999387]
  [-0.02459138]]]
After layer reshape42_0 (20, 512) <class 'numpy.float32'> [[ 0.01786385  0.03945281 -0.03344879 ..., -0.01095853  0.00999386
  -0.02459152]
 [ 0.01786317  0.03945203 -0.03344753 ..., -0.01095837  0.00999383
  -0.02459202]
 [ 0.01785992  0.03944828 -0.03344147 ..., -0.01095763  0.00999367
  -0.0245944 ]
 ...,
 [ 0.01786451  0.03945358 -0.03345003 ..., -0.01095868  0.00999389
  -0.02459104]
 [ 0.01786629  0.03945563 -0.03345335 ..., -0.01095909  0.00999398
  -0.02458973]
 [ 0.01786404  0.03945304 -0.03344915 ..., -0.01095857  0.00999387
  -0.02459138]]
After layer decoder_rnn_hidden_concat_t0_output (20, 1024) <class 'numpy.float32'> [[-0.00119907 -0.91837567  0.19760287 ..., -0.01095853  0.00999386
  -0.02459152]
 [-0.00119865 -0.91838712  0.19768503 ..., -0.01095837  0.00999383
  -0.02459202]
 [-0.00120047 -0.91861314  0.19727179 ..., -0.01095763  0.00999367
  -0.0245944 ]
 ...,
 [-0.00119881 -0.91838956  0.19748572 ..., -0.01095868  0.00999389
  -0.02459104]
 [-0.00119938 -0.91840887  0.19723399 ..., -0.01095909  0.00999398
  -0.02458973]
 [-0.00119899 -0.9184168   0.19748804 ..., -0.01095857  0.00999387
  -0.02459138]]
After layer decoder_rnn_hidden_fc_t0_output (20, 512) <class 'numpy.float32'> [[-1.97590697  0.2164169  -0.82197815 ...,  1.98444319  2.12205553
  -1.60887527]
 [-1.97568965  0.21590585 -0.82172149 ...,  1.98429167  2.12240481
  -1.60879457]
 [-1.97512984  0.21786816 -0.82446694 ...,  1.98288417  2.12046599
  -1.60984588]
 ...,
 [-1.97630382  0.21722235 -0.82315344 ...,  1.98415017  2.12171555
  -1.60956609]
 [-1.97683275  0.21866372 -0.82460016 ...,  1.98399663  2.12084866
  -1.61000609]
 [-1.97600782  0.21697611 -0.82294989 ...,  1.98407853  2.12168741
  -1.60915136]]
After layer decoder_rnn_next_hidden_t0_output (20, 512) <class 'numpy.float32'> [[-0.96228528  0.2131003  -0.67614514 ...,  0.96291184  0.97170895
  -0.92299366]
 [-0.96226919  0.21261241 -0.67600578 ...,  0.96290082  0.97172844
  -0.92298168]
 [-0.9622277   0.21448523 -0.67749381 ...,  0.96279818  0.97162014
  -0.92313725]
 ...,
 [-0.96231461  0.21386904 -0.67678261 ...,  0.96289051  0.97169    -0.92309588]
 [-0.96235371  0.21524407 -0.67756587 ...,  0.9628793   0.97164154
  -0.92316091]
 [-0.96229273  0.21363404 -0.67667222 ...,  0.96288526  0.97168845
  -0.92303455]]
After layer logits_output (20, 16743) <class 'numpy.float32'> [[-2.01652956 -2.82579231 -2.40849924 ..., -2.09291434 -3.50269365
  -2.59026265]
 [-2.01674342 -2.82592869 -2.40847397 ..., -2.09286737 -3.50270152
  -2.59029651]
 [-2.01553273 -2.82627916 -2.40812278 ..., -2.0939219  -3.50217485
  -2.59110284]
 ...,
 [-2.016608   -2.82592154 -2.40847945 ..., -2.09314704 -3.50243306
  -2.5908823 ]
 [-2.01621914 -2.82578897 -2.40850711 ..., -2.0934267  -3.5021081
  -2.5912807 ]
 [-2.0164609  -2.82588601 -2.40842223 ..., -2.09311128 -3.50240231
  -2.59066319]]
After layer softmax_0 (20, 16743) <class 'numpy.float32'> [[  8.34281252e-07   3.71410636e-07   5.63744436e-07 ...,   7.72928161e-07
    1.88746796e-07   4.70049628e-07]
 [  8.33903869e-07   3.71271284e-07   5.63624212e-07 ...,   7.72780311e-07
    1.88700284e-07   4.69921190e-07]
 [  8.37955099e-07   3.72492991e-07   5.65875439e-07 ...,   7.74777106e-07
    1.89487395e-07   4.71252690e-07]
 ...,
 [  8.35269020e-07   3.71831590e-07   5.64467257e-07 ...,   7.73723684e-07
    1.89034424e-07   4.70351239e-07]
 [  8.36990409e-07   3.72502285e-07   5.65394885e-07 ...,   7.74800071e-07
    1.89411907e-07   4.70949487e-07]
 [  8.35415449e-07   3.71855293e-07   5.64515631e-07 ...,   7.73773706e-07
    1.89045608e-07   4.70467853e-07]]
After layer reshape43_0 (20, 10) <class 'numpy.float32'> [[ 0.40280464  0.59719533  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.4028326   0.59716737  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40296733  0.59703267  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40276161  0.59723842  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40290385  0.5970962   0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40271884  0.59728116  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40280139  0.59719861  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40283081  0.59716922  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40307933  0.59692073  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40304288  0.59695715  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40302649  0.59697354  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40319213  0.59680784  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40285864  0.59714133  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40336022  0.59663975  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40281752  0.59718251  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40279597  0.59720403  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40280426  0.59719574  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40277711  0.59722286  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40270334  0.5972966   0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40279663  0.59720337  0.          0.          0.          0.          0.
   0.          0.          0.        ]]
1.992	conclusion
[14:32:36] /home/ec2-user/danchenk/incubator-mxnet/src/engine/naive_engine.cc:55: Engine shutdown

Process finished with exit code 0
