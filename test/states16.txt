ssh://ec2-user@ec2-52-214-115-94.eu-west-1.compute.amazonaws.com:22/home/ec2-user/.pyenv/versions/3.5.4-trt/bin/python -u /home/ec2-user/kellen/sockeye/test/translate.py
/home/ec2-user/kellen/sockeye/sockeye/__init__.py
/home/ec2-user/danchenk/incubator-mxnet/python/mxnet/__init__.py
[INFO:sockeye.vocab] Vocabulary (22309 words) loaded from "/home/ec2-user/kellen/sockeye/test/wmt_model/vocab.src.json"
[INFO:sockeye.vocab] Vocabulary (16743 words) loaded from "/home/ec2-user/kellen/sockeye/test/wmt_model/vocab.trg.json"
[INFO:sockeye.inference] Model version: 1.16.2
[INFO:sockeye.model] ModelConfig loaded from "/home/ec2-user/kellen/sockeye/test/wmt_model/config"
[INFO:sockeye.model] Config[_frozen=True, config_data=Config[_frozen=True, data_statistics=Config[_frozen=True, average_len_target_per_bucket=[5.6599009900989845, 14.83566261975379, 23.622827780137886, 32.348828135886386, 40.9103269172012, 49.4851570964248], buckets=[(10, 10), (20, 20), (30, 30), (40, 40), (50, 50), (60, 60)], length_ratio_mean=0.9875086015461053, length_ratio_std=0.4514233014884626, max_observed_len_source=60, max_observed_len_target=60, num_discarded=6631, num_sents=193369, num_sents_per_bucket=[32320, 46867, 49431, 35883, 19638, 9230], num_tokens_source=4563547, num_tokens_target=4466849, num_unks_source=0, num_unks_target=0, size_vocab_source=22309, size_vocab_target=16743], max_seq_len_source=60, max_seq_len_target=60, num_shards=1, shared_vocab=False, source=/home/ec2-user/kellen/data/training/corpus.tc.BPE.de.200K, target=/home/ec2-user/kellen/data/training/corpus.tc.BPE.en.200K, vocab_source=None, vocab_target=None], config_decoder=Config[_frozen=True, attention_config=Config[_frozen=True, config_coverage=None, input_previous_word=False, layer_normalization=False, num_heads=None, num_hidden=512, query_num_hidden=512, source_num_hidden=512, type=dot], attention_in_upper_layers=False, context_gating=False, dtype=<class 'numpy.float16'>, hidden_dropout=0.0, layer_normalization=False, max_seq_len_source=60, rnn_config=Config[_frozen=True, cell_type=lstm, dropout_inputs=0.0, dropout_recurrent=0.0, dropout_states=0.0, first_residual_layer=2, forget_bias=0.0, num_hidden=512, num_layers=1, residual=False], state_init=last, use_fp16=False], config_embed_source=Config[_frozen=True, dropout=0.0, num_embed=256, vocab_size=22309], config_embed_target=Config[_frozen=True, dropout=0.0, num_embed=256, vocab_size=16743], config_encoder=Config[_frozen=True, conv_config=None, dtype=<class 'numpy.float16'>, reverse_input=False, rnn_config=Config[_frozen=True, cell_type=lstm, dropout_inputs=0.0, dropout_recurrent=0.0, dropout_states=0.0, first_residual_layer=2, forget_bias=0.0, num_hidden=512, num_layers=1, residual=False], use_fp16=False], config_loss=Config[_frozen=True, label_smoothing=0.0, name=cross-entropy, normalization_type=valid, vocab_size=16743], max_seq_len_source=60, max_seq_len_target=60, vocab_source_size=22309, vocab_target_size=16743, weight_normalization=False, weight_tying=False, weight_tying_type=None]
[INFO:sockeye.encoder] Encoder EncoderSequence dtype float16
[INFO:sockeye.encoder] Encoder BatchMajor2TimeMajor dtype float16
[INFO:sockeye.encoder] Encoder BiDirectionalRNNEncoder dtype float16
[INFO:sockeye.encoder] Encoder RecurrentEncoder dtype float16
[INFO:sockeye.encoder] Encoder RecurrentEncoder dtype float16
[INFO:sockeye.decoder] Decoder RecurrentDecoder dtype float16
[INFO:sockeye.model] Encoder EncoderSequence dtype: float16
[INFO:sockeye.model] Decoder RecurrentDecoder dtype: float16
[INFO:sockeye.encoder] Encoder Embedding dtype float16
[INFO:sockeye.encoder] Encoder Embedding dtype float16
[WARNING:sockeye.inference] Model was only trained with sentences up to a length of 60, but a max_input_len of 256 is used.
[14:31:39] /home/ec2-user/danchenk/incubator-mxnet/src/engine/engine.cc:55: MXNet start using engine: NaiveEngine
[INFO:sockeye.model] Loaded params from "/home/ec2-user/kellen/sockeye/test/wmt_model/params.best"
[INFO:sockeye.inference] Translator (1 model(s) beam_size=20 ensemble_mode=None batch_size=1 buckets_source=[10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, 120, 130, 140, 150, 160, 170, 180, 190, 200, 210, 220, 230, 240, 250, 256])
After layer source_embed_embed_0 (1, 10, 256) <class 'numpy.float16'> [[[-0.00175095 -0.0164032  -0.0703125  ...,  0.00574493 -0.01233673
    0.0269928 ]
  [-0.06872559 -0.00477982 -0.00354767 ..., -0.06140137 -0.04299927
    0.03726196]
  [ 0.06011963  0.00928497  0.03005981 ...,  0.06628418  0.02203369
   -0.06420898]
  ...,
  [ 0.06011963  0.00928497  0.03005981 ...,  0.06628418  0.02203369
   -0.06420898]
  [ 0.06011963  0.00928497  0.03005981 ...,  0.06628418  0.02203369
   -0.06420898]
  [ 0.06011963  0.00928497  0.03005981 ...,  0.06628418  0.02203369
   -0.06420898]]]
After layer swapaxes10_output (10, 1, 256) <class 'numpy.float16'> [[[-0.00175095 -0.0164032  -0.0703125  ...,  0.00574493 -0.01233673
    0.0269928 ]]

 [[-0.06872559 -0.00477982 -0.00354767 ..., -0.06140137 -0.04299927
    0.03726196]]

 [[ 0.06011963  0.00928497  0.03005981 ...,  0.06628418  0.02203369
   -0.06420898]]

 ...,
 [[ 0.06011963  0.00928497  0.03005981 ...,  0.06628418  0.02203369
   -0.06420898]]

 [[ 0.06011963  0.00928497  0.03005981 ...,  0.06628418  0.02203369
   -0.06420898]]

 [[ 0.06011963  0.00928497  0.03005981 ...,  0.06628418  0.02203369
   -0.06420898]]]
After layer split4_output0 (1, 256) <class 'numpy.float16'> [[ -1.75094604e-03  -1.64031982e-02  -7.03125000e-02   3.06243896e-02
   -5.19409180e-02  -2.61383057e-02  -1.62506104e-02  -4.49218750e-02
   -7.18593597e-04   2.31018066e-02   5.72814941e-02  -7.00073242e-02
    8.66088867e-02  -6.09436035e-02   4.63867188e-02  -8.91723633e-02
   -3.99169922e-02   4.47692871e-02   6.22863770e-02   3.35388184e-02
    4.08935547e-02  -1.47018433e-02  -5.96618652e-02  -4.84924316e-02
   -1.29013062e-02   4.08325195e-02  -7.45239258e-02  -4.81262207e-02
    1.84936523e-02   6.60400391e-02  -8.18634033e-03  -8.49609375e-02
    7.13500977e-02   2.64892578e-02  -5.14221191e-02   8.77685547e-02
   -3.56292725e-03   4.24804688e-02   4.79507446e-03   8.68530273e-02
    5.55419922e-02  -5.71899414e-02  -6.66379929e-05  -5.02014160e-02
   -6.50024414e-02  -7.35473633e-02  -6.50024414e-02   6.91604614e-03
   -4.83703613e-02   3.69567871e-02   3.84826660e-02  -8.99658203e-02
   -7.94677734e-02  -2.89154053e-02   1.76086426e-02  -2.56958008e-02
   -8.03222656e-02  -8.96930695e-04  -2.29644775e-02   6.87255859e-02
    7.87353516e-02   8.48388672e-02  -8.77075195e-02   3.80859375e-02
    4.70275879e-02   1.64794922e-02   4.80041504e-02   5.49621582e-02
    1.05895996e-02   3.70483398e-02  -2.94036865e-02   1.57165527e-02
    8.14056396e-03   2.80456543e-02  -9.49707031e-02   4.28161621e-02
   -3.33557129e-02   3.94287109e-02   2.30865479e-02  -6.39343262e-03
    6.87789917e-03  -6.32324219e-02   4.43115234e-02   5.30700684e-02
    7.01293945e-02   9.04541016e-02   5.86853027e-02  -2.09197998e-02
   -5.39245605e-02  -9.89913940e-04  -1.98669434e-02  -4.91638184e-02
    8.55712891e-02  -7.08007812e-02   4.53186035e-02   2.46276855e-02
   -3.30505371e-02   6.35375977e-02   9.27734375e-02   6.46972656e-02
    4.85534668e-02   2.13165283e-02  -7.03735352e-02   3.72314453e-02
   -9.88769531e-03  -5.31921387e-02  -3.93390656e-05   6.41479492e-02
    2.13012695e-02  -9.07592773e-02   7.87963867e-02  -9.22851562e-02
   -1.34811401e-02   9.36889648e-02  -4.03747559e-02   3.54919434e-02
    2.44140625e-02   3.03497314e-02  -9.39941406e-02  -3.61633301e-02
   -7.84301758e-02  -6.00433350e-03  -8.94775391e-02  -7.80029297e-02
    6.12792969e-02   6.24084473e-02  -5.09948730e-02   7.50732422e-02
   -1.14898682e-02   5.39855957e-02   1.90429688e-02  -1.08413696e-02
    1.87683105e-02   5.22155762e-02   3.15246582e-02  -6.48193359e-02
    8.28857422e-02  -9.52148438e-02  -2.36511230e-02  -6.02111816e-02
    6.54296875e-02   2.20794678e-02   5.34362793e-02   9.44824219e-02
    4.73937988e-02   6.45141602e-02  -5.77697754e-02   2.14233398e-02
   -2.18963623e-02   6.32934570e-02   3.09143066e-02  -6.65283203e-02
   -2.84881592e-02   7.99560547e-02  -2.42004395e-02  -9.03320312e-02
   -4.91027832e-02  -4.82788086e-02  -5.17272949e-02  -8.64257812e-02
   -7.20596313e-03  -3.64685059e-02  -7.72857666e-03  -1.00860596e-02
   -9.68170166e-03  -7.68432617e-02   8.88671875e-02  -4.43420410e-02
   -3.70788574e-02   1.91192627e-02  -2.69317627e-02  -7.25708008e-02
   -1.19781494e-03   5.15747070e-02  -9.18579102e-02   2.07977295e-02
    3.40576172e-02  -7.94677734e-02   3.50952148e-02   7.12890625e-02
   -3.65295410e-02   8.11157227e-02   5.85937500e-02  -1.91040039e-02
    7.52639771e-03  -5.55725098e-02   6.59561157e-03   8.09936523e-02
    1.13449097e-02   3.52783203e-02  -2.69622803e-02  -7.88574219e-02
    9.19342041e-03   4.10461426e-02  -1.50489807e-03   6.55746460e-03
    1.35345459e-02  -9.20410156e-02   1.93328857e-02  -8.72802734e-02
    7.85522461e-02  -7.56835938e-02  -3.75671387e-02   7.18383789e-02
   -6.65283203e-02  -1.42364502e-02  -4.59289551e-03  -2.31323242e-02
   -7.43865967e-03   1.91879272e-03  -2.13165283e-02   9.43756104e-03
    9.24072266e-02   3.81774902e-02  -1.27105713e-02   5.32836914e-02
    3.09906006e-02  -5.84716797e-02   5.46569824e-02   6.27441406e-02
   -2.81066895e-02  -8.21533203e-02   7.26928711e-02  -1.46560669e-02
   -7.08618164e-02  -6.82373047e-02   6.75659180e-02  -7.94677734e-02
    5.14831543e-02   1.47018433e-02   6.58569336e-02  -7.11059570e-02
   -4.29687500e-02   4.22973633e-02  -1.16195679e-02   6.43310547e-02
    6.09130859e-02  -6.90078735e-03  -6.05163574e-02   2.84881592e-02
   -6.09130859e-02  -6.51855469e-02  -3.97949219e-02   3.13415527e-02
    2.64892578e-02   1.49688721e-02  -3.68118286e-03  -5.97534180e-02
    4.87518311e-03  -9.42993164e-02   4.44335938e-02  -8.22143555e-02
    3.35083008e-02   5.74493408e-03  -1.23367310e-02   2.69927979e-02]]
After layer split4_output1 (1, 256) <class 'numpy.float16'> [[-0.06872559 -0.00477982 -0.00354767 -0.01820374 -0.01612854  0.08428955
  -0.06951904  0.00264549 -0.06427002  0.05566406  0.03616333  0.06744385
   0.01268768  0.02503967 -0.00322533  0.00941467 -0.03817749 -0.01480103
  -0.06390381 -0.00082541 -0.04299927  0.05258179 -0.03115845 -0.04760742
  -0.01341248  0.00824738 -0.03616333  0.05459595 -0.00548172 -0.08770752
  -0.0380249   0.02459717 -0.05517578 -0.06402588  0.06884766  0.07977295
   0.03912354  0.04818726  0.09075928  0.02204895 -0.09381104 -0.05026245
  -0.06982422  0.02409363 -0.0067482  -0.00616837 -0.02383423  0.05352783
   0.08691406 -0.06396484  0.04638672  0.08349609 -0.03488159 -0.09228516
   0.08404541  0.07086182 -0.04742432  0.02374268 -0.08935547  0.07965088
  -0.07897949  0.03561401  0.06286621  0.06707764  0.015625   -0.04220581
  -0.03765869 -0.01841736  0.00150776 -0.01802063 -0.09423828  0.07720947
   0.03140259 -0.0836792  -0.0725708  -0.04382324  0.00515366 -0.00694656
  -0.05938721  0.03411865  0.09222412  0.04168701  0.03198242 -0.00574875
   0.02363586  0.07275391 -0.0791626   0.0692749  -0.04470825 -0.06378174
   0.07495117 -0.0425415   0.09332275  0.08538818 -0.06231689  0.05157471
   0.04559326 -0.07385254 -0.03271484 -0.040802   -0.05093384  0.03372192
   0.0453186   0.01898193  0.02832031  0.02198792 -0.05975342  0.02789307
  -0.06890869  0.07781982 -0.0451355   0.06726074  0.01552582  0.02284241
   0.0793457   0.09033203  0.05105591  0.06140137  0.00379372  0.02333069
   0.078125    0.01802063  0.04208374  0.05169678  0.08758545 -0.04968262
   0.06512451  0.0064621   0.02359009  0.01506805 -0.03088379  0.0725708
   0.00184059  0.07592773  0.04055786  0.07019043  0.01560211  0.06787109
  -0.00635147  0.01701355 -0.00484848 -0.06152344  0.08978271  0.06109619
  -0.08135986  0.07098389 -0.08624268  0.07788086 -0.02548218 -0.02539062
  -0.04089355 -0.03823853  0.07440186  0.04370117 -0.01373291  0.02972412
   0.03491211 -0.03488159  0.07348633  0.02772522 -0.07122803  0.04489136
   0.03134155  0.06896973  0.00819397 -0.05523682 -0.03001404 -0.08703613
   0.08984375 -0.02163696  0.07391357  0.08508301 -0.06445312 -0.05703735
  -0.01725769  0.02288818  0.09173584  0.0064621   0.05944824  0.07824707
  -0.03109741 -0.05822754 -0.04455566 -0.07830811 -0.03317261 -0.07208252
  -0.04022217  0.0355835   0.06433105 -0.06378174 -0.0163269   0.03146362
  -0.04788208 -0.08764648 -0.06896973  0.06286621 -0.09527588 -0.08459473
  -0.05029297 -0.09246826  0.03024292 -0.03356934  0.05667114 -0.00226593
   0.08392334  0.02262878 -0.0247345  -0.0089798   0.05606079 -0.07501221
  -0.04611206 -0.04418945  0.05441284  0.00803375  0.09259033 -0.03710938
  -0.08795166 -0.04641724  0.01368713  0.02748108  0.03753662  0.06182861
  -0.07946777 -0.02145386 -0.02024841  0.03305054 -0.00712204  0.07513428
  -0.07617188 -0.00623322 -0.02082825 -0.00763702 -0.03875732 -0.00661469
  -0.03726196 -0.07226562  0.08209229  0.00625992  0.04260254  0.09307861
  -0.07598877  0.05856323 -0.05401611  0.09051514 -0.02059937  0.02522278
  -0.07348633 -0.07568359  0.03039551 -0.06561279  0.02690125  0.06768799
   0.07397461 -0.06140137 -0.04299927  0.03726196]]
After layer split4_output2 (1, 256) <class 'numpy.float16'> [[ 0.06011963  0.00928497  0.03005981 -0.03009033 -0.03494263  0.00979614
   0.04443359  0.0892334  -0.0647583   0.06057739 -0.03366089 -0.0413208
   0.05426025  0.00199127 -0.04977417 -0.01615906  0.02236938  0.04937744
  -0.07427979  0.01543427  0.03674316 -0.07714844  0.00384521  0.04898071
   0.04669189  0.0435791   0.05166626 -0.03117371  0.00643921 -0.0916748
  -0.06555176  0.04605103  0.03308105 -0.02362061 -0.05386353  0.05136108
  -0.05328369  0.00138664  0.0087204   0.0222168  -0.08197021  0.01593018
  -0.09448242 -0.01968384 -0.05157471 -0.02156067  0.09191895 -0.0456543
  -0.01366425  0.02568054  0.05508423 -0.06210327 -0.06109619  0.09179688
   0.034729    0.00032783  0.08184814 -0.00460052 -0.06396484 -0.07873535
  -0.07684326  0.03585815  0.03106689 -0.02568054 -0.09423828  0.09216309
   0.05581665 -0.07940674 -0.00190926  0.01980591 -0.01357269 -0.07611084
  -0.03887939 -0.06494141 -0.03253174  0.00991821  0.06130981  0.06057739
  -0.02391052 -0.05252075  0.05300903 -0.06097412  0.06945801  0.03237915
   0.07281494 -0.03497314  0.01681519 -0.01838684  0.03123474  0.05499268
   0.03588867 -0.06677246  0.01105499  0.08728027  0.07897949 -0.04669189
   0.01126862  0.08270264  0.07562256 -0.08111572 -0.07165527  0.0562439
   0.09436035  0.03012085  0.07299805  0.05389404 -0.06439209  0.03515625
   0.09405518  0.03613281 -0.04663086 -0.00576401 -0.03102112  0.0838623
  -0.04074097 -0.05682373 -0.0304718  -0.04257202  0.06616211  0.08886719
  -0.08056641 -0.00977325  0.0760498  -0.06884766 -0.05273438  0.04104614
   0.0186615   0.05349731 -0.05892944  0.05801392  0.07830811  0.00614548
  -0.06091309  0.04446411  0.00978851  0.00144386 -0.07788086  0.08276367
   0.07202148  0.08605957 -0.04882812  0.00289917  0.03555298  0.07757568
  -0.07965088  0.03540039 -0.0254364  -0.05508423  0.05841064 -0.03363037
   0.07727051  0.02099609  0.07696533 -0.0352478  -0.06634521 -0.01145172
  -0.05770874  0.02613831  0.06896973  0.02345276 -0.03134155 -0.03076172
  -0.0869751  -0.05670166 -0.04318237  0.01870728  0.06878662  0.08166504
   0.05862427  0.06976318  0.01977539 -0.0680542   0.07312012  0.04721069
   0.04644775  0.06045532 -0.07788086 -0.02279663  0.00743866  0.01916504
   0.05877686 -0.05581665  0.02497864  0.08215332 -0.04962158 -0.04550171
  -0.07220459  0.02761841 -0.00298882 -0.01675415  0.06939697 -0.08612061
   0.09387207  0.06481934  0.00206184  0.08013916 -0.00548172  0.01785278
   0.04898071 -0.06671143 -0.00177479 -0.04730225  0.02372742  0.05212402
  -0.06420898 -0.0300293  -0.04797363 -0.05340576 -0.06292725 -0.07714844
   0.0657959  -0.03717041 -0.0149765   0.06335449 -0.04147339 -0.05319214
   0.00527573  0.01927185  0.01180267  0.0838623   0.00623322 -0.00313187
   0.09326172  0.03146362  0.00914001  0.09161377  0.06488037 -0.06155396
   0.02760315 -0.06207275 -0.06124878 -0.01649475  0.06549072 -0.01605225
  -0.0793457  -0.02545166 -0.08441162 -0.04592896 -0.06707764  0.06787109
  -0.00608063  0.02279663 -0.0328064   0.04278564 -0.05740356 -0.04873657
   0.06732178 -0.05264282 -0.06866455  0.07745361 -0.03759766 -0.0319519
  -0.05053711  0.06628418  0.02203369 -0.06420898]]
After layer split4_output3 (1, 256) <class 'numpy.float16'> [[ 0.06011963  0.00928497  0.03005981 -0.03009033 -0.03494263  0.00979614
   0.04443359  0.0892334  -0.0647583   0.06057739 -0.03366089 -0.0413208
   0.05426025  0.00199127 -0.04977417 -0.01615906  0.02236938  0.04937744
  -0.07427979  0.01543427  0.03674316 -0.07714844  0.00384521  0.04898071
   0.04669189  0.0435791   0.05166626 -0.03117371  0.00643921 -0.0916748
  -0.06555176  0.04605103  0.03308105 -0.02362061 -0.05386353  0.05136108
  -0.05328369  0.00138664  0.0087204   0.0222168  -0.08197021  0.01593018
  -0.09448242 -0.01968384 -0.05157471 -0.02156067  0.09191895 -0.0456543
  -0.01366425  0.02568054  0.05508423 -0.06210327 -0.06109619  0.09179688
   0.034729    0.00032783  0.08184814 -0.00460052 -0.06396484 -0.07873535
  -0.07684326  0.03585815  0.03106689 -0.02568054 -0.09423828  0.09216309
   0.05581665 -0.07940674 -0.00190926  0.01980591 -0.01357269 -0.07611084
  -0.03887939 -0.06494141 -0.03253174  0.00991821  0.06130981  0.06057739
  -0.02391052 -0.05252075  0.05300903 -0.06097412  0.06945801  0.03237915
   0.07281494 -0.03497314  0.01681519 -0.01838684  0.03123474  0.05499268
   0.03588867 -0.06677246  0.01105499  0.08728027  0.07897949 -0.04669189
   0.01126862  0.08270264  0.07562256 -0.08111572 -0.07165527  0.0562439
   0.09436035  0.03012085  0.07299805  0.05389404 -0.06439209  0.03515625
   0.09405518  0.03613281 -0.04663086 -0.00576401 -0.03102112  0.0838623
  -0.04074097 -0.05682373 -0.0304718  -0.04257202  0.06616211  0.08886719
  -0.08056641 -0.00977325  0.0760498  -0.06884766 -0.05273438  0.04104614
   0.0186615   0.05349731 -0.05892944  0.05801392  0.07830811  0.00614548
  -0.06091309  0.04446411  0.00978851  0.00144386 -0.07788086  0.08276367
   0.07202148  0.08605957 -0.04882812  0.00289917  0.03555298  0.07757568
  -0.07965088  0.03540039 -0.0254364  -0.05508423  0.05841064 -0.03363037
   0.07727051  0.02099609  0.07696533 -0.0352478  -0.06634521 -0.01145172
  -0.05770874  0.02613831  0.06896973  0.02345276 -0.03134155 -0.03076172
  -0.0869751  -0.05670166 -0.04318237  0.01870728  0.06878662  0.08166504
   0.05862427  0.06976318  0.01977539 -0.0680542   0.07312012  0.04721069
   0.04644775  0.06045532 -0.07788086 -0.02279663  0.00743866  0.01916504
   0.05877686 -0.05581665  0.02497864  0.08215332 -0.04962158 -0.04550171
  -0.07220459  0.02761841 -0.00298882 -0.01675415  0.06939697 -0.08612061
   0.09387207  0.06481934  0.00206184  0.08013916 -0.00548172  0.01785278
   0.04898071 -0.06671143 -0.00177479 -0.04730225  0.02372742  0.05212402
  -0.06420898 -0.0300293  -0.04797363 -0.05340576 -0.06292725 -0.07714844
   0.0657959  -0.03717041 -0.0149765   0.06335449 -0.04147339 -0.05319214
   0.00527573  0.01927185  0.01180267  0.0838623   0.00623322 -0.00313187
   0.09326172  0.03146362  0.00914001  0.09161377  0.06488037 -0.06155396
   0.02760315 -0.06207275 -0.06124878 -0.01649475  0.06549072 -0.01605225
  -0.0793457  -0.02545166 -0.08441162 -0.04592896 -0.06707764  0.06787109
  -0.00608063  0.02279663 -0.0328064   0.04278564 -0.05740356 -0.04873657
   0.06732178 -0.05264282 -0.06866455  0.07745361 -0.03759766 -0.0319519
  -0.05053711  0.06628418  0.02203369 -0.06420898]]
After layer split4_output4 (1, 256) <class 'numpy.float16'> [[ 0.06011963  0.00928497  0.03005981 -0.03009033 -0.03494263  0.00979614
   0.04443359  0.0892334  -0.0647583   0.06057739 -0.03366089 -0.0413208
   0.05426025  0.00199127 -0.04977417 -0.01615906  0.02236938  0.04937744
  -0.07427979  0.01543427  0.03674316 -0.07714844  0.00384521  0.04898071
   0.04669189  0.0435791   0.05166626 -0.03117371  0.00643921 -0.0916748
  -0.06555176  0.04605103  0.03308105 -0.02362061 -0.05386353  0.05136108
  -0.05328369  0.00138664  0.0087204   0.0222168  -0.08197021  0.01593018
  -0.09448242 -0.01968384 -0.05157471 -0.02156067  0.09191895 -0.0456543
  -0.01366425  0.02568054  0.05508423 -0.06210327 -0.06109619  0.09179688
   0.034729    0.00032783  0.08184814 -0.00460052 -0.06396484 -0.07873535
  -0.07684326  0.03585815  0.03106689 -0.02568054 -0.09423828  0.09216309
   0.05581665 -0.07940674 -0.00190926  0.01980591 -0.01357269 -0.07611084
  -0.03887939 -0.06494141 -0.03253174  0.00991821  0.06130981  0.06057739
  -0.02391052 -0.05252075  0.05300903 -0.06097412  0.06945801  0.03237915
   0.07281494 -0.03497314  0.01681519 -0.01838684  0.03123474  0.05499268
   0.03588867 -0.06677246  0.01105499  0.08728027  0.07897949 -0.04669189
   0.01126862  0.08270264  0.07562256 -0.08111572 -0.07165527  0.0562439
   0.09436035  0.03012085  0.07299805  0.05389404 -0.06439209  0.03515625
   0.09405518  0.03613281 -0.04663086 -0.00576401 -0.03102112  0.0838623
  -0.04074097 -0.05682373 -0.0304718  -0.04257202  0.06616211  0.08886719
  -0.08056641 -0.00977325  0.0760498  -0.06884766 -0.05273438  0.04104614
   0.0186615   0.05349731 -0.05892944  0.05801392  0.07830811  0.00614548
  -0.06091309  0.04446411  0.00978851  0.00144386 -0.07788086  0.08276367
   0.07202148  0.08605957 -0.04882812  0.00289917  0.03555298  0.07757568
  -0.07965088  0.03540039 -0.0254364  -0.05508423  0.05841064 -0.03363037
   0.07727051  0.02099609  0.07696533 -0.0352478  -0.06634521 -0.01145172
  -0.05770874  0.02613831  0.06896973  0.02345276 -0.03134155 -0.03076172
  -0.0869751  -0.05670166 -0.04318237  0.01870728  0.06878662  0.08166504
   0.05862427  0.06976318  0.01977539 -0.0680542   0.07312012  0.04721069
   0.04644775  0.06045532 -0.07788086 -0.02279663  0.00743866  0.01916504
   0.05877686 -0.05581665  0.02497864  0.08215332 -0.04962158 -0.04550171
  -0.07220459  0.02761841 -0.00298882 -0.01675415  0.06939697 -0.08612061
   0.09387207  0.06481934  0.00206184  0.08013916 -0.00548172  0.01785278
   0.04898071 -0.06671143 -0.00177479 -0.04730225  0.02372742  0.05212402
  -0.06420898 -0.0300293  -0.04797363 -0.05340576 -0.06292725 -0.07714844
   0.0657959  -0.03717041 -0.0149765   0.06335449 -0.04147339 -0.05319214
   0.00527573  0.01927185  0.01180267  0.0838623   0.00623322 -0.00313187
   0.09326172  0.03146362  0.00914001  0.09161377  0.06488037 -0.06155396
   0.02760315 -0.06207275 -0.06124878 -0.01649475  0.06549072 -0.01605225
  -0.0793457  -0.02545166 -0.08441162 -0.04592896 -0.06707764  0.06787109
  -0.00608063  0.02279663 -0.0328064   0.04278564 -0.05740356 -0.04873657
   0.06732178 -0.05264282 -0.06866455  0.07745361 -0.03759766 -0.0319519
  -0.05053711  0.06628418  0.02203369 -0.06420898]]
After layer split4_output5 (1, 256) <class 'numpy.float16'> [[ 0.06011963  0.00928497  0.03005981 -0.03009033 -0.03494263  0.00979614
   0.04443359  0.0892334  -0.0647583   0.06057739 -0.03366089 -0.0413208
   0.05426025  0.00199127 -0.04977417 -0.01615906  0.02236938  0.04937744
  -0.07427979  0.01543427  0.03674316 -0.07714844  0.00384521  0.04898071
   0.04669189  0.0435791   0.05166626 -0.03117371  0.00643921 -0.0916748
  -0.06555176  0.04605103  0.03308105 -0.02362061 -0.05386353  0.05136108
  -0.05328369  0.00138664  0.0087204   0.0222168  -0.08197021  0.01593018
  -0.09448242 -0.01968384 -0.05157471 -0.02156067  0.09191895 -0.0456543
  -0.01366425  0.02568054  0.05508423 -0.06210327 -0.06109619  0.09179688
   0.034729    0.00032783  0.08184814 -0.00460052 -0.06396484 -0.07873535
  -0.07684326  0.03585815  0.03106689 -0.02568054 -0.09423828  0.09216309
   0.05581665 -0.07940674 -0.00190926  0.01980591 -0.01357269 -0.07611084
  -0.03887939 -0.06494141 -0.03253174  0.00991821  0.06130981  0.06057739
  -0.02391052 -0.05252075  0.05300903 -0.06097412  0.06945801  0.03237915
   0.07281494 -0.03497314  0.01681519 -0.01838684  0.03123474  0.05499268
   0.03588867 -0.06677246  0.01105499  0.08728027  0.07897949 -0.04669189
   0.01126862  0.08270264  0.07562256 -0.08111572 -0.07165527  0.0562439
   0.09436035  0.03012085  0.07299805  0.05389404 -0.06439209  0.03515625
   0.09405518  0.03613281 -0.04663086 -0.00576401 -0.03102112  0.0838623
  -0.04074097 -0.05682373 -0.0304718  -0.04257202  0.06616211  0.08886719
  -0.08056641 -0.00977325  0.0760498  -0.06884766 -0.05273438  0.04104614
   0.0186615   0.05349731 -0.05892944  0.05801392  0.07830811  0.00614548
  -0.06091309  0.04446411  0.00978851  0.00144386 -0.07788086  0.08276367
   0.07202148  0.08605957 -0.04882812  0.00289917  0.03555298  0.07757568
  -0.07965088  0.03540039 -0.0254364  -0.05508423  0.05841064 -0.03363037
   0.07727051  0.02099609  0.07696533 -0.0352478  -0.06634521 -0.01145172
  -0.05770874  0.02613831  0.06896973  0.02345276 -0.03134155 -0.03076172
  -0.0869751  -0.05670166 -0.04318237  0.01870728  0.06878662  0.08166504
   0.05862427  0.06976318  0.01977539 -0.0680542   0.07312012  0.04721069
   0.04644775  0.06045532 -0.07788086 -0.02279663  0.00743866  0.01916504
   0.05877686 -0.05581665  0.02497864  0.08215332 -0.04962158 -0.04550171
  -0.07220459  0.02761841 -0.00298882 -0.01675415  0.06939697 -0.08612061
   0.09387207  0.06481934  0.00206184  0.08013916 -0.00548172  0.01785278
   0.04898071 -0.06671143 -0.00177479 -0.04730225  0.02372742  0.05212402
  -0.06420898 -0.0300293  -0.04797363 -0.05340576 -0.06292725 -0.07714844
   0.0657959  -0.03717041 -0.0149765   0.06335449 -0.04147339 -0.05319214
   0.00527573  0.01927185  0.01180267  0.0838623   0.00623322 -0.00313187
   0.09326172  0.03146362  0.00914001  0.09161377  0.06488037 -0.06155396
   0.02760315 -0.06207275 -0.06124878 -0.01649475  0.06549072 -0.01605225
  -0.0793457  -0.02545166 -0.08441162 -0.04592896 -0.06707764  0.06787109
  -0.00608063  0.02279663 -0.0328064   0.04278564 -0.05740356 -0.04873657
   0.06732178 -0.05264282 -0.06866455  0.07745361 -0.03759766 -0.0319519
  -0.05053711  0.06628418  0.02203369 -0.06420898]]
After layer split4_output6 (1, 256) <class 'numpy.float16'> [[ 0.06011963  0.00928497  0.03005981 -0.03009033 -0.03494263  0.00979614
   0.04443359  0.0892334  -0.0647583   0.06057739 -0.03366089 -0.0413208
   0.05426025  0.00199127 -0.04977417 -0.01615906  0.02236938  0.04937744
  -0.07427979  0.01543427  0.03674316 -0.07714844  0.00384521  0.04898071
   0.04669189  0.0435791   0.05166626 -0.03117371  0.00643921 -0.0916748
  -0.06555176  0.04605103  0.03308105 -0.02362061 -0.05386353  0.05136108
  -0.05328369  0.00138664  0.0087204   0.0222168  -0.08197021  0.01593018
  -0.09448242 -0.01968384 -0.05157471 -0.02156067  0.09191895 -0.0456543
  -0.01366425  0.02568054  0.05508423 -0.06210327 -0.06109619  0.09179688
   0.034729    0.00032783  0.08184814 -0.00460052 -0.06396484 -0.07873535
  -0.07684326  0.03585815  0.03106689 -0.02568054 -0.09423828  0.09216309
   0.05581665 -0.07940674 -0.00190926  0.01980591 -0.01357269 -0.07611084
  -0.03887939 -0.06494141 -0.03253174  0.00991821  0.06130981  0.06057739
  -0.02391052 -0.05252075  0.05300903 -0.06097412  0.06945801  0.03237915
   0.07281494 -0.03497314  0.01681519 -0.01838684  0.03123474  0.05499268
   0.03588867 -0.06677246  0.01105499  0.08728027  0.07897949 -0.04669189
   0.01126862  0.08270264  0.07562256 -0.08111572 -0.07165527  0.0562439
   0.09436035  0.03012085  0.07299805  0.05389404 -0.06439209  0.03515625
   0.09405518  0.03613281 -0.04663086 -0.00576401 -0.03102112  0.0838623
  -0.04074097 -0.05682373 -0.0304718  -0.04257202  0.06616211  0.08886719
  -0.08056641 -0.00977325  0.0760498  -0.06884766 -0.05273438  0.04104614
   0.0186615   0.05349731 -0.05892944  0.05801392  0.07830811  0.00614548
  -0.06091309  0.04446411  0.00978851  0.00144386 -0.07788086  0.08276367
   0.07202148  0.08605957 -0.04882812  0.00289917  0.03555298  0.07757568
  -0.07965088  0.03540039 -0.0254364  -0.05508423  0.05841064 -0.03363037
   0.07727051  0.02099609  0.07696533 -0.0352478  -0.06634521 -0.01145172
  -0.05770874  0.02613831  0.06896973  0.02345276 -0.03134155 -0.03076172
  -0.0869751  -0.05670166 -0.04318237  0.01870728  0.06878662  0.08166504
   0.05862427  0.06976318  0.01977539 -0.0680542   0.07312012  0.04721069
   0.04644775  0.06045532 -0.07788086 -0.02279663  0.00743866  0.01916504
   0.05877686 -0.05581665  0.02497864  0.08215332 -0.04962158 -0.04550171
  -0.07220459  0.02761841 -0.00298882 -0.01675415  0.06939697 -0.08612061
   0.09387207  0.06481934  0.00206184  0.08013916 -0.00548172  0.01785278
   0.04898071 -0.06671143 -0.00177479 -0.04730225  0.02372742  0.05212402
  -0.06420898 -0.0300293  -0.04797363 -0.05340576 -0.06292725 -0.07714844
   0.0657959  -0.03717041 -0.0149765   0.06335449 -0.04147339 -0.05319214
   0.00527573  0.01927185  0.01180267  0.0838623   0.00623322 -0.00313187
   0.09326172  0.03146362  0.00914001  0.09161377  0.06488037 -0.06155396
   0.02760315 -0.06207275 -0.06124878 -0.01649475  0.06549072 -0.01605225
  -0.0793457  -0.02545166 -0.08441162 -0.04592896 -0.06707764  0.06787109
  -0.00608063  0.02279663 -0.0328064   0.04278564 -0.05740356 -0.04873657
   0.06732178 -0.05264282 -0.06866455  0.07745361 -0.03759766 -0.0319519
  -0.05053711  0.06628418  0.02203369 -0.06420898]]
After layer split4_output7 (1, 256) <class 'numpy.float16'> [[ 0.06011963  0.00928497  0.03005981 -0.03009033 -0.03494263  0.00979614
   0.04443359  0.0892334  -0.0647583   0.06057739 -0.03366089 -0.0413208
   0.05426025  0.00199127 -0.04977417 -0.01615906  0.02236938  0.04937744
  -0.07427979  0.01543427  0.03674316 -0.07714844  0.00384521  0.04898071
   0.04669189  0.0435791   0.05166626 -0.03117371  0.00643921 -0.0916748
  -0.06555176  0.04605103  0.03308105 -0.02362061 -0.05386353  0.05136108
  -0.05328369  0.00138664  0.0087204   0.0222168  -0.08197021  0.01593018
  -0.09448242 -0.01968384 -0.05157471 -0.02156067  0.09191895 -0.0456543
  -0.01366425  0.02568054  0.05508423 -0.06210327 -0.06109619  0.09179688
   0.034729    0.00032783  0.08184814 -0.00460052 -0.06396484 -0.07873535
  -0.07684326  0.03585815  0.03106689 -0.02568054 -0.09423828  0.09216309
   0.05581665 -0.07940674 -0.00190926  0.01980591 -0.01357269 -0.07611084
  -0.03887939 -0.06494141 -0.03253174  0.00991821  0.06130981  0.06057739
  -0.02391052 -0.05252075  0.05300903 -0.06097412  0.06945801  0.03237915
   0.07281494 -0.03497314  0.01681519 -0.01838684  0.03123474  0.05499268
   0.03588867 -0.06677246  0.01105499  0.08728027  0.07897949 -0.04669189
   0.01126862  0.08270264  0.07562256 -0.08111572 -0.07165527  0.0562439
   0.09436035  0.03012085  0.07299805  0.05389404 -0.06439209  0.03515625
   0.09405518  0.03613281 -0.04663086 -0.00576401 -0.03102112  0.0838623
  -0.04074097 -0.05682373 -0.0304718  -0.04257202  0.06616211  0.08886719
  -0.08056641 -0.00977325  0.0760498  -0.06884766 -0.05273438  0.04104614
   0.0186615   0.05349731 -0.05892944  0.05801392  0.07830811  0.00614548
  -0.06091309  0.04446411  0.00978851  0.00144386 -0.07788086  0.08276367
   0.07202148  0.08605957 -0.04882812  0.00289917  0.03555298  0.07757568
  -0.07965088  0.03540039 -0.0254364  -0.05508423  0.05841064 -0.03363037
   0.07727051  0.02099609  0.07696533 -0.0352478  -0.06634521 -0.01145172
  -0.05770874  0.02613831  0.06896973  0.02345276 -0.03134155 -0.03076172
  -0.0869751  -0.05670166 -0.04318237  0.01870728  0.06878662  0.08166504
   0.05862427  0.06976318  0.01977539 -0.0680542   0.07312012  0.04721069
   0.04644775  0.06045532 -0.07788086 -0.02279663  0.00743866  0.01916504
   0.05877686 -0.05581665  0.02497864  0.08215332 -0.04962158 -0.04550171
  -0.07220459  0.02761841 -0.00298882 -0.01675415  0.06939697 -0.08612061
   0.09387207  0.06481934  0.00206184  0.08013916 -0.00548172  0.01785278
   0.04898071 -0.06671143 -0.00177479 -0.04730225  0.02372742  0.05212402
  -0.06420898 -0.0300293  -0.04797363 -0.05340576 -0.06292725 -0.07714844
   0.0657959  -0.03717041 -0.0149765   0.06335449 -0.04147339 -0.05319214
   0.00527573  0.01927185  0.01180267  0.0838623   0.00623322 -0.00313187
   0.09326172  0.03146362  0.00914001  0.09161377  0.06488037 -0.06155396
   0.02760315 -0.06207275 -0.06124878 -0.01649475  0.06549072 -0.01605225
  -0.0793457  -0.02545166 -0.08441162 -0.04592896 -0.06707764  0.06787109
  -0.00608063  0.02279663 -0.0328064   0.04278564 -0.05740356 -0.04873657
   0.06732178 -0.05264282 -0.06866455  0.07745361 -0.03759766 -0.0319519
  -0.05053711  0.06628418  0.02203369 -0.06420898]]
After layer split4_output8 (1, 256) <class 'numpy.float16'> [[ 0.06011963  0.00928497  0.03005981 -0.03009033 -0.03494263  0.00979614
   0.04443359  0.0892334  -0.0647583   0.06057739 -0.03366089 -0.0413208
   0.05426025  0.00199127 -0.04977417 -0.01615906  0.02236938  0.04937744
  -0.07427979  0.01543427  0.03674316 -0.07714844  0.00384521  0.04898071
   0.04669189  0.0435791   0.05166626 -0.03117371  0.00643921 -0.0916748
  -0.06555176  0.04605103  0.03308105 -0.02362061 -0.05386353  0.05136108
  -0.05328369  0.00138664  0.0087204   0.0222168  -0.08197021  0.01593018
  -0.09448242 -0.01968384 -0.05157471 -0.02156067  0.09191895 -0.0456543
  -0.01366425  0.02568054  0.05508423 -0.06210327 -0.06109619  0.09179688
   0.034729    0.00032783  0.08184814 -0.00460052 -0.06396484 -0.07873535
  -0.07684326  0.03585815  0.03106689 -0.02568054 -0.09423828  0.09216309
   0.05581665 -0.07940674 -0.00190926  0.01980591 -0.01357269 -0.07611084
  -0.03887939 -0.06494141 -0.03253174  0.00991821  0.06130981  0.06057739
  -0.02391052 -0.05252075  0.05300903 -0.06097412  0.06945801  0.03237915
   0.07281494 -0.03497314  0.01681519 -0.01838684  0.03123474  0.05499268
   0.03588867 -0.06677246  0.01105499  0.08728027  0.07897949 -0.04669189
   0.01126862  0.08270264  0.07562256 -0.08111572 -0.07165527  0.0562439
   0.09436035  0.03012085  0.07299805  0.05389404 -0.06439209  0.03515625
   0.09405518  0.03613281 -0.04663086 -0.00576401 -0.03102112  0.0838623
  -0.04074097 -0.05682373 -0.0304718  -0.04257202  0.06616211  0.08886719
  -0.08056641 -0.00977325  0.0760498  -0.06884766 -0.05273438  0.04104614
   0.0186615   0.05349731 -0.05892944  0.05801392  0.07830811  0.00614548
  -0.06091309  0.04446411  0.00978851  0.00144386 -0.07788086  0.08276367
   0.07202148  0.08605957 -0.04882812  0.00289917  0.03555298  0.07757568
  -0.07965088  0.03540039 -0.0254364  -0.05508423  0.05841064 -0.03363037
   0.07727051  0.02099609  0.07696533 -0.0352478  -0.06634521 -0.01145172
  -0.05770874  0.02613831  0.06896973  0.02345276 -0.03134155 -0.03076172
  -0.0869751  -0.05670166 -0.04318237  0.01870728  0.06878662  0.08166504
   0.05862427  0.06976318  0.01977539 -0.0680542   0.07312012  0.04721069
   0.04644775  0.06045532 -0.07788086 -0.02279663  0.00743866  0.01916504
   0.05877686 -0.05581665  0.02497864  0.08215332 -0.04962158 -0.04550171
  -0.07220459  0.02761841 -0.00298882 -0.01675415  0.06939697 -0.08612061
   0.09387207  0.06481934  0.00206184  0.08013916 -0.00548172  0.01785278
   0.04898071 -0.06671143 -0.00177479 -0.04730225  0.02372742  0.05212402
  -0.06420898 -0.0300293  -0.04797363 -0.05340576 -0.06292725 -0.07714844
   0.0657959  -0.03717041 -0.0149765   0.06335449 -0.04147339 -0.05319214
   0.00527573  0.01927185  0.01180267  0.0838623   0.00623322 -0.00313187
   0.09326172  0.03146362  0.00914001  0.09161377  0.06488037 -0.06155396
   0.02760315 -0.06207275 -0.06124878 -0.01649475  0.06549072 -0.01605225
  -0.0793457  -0.02545166 -0.08441162 -0.04592896 -0.06707764  0.06787109
  -0.00608063  0.02279663 -0.0328064   0.04278564 -0.05740356 -0.04873657
   0.06732178 -0.05264282 -0.06866455  0.07745361 -0.03759766 -0.0319519
  -0.05053711  0.06628418  0.02203369 -0.06420898]]
After layer split4_output9 (1, 256) <class 'numpy.float16'> [[ 0.06011963  0.00928497  0.03005981 -0.03009033 -0.03494263  0.00979614
   0.04443359  0.0892334  -0.0647583   0.06057739 -0.03366089 -0.0413208
   0.05426025  0.00199127 -0.04977417 -0.01615906  0.02236938  0.04937744
  -0.07427979  0.01543427  0.03674316 -0.07714844  0.00384521  0.04898071
   0.04669189  0.0435791   0.05166626 -0.03117371  0.00643921 -0.0916748
  -0.06555176  0.04605103  0.03308105 -0.02362061 -0.05386353  0.05136108
  -0.05328369  0.00138664  0.0087204   0.0222168  -0.08197021  0.01593018
  -0.09448242 -0.01968384 -0.05157471 -0.02156067  0.09191895 -0.0456543
  -0.01366425  0.02568054  0.05508423 -0.06210327 -0.06109619  0.09179688
   0.034729    0.00032783  0.08184814 -0.00460052 -0.06396484 -0.07873535
  -0.07684326  0.03585815  0.03106689 -0.02568054 -0.09423828  0.09216309
   0.05581665 -0.07940674 -0.00190926  0.01980591 -0.01357269 -0.07611084
  -0.03887939 -0.06494141 -0.03253174  0.00991821  0.06130981  0.06057739
  -0.02391052 -0.05252075  0.05300903 -0.06097412  0.06945801  0.03237915
   0.07281494 -0.03497314  0.01681519 -0.01838684  0.03123474  0.05499268
   0.03588867 -0.06677246  0.01105499  0.08728027  0.07897949 -0.04669189
   0.01126862  0.08270264  0.07562256 -0.08111572 -0.07165527  0.0562439
   0.09436035  0.03012085  0.07299805  0.05389404 -0.06439209  0.03515625
   0.09405518  0.03613281 -0.04663086 -0.00576401 -0.03102112  0.0838623
  -0.04074097 -0.05682373 -0.0304718  -0.04257202  0.06616211  0.08886719
  -0.08056641 -0.00977325  0.0760498  -0.06884766 -0.05273438  0.04104614
   0.0186615   0.05349731 -0.05892944  0.05801392  0.07830811  0.00614548
  -0.06091309  0.04446411  0.00978851  0.00144386 -0.07788086  0.08276367
   0.07202148  0.08605957 -0.04882812  0.00289917  0.03555298  0.07757568
  -0.07965088  0.03540039 -0.0254364  -0.05508423  0.05841064 -0.03363037
   0.07727051  0.02099609  0.07696533 -0.0352478  -0.06634521 -0.01145172
  -0.05770874  0.02613831  0.06896973  0.02345276 -0.03134155 -0.03076172
  -0.0869751  -0.05670166 -0.04318237  0.01870728  0.06878662  0.08166504
   0.05862427  0.06976318  0.01977539 -0.0680542   0.07312012  0.04721069
   0.04644775  0.06045532 -0.07788086 -0.02279663  0.00743866  0.01916504
   0.05877686 -0.05581665  0.02497864  0.08215332 -0.04962158 -0.04550171
  -0.07220459  0.02761841 -0.00298882 -0.01675415  0.06939697 -0.08612061
   0.09387207  0.06481934  0.00206184  0.08013916 -0.00548172  0.01785278
   0.04898071 -0.06671143 -0.00177479 -0.04730225  0.02372742  0.05212402
  -0.06420898 -0.0300293  -0.04797363 -0.05340576 -0.06292725 -0.07714844
   0.0657959  -0.03717041 -0.0149765   0.06335449 -0.04147339 -0.05319214
   0.00527573  0.01927185  0.01180267  0.0838623   0.00623322 -0.00313187
   0.09326172  0.03146362  0.00914001  0.09161377  0.06488037 -0.06155396
   0.02760315 -0.06207275 -0.06124878 -0.01649475  0.06549072 -0.01605225
  -0.0793457  -0.02545166 -0.08441162 -0.04592896 -0.06707764  0.06787109
  -0.00608063  0.02279663 -0.0328064   0.04278564 -0.05740356 -0.04873657
   0.06732178 -0.05264282 -0.06866455  0.07745361 -0.03759766 -0.0319519
  -0.05053711  0.06628418  0.02203369 -0.06420898]]
After layer encoder_birnn_forward_l0_t0_i2h_output (1, 1024) <class 'numpy.float16'> [[-0.07537842 -0.03747559 -0.0519104  ...,  0.05627441 -0.06604004
  -0.01455688]]
After layer encoder_birnn_forward_l0_begin_state_0_0 (1, 256) <class 'numpy.float16'> [[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
   0.  0.  0.  0.]]
After layer encoder_birnn_forward_l0_t0_h2h_output (1, 1024) <class 'numpy.float16'> [[ 0.01966858  0.00881195  0.05056763 ...,  0.0147934   0.02441406
   0.02816772]]
After layer _plus1026_0 (1, 1024) <class 'numpy.float16'> [[-0.0557251  -0.02865601 -0.00134277 ...,  0.07104492 -0.04162598
   0.01361084]]
After layer encoder_birnn_forward_l0_t0_slice_output0 (1, 256) <class 'numpy.float16'> [[-0.0557251  -0.02865601 -0.00134277 -0.01141357  0.11767578  0.08398438
   0.04196167  0.05859375 -0.04455566  0.00779724  0.08001709  0.03112793
   0.02078247 -0.04669189  0.13964844  0.12731934  0.00674438  0.02030945
   0.03594971  0.0559082   0.00546265  0.11218262  0.03222656 -0.02642822
   0.05218506  0.11914062  0.05535889  0.00811005  0.04232788  0.10021973
  -0.00125122 -0.01303101  0.07366943  0.15551758  0.16430664  0.03787231
   0.02352905  0.09436035  0.09613037  0.02987671 -0.0402832   0.04888916
   0.08343506  0.01071167  0.13989258  0.00970459 -0.01031494  0.03430176
   0.03479004 -0.08050537  0.05014038 -0.02682495  0.15783691  0.03771973
   0.02261353  0.03955078  0.02093506 -0.03356934  0.03625488  0.00696564
   0.13684082  0.02038574  0.05145264  0.05484009  0.09783936  0.03289795
   0.034729    0.07507324  0.10217285  0.10064697 -0.0107193   0.12109375
   0.0970459   0.04595947  0.1307373   0.0458374   0.06933594  0.07781982
   0.12695312  0.12231445  0.01599121  0.04748535  0.23876953  0.03594971
   0.04660034 -0.00308228  0.03198242 -0.00964355  0.24072266  0.12744141
   0.04721069 -0.01602173  0.00222778  0.02880859  0.00378418  0.05688477
   0.07324219  0.07641602  0.05065918  0.05755615  0.09228516 -0.01474762
   0.06884766 -0.00918579  0.01702881  0.07666016  0.00619507  0.06274414
   0.10943604  0.05227661  0.04208374 -0.01031494  0.18261719  0.18615723
  -0.01976013  0.04428101  0.06622314  0.04428101 -0.01853943  0.13366699
   0.04162598  0.11303711  0.05581665  0.07910156  0.12561035  0.06048584
   0.12988281  0.07006836  0.04022217  0.12670898  0.06762695  0.04129028
   0.02813721  0.03570557  0.06323242  0.11523438  0.07531738  0.07159424
   0.18530273  0.08123779  0.09527588  0.05175781  0.08215332  0.08331299
  -0.01235962  0.02456665  0.08508301  0.05142212  0.21118164  0.03076172
   0.05892944  0.00662231  0.13183594 -0.01190186  0.01095581 -0.00079346
   0.06958008 -0.01678467  0.05541992 -0.06317139  0.08544922  0.05627441
   0.04095459 -0.04290771  0.05184937  0.01765442  0.01649475  0.06976318
   0.09960938  0.05181885  0.08605957  0.16943359 -0.02836609 -0.00756836
   0.02728271  0.08184814  0.07348633 -0.03588867  0.07434082 -0.04833984
   0.07177734  0.08612061  0.03308105  0.08465576  0.06793213  0.01538086
   0.04510498  0.12597656  0.00389099  0.0206604  -0.00938416 -0.02212524
   0.00372314  0.05212402 -0.0241394   0.09283447  0.14196777  0.04907227
   0.10418701  0.02261353  0.07556152  0.07263184  0.11865234  0.07202148
  -0.04553223  0.11224365  0.02250671  0.01913452  0.13293457 -0.04263306
   0.00366211  0.14038086  0.01664734  0.12646484  0.01715088 -0.00546265
  -0.03744507  0.09436035  0.04394531 -0.0058136   0.00296021  0.03056335
   0.18579102  0.01235962  0.02748108  0.14318848  0.04376221 -0.00500488
   0.01652527 -0.00650024  0.05056763  0.07458496  0.01442719  0.03302002
  -0.027771   -0.10900879  0.01568604  0.03295898 -0.00508118  0.12298584
   0.05322266  0.0803833   0.17480469  0.07409668  0.03143311  0.1550293
   0.03939819 -0.06286621  0.01483154  0.00749207  0.05917358 -0.03771973
  -0.07073975 -0.00213623  0.06274414  0.11572266]]
After layer encoder_birnn_forward_l0_t0_slice_output1 (1, 256) <class 'numpy.float16'> [[  5.61218262e-02   6.37817383e-03   3.42102051e-02   4.01000977e-02
   -4.04663086e-02   2.70690918e-02   7.83081055e-02   1.11938477e-01
    4.46777344e-02   8.68530273e-02  -6.59179688e-03  -2.56805420e-02
    6.01806641e-02  -7.79418945e-02   7.59887695e-02   4.59899902e-02
   -8.08105469e-02   9.04541016e-02   6.31713867e-02   7.73925781e-02
    2.22473145e-02   1.20178223e-01   5.09643555e-02   2.42919922e-02
    1.09436035e-01   2.33764648e-02   8.94775391e-02  -1.20773315e-02
    6.28662109e-02   6.86035156e-02  -5.05981445e-02   3.79333496e-02
    5.49926758e-02   7.68432617e-02   7.59887695e-02   4.43420410e-02
    1.52130127e-02   3.75976562e-02   5.20629883e-02   3.34777832e-02
    2.61077881e-02   9.70458984e-03   8.23364258e-02   1.22222900e-02
    8.36181641e-02   2.02178955e-03   8.74023438e-02   5.37109375e-02
    2.27966309e-02   5.29479980e-02   1.77917480e-02   1.47399902e-02
    9.72900391e-02  -7.59887695e-03   2.87170410e-02   5.55419922e-02
    1.09069824e-01  -9.24682617e-03   1.06628418e-01   1.31103516e-01
    1.82495117e-02  -1.92565918e-02  -1.23977661e-02   1.80541992e-01
    9.05151367e-02  -1.73950195e-02   1.34582520e-02   7.99560547e-02
    2.22778320e-02   1.26464844e-01   4.32739258e-02   4.02832031e-03
   -1.04980469e-02   3.07159424e-02   7.04956055e-02   1.16699219e-01
    1.16210938e-01   9.97314453e-02   1.35375977e-01   5.42907715e-02
    5.02319336e-02   2.60009766e-02   2.27539062e-01  -9.10186768e-03
    1.10107422e-01  -3.77807617e-02   2.67639160e-02   5.47485352e-02
    2.31079102e-01  -1.32369995e-02   9.23919678e-03   8.48999023e-02
    9.79614258e-02   1.13372803e-02   4.11987305e-03   3.55834961e-02
    6.64062500e-02  -4.57763672e-03   6.34155273e-02   5.88684082e-02
    5.52978516e-02  -5.72509766e-02   4.09851074e-02   1.02691650e-02
    3.97033691e-02   4.50744629e-02   3.58581543e-03  -4.02832031e-02
   -1.48162842e-02  -2.48870850e-02   9.06372070e-03   4.58984375e-02
    9.92431641e-02   1.01440430e-01  -2.76336670e-02   1.32446289e-02
   -6.16455078e-03   1.24511719e-01   5.84716797e-02   2.98767090e-02
    8.96453857e-03   3.28369141e-02   1.03088379e-01  -1.37405396e-02
    1.87683105e-02  -9.64355469e-03   4.23583984e-02  -1.29394531e-02
    1.09786987e-02   1.17553711e-01   5.50537109e-02  -3.14331055e-03
    7.72094727e-03   5.83648682e-03  -5.31005859e-03   9.09423828e-02
    2.78320312e-02   5.03540039e-02   3.66210938e-02  -5.79833984e-04
    2.77404785e-02   4.91943359e-02   1.31591797e-01  -9.97924805e-03
   -2.55126953e-02   5.57556152e-02  -4.08935547e-02   5.27954102e-02
    2.25830078e-03   4.51660156e-02   4.95605469e-02   6.21948242e-02
    1.02294922e-01   9.16748047e-02  -3.93676758e-02  -4.00390625e-02
   -2.46734619e-02   3.87573242e-02  -1.11999512e-02   8.02612305e-02
    1.37207031e-01   6.68945312e-02  -7.18994141e-02   3.42407227e-02
    3.10058594e-02  -7.28149414e-02   2.37884521e-02   5.67932129e-02
    2.31323242e-02   4.85839844e-02  -2.51159668e-02   1.26708984e-01
   -4.47998047e-02   5.50537109e-02   1.94702148e-02   5.29785156e-02
    3.18603516e-02   1.23413086e-01  -4.91943359e-02   1.54571533e-02
    5.21850586e-02   3.08227539e-03   4.05273438e-02   4.32128906e-02
   -1.70898438e-02  -1.81427002e-02   5.12695312e-02   8.52661133e-02
    2.16674805e-02  -1.35498047e-02   1.80206299e-02   6.47583008e-02
   -4.45556641e-03   4.00085449e-02   3.19519043e-02   8.99047852e-02
    2.15576172e-01   1.07269287e-02  -4.90112305e-02   5.19714355e-02
    9.71679688e-02   1.55395508e-01   1.05224609e-01   1.00097656e-02
    4.27246094e-02  -8.88061523e-03   1.46972656e-01   4.90417480e-02
   -2.28881836e-04   3.03039551e-02   2.21862793e-02   3.33862305e-02
   -1.68304443e-02   1.20178223e-01   1.52587891e-01  -6.45751953e-02
   -1.31530762e-02  -1.66625977e-02   7.11822510e-03  -2.57873535e-02
    3.60107422e-03   6.22558594e-02   5.81054688e-02   1.23718262e-01
    8.06274414e-02   9.21020508e-02   7.22656250e-02   3.59497070e-02
    7.93457031e-04  -2.44445801e-02   9.98535156e-02   5.92651367e-02
    2.56958008e-02   4.35485840e-02   7.04345703e-02   7.65380859e-02
    1.60369873e-02   3.44543457e-02   5.95703125e-02   7.33642578e-02
    5.49926758e-02   5.35278320e-02   1.74560547e-01   8.95385742e-02
    2.34375000e-02   2.18658447e-02   3.62548828e-02  -1.16943359e-01
    7.73315430e-02   9.21020508e-02   4.31518555e-02  -5.47485352e-02
    1.51062012e-02  -1.30233765e-02   3.48815918e-02   7.47680664e-02]]
After layer encoder_birnn_forward_l0_t0_slice_output2 (1, 256) <class 'numpy.float16'> [[ 0.01441956  0.08984375 -0.0246582  -0.03509521  0.11303711 -0.02542114
   0.04425049 -0.14575195  0.05862427  0.01551819  0.06542969  0.02282715
   0.0880127  -0.04345703  0.1036377  -0.03082275 -0.01741028  0.01676941
  -0.03424072 -0.01887512  0.0292511  -0.11077881 -0.13330078  0.11468506
   0.00827026 -0.06243896 -0.04937744 -0.05297852 -0.04922485  0.03729248
   0.05160522 -0.05963135  0.03707886 -0.02697754  0.0758667   0.03283691
   0.03683472 -0.02923584 -0.05001831 -0.03071594 -0.05462646  0.10083008
  -0.0206604   0.07165527 -0.08447266 -0.08239746  0.0133667   0.08483887
   0.05987549 -0.01904297 -0.00866699 -0.07189941  0.08215332 -0.09997559
   0.03094482  0.12792969  0.0355835  -0.06536865  0.08422852 -0.05206299
   0.07275391 -0.06719971  0.01242065  0.01934814 -0.01138306 -0.02233887
   0.02035522  0.07080078 -0.00396729 -0.0703125  -0.00140381 -0.09484863
  -0.13110352  0.07611084  0.14892578 -0.00505066  0.13952637 -0.14160156
   0.12390137 -0.04818726  0.09008789 -0.04650879  0.15478516  0.02531433
   0.01921082 -0.03921509  0.05932617 -0.12322998 -0.06396484  0.07958984
  -0.03004456  0.06768799 -0.09094238 -0.05230713 -0.0848999   0.04602051
   0.01954651 -0.14978027  0.07440186  0.10162354 -0.11816406 -0.01776123
   0.00152588  0.01721191  0.04748535 -0.08166504  0.01747131  0.11669922
   0.08666992  0.05664062  0.02545166 -0.0859375   0.15002441  0.17114258
  -0.06567383 -0.00921631  0.06057739  0.15649414  0.02041626  0.03936768
   0.01340485 -0.10717773  0.12316895 -0.12402344  0.09484863 -0.02589417
   0.04699707  0.09405518  0.00592041 -0.15930176  0.00097656  0.02815247
   0.06860352 -0.04412842  0.07067871  0.09265137  0.05749512  0.12780762
  -0.1003418   0.00830078 -0.06231689  0.14147949 -0.10668945 -0.0793457
   0.11218262  0.09521484  0.05529785 -0.0647583   0.14038086 -0.06915283
  -0.01551819  0.01286316  0.08935547  0.10235596  0.06842041 -0.09460449
   0.08056641  0.0446167   0.05957031  0.0199585   0.01611328  0.05279541
  -0.00961304  0.02337646 -0.06286621  0.06140137 -0.14782715 -0.01477051
  -0.112854   -0.05438232  0.00636292 -0.01025391 -0.01446533 -0.01148987
   0.01986694 -0.03894043  0.16381836  0.00350952 -0.05096436  0.00872803
   0.05755615  0.07592773  0.06536865  0.00308228  0.02243042 -0.08093262
   0.0078125   0.02723694  0.04348755  0.02082825  0.0297699  -0.03536987
  -0.14855957  0.1854248   0.0032959  -0.1661377  -0.08740234 -0.08984375
   0.06726074  0.10510254  0.10766602 -0.11114502 -0.00274658 -0.01330566
  -0.08465576 -0.00842285  0.02972412  0.07434082  0.05218506 -0.00244141
   0.01420593  0.07958984  0.09350586 -0.03053284  0.00085449 -0.00289917
  -0.0657959  -0.09082031 -0.07342529  0.01017761 -0.050354    0.03936768
   0.0329895  -0.16467285  0.0869751  -0.03753662 -0.12597656 -0.02464294
   0.01454163 -0.06445312 -0.04675293 -0.04870605  0.06713867  0.04980469
  -0.06555176 -0.02020264  0.050354    0.10040283 -0.03604126 -0.00256348
   0.04150391  0.08972168 -0.00610352 -0.09362793  0.05657959 -0.08911133
   0.05279541 -0.05395508 -0.08526611  0.02639771 -0.07751465  0.01174927
   0.02204895 -0.11621094  0.06994629  0.00106812]]
After layer encoder_birnn_forward_l0_t0_slice_output3 (1, 256) <class 'numpy.float16'> [[-0.03271484  0.06787109  0.13342285  0.02438354  0.01905823  0.02928162
   0.07067871 -0.03637695  0.10882568  0.02334595  0.13110352  0.06091309
   0.01716614  0.16015625  0.12524414  0.09558105  0.0211792   0.05609131
   0.16320801  0.05072021  0.06976318  0.06970215  0.0149231   0.0284729
   0.04943848  0.03967285  0.05126953  0.0803833   0.00241089  0.02745056
   0.07025146  0.03305054  0.03366089  0.06756592  0.04998779  0.11547852
   0.01583862  0.08563232  0.03344727  0.02438354  0.10900879  0.14758301
   0.0428772   0.01568604  0.13818359  0.06622314  0.03387451  0.00408936
   0.06616211  0.014534    0.05178833  0.05136108  0.08459473  0.04284668
   0.02246094  0.04110718  0.03643799  0.1348877   0.01040649 -0.00161743
  -0.0017395  -0.02003479  0.01525116  0.04489136 -0.06213379 -0.05163574
   0.01174927  0.09942627  0.02848816  0.03338623  0.02224731 -0.01208496
   0.07348633  0.10693359  0.11383057  0.12316895  0.01568604  0.09960938
   0.16577148  0.13977051  0.10827637  0.04284668  0.21716309  0.04840088
   0.09735107  0.08856201 -0.00582886  0.06207275  0.18017578  0.09851074
   0.00366211  0.10882568 -0.0015564   0.08203125  0.05560303  0.10998535
   0.05151367  0.05389404  0.00579834  0.11621094  0.04803467 -0.00257874
   0.05487061  0.12792969  0.06118774  0.02738953  0.05917358  0.02764893
   0.11895752  0.0218811   0.07019043  0.10144043  0.22607422  0.13757324
  -0.03460693 -0.02702332  0.09918213  0.0579834  -0.01396179  0.03845215
  -0.00939178  0.10229492  0.08789062  0.08007812  0.05059814  0.10339355
   0.10479736  0.1227417  -0.01062012  0.19091797  0.03399658 -0.02172852
   0.05575562  0.01683044  0.00961304  0.07171631  0.11474609 -0.04211426
   0.1171875   0.02578735  0.03735352  0.03356934  0.08062744 -0.01782227
  -0.0027771   0.05374146  0.01741028  0.10443115  0.05541992  0.05633545
   0.0982666   0.04852295  0.01055908  0.06860352 -0.02249146  0.04440308
   0.00604248  0.00531006 -0.02178955 -0.06222534  0.11950684 -0.01489258
  -0.00390625  0.16931152  0.04400635  0.05407715  0.08227539  0.07910156
   0.13830566  0.08087158  0.00335693  0.11645508 -0.06762695  0.10876465
   0.09204102 -0.00540161  0.05133057  0.06481934  0.02513123  0.07775879
   0.11022949  0.1048584   0.05386353  0.10266113 -0.01757812 -0.02392578
   0.01231384  0.05419922 -0.00314331 -0.01347351  0.12780762  0.01409912
   0.11627197  0.10693359 -0.01634216  0.12463379  0.12402344 -0.00405884
   0.1204834   0.11413574  0.07275391  0.03445435  0.06085205  0.06240845
  -0.04937744  0.08258057  0.0425415   0.11242676  0.1706543   0.05383301
   0.01403809  0.02171326  0.04940796  0.09503174  0.16113281 -0.00793457
   0.01325226  0.12609863 -0.08776855  0.06402588  0.01158142  0.02941895
   0.00163269  0.05096436  0.08117676  0.07415771  0.02609253 -0.00747681
  -0.02452087  0.03494263  0.03863525  0.0491333   0.09832764  0.00823975
  -0.00204468  0.13989258  0.08294678 -0.08392334  0.0256958   0.13500977
   0.02049255 -0.05334473  0.19458008  0.08978271 -0.01878357  0.01312256
  -0.05175781 -0.06420898  0.01678467  0.02587891  0.01239014  0.08203125
   0.02093506  0.07104492 -0.04162598  0.01361084]]
After layer encoder_birnn_forward_l0_t0_o_output (1, 256) <class 'numpy.float16'> [[ 0.49194336  0.51708984  0.53320312  0.50585938  0.50488281  0.50732422
   0.51757812  0.4909668   0.52734375  0.50585938  0.53271484  0.51513672
   0.50439453  0.54003906  0.53125     0.52392578  0.50537109  0.51416016
   0.54052734  0.51269531  0.51757812  0.51757812  0.50390625  0.50732422
   0.51220703  0.50976562  0.51269531  0.52001953  0.50048828  0.50683594
   0.51757812  0.50830078  0.50830078  0.51708984  0.51269531  0.52880859
   0.50390625  0.52148438  0.50830078  0.50585938  0.52734375  0.53662109
   0.51074219  0.50390625  0.53466797  0.51660156  0.50830078  0.50097656
   0.51660156  0.50341797  0.51318359  0.51269531  0.52099609  0.51074219
   0.50537109  0.51025391  0.50927734  0.53369141  0.50244141  0.49951172
   0.49951172  0.49487305  0.50390625  0.51123047  0.484375    0.48706055
   0.50292969  0.52490234  0.50732422  0.50830078  0.50537109  0.49707031
   0.51855469  0.52685547  0.52832031  0.53076172  0.50390625  0.52490234
   0.54150391  0.53466797  0.52685547  0.51074219  0.55419922  0.51220703
   0.52441406  0.52197266  0.49853516  0.515625    0.54492188  0.52441406
   0.50097656  0.52734375  0.49951172  0.52050781  0.51367188  0.52734375
   0.51269531  0.51367188  0.50146484  0.52880859  0.51220703  0.49926758
   0.51367188  0.53173828  0.51513672  0.50683594  0.51464844  0.50683594
   0.52978516  0.50537109  0.51757812  0.52539062  0.55615234  0.53417969
   0.49145508  0.49316406  0.52490234  0.51464844  0.49658203  0.50976562
   0.49755859  0.52539062  0.52197266  0.52001953  0.51269531  0.52587891
   0.52636719  0.53076172  0.49731445  0.54736328  0.50830078  0.49462891
   0.51416016  0.50439453  0.50244141  0.51806641  0.52880859  0.48950195
   0.52929688  0.50634766  0.50927734  0.50830078  0.52001953  0.49560547
   0.49926758  0.51367188  0.50439453  0.52587891  0.51367188  0.51416016
   0.52441406  0.51220703  0.50244141  0.51708984  0.49438477  0.51123047
   0.50146484  0.50146484  0.49462891  0.484375    0.52978516  0.49633789
   0.49902344  0.54199219  0.51123047  0.51367188  0.52050781  0.51953125
   0.53466797  0.52001953  0.50097656  0.52929688  0.4831543   0.52734375
   0.52294922  0.49853516  0.51269531  0.51611328  0.50634766  0.51953125
   0.52734375  0.52636719  0.51367188  0.52587891  0.49560547  0.49414062
   0.50292969  0.51367188  0.49926758  0.49658203  0.53173828  0.50341797
   0.52880859  0.52685547  0.49584961  0.53125     0.53076172  0.49902344
   0.53027344  0.52832031  0.51806641  0.50878906  0.51513672  0.515625
   0.48754883  0.52050781  0.51074219  0.52832031  0.54248047  0.51367188
   0.50341797  0.50537109  0.51220703  0.52392578  0.54003906  0.49804688
   0.50341797  0.53125     0.47802734  0.51611328  0.50292969  0.50732422
   0.50048828  0.51269531  0.52050781  0.51855469  0.50634766  0.49804688
   0.49389648  0.50878906  0.50976562  0.51220703  0.52441406  0.50195312
   0.49951172  0.53515625  0.52050781  0.47900391  0.50634766  0.53369141
   0.50488281  0.48657227  0.54833984  0.52246094  0.49536133  0.50341797
   0.48706055  0.48388672  0.50439453  0.50634766  0.50292969  0.52050781
   0.50537109  0.51757812  0.48950195  0.50341797]]
After layer encoder_birnn_forward_l0_t0_f_output (1, 256) <class 'numpy.float16'> [[ 0.51416016  0.50146484  0.50878906  0.51025391  0.48999023  0.50683594
   0.51953125  0.52783203  0.51123047  0.52148438  0.49829102  0.49365234
   0.51513672  0.48046875  0.51904297  0.51171875  0.47973633  0.52246094
   0.515625    0.51953125  0.50537109  0.52978516  0.51269531  0.50585938
   0.52734375  0.50585938  0.52246094  0.49707031  0.515625    0.51708984
   0.48730469  0.50927734  0.51367188  0.51904297  0.51904297  0.51123047
   0.50390625  0.50927734  0.51318359  0.50830078  0.50634766  0.50244141
   0.52050781  0.50292969  0.52099609  0.50048828  0.52197266  0.51318359
   0.50585938  0.51318359  0.50439453  0.50390625  0.52441406  0.49804688
   0.50732422  0.51367188  0.52734375  0.49780273  0.52685547  0.53271484
   0.50439453  0.49511719  0.49682617  0.54492188  0.52246094  0.49560547
   0.50341797  0.52001953  0.50537109  0.53173828  0.51074219  0.50097656
   0.49731445  0.5078125   0.51757812  0.52929688  0.52880859  0.52490234
   0.53369141  0.51367188  0.51269531  0.50634766  0.55664062  0.49780273
   0.52734375  0.49047852  0.50683594  0.51367188  0.55761719  0.49658203
   0.50244141  0.52099609  0.52441406  0.50292969  0.50097656  0.50878906
   0.51660156  0.4987793   0.515625    0.51464844  0.51367188  0.4855957
   0.51025391  0.50244141  0.50976562  0.51123047  0.50097656  0.48999023
   0.49633789  0.49389648  0.50244141  0.51123047  0.52490234  0.52539062
   0.49316406  0.50341797  0.49853516  0.53125     0.51464844  0.50732422
   0.50244141  0.50830078  0.52587891  0.49658203  0.50488281  0.49755859
   0.51074219  0.49682617  0.50292969  0.52929688  0.51367188  0.49926758
   0.50195312  0.50146484  0.4987793   0.52294922  0.50683594  0.51269531
   0.50927734  0.49975586  0.50683594  0.51220703  0.53271484  0.49755859
   0.49365234  0.51416016  0.48974609  0.51318359  0.50048828  0.51123047
   0.51220703  0.515625    0.52539062  0.52294922  0.49023438  0.48999023
   0.49389648  0.50976562  0.49731445  0.52001953  0.53417969  0.51660156
   0.48193359  0.50878906  0.5078125   0.48168945  0.50585938  0.51416016
   0.50585938  0.51220703  0.49365234  0.53173828  0.48876953  0.51367188
   0.50488281  0.51318359  0.5078125   0.53076172  0.48779297  0.50390625
   0.51318359  0.50097656  0.51025391  0.51074219  0.49584961  0.49536133
   0.51269531  0.52148438  0.50537109  0.49658203  0.50439453  0.51611328
   0.4987793   0.50976562  0.5078125   0.52246094  0.55371094  0.50244141
   0.48779297  0.51318359  0.52441406  0.53857422  0.52636719  0.50244141
   0.51074219  0.49780273  0.53662109  0.51220703  0.5         0.5078125
   0.50537109  0.50830078  0.49584961  0.52978516  0.53808594  0.48388672
   0.49682617  0.49584961  0.50195312  0.49365234  0.50097656  0.515625
   0.51464844  0.53076172  0.52001953  0.52294922  0.51806641  0.50878906
   0.5         0.49389648  0.52490234  0.51464844  0.50634766  0.51074219
   0.51757812  0.51904297  0.50390625  0.50878906  0.51464844  0.51855469
   0.51367188  0.51318359  0.54345703  0.52246094  0.50585938  0.50537109
   0.50927734  0.47070312  0.51953125  0.52294922  0.51074219  0.48632812
   0.50390625  0.49682617  0.50878906  0.51855469]]
After layer encoder_birnn_forward_l0_begin_state_1_0 (1, 256) <class 'numpy.float16'> [[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
   0.  0.  0.  0.]]
After layer _mul2052_0 (1, 256) <class 'numpy.float16'> [[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
   0.  0.  0.  0.]]
After layer encoder_birnn_forward_l0_t0_i_output (1, 256) <class 'numpy.float16'> [[ 0.48608398  0.49291992  0.49975586  0.49707031  0.52929688  0.52099609
   0.51025391  0.51464844  0.48876953  0.50195312  0.52001953  0.5078125
   0.50537109  0.48828125  0.53466797  0.53173828  0.50146484  0.50488281
   0.50878906  0.51416016  0.50146484  0.52783203  0.5078125   0.4934082
   0.51318359  0.52978516  0.51367188  0.50195312  0.51074219  0.52490234
   0.49975586  0.49682617  0.51855469  0.53857422  0.54101562  0.50927734
   0.50585938  0.5234375   0.52392578  0.50732422  0.48999023  0.51220703
   0.52099609  0.50244141  0.53515625  0.50244141  0.49731445  0.50878906
   0.50878906  0.47998047  0.51269531  0.4934082   0.53955078  0.50927734
   0.50585938  0.50976562  0.50537109  0.49169922  0.50927734  0.50195312
   0.53417969  0.50488281  0.51269531  0.51367188  0.52441406  0.50830078
   0.50878906  0.51855469  0.52539062  0.52490234  0.49731445  0.53027344
   0.52441406  0.51171875  0.53271484  0.51123047  0.51708984  0.51953125
   0.53173828  0.53076172  0.50390625  0.51171875  0.55957031  0.50878906
   0.51171875  0.49926758  0.5078125   0.49755859  0.56005859  0.53173828
   0.51171875  0.49609375  0.50048828  0.50732422  0.50097656  0.51416016
   0.51806641  0.51904297  0.51269531  0.51416016  0.52294922  0.49633789
   0.51708984  0.49780273  0.50439453  0.51904297  0.50146484  0.515625
   0.52734375  0.51318359  0.51074219  0.49731445  0.54541016  0.54638672
   0.49511719  0.51123047  0.51660156  0.51123047  0.49536133  0.53320312
   0.51025391  0.52832031  0.51416016  0.51953125  0.53125     0.51513672
   0.53222656  0.51757812  0.51025391  0.53173828  0.51708984  0.51025391
   0.50683594  0.50878906  0.515625    0.52880859  0.51904297  0.51806641
   0.54638672  0.52050781  0.52392578  0.51269531  0.52050781  0.52099609
   0.49682617  0.50634766  0.52148438  0.51269531  0.55273438  0.5078125
   0.51464844  0.50146484  0.53271484  0.49707031  0.50292969  0.49975586
   0.51757812  0.49584961  0.51367188  0.48413086  0.52148438  0.51416016
   0.51025391  0.48925781  0.51318359  0.50439453  0.50390625  0.51757812
   0.52490234  0.51318359  0.52148438  0.54248047  0.49291992  0.49804688
   0.50683594  0.52050781  0.51855469  0.4909668   0.51855469  0.48803711
   0.51806641  0.52148438  0.50830078  0.52099609  0.51708984  0.50390625
   0.51123047  0.53125     0.50097656  0.50537109  0.49755859  0.49438477
   0.50097656  0.51318359  0.49389648  0.52294922  0.53564453  0.51220703
   0.52587891  0.50585938  0.51904297  0.51806641  0.52978516  0.51806641
   0.48852539  0.52783203  0.50585938  0.50488281  0.53320312  0.48925781
   0.50097656  0.53515625  0.50439453  0.53173828  0.50439453  0.49853516
   0.49072266  0.5234375   0.51074219  0.49853516  0.50097656  0.5078125
   0.54638672  0.50292969  0.50683594  0.53564453  0.51074219  0.4987793
   0.50390625  0.49829102  0.51269531  0.51855469  0.50341797  0.50830078
   0.49316406  0.47265625  0.50390625  0.50830078  0.4987793   0.53076172
   0.51318359  0.52001953  0.54345703  0.51855469  0.5078125   0.53857422
   0.50976562  0.484375    0.50390625  0.50195312  0.51464844  0.49047852
   0.48242188  0.49951172  0.515625    0.52880859]]
After layer encoder_birnn_forward_l0_t0_c_output (1, 256) <class 'numpy.float16'> [[ 0.01441956  0.08959961 -0.0246582  -0.03509521  0.11254883 -0.02542114
   0.04421997 -0.14477539  0.05856323  0.01551819  0.06530762  0.02282715
   0.08776855 -0.04342651  0.10327148 -0.0308075  -0.01741028  0.01676941
  -0.03424072 -0.01887512  0.02923584 -0.11035156 -0.13256836  0.11419678
   0.00827026 -0.06234741 -0.04934692 -0.05291748 -0.04919434  0.03726196
   0.05157471 -0.05957031  0.03704834 -0.02697754  0.07574463  0.03283691
   0.0368042  -0.02922058 -0.04998779 -0.03070068 -0.05456543  0.10046387
  -0.0206604   0.0715332  -0.08428955 -0.08221436  0.0133667   0.08465576
   0.05981445 -0.01904297 -0.00866699 -0.07177734  0.08197021 -0.09967041
   0.03092957  0.12719727  0.0355835  -0.06524658  0.08404541 -0.05200195
   0.07263184 -0.06707764  0.01242065  0.01934814 -0.01138306 -0.02233887
   0.02035522  0.07067871 -0.00396729 -0.07019043 -0.00140381 -0.09454346
  -0.13037109  0.07598877  0.14782715 -0.00505066  0.13867188 -0.140625
   0.12329102 -0.04815674  0.08984375 -0.04647827  0.15356445  0.02531433
   0.01921082 -0.03918457  0.05926514 -0.12261963 -0.06390381  0.07940674
  -0.0300293   0.06756592 -0.09069824 -0.05224609 -0.0847168   0.04598999
   0.01954651 -0.14868164  0.07427979  0.10125732 -0.11761475 -0.01776123
   0.00152588  0.01721191  0.04745483 -0.08148193  0.01747131  0.1161499
   0.08642578  0.05657959  0.02545166 -0.08575439  0.14892578  0.16943359
  -0.06555176 -0.00921631  0.06051636  0.15527344  0.02041626  0.03933716
   0.01340485 -0.10675049  0.12255859 -0.12341309  0.09454346 -0.02589417
   0.04696655  0.09375     0.00592041 -0.15795898  0.00097656  0.02815247
   0.06848145 -0.0440979   0.07055664  0.09240723  0.05743408  0.1270752
  -0.10003662  0.00830078 -0.06222534  0.14050293 -0.10626221 -0.0791626
   0.11169434  0.09490967  0.05523682 -0.06469727  0.13952637 -0.06903076
  -0.01551819  0.01286316  0.08911133  0.10198975  0.06829834 -0.09429932
   0.0803833   0.04458618  0.05950928  0.0199585   0.01611328  0.05273438
  -0.00961304  0.02337646 -0.06280518  0.06130981 -0.14672852 -0.01477051
  -0.11236572 -0.05432129  0.00636292 -0.01025391 -0.01446533 -0.01148987
   0.01986694 -0.03890991  0.16235352  0.00350952 -0.05093384  0.00872803
   0.05749512  0.07580566  0.06524658  0.00308228  0.02243042 -0.08074951
   0.0078125   0.02723694  0.04345703  0.02082825  0.02975464 -0.03536987
  -0.14746094  0.18334961  0.0032959  -0.16467285 -0.0871582  -0.08959961
   0.06713867  0.10473633  0.10723877 -0.11071777 -0.00274658 -0.01330566
  -0.08447266 -0.00842285  0.02970886  0.07421875  0.05212402 -0.00244141
   0.01420593  0.07940674  0.09326172 -0.03051758  0.00085449 -0.00289917
  -0.06567383 -0.09057617 -0.07330322  0.01017761 -0.05032349  0.03933716
   0.0329895  -0.16320801  0.08673096 -0.0375061  -0.12536621 -0.02464294
   0.01454163 -0.06439209 -0.04672241 -0.04867554  0.0670166   0.04977417
  -0.06542969 -0.02020264  0.05032349  0.10003662 -0.03601074 -0.00256348
   0.04147339  0.08947754 -0.00610352 -0.09338379  0.05651855 -0.08886719
   0.05273438 -0.05389404 -0.08508301  0.02639771 -0.07733154  0.01174927
   0.02204895 -0.11566162  0.06982422  0.00106812]]
After layer _mul2053_0 (1, 256) <class 'numpy.float16'> [[ 0.0070076   0.04415894 -0.01232147 -0.0174408   0.05957031 -0.01324463
   0.02256775 -0.07452393  0.02862549  0.00778961  0.03396606  0.01158905
   0.04434204 -0.02120972  0.0552063  -0.01638794 -0.00872803  0.00846863
  -0.01742554 -0.00970459  0.0146637  -0.05825806 -0.06732178  0.05633545
   0.00424576 -0.03302002 -0.02534485 -0.02656555 -0.02513123  0.01956177
   0.02577209 -0.02960205  0.01921082 -0.01452637  0.04098511  0.01672363
   0.01861572 -0.01529694 -0.02618408 -0.01557159 -0.0267334   0.05145264
  -0.01076508  0.03594971 -0.04510498 -0.0413208   0.00664902  0.0430603
   0.03042603 -0.00914001 -0.00444412 -0.03540039  0.04421997 -0.05075073
   0.01564026  0.06481934  0.01799011 -0.03207397  0.04281616 -0.02610779
   0.03878784 -0.03387451  0.00636673  0.0099411  -0.00597    -0.01135254
   0.01035309  0.03665161 -0.00208473 -0.03683472 -0.00069809 -0.05014038
  -0.06835938  0.03887939  0.07873535 -0.00258255  0.07171631 -0.07305908
   0.06555176 -0.02555847  0.04528809 -0.02378845  0.0859375   0.01287842
   0.00983429 -0.01956177  0.03009033 -0.06100464 -0.03579712  0.04223633
  -0.0153656   0.0335083  -0.04537964 -0.02650452 -0.04244995  0.02365112
   0.01012421 -0.07714844  0.03808594  0.05206299 -0.06149292 -0.00881195
   0.00078917  0.00856781  0.02394104 -0.04229736  0.00875854  0.05987549
   0.04556274  0.02903748  0.01300049 -0.04263306  0.08123779  0.09259033
  -0.0324707  -0.00471115  0.03125     0.07940674  0.01011658  0.02098083
   0.00683975 -0.05639648  0.06298828 -0.06408691  0.05023193 -0.01333618
   0.0249939   0.04852295  0.00302124 -0.08398438  0.00050497  0.01436615
   0.03469849 -0.02243042  0.03637695  0.04885864  0.02981567  0.06585693
  -0.05465698  0.00432205 -0.03259277  0.07202148 -0.05529785 -0.04122925
   0.05548096  0.04806519  0.02880859 -0.03317261  0.07714844 -0.0350647
  -0.00798798  0.00645065  0.04748535  0.0506897   0.03436279 -0.04711914
   0.04159546  0.02210999  0.03056335  0.00965881  0.00839996  0.02711487
  -0.0049057   0.01143646 -0.03222656  0.03092957 -0.07391357 -0.00764465
  -0.05899048 -0.02787781  0.00331879 -0.00556183 -0.00712967 -0.00572205
   0.0100708  -0.02024841  0.08416748  0.00172329 -0.02641296  0.00426102
   0.02978516  0.03952026  0.03317261  0.00160599  0.01159668 -0.04067993
   0.00399399  0.01447296  0.02177429  0.01052856  0.01480103 -0.01748657
  -0.07385254  0.09411621  0.00162792 -0.08612061 -0.04669189 -0.04589844
   0.03530884  0.05297852  0.05566406 -0.05737305 -0.00145531 -0.00689316
  -0.04125977 -0.00444412  0.01502991  0.03747559  0.02778625 -0.001194
   0.00711823  0.04248047  0.04702759 -0.01622009  0.00043106 -0.00144577
  -0.03222656 -0.04742432 -0.03744507  0.00507355 -0.02520752  0.01997375
   0.01802063 -0.08209229  0.04394531 -0.02009583 -0.06402588 -0.01229095
   0.00732803 -0.03207397 -0.0239563  -0.02523804  0.03375244  0.02529907
  -0.03225708 -0.009552    0.02536011  0.05084229 -0.01795959 -0.00136089
   0.02128601  0.04653931 -0.00331688 -0.0484314   0.02870178 -0.04785156
   0.02688599 -0.02610779 -0.0428772   0.01325226 -0.03979492  0.00576401
   0.01063538 -0.05776978  0.03601074  0.00056505]]
After layer encoder_birnn_forward_l0_t0_state_0 (1, 256) <class 'numpy.float16'> [[ 0.0070076   0.04415894 -0.01232147 -0.0174408   0.05957031 -0.01324463
   0.02256775 -0.07452393  0.02862549  0.00778961  0.03396606  0.01158905
   0.04434204 -0.02120972  0.0552063  -0.01638794 -0.00872803  0.00846863
  -0.01742554 -0.00970459  0.0146637  -0.05825806 -0.06732178  0.05633545
   0.00424576 -0.03302002 -0.02534485 -0.02656555 -0.02513123  0.01956177
   0.02577209 -0.02960205  0.01921082 -0.01452637  0.04098511  0.01672363
   0.01861572 -0.01529694 -0.02618408 -0.01557159 -0.0267334   0.05145264
  -0.01076508  0.03594971 -0.04510498 -0.0413208   0.00664902  0.0430603
   0.03042603 -0.00914001 -0.00444412 -0.03540039  0.04421997 -0.05075073
   0.01564026  0.06481934  0.01799011 -0.03207397  0.04281616 -0.02610779
   0.03878784 -0.03387451  0.00636673  0.0099411  -0.00597    -0.01135254
   0.01035309  0.03665161 -0.00208473 -0.03683472 -0.00069809 -0.05014038
  -0.06835938  0.03887939  0.07873535 -0.00258255  0.07171631 -0.07305908
   0.06555176 -0.02555847  0.04528809 -0.02378845  0.0859375   0.01287842
   0.00983429 -0.01956177  0.03009033 -0.06100464 -0.03579712  0.04223633
  -0.0153656   0.0335083  -0.04537964 -0.02650452 -0.04244995  0.02365112
   0.01012421 -0.07714844  0.03808594  0.05206299 -0.06149292 -0.00881195
   0.00078917  0.00856781  0.02394104 -0.04229736  0.00875854  0.05987549
   0.04556274  0.02903748  0.01300049 -0.04263306  0.08123779  0.09259033
  -0.0324707  -0.00471115  0.03125     0.07940674  0.01011658  0.02098083
   0.00683975 -0.05639648  0.06298828 -0.06408691  0.05023193 -0.01333618
   0.0249939   0.04852295  0.00302124 -0.08398438  0.00050497  0.01436615
   0.03469849 -0.02243042  0.03637695  0.04885864  0.02981567  0.06585693
  -0.05465698  0.00432205 -0.03259277  0.07202148 -0.05529785 -0.04122925
   0.05548096  0.04806519  0.02880859 -0.03317261  0.07714844 -0.0350647
  -0.00798798  0.00645065  0.04748535  0.0506897   0.03436279 -0.04711914
   0.04159546  0.02210999  0.03056335  0.00965881  0.00839996  0.02711487
  -0.0049057   0.01143646 -0.03222656  0.03092957 -0.07391357 -0.00764465
  -0.05899048 -0.02787781  0.00331879 -0.00556183 -0.00712967 -0.00572205
   0.0100708  -0.02024841  0.08416748  0.00172329 -0.02641296  0.00426102
   0.02978516  0.03952026  0.03317261  0.00160599  0.01159668 -0.04067993
   0.00399399  0.01447296  0.02177429  0.01052856  0.01480103 -0.01748657
  -0.07385254  0.09411621  0.00162792 -0.08612061 -0.04669189 -0.04589844
   0.03530884  0.05297852  0.05566406 -0.05737305 -0.00145531 -0.00689316
  -0.04125977 -0.00444412  0.01502991  0.03747559  0.02778625 -0.001194
   0.00711823  0.04248047  0.04702759 -0.01622009  0.00043106 -0.00144577
  -0.03222656 -0.04742432 -0.03744507  0.00507355 -0.02520752  0.01997375
   0.01802063 -0.08209229  0.04394531 -0.02009583 -0.06402588 -0.01229095
   0.00732803 -0.03207397 -0.0239563  -0.02523804  0.03375244  0.02529907
  -0.03225708 -0.009552    0.02536011  0.05084229 -0.01795959 -0.00136089
   0.02128601  0.04653931 -0.00331688 -0.0484314   0.02870178 -0.04785156
   0.02688599 -0.02610779 -0.0428772   0.01325226 -0.03979492  0.00576401
   0.01063538 -0.05776978  0.03601074  0.00056505]]
After layer activation1026_output (1, 256) <class 'numpy.float16'> [[ 0.0070076   0.04412842 -0.01232147 -0.0174408   0.05950928 -0.01324463
   0.02256775 -0.07440186  0.02861023  0.00778961  0.03396606  0.01158905
   0.04431152 -0.02120972  0.05514526 -0.01638794 -0.00872803  0.00846863
  -0.01742554 -0.00970459  0.0146637  -0.05819702 -0.06719971  0.05627441
   0.00424576 -0.03302002 -0.02534485 -0.02656555 -0.02513123  0.01956177
   0.02577209 -0.02958679  0.01921082 -0.01452637  0.04095459  0.01672363
   0.01861572 -0.01529694 -0.02618408 -0.01557159 -0.0267334   0.05142212
  -0.01076508  0.03591919 -0.04507446 -0.04129028  0.00664902  0.04302979
   0.03041077 -0.00914001 -0.00444412 -0.03540039  0.04418945 -0.05072021
   0.01564026  0.0647583   0.01799011 -0.03207397  0.04278564 -0.02610779
   0.03875732 -0.03387451  0.00636673  0.0099411  -0.00597    -0.01135254
   0.01035309  0.03662109 -0.00208473 -0.0368042  -0.00069809 -0.05010986
  -0.0682373   0.03884888  0.07855225 -0.00258255  0.07159424 -0.07293701
   0.06542969 -0.02555847  0.04525757 -0.02378845  0.08575439  0.01287842
   0.00983429 -0.01956177  0.03007507 -0.0609436  -0.0357666   0.04220581
  -0.0153656   0.0335083  -0.04534912 -0.02650452 -0.04241943  0.02365112
   0.01012421 -0.07696533  0.03805542  0.05200195 -0.06140137 -0.00881195
   0.00078917  0.00856781  0.02394104 -0.04226685  0.00875854  0.05981445
   0.04553223  0.02902222  0.01300049 -0.04260254  0.08105469  0.09234619
  -0.0324707  -0.00471115  0.03123474  0.07922363  0.01011658  0.02098083
   0.00683975 -0.05633545  0.06292725 -0.06402588  0.05020142 -0.01333618
   0.0249939   0.04849243  0.00302124 -0.08380127  0.00050497  0.01436615
   0.03469849 -0.02243042  0.03634644  0.04882812  0.02980042  0.06573486
  -0.05459595  0.00432205 -0.03259277  0.07189941 -0.05523682 -0.04119873
   0.05541992  0.04803467  0.02879333 -0.03317261  0.07696533 -0.0350647
  -0.00798798  0.00645065  0.04745483  0.05065918  0.03436279 -0.04708862
   0.04156494  0.02210999  0.0305481   0.00965881  0.00839996  0.02711487
  -0.0049057   0.01143646 -0.03222656  0.03091431 -0.0737915  -0.00764465
  -0.05892944 -0.02787781  0.00331879 -0.00556183 -0.00712967 -0.00572205
   0.0100708  -0.02024841  0.08398438  0.00172329 -0.02641296  0.00426102
   0.0297699   0.03948975  0.03317261  0.00160599  0.01159668 -0.04064941
   0.00399399  0.01447296  0.02177429  0.01052856  0.01480103 -0.01748657
  -0.07373047  0.09381104  0.00162792 -0.0859375  -0.04666138 -0.04586792
   0.03530884  0.05291748  0.05560303 -0.05731201 -0.00145531 -0.00689316
  -0.04122925 -0.00444412  0.01502991  0.03744507  0.02778625 -0.001194
   0.00711823  0.04244995  0.04699707 -0.01622009  0.00043106 -0.00144577
  -0.03222656 -0.0473938  -0.03741455  0.00507355 -0.02520752  0.01997375
   0.01802063 -0.08190918  0.04391479 -0.02009583 -0.06396484 -0.01229095
   0.00732803 -0.03207397 -0.0239563  -0.02523804  0.03375244  0.02529907
  -0.03225708 -0.009552    0.02536011  0.05081177 -0.01795959 -0.00136089
   0.02128601  0.04650879 -0.00331688 -0.04840088  0.02868652 -0.04782104
   0.02688599 -0.02610779 -0.04284668  0.01325226 -0.0397644   0.00576401
   0.01063538 -0.05770874  0.03598022  0.00056505]]
After layer encoder_birnn_forward_l0_t0_out_0 (1, 256) <class 'numpy.float16'> [[ 0.00344658  0.02281189 -0.00656891 -0.00881958  0.03004456 -0.00671768
   0.0116806  -0.03652954  0.01509094  0.00394058  0.01809692  0.00597
   0.02235413 -0.01145172  0.02929688 -0.00858307 -0.00440979  0.00435257
  -0.0094223  -0.00497437  0.00759125 -0.03012085 -0.03387451  0.02854919
   0.00217438 -0.01683044 -0.01299286 -0.01381683 -0.01258087  0.00991821
   0.01333618 -0.01503754  0.00976562 -0.00751114  0.02099609  0.00884247
   0.00938416 -0.00798035 -0.01330566 -0.00787354 -0.01409912  0.02758789
  -0.00549698  0.01809692 -0.02409363 -0.02133179  0.00337982  0.02156067
   0.01571655 -0.00460052 -0.00228119 -0.0181427   0.02302551 -0.02590942
   0.00790405  0.03305054  0.0091629  -0.01712036  0.02149963 -0.01303864
   0.0193634  -0.01676941  0.00320816  0.00508118 -0.00289154 -0.0055275
   0.00520706  0.01922607 -0.00105762 -0.01870728 -0.00035286 -0.02490234
  -0.03536987  0.02046204  0.04150391 -0.00137043  0.03607178 -0.03829956
   0.03543091 -0.01366425  0.02384949 -0.012146    0.04751587  0.00659561
   0.00515747 -0.01020813  0.01499176 -0.03143311 -0.01948547  0.0221405
  -0.00769806  0.01766968 -0.0226593  -0.01379395 -0.02178955  0.01247406
   0.0051918  -0.03952026  0.01908875  0.02749634 -0.03146362 -0.00439835
   0.00040531  0.00455475  0.0123291  -0.02142334  0.00450897  0.03031921
   0.02412415  0.0146637   0.00672913 -0.02238464  0.04507446  0.04931641
  -0.01596069 -0.00232315  0.01638794  0.04077148  0.00502396  0.01069641
   0.00340271 -0.02960205  0.03283691 -0.03329468  0.02574158 -0.00701141
   0.01315308  0.02574158  0.00150204 -0.04586792  0.00025678  0.00710678
   0.01783752 -0.01131439  0.01826477  0.02529907  0.01576233  0.03216553
  -0.02890015  0.00218773 -0.01660156  0.03656006 -0.02871704 -0.02041626
   0.02766418  0.02467346  0.01452637 -0.0174408   0.03952026 -0.01803589
  -0.00418854  0.00330353  0.02384949  0.02619934  0.01698303 -0.02407837
   0.02084351  0.01108551  0.0151062   0.00467682  0.00445175  0.01345825
  -0.00244713  0.00619888 -0.01647949  0.0158844  -0.03842163 -0.0039711
  -0.03149414 -0.01449585  0.00166225 -0.00294304 -0.00344467 -0.00301743
   0.0052681  -0.01009369  0.0430603   0.0008893  -0.01337433  0.00221443
   0.01570129  0.02078247  0.01704407  0.00084448  0.00574875 -0.02008057
   0.00200844  0.00743484  0.01087189  0.00522995  0.00787354 -0.00880432
  -0.03900146  0.04943848  0.00080729 -0.0456543  -0.02476501 -0.02288818
   0.01872253  0.0279541   0.02880859 -0.02915955 -0.00074959 -0.00355339
  -0.02009583 -0.00231361  0.00767517  0.01977539  0.01507568 -0.00061321
   0.00358391  0.02145386  0.02407837 -0.00849915  0.00023282 -0.00072002
  -0.01622009 -0.025177   -0.0178833   0.00261879 -0.01268005  0.01013184
   0.00901794 -0.04199219  0.02285767 -0.01042175 -0.03237915 -0.00612259
   0.00362015 -0.01631165 -0.01221466 -0.01292419  0.0177002   0.01269531
  -0.01611328 -0.00511169  0.01319885  0.02433777 -0.00909424 -0.00072622
   0.01074982  0.02262878 -0.00181866 -0.02528381  0.01421356 -0.02407837
   0.01309204 -0.01263428 -0.02160645  0.00671005 -0.02000427  0.00300026
   0.00537491 -0.02986145  0.01760864  0.00028443]]
After layer expand_dims1032_0 (1, 1, 256) <class 'numpy.float16'> [[[ 0.00344658  0.02281189 -0.00656891 -0.00881958  0.03004456 -0.00671768
    0.0116806  -0.03652954  0.01509094  0.00394058  0.01809692  0.00597
    0.02235413 -0.01145172  0.02929688 -0.00858307 -0.00440979  0.00435257
   -0.0094223  -0.00497437  0.00759125 -0.03012085 -0.03387451  0.02854919
    0.00217438 -0.01683044 -0.01299286 -0.01381683 -0.01258087  0.00991821
    0.01333618 -0.01503754  0.00976562 -0.00751114  0.02099609  0.00884247
    0.00938416 -0.00798035 -0.01330566 -0.00787354 -0.01409912  0.02758789
   -0.00549698  0.01809692 -0.02409363 -0.02133179  0.00337982  0.02156067
    0.01571655 -0.00460052 -0.00228119 -0.0181427   0.02302551 -0.02590942
    0.00790405  0.03305054  0.0091629  -0.01712036  0.02149963 -0.01303864
    0.0193634  -0.01676941  0.00320816  0.00508118 -0.00289154 -0.0055275
    0.00520706  0.01922607 -0.00105762 -0.01870728 -0.00035286 -0.02490234
   -0.03536987  0.02046204  0.04150391 -0.00137043  0.03607178 -0.03829956
    0.03543091 -0.01366425  0.02384949 -0.012146    0.04751587  0.00659561
    0.00515747 -0.01020813  0.01499176 -0.03143311 -0.01948547  0.0221405
   -0.00769806  0.01766968 -0.0226593  -0.01379395 -0.02178955  0.01247406
    0.0051918  -0.03952026  0.01908875  0.02749634 -0.03146362 -0.00439835
    0.00040531  0.00455475  0.0123291  -0.02142334  0.00450897  0.03031921
    0.02412415  0.0146637   0.00672913 -0.02238464  0.04507446  0.04931641
   -0.01596069 -0.00232315  0.01638794  0.04077148  0.00502396  0.01069641
    0.00340271 -0.02960205  0.03283691 -0.03329468  0.02574158 -0.00701141
    0.01315308  0.02574158  0.00150204 -0.04586792  0.00025678  0.00710678
    0.01783752 -0.01131439  0.01826477  0.02529907  0.01576233  0.03216553
   -0.02890015  0.00218773 -0.01660156  0.03656006 -0.02871704 -0.02041626
    0.02766418  0.02467346  0.01452637 -0.0174408   0.03952026 -0.01803589
   -0.00418854  0.00330353  0.02384949  0.02619934  0.01698303 -0.02407837
    0.02084351  0.01108551  0.0151062   0.00467682  0.00445175  0.01345825
   -0.00244713  0.00619888 -0.01647949  0.0158844  -0.03842163 -0.0039711
   -0.03149414 -0.01449585  0.00166225 -0.00294304 -0.00344467 -0.00301743
    0.0052681  -0.01009369  0.0430603   0.0008893  -0.01337433  0.00221443
    0.01570129  0.02078247  0.01704407  0.00084448  0.00574875 -0.02008057
    0.00200844  0.00743484  0.01087189  0.00522995  0.00787354 -0.00880432
   -0.03900146  0.04943848  0.00080729 -0.0456543  -0.02476501 -0.02288818
    0.01872253  0.0279541   0.02880859 -0.02915955 -0.00074959 -0.00355339
   -0.02009583 -0.00231361  0.00767517  0.01977539  0.01507568 -0.00061321
    0.00358391  0.02145386  0.02407837 -0.00849915  0.00023282 -0.00072002
   -0.01622009 -0.025177   -0.0178833   0.00261879 -0.01268005  0.01013184
    0.00901794 -0.04199219  0.02285767 -0.01042175 -0.03237915 -0.00612259
    0.00362015 -0.01631165 -0.01221466 -0.01292419  0.0177002   0.01269531
   -0.01611328 -0.00511169  0.01319885  0.02433777 -0.00909424 -0.00072622
    0.01074982  0.02262878 -0.00181866 -0.02528381  0.01421356 -0.02407837
    0.01309204 -0.01263428 -0.02160645  0.00671005 -0.02000427  0.00300026
    0.00537491 -0.02986145  0.01760864  0.00028443]]]
After layer encoder_birnn_forward_l0_t1_i2h_output (1, 1024) <class 'numpy.float16'> [[ 0.08166504 -0.05380249  0.08984375 ...,  0.03198242  0.0880127
   0.01552582]]
After layer encoder_birnn_forward_l0_t1_h2h_output (1, 1024) <class 'numpy.float16'> [[ 0.0440979   0.03952026  0.08905029 ...,  0.06185913  0.07281494
   0.07775879]]
After layer _plus1027_0 (1, 1024) <class 'numpy.float16'> [[ 0.12573242 -0.01428223  0.17895508 ...,  0.09387207  0.16088867
   0.09326172]]
After layer encoder_birnn_forward_l0_t1_slice_output0 (1, 256) <class 'numpy.float16'> [[ 0.12573242 -0.01428223  0.17895508  0.13842773  0.09552002  0.06347656
   0.07904053  0.07183838  0.03103638  0.07287598  0.14379883  0.12561035
   0.01246643  0.0947876  -0.01834106  0.06469727 -0.01805115  0.15734863
   0.12475586  0.0847168  -0.00674438  0.05697632  0.21899414  0.01190186
   0.03710938  0.02684021  0.15539551 -0.00126648  0.052948    0.05236816
   0.02941895  0.16137695  0.14123535  0.0118103   0.10247803  0.05999756
   0.03326416  0.24902344  0.16992188  0.00347137  0.08673096  0.0949707
   0.20556641  0.02438354  0.08789062  0.09631348  0.15441895  0.0607605
   0.09277344  0.05383301  0.07269287 -0.0480957   0.29711914  0.04595947
   0.140625    0.06890869  0.04718018  0.06390381  0.07897949 -0.04971313
   0.0401001   0.16015625  0.11999512  0.28759766  0.13842773 -0.0378418
   0.23742676  0.05786133  0.00228882  0.11254883  0.02894592  0.01980591
   0.24487305  0.02120972  0.059021    0.09417725  0.14819336  0.19396973
   0.10955811  0.05386353  0.12408447  0.07421875  0.26806641  0.00578308
   0.14025879  0.13671875  0.11584473  0.19458008  0.30297852 -0.015625
   0.04354858  0.02513123  0.01045227  0.1607666   0.05245972  0.12207031
   0.07550049  0.23852539  0.12164307  0.10223389  0.07348633 -0.04321289
   0.11358643  0.07849121  0.13842773  0.01556396  0.12017822  0.05911255
   0.04827881  0.1036377   0.24035645  0.17919922  0.11413574  0.14318848
   0.0925293   0.03289795  0.16564941  0.08288574  0.01406097  0.18701172
  -0.01098633  0.19177246  0.18664551  0.04220581  0.22094727  0.06329346
   0.07751465  0.07269287  0.10827637  0.2878418   0.06774902  0.14855957
   0.05648804  0.06011963  0.18066406  0.10351562 -0.01248169  0.056427
   0.17749023  0.12139893 -0.04483032  0.06396484  0.11773682  0.11584473
   0.02844238 -0.05737305  0.08117676 -0.03540039  0.06121826  0.03646851
   0.21179199  0.11694336  0.1484375   0.14318848  0.0378418   0.16186523
   0.02981567  0.10284424  0.13549805  0.12042236  0.21472168 -0.03308105
   0.07995605  0.07751465  0.09863281  0.03631592  0.06573486  0.06390381
   0.16320801  0.01950073  0.01130676  0.3984375   0.18835449  0.18969727
   0.13745117 -0.00448608  0.02537537  0.01577759  0.02262878  0.05648804
   0.13781738  0.04650879  0.08221436  0.05639648 -0.07598877  0.02883911
   0.11975098  0.07543945  0.15087891  0.14550781  0.05505371  0.1060791
   0.12463379  0.14440918  0.04238892  0.0531311   0.33398438  0.10998535
   0.1887207   0.08435059  0.16113281  0.12054443  0.07781982 -0.02633667
   0.13745117 -0.01940918  0.14001465  0.02900696  0.04486084  0.04803467
   0.11303711  0.06262207  0.09912109  0.07897949  0.26635742  0.12573242
   0.06481934  0.23596191 -0.00056458  0.09906006  0.08813477  0.12097168
   0.07061768  0.11480713  0.1217041   0.29296875  0.12475586 -0.03091431
   0.1151123  -0.00593567 -0.00619507  0.30737305  0.03012085  0.10351562
   0.06689453  0.04928589  0.07806396  0.06182861  0.05273438  0.27539062
   0.00288391  0.07495117  0.31445312  0.05862427  0.13720703  0.05749512
   0.07495117  0.03384399  0.09851074  0.14855957  0.15588379 -0.03222656
   0.17529297 -0.0234375   0.00553894  0.19189453]]
After layer encoder_birnn_forward_l0_t1_slice_output1 (1, 256) <class 'numpy.float16'> [[ 0.17138672  0.06420898  0.09484863  0.03515625  0.15246582  0.08166504
   0.06335449  0.00700378  0.20239258  0.12329102  0.21313477  0.1394043
   0.06262207  0.13439941 -0.08886719  0.10229492  0.07373047  0.11315918
   0.25610352  0.07391357  0.04464722  0.06323242  0.1550293   0.07757568
   0.07104492 -0.0526123   0.10314941  0.00738525 -0.00646973  0.06066895
   0.14404297  0.12548828  0.08502197  0.1072998   0.19396973 -0.02618408
   0.09924316  0.08428955  0.06359863  0.027771    0.03320312  0.14770508
   0.17883301  0.01782227  0.0513916   0.1182251   0.13964844  0.1050415
   0.10095215  0.06097412  0.04217529  0.0803833   0.28930664  0.04162598
   0.0345459   0.05358887  0.15686035  0.05703735  0.00299072  0.15124512
   0.02110291 -0.02536011  0.01705933  0.18884277  0.12261963  0.1730957
   0.13720703  0.07202148  0.00846863  0.07666016  0.1038208   0.06958008
   0.09289551  0.11328125  0.04953003  0.2277832   0.14526367  0.32006836
   0.07958984 -0.05957031  0.18945312  0.01470184  0.35546875  0.14611816
   0.10461426 -0.00942993  0.06408691  0.12963867  0.28051758  0.06396484
   0.01553345 -0.02722168 -0.02043152  0.02392578  0.03839111  0.10540771
   0.0329895   0.13439941  0.11132812  0.12115479  0.0335083   0.09570312
   0.08056641  0.1550293   0.11254883 -0.01382446  0.04244995  0.02880859
   0.13769531  0.16052246  0.11981201  0.15075684  0.23925781  0.14221191
   0.0581665   0.08166504  0.17858887  0.22167969  0.08056641  0.10748291
   0.00479126  0.20263672  0.17578125  0.03820801  0.17871094  0.11975098
   0.10083008  0.13439941  0.06036377  0.23657227  0.03533936  0.15307617
   0.05749512  0.05450439  0.01721191  0.03302002  0.1081543  -0.02740479
   0.24682617  0.03356934  0.0612793   0.20776367  0.05834961  0.06677246
   0.07556152  0.16137695  0.09912109  0.01348877  0.08111572  0.03912354
   0.12036133  0.06988525  0.01290894  0.06738281  0.10961914  0.14672852
   0.07696533  0.05950928  0.14868164  0.11499023  0.13354492  0.11273193
   0.10528564  0.11541748  0.10559082 -0.01451111  0.03213501  0.09326172
   0.07745361  0.03031921 -0.00415802  0.22436523  0.06933594  0.13500977
   0.01476288  0.03063965  0.08886719  0.08984375  0.00200272  0.07983398
   0.1809082  -0.0142746   0.18188477  0.13439941 -0.03552246  0.06958008
   0.08947754  0.12939453  0.11712646  0.11950684  0.01916504 -0.02212524
   0.13818359  0.11138916 -0.06964111  0.09143066  0.50488281  0.02406311
   0.01312256 -0.021698    0.15039062  0.07122803  0.12084961  0.12207031
   0.12866211  0.08728027  0.10919189 -0.00576782 -0.0176239   0.1015625
   0.1484375   0.0479126   0.11553955  0.00540924  0.33007812  0.04678345
   0.0645752   0.10864258  0.03161621 -0.03503418  0.06134033  0.0847168
  -0.0345459   0.12963867  0.0319519   0.21679688  0.05834961  0.01977539
   0.14453125  0.06750488  0.10803223  0.15625     0.1262207   0.08911133
   0.14746094  0.1418457   0.10864258 -0.00915527  0.05813599  0.16699219
   0.06518555  0.16699219  0.46875     0.02189636  0.07653809  0.07470703
   0.05429077  0.01998901  0.18994141  0.10949707  0.15380859 -0.02006531
   0.16772461  0.03512573  0.11676025  0.10290527]]
After layer encoder_birnn_forward_l0_t1_slice_output2 (1, 256) <class 'numpy.float16'> [[  9.32617188e-02   1.50634766e-01  -1.76147461e-01  -4.32739258e-02
    1.57470703e-01  -1.16943359e-01   1.08581543e-01  -5.32531738e-02
    5.22460938e-02  -7.61108398e-02   1.40991211e-02   9.75952148e-02
    1.24877930e-01  -1.76269531e-01   5.63354492e-02  -1.14257812e-01
    5.16662598e-02   1.74316406e-01  -3.21350098e-02   9.64965820e-02
   -1.73583984e-01  -1.01440430e-01  -1.72485352e-01   7.61718750e-02
    1.01928711e-02  -1.12609863e-02  -2.71728516e-01  -1.01684570e-01
   -7.44018555e-02   9.35668945e-02   3.90625000e-02  -1.69067383e-01
    2.11914062e-01  -6.37817383e-03   1.55395508e-01   1.56738281e-01
    9.21020508e-02  -1.69921875e-01  -1.82373047e-01   7.80639648e-02
   -1.23901367e-01   9.31396484e-02  -1.56372070e-01   7.13500977e-02
   -4.81567383e-02  -1.52587891e-02   6.92749023e-02   1.27197266e-01
    1.29394531e-01   1.27868652e-02   2.60314941e-02   1.22619629e-01
    7.06176758e-02  -3.53698730e-02   2.12158203e-01   1.15417480e-01
   -9.71679688e-02  -3.18603516e-02   1.60156250e-01  -9.02099609e-02
    1.05224609e-01  -5.14526367e-02   1.35742188e-01   2.22778320e-01
   -1.51245117e-01   8.48388672e-02   3.32641602e-02   1.95312500e-01
    8.88671875e-02  -2.06787109e-01   5.88989258e-02  -7.59277344e-02
   -2.67089844e-01   8.06274414e-02   8.30078125e-02   1.22131348e-01
    1.14990234e-01  -2.81005859e-01   1.32812500e-01  -1.97998047e-01
    1.33789062e-01  -1.77001953e-01   9.08813477e-02   5.96313477e-02
   -1.04248047e-01  -2.04101562e-01   8.80126953e-02  -1.92871094e-01
    5.47790527e-02   1.03332520e-01   1.18774414e-01   1.10656738e-01
   -9.77783203e-02  -7.22656250e-02  -1.94458008e-01  -8.25500488e-03
   -1.53808594e-02  -2.44750977e-01   6.05468750e-02   1.52343750e-01
   -4.92248535e-02  -2.87475586e-02  -5.67016602e-02   1.73706055e-01
   -9.78393555e-02  -1.20422363e-01   5.17883301e-02   1.47338867e-01
    8.22753906e-02   2.06298828e-01  -1.25366211e-01  -1.49169922e-01
    1.67846680e-01   1.61865234e-01  -2.01110840e-02   1.83105469e-01
    1.05957031e-01   6.93969727e-02   1.43920898e-01  -3.29589844e-02
    2.48413086e-02  -1.97875977e-01   1.66503906e-01  -4.35791016e-02
    2.83935547e-01  -2.41699219e-02   1.53930664e-01   9.17358398e-02
   -1.77246094e-01  -2.54638672e-01  -2.20794678e-02   1.14990234e-01
    5.74951172e-02  -4.97741699e-02   1.92993164e-01   1.70898438e-01
   -5.40466309e-02   1.15722656e-01  -2.24853516e-01  -8.62426758e-02
   -5.39550781e-02   1.60278320e-01  -1.66259766e-01  -2.57720947e-02
    1.65893555e-01   5.51452637e-02   1.45996094e-01  -6.21948242e-02
    1.23107910e-01  -9.77783203e-02   1.45385742e-01  -1.53076172e-01
    1.52954102e-01   2.79785156e-01   9.56420898e-02  -2.04711914e-01
    1.55395508e-01  -5.67626953e-02   8.44726562e-02   7.06787109e-02
    2.70507812e-01   1.06750488e-01   2.18505859e-01   1.36352539e-01
   -1.12426758e-01   8.31298828e-02  -6.37817383e-02   1.32812500e-01
   -1.43920898e-01  -1.14868164e-01   1.03881836e-01   2.33032227e-01
   -1.18164062e-01   1.51367188e-01  -1.02905273e-01  -9.27734375e-02
    8.77685547e-02   1.77001953e-01  -1.66625977e-01  -4.23889160e-02
    2.02026367e-01   1.40014648e-01   9.18579102e-02   1.32324219e-01
   -8.17871094e-02  -1.34643555e-01  -1.05529785e-01   2.49755859e-01
    6.73828125e-02  -6.29882812e-02   6.61010742e-02  -1.63818359e-01
   -1.80419922e-01   1.64184570e-01   8.25805664e-02  -1.20178223e-01
    4.93774414e-02  -1.93481445e-01   1.34887695e-01  -9.15527344e-05
    1.10107422e-01  -1.63085938e-01  -1.11694336e-01  -3.66821289e-02
   -1.26708984e-01   1.39770508e-01   2.88696289e-02   4.05273438e-02
    7.03125000e-02   1.81274414e-01  -9.89990234e-02   2.07153320e-01
    1.07910156e-01   2.76641846e-02   2.16308594e-01  -1.94702148e-01
   -1.06445312e-01  -1.82495117e-01  -4.26635742e-02   2.36206055e-02
   -9.69238281e-02   8.00781250e-02   1.83349609e-01  -2.16064453e-01
    9.17358398e-02  -3.35937500e-01  -2.50000000e-01  -1.94335938e-01
    5.57556152e-02  -3.45764160e-02  -8.67919922e-02  -1.59790039e-01
   -5.67932129e-02   2.65869141e-01  -7.42187500e-02  -2.38647461e-02
    2.60742188e-01   2.02636719e-01  -3.74755859e-02   2.18627930e-01
    1.04614258e-01   9.66796875e-02  -2.48413086e-01  -1.27197266e-01
    1.75170898e-01  -1.07116699e-01   7.01904297e-04  -1.08276367e-01
   -1.80664062e-01   1.50390625e-01  -1.34155273e-01  -6.02111816e-02
   -1.48437500e-01  -1.02844238e-01  -1.34277344e-02   1.77246094e-01]]
After layer encoder_birnn_forward_l0_t1_slice_output3 (1, 256) <class 'numpy.float16'> [[ 0.07580566  0.09533691  0.04190063  0.08032227  0.09130859  0.12219238
   0.18579102  0.04421997  0.15673828  0.1192627   0.07373047  0.08172607
   0.0960083   0.15551758 -0.01521301 -0.00161743  0.10540771  0.02685547
   0.25292969  0.10144043  0.09765625  0.00901794  0.22937012  0.11437988
   0.14868164  0.16772461  0.203125    0.08685303  0.05877686  0.15722656
   0.13342285  0.17407227  0.07421875  0.15466309  0.18408203  0.0604248
   0.1227417   0.08911133  0.02644348  0.15576172  0.19604492  0.10876465
   0.02392578  0.13696289  0.11798096  0.16455078  0.16186523  0.0557251
   0.16967773  0.08557129 -0.02920532  0.10998535  0.36865234  0.0447998
   0.07531738  0.00386047  0.17675781  0.03665161  0.14611816  0.19055176
   0.06481934  0.12768555  0.00868225  0.30957031  0.12451172  0.15991211
   0.20666504  0.11468506  0.08032227  0.13110352  0.17895508  0.16833496
   0.13110352  0.08068848  0.09277344  0.2388916   0.06463623  0.23144531
   0.19445801  0.09216309  0.12792969 -0.05535889  0.39746094  0.11437988
   0.19360352  0.15234375  0.10522461  0.09362793  0.27734375  0.06860352
   0.05688477  0.06445312  0.09442139  0.22143555  0.13439941  0.18286133
   0.10638428  0.22412109  0.14477539  0.30224609  0.07324219  0.02484131
   0.15637207  0.1809082   0.12243652  0.00212097  0.15209961  0.20410156
   0.16418457  0.13549805  0.1270752   0.17419434  0.16088867  0.23999023
   0.14575195  0.05865479  0.10906982  0.16870117  0.11724854  0.23132324
   0.10852051  0.28271484  0.08074951  0.13916016  0.10681152  0.08062744
   0.06414795  0.03723145  0.05331421  0.20349121  0.10803223  0.17004395
   0.05889893  0.14245605  0.05795288  0.0559082   0.02539062  0.11138916
   0.09985352  0.17138672  0.12103271 -0.00341797  0.14868164  0.09069824
   0.07641602  0.04037476 -0.02243042  0.13574219  0.02661133  0.07922363
   0.12780762  0.09228516  0.16394043  0.11633301  0.13427734  0.08734131
   0.16308594  0.1652832   0.18383789  0.08673096  0.11999512  0.12347412
   0.06268311  0.16943359  0.17602539  0.03192139  0.15710449  0.09973145
   0.08312988 -0.01037598  0.19226074  0.34130859  0.14355469  0.25610352
  -0.01774597  0.09387207  0.09124756  0.09436035  0.0194397   0.04693604
   0.07818604  0.14709473  0.17102051  0.10705566 -0.01644897  0.12200928
   0.10192871  0.09698486  0.13195801  0.1328125  -0.07641602  0.04464722
   0.20373535  0.15600586  0.04370117  0.14099121  0.51416016  0.03796387
   0.18823242  0.01342773  0.03323364  0.01376343  0.17797852  0.0802002
   0.17529297  0.17773438  0.04376221 -0.03225708 -0.02874756  0.19189453
   0.18823242  0.03970337  0.15893555  0.23706055  0.18286133  0.203125
   0.19897461  0.06799316  0.14111328  0.0380249   0.08642578  0.21777344
   0.07507324  0.01702881  0.15966797  0.09436035  0.04772949  0.14404297
   0.05303955  0.07824707  0.11468506  0.06817627  0.08135986  0.06433105
   0.13354492  0.06506348  0.03683472  0.09051514  0.01583862  0.14587402
   0.04660034  0.26708984  0.38500977  0.07092285  0.09777832  0.08251953
   0.11279297  0.05340576  0.15441895  0.05664062  0.1472168   0.12805176
   0.18359375  0.09387207  0.16088867  0.09326172]]
After layer encoder_birnn_forward_l0_t1_o_output (1, 256) <class 'numpy.float16'> [[ 0.51904297  0.52392578  0.51025391  0.52001953  0.52294922  0.53027344
   0.54638672  0.51123047  0.5390625   0.52978516  0.51855469  0.52050781
   0.52392578  0.53857422  0.49609375  0.49951172  0.52636719  0.50683594
   0.56298828  0.52539062  0.52441406  0.50244141  0.55712891  0.52832031
   0.53710938  0.54199219  0.55078125  0.52148438  0.51464844  0.5390625
   0.53320312  0.54345703  0.51855469  0.53857422  0.54589844  0.51513672
   0.53076172  0.52246094  0.50683594  0.5390625   0.54882812  0.52734375
   0.50585938  0.53417969  0.52929688  0.54101562  0.54052734  0.51416016
   0.54248047  0.52148438  0.49267578  0.52734375  0.59130859  0.51123047
   0.51904297  0.50097656  0.54394531  0.50927734  0.53662109  0.54736328
   0.51611328  0.53173828  0.50195312  0.57666016  0.53125     0.54003906
   0.55126953  0.52880859  0.52001953  0.53271484  0.54443359  0.54199219
   0.53271484  0.52001953  0.52294922  0.55957031  0.51611328  0.55761719
   0.54833984  0.52294922  0.53173828  0.48608398  0.59814453  0.52832031
   0.54833984  0.53808594  0.52636719  0.5234375   0.56884766  0.51708984
   0.51416016  0.51611328  0.5234375   0.55517578  0.53369141  0.54541016
   0.52636719  0.55566406  0.53613281  0.57519531  0.51806641  0.50634766
   0.5390625   0.54492188  0.53076172  0.50048828  0.53808594  0.55078125
   0.54101562  0.53369141  0.53173828  0.54345703  0.54003906  0.55957031
   0.53613281  0.51464844  0.52734375  0.54199219  0.52929688  0.55761719
   0.52734375  0.5703125   0.52001953  0.53466797  0.52685547  0.52001953
   0.51611328  0.50927734  0.51318359  0.55078125  0.52685547  0.54248047
   0.51464844  0.53564453  0.51464844  0.51416016  0.50634766  0.52783203
   0.52490234  0.54296875  0.53027344  0.49926758  0.53710938  0.52246094
   0.51904297  0.51025391  0.49438477  0.53369141  0.50683594  0.52001953
   0.53173828  0.52294922  0.54101562  0.52880859  0.53369141  0.52197266
   0.54052734  0.54101562  0.54589844  0.52148438  0.52978516  0.53076172
   0.515625    0.54248047  0.54394531  0.5078125   0.5390625   0.52490234
   0.52099609  0.49731445  0.54785156  0.58447266  0.53564453  0.56347656
   0.49560547  0.5234375   0.52294922  0.5234375   0.50488281  0.51171875
   0.51953125  0.53662109  0.54248047  0.52685547  0.49584961  0.53027344
   0.52539062  0.52441406  0.53271484  0.53320312  0.48095703  0.51123047
   0.55078125  0.5390625   0.51074219  0.53515625  0.62597656  0.50927734
   0.546875    0.50341797  0.50830078  0.50341797  0.54443359  0.52001953
   0.54394531  0.54443359  0.51074219  0.49194336  0.49291992  0.54785156
   0.546875    0.50976562  0.53955078  0.55908203  0.54541016  0.55078125
   0.54980469  0.51708984  0.53515625  0.50927734  0.52148438  0.55419922
   0.51855469  0.50439453  0.54003906  0.5234375   0.51171875  0.53613281
   0.51318359  0.51953125  0.52880859  0.51708984  0.52050781  0.51611328
   0.53320312  0.51611328  0.50927734  0.52246094  0.50390625  0.53662109
   0.51171875  0.56640625  0.59521484  0.51757812  0.52441406  0.52050781
   0.52832031  0.51318359  0.53857422  0.51416016  0.53662109  0.53173828
   0.54589844  0.5234375   0.54003906  0.5234375 ]]
After layer encoder_birnn_forward_l0_t1_f_output (1, 256) <class 'numpy.float16'> [[ 0.54296875  0.51611328  0.52392578  0.50878906  0.53808594  0.52050781
   0.515625    0.50195312  0.55029297  0.53076172  0.55322266  0.53466797
   0.515625    0.53369141  0.4777832   0.52539062  0.51855469  0.52832031
   0.56347656  0.51855469  0.51123047  0.515625    0.53857422  0.51953125
   0.51757812  0.48681641  0.52587891  0.50195312  0.49829102  0.51513672
   0.53613281  0.53125     0.52148438  0.52685547  0.54833984  0.4934082
   0.52490234  0.52099609  0.51611328  0.50683594  0.50830078  0.53662109
   0.54443359  0.50439453  0.51269531  0.52929688  0.53466797  0.52636719
   0.52539062  0.51513672  0.51074219  0.52001953  0.57177734  0.51025391
   0.50878906  0.51318359  0.5390625   0.51416016  0.50097656  0.53759766
   0.50537109  0.49365234  0.50439453  0.546875    0.53076172  0.54296875
   0.53417969  0.51806641  0.50195312  0.51904297  0.52587891  0.51757812
   0.5234375   0.52832031  0.51220703  0.55664062  0.53613281  0.57910156
   0.52001953  0.48510742  0.54736328  0.50390625  0.58789062  0.53662109
   0.52636719  0.49755859  0.51611328  0.53222656  0.56982422  0.51611328
   0.50390625  0.49316406  0.49487305  0.50585938  0.50976562  0.52636719
   0.50830078  0.53369141  0.52783203  0.53027344  0.50830078  0.52392578
   0.52001953  0.53857422  0.52832031  0.49658203  0.51074219  0.50732422
   0.53417969  0.54003906  0.52978516  0.53759766  0.55957031  0.53564453
   0.51464844  0.52050781  0.54443359  0.55517578  0.52001953  0.52685547
   0.50097656  0.55029297  0.54394531  0.50976562  0.54443359  0.52978516
   0.52539062  0.53369141  0.51513672  0.55908203  0.50878906  0.53808594
   0.51416016  0.51367188  0.50439453  0.50830078  0.52685547  0.49316406
   0.56152344  0.50830078  0.51513672  0.55175781  0.51464844  0.51660156
   0.51904297  0.54003906  0.52490234  0.50341797  0.52050781  0.50976562
   0.53027344  0.51757812  0.50341797  0.51660156  0.52734375  0.53662109
   0.51904297  0.51464844  0.53710938  0.52880859  0.53320312  0.52832031
   0.52636719  0.52880859  0.52636719  0.49633789  0.5078125   0.5234375
   0.51953125  0.5078125   0.49902344  0.55566406  0.51708984  0.53369141
   0.50390625  0.5078125   0.52197266  0.52246094  0.50048828  0.52001953
   0.54492188  0.49633789  0.54541016  0.53369141  0.49121094  0.51757812
   0.52246094  0.53222656  0.52929688  0.52978516  0.50488281  0.49438477
   0.53466797  0.52783203  0.48266602  0.52294922  0.62353516  0.50585938
   0.50341797  0.49462891  0.53759766  0.51757812  0.53027344  0.53027344
   0.53222656  0.52197266  0.52734375  0.49853516  0.49560547  0.52539062
   0.53710938  0.51220703  0.52880859  0.50146484  0.58154297  0.51171875
   0.51611328  0.52734375  0.5078125   0.49121094  0.51513672  0.52099609
   0.49145508  0.53222656  0.5078125   0.55419922  0.51464844  0.50488281
   0.53613281  0.51708984  0.52685547  0.5390625   0.53173828  0.52246094
   0.53662109  0.53564453  0.52734375  0.49780273  0.51464844  0.54150391
   0.51611328  0.54150391  0.61523438  0.50537109  0.51904297  0.51855469
   0.51367188  0.50488281  0.54736328  0.52734375  0.53857422  0.49487305
   0.54199219  0.50878906  0.52929688  0.52587891]]
After layer _mul2054_0 (1, 256) <class 'numpy.float16'> [[ 0.00380516  0.02279663 -0.00645447 -0.00887299  0.03204346 -0.00689316
   0.01163483 -0.03741455  0.01574707  0.00413513  0.01878357  0.00619507
   0.02285767 -0.01132202  0.02638245 -0.00861359 -0.00452423  0.00447464
  -0.00981903 -0.00503159  0.00749588 -0.03004456 -0.03625488  0.02926636
   0.00219727 -0.0160675  -0.01332855 -0.01333618 -0.01251984  0.01007843
   0.01381683 -0.01573181  0.0100174  -0.00765228  0.0224762   0.008255
   0.00977325 -0.00797272 -0.01351166 -0.00788879 -0.01358795  0.02760315
  -0.00585938  0.01812744 -0.02313232 -0.02186584  0.0035553   0.0226593
   0.01599121 -0.00470734 -0.00226974 -0.0184021   0.02528381 -0.02589417
   0.00795746  0.03326416  0.00969696 -0.01649475  0.02145386 -0.01403809
   0.01960754 -0.01672363  0.00321198  0.00543594 -0.00316811 -0.00616455
   0.00553131  0.01898193 -0.00104618 -0.01911926 -0.00036716 -0.0259552
  -0.0357666   0.02053833  0.04031372 -0.00143719  0.03845215 -0.04229736
   0.03408813 -0.01239777  0.02479553 -0.01198578  0.05053711  0.00691223
   0.00517654 -0.00973511  0.01553345 -0.0324707  -0.020401    0.02180481
  -0.00774384  0.01652527 -0.02246094 -0.01340485 -0.02163696  0.01245117
   0.00514603 -0.04116821  0.02009583  0.02760315 -0.03125    -0.00461578
   0.00041032  0.00461578  0.01264954 -0.02101135  0.00447464  0.03038025
   0.02433777  0.01568604  0.00688934 -0.0229187   0.04547119  0.04959106
  -0.01670837 -0.00245285  0.01701355  0.0440979   0.00526047  0.01105499
   0.00342751 -0.03103638  0.03427124 -0.03268433  0.02734375 -0.00706482
   0.01313019  0.02589417  0.0015564  -0.04696655  0.00025702  0.00772858
   0.01783752 -0.01152039  0.01834106  0.02484131  0.01570129  0.0324707
  -0.03068542  0.00219727 -0.01678467  0.03973389 -0.02845764 -0.02130127
   0.02879333  0.0259552   0.01512146 -0.01669312  0.04016113 -0.01786804
  -0.00423431  0.00333786  0.02391052  0.02618408  0.01812744 -0.02528381
   0.02159119  0.01137543  0.01641846  0.00510788  0.00447845  0.014328
  -0.00258255  0.0060463  -0.01696777  0.01535034 -0.03753662 -0.00400162
  -0.03065491 -0.01416016  0.00165653 -0.0030899  -0.0036869  -0.00305367
   0.00507355 -0.01028442  0.04394531  0.00090027 -0.01322174  0.00221634
   0.01623535  0.0196228   0.01809692  0.00085688  0.00569534 -0.02105713
   0.00208664  0.00770187  0.01152802  0.00557709  0.00747299 -0.0086441
  -0.03948975  0.04968262  0.00078583 -0.04504395 -0.02911377 -0.02322388
   0.01777649  0.02619934  0.02992249 -0.0296936  -0.00077152 -0.00365448
  -0.0219574  -0.00231934  0.00792694  0.01867676  0.01377106 -0.00062752
   0.00382233  0.02175903  0.02487183 -0.00813293  0.00025058 -0.00074005
  -0.01663208 -0.02500916 -0.01901245  0.0024929  -0.01298523  0.01040649
   0.00885773 -0.04370117  0.02230835 -0.01113892 -0.03295898 -0.00620651
   0.00392914 -0.0165863  -0.01261902 -0.01360321  0.01794434  0.01321411
  -0.01730347 -0.00511551  0.01337433  0.02531433 -0.0092392  -0.00073671
   0.01098633  0.02520752 -0.00204086 -0.0244751   0.01490021 -0.02481079
   0.0138092  -0.01318359 -0.02346802  0.00698853 -0.0214386   0.00285339
   0.00576401 -0.02938843  0.01905823  0.00029707]]
After layer encoder_birnn_forward_l0_t1_i_output (1, 256) <class 'numpy.float16'> [[ 0.53125     0.49633789  0.54443359  0.53466797  0.52392578  0.515625
   0.51953125  0.51806641  0.5078125   0.51806641  0.53564453  0.53125
   0.50292969  0.5234375   0.49536133  0.51611328  0.49560547  0.5390625
   0.53125     0.52099609  0.49829102  0.51416016  0.5546875   0.50292969
   0.50927734  0.50683594  0.53857422  0.49975586  0.51318359  0.51318359
   0.50732422  0.54003906  0.53515625  0.50292969  0.52539062  0.51513672
   0.50830078  0.56201172  0.54248047  0.50097656  0.52148438  0.52392578
   0.55126953  0.50585938  0.52197266  0.52392578  0.53857422  0.51513672
   0.52294922  0.51367188  0.51806641  0.48803711  0.57373047  0.51171875
   0.53515625  0.51708984  0.51171875  0.51611328  0.51953125  0.48754883
   0.51025391  0.54003906  0.52978516  0.57128906  0.53466797  0.49047852
   0.55908203  0.51464844  0.50048828  0.52832031  0.50732422  0.50488281
   0.56103516  0.50537109  0.51464844  0.5234375   0.53710938  0.54833984
   0.52734375  0.51367188  0.53076172  0.51855469  0.56640625  0.50146484
   0.53515625  0.53417969  0.52880859  0.54833984  0.57519531  0.49609375
   0.51074219  0.50634766  0.50244141  0.54003906  0.51318359  0.53027344
   0.51904297  0.55957031  0.53027344  0.52539062  0.51855469  0.48925781
   0.52832031  0.51953125  0.53466797  0.50390625  0.52978516  0.51464844
   0.51220703  0.52587891  0.55957031  0.54492188  0.52832031  0.53564453
   0.52294922  0.50830078  0.54150391  0.52050781  0.50341797  0.54638672
   0.49731445  0.54785156  0.54638672  0.51074219  0.55517578  0.515625
   0.51953125  0.51806641  0.52685547  0.57128906  0.51708984  0.53710938
   0.51416016  0.51513672  0.54492188  0.52587891  0.49682617  0.51416016
   0.54443359  0.53027344  0.48876953  0.51611328  0.52929688  0.52880859
   0.50732422  0.4855957   0.52050781  0.49121094  0.51513672  0.50927734
   0.55273438  0.52929688  0.53710938  0.53564453  0.50927734  0.54052734
   0.50732422  0.52587891  0.53369141  0.53027344  0.55371094  0.49169922
   0.52001953  0.51953125  0.52441406  0.50927734  0.51660156  0.51611328
   0.54052734  0.50488281  0.50292969  0.59814453  0.546875    0.54736328
   0.53417969  0.4987793   0.50634766  0.50390625  0.50585938  0.51416016
   0.53417969  0.51171875  0.52050781  0.51416016  0.48095703  0.50732422
   0.52978516  0.51904297  0.53759766  0.53613281  0.51367188  0.52636719
   0.53125     0.53613281  0.51074219  0.51318359  0.58251953  0.52734375
   0.546875    0.52099609  0.54003906  0.53027344  0.51953125  0.4934082
   0.53417969  0.49511719  0.53515625  0.50732422  0.51123047  0.51220703
   0.52832031  0.515625    0.52490234  0.51953125  0.56640625  0.53125
   0.51611328  0.55859375  0.49975586  0.52490234  0.52197266  0.53027344
   0.51757812  0.52880859  0.53027344  0.57275391  0.53125     0.4921875
   0.52880859  0.49853516  0.49853516  0.57617188  0.50732422  0.52587891
   0.51660156  0.51220703  0.51953125  0.515625    0.51318359  0.56835938
   0.50048828  0.51855469  0.578125    0.51464844  0.53417969  0.51416016
   0.51855469  0.50830078  0.52441406  0.53710938  0.5390625   0.49194336
   0.54394531  0.49414062  0.50146484  0.54785156]]
After layer encoder_birnn_forward_l0_t1_c_output (1, 256) <class 'numpy.float16'> [[  9.30175781e-02   1.49536133e-01  -1.74316406e-01  -4.32434082e-02
    1.56127930e-01  -1.16394043e-01   1.08154297e-01  -5.31921387e-02
    5.21850586e-02  -7.59887695e-02   1.40991211e-02   9.72900391e-02
    1.24206543e-01  -1.74438477e-01   5.62744141e-02  -1.13769531e-01
    5.16052246e-02   1.72607422e-01  -3.21350098e-02   9.61914062e-02
   -1.71875000e-01  -1.01074219e-01  -1.70776367e-01   7.60498047e-02
    1.01928711e-02  -1.12609863e-02  -2.65136719e-01  -1.01318359e-01
   -7.42797852e-02   9.33227539e-02   3.90319824e-02  -1.67480469e-01
    2.08740234e-01  -6.37817383e-03   1.54174805e-01   1.55517578e-01
    9.18579102e-02  -1.68334961e-01  -1.80419922e-01   7.78808594e-02
   -1.23291016e-01   9.28955078e-02  -1.55151367e-01   7.12280273e-02
   -4.81262207e-02  -1.52587891e-02   6.91528320e-02   1.26464844e-01
    1.28662109e-01   1.27868652e-02   2.60314941e-02   1.22009277e-01
    7.04956055e-02  -3.53698730e-02   2.08984375e-01   1.14929199e-01
   -9.68627930e-02  -3.18603516e-02   1.58813477e-01  -8.99658203e-02
    1.04858398e-01  -5.14221191e-02   1.34887695e-01   2.19116211e-01
   -1.50146484e-01   8.46557617e-02   3.32641602e-02   1.92871094e-01
    8.86230469e-02  -2.03857422e-01   5.88378906e-02  -7.58056641e-02
   -2.60986328e-01   8.04443359e-02   8.28247070e-02   1.21520996e-01
    1.14501953e-01  -2.73925781e-01   1.32080078e-01  -1.95434570e-01
    1.33056641e-01  -1.75170898e-01   9.06372070e-02   5.95703125e-02
   -1.03881836e-01  -2.01293945e-01   8.77685547e-02  -1.90551758e-01
    5.47180176e-02   1.02966309e-01   1.18225098e-01   1.10229492e-01
   -9.74731445e-02  -7.21435547e-02  -1.92016602e-01  -8.25500488e-03
   -1.53808594e-02  -2.39990234e-01   6.04858398e-02   1.51123047e-01
   -4.91943359e-02  -2.87322998e-02  -5.66406250e-02   1.71997070e-01
   -9.75341797e-02  -1.19873047e-01   5.17272949e-02   1.46240234e-01
    8.20922852e-02   2.03369141e-01  -1.24694824e-01  -1.48071289e-01
    1.66259766e-01   1.60522461e-01  -2.01110840e-02   1.81030273e-01
    1.05590820e-01   6.92749023e-02   1.42944336e-01  -3.29589844e-02
    2.48413086e-02  -1.95312500e-01   1.65039062e-01  -4.35485840e-02
    2.76611328e-01  -2.41699219e-02   1.52709961e-01   9.14916992e-02
   -1.75415039e-01  -2.49267578e-01  -2.20794678e-02   1.14501953e-01
    5.74340820e-02  -4.97436523e-02   1.90673828e-01   1.69311523e-01
   -5.39855957e-02   1.15234375e-01  -2.21191406e-01  -8.60595703e-02
   -5.38940430e-02   1.58935547e-01  -1.64794922e-01  -2.57720947e-02
    1.64428711e-01   5.50842285e-02   1.45019531e-01  -6.21032715e-02
    1.22497559e-01  -9.74731445e-02   1.44409180e-01  -1.51855469e-01
    1.51733398e-01   2.72705078e-01   9.53369141e-02  -2.01904297e-01
    1.54174805e-01  -5.67016602e-02   8.42895508e-02   7.05566406e-02
    2.64160156e-01   1.06323242e-01   2.15087891e-01   1.35498047e-01
   -1.11938477e-01   8.29467773e-02  -6.37207031e-02   1.32080078e-01
   -1.42944336e-01  -1.14379883e-01   1.03515625e-01   2.28881836e-01
   -1.17614746e-01   1.50268555e-01  -1.02539062e-01  -9.25292969e-02
    8.75244141e-02   1.75170898e-01  -1.65161133e-01  -4.23583984e-02
    1.99340820e-01   1.39160156e-01   9.16137695e-02   1.31591797e-01
   -8.16040039e-02  -1.33789062e-01  -1.05163574e-01   2.44628906e-01
    6.72607422e-02  -6.29272461e-02   6.59790039e-02  -1.62353516e-01
   -1.78466797e-01   1.62719727e-01   8.23974609e-02  -1.19628906e-01
    4.93469238e-02  -1.91162109e-01   1.34033203e-01  -9.15527344e-05
    1.09680176e-01  -1.61621094e-01  -1.11206055e-01  -3.66516113e-02
   -1.25976562e-01   1.38916016e-01   2.88543701e-02   4.04968262e-02
    7.01904297e-02   1.79321289e-01  -9.86938477e-02   2.04223633e-01
    1.07482910e-01   2.76641846e-02   2.13012695e-01  -1.92260742e-01
   -1.06018066e-01  -1.80541992e-01  -4.26330566e-02   2.36206055e-02
   -9.66186523e-02   7.98950195e-02   1.81274414e-01  -2.12768555e-01
    9.14916992e-02  -3.23730469e-01  -2.44873047e-01  -1.91894531e-01
    5.56945801e-02  -3.45764160e-02  -8.65478516e-02  -1.58447266e-01
   -5.67321777e-02   2.59765625e-01  -7.40966797e-02  -2.38647461e-02
    2.54882812e-01   1.99951172e-01  -3.74450684e-02   2.15209961e-01
    1.04248047e-01   9.63745117e-02  -2.43408203e-01  -1.26464844e-01
    1.73461914e-01  -1.06689453e-01   7.01904297e-04  -1.07849121e-01
   -1.78710938e-01   1.49291992e-01  -1.33300781e-01  -6.01501465e-02
   -1.47338867e-01  -1.02478027e-01  -1.34277344e-02   1.75415039e-01]]
After layer _mul2055_0 (1, 256) <class 'numpy.float16'> [[  4.94079590e-02   7.42187500e-02  -9.49096680e-02  -2.31170654e-02
    8.17871094e-02  -6.00280762e-02   5.61828613e-02  -2.75573730e-02
    2.65045166e-02  -3.93676758e-02   7.55310059e-03   5.16967773e-02
    6.24694824e-02  -9.13085938e-02   2.78778076e-02  -5.87158203e-02
    2.55737305e-02   9.30175781e-02  -1.70745850e-02   5.01098633e-02
   -8.56323242e-02  -5.19714355e-02  -9.47265625e-02   3.82385254e-02
    5.19180298e-03  -5.70678711e-03  -1.42822266e-01  -5.06286621e-02
   -3.81164551e-02   4.78820801e-02   1.98059082e-02  -9.04541016e-02
    1.11694336e-01  -3.20816040e-03   8.09936523e-02   8.01391602e-02
    4.66918945e-02  -9.46044922e-02  -9.79003906e-02   3.90014648e-02
   -6.42700195e-02   4.86755371e-02  -8.55102539e-02   3.60412598e-02
   -2.51159668e-02  -7.99560547e-03   3.72314453e-02   6.51245117e-02
    6.72607422e-02   6.56890869e-03   1.34887695e-02   5.95397949e-02
    4.04357910e-02  -1.80969238e-02   1.11816406e-01   5.94177246e-02
   -4.95605469e-02  -1.64489746e-02   8.25195312e-02  -4.38537598e-02
    5.34973145e-02  -2.77709961e-02   7.14721680e-02   1.25122070e-01
   -8.02612305e-02   4.15344238e-02   1.86004639e-02   9.92431641e-02
    4.43420410e-02  -1.07727051e-01   2.98461914e-02  -3.82690430e-02
   -1.46362305e-01   4.06494141e-02   4.26330566e-02   6.35986328e-02
    6.14929199e-02  -1.50146484e-01   6.96411133e-02  -1.00402832e-01
    7.06176758e-02  -9.08203125e-02   5.13305664e-02   2.98767090e-02
   -5.56030273e-02  -1.07543945e-01   4.64172363e-02  -1.04492188e-01
    3.14636230e-02   5.10864258e-02   6.03942871e-02   5.58166504e-02
   -4.89807129e-02  -3.89709473e-02  -9.85107422e-02  -4.37927246e-03
   -7.98034668e-03  -1.34277344e-01   3.20739746e-02   7.94067383e-02
   -2.55126953e-02  -1.40609741e-02  -2.99224854e-02   8.93554688e-02
   -5.21545410e-02  -6.03942871e-02   2.74047852e-02   7.52563477e-02
    4.20532227e-02   1.06933594e-01  -6.97631836e-02  -8.06884766e-02
    8.78295898e-02   8.59985352e-02  -1.05133057e-02   9.20410156e-02
    5.71899414e-02   3.60717773e-02   7.19604492e-02  -1.80053711e-02
    1.23519897e-02  -1.06994629e-01   9.01489258e-02  -2.22473145e-02
    1.53564453e-01  -1.24664307e-02   7.93457031e-02   4.73937988e-02
   -9.24072266e-02  -1.42456055e-01  -1.14135742e-02   6.14929199e-02
    2.95257568e-02  -2.56195068e-02   1.03881836e-01   8.90502930e-02
   -2.68249512e-02   5.92346191e-02  -1.20422363e-01  -4.56237793e-02
   -2.63366699e-02   8.20312500e-02  -8.72192383e-02  -1.36260986e-02
    8.34350586e-02   2.67486572e-02   7.55004883e-02  -3.05023193e-02
    6.31103516e-02  -4.96520996e-02   7.98339844e-02  -8.03833008e-02
    8.14819336e-02   1.46118164e-01   4.85534668e-02  -1.09130859e-01
    7.82470703e-02  -2.98156738e-02   4.49829102e-02   3.74145508e-02
    1.46240234e-01   5.22766113e-02   1.11877441e-01   7.03735352e-02
   -5.87158203e-02   4.22363281e-02  -3.29284668e-02   6.81762695e-02
   -7.72705078e-02  -5.77392578e-02   5.20629883e-02   1.36962891e-01
   -6.43310547e-02   8.22753906e-02  -5.47790527e-02  -4.61425781e-02
    4.43115234e-02   8.82568359e-02  -8.35571289e-02  -2.17742920e-02
    1.06506348e-01   7.12280273e-02   4.76989746e-02   6.76879883e-02
   -3.92456055e-02  -6.78710938e-02  -5.57250977e-02   1.26953125e-01
    3.61633301e-02  -3.37524414e-02   3.39050293e-02  -8.54492188e-02
   -9.47875977e-02   8.72192383e-02   4.20837402e-02  -6.14013672e-02
    2.87475586e-02  -1.00830078e-01   7.33032227e-02  -4.76837158e-05
    5.92346191e-02  -8.56933594e-02  -5.77697754e-02  -1.80816650e-02
   -6.73217773e-02   6.87866211e-02   1.54418945e-02   2.05383301e-02
    3.58886719e-02   9.18579102e-02  -5.21545410e-02   1.05285645e-01
    5.64270020e-02   1.43737793e-02   1.20666504e-01  -1.02111816e-01
   -5.47180176e-02  -1.00830078e-01  -2.13012695e-02   1.23977661e-02
   -5.04455566e-02   4.23583984e-02   9.38110352e-02  -1.12487793e-01
    4.85229492e-02  -1.85424805e-01  -1.30126953e-01  -9.44213867e-02
    2.94494629e-02  -1.72424316e-02  -4.31518555e-02  -9.13085938e-02
   -2.87780762e-02   1.36596680e-01  -3.82690430e-02  -1.22222900e-02
    1.32446289e-01   1.03088379e-01  -1.92108154e-02   1.22314453e-01
    5.21850586e-02   4.99877930e-02  -1.40747070e-01  -6.50634766e-02
    9.26513672e-02  -5.48706055e-02   3.64065170e-04  -5.48095703e-02
   -9.36889648e-02   8.02001953e-02  -7.18383789e-02  -2.95867920e-02
   -8.01391602e-02  -5.06286621e-02  -6.73294067e-03   9.61303711e-02]]
After layer encoder_birnn_forward_l0_t1_state_0 (1, 256) <class 'numpy.float16'> [[ 0.05322266  0.0970459  -0.10137939 -0.03198242  0.11383057 -0.06689453
   0.06781006 -0.06494141  0.04223633 -0.03521729  0.02633667  0.05789185
   0.08532715 -0.10266113  0.05426025 -0.06732178  0.02105713  0.09747314
  -0.02688599  0.04507446 -0.078125   -0.08203125 -0.13098145  0.06750488
   0.00738907 -0.02177429 -0.15612793 -0.06396484 -0.05062866  0.05795288
   0.03363037 -0.10620117  0.1217041  -0.01086426  0.10345459  0.08837891
   0.05645752 -0.1026001  -0.11138916  0.03111267 -0.07788086  0.07629395
  -0.09136963  0.0541687  -0.04824829 -0.02986145  0.04077148  0.08776855
   0.08325195  0.00186157  0.01121521  0.0411377   0.06573486 -0.04400635
   0.11975098  0.09265137 -0.03985596 -0.03295898  0.10400391 -0.05789185
   0.07312012 -0.04449463  0.07470703  0.13061523 -0.08343506  0.03536987
   0.0241394   0.1182251   0.04330444 -0.12683105  0.02947998 -0.06420898
  -0.18212891  0.06118774  0.08294678  0.06216431  0.09997559 -0.19238281
   0.10375977 -0.11279297  0.09539795 -0.1027832   0.10186768  0.0368042
  -0.05041504 -0.11730957  0.06195068 -0.13696289  0.01106262  0.07287598
   0.05264282  0.07232666 -0.07141113 -0.05236816 -0.12011719  0.0080719
  -0.00283432 -0.17541504  0.05218506  0.10699463 -0.0567627  -0.01867676
  -0.0295105   0.09399414 -0.03948975 -0.0814209   0.03189087  0.10565186
   0.06640625  0.12261963 -0.06286621 -0.1036377   0.13330078  0.13562012
  -0.02722168  0.08959961  0.07421875  0.0802002   0.07720947 -0.00695038
   0.01577759 -0.13806152  0.12438965 -0.05493164  0.1809082  -0.01953125
   0.09246826  0.07330322 -0.09082031 -0.18945312 -0.01115417  0.06921387
   0.04736328 -0.03713989  0.12219238  0.1138916  -0.01112366  0.0916748
  -0.15112305 -0.04342651 -0.04312134  0.12176514 -0.11566162 -0.03491211
   0.11224365  0.05270386  0.09063721 -0.04718018  0.10327148 -0.06750488
   0.07562256 -0.07702637  0.10540771  0.17236328  0.06665039 -0.13439941
   0.09985352 -0.01843262  0.06140137  0.04251099  0.15075684  0.06658936
   0.10931396  0.07641602 -0.07568359  0.05758667 -0.07043457  0.06414795
  -0.10791016 -0.07189941  0.05371094  0.13391113 -0.06799316  0.07922363
  -0.04971313 -0.056427    0.08825684  0.08917236 -0.09680176 -0.01956177
   0.1227417   0.09082031  0.0657959   0.06854248 -0.03353882 -0.08892822
  -0.0536499   0.13464355  0.04769897 -0.02816772  0.04138184 -0.09411621
  -0.13427734  0.13696289  0.0428772  -0.10644531 -0.00036621 -0.12402344
   0.09106445  0.02615356  0.08917236 -0.11535645 -0.05853271 -0.02172852
  -0.08929443  0.06646729  0.02337646  0.03921509  0.0496521   0.09124756
  -0.04833984  0.1270752   0.08129883  0.00624084  0.12091064 -0.10284424
  -0.0713501  -0.12585449 -0.04031372  0.01489258 -0.06341553  0.05276489
   0.10266113 -0.15625     0.07080078 -0.1965332  -0.16308594 -0.10064697
   0.03338623 -0.03381348 -0.05578613 -0.10491943 -0.01083374  0.14978027
  -0.05557251 -0.01733398  0.14587402  0.12841797 -0.02844238  0.12158203
   0.06317139  0.07519531 -0.14282227 -0.08953857  0.10754395 -0.07971191
   0.01417542 -0.06799316 -0.1171875   0.0871582  -0.09326172 -0.0267334
  -0.07440186 -0.08001709  0.0123291   0.09643555]]
After layer activation1027_output (1, 256) <class 'numpy.float16'> [[ 0.05316162  0.09674072 -0.10101318 -0.03198242  0.11334229 -0.06677246
   0.06768799 -0.06488037  0.04220581 -0.03521729  0.02633667  0.05783081
   0.08514404 -0.10229492  0.05419922 -0.06719971  0.02105713  0.09716797
  -0.02688599  0.04504395 -0.07794189 -0.08184814 -0.13024902  0.06738281
   0.00738907 -0.02177429 -0.15490723 -0.06390381 -0.05059814  0.05789185
   0.03363037 -0.10577393  0.12109375 -0.01086426  0.10308838  0.08813477
   0.05639648 -0.10223389 -0.11090088  0.03109741 -0.07769775  0.07617188
  -0.09112549  0.05410767 -0.04821777 -0.02984619  0.04074097  0.08752441
   0.08306885  0.00186157  0.01121521  0.04110718  0.06561279 -0.04397583
   0.11920166  0.09240723 -0.03982544 -0.03295898  0.1036377  -0.05783081
   0.07299805 -0.04446411  0.07458496  0.12988281 -0.08325195  0.03536987
   0.0241394   0.11767578  0.04327393 -0.12609863  0.02946472 -0.06414795
  -0.18017578  0.06112671  0.08276367  0.06207275  0.09967041 -0.19006348
   0.10339355 -0.11230469  0.09509277 -0.10241699  0.10150146  0.03677368
  -0.05038452 -0.11676025  0.06185913 -0.1361084   0.01106262  0.07275391
   0.05258179  0.07220459 -0.07128906 -0.05230713 -0.11956787  0.0080719
  -0.00283432 -0.17358398  0.05212402  0.10656738 -0.05670166 -0.01867676
  -0.02949524  0.09368896 -0.03945923 -0.08123779  0.03189087  0.10528564
   0.06628418  0.12200928 -0.06280518 -0.10327148  0.13256836  0.13476562
  -0.02722168  0.08935547  0.07409668  0.08001709  0.07702637 -0.00695038
   0.01577759 -0.13720703  0.1237793  -0.05487061  0.17895508 -0.01953125
   0.09222412  0.07318115 -0.09057617 -0.18725586 -0.01115417  0.0690918
   0.04733276 -0.03710938  0.12158203  0.11340332 -0.01112366  0.09143066
  -0.15002441 -0.043396   -0.04309082  0.12115479 -0.11517334 -0.03491211
   0.11175537  0.05264282  0.09039307 -0.04714966  0.10290527 -0.06738281
   0.07550049 -0.0769043   0.1050415   0.1706543   0.06652832 -0.13354492
   0.09954834 -0.01843262  0.06130981  0.04248047  0.1496582   0.06646729
   0.10888672  0.07629395 -0.07556152  0.05752563 -0.0703125   0.06408691
  -0.10748291 -0.07177734  0.0536499   0.13305664 -0.06787109  0.07904053
  -0.04968262 -0.05636597  0.0880127   0.08892822 -0.09649658 -0.01956177
   0.12213135  0.09057617  0.06567383  0.06842041 -0.03353882 -0.08868408
  -0.05358887  0.13378906  0.04766846 -0.02816772  0.04135132 -0.09381104
  -0.13342285  0.1361084   0.04284668 -0.10601807 -0.00036621 -0.12341309
   0.09082031  0.02615356  0.08892822 -0.11486816 -0.05847168 -0.02172852
  -0.08905029  0.06634521  0.02337646  0.03918457  0.04962158  0.09100342
  -0.04830933  0.12634277  0.08111572  0.00624084  0.12030029 -0.10247803
  -0.07122803 -0.12524414 -0.0402832   0.01489258 -0.06335449  0.05270386
   0.10229492 -0.1550293   0.07067871 -0.1940918  -0.16162109 -0.10028076
   0.03338623 -0.03381348 -0.0557251  -0.10455322 -0.01083374  0.14868164
  -0.05551147 -0.01733398  0.14489746  0.12768555 -0.02842712  0.12097168
   0.06311035  0.07507324 -0.1418457  -0.08929443  0.1071167  -0.07952881
   0.01417542 -0.06787109 -0.11663818  0.08691406 -0.09301758 -0.0267334
  -0.07427979 -0.07983398  0.0123291   0.09613037]]
After layer encoder_birnn_forward_l0_t1_out_0 (1, 256) <class 'numpy.float16'> [[ 0.02758789  0.0506897  -0.05154419 -0.01663208  0.05926514 -0.03540039
   0.0369873  -0.03317261  0.02275085 -0.0186615   0.01365662  0.03010559
   0.0446167  -0.05508423  0.02688599 -0.03356934  0.01108551  0.04925537
  -0.01513672  0.02366638 -0.04086304 -0.0411377  -0.0725708   0.03561401
   0.00396729 -0.01180267 -0.08532715 -0.0333252  -0.02604675  0.03120422
   0.01792908 -0.05749512  0.06280518 -0.00585175  0.05627441  0.04541016
   0.02993774 -0.05340576 -0.05621338  0.01676941 -0.04263306  0.04016113
  -0.04608154  0.02890015 -0.02552795 -0.0161438   0.02201843  0.04501343
   0.04507446  0.00097084  0.00552368  0.02168274  0.03878784 -0.0224762
   0.06185913  0.04629517 -0.02166748 -0.01678467  0.05560303 -0.03164673
   0.03768921 -0.02363586  0.03744507  0.07489014 -0.04421997  0.019104
   0.01330566  0.06222534  0.02250671 -0.06719971  0.01603699 -0.03475952
  -0.0960083   0.03179932  0.04327393  0.034729    0.05145264 -0.10595703
   0.05670166 -0.05871582  0.05056763 -0.04977417  0.06069946  0.01942444
  -0.02763367 -0.06280518  0.03256226 -0.07122803  0.00629425  0.03762817
   0.02703857  0.03726196 -0.037323   -0.02903748 -0.06384277  0.00440216
  -0.00149155 -0.09643555  0.02793884  0.06130981 -0.02937317 -0.00946045
  -0.01589966  0.05105591 -0.02095032 -0.04064941  0.01716614  0.0579834
   0.03585815  0.06512451 -0.03338623 -0.05612183  0.07159424  0.07543945
  -0.01459503  0.04598999  0.0390625   0.04336548  0.04077148 -0.00387573
   0.00832367 -0.07824707  0.06439209 -0.02934265  0.09429932 -0.01015472
   0.04760742  0.03726196 -0.04647827 -0.10314941 -0.00587845  0.03747559
   0.02435303 -0.0198822   0.06256104  0.05831909 -0.00563431  0.04824829
  -0.07873535 -0.02355957 -0.02284241  0.06048584 -0.06185913 -0.01823425
   0.05801392  0.02685547  0.04467773 -0.02516174  0.05215454 -0.03503418
   0.04016113 -0.04022217  0.05682373  0.090271    0.03549194 -0.06970215
   0.05380249 -0.00997162  0.03347778  0.02215576  0.07928467  0.03527832
   0.05615234  0.04138184 -0.04110718  0.02920532 -0.03790283  0.03363037
  -0.05599976 -0.03570557  0.02938843  0.07775879 -0.03634644  0.04452515
  -0.02462769 -0.0295105   0.04602051  0.04653931 -0.04870605 -0.01000977
   0.06347656  0.0486145   0.03561401  0.03604126 -0.01663208 -0.04702759
  -0.02815247  0.07019043  0.02539062 -0.01502228  0.0198822  -0.04797363
  -0.07348633  0.07336426  0.0218811  -0.05673218 -0.00022924 -0.06286621
   0.04968262  0.01316833  0.04519653 -0.05783081 -0.03182983 -0.01129913
  -0.0484314   0.03613281  0.01194     0.01927185  0.02445984  0.04986572
  -0.02641296  0.06439209  0.04376221  0.00348854  0.06561279 -0.05645752
  -0.03915405 -0.0647583  -0.02156067  0.00758362 -0.03305054  0.02920532
   0.05303955 -0.07818604  0.03817749 -0.10162354 -0.08270264 -0.05377197
   0.01713562 -0.01756287 -0.02946472 -0.05407715 -0.00563812  0.07672119
  -0.02960205 -0.00894928  0.0737915   0.06671143 -0.014328    0.06494141
   0.0322876   0.04251099 -0.08441162 -0.04620361  0.05618286 -0.04138184
   0.00748825 -0.03482056 -0.06280518  0.04467773 -0.04992676 -0.01421356
  -0.04055786 -0.04177856  0.00665665  0.05032349]]
After layer expand_dims1033_0 (1, 1, 256) <class 'numpy.float16'> [[[ 0.02758789  0.0506897  -0.05154419 -0.01663208  0.05926514 -0.03540039
    0.0369873  -0.03317261  0.02275085 -0.0186615   0.01365662  0.03010559
    0.0446167  -0.05508423  0.02688599 -0.03356934  0.01108551  0.04925537
   -0.01513672  0.02366638 -0.04086304 -0.0411377  -0.0725708   0.03561401
    0.00396729 -0.01180267 -0.08532715 -0.0333252  -0.02604675  0.03120422
    0.01792908 -0.05749512  0.06280518 -0.00585175  0.05627441  0.04541016
    0.02993774 -0.05340576 -0.05621338  0.01676941 -0.04263306  0.04016113
   -0.04608154  0.02890015 -0.02552795 -0.0161438   0.02201843  0.04501343
    0.04507446  0.00097084  0.00552368  0.02168274  0.03878784 -0.0224762
    0.06185913  0.04629517 -0.02166748 -0.01678467  0.05560303 -0.03164673
    0.03768921 -0.02363586  0.03744507  0.07489014 -0.04421997  0.019104
    0.01330566  0.06222534  0.02250671 -0.06719971  0.01603699 -0.03475952
   -0.0960083   0.03179932  0.04327393  0.034729    0.05145264 -0.10595703
    0.05670166 -0.05871582  0.05056763 -0.04977417  0.06069946  0.01942444
   -0.02763367 -0.06280518  0.03256226 -0.07122803  0.00629425  0.03762817
    0.02703857  0.03726196 -0.037323   -0.02903748 -0.06384277  0.00440216
   -0.00149155 -0.09643555  0.02793884  0.06130981 -0.02937317 -0.00946045
   -0.01589966  0.05105591 -0.02095032 -0.04064941  0.01716614  0.0579834
    0.03585815  0.06512451 -0.03338623 -0.05612183  0.07159424  0.07543945
   -0.01459503  0.04598999  0.0390625   0.04336548  0.04077148 -0.00387573
    0.00832367 -0.07824707  0.06439209 -0.02934265  0.09429932 -0.01015472
    0.04760742  0.03726196 -0.04647827 -0.10314941 -0.00587845  0.03747559
    0.02435303 -0.0198822   0.06256104  0.05831909 -0.00563431  0.04824829
   -0.07873535 -0.02355957 -0.02284241  0.06048584 -0.06185913 -0.01823425
    0.05801392  0.02685547  0.04467773 -0.02516174  0.05215454 -0.03503418
    0.04016113 -0.04022217  0.05682373  0.090271    0.03549194 -0.06970215
    0.05380249 -0.00997162  0.03347778  0.02215576  0.07928467  0.03527832
    0.05615234  0.04138184 -0.04110718  0.02920532 -0.03790283  0.03363037
   -0.05599976 -0.03570557  0.02938843  0.07775879 -0.03634644  0.04452515
   -0.02462769 -0.0295105   0.04602051  0.04653931 -0.04870605 -0.01000977
    0.06347656  0.0486145   0.03561401  0.03604126 -0.01663208 -0.04702759
   -0.02815247  0.07019043  0.02539062 -0.01502228  0.0198822  -0.04797363
   -0.07348633  0.07336426  0.0218811  -0.05673218 -0.00022924 -0.06286621
    0.04968262  0.01316833  0.04519653 -0.05783081 -0.03182983 -0.01129913
   -0.0484314   0.03613281  0.01194     0.01927185  0.02445984  0.04986572
   -0.02641296  0.06439209  0.04376221  0.00348854  0.06561279 -0.05645752
   -0.03915405 -0.0647583  -0.02156067  0.00758362 -0.03305054  0.02920532
    0.05303955 -0.07818604  0.03817749 -0.10162354 -0.08270264 -0.05377197
    0.01713562 -0.01756287 -0.02946472 -0.05407715 -0.00563812  0.07672119
   -0.02960205 -0.00894928  0.0737915   0.06671143 -0.014328    0.06494141
    0.0322876   0.04251099 -0.08441162 -0.04620361  0.05618286 -0.04138184
    0.00748825 -0.03482056 -0.06280518  0.04467773 -0.04992676 -0.01421356
   -0.04055786 -0.04177856  0.00665665  0.05032349]]]
After layer encoder_birnn_forward_l0_t2_i2h_output (1, 1024) <class 'numpy.float16'> [[ 0.0737915  -0.0458374   0.06152344 ...,  0.03591919  0.03396606
   0.02903748]]
After layer encoder_birnn_forward_l0_t2_h2h_output (1, 1024) <class 'numpy.float16'> [[ 0.10198975  0.08575439  0.11169434 ...,  0.1862793   0.12890625
   0.16601562]]
After layer _plus1028_0 (1, 1024) <class 'numpy.float16'> [[ 0.17578125  0.03991699  0.17321777 ...,  0.22216797  0.1628418
   0.19506836]]
After layer encoder_birnn_forward_l0_t2_slice_output0 (1, 256) <class 'numpy.float16'> [[ 0.17578125  0.03991699  0.17321777  0.02688599  0.1829834   0.1282959
   0.23937988  0.06835938 -0.01953125  0.13525391  0.11773682  0.19689941
   0.00772858  0.26977539  0.03125     0.09594727  0.06451416  0.09069824
   0.23059082  0.09008789  0.0375061  -0.02941895  0.12036133  0.12017822
   0.1427002   0.07171631  0.24755859  0.03381348  0.20617676  0.15881348
   0.07971191  0.16381836  0.33691406  0.02209473  0.32104492  0.0814209
   0.07189941  0.4050293   0.26928711 -0.01690674  0.00251007  0.18676758
   0.17626953  0.09350586  0.28271484  0.1159668   0.16943359  0.20947266
   0.13696289 -0.02923584 -0.04135132 -0.0224762   0.61279297  0.15576172
   0.32299805  0.14807129  0.18115234 -0.02963257  0.08123779 -0.11541748
   0.15136719  0.13891602  0.0836792   0.26708984  0.09643555  0.08563232
   0.20678711  0.25927734  0.18261719  0.2043457  -0.02770996 -0.04400635
   0.30444336  0.08874512  0.23339844  0.33325195  0.21411133  0.54052734
   0.15686035  0.06524658  0.14819336  0.18054199  0.24743652  0.07574463
   0.26904297  0.16918945  0.03707886  0.33056641  0.29345703  0.01902771
   0.07824707  0.01449585 -0.03692627  0.13024902  0.05822754 -0.02734375
   0.24951172  0.28979492  0.20800781  0.18041992  0.03381348 -0.05413818
   0.14880371  0.23913574  0.25488281  0.13012695  0.05718994  0.14587402
   0.00518799  0.10540771  0.32373047  0.20922852  0.46679688  0.51660156
   0.24584961  0.18725586  0.18945312  0.24023438  0.00921631  0.09954834
  -0.0082016   0.23693848  0.30395508  0.09399414  0.43847656  0.03173828
   0.16906738  0.11560059  0.17041016  0.43334961 -0.05462646  0.17529297
   0.04840088 -0.05987549  0.27783203  0.12060547  0.11517334 -0.034729
   0.23449707 -0.01539612  0.05828857  0.25244141  0.18823242  0.05020142
   0.12866211 -0.11303711  0.06628418 -0.12243652  0.18334961 -0.00379944
   0.33374023  0.22631836  0.38720703  0.25366211  0.10919189  0.1730957
   0.12316895 -0.05200195  0.19836426  0.14318848  0.41113281  0.00566101
   0.18457031  0.19140625  0.20678711  0.06616211  0.06506348  0.12744141
   0.00779724  0.14831543 -0.05047607  0.69042969  0.04840088  0.31616211
   0.19140625  0.03259277 -0.0138092  -0.11181641  0.03118896  0.06878662
   0.32421875  0.12115479  0.19433594  0.10473633 -0.03128052  0.13476562
   0.00811768  0.25488281  0.09387207  0.13513184 -0.04205322  0.12268066
   0.28833008  0.1072998   0.12304688  0.28515625  0.6796875   0.31274414
   0.11682129  0.12915039  0.07330322  0.20532227  0.14099121  0.00201416
   0.14550781  0.01602173  0.1262207  -0.08081055  0.01947021  0.10620117
   0.14941406  0.05511475  0.17211914  0.11578369  0.3762207   0.15356445
   0.10070801  0.26025391  0.09918213 -0.12231445  0.05664062  0.0592041
   0.24389648  0.16845703  0.21520996  0.48071289  0.12585449  0.09082031
   0.07440186  0.04364014 -0.0723877   0.5078125   0.01553345  0.28051758
   0.10742188  0.05419922  0.15405273 -0.03198242  0.09765625  0.24047852
   0.10577393  0.24316406  0.73193359  0.13195801  0.2578125   0.16137695
   0.10046387  0.11199951  0.20898438  0.07415771  0.41259766 -0.09020996
   0.20593262  0.10595703 -0.04156494  0.11553955]]
After layer encoder_birnn_forward_l0_t2_slice_output1 (1, 256) <class 'numpy.float16'> [[  2.68310547e-01  -3.27148438e-02   8.21533203e-02   1.48681641e-01
    9.03320312e-02   1.67236328e-01   1.69433594e-01   1.12304688e-01
    3.10302734e-01   8.86230469e-02   1.95800781e-01   6.96411133e-02
    1.49047852e-01   9.93652344e-02   6.50634766e-02   1.03393555e-01
    1.46484375e-03   9.52758789e-02   2.91015625e-01   1.51733398e-01
    1.18286133e-01   4.26635742e-02   2.83447266e-01   9.77172852e-02
    1.60400391e-01   1.29394531e-01   2.06542969e-01   1.21520996e-01
    2.17529297e-01   1.76696777e-02   1.28906250e-01   1.08276367e-01
    1.67724609e-01   1.41113281e-01   2.85400391e-01   2.08251953e-01
    1.28173828e-01   1.45874023e-02   2.58056641e-01   1.05590820e-02
    2.46215820e-01   1.19812012e-01   2.64648438e-01  -1.68609619e-02
    6.45141602e-02  -4.91943359e-02   1.92016602e-01   7.88574219e-02
    1.19018555e-01  -8.91113281e-02  -4.51965332e-02   7.90405273e-02
    6.47949219e-01  -2.18200684e-02   2.16308594e-01   5.15441895e-02
    9.79003906e-02   6.99462891e-02   9.53979492e-02   2.03613281e-01
   -2.45666504e-02   3.98864746e-02   1.51489258e-01   2.46215820e-01
    2.94799805e-02   8.30078125e-02   1.30615234e-01   2.46582031e-01
    1.24267578e-01   2.69042969e-01  -9.61303711e-02   1.32202148e-01
    3.50830078e-01   1.20544434e-01   5.91430664e-02   5.21484375e-01
    1.46972656e-01   4.03320312e-01   2.07885742e-01  -4.07714844e-02
    2.00073242e-01  -1.20605469e-01   5.80078125e-01   1.14013672e-01
    2.09472656e-01   6.59179688e-02   1.00402832e-02   3.07128906e-01
    5.37109375e-01   1.62109375e-01   8.09326172e-02   1.31835938e-01
   -3.37524414e-02   9.19189453e-02  -1.39007568e-02   2.67333984e-02
    1.82617188e-01   1.74804688e-01   2.45971680e-01   1.39282227e-01
    3.64379883e-02  -8.79516602e-02   6.05773926e-02   1.75170898e-01
    1.56616211e-01   7.15332031e-02   1.84814453e-01   1.42822266e-01
    1.33422852e-01   1.26342773e-01   1.80664062e-01   2.27050781e-01
    3.37890625e-01   4.47509766e-01   1.95312500e-01   1.14440918e-01
    2.49633789e-01   2.03002930e-01   1.16882324e-01   7.53173828e-02
    1.25000000e-01   3.33984375e-01   7.78198242e-02   1.51367188e-01
    2.91748047e-01   1.69189453e-01  -4.02221680e-02   1.06933594e-01
    8.39843750e-02   2.56347656e-01   2.14233398e-02   1.69067383e-01
    8.26416016e-02   5.90820312e-02   1.10717773e-01   2.49023438e-01
    7.09838867e-02  -7.45849609e-02   3.75732422e-01   1.52099609e-01
    1.45263672e-01   1.40869141e-01   1.92260742e-01   1.45629883e-01
    2.61840820e-02   2.31201172e-01   9.10034180e-02   1.05224609e-01
    1.57958984e-01   1.08276367e-01   2.57080078e-01   1.16516113e-01
    2.30712891e-01   2.19726562e-02   1.11328125e-01   7.98950195e-02
    2.18505859e-01   3.58886719e-02   2.25341797e-01   7.93457031e-02
    3.11767578e-01   1.26586914e-01   2.55859375e-01   1.86279297e-01
    1.92504883e-01   7.20214844e-03   4.58374023e-02   8.72802734e-02
   -2.05841064e-02   8.85009766e-02  -1.45416260e-02   4.76562500e-01
    1.42822266e-01   2.77343750e-01  -1.28173828e-02   1.18896484e-01
    5.42297363e-02   1.52465820e-01  -1.18041992e-01   1.97753906e-01
    1.42333984e-01  -6.71386719e-04   1.89331055e-01   1.16210938e-01
    9.42993164e-02   1.77734375e-01   2.87597656e-01   1.75048828e-01
    3.54003906e-02   1.62719727e-01  -2.28271484e-02   1.66015625e-01
    1.27441406e-01   1.04858398e-01   7.47680664e-02   1.60888672e-01
    8.70605469e-01  -8.36791992e-02   1.38427734e-01   1.87683105e-02
    1.71630859e-01   9.68017578e-02   6.67724609e-02   2.70996094e-01
    1.91894531e-01   1.21887207e-01   1.69921875e-01  -1.22985840e-01
    4.54711914e-02   1.30737305e-01   2.03613281e-01   8.28857422e-02
    1.36962891e-01   1.69677734e-01   3.33007812e-01   2.29492188e-01
    2.96020508e-03   2.17895508e-01   8.80737305e-02   7.64770508e-02
    4.54711914e-03   2.35839844e-01  -4.18395996e-02   1.74438477e-01
    1.01806641e-01   3.24707031e-01   1.69067383e-02   3.21044922e-02
    1.51245117e-01   4.40979004e-02   1.16271973e-01   3.80859375e-01
    2.81372070e-02   2.04223633e-01   1.89453125e-01   1.77734375e-01
   -2.02636719e-02   6.82373047e-02   1.39160156e-02   2.90771484e-01
    3.38134766e-02   2.16796875e-01   6.63085938e-01   1.96380615e-02
    3.94287109e-02   8.57543945e-03   1.11694336e-01   1.21643066e-01
    1.12426758e-01   2.15820312e-01   3.37646484e-01  -7.35473633e-02
    2.28759766e-01   2.12890625e-01   8.92333984e-02   1.65405273e-01]]
After layer encoder_birnn_forward_l0_t2_slice_output2 (1, 256) <class 'numpy.float16'> [[ 0.08831787  0.19580078 -0.29638672 -0.18115234  0.37817383 -0.00518799
   0.30517578 -0.09741211 -0.03408813 -0.09667969  0.17053223  0.19787598
   0.01153564 -0.28564453  0.07507324 -0.01490784  0.16870117  0.26806641
  -0.05239868  0.11535645 -0.14050293 -0.46191406 -0.30322266  0.14746094
  -0.15039062 -0.09631348 -0.31054688 -0.07434082 -0.22436523  0.15576172
   0.14892578 -0.07763672  0.35107422 -0.08843994  0.4128418   0.08831787
   0.14453125 -0.43359375 -0.28588867  0.13330078 -0.09844971  0.23120117
  -0.12255859  0.27587891 -0.46142578 -0.1472168   0.02850342  0.23339844
   0.15209961  0.10070801  0.06652832  0.05029297 -0.01013184 -0.24768066
   0.35375977  0.31591797 -0.32788086 -0.08343506  0.0793457  -0.02534485
   0.24169922 -0.09204102  0.08776855  0.609375   -0.18200684  0.02574158
   0.12817383  0.41210938  0.10241699 -0.17919922  0.1730957  -0.04730225
  -0.39013672  0.19458008  0.22290039  0.31420898  0.27758789 -0.5625
   0.15930176 -0.43969727  0.34692383 -0.29223633  0.01686096  0.1282959
  -0.17150879 -0.24108887  0.01635742 -0.34741211  0.07519531 -0.02069092
   0.11639404  0.13989258 -0.37719727 -0.14147949 -0.34838867 -0.00146484
  -0.22094727 -0.33251953  0.18383789  0.11022949 -0.15844727 -0.00857544
  -0.06109619  0.23059082 -0.26269531 -0.24829102  0.26806641  0.23681641
   0.23144531  0.17749023 -0.29736328 -0.20385742  0.48706055  0.38623047
  -0.20605469  0.29736328  0.16210938  0.11273193  0.16345215  0.09020996
   0.00592041 -0.2644043   0.28271484 -0.14233398  0.53955078  0.06109619
   0.41040039  0.20336914 -0.32470703 -0.30419922  0.08856201  0.30175781
   0.09838867 -0.08276367  0.30908203  0.35791016  0.03430176  0.20141602
  -0.41015625 -0.05728149 -0.06188965  0.40917969 -0.33398438 -0.09869385
   0.27124023  0.05026245  0.22631836 -0.08886719  0.35717773 -0.12200928
   0.36816406 -0.27636719  0.49609375  0.12139893  0.12585449 -0.36035156
   0.42285156 -0.08618164  0.18469238  0.17431641  0.49560547  0.19458008
   0.14575195  0.28857422 -0.15795898  0.16674805 -0.04455566  0.35913086
  -0.24780273 -0.27124023  0.1027832   0.62011719 -0.15490723  0.36376953
  -0.2199707  -0.3425293   0.08349609  0.06634521 -0.13989258 -0.04348755
   0.41235352  0.26416016  0.14990234  0.25512695 -0.03945923 -0.27001953
  -0.13220215  0.26074219  0.12310791 -0.16418457  0.29956055 -0.27099609
  -0.2434082   0.27612305  0.09503174 -0.37084961  0.03430176 -0.32250977
   0.26586914  0.00878906  0.12365723 -0.33227539 -0.35595703 -0.23400879
  -0.15551758 -0.0456543   0.26782227  0.10162354  0.12890625  0.11645508
  -0.1340332   0.20629883  0.11767578  0.1529541   0.44995117 -0.30004883
  -0.19848633 -0.30200195 -0.0994873  -0.15649414 -0.09814453  0.23291016
   0.30541992 -0.42919922  0.09039307 -0.5234375  -0.29663086 -0.15942383
   0.16552734 -0.06176758 -0.11199951 -0.46972656 -0.15380859  0.3190918
  -0.23449707  0.04534912  0.38330078  0.19128418 -0.16125488  0.45703125
   0.18835449  0.34326172 -0.46142578 -0.29492188  0.31152344 -0.20910645
   0.13012695 -0.13720703 -0.25732422  0.13708496 -0.43652344 -0.05352783
  -0.20153809 -0.23095703  0.03659058  0.20288086]]
After layer encoder_birnn_forward_l0_t2_slice_output3 (1, 256) <class 'numpy.float16'> [[ 0.26293945  0.18188477  0.18847656  0.28393555  0.13183594  0.23486328
   0.32910156  0.18920898  0.27270508  0.22216797  0.1550293   0.14343262
   0.16699219  0.14501953  0.03845215  0.13354492  0.13122559  0.2043457
   0.43041992  0.23474121  0.02246094  0.02807617  0.3137207   0.23730469
   0.21569824  0.1083374   0.27978516  0.23828125  0.00738525  0.16711426
   0.18188477  0.27270508  0.11810303  0.12597656  0.16455078  0.15783691
   0.2121582   0.12890625 -0.08099365  0.0904541   0.15917969  0.18505859
   0.08184814  0.140625    0.14379883  0.19848633  0.34008789  0.16625977
   0.16149902  0.04272461 -0.003479    0.17907715  0.64355469  0.0461731
   0.1854248  -0.05755615  0.12310791  0.08129883  0.15039062  0.17248535
   0.04626465  0.21191406  0.03012085  0.28833008  0.14562988  0.1550293
   0.30322266  0.14379883  0.12390137  0.17687988  0.22070312  0.19128418
   0.3684082   0.09832764  0.14758301  0.55859375  0.20227051  0.56494141
   0.34472656  0.13085938  0.25170898  0.00378418  0.57324219  0.12438965
   0.23950195  0.15844727  0.06481934  0.27026367  0.49145508  0.14672852
   0.12023926  0.05841064 -0.05291748  0.24914551  0.08355713  0.328125
   0.29150391  0.23022461  0.28955078  0.33398438  0.10119629  0.1394043
   0.12139893  0.2734375   0.21398926 -0.0145874   0.11865234  0.31420898
   0.2409668   0.1060791   0.28369141  0.1583252   0.48974609  0.46557617
   0.26049805  0.10217285  0.17797852  0.33837891  0.17163086  0.18591309
   0.11682129  0.34472656  0.21337891  0.14416504  0.13110352  0.20141602
   0.13098145  0.00622559  0.10583496  0.46337891  0.24072266  0.34936523
   0.08843994  0.16760254  0.10559082  0.07080078  0.23303223  0.1239624
   0.31689453  0.21142578  0.10803223  0.24414062  0.1875      0.16845703
   0.11499023  0.14685059  0.13391113  0.14111328  0.07751465  0.1875
   0.39892578  0.14929199  0.15979004  0.00863647  0.15734863  0.02488708
   0.07226562  0.14929199  0.26147461  0.24536133  0.21520996  0.18383789
   0.15527344  0.18676758  0.27246094  0.07092285  0.16210938  0.06811523
  -0.00894165  0.14196777  0.04528809  0.74609375  0.23120117  0.38818359
  -0.01502991  0.17675781  0.17211914  0.18652344  0.1081543   0.28198242
   0.19799805 -0.00632477  0.11193848  0.23937988  0.07501221  0.22705078
   0.20483398  0.07977295  0.05419922  0.18237305 -0.01112366  0.10369873
   0.34326172  0.2121582   0.07409668  0.22338867  0.75292969  0.2578125
   0.20471191  0.19812012  0.08587646  0.05291748  0.24365234  0.14379883
   0.17382812  0.26416016  0.32543945  0.00085449 -0.09606934  0.24243164
   0.20654297  0.05273438  0.18652344  0.20947266  0.48706055  0.44238281
   0.16662598  0.34521484  0.21374512  0.11340332  0.07824707  0.24780273
   0.01850891  0.18603516  0.12402344  0.18762207  0.12731934  0.11779785
   0.21948242  0.06774902  0.0055542   0.31225586  0.14111328  0.17797852
   0.23718262  0.08325195  0.00588989  0.02932739  0.09234619  0.29394531
   0.12322998  0.28466797  0.76367188 -0.08551025  0.20300293  0.13586426
   0.18847656  0.17004395  0.2010498   0.27514648  0.26098633  0.11987305
   0.30200195  0.22216797  0.1628418   0.19506836]]
After layer encoder_birnn_forward_l0_t2_o_output (1, 256) <class 'numpy.float16'> [[ 0.56542969  0.54541016  0.546875    0.5703125   0.53271484  0.55859375
   0.58154297  0.54736328  0.56787109  0.55517578  0.53857422  0.53564453
   0.54150391  0.53613281  0.50976562  0.53320312  0.53271484  0.55078125
   0.60595703  0.55859375  0.50537109  0.50683594  0.57763672  0.55908203
   0.55371094  0.52685547  0.56933594  0.55908203  0.50195312  0.54150391
   0.54541016  0.56787109  0.52929688  0.53125     0.54101562  0.53955078
   0.55273438  0.53222656  0.47973633  0.52246094  0.53955078  0.54589844
   0.52050781  0.53515625  0.53564453  0.54931641  0.58398438  0.54150391
   0.54052734  0.51074219  0.49902344  0.54443359  0.65576172  0.51171875
   0.54638672  0.4855957   0.53076172  0.52050781  0.53759766  0.54296875
   0.51171875  0.55273438  0.50732422  0.57177734  0.53613281  0.53857422
   0.57519531  0.53564453  0.53076172  0.54394531  0.55517578  0.54785156
   0.59130859  0.52441406  0.53662109  0.63623047  0.55029297  0.63769531
   0.58544922  0.53271484  0.5625      0.50097656  0.63964844  0.53125
   0.55957031  0.53955078  0.51611328  0.56738281  0.62060547  0.53662109
   0.52978516  0.51464844  0.48681641  0.56201172  0.52099609  0.58154297
   0.57226562  0.55712891  0.57177734  0.58251953  0.52539062  0.53466797
   0.53027344  0.56787109  0.55322266  0.49633789  0.52978516  0.578125
   0.56005859  0.52636719  0.5703125   0.53955078  0.62011719  0.61425781
   0.56494141  0.52539062  0.54443359  0.58398438  0.54296875  0.54638672
   0.52929688  0.58544922  0.55322266  0.53613281  0.53271484  0.55029297
   0.53271484  0.50146484  0.52636719  0.61376953  0.56005859  0.58642578
   0.52197266  0.54199219  0.52636719  0.51757812  0.55810547  0.53076172
   0.57861328  0.55273438  0.52685547  0.56054688  0.546875    0.54199219
   0.52880859  0.53662109  0.53320312  0.53515625  0.51953125  0.546875
   0.59863281  0.53710938  0.54003906  0.50195312  0.5390625   0.50634766
   0.51806641  0.53710938  0.56494141  0.56103516  0.55371094  0.54589844
   0.53857422  0.54638672  0.56787109  0.51757812  0.54052734  0.51708984
   0.49780273  0.53564453  0.51123047  0.67822266  0.55761719  0.59570312
   0.49633789  0.54394531  0.54296875  0.54638672  0.52685547  0.56982422
   0.54931641  0.49853516  0.52783203  0.55957031  0.51855469  0.55664062
   0.55126953  0.52001953  0.51367188  0.54541016  0.49731445  0.52587891
   0.58496094  0.55273438  0.51855469  0.55566406  0.6796875   0.56396484
   0.55078125  0.54931641  0.52148438  0.51318359  0.56054688  0.53564453
   0.54345703  0.56542969  0.58056641  0.5         0.47607422  0.56054688
   0.55126953  0.51318359  0.54638672  0.55224609  0.61962891  0.60888672
   0.54150391  0.58544922  0.55322266  0.52832031  0.51953125  0.56152344
   0.50439453  0.54638672  0.53076172  0.546875    0.53173828  0.52929688
   0.5546875   0.51708984  0.50146484  0.57763672  0.53515625  0.54443359
   0.55908203  0.52099609  0.50146484  0.50732422  0.52294922  0.57275391
   0.53076172  0.57080078  0.68212891  0.47851562  0.55078125  0.53369141
   0.546875    0.54248047  0.55029297  0.56835938  0.56494141  0.52978516
   0.57470703  0.55517578  0.54052734  0.54882812]]
After layer encoder_birnn_forward_l0_t2_f_output (1, 256) <class 'numpy.float16'> [[ 0.56689453  0.49194336  0.52050781  0.53710938  0.52246094  0.54150391
   0.54248047  0.52783203  0.57714844  0.52197266  0.54882812  0.51757812
   0.53710938  0.52490234  0.51611328  0.52587891  0.50048828  0.52392578
   0.57226562  0.53808594  0.52929688  0.51074219  0.5703125   0.52441406
   0.54003906  0.53222656  0.55126953  0.53027344  0.55419922  0.50439453
   0.53222656  0.52685547  0.54199219  0.53515625  0.57080078  0.55175781
   0.53222656  0.50341797  0.56396484  0.50244141  0.56103516  0.52978516
   0.56591797  0.49584961  0.51611328  0.48779297  0.54785156  0.51953125
   0.52978516  0.4777832   0.48876953  0.51953125  0.65673828  0.49462891
   0.55371094  0.51269531  0.52441406  0.51757812  0.52392578  0.55078125
   0.49389648  0.50976562  0.53759766  0.56103516  0.50732422  0.52050781
   0.53271484  0.56152344  0.53125     0.56689453  0.47607422  0.53320312
   0.58691406  0.53027344  0.51464844  0.62744141  0.53662109  0.59960938
   0.55175781  0.48974609  0.54980469  0.4699707   0.64111328  0.52832031
   0.55224609  0.51660156  0.50244141  0.57617188  0.63134766  0.54052734
   0.52001953  0.53271484  0.49145508  0.52294922  0.49658203  0.50683594
   0.54541016  0.54345703  0.56103516  0.53466797  0.50927734  0.47802734
   0.51513672  0.54345703  0.5390625   0.51806641  0.54589844  0.53564453
   0.53320312  0.53173828  0.54492188  0.55664062  0.58349609  0.60986328
   0.54882812  0.52880859  0.56201172  0.55078125  0.52929688  0.51904297
   0.53125     0.58251953  0.51953125  0.53759766  0.57226562  0.54199219
   0.48999023  0.52685547  0.52099609  0.56396484  0.50537109  0.54199219
   0.52050781  0.51464844  0.52783203  0.56201172  0.51757812  0.48144531
   0.59277344  0.53808594  0.53613281  0.53515625  0.54785156  0.53613281
   0.50634766  0.55761719  0.52294922  0.52636719  0.53955078  0.52685547
   0.56396484  0.52929688  0.55761719  0.50537109  0.52783203  0.52001953
   0.55419922  0.50878906  0.55615234  0.52001953  0.57714844  0.53173828
   0.56347656  0.54638672  0.54785156  0.50195312  0.51123047  0.52197266
   0.49487305  0.52197266  0.49633789  0.61669922  0.53564453  0.56884766
   0.49682617  0.52978516  0.51367188  0.53808594  0.47045898  0.54931641
   0.53564453  0.49975586  0.54736328  0.52880859  0.5234375   0.54443359
   0.57128906  0.54345703  0.50878906  0.54052734  0.49438477  0.54150391
   0.53173828  0.52636719  0.51855469  0.54003906  0.70507812  0.47900391
   0.53466797  0.50488281  0.54296875  0.52441406  0.51660156  0.56738281
   0.54785156  0.53027344  0.54248047  0.46923828  0.51123047  0.53271484
   0.55078125  0.52050781  0.53417969  0.54248047  0.58251953  0.55712891
   0.50097656  0.55419922  0.52197266  0.51904297  0.50097656  0.55859375
   0.48950195  0.54345703  0.52539062  0.58056641  0.50439453  0.5078125
   0.53759766  0.51123047  0.52880859  0.59423828  0.50683594  0.55078125
   0.54736328  0.54443359  0.49487305  0.51708984  0.50341797  0.57226562
   0.50830078  0.55419922  0.66015625  0.50488281  0.50976562  0.50195312
   0.52783203  0.53027344  0.52832031  0.55371094  0.58349609  0.48168945
   0.55712891  0.55322266  0.52246094  0.54101562]]
After layer _mul2056_0 (1, 256) <class 'numpy.float16'> [[ 0.03016663  0.04772949 -0.05276489 -0.0171814   0.05947876 -0.03622437
   0.03677368 -0.03427124  0.02438354 -0.01838684  0.0144577   0.02996826
   0.0458374  -0.05389404  0.02799988 -0.03540039  0.01053619  0.05105591
  -0.01538849  0.02426147 -0.04135132 -0.04190063 -0.07470703  0.03540039
   0.00399017 -0.01158905 -0.08605957 -0.03390503 -0.02806091  0.02923584
   0.01789856 -0.05593872  0.065979   -0.0058136   0.05905151  0.04876709
   0.03004456 -0.05163574 -0.06280518  0.015625   -0.04370117  0.04040527
  -0.05169678  0.02685547 -0.02490234 -0.01456451  0.02233887  0.04559326
   0.0440979   0.0008893   0.00548172  0.02137756  0.04318237 -0.02177429
   0.06628418  0.04751587 -0.02090454 -0.01705933  0.05450439 -0.03189087
   0.03610229 -0.02267456  0.04016113  0.07330322 -0.04232788  0.01841736
   0.01286316  0.06640625  0.02301025 -0.07189941  0.01403809 -0.03424072
  -0.10687256  0.03244019  0.04269409  0.03900146  0.0536499  -0.11535645
   0.05725098 -0.05523682  0.05245972 -0.04830933  0.06530762  0.0194397
  -0.02784729 -0.06060791  0.03112793 -0.07891846  0.00698471  0.03939819
   0.02737427  0.0385437  -0.03509521 -0.02738953 -0.05966187  0.00408936
  -0.00154591 -0.09533691  0.02928162  0.05722046 -0.02891541 -0.00892639
  -0.01520538  0.05108643 -0.02128601 -0.04217529  0.01741028  0.05657959
   0.03540039  0.06518555 -0.03427124 -0.05767822  0.07775879  0.08270264
  -0.01493835  0.0473938   0.04171753  0.04415894  0.04086304 -0.0036068
   0.0083847  -0.08044434  0.06463623 -0.02952576  0.10351562 -0.0105896
   0.0453186   0.03863525 -0.04730225 -0.10687256 -0.00563812  0.0375061
   0.0246582  -0.01911926  0.06451416  0.06402588 -0.00575638  0.04412842
  -0.08959961 -0.02336121 -0.02311707  0.06518555 -0.06335449 -0.01872253
   0.05682373  0.02938843  0.0473938  -0.02484131  0.0557251  -0.03555298
   0.04266357 -0.04077148  0.05877686  0.08709717  0.03518677 -0.06988525
   0.05532837 -0.00937653  0.03414917  0.02210999  0.08703613  0.03540039
   0.06158447  0.04174805 -0.04147339  0.02890015 -0.03601074  0.03347778
  -0.05340576 -0.03753662  0.0266571   0.08258057 -0.03640747  0.04507446
  -0.02470398 -0.02989197  0.04534912  0.04797363 -0.04553223 -0.01074219
   0.06573486  0.04537964  0.03601074  0.03625488 -0.01756287 -0.04840088
  -0.03065491  0.07318115  0.02426147 -0.01522827  0.02046204 -0.05096436
  -0.07141113  0.07208252  0.02223206 -0.05749512 -0.00025821 -0.05941772
   0.04867554  0.01320648  0.0484314  -0.06048584 -0.03024292 -0.0123291
  -0.04891968  0.0352478   0.01268005  0.0184021   0.02539062  0.0486145
  -0.02662659  0.06616211  0.04342651  0.00338554  0.07043457 -0.05731201
  -0.03573608 -0.06976318 -0.02104187  0.00772858 -0.0317688   0.02947998
   0.05026245 -0.0848999   0.03720093 -0.11407471 -0.08227539 -0.05111694
   0.01794434 -0.01728821 -0.02949524 -0.06234741 -0.00548935  0.08251953
  -0.03041077 -0.00943756  0.07220459  0.06640625 -0.01432037  0.06958008
   0.03210449  0.04168701 -0.09429932 -0.04519653  0.05480957 -0.04000854
   0.00748062 -0.03604126 -0.06192017  0.04824829 -0.05441284 -0.01287842
  -0.04144287 -0.04428101  0.00644302  0.05218506]]
After layer encoder_birnn_forward_l0_t2_i_output (1, 256) <class 'numpy.float16'> [[ 0.54394531  0.50976562  0.54296875  0.50683594  0.54541016  0.53222656
   0.55957031  0.51708984  0.49511719  0.53369141  0.52929688  0.54882812
   0.50195312  0.56689453  0.5078125   0.52392578  0.51611328  0.52246094
   0.55761719  0.52246094  0.50927734  0.49267578  0.53027344  0.52978516
   0.53564453  0.51806641  0.56152344  0.50830078  0.55126953  0.53955078
   0.52001953  0.54101562  0.58349609  0.50537109  0.57958984  0.52050781
   0.51806641  0.60009766  0.56689453  0.49584961  0.50048828  0.54638672
   0.54394531  0.5234375   0.5703125   0.52880859  0.54248047  0.55224609
   0.53417969  0.49267578  0.48974609  0.49438477  0.6484375   0.5390625
   0.58007812  0.53710938  0.54492188  0.49267578  0.52050781  0.47119141
   0.53759766  0.53466797  0.52099609  0.56640625  0.52392578  0.52148438
   0.55126953  0.56445312  0.54541016  0.55078125  0.49316406  0.48901367
   0.57568359  0.52197266  0.55810547  0.58251953  0.55322266  0.63183594
   0.5390625   0.51611328  0.53710938  0.54492188  0.56152344  0.51904297
   0.56689453  0.54199219  0.50927734  0.58203125  0.57275391  0.50488281
   0.51953125  0.50341797  0.49072266  0.53271484  0.51464844  0.49316406
   0.56201172  0.57177734  0.55175781  0.54492188  0.50830078  0.48657227
   0.53710938  0.55957031  0.56347656  0.53271484  0.51416016  0.53662109
   0.50146484  0.52636719  0.58007812  0.55224609  0.61474609  0.62646484
   0.56103516  0.546875    0.54736328  0.55957031  0.50244141  0.52490234
   0.49804688  0.55908203  0.57519531  0.5234375   0.60791016  0.5078125
   0.54199219  0.52880859  0.54248047  0.60644531  0.48632812  0.54394531
   0.51220703  0.48510742  0.56884766  0.53027344  0.52880859  0.49121094
   0.55859375  0.49609375  0.51464844  0.56298828  0.546875    0.51269531
   0.53222656  0.47167969  0.51660156  0.46948242  0.54589844  0.49902344
   0.58251953  0.55615234  0.59570312  0.56298828  0.52734375  0.54296875
   0.53076172  0.48706055  0.54931641  0.53564453  0.6015625   0.50146484
   0.54589844  0.54785156  0.55126953  0.51660156  0.51611328  0.53173828
   0.50195312  0.53710938  0.48730469  0.66601562  0.51220703  0.57861328
   0.54785156  0.50830078  0.49658203  0.47216797  0.5078125   0.51708984
   0.58056641  0.53027344  0.54833984  0.52636719  0.4921875   0.53369141
   0.50195312  0.56347656  0.5234375   0.53369141  0.48950195  0.53076172
   0.57177734  0.52685547  0.53076172  0.57080078  0.66357422  0.57763672
   0.52929688  0.53222656  0.51855469  0.55126953  0.53515625  0.50048828
   0.53613281  0.50390625  0.53173828  0.47973633  0.50488281  0.52636719
   0.53710938  0.51367188  0.54296875  0.52880859  0.59277344  0.53808594
   0.52539062  0.56494141  0.52490234  0.46948242  0.51416016  0.51464844
   0.56054688  0.54199219  0.55371094  0.61767578  0.53125     0.52246094
   0.51855469  0.51074219  0.48193359  0.62451172  0.50390625  0.56982422
   0.52685547  0.51367188  0.53857422  0.49194336  0.52441406  0.56005859
   0.52636719  0.56054688  0.67529297  0.53271484  0.56396484  0.54003906
   0.52490234  0.52783203  0.55224609  0.51855469  0.6015625   0.47753906
   0.55126953  0.52636719  0.48950195  0.52880859]]
After layer encoder_birnn_forward_l0_t2_c_output (1, 256) <class 'numpy.float16'> [[ 0.08807373  0.19335938 -0.28808594 -0.17919922  0.36108398 -0.00518799
   0.29614258 -0.09710693 -0.03408813 -0.09637451  0.16894531  0.1953125
   0.01153564 -0.27807617  0.07495117 -0.01490784  0.16711426  0.26171875
  -0.05233765  0.11486816 -0.13952637 -0.43164062 -0.29418945  0.1463623
  -0.14929199 -0.0960083  -0.30102539 -0.07421875 -0.22070312  0.15454102
   0.14782715 -0.07745361  0.33740234 -0.0881958   0.39086914  0.08807373
   0.14355469 -0.40820312 -0.27832031  0.13256836 -0.09814453  0.22717285
  -0.12194824  0.26904297 -0.43115234 -0.14611816  0.02848816  0.22924805
   0.15087891  0.1003418   0.06640625  0.05026245 -0.01013184 -0.24279785
   0.33959961  0.3059082  -0.31665039 -0.08325195  0.0791626  -0.02534485
   0.23706055 -0.09179688  0.08752441  0.54345703 -0.18005371  0.02574158
   0.12744141  0.39038086  0.10205078 -0.17724609  0.17138672 -0.04727173
  -0.37158203  0.19213867  0.21923828  0.30419922  0.27075195 -0.50976562
   0.15795898 -0.41333008  0.33374023 -0.28417969  0.01686096  0.12756348
  -0.1697998  -0.23657227  0.01635742 -0.33398438  0.07507324 -0.02069092
   0.11584473  0.13903809 -0.36035156 -0.14050293 -0.33496094 -0.00146484
  -0.21740723 -0.32080078  0.1817627   0.10980225 -0.15710449 -0.00857544
  -0.06103516  0.2265625  -0.25683594 -0.24328613  0.26171875  0.23254395
   0.22741699  0.17565918 -0.28881836 -0.2010498   0.4519043   0.36816406
  -0.20324707  0.28881836  0.16064453  0.11224365  0.1619873   0.08996582
   0.00592041 -0.25830078  0.27539062 -0.14135742  0.49267578  0.06103516
   0.38891602  0.20056152 -0.3137207  -0.29516602  0.08831787  0.29296875
   0.0980835  -0.08258057  0.29956055  0.34326172  0.03430176  0.19873047
  -0.38867188 -0.05722046 -0.0617981   0.38769531 -0.32202148 -0.09838867
   0.26489258  0.05023193  0.22253418 -0.08862305  0.34277344 -0.12139893
   0.35229492 -0.26953125  0.45898438  0.12078857  0.12524414 -0.34545898
   0.39941406 -0.08599854  0.18261719  0.17260742  0.45874023  0.19213867
   0.14477539  0.28076172 -0.15661621  0.16516113 -0.04452515  0.34448242
  -0.24279785 -0.26489258  0.10241699  0.55126953 -0.15368652  0.34863281
  -0.21643066 -0.32983398  0.08331299  0.06622314 -0.13903809 -0.04345703
   0.39038086  0.25830078  0.14880371  0.24975586 -0.03942871 -0.26367188
  -0.13146973  0.25488281  0.12249756 -0.16271973  0.29101562 -0.26464844
  -0.23876953  0.26928711  0.09472656 -0.35473633  0.03430176 -0.31176758
   0.25976562  0.00878906  0.12304688 -0.32055664 -0.34155273 -0.2298584
  -0.15429688 -0.04562378  0.26171875  0.10125732  0.12817383  0.11590576
  -0.13317871  0.20336914  0.11712646  0.1517334   0.421875   -0.29125977
  -0.19592285 -0.29321289 -0.09918213 -0.15527344 -0.09783936  0.22875977
   0.29638672 -0.40454102  0.09014893 -0.48046875 -0.28833008 -0.15808105
   0.1640625  -0.06167603 -0.11151123 -0.43798828 -0.15258789  0.30859375
  -0.23034668  0.0453186   0.36547852  0.18896484 -0.15991211  0.42773438
   0.18615723  0.33032227 -0.43115234 -0.28662109  0.30175781 -0.20605469
   0.12939453 -0.13635254 -0.25170898  0.13623047 -0.41064453 -0.0534668
  -0.19885254 -0.22692871  0.03656006  0.20019531]]
After layer _mul2057_0 (1, 256) <class 'numpy.float16'> [[ 0.0479126   0.09857178 -0.15637207 -0.09082031  0.19689941 -0.00276184
   0.16577148 -0.05020142 -0.01687622 -0.05142212  0.0894165   0.10717773
   0.00579071 -0.15759277  0.03805542 -0.0078125   0.08624268  0.13671875
  -0.02919006  0.06002808 -0.07104492 -0.21264648 -0.15600586  0.07751465
  -0.07995605 -0.04974365 -0.16906738 -0.03771973 -0.12164307  0.08337402
   0.07684326 -0.04190063  0.19689941 -0.04458618  0.2265625   0.0458374
   0.07434082 -0.24499512 -0.15783691  0.06573486 -0.0491333   0.12414551
  -0.06634521  0.14086914 -0.24584961 -0.07727051  0.01545715  0.12658691
   0.08056641  0.04943848  0.03253174  0.02485657 -0.00656891 -0.13085938
   0.19702148  0.16430664 -0.17260742 -0.04101562  0.04119873 -0.01194
   0.12744141 -0.04907227  0.04559326  0.30786133 -0.09436035  0.0134201
   0.07025146  0.22033691  0.05566406 -0.09759521  0.08453369 -0.02311707
  -0.21386719  0.10028076  0.12237549  0.17724609  0.14978027 -0.32202148
   0.08514404 -0.21337891  0.17919922 -0.15490723  0.00946808  0.06622314
  -0.09625244 -0.12817383  0.0083313  -0.19433594  0.04299927 -0.01044464
   0.06018066  0.07000732 -0.17687988 -0.0748291  -0.17236328 -0.00072241
  -0.12219238 -0.18347168  0.10028076  0.05984497 -0.07983398 -0.00417328
  -0.03277588  0.12683105 -0.14477539 -0.12963867  0.13452148  0.12481689
   0.11401367  0.09246826 -0.16748047 -0.11102295  0.27783203  0.23059082
  -0.11401367  0.15795898  0.08795166  0.06280518  0.08135986  0.04721069
   0.00294876 -0.14440918  0.15844727 -0.07397461  0.29956055  0.0309906
   0.21081543  0.1060791  -0.17016602 -0.17895508  0.04293823  0.15930176
   0.05023193 -0.04006958  0.17041016  0.18200684  0.0181427   0.09759521
  -0.21716309 -0.02838135 -0.03179932  0.21826172 -0.17614746 -0.05044556
   0.14099121  0.0236969   0.11499023 -0.04159546  0.18713379 -0.06057739
   0.2052002  -0.14990234  0.2734375   0.06799316  0.06604004 -0.18762207
   0.21203613 -0.04190063  0.1003418   0.09246826  0.27587891  0.09637451
   0.07904053  0.15380859 -0.08636475  0.08532715 -0.02297974  0.18322754
  -0.12188721 -0.14233398  0.04989624  0.3671875  -0.07873535  0.20178223
  -0.11859131 -0.16760254  0.04138184  0.03128052 -0.07061768 -0.0224762
   0.22668457  0.13696289  0.081604    0.13146973 -0.01940918 -0.14074707
  -0.065979    0.14367676  0.06414795 -0.08685303  0.14245605 -0.14050293
  -0.13647461  0.1418457   0.05026245 -0.20251465  0.02276611 -0.18005371
   0.13745117  0.00467682  0.06378174 -0.17675781 -0.18273926 -0.11505127
  -0.08270264 -0.022995    0.13916016  0.04858398  0.06469727  0.06100464
  -0.0715332   0.10449219  0.06359863  0.08026123  0.25       -0.15673828
  -0.10296631 -0.16564941 -0.05206299 -0.07287598 -0.05029297  0.11773682
   0.1661377  -0.21923828  0.04992676 -0.296875   -0.15319824 -0.08258057
   0.08508301 -0.03149414 -0.05374146 -0.2734375  -0.0769043   0.17590332
  -0.12133789  0.02328491  0.19677734  0.09295654 -0.0838623   0.23950195
   0.09796143  0.18518066 -0.29125977 -0.15270996  0.17016602 -0.11126709
   0.06793213 -0.07196045 -0.13903809  0.07061768 -0.24707031 -0.02552795
  -0.10961914 -0.1194458   0.01789856  0.10583496]]
After layer encoder_birnn_forward_l0_t2_state_0 (1, 256) <class 'numpy.float16'> [[ 0.07806396  0.14624023 -0.20910645 -0.10803223  0.25634766 -0.03900146
   0.20251465 -0.08447266  0.00750732 -0.06982422  0.10388184  0.13720703
   0.05163574 -0.21142578  0.06604004 -0.04321289  0.09680176  0.18774414
  -0.04458618  0.08428955 -0.11242676 -0.25463867 -0.23071289  0.11291504
  -0.07598877 -0.06134033 -0.25512695 -0.07165527 -0.1496582   0.11260986
   0.09472656 -0.09783936  0.26293945 -0.05041504  0.28564453  0.09460449
   0.10437012 -0.29663086 -0.22070312  0.08135986 -0.09283447  0.16455078
  -0.11804199  0.16772461 -0.27075195 -0.09185791  0.03778076  0.17211914
   0.12463379  0.05032349  0.0380249   0.04623413  0.03662109 -0.15258789
   0.26318359  0.21179199 -0.19348145 -0.05807495  0.09570312 -0.04382324
   0.16357422 -0.07177734  0.08575439  0.38110352 -0.13671875  0.03182983
   0.08312988  0.28662109  0.07867432 -0.16943359  0.09857178 -0.05737305
  -0.32080078  0.13269043  0.16503906  0.21630859  0.20336914 -0.4375
   0.14233398 -0.26855469  0.23168945 -0.20324707  0.07476807  0.08569336
  -0.12408447 -0.1887207   0.03945923 -0.27319336  0.04998779  0.02896118
   0.08752441  0.10852051 -0.21191406 -0.10223389 -0.23205566  0.00336647
  -0.12371826 -0.27880859  0.1295166   0.11706543 -0.10876465 -0.01309967
  -0.04797363  0.17797852 -0.16601562 -0.171875    0.15197754  0.18139648
   0.14941406  0.15771484 -0.20178223 -0.16870117  0.35546875  0.31323242
  -0.12890625  0.20532227  0.12963867  0.10693359  0.12219238  0.04360962
   0.01133728 -0.22485352  0.22314453 -0.10351562  0.40307617  0.020401
   0.25610352  0.14477539 -0.2175293  -0.28588867  0.03729248  0.19677734
   0.07489014 -0.0592041   0.23486328  0.24609375  0.01239014  0.14172363
  -0.30664062 -0.05175781 -0.05493164  0.28344727 -0.23950195 -0.06915283
   0.19775391  0.05310059  0.16235352 -0.06640625  0.24291992 -0.09613037
   0.24780273 -0.19067383  0.33227539  0.1550293   0.10119629 -0.25756836
   0.26733398 -0.05126953  0.13452148  0.11456299  0.36279297  0.13183594
   0.140625    0.19555664 -0.12780762  0.11425781 -0.05899048  0.2166748
  -0.17529297 -0.17993164  0.07653809  0.44970703 -0.1151123   0.24682617
  -0.14331055 -0.19750977  0.08673096  0.07922363 -0.1161499  -0.03320312
   0.29248047  0.18237305  0.11761475  0.16772461 -0.0369873  -0.18920898
  -0.09661865  0.21679688  0.08837891 -0.10205078  0.16296387 -0.19140625
  -0.20788574  0.21386719  0.07250977 -0.26000977  0.02250671 -0.23950195
   0.18615723  0.0178833   0.11218262 -0.23730469 -0.2130127  -0.12744141
  -0.1315918   0.01225281  0.15185547  0.0670166   0.09008789  0.10961914
  -0.09814453  0.1706543   0.10705566  0.08361816  0.3203125  -0.21411133
  -0.13867188 -0.23535156 -0.07312012 -0.06512451 -0.08203125  0.1472168
   0.21643066 -0.30419922  0.0871582  -0.41088867 -0.23547363 -0.13366699
   0.10302734 -0.04876709 -0.08325195 -0.33569336 -0.08239746  0.25830078
  -0.1517334   0.01384735  0.26904297  0.15942383 -0.09820557  0.30908203
   0.13012695  0.22680664 -0.38549805 -0.19787598  0.22497559 -0.15124512
   0.07543945 -0.10803223 -0.20092773  0.11889648 -0.30151367 -0.03839111
  -0.15112305 -0.16369629  0.02433777  0.15795898]]
After layer activation1028_output (1, 256) <class 'numpy.float16'> [[ 0.07788086  0.14526367 -0.20605469 -0.10760498  0.25097656 -0.03897095
   0.1998291  -0.08428955  0.00750732 -0.06970215  0.10351562  0.13635254
   0.05157471 -0.20837402  0.06591797 -0.04318237  0.09649658  0.18554688
  -0.04455566  0.08410645 -0.11193848 -0.24926758 -0.22668457  0.11242676
  -0.0758667  -0.06124878 -0.24975586 -0.0715332  -0.14855957  0.11212158
   0.09442139 -0.09753418  0.25708008 -0.05038452  0.27807617  0.09429932
   0.10400391 -0.28833008 -0.21716309  0.08117676 -0.09259033  0.16308594
  -0.11749268  0.1661377  -0.2644043  -0.09161377  0.03775024  0.17041016
   0.1239624   0.05029297  0.03799438  0.04620361  0.03659058 -0.15136719
   0.25732422  0.20874023 -0.19116211 -0.05801392  0.09539795 -0.04379272
   0.16210938 -0.07165527  0.08557129  0.36376953 -0.13586426  0.03182983
   0.08294678  0.27905273  0.07849121 -0.16784668  0.0982666  -0.05731201
  -0.31030273  0.13195801  0.16357422  0.2130127   0.20056152 -0.41162109
   0.14135742 -0.26220703  0.22766113 -0.20043945  0.074646    0.08551025
  -0.12347412 -0.18652344  0.03942871 -0.26660156  0.04995728  0.02894592
   0.08728027  0.10809326 -0.20874023 -0.10186768 -0.22802734  0.00336647
  -0.12310791 -0.27172852  0.12878418  0.11651611 -0.1083374  -0.01309967
  -0.04794312  0.17614746 -0.16455078 -0.17016602  0.15087891  0.17944336
   0.14831543  0.15637207 -0.19909668 -0.16711426  0.34130859  0.3034668
  -0.12817383  0.20251465  0.12890625  0.10650635  0.12158203  0.0435791
   0.01133728 -0.22119141  0.21948242 -0.10314941  0.38256836  0.020401
   0.25073242  0.14379883 -0.21411133 -0.27832031  0.03726196  0.19433594
   0.07476807 -0.05914307  0.23059082  0.24121094  0.01239014  0.14074707
  -0.29736328 -0.05169678 -0.05487061  0.27612305 -0.23498535 -0.06903076
   0.19519043  0.05303955  0.16088867 -0.06628418  0.23828125 -0.0958252
   0.24279785 -0.18835449  0.32055664  0.15380859  0.10083008 -0.25195312
   0.26123047 -0.05123901  0.13366699  0.11407471  0.34765625  0.13110352
   0.13964844  0.19311523 -0.1270752   0.11376953 -0.05892944  0.21337891
  -0.17346191 -0.17797852  0.07641602  0.42163086 -0.11462402  0.24194336
  -0.14233398 -0.19494629  0.08648682  0.07904053 -0.11560059 -0.03320312
   0.28442383  0.18041992  0.11706543  0.1661377  -0.03695679 -0.18701172
  -0.09631348  0.21350098  0.08813477 -0.10168457  0.16149902 -0.18908691
  -0.20495605  0.21069336  0.0723877  -0.25439453  0.02250671 -0.23498535
   0.18408203  0.0178833   0.11169434 -0.23291016 -0.20983887 -0.12670898
  -0.13085938  0.01225281  0.15075684  0.06689453  0.08984375  0.10919189
  -0.09783936  0.16906738  0.10662842  0.08343506  0.30981445 -0.2109375
  -0.13781738 -0.2310791  -0.07299805 -0.06500244 -0.08184814  0.14611816
   0.21313477 -0.29516602  0.08691406 -0.38916016 -0.23120117 -0.13293457
   0.10266113 -0.04873657 -0.08306885 -0.32373047 -0.08221436  0.25268555
  -0.15063477  0.01384735  0.26269531  0.15808105 -0.09790039  0.29956055
   0.12939453  0.22302246 -0.36743164 -0.1953125   0.22131348 -0.15014648
   0.07531738 -0.10760498 -0.19824219  0.11834717 -0.29272461 -0.0383606
  -0.15002441 -0.16223145  0.02433777  0.15661621]]
After layer encoder_birnn_forward_l0_t2_out_0 (1, 256) <class 'numpy.float16'> [[ 0.04403687  0.07922363 -0.1126709  -0.06137085  0.13366699 -0.02177429
   0.11621094 -0.04614258  0.00426483 -0.03869629  0.05575562  0.07305908
   0.02792358 -0.11169434  0.03359985 -0.02302551  0.0513916   0.10217285
  -0.0269928   0.04696655 -0.05657959 -0.12634277 -0.13098145  0.06286621
  -0.04202271 -0.03225708 -0.14221191 -0.03997803 -0.07458496  0.06069946
   0.05148315 -0.0553894   0.1361084  -0.02676392  0.15039062  0.0508728
   0.05749512 -0.15344238 -0.10418701  0.04241943 -0.04995728  0.08905029
  -0.06115723  0.08892822 -0.14160156 -0.05032349  0.02204895  0.09228516
   0.0670166   0.02568054  0.01896667  0.02516174  0.02400208 -0.07745361
   0.140625    0.10137939 -0.10144043 -0.03019714  0.05130005 -0.02377319
   0.08294678 -0.03961182  0.04342651  0.20800781 -0.07281494  0.01713562
   0.04769897  0.14941406  0.04165649 -0.09130859  0.05456543 -0.03140259
  -0.18347168  0.06921387  0.08776855  0.13549805  0.11035156 -0.26245117
   0.08276367 -0.13964844  0.12805176 -0.10040283  0.04776001  0.04544067
  -0.0690918  -0.10064697  0.02035522 -0.15124512  0.03100586  0.01553345
   0.04623413  0.05563354 -0.10162354 -0.05725098 -0.11877441  0.00195694
  -0.07043457 -0.15136719  0.0736084   0.06787109 -0.05691528 -0.00700378
  -0.02542114  0.10003662 -0.09100342 -0.08447266  0.07995605  0.10375977
   0.08306885  0.08233643 -0.11352539 -0.09014893  0.21166992  0.18640137
  -0.0723877   0.10638428  0.07019043  0.06219482  0.06604004  0.02380371
   0.00600052 -0.1295166   0.12139893 -0.05529785  0.20385742  0.01122284
   0.13354492  0.07208252 -0.1126709  -0.17077637  0.02087402  0.11395264
   0.03903198 -0.03204346  0.12139893  0.12481689  0.00691605  0.07470703
  -0.17211914 -0.02857971 -0.02891541  0.15478516 -0.12854004 -0.03741455
   0.10321045  0.02845764  0.08581543 -0.03546143  0.1237793  -0.05239868
   0.14538574 -0.10119629  0.1730957   0.07720947  0.05435181 -0.12756348
   0.13537598 -0.02752686  0.07550049  0.06402588  0.19250488  0.07159424
   0.07519531  0.10552979 -0.07214355  0.05889893 -0.03186035  0.11035156
  -0.08636475 -0.09533691  0.0390625   0.28588867 -0.06390381  0.14416504
  -0.07061768 -0.10601807  0.04696655  0.04318237 -0.06091309 -0.0189209
   0.15625     0.08996582  0.0617981   0.09295654 -0.01916504 -0.10412598
  -0.05310059  0.11102295  0.04525757 -0.05545044  0.08032227 -0.09942627
  -0.11987305  0.11645508  0.03753662 -0.14135742  0.01529694 -0.13256836
   0.10137939  0.00982666  0.05825806 -0.11950684 -0.11761475 -0.06787109
  -0.07110596  0.00692749  0.08752441  0.03344727  0.04278564  0.06121826
  -0.05392456  0.08679199  0.05825806  0.04608154  0.1920166  -0.12841797
  -0.074646   -0.13525391 -0.04037476 -0.03433228 -0.04251099  0.08203125
   0.10748291 -0.16125488  0.04614258 -0.21276855 -0.1229248  -0.07037354
   0.0569458  -0.02520752 -0.04165649 -0.18701172 -0.04400635  0.13757324
  -0.08422852  0.00721359  0.13171387  0.0802002  -0.0512085   0.17163086
   0.06866455  0.12731934 -0.25073242 -0.09344482  0.12188721 -0.08013916
   0.04119873 -0.05838013 -0.10906982  0.06726074 -0.16540527 -0.02032471
  -0.08624268 -0.09008789  0.01315308  0.0859375 ]]
After layer expand_dims1034_0 (1, 1, 256) <class 'numpy.float16'> [[[ 0.04403687  0.07922363 -0.1126709  -0.06137085  0.13366699 -0.02177429
    0.11621094 -0.04614258  0.00426483 -0.03869629  0.05575562  0.07305908
    0.02792358 -0.11169434  0.03359985 -0.02302551  0.0513916   0.10217285
   -0.0269928   0.04696655 -0.05657959 -0.12634277 -0.13098145  0.06286621
   -0.04202271 -0.03225708 -0.14221191 -0.03997803 -0.07458496  0.06069946
    0.05148315 -0.0553894   0.1361084  -0.02676392  0.15039062  0.0508728
    0.05749512 -0.15344238 -0.10418701  0.04241943 -0.04995728  0.08905029
   -0.06115723  0.08892822 -0.14160156 -0.05032349  0.02204895  0.09228516
    0.0670166   0.02568054  0.01896667  0.02516174  0.02400208 -0.07745361
    0.140625    0.10137939 -0.10144043 -0.03019714  0.05130005 -0.02377319
    0.08294678 -0.03961182  0.04342651  0.20800781 -0.07281494  0.01713562
    0.04769897  0.14941406  0.04165649 -0.09130859  0.05456543 -0.03140259
   -0.18347168  0.06921387  0.08776855  0.13549805  0.11035156 -0.26245117
    0.08276367 -0.13964844  0.12805176 -0.10040283  0.04776001  0.04544067
   -0.0690918  -0.10064697  0.02035522 -0.15124512  0.03100586  0.01553345
    0.04623413  0.05563354 -0.10162354 -0.05725098 -0.11877441  0.00195694
   -0.07043457 -0.15136719  0.0736084   0.06787109 -0.05691528 -0.00700378
   -0.02542114  0.10003662 -0.09100342 -0.08447266  0.07995605  0.10375977
    0.08306885  0.08233643 -0.11352539 -0.09014893  0.21166992  0.18640137
   -0.0723877   0.10638428  0.07019043  0.06219482  0.06604004  0.02380371
    0.00600052 -0.1295166   0.12139893 -0.05529785  0.20385742  0.01122284
    0.13354492  0.07208252 -0.1126709  -0.17077637  0.02087402  0.11395264
    0.03903198 -0.03204346  0.12139893  0.12481689  0.00691605  0.07470703
   -0.17211914 -0.02857971 -0.02891541  0.15478516 -0.12854004 -0.03741455
    0.10321045  0.02845764  0.08581543 -0.03546143  0.1237793  -0.05239868
    0.14538574 -0.10119629  0.1730957   0.07720947  0.05435181 -0.12756348
    0.13537598 -0.02752686  0.07550049  0.06402588  0.19250488  0.07159424
    0.07519531  0.10552979 -0.07214355  0.05889893 -0.03186035  0.11035156
   -0.08636475 -0.09533691  0.0390625   0.28588867 -0.06390381  0.14416504
   -0.07061768 -0.10601807  0.04696655  0.04318237 -0.06091309 -0.0189209
    0.15625     0.08996582  0.0617981   0.09295654 -0.01916504 -0.10412598
   -0.05310059  0.11102295  0.04525757 -0.05545044  0.08032227 -0.09942627
   -0.11987305  0.11645508  0.03753662 -0.14135742  0.01529694 -0.13256836
    0.10137939  0.00982666  0.05825806 -0.11950684 -0.11761475 -0.06787109
   -0.07110596  0.00692749  0.08752441  0.03344727  0.04278564  0.06121826
   -0.05392456  0.08679199  0.05825806  0.04608154  0.1920166  -0.12841797
   -0.074646   -0.13525391 -0.04037476 -0.03433228 -0.04251099  0.08203125
    0.10748291 -0.16125488  0.04614258 -0.21276855 -0.1229248  -0.07037354
    0.0569458  -0.02520752 -0.04165649 -0.18701172 -0.04400635  0.13757324
   -0.08422852  0.00721359  0.13171387  0.0802002  -0.0512085   0.17163086
    0.06866455  0.12731934 -0.25073242 -0.09344482  0.12188721 -0.08013916
    0.04119873 -0.05838013 -0.10906982  0.06726074 -0.16540527 -0.02032471
   -0.08624268 -0.09008789  0.01315308  0.0859375 ]]]
After layer encoder_birnn_forward_l0_t3_i2h_output (1, 1024) <class 'numpy.float16'> [[ 0.0737915  -0.0458374   0.06152344 ...,  0.03591919  0.03396606
   0.02903748]]
After layer encoder_birnn_forward_l0_t3_h2h_output (1, 1024) <class 'numpy.float16'> [[ 0.18188477  0.17785645  0.14501953 ...,  0.38305664  0.23510742
   0.33081055]]
After layer _plus1029_0 (1, 1024) <class 'numpy.float16'> [[ 0.25561523  0.13208008  0.20654297 ...,  0.41894531  0.26904297
   0.35986328]]
After layer encoder_birnn_forward_l0_t3_slice_output0 (1, 256) <class 'numpy.float16'> [[  2.55615234e-01   1.32080078e-01   2.06542969e-01   9.26513672e-02
    3.29589844e-01   2.65380859e-01   4.78027344e-01   7.98950195e-02
   -9.36279297e-02   2.12158203e-01   1.69189453e-01   2.86132812e-01
    2.72369385e-03   4.04541016e-01  -4.84619141e-02   1.18164062e-01
    1.28417969e-01   2.03857422e-01   3.60595703e-01   1.59423828e-01
    2.54669189e-02  -1.96166992e-01   2.18017578e-01   1.80664062e-01
    1.54418945e-01   9.18579102e-02   3.90625000e-01   5.13916016e-02
    3.14453125e-01   2.50732422e-01   2.09594727e-01   2.81982422e-01
    4.91943359e-01   1.27197266e-01   6.06445312e-01   6.22558594e-02
    1.22497559e-01   7.02148438e-01   4.64843750e-01  -1.01196289e-01
   -3.95507812e-02   2.62695312e-01   3.36669922e-01   1.35864258e-01
    5.49804688e-01   2.06909180e-01   2.05322266e-01   3.13232422e-01
    1.46850586e-01  -4.55932617e-02  -9.75341797e-02  -7.89184570e-02
    1.12597656e+00   1.87133789e-01   5.01464844e-01   1.51000977e-01
    3.58398438e-01  -4.16870117e-02   1.39038086e-01  -2.91259766e-01
    1.92138672e-01   2.12402344e-01   6.32324219e-02   4.50683594e-01
    9.98535156e-02   7.93457031e-02   3.05908203e-01   5.01953125e-01
    2.77832031e-01   3.96240234e-01  -5.45349121e-02  -2.22900391e-01
    6.16699219e-01   2.07031250e-01   3.09082031e-01   6.18164062e-01
    3.27880859e-01   9.28222656e-01   2.22900391e-01  -2.92968750e-03
    3.28125000e-01   2.55371094e-01   3.69140625e-01   3.03955078e-02
    4.45556641e-01   2.91503906e-01   1.07421875e-01   5.56640625e-01
    4.90722656e-01  -3.71704102e-02   1.61499023e-01  -4.33654785e-02
   -7.72094727e-02   2.23510742e-01  -4.66308594e-02  -1.52832031e-01
    4.44335938e-01   4.90478516e-01   3.76464844e-01   2.70996094e-01
    7.78808594e-02  -9.57641602e-02   2.03369141e-01   4.56542969e-01
    4.02099609e-01   1.86279297e-01   5.99365234e-02   1.86035156e-01
    2.77709961e-02   1.46728516e-01   5.07812500e-01   3.76708984e-01
    8.18847656e-01   9.54101562e-01   3.54492188e-01   3.48144531e-01
    2.69042969e-01   4.08447266e-01   6.17065430e-02   6.04858398e-02
   -5.11779785e-02   4.01855469e-01   6.05468750e-01   1.42822266e-01
    7.17285156e-01   8.09936523e-02   2.09106445e-01   1.85546875e-01
    2.00439453e-01   7.45605469e-01  -1.14929199e-01   3.15185547e-01
    1.00524902e-01   1.87988281e-02   4.11621094e-01   2.26074219e-01
    2.55615234e-01  -1.64550781e-01   3.46191406e-01  -3.54614258e-02
    4.72717285e-02   4.36035156e-01   3.12255859e-01   5.78308105e-02
    2.31689453e-01  -2.12890625e-01   5.28259277e-02  -1.94824219e-01
    3.40820312e-01  -3.14941406e-02   6.04003906e-01   3.36669922e-01
    6.16699219e-01   4.44824219e-01   1.02294922e-01   3.68652344e-01
    2.49267578e-01  -1.14746094e-01   3.95019531e-01   3.08105469e-01
    7.17773438e-01  -2.27050781e-02   3.26171875e-01   3.34716797e-01
    3.01757812e-01   7.06787109e-02   7.72705078e-02   2.21191406e-01
    6.48498535e-03   1.90307617e-01  -1.26098633e-01   1.30566406e+00
    1.34399414e-01   5.43457031e-01   3.02734375e-01   9.59472656e-02
   -4.13818359e-02  -1.86035156e-01  -6.86645508e-04   1.33544922e-01
    5.29296875e-01   2.11669922e-01   2.57324219e-01   1.51977539e-01
   -8.20922852e-02   2.26196289e-01   1.40228271e-02   4.53857422e-01
    2.29980469e-01   2.48413086e-01  -1.36230469e-01   1.45996094e-01
    5.41015625e-01   1.67724609e-01   1.99584961e-01   4.45556641e-01
    1.19140625e+00   5.02929688e-01   2.37304688e-01   1.33422852e-01
    1.39648438e-01   3.72314453e-01   2.24609375e-01   1.02111816e-01
    2.43286133e-01   6.97326660e-03   2.85644531e-01  -1.23413086e-01
   -2.67944336e-02   1.82495117e-01   2.64648438e-01   1.30126953e-01
    3.41796875e-01   1.84082031e-01   7.18750000e-01   3.10791016e-01
    1.42822266e-01   4.72656250e-01   1.92138672e-01  -1.84082031e-01
    8.58154297e-02   1.35131836e-01   3.32031250e-01   2.75634766e-01
    2.84423828e-01   9.53613281e-01   2.63183594e-01   6.27441406e-02
    8.89282227e-02   5.01708984e-02  -1.69067383e-01   9.12109375e-01
    1.08764648e-01   4.81933594e-01   2.04711914e-01   2.70843506e-02
    2.16064453e-01  -9.30786133e-02   1.39892578e-01   4.98046875e-01
    1.38549805e-01   3.73779297e-01   1.42089844e+00   2.18139648e-01
    4.31396484e-01   2.84423828e-01   1.46484375e-01   1.47705078e-01
    3.17382812e-01   1.47094727e-01   6.35742188e-01  -1.78466797e-01
    3.95019531e-01   2.07641602e-01  -9.56420898e-02   1.83227539e-01]]
After layer encoder_birnn_forward_l0_t3_slice_output1 (1, 256) <class 'numpy.float16'> [[ 0.47167969 -0.00396729  0.12060547  0.23364258  0.1541748   0.22314453
   0.39941406  0.18127441  0.63330078  0.1472168   0.40087891  0.17114258
   0.30810547  0.25683594  0.02276611  0.20874023  0.0871582   0.17077637
   0.48950195  0.2578125   0.13708496  0.00518799  0.46337891  0.15185547
   0.2824707   0.23254395  0.3269043   0.1829834   0.40112305  0.06222534
   0.31494141  0.25439453  0.23986816  0.26660156  0.50195312  0.26269531
   0.14794922  0.13354492  0.49145508  0.04067993  0.35742188  0.18908691
   0.46728516 -0.03515625  0.05401611 -0.08862305  0.44482422  0.18457031
   0.16699219 -0.1072998  -0.07855225  0.14428711  1.05664062 -0.05740356
   0.39501953 -0.00561523  0.15734863  0.16271973  0.21875     0.31567383
  -0.00262451  0.14526367  0.16357422  0.38134766  0.07617188  0.16052246
   0.26757812  0.40991211  0.1953125   0.50976562 -0.09411621  0.21960449
   0.56542969  0.22351074  0.08459473  0.90625     0.23547363  0.78710938
   0.35888672 -0.14672852  0.3605957  -0.18054199  0.9453125   0.24536133
   0.36694336  0.1706543   0.01019287  0.54345703  0.9453125   0.23266602
   0.11132812  0.22436523 -0.00919342  0.19580078 -0.05401611  0.03613281
   0.38256836  0.35375977  0.42041016  0.31811523  0.06774902 -0.12756348
   0.06494141  0.33447266  0.31640625  0.12060547  0.28320312  0.25537109
   0.22094727  0.17944336  0.33691406  0.45556641  0.60009766  0.765625
   0.30322266  0.21459961  0.45361328  0.42773438  0.20678711  0.17749023
   0.22619629  0.53808594  0.20507812  0.21020508  0.4543457   0.25805664
  -0.10272217  0.18981934  0.16235352  0.60839844  0.12561035  0.29370117
   0.10961914  0.09405518  0.18688965  0.42724609  0.21069336 -0.16711426
   0.56982422  0.296875    0.2064209   0.23291016  0.32910156  0.24743652
   0.17871094  0.41723633  0.13476562  0.20654297  0.36914062  0.24157715
   0.39990234  0.13049316  0.31103516  0.14794922  0.16516113  0.11474609
   0.40039062  0.08605957  0.46850586  0.21166992  0.50292969  0.20861816
   0.41064453  0.34643555  0.35839844  0.06848145  0.09997559  0.16491699
  -0.04071045  0.12359619 -0.06207275  0.78808594  0.22827148  0.52587891
   0.00787354  0.12408447  0.1159668   0.30151367 -0.12188721  0.37353516
   0.18139648 -0.03686523  0.36621094  0.23754883  0.16638184  0.26660156
   0.42626953  0.31640625  0.17199707  0.30322266 -0.11462402  0.25292969
   0.33422852  0.2401123   0.03869629  0.20458984  1.54882812 -0.09307861
   0.2487793  -0.00332642  0.26220703  0.22473145  0.14624023  0.49926758
   0.28344727  0.16699219  0.36254883 -0.19677734  0.04519653  0.26513672
   0.35083008  0.18518066  0.27709961  0.26806641  0.66064453  0.43334961
   0.06713867  0.36425781  0.10351562  0.07849121  0.03140259  0.36132812
  -0.06008911  0.29663086  0.17016602  0.57617188 -0.05554199  0.10192871
   0.28369141  0.12237549  0.18347168  0.66650391  0.11975098  0.31396484
   0.36987305  0.29394531  0.00628662  0.09716797  0.0836792   0.56591797
   0.0838623   0.39306641  1.32519531 -0.01828003  0.1229248  -0.01455688
   0.15625     0.18249512  0.25195312  0.34619141  0.59179688 -0.06158447
   0.4440918   0.28686523  0.15563965  0.28613281]]
After layer encoder_birnn_forward_l0_t3_slice_output2 (1, 256) <class 'numpy.float16'> [[ 0.13916016  0.28173828 -0.46582031 -0.23327637  0.63085938 -0.05853271
   0.52587891 -0.0736084  -0.11981201 -0.09643555  0.32861328  0.36743164
   0.06494141 -0.47509766  0.09991455 -0.00650024  0.28833008  0.45605469
  -0.07958984  0.20507812 -0.19299316 -0.859375   -0.62451172  0.26879883
  -0.16821289 -0.10772705 -0.54394531 -0.07415771 -0.44042969  0.28417969
   0.24853516 -0.14196777  0.53125    -0.15454102  0.78466797  0.19995117
   0.23925781 -0.80957031 -0.54589844  0.11077881 -0.09130859  0.52929688
  -0.13891602  0.48925781 -0.91845703 -0.26245117 -0.00123596  0.34643555
   0.28442383  0.18310547  0.04138184  0.02536011 -0.18432617 -0.34277344
   0.65136719  0.48828125 -0.66064453 -0.11877441  0.24755859 -0.02993774
   0.45117188 -0.12792969  0.11120605  1.15429688 -0.35595703  0.06439209
   0.27246094  0.67333984  0.19396973 -0.41796875  0.29833984  0.00170898
  -0.75732422  0.25634766  0.39355469  0.61376953  0.51367188 -1.06054688
   0.32250977 -0.72753906  0.66259766 -0.44750977 -0.02520752  0.14196777
  -0.25756836 -0.47558594  0.05993652 -0.64404297  0.11425781 -0.04434204
   0.27148438  0.22412109 -0.63671875 -0.20898438 -0.79345703 -0.16931152
  -0.36450195 -0.70654297  0.32739258  0.14501953 -0.32592773 -0.03823853
  -0.04818726  0.38818359 -0.38256836 -0.47802734  0.37255859  0.31811523
   0.32421875  0.3059082  -0.55957031 -0.46166992  0.94482422  0.80029297
  -0.23144531  0.53515625  0.27905273  0.13562012  0.24853516  0.11737061
   0.02566528 -0.44360352  0.51269531 -0.22961426  1.00292969 -0.00457764
   0.73876953  0.33862305 -0.5859375  -0.69091797  0.14648438  0.4621582
   0.18383789 -0.12939453  0.55957031  0.64990234  0.14111328  0.375
  -0.73974609 -0.16015625 -0.05407715  0.74609375 -0.64111328 -0.11639404
   0.52783203  0.01309967  0.40625    -0.07922363  0.7265625  -0.15234375
   0.72265625 -0.42578125  0.89648438  0.32836914  0.16748047 -0.68798828
   0.77099609 -0.09869385  0.3840332   0.3815918   1.03417969  0.17456055
   0.20874023  0.53222656 -0.17272949  0.2043457  -0.03643799  0.63720703
  -0.39233398 -0.39086914  0.14465332  1.16210938 -0.22570801  0.77636719
  -0.3972168  -0.6640625   0.09924316  0.09484863 -0.27001953 -0.08703613
   0.73095703  0.50488281  0.27270508  0.3828125  -0.03305054 -0.45068359
  -0.23706055  0.56445312  0.25073242 -0.28295898  0.62988281 -0.44995117
  -0.45532227  0.56689453  0.16186523 -0.69433594 -0.04522705 -0.60009766
   0.44921875 -0.04934692  0.09362793 -0.52587891 -0.70800781 -0.34423828
  -0.18212891 -0.10107422  0.54101562  0.10974121  0.20068359  0.12329102
  -0.19128418  0.32836914  0.24523926  0.23632812  0.875      -0.55371094
  -0.33056641 -0.59912109 -0.1817627  -0.25341797 -0.18981934  0.35424805
   0.54199219 -0.78515625  0.17260742 -0.96679688 -0.54394531 -0.22302246
   0.25463867 -0.03662109 -0.21020508 -0.81689453 -0.21289062  0.62255859
  -0.38085938  0.01939392  0.63916016  0.31030273 -0.16101074  0.96582031
   0.40234375  0.56445312 -1.00683594 -0.60253906  0.58642578 -0.35693359
   0.21630859 -0.18066406 -0.46508789  0.28588867 -0.71533203 -0.105896
  -0.32299805 -0.34790039  0.00196838  0.26147461]]
After layer encoder_birnn_forward_l0_t3_slice_output3 (1, 256) <class 'numpy.float16'> [[  4.30908203e-01   2.84423828e-01   3.40576172e-01   4.24804688e-01
    2.61962891e-01   3.85253906e-01   6.47460938e-01   2.75146484e-01
    3.88427734e-01   3.59375000e-01   2.64648438e-01   3.07128906e-01
    2.57812500e-01   3.86230469e-01  -3.96728516e-03   1.63818359e-01
    3.21533203e-01   2.40478516e-01   7.02636719e-01   4.03320312e-01
    1.18774414e-01   2.13928223e-02   5.78125000e-01   4.02099609e-01
    3.26171875e-01   1.59301758e-01   5.07324219e-01   3.74755859e-01
    4.81872559e-02   2.60498047e-01   3.54736328e-01   4.53125000e-01
    1.22070312e-01   2.38037109e-01   2.67333984e-01   2.23144531e-01
    3.46679688e-01   1.55273438e-01  -1.71142578e-01   1.77856445e-01
    2.67822266e-01   2.84423828e-01   1.88720703e-01   2.64404297e-01
    2.64404297e-01   3.31542969e-01   6.73339844e-01   3.28369141e-01
    2.72216797e-01   7.91015625e-02  -6.88476562e-02   3.26171875e-01
    1.16406250e+00   2.14843750e-02   3.35205078e-01  -6.66503906e-02
    1.92871094e-01   2.07763672e-01   3.02490234e-01   2.99316406e-01
    1.94702148e-02   3.12500000e-01   4.59289551e-02   4.75341797e-01
    1.90429688e-01   2.85888672e-01   4.83886719e-01   2.18750000e-01
    2.58544922e-01   2.55371094e-01   3.77197266e-01   3.34716797e-01
    6.53320312e-01   2.31445312e-01   2.37304688e-01   9.97070312e-01
    3.28369141e-01   1.02832031e+00   5.44921875e-01   1.63818359e-01
    4.82910156e-01  -3.36303711e-02   1.12402344e+00   2.53173828e-01
    4.57031250e-01   2.36572266e-01   1.33178711e-01   4.12353516e-01
    8.38378906e-01   3.26171875e-01   2.21679688e-01   1.78710938e-01
   -1.29028320e-01   4.70947266e-01   9.75952148e-02   5.22949219e-01
    4.30908203e-01   4.15039062e-01   4.51660156e-01   5.80078125e-01
    1.54418945e-01   2.33764648e-01   1.53686523e-01   5.15136719e-01
    4.07958984e-01   4.95605469e-02   2.31445312e-01   4.82177734e-01
    4.21875000e-01   1.55761719e-01   5.06835938e-01   2.86865234e-01
    8.44726562e-01   7.76367188e-01   4.22851562e-01   2.61718750e-01
    3.30078125e-01   6.22558594e-01   3.17871094e-01   3.56689453e-01
    2.47558594e-01   6.12304688e-01   3.48388672e-01   2.66113281e-01
    3.36181641e-01   3.81835938e-01   1.28540039e-01   1.35498047e-02
    2.11181641e-01   8.62304688e-01   3.90869141e-01   5.96679688e-01
    1.84814453e-01   2.86865234e-01   1.87377930e-01   1.29272461e-01
    3.95996094e-01   2.37915039e-01   5.45898438e-01   3.21533203e-01
    1.61621094e-01   3.49609375e-01   3.08349609e-01   3.11767578e-01
    1.92626953e-01   3.01025391e-01   2.24121094e-01   2.33032227e-01
    8.32519531e-02   2.42675781e-01   6.98242188e-01   1.92626953e-01
    3.23486328e-01  -1.07421875e-02   1.92382812e-01   3.75366211e-03
    1.53930664e-01   2.45239258e-01   5.28320312e-01   3.77441406e-01
    3.40332031e-01   3.35205078e-01   1.81152344e-01   3.46679688e-01
    5.10742188e-01   1.33056641e-01   3.01269531e-01   1.41723633e-01
   -3.49121094e-02   2.05200195e-01   1.49536133e-01   1.32617188e+00
    4.00634766e-01   6.23535156e-01  -1.63269043e-02   1.93359375e-01
    2.82958984e-01   3.47412109e-01   1.89697266e-01   4.59960938e-01
    2.98583984e-01  -3.81469727e-02   2.76611328e-01   4.02343750e-01
    1.66503906e-01   3.75488281e-01   3.23486328e-01   1.52709961e-01
    2.41088867e-01   4.15527344e-01  -1.79595947e-02   2.40478516e-01
    5.92285156e-01   3.36669922e-01   9.50927734e-02   3.84033203e-01
    1.37792969e+00   3.44726562e-01   3.43505859e-01   3.37402344e-01
    1.56250000e-01   7.55615234e-02   3.95751953e-01   3.74023438e-01
    3.39111328e-01   4.54589844e-01   5.28320312e-01   3.62548828e-02
   -1.68457031e-01   3.65478516e-01   3.64013672e-01   1.38305664e-01
    4.03320312e-01   3.84765625e-01   8.99902344e-01   6.80175781e-01
    2.56835938e-01   5.92285156e-01   3.94531250e-01   2.00683594e-01
    2.01660156e-01   4.18701172e-01   2.40020752e-02   2.39013672e-01
    2.96875000e-01   2.43652344e-01   2.77099609e-01   2.60742188e-01
    3.63037109e-01   1.24145508e-01   6.61621094e-02   5.57617188e-01
    2.96630859e-01   3.50097656e-01   4.18945312e-01   1.66870117e-01
    2.72827148e-02  -2.74658203e-04   2.18017578e-01   6.20117188e-01
    1.45996094e-01   4.71435547e-01   1.51953125e+00  -3.88793945e-02
    3.14941406e-01   1.73828125e-01   3.27636719e-01   3.04199219e-01
    4.21630859e-01   4.62158203e-01   5.16601562e-01   1.75781250e-01
    5.33691406e-01   4.18945312e-01   2.69042969e-01   3.59863281e-01]]
After layer encoder_birnn_forward_l0_t3_o_output (1, 256) <class 'numpy.float16'> [[ 0.60595703  0.57080078  0.58447266  0.60449219  0.56494141  0.59521484
   0.65625     0.56835938  0.59570312  0.58886719  0.56591797  0.57617188
   0.56396484  0.59521484  0.49902344  0.54101562  0.57958984  0.56005859
   0.66894531  0.59960938  0.52978516  0.50537109  0.640625    0.59912109
   0.58105469  0.53955078  0.62402344  0.59277344  0.51220703  0.56494141
   0.58789062  0.61132812  0.53027344  0.55908203  0.56640625  0.55566406
   0.5859375   0.53857422  0.45727539  0.54443359  0.56640625  0.57080078
   0.546875    0.56591797  0.56591797  0.58203125  0.66210938  0.58154297
   0.56787109  0.51953125  0.48291016  0.58105469  0.76220703  0.50537109
   0.58300781  0.48339844  0.54785156  0.55175781  0.57519531  0.57421875
   0.50488281  0.57763672  0.51171875  0.61669922  0.54736328  0.57080078
   0.61865234  0.5546875   0.56445312  0.56347656  0.59326172  0.58300781
   0.65771484  0.55761719  0.55908203  0.73046875  0.58154297  0.73681641
   0.6328125   0.54101562  0.61865234  0.49169922  0.75488281  0.56298828
   0.61230469  0.55908203  0.53320312  0.6015625   0.69824219  0.58105469
   0.55517578  0.54443359  0.46777344  0.61572266  0.52441406  0.62792969
   0.60595703  0.60253906  0.61083984  0.64111328  0.53857422  0.55810547
   0.53857422  0.62597656  0.60058594  0.51220703  0.55761719  0.61816406
   0.60400391  0.5390625   0.62402344  0.57128906  0.69921875  0.68505859
   0.60400391  0.56494141  0.58154297  0.65087891  0.57861328  0.58837891
   0.56152344  0.6484375   0.58642578  0.56591797  0.58349609  0.59423828
   0.53222656  0.50341797  0.55273438  0.703125    0.59667969  0.64501953
   0.54589844  0.57128906  0.546875    0.53222656  0.59765625  0.55908203
   0.63330078  0.57958984  0.54052734  0.58642578  0.57666016  0.57714844
   0.54785156  0.57470703  0.55566406  0.55810547  0.52099609  0.56054688
   0.66796875  0.54785156  0.58007812  0.49731445  0.54785156  0.50097656
   0.53857422  0.56103516  0.62890625  0.59326172  0.58447266  0.58300781
   0.54492188  0.5859375   0.625       0.53320312  0.57470703  0.53515625
   0.49121094  0.55126953  0.53710938  0.79003906  0.59863281  0.65087891
   0.49584961  0.54833984  0.5703125   0.5859375   0.54736328  0.61279297
   0.57421875  0.49047852  0.56884766  0.59912109  0.54150391  0.59277344
   0.58007812  0.53808594  0.56005859  0.60253906  0.49560547  0.56005859
   0.64404297  0.58349609  0.52392578  0.59472656  0.79882812  0.58544922
   0.58496094  0.58349609  0.5390625   0.51904297  0.59765625  0.59228516
   0.58398438  0.61181641  0.62890625  0.50927734  0.45800781  0.59033203
   0.58984375  0.53466797  0.59960938  0.59521484  0.7109375   0.66357422
   0.56396484  0.64404297  0.59716797  0.54980469  0.55029297  0.60302734
   0.50585938  0.55957031  0.57373047  0.56054688  0.56884766  0.56494141
   0.58984375  0.53076172  0.51660156  0.63574219  0.57373047  0.58642578
   0.60302734  0.54150391  0.50683594  0.5         0.55419922  0.65039062
   0.53662109  0.61572266  0.8203125   0.49023438  0.578125    0.54345703
   0.58105469  0.57568359  0.60400391  0.61376953  0.62646484  0.54394531
   0.63037109  0.60302734  0.56689453  0.58886719]]
After layer encoder_birnn_forward_l0_t3_f_output (1, 256) <class 'numpy.float16'> [[ 0.61572266  0.49902344  0.53027344  0.55810547  0.53857422  0.55566406
   0.59863281  0.54541016  0.65332031  0.53662109  0.59912109  0.54248047
   0.57666016  0.56396484  0.50585938  0.55175781  0.52197266  0.54248047
   0.62011719  0.56396484  0.53417969  0.50146484  0.61376953  0.53808594
   0.5703125   0.55810547  0.58105469  0.54541016  0.59912109  0.515625
   0.578125    0.56347656  0.55957031  0.56640625  0.62304688  0.56542969
   0.53710938  0.53320312  0.62060547  0.51025391  0.58837891  0.54736328
   0.61474609  0.49121094  0.51367188  0.4777832   0.609375    0.54589844
   0.54150391  0.47314453  0.48046875  0.53613281  0.7421875   0.4855957
   0.59765625  0.49853516  0.5390625   0.54052734  0.5546875   0.578125
   0.49926758  0.53613281  0.54101562  0.59423828  0.51904297  0.54003906
   0.56640625  0.60107422  0.54882812  0.62451172  0.4765625   0.5546875
   0.63769531  0.55566406  0.52099609  0.71240234  0.55859375  0.68701172
   0.58886719  0.46337891  0.58935547  0.45507812  0.72021484  0.56103516
   0.59082031  0.54248047  0.50244141  0.6328125   0.72021484  0.55810547
   0.52783203  0.55566406  0.49780273  0.54882812  0.48657227  0.50878906
   0.59472656  0.58740234  0.60351562  0.57910156  0.51708984  0.46826172
   0.51611328  0.58300781  0.57861328  0.53027344  0.5703125   0.56347656
   0.55517578  0.54492188  0.58349609  0.61181641  0.64550781  0.68261719
   0.57519531  0.55322266  0.61132812  0.60546875  0.55126953  0.54443359
   0.55615234  0.63134766  0.55126953  0.55224609  0.61181641  0.56396484
   0.47436523  0.54736328  0.54052734  0.64746094  0.53125     0.57275391
   0.52734375  0.5234375   0.54638672  0.60498047  0.55224609  0.45825195
   0.63867188  0.57373047  0.55126953  0.55810547  0.58154297  0.56152344
   0.54443359  0.60302734  0.53369141  0.55126953  0.59130859  0.56005859
   0.59863281  0.53271484  0.57714844  0.53710938  0.54101562  0.52880859
   0.59863281  0.52148438  0.61523438  0.55273438  0.62304688  0.55175781
   0.60107422  0.5859375   0.58886719  0.51708984  0.52490234  0.54101562
   0.48974609  0.53076172  0.484375    0.6875      0.55664062  0.62841797
   0.50195312  0.53076172  0.52880859  0.57470703  0.46948242  0.59228516
   0.54541016  0.49072266  0.59033203  0.55908203  0.54150391  0.56640625
   0.60498047  0.57861328  0.54296875  0.57519531  0.47143555  0.56298828
   0.58300781  0.55957031  0.50976562  0.55078125  0.82470703  0.47680664
   0.56201172  0.49926758  0.56494141  0.55615234  0.53662109  0.62207031
   0.5703125   0.54150391  0.58984375  0.45092773  0.51123047  0.56591797
   0.58691406  0.54638672  0.56884766  0.56640625  0.65917969  0.60644531
   0.51660156  0.58984375  0.52587891  0.51953125  0.5078125   0.58935547
   0.48486328  0.57373047  0.54248047  0.64013672  0.48608398  0.52539062
   0.5703125   0.53076172  0.54589844  0.66064453  0.52978516  0.57763672
   0.59130859  0.57275391  0.50146484  0.52441406  0.52099609  0.63769531
   0.52099609  0.59716797  0.79003906  0.49536133  0.53076172  0.49633789
   0.5390625   0.54541016  0.5625      0.5859375   0.64355469  0.48461914
   0.609375    0.57128906  0.5390625   0.57128906]]
After layer _mul2058_0 (1, 256) <class 'numpy.float16'> [[ 0.04806519  0.07299805 -0.11090088 -0.06030273  0.13806152 -0.02166748
   0.12121582 -0.04608154  0.0049057  -0.03747559  0.06222534  0.07440186
   0.0297699  -0.1192627   0.03341675 -0.02384949  0.05053711  0.10186768
  -0.02764893  0.04754639 -0.06005859 -0.12768555 -0.14160156  0.0607605
  -0.04333496 -0.03424072 -0.14819336 -0.03909302 -0.08966064  0.05807495
   0.05474854 -0.05514526  0.14709473 -0.02854919  0.17797852  0.05349731
   0.05606079 -0.15820312 -0.13696289  0.04150391 -0.05462646  0.09008789
  -0.0725708   0.08239746 -0.13903809 -0.04388428  0.02302551  0.09393311
   0.06750488  0.02380371  0.01826477  0.02478027  0.0271759  -0.07409668
   0.15734863  0.10559082 -0.10430908 -0.03140259  0.05310059 -0.02532959
   0.08166504 -0.03848267  0.04638672  0.22644043 -0.07098389  0.01719666
   0.04708862  0.17224121  0.04318237 -0.10583496  0.04696655 -0.03182983
  -0.20458984  0.07373047  0.08599854  0.15405273  0.11358643 -0.30053711
   0.08380127 -0.12445068  0.13659668 -0.09246826  0.05386353  0.04806519
  -0.07330322 -0.10235596  0.01982117 -0.17285156  0.03601074  0.01615906
   0.04620361  0.06030273 -0.10546875 -0.05612183 -0.11291504  0.0017128
  -0.0736084  -0.16381836  0.07818604  0.06781006 -0.0562439  -0.00613403
  -0.02476501  0.10375977 -0.09606934 -0.09112549  0.08666992  0.10223389
   0.08294678  0.0859375  -0.11773682 -0.10321045  0.22949219  0.21386719
  -0.07415771  0.11358643  0.07922363  0.0647583   0.06738281  0.02374268
   0.00630569 -0.14196777  0.12298584 -0.05715942  0.24658203  0.01150513
   0.12145996  0.07922363 -0.11755371 -0.18505859  0.01980591  0.11273193
   0.03948975 -0.0309906   0.1282959   0.14892578  0.00684357  0.06494141
  -0.19580078 -0.0296936  -0.0302887   0.15820312 -0.13928223 -0.03881836
   0.10766602  0.03201294  0.08666992 -0.03662109  0.14367676 -0.05383301
   0.14831543 -0.1015625   0.19177246  0.08325195  0.05474854 -0.13623047
   0.16003418 -0.0267334   0.08276367  0.06329346  0.22607422  0.07275391
   0.08453369  0.11456299 -0.07525635  0.05908203 -0.03096008  0.11724854
  -0.08587646 -0.09552002  0.03707886  0.30908203 -0.06408691  0.15515137
  -0.07196045 -0.1048584   0.04586792  0.04553223 -0.05453491 -0.01966858
   0.1595459   0.08947754  0.06945801  0.09375    -0.02003479 -0.10717773
  -0.05844116  0.12548828  0.04797363 -0.0586853   0.07684326 -0.10778809
  -0.12121582  0.11968994  0.03695679 -0.14318848  0.01855469 -0.11419678
   0.10461426  0.00892639  0.06335449 -0.13195801 -0.11431885 -0.07928467
  -0.07507324  0.00663376  0.08959961  0.0302124   0.04605103  0.06204224
  -0.05761719  0.09326172  0.06091309  0.04736328  0.21118164 -0.12988281
  -0.07165527 -0.13879395 -0.03845215 -0.03384399 -0.04165649  0.08679199
   0.10491943 -0.17456055  0.04727173 -0.26293945 -0.11444092 -0.07025146
   0.05874634 -0.02587891 -0.04544067 -0.22180176 -0.04364014  0.14916992
  -0.08972168  0.00793457  0.1348877   0.08361816 -0.05117798  0.19714355
   0.06781006  0.13549805 -0.30444336 -0.09802246  0.11938477 -0.07507324
   0.04067993 -0.05892944 -0.11303711  0.06964111 -0.1940918  -0.01860046
  -0.09210205 -0.09350586  0.01312256  0.09020996]]
After layer encoder_birnn_forward_l0_t3_i_output (1, 256) <class 'numpy.float16'> [[ 0.56347656  0.53320312  0.55126953  0.52294922  0.58154297  0.56591797
   0.6171875   0.52001953  0.4765625   0.55273438  0.54199219  0.57128906
   0.50048828  0.59960938  0.48779297  0.52929688  0.53222656  0.55078125
   0.58935547  0.53955078  0.50634766  0.45117188  0.55419922  0.54492188
   0.53857422  0.52294922  0.59619141  0.51269531  0.578125    0.5625
   0.55224609  0.56982422  0.62060547  0.53173828  0.64697266  0.515625
   0.53076172  0.66845703  0.61425781  0.47460938  0.49023438  0.56542969
   0.58349609  0.53369141  0.63427734  0.55175781  0.55126953  0.57763672
   0.53662109  0.48852539  0.47558594  0.48022461  0.75488281  0.546875
   0.62304688  0.53759766  0.58886719  0.48950195  0.53466797  0.42773438
   0.54785156  0.55273438  0.515625    0.61083984  0.52490234  0.52001953
   0.57568359  0.62304688  0.56884766  0.59765625  0.48632812  0.44458008
   0.64941406  0.55175781  0.57666016  0.64990234  0.58105469  0.71679688
   0.55566406  0.49926758  0.58154297  0.56347656  0.59130859  0.5078125
   0.609375    0.57226562  0.52685547  0.63574219  0.62011719  0.49072266
   0.54052734  0.48925781  0.48071289  0.55566406  0.48828125  0.46191406
   0.609375    0.62011719  0.59326172  0.56738281  0.51953125  0.47607422
   0.55078125  0.61230469  0.59912109  0.54638672  0.51513672  0.54638672
   0.50683594  0.53662109  0.62451172  0.59326172  0.69384766  0.72216797
   0.58789062  0.5859375   0.56689453  0.60058594  0.515625    0.51513672
   0.48730469  0.59912109  0.64697266  0.53564453  0.671875    0.52001953
   0.55224609  0.54638672  0.54980469  0.67822266  0.47119141  0.578125
   0.52490234  0.50488281  0.6015625   0.55615234  0.56347656  0.45898438
   0.5859375   0.49121094  0.51171875  0.60742188  0.57763672  0.51464844
   0.55761719  0.44702148  0.51318359  0.45141602  0.58447266  0.4921875
   0.64648438  0.58349609  0.64941406  0.609375    0.52539062  0.59130859
   0.56201172  0.47143555  0.59765625  0.57666016  0.671875    0.49438477
   0.58105469  0.58300781  0.57470703  0.51757812  0.51953125  0.55517578
   0.50146484  0.54736328  0.46850586  0.78662109  0.53369141  0.6328125
   0.57519531  0.52392578  0.48974609  0.45361328  0.49975586  0.53320312
   0.62939453  0.55273438  0.56396484  0.53808594  0.47949219  0.55615234
   0.50341797  0.61132812  0.55712891  0.56201172  0.46606445  0.53662109
   0.63183594  0.54199219  0.54980469  0.609375    0.76708984  0.62304688
   0.55908203  0.53320312  0.53466797  0.59179688  0.55615234  0.52539062
   0.56054688  0.50195312  0.57080078  0.46923828  0.4934082   0.54541016
   0.56591797  0.53271484  0.58447266  0.54589844  0.67236328  0.57714844
   0.53564453  0.61621094  0.54785156  0.45410156  0.52148438  0.53369141
   0.58203125  0.56835938  0.57080078  0.72167969  0.56542969  0.515625
   0.52246094  0.51269531  0.45776367  0.71337891  0.52734375  0.61816406
   0.55078125  0.50683594  0.55371094  0.47680664  0.53515625  0.62207031
   0.53466797  0.59228516  0.80566406  0.55419922  0.60644531  0.57080078
   0.53662109  0.53662109  0.57861328  0.53662109  0.65380859  0.45556641
   0.59765625  0.55175781  0.47607422  0.54589844]]
After layer encoder_birnn_forward_l0_t3_c_output (1, 256) <class 'numpy.float16'> [[ 0.13830566  0.27441406 -0.43481445 -0.22912598  0.55859375 -0.05847168
   0.48217773 -0.07348633 -0.1192627  -0.09613037  0.31738281  0.35180664
   0.06488037 -0.44238281  0.09960938 -0.00650024  0.28051758  0.42675781
  -0.07940674  0.20227051 -0.19067383 -0.69580078 -0.55419922  0.26245117
  -0.16662598 -0.1072998  -0.49584961 -0.07403564 -0.4140625   0.27685547
   0.24353027 -0.14099121  0.48632812 -0.15332031  0.65527344  0.1973877
   0.23474121 -0.66943359 -0.49755859  0.11035156 -0.09106445  0.48486328
  -0.13806152  0.45361328 -0.72509766 -0.2565918  -0.00123596  0.33325195
   0.27709961  0.18103027  0.04135132  0.02536011 -0.18225098 -0.32983398
   0.57275391  0.45288086 -0.57861328 -0.1182251   0.24267578 -0.02992249
   0.42285156 -0.12719727  0.11077881  0.81933594 -0.34155273  0.06433105
   0.26586914  0.58740234  0.19152832 -0.39526367  0.28979492  0.00170898
  -0.63964844  0.25097656  0.37451172  0.546875    0.47290039 -0.78564453
   0.31176758 -0.62158203  0.58007812 -0.41992188 -0.02520752  0.14099121
  -0.25195312 -0.44262695  0.05987549 -0.56787109  0.11376953 -0.04431152
   0.26489258  0.22045898 -0.5625     -0.20605469 -0.66015625 -0.16772461
  -0.34912109 -0.60839844  0.31616211  0.14404297 -0.31494141 -0.03820801
  -0.04815674  0.36987305 -0.36499023 -0.44458008  0.35620117  0.30786133
   0.31323242  0.29663086 -0.5078125  -0.43139648  0.73730469  0.6640625
  -0.22741699  0.48925781  0.27197266  0.13476562  0.24353027  0.11682129
   0.02566528 -0.41674805  0.47192383 -0.22570801  0.76269531 -0.00457764
   0.62841797  0.32617188 -0.52685547 -0.59863281  0.14538574  0.43188477
   0.1817627  -0.12866211  0.5078125   0.57177734  0.14013672  0.35839844
  -0.62890625 -0.15881348 -0.05401611  0.6328125  -0.56542969 -0.11584473
   0.48364258  0.01309967  0.38525391 -0.07904053  0.62109375 -0.15112305
   0.61865234 -0.40185547  0.71435547  0.31713867  0.16589355 -0.59667969
   0.64746094 -0.09838867  0.36621094  0.36401367  0.77539062  0.17285156
   0.20581055  0.48706055 -0.17102051  0.20153809 -0.03640747  0.56298828
  -0.37329102 -0.37207031  0.14367676  0.82177734 -0.22192383  0.65039062
  -0.37768555 -0.58105469  0.09893799  0.09454346 -0.26367188 -0.08679199
   0.62353516  0.46606445  0.26611328  0.36523438 -0.03305054 -0.42236328
  -0.23266602  0.51123047  0.24560547 -0.27563477  0.55810547 -0.421875
  -0.42626953  0.51318359  0.16052246 -0.60058594 -0.04519653 -0.53710938
   0.42114258 -0.04931641  0.09338379 -0.48217773 -0.609375   -0.33129883
  -0.18017578 -0.10070801  0.49365234  0.10931396  0.19799805  0.12268066
  -0.18896484  0.31713867  0.24047852  0.23205566  0.70410156 -0.50341797
  -0.3190918  -0.53662109 -0.17980957 -0.24816895 -0.18762207  0.34008789
   0.49438477 -0.65576172  0.17089844 -0.74707031 -0.49584961 -0.21936035
   0.24926758 -0.03659058 -0.20715332 -0.67333984 -0.2097168   0.55273438
  -0.36352539  0.01939392  0.56445312  0.30078125 -0.15966797  0.74707031
   0.38183594  0.51123047 -0.76464844 -0.5390625   0.52734375 -0.3425293
   0.2130127  -0.17871094 -0.43432617  0.27832031 -0.61376953 -0.10552979
  -0.31225586 -0.33447266  0.00196838  0.25561523]]
After layer _mul2059_0 (1, 256) <class 'numpy.float16'> [[ 0.07794189  0.1463623  -0.23974609 -0.11981201  0.32495117 -0.03308105
   0.29760742 -0.03820801 -0.05682373 -0.0531311   0.17199707  0.20092773
   0.0324707  -0.26513672  0.04858398 -0.00344086  0.14929199  0.23510742
  -0.04681396  0.10913086 -0.09655762 -0.31396484 -0.30712891  0.14306641
  -0.08972168 -0.05612183 -0.2956543  -0.03796387 -0.23937988  0.15576172
   0.13452148 -0.08032227  0.30175781 -0.08154297  0.42382812  0.10180664
   0.12457275 -0.44750977 -0.30566406  0.05236816 -0.04464722  0.27416992
  -0.08056641  0.24206543 -0.45996094 -0.14160156 -0.0006814   0.19250488
   0.14868164  0.08843994  0.01966858  0.01217651 -0.13757324 -0.18041992
   0.35693359  0.2434082  -0.34082031 -0.05786133  0.12976074 -0.01280212
   0.23168945 -0.0703125   0.05712891  0.50048828 -0.17932129  0.03344727
   0.15307617  0.3659668   0.10894775 -0.23620605  0.14099121  0.0007596
  -0.4152832   0.13842773  0.21594238  0.35546875  0.27490234 -0.56298828
   0.17321777 -0.31030273  0.33740234 -0.23657227 -0.01490784  0.07159424
  -0.15356445 -0.25341797  0.03155518 -0.36108398  0.07055664 -0.02174377
   0.14318848  0.10784912 -0.27050781 -0.11450195 -0.32226562 -0.07745361
  -0.21276855 -0.37719727  0.18762207  0.08172607 -0.16357422 -0.01818848
  -0.02651978  0.22644043 -0.21862793 -0.24291992  0.18347168  0.16821289
   0.15881348  0.15917969 -0.31713867 -0.25585938  0.51171875  0.47949219
  -0.13366699  0.28662109  0.1541748   0.08093262  0.12561035  0.06018066
   0.01250458 -0.24963379  0.30541992 -0.12091064  0.51220703 -0.00238037
   0.34692383  0.17822266 -0.28955078 -0.40600586  0.06848145  0.24963379
   0.09539795 -0.06494141  0.30541992  0.31811523  0.07897949  0.16455078
  -0.3684082  -0.07800293 -0.02763367  0.38427734 -0.32666016 -0.05963135
   0.26977539  0.00585556  0.19775391 -0.03567505  0.36303711 -0.07440186
   0.39990234 -0.23449707  0.46386719  0.1932373   0.0871582  -0.3527832
   0.36376953 -0.04638672  0.21887207  0.20996094  0.52099609  0.08544922
   0.11956787  0.28393555 -0.0982666   0.10430908 -0.0189209   0.3125
  -0.18713379 -0.20361328  0.06732178  0.64648438 -0.11846924  0.41162109
  -0.21728516 -0.30444336  0.04846191  0.0428772  -0.13171387 -0.04626465
   0.39233398  0.25756836  0.15002441  0.1965332  -0.01585388 -0.23486328
  -0.11712646  0.3125      0.13684082 -0.15490723  0.26000977 -0.22644043
  -0.26928711  0.27807617  0.08825684 -0.3659668  -0.03466797 -0.3347168
   0.23547363 -0.02629089  0.04992676 -0.28540039 -0.33886719 -0.17407227
  -0.10101318 -0.05053711  0.28173828  0.05130005  0.09771729  0.06689453
  -0.10693359  0.16894531  0.14050293  0.12670898  0.47338867 -0.29052734
  -0.17089844 -0.33056641 -0.09851074 -0.1126709  -0.09783936  0.18151855
   0.2878418  -0.37280273  0.09753418 -0.5390625  -0.28027344 -0.11309814
   0.13024902 -0.01875305 -0.09484863 -0.48022461 -0.1105957   0.34179688
  -0.20019531  0.00982666  0.3125      0.14343262 -0.08544922  0.46484375
   0.20410156  0.30273438 -0.61621094 -0.29882812  0.31982422 -0.19555664
   0.11431885 -0.09588623 -0.2512207   0.14929199 -0.40136719 -0.04806519
  -0.18664551 -0.18457031  0.00093699  0.13952637]]
After layer encoder_birnn_forward_l0_t3_state_0 (1, 256) <class 'numpy.float16'> [[ 0.12597656  0.21936035 -0.35058594 -0.18017578  0.46289062 -0.05474854
   0.41894531 -0.08428955 -0.0519104  -0.09057617  0.23425293  0.27539062
   0.06225586 -0.38427734  0.08203125 -0.02728271  0.1998291   0.33691406
  -0.07446289  0.15673828 -0.15661621 -0.44165039 -0.44873047  0.20385742
  -0.13305664 -0.09033203 -0.44384766 -0.07702637 -0.32910156  0.21386719
   0.18920898 -0.13549805  0.44873047 -0.11010742  0.6015625   0.15527344
   0.18066406 -0.60546875 -0.44262695  0.09387207 -0.09924316  0.36425781
  -0.15307617  0.32446289 -0.59912109 -0.18554688  0.02233887  0.28637695
   0.21618652  0.11224365  0.03793335  0.03695679 -0.1104126  -0.25439453
   0.51416016  0.34912109 -0.44506836 -0.0892334   0.18286133 -0.03814697
   0.31347656 -0.10876465  0.10351562  0.72705078 -0.25024414  0.05065918
   0.20019531  0.53808594  0.15209961 -0.34204102  0.18798828 -0.03106689
  -0.62011719  0.2121582   0.30200195  0.50976562  0.38842773 -0.86328125
   0.25708008 -0.43481445  0.47412109 -0.32910156  0.03894043  0.11962891
  -0.22680664 -0.35571289  0.0513916  -0.53417969  0.10656738 -0.00558472
   0.18945312  0.16821289 -0.37597656 -0.1706543  -0.43505859 -0.07574463
  -0.28637695 -0.54101562  0.26586914  0.14953613 -0.21984863 -0.02432251
  -0.05126953  0.33007812 -0.31469727 -0.33398438  0.27001953  0.27050781
   0.24169922  0.24511719 -0.43481445 -0.35913086  0.74121094  0.69335938
  -0.20776367  0.40014648  0.23339844  0.14575195  0.19299316  0.08392334
   0.01881409 -0.39160156  0.4284668  -0.17810059  0.75878906  0.00912476
   0.46826172  0.25732422 -0.40722656 -0.59082031  0.08825684  0.36230469
   0.1348877  -0.09594727  0.43359375  0.46704102  0.08581543  0.22949219
  -0.56445312 -0.10766602 -0.05792236  0.54248047 -0.46582031 -0.09844971
   0.37744141  0.03787231  0.28442383 -0.07226562  0.50683594 -0.12817383
   0.54833984 -0.3359375   0.65576172  0.27636719  0.1418457  -0.48901367
   0.52392578 -0.07312012  0.30175781  0.27319336  0.74707031  0.15820312
   0.20410156  0.3984375  -0.17358398  0.16333008 -0.04986572  0.4296875
  -0.27294922 -0.29907227  0.10437012  0.95556641 -0.18261719  0.56689453
  -0.28930664 -0.40917969  0.09436035  0.08837891 -0.1862793  -0.06591797
   0.55175781  0.34716797  0.21948242  0.2902832  -0.03588867 -0.34204102
  -0.17553711  0.43798828  0.18481445 -0.21362305  0.33691406 -0.33422852
  -0.390625    0.39770508  0.12524414 -0.50927734 -0.01611328 -0.44897461
   0.34008789 -0.0173645   0.11328125 -0.41748047 -0.453125   -0.25341797
  -0.17602539 -0.04391479  0.37133789  0.08154297  0.14379883  0.12890625
  -0.16455078  0.26220703  0.20141602  0.17407227  0.68457031 -0.42041016
  -0.24255371 -0.46923828 -0.13696289 -0.14648438 -0.13952637  0.26831055
   0.39282227 -0.54736328  0.14477539 -0.80175781 -0.39477539 -0.18334961
   0.18896484 -0.0446167  -0.14025879 -0.70214844 -0.15429688  0.4909668
  -0.29003906  0.01776123  0.44726562  0.22705078 -0.13659668  0.66210938
   0.27197266  0.43823242 -0.92089844 -0.39697266  0.43920898 -0.27050781
   0.1550293  -0.15478516 -0.36425781  0.21899414 -0.59570312 -0.06665039
  -0.27880859 -0.27807617  0.01406097  0.22973633]]
After layer activation1029_output (1, 256) <class 'numpy.float16'> [[ 0.12536621  0.21594238 -0.33691406 -0.17822266  0.43237305 -0.0546875
   0.39599609 -0.08410645 -0.05184937 -0.09033203  0.23010254  0.26855469
   0.06216431 -0.36645508  0.08184814 -0.02728271  0.19726562  0.32470703
  -0.07434082  0.15551758 -0.15539551 -0.41503906 -0.42089844  0.2010498
  -0.13232422 -0.09008789 -0.41674805 -0.0769043  -0.31762695  0.21069336
   0.18701172 -0.13464355  0.42089844 -0.10968018  0.53808594  0.15405273
   0.17871094 -0.54101562 -0.41577148  0.09356689 -0.09893799  0.34887695
  -0.15185547  0.31347656 -0.53662109 -0.18347168  0.02233887  0.27880859
   0.21289062  0.11175537  0.03790283  0.03692627 -0.10998535 -0.24902344
   0.47314453  0.33569336 -0.41772461 -0.08898926  0.1809082  -0.03811646
   0.30371094 -0.1083374   0.10314941  0.62109375 -0.24511719  0.05062866
   0.19750977  0.49145508  0.15087891 -0.3293457   0.18579102 -0.03105164
  -0.55126953  0.20898438  0.29321289  0.46972656  0.37011719 -0.69775391
   0.25146484 -0.40942383  0.44140625 -0.31762695  0.03890991  0.11907959
  -0.22302246 -0.34155273  0.05136108 -0.48852539  0.10614014 -0.00558472
   0.18725586  0.16662598 -0.35913086 -0.16906738 -0.40942383 -0.07562256
  -0.27880859 -0.49365234  0.25976562  0.1484375  -0.21643066 -0.02432251
  -0.05123901  0.31860352 -0.3046875  -0.32202148  0.26367188  0.26416016
   0.23706055  0.24035645 -0.40942383 -0.34448242  0.62988281  0.60009766
  -0.20483398  0.38012695  0.22924805  0.14477539  0.19067383  0.08374023
   0.01881409 -0.37280273  0.40405273 -0.17626953  0.64013672  0.00912476
   0.43676758  0.25170898 -0.38623047 -0.53027344  0.0880127   0.34716797
   0.1340332  -0.09564209  0.40820312  0.43579102  0.08563232  0.22558594
  -0.51123047 -0.10723877 -0.05786133  0.49487305 -0.43481445 -0.09814453
   0.3605957   0.0378418   0.27709961 -0.07214355  0.4675293  -0.12744141
   0.49926758 -0.32373047  0.57568359  0.26953125  0.14086914 -0.45336914
   0.48071289 -0.07299805  0.29296875  0.26660156  0.63330078  0.15686035
   0.20129395  0.37866211 -0.171875    0.16186523 -0.04983521  0.4050293
  -0.26635742 -0.29052734  0.10400391  0.7421875  -0.18066406  0.51318359
  -0.28149414 -0.38769531  0.09405518  0.08813477 -0.1842041  -0.0657959
   0.50195312  0.33374023  0.21606445  0.2824707  -0.03585815 -0.3293457
  -0.17370605  0.41186523  0.18273926 -0.21044922  0.32470703 -0.32226562
  -0.37182617  0.37792969  0.12457275 -0.46948242 -0.01611328 -0.42114258
   0.32763672 -0.0173645   0.11279297 -0.39477539 -0.42456055 -0.24816895
  -0.17419434 -0.04388428  0.35522461  0.08135986  0.14282227  0.12817383
  -0.16308594  0.25634766  0.19873047  0.17236328  0.59472656 -0.3972168
  -0.23791504 -0.4375     -0.1361084  -0.14538574 -0.13867188  0.26196289
   0.3737793  -0.49853516  0.14379883 -0.66503906 -0.37548828 -0.18127441
   0.18676758 -0.04458618 -0.1394043  -0.60595703 -0.15307617  0.45507812
  -0.28222656  0.01776123  0.41967773  0.2232666  -0.13574219  0.57958984
   0.26538086  0.41210938 -0.7265625  -0.37744141  0.41308594 -0.26416016
   0.15380859 -0.15356445 -0.34887695  0.21557617 -0.53417969 -0.06652832
  -0.27172852 -0.27124023  0.01406097  0.22583008]]
After layer encoder_birnn_forward_l0_t3_out_0 (1, 256) <class 'numpy.float16'> [[ 0.07598877  0.12322998 -0.19689941 -0.10772705  0.2442627  -0.03256226
   0.25976562 -0.04779053 -0.03088379 -0.05319214  0.13024902  0.15478516
   0.0350647  -0.21813965  0.04083252 -0.01476288  0.11431885  0.18188477
  -0.04974365  0.09326172 -0.08233643 -0.2097168  -0.26953125  0.1204834
  -0.0769043  -0.0486145  -0.26000977 -0.04559326 -0.16271973  0.11901855
   0.10992432 -0.08233643  0.22314453 -0.06130981  0.3046875   0.08557129
   0.10473633 -0.29125977 -0.19006348  0.05093384 -0.05603027  0.19909668
  -0.08306885  0.17736816 -0.30371094 -0.10681152  0.0147934   0.16210938
   0.12091064  0.05807495  0.01831055  0.02145386 -0.08380127 -0.12585449
   0.27587891  0.16223145 -0.22888184 -0.04910278  0.10406494 -0.0218811
   0.15332031 -0.06256104  0.05279541  0.38305664 -0.13415527  0.02890015
   0.12219238  0.27270508  0.08514404 -0.18554688  0.11022949 -0.01809692
  -0.36254883  0.11651611  0.16394043  0.34301758  0.21520996 -0.51416016
   0.15917969 -0.22155762  0.27319336 -0.15612793  0.02937317  0.0670166
  -0.13659668 -0.19091797  0.02738953 -0.29394531  0.07409668 -0.0032444
   0.10394287  0.09069824 -0.16796875 -0.10412598 -0.21472168 -0.04748535
  -0.16894531 -0.29736328  0.15869141  0.09515381 -0.11657715 -0.01357269
  -0.02760315  0.19946289 -0.1829834  -0.16491699  0.14697266  0.16333008
   0.14318848  0.1295166  -0.25537109 -0.19677734  0.44042969  0.41113281
  -0.12371826  0.21472168  0.13330078  0.09423828  0.11035156  0.04928589
   0.01056671 -0.24169922  0.23693848 -0.09973145  0.37353516  0.00542068
   0.23242188  0.12670898 -0.21350098 -0.37280273  0.05252075  0.22387695
   0.07318115 -0.05462646  0.2232666   0.23193359  0.05117798  0.12609863
  -0.32373047 -0.06216431 -0.03128052  0.2902832  -0.25073242 -0.05664062
   0.19750977  0.02174377  0.15393066 -0.04025269  0.24353027 -0.07141113
   0.33349609 -0.17736816  0.33398438  0.1340332   0.07714844 -0.22717285
   0.25878906 -0.04095459  0.1842041   0.15820312  0.37011719  0.09143066
   0.10968018  0.22192383 -0.10742188  0.08630371 -0.02864075  0.21679688
  -0.13085938 -0.16015625  0.05584717  0.58642578 -0.1081543   0.33398438
  -0.13952637 -0.21264648  0.0536499   0.05163574 -0.10083008 -0.04031372
   0.28833008  0.16369629  0.1229248   0.16918945 -0.01942444 -0.19519043
  -0.10076904  0.22167969  0.10235596 -0.12683105  0.16088867 -0.18054199
  -0.23950195  0.22058105  0.06524658 -0.27929688 -0.01287079 -0.24658203
   0.19165039 -0.01013184  0.06079102 -0.20495605 -0.25366211 -0.14697266
  -0.10174561 -0.02685547  0.22338867  0.04144287  0.06542969  0.07568359
  -0.09619141  0.13708496  0.11914062  0.1026001   0.42285156 -0.26367188
  -0.13415527 -0.28173828 -0.08129883 -0.07995605 -0.07629395  0.15795898
   0.18908691 -0.27905273  0.08251953 -0.37280273 -0.21362305 -0.10241699
   0.11016846 -0.02366638 -0.07202148 -0.38525391 -0.08782959  0.2668457
  -0.17016602  0.00962067  0.21276855  0.1116333  -0.07525635  0.37695312
   0.14245605  0.25366211 -0.59619141 -0.18505859  0.23876953 -0.14355469
   0.08935547 -0.08837891 -0.21069336  0.13232422 -0.3347168  -0.03619385
  -0.17126465 -0.16357422  0.00797272  0.13293457]]
After layer expand_dims1035_0 (1, 1, 256) <class 'numpy.float16'> [[[ 0.07598877  0.12322998 -0.19689941 -0.10772705  0.2442627  -0.03256226
    0.25976562 -0.04779053 -0.03088379 -0.05319214  0.13024902  0.15478516
    0.0350647  -0.21813965  0.04083252 -0.01476288  0.11431885  0.18188477
   -0.04974365  0.09326172 -0.08233643 -0.2097168  -0.26953125  0.1204834
   -0.0769043  -0.0486145  -0.26000977 -0.04559326 -0.16271973  0.11901855
    0.10992432 -0.08233643  0.22314453 -0.06130981  0.3046875   0.08557129
    0.10473633 -0.29125977 -0.19006348  0.05093384 -0.05603027  0.19909668
   -0.08306885  0.17736816 -0.30371094 -0.10681152  0.0147934   0.16210938
    0.12091064  0.05807495  0.01831055  0.02145386 -0.08380127 -0.12585449
    0.27587891  0.16223145 -0.22888184 -0.04910278  0.10406494 -0.0218811
    0.15332031 -0.06256104  0.05279541  0.38305664 -0.13415527  0.02890015
    0.12219238  0.27270508  0.08514404 -0.18554688  0.11022949 -0.01809692
   -0.36254883  0.11651611  0.16394043  0.34301758  0.21520996 -0.51416016
    0.15917969 -0.22155762  0.27319336 -0.15612793  0.02937317  0.0670166
   -0.13659668 -0.19091797  0.02738953 -0.29394531  0.07409668 -0.0032444
    0.10394287  0.09069824 -0.16796875 -0.10412598 -0.21472168 -0.04748535
   -0.16894531 -0.29736328  0.15869141  0.09515381 -0.11657715 -0.01357269
   -0.02760315  0.19946289 -0.1829834  -0.16491699  0.14697266  0.16333008
    0.14318848  0.1295166  -0.25537109 -0.19677734  0.44042969  0.41113281
   -0.12371826  0.21472168  0.13330078  0.09423828  0.11035156  0.04928589
    0.01056671 -0.24169922  0.23693848 -0.09973145  0.37353516  0.00542068
    0.23242188  0.12670898 -0.21350098 -0.37280273  0.05252075  0.22387695
    0.07318115 -0.05462646  0.2232666   0.23193359  0.05117798  0.12609863
   -0.32373047 -0.06216431 -0.03128052  0.2902832  -0.25073242 -0.05664062
    0.19750977  0.02174377  0.15393066 -0.04025269  0.24353027 -0.07141113
    0.33349609 -0.17736816  0.33398438  0.1340332   0.07714844 -0.22717285
    0.25878906 -0.04095459  0.1842041   0.15820312  0.37011719  0.09143066
    0.10968018  0.22192383 -0.10742188  0.08630371 -0.02864075  0.21679688
   -0.13085938 -0.16015625  0.05584717  0.58642578 -0.1081543   0.33398438
   -0.13952637 -0.21264648  0.0536499   0.05163574 -0.10083008 -0.04031372
    0.28833008  0.16369629  0.1229248   0.16918945 -0.01942444 -0.19519043
   -0.10076904  0.22167969  0.10235596 -0.12683105  0.16088867 -0.18054199
   -0.23950195  0.22058105  0.06524658 -0.27929688 -0.01287079 -0.24658203
    0.19165039 -0.01013184  0.06079102 -0.20495605 -0.25366211 -0.14697266
   -0.10174561 -0.02685547  0.22338867  0.04144287  0.06542969  0.07568359
   -0.09619141  0.13708496  0.11914062  0.1026001   0.42285156 -0.26367188
   -0.13415527 -0.28173828 -0.08129883 -0.07995605 -0.07629395  0.15795898
    0.18908691 -0.27905273  0.08251953 -0.37280273 -0.21362305 -0.10241699
    0.11016846 -0.02366638 -0.07202148 -0.38525391 -0.08782959  0.2668457
   -0.17016602  0.00962067  0.21276855  0.1116333  -0.07525635  0.37695312
    0.14245605  0.25366211 -0.59619141 -0.18505859  0.23876953 -0.14355469
    0.08935547 -0.08837891 -0.21069336  0.13232422 -0.3347168  -0.03619385
   -0.17126465 -0.16357422  0.00797272  0.13293457]]]
After layer encoder_birnn_forward_l0_t4_i2h_output (1, 1024) <class 'numpy.float16'> [[ 0.0737915  -0.0458374   0.06152344 ...,  0.03591919  0.03396606
   0.02903748]]
After layer encoder_birnn_forward_l0_t4_h2h_output (1, 1024) <class 'numpy.float16'> [[ 0.30981445  0.32763672  0.20324707 ...,  0.69384766  0.38623047
   0.59912109]]
After layer _plus1030_0 (1, 1024) <class 'numpy.float16'> [[ 0.38354492  0.28173828  0.26464844 ...,  0.72998047  0.42016602
   0.62792969]]
After layer encoder_birnn_forward_l0_t4_slice_output0 (1, 256) <class 'numpy.float16'> [[  3.83544922e-01   2.81738281e-01   2.64648438e-01   2.11914062e-01
    5.43457031e-01   4.96826172e-01   8.70605469e-01   8.26416016e-02
   -2.09106445e-01   3.42285156e-01   2.68554688e-01   4.74121094e-01
   -1.24206543e-02   6.34765625e-01  -1.84082031e-01   1.58203125e-01
    2.47436523e-01   3.86718750e-01   5.42968750e-01   2.69531250e-01
    1.29699707e-03  -4.87304688e-01   3.74023438e-01   2.89062500e-01
    1.94458008e-01   1.37695312e-01   6.20117188e-01   5.74340820e-02
    4.89257812e-01   4.20898438e-01   4.25292969e-01   4.57031250e-01
    7.33398438e-01   3.38134766e-01   1.07421875e+00   5.15136719e-02
    2.19604492e-01   1.19140625e+00   7.91015625e-01  -2.94677734e-01
   -1.38549805e-01   3.85009766e-01   6.20117188e-01   1.98120117e-01
    1.00000000e+00   3.75244141e-01   2.69042969e-01   4.66308594e-01
    1.74560547e-01  -9.25903320e-02  -1.90307617e-01  -1.69311523e-01
    1.99609375e+00   2.51464844e-01   8.12011719e-01   1.36352539e-01
    6.53808594e-01  -3.57666016e-02   2.50000000e-01  -5.87402344e-01
    2.77832031e-01   3.18847656e-01  -2.38037109e-03   7.58300781e-01
    7.12280273e-02   1.07177734e-01   5.09277344e-01   9.07714844e-01
    4.64599609e-01   7.34375000e-01  -1.05773926e-01  -5.18554688e-01
    1.13085938e+00   3.77441406e-01   4.06982422e-01   1.13867188e+00
    5.28808594e-01   1.61132812e+00   3.61572266e-01  -1.47460938e-01
    6.32324219e-01   3.74267578e-01   5.28808594e-01  -5.10253906e-02
    7.21191406e-01   5.00488281e-01   2.16308594e-01   9.44824219e-01
    7.91992188e-01  -1.33300781e-01   3.15185547e-01  -1.16333008e-01
   -1.35864258e-01   3.59375000e-01  -2.24487305e-01  -3.73291016e-01
    7.42675781e-01   8.03710938e-01   6.52832031e-01   4.00878906e-01
    1.42944336e-01  -1.78710938e-01   2.94433594e-01   8.31542969e-01
    6.18652344e-01   2.38525391e-01   7.69653320e-02   2.39501953e-01
    3.60107422e-02   2.08984375e-01   8.12500000e-01   6.64550781e-01
    1.41308594e+00   1.70507812e+00   5.30273438e-01   6.12304688e-01
    3.97705078e-01   6.72363281e-01   1.46728516e-01  -4.68139648e-02
   -1.29638672e-01   7.04101562e-01   1.11718750e+00   2.44140625e-01
    1.19042969e+00   1.76879883e-01   2.84667969e-01   2.81738281e-01
    2.43164062e-01   1.28710938e+00  -2.28637695e-01   5.57617188e-01
    2.27783203e-01   1.15905762e-01   6.40625000e-01   4.06738281e-01
    4.64599609e-01  -3.63769531e-01   5.40039062e-01  -6.36596680e-02
    3.55834961e-02   7.55859375e-01   5.20019531e-01   5.28259277e-02
    3.93798828e-01  -3.91845703e-01   3.08380127e-02  -3.09082031e-01
    6.16210938e-01  -6.92138672e-02   1.04589844e+00   5.42968750e-01
    1.02343750e+00   7.70507812e-01   7.82470703e-02   6.59667969e-01
    4.42626953e-01  -2.11303711e-01   6.99707031e-01   5.68847656e-01
    1.24218750e+00  -8.71582031e-02   5.46875000e-01   5.85937500e-01
    4.68750000e-01   6.71386719e-02   1.07299805e-01   3.65722656e-01
   -3.05480957e-02   2.85156250e-01  -2.64404297e-01   2.38085938e+00
    2.70507812e-01   9.08691406e-01   4.61914062e-01   2.02514648e-01
   -9.46655273e-02  -3.18115234e-01  -5.17578125e-02   2.40478516e-01
    8.71093750e-01   3.34228516e-01   3.90380859e-01   2.21923828e-01
   -1.61132812e-01   3.99414062e-01   3.88793945e-02   7.42675781e-01
    4.41406250e-01   4.24804688e-01  -3.01025391e-01   1.63085938e-01
    9.61425781e-01   2.71484375e-01   3.30810547e-01   7.14843750e-01
    2.02343750e+00   8.12011719e-01   4.42382812e-01   1.48071289e-01
    2.29980469e-01   6.25976562e-01   3.74267578e-01   3.18115234e-01
    3.97949219e-01  -8.70513916e-03   5.40039062e-01  -2.14355469e-01
   -1.39282227e-01   3.00292969e-01   4.49707031e-01   2.37548828e-01
    6.23535156e-01   3.01513672e-01   1.29589844e+00   6.15722656e-01
    2.21801758e-01   8.32031250e-01   3.53027344e-01  -2.71484375e-01
    1.48193359e-01   2.45849609e-01   4.34570312e-01   4.71923828e-01
    4.11621094e-01   1.76269531e+00   4.82177734e-01   1.31225586e-02
    7.70874023e-02   7.00073242e-02  -3.57666016e-01   1.61132812e+00
    2.34985352e-01   8.06640625e-01   3.71582031e-01  -1.04217529e-02
    3.37646484e-01  -1.86523438e-01   1.83837891e-01   9.18945312e-01
    1.87011719e-01   5.96191406e-01   2.61718750e+00   3.47167969e-01
    7.23632812e-01   4.79003906e-01   2.58789062e-01   2.11669922e-01
    5.21484375e-01   2.84179688e-01   1.02636719e+00  -3.22265625e-01
    7.00195312e-01   3.92578125e-01  -2.31933594e-01   2.83203125e-01]]
After layer encoder_birnn_forward_l0_t4_slice_output1 (1, 256) <class 'numpy.float16'> [[  7.59277344e-01   3.36303711e-02   1.62109375e-01   3.58398438e-01
    2.51464844e-01   3.17382812e-01   7.78320312e-01   2.70751953e-01
    1.16210938e+00   2.27905273e-01   7.59277344e-01   3.40576172e-01
    5.51269531e-01   5.11718750e-01  -4.86450195e-02   3.46679688e-01
    2.25585938e-01   2.64892578e-01   7.74902344e-01   4.24316406e-01
    1.58935547e-01  -6.67114258e-02   7.86132812e-01   2.13012695e-01
    4.83154297e-01   4.05517578e-01   5.10253906e-01   2.62939453e-01
    6.87500000e-01   1.36840820e-01   6.19628906e-01   5.16601562e-01
    3.72070312e-01   4.69482422e-01   8.72070312e-01   3.61572266e-01
    1.83349609e-01   3.34716797e-01   8.94531250e-01   8.39843750e-02
    5.47363281e-01   3.17382812e-01   7.97851562e-01  -8.01391602e-02
    6.57348633e-02  -1.55273438e-01   8.32031250e-01   3.64746094e-01
    2.34619141e-01  -1.42822266e-01  -1.52709961e-01   2.60742188e-01
    1.74511719e+00  -1.16088867e-01   6.90917969e-01  -1.08215332e-01
    2.34130859e-01   3.25683594e-01   4.06738281e-01   4.97802734e-01
    2.53295898e-02   3.04687500e-01   1.74438477e-01   5.95214844e-01
    1.45874023e-01   2.93945312e-01   5.00000000e-01   6.64062500e-01
    3.28125000e-01   8.95507812e-01  -9.63134766e-02   3.46923828e-01
    9.54101562e-01   3.68896484e-01   1.05773926e-01   1.58203125e+00
    3.32031250e-01   1.45312500e+00   5.70800781e-01  -3.21044922e-01
    6.16210938e-01  -3.05908203e-01   1.49707031e+00   4.79003906e-01
    6.25000000e-01   3.70849609e-01   1.65939331e-03   9.48242188e-01
    1.59570312e+00   3.25439453e-01   1.89941406e-01   3.86962891e-01
    5.62286377e-03   3.75000000e-01  -1.15905762e-01   6.75048828e-02
    7.17773438e-01   6.49414062e-01   7.15332031e-01   6.49414062e-01
    1.23779297e-01  -1.89331055e-01   6.50634766e-02   6.09375000e-01
    5.62011719e-01   1.81152344e-01   4.38964844e-01   4.53125000e-01
    3.45458984e-01   2.68554688e-01   6.19628906e-01   8.33984375e-01
    1.03515625e+00   1.29199219e+00   4.72167969e-01   3.83300781e-01
    7.55859375e-01   7.76367188e-01   3.68408203e-01   3.19824219e-01
    3.95019531e-01   8.86718750e-01   4.36523438e-01   3.21044922e-01
    7.37304688e-01   4.21386719e-01  -2.06665039e-01   3.16406250e-01
    3.03466797e-01   1.19726562e+00   2.80761719e-01   5.16113281e-01
    1.53320312e-01   1.65771484e-01   3.31787109e-01   6.95800781e-01
    4.59716797e-01  -3.11035156e-01   9.30175781e-01   5.37597656e-01
    3.20556641e-01   4.00878906e-01   5.49804688e-01   4.43115234e-01
    4.23339844e-01   7.06542969e-01   2.10937500e-01   3.86474609e-01
    7.02636719e-01   4.49951172e-01   6.45507812e-01   1.74804688e-01
    4.65820312e-01   3.72558594e-01   2.75878906e-01   1.85546875e-01
    7.04589844e-01   1.81396484e-01   8.62304688e-01   4.22363281e-01
    8.31054688e-01   3.63769531e-01   6.65527344e-01   5.90332031e-01
    6.19628906e-01   1.75903320e-01   1.92871094e-01   2.73681641e-01
   -8.40454102e-02   1.78222656e-01  -1.34643555e-01   1.32812500e+00
    3.70605469e-01   9.42871094e-01   3.43933105e-02   1.49658203e-01
    2.31811523e-01   5.59082031e-01  -1.33056641e-01   6.92871094e-01
    2.53173828e-01  -8.80737305e-02   6.64550781e-01   4.58496094e-01
    2.76367188e-01   4.30664062e-01   6.75781250e-01   5.44433594e-01
    3.99902344e-01   5.66406250e-01  -2.68554688e-01   3.92333984e-01
    7.02148438e-01   4.76074219e-01  -1.30004883e-02   2.80029297e-01
    2.66015625e+00  -1.38549805e-01   4.26025391e-01  -4.05883789e-02
    3.91845703e-01   4.36279297e-01   2.98828125e-01   8.87695312e-01
    4.39697266e-01   2.34619141e-01   6.94824219e-01  -3.12011719e-01
    4.98657227e-02   5.22949219e-01   5.90820312e-01   3.41308594e-01
    5.29785156e-01   4.25292969e-01   1.21582031e+00   7.92968750e-01
    1.48681641e-01   6.25000000e-01   1.00708008e-01   7.80639648e-02
    1.10961914e-01   5.69824219e-01  -9.59472656e-02   5.29296875e-01
    2.89794922e-01   9.57031250e-01  -1.94580078e-01   2.38159180e-01
    4.86816406e-01   2.53662109e-01   2.87109375e-01   1.13867188e+00
    2.52929688e-01   4.97314453e-01   6.54785156e-01   4.84375000e-01
    6.73217773e-02   1.52221680e-01   1.76269531e-01   1.01074219e+00
    1.65527344e-01   6.90429688e-01   2.46875000e+00  -6.71386719e-02
    2.49511719e-01  -7.66601562e-02   2.17651367e-01   3.06152344e-01
    4.73876953e-01   5.80566406e-01   1.00585938e+00  -8.24584961e-02
    8.03222656e-01   3.95751953e-01   2.68066406e-01   4.81445312e-01]]
After layer encoder_birnn_forward_l0_t4_slice_output2 (1, 256) <class 'numpy.float16'> [[  2.10205078e-01   4.36035156e-01  -7.64648438e-01  -3.12011719e-01
    1.04980469e+00  -1.31103516e-01   9.04296875e-01  -1.56250000e-02
   -2.86621094e-01  -8.40454102e-02   5.78613281e-01   6.36718750e-01
    1.60766602e-01  -8.01269531e-01   1.18164062e-01   1.08947754e-02
    4.55322266e-01   7.63671875e-01  -6.89697266e-02   3.45703125e-01
   -2.37426758e-01  -1.48535156e+00  -1.19140625e+00   4.67773438e-01
   -1.96899414e-01  -1.22924805e-01  -9.43359375e-01  -5.57250977e-02
   -7.82714844e-01   5.38085938e-01   4.19677734e-01  -2.53173828e-01
    8.14941406e-01  -3.10791016e-01   1.42675781e+00   3.75000000e-01
    4.11621094e-01  -1.43750000e+00  -1.00195312e+00   6.68334961e-02
   -7.64160156e-02   1.05078125e+00  -1.50634766e-01   8.61328125e-01
   -1.68847656e+00  -4.45312500e-01  -5.89904785e-02   5.12695312e-01
    4.86328125e-01   3.20556641e-01  -1.73034668e-02  -6.39343262e-03
   -5.01464844e-01  -5.37109375e-01   1.13476562e+00   7.56835938e-01
   -1.21386719e+00  -1.59667969e-01   5.57617188e-01  -2.07519531e-03
    8.23242188e-01  -1.54663086e-01   1.61743164e-01   2.06835938e+00
   -6.32324219e-01   9.79003906e-02   5.28808594e-01   1.10449219e+00
    3.44726562e-01  -8.40332031e-01   5.05371094e-01   8.30078125e-02
   -1.37695312e+00   3.65722656e-01   6.50878906e-01   1.12695312e+00
    9.11621094e-01  -1.89062500e+00   5.83984375e-01  -1.22070312e+00
    1.21191406e+00  -6.97753906e-01  -1.21093750e-01   1.46972656e-01
   -3.93066406e-01  -8.98925781e-01   1.56616211e-01  -1.18359375e+00
    1.50512695e-01  -9.90600586e-02   5.35644531e-01   3.51562500e-01
   -1.06542969e+00  -3.63037109e-01  -1.51171875e+00  -4.29199219e-01
   -6.06445312e-01  -1.32031250e+00   5.68847656e-01   1.91650391e-01
   -6.09863281e-01  -7.82470703e-02  -1.31454468e-02   6.35253906e-01
   -5.50781250e-01  -8.75000000e-01   5.22460938e-01   4.46289062e-01
    4.61914062e-01   5.05371094e-01  -1.00000000e+00  -8.66210938e-01
    1.70410156e+00   1.49316406e+00  -2.47802734e-01   9.36035156e-01
    4.62158203e-01   1.58569336e-01   3.94531250e-01   1.28173828e-01
    8.80126953e-02  -7.59277344e-01   9.13085938e-01  -3.86718750e-01
    1.75488281e+00  -1.14685059e-01   1.31054688e+00   5.61523438e-01
   -1.05761719e+00  -1.34472656e+00   2.31933594e-01   7.16796875e-01
    3.15917969e-01  -1.98852539e-01   9.63867188e-01   1.14355469e+00
    3.11523438e-01   7.09472656e-01  -1.31445312e+00  -3.42529297e-01
   -1.21612549e-02   1.31542969e+00  -1.13085938e+00  -1.29394531e-01
    9.81445312e-01  -1.40380859e-02   7.09960938e-01  -3.61328125e-02
    1.31835938e+00  -1.88476562e-01   1.34082031e+00  -6.67968750e-01
    1.57812500e+00   6.99707031e-01   2.71972656e-01  -1.24316406e+00
    1.36230469e+00  -8.00170898e-02   7.11425781e-01   7.29492188e-01
    1.92480469e+00   1.41601562e-01   3.02246094e-01   9.13085938e-01
   -2.01538086e-01   2.50244141e-01  -3.36303711e-02   1.06445312e+00
   -6.07910156e-01  -5.98632812e-01   2.18994141e-01   2.08398438e+00
   -3.52050781e-01   1.45800781e+00  -6.85058594e-01  -1.20410156e+00
    1.37207031e-01   1.39892578e-01  -4.66064453e-01  -1.54785156e-01
    1.28222656e+00   9.05273438e-01   4.51660156e-01   5.98144531e-01
   -1.58691406e-02  -7.47558594e-01  -4.04541016e-01   1.06250000e+00
    4.46777344e-01  -4.83886719e-01   1.14843750e+00  -7.47558594e-01
   -8.24707031e-01   1.04882812e+00   2.64160156e-01  -1.23632812e+00
   -1.96777344e-01  -1.05078125e+00   7.61718750e-01  -1.54052734e-01
    5.16357422e-02  -8.51074219e-01  -1.31054688e+00  -5.56152344e-01
   -2.24853516e-01  -2.09228516e-01   9.92675781e-01   1.13281250e-01
    3.28125000e-01   1.08642578e-01  -2.97607422e-01   5.27343750e-01
    4.52148438e-01   3.65234375e-01   1.58496094e+00  -9.93164062e-01
   -5.62988281e-01  -1.08203125e+00  -3.37890625e-01  -4.27490234e-01
   -3.12500000e-01   5.43457031e-01   9.41894531e-01  -1.40136719e+00
    2.82958984e-01  -1.73535156e+00  -9.53613281e-01  -3.30078125e-01
    3.52294922e-01  -2.20184326e-02  -3.42773438e-01  -1.39843750e+00
   -2.90039062e-01   1.15527344e+00  -5.96191406e-01  -2.00500488e-02
    1.06542969e+00   5.21484375e-01  -1.55029297e-01   1.85839844e+00
    7.67578125e-01   9.37011719e-01  -1.93847656e+00  -1.12207031e+00
    1.04394531e+00  -6.17187500e-01   3.70361328e-01  -2.64160156e-01
   -8.06640625e-01   5.32714844e-01  -1.19335938e+00  -1.63452148e-01
   -5.13671875e-01  -5.39062500e-01  -6.87255859e-02   3.59375000e-01]]
After layer encoder_birnn_forward_l0_t4_slice_output3 (1, 256) <class 'numpy.float16'> [[  7.19726562e-01   4.54101562e-01   5.38574219e-01   6.67968750e-01
    4.63134766e-01   6.45019531e-01   1.20996094e+00   4.11865234e-01
    6.04492188e-01   5.70800781e-01   4.75585938e-01   5.65917969e-01
    4.16748047e-01   7.90527344e-01  -4.02221680e-02   2.20703125e-01
    5.84472656e-01   3.24218750e-01   1.15722656e+00   6.91894531e-01
    2.82226562e-01   8.97216797e-03   1.02734375e+00   6.92382812e-01
    4.87304688e-01   2.45727539e-01   8.79394531e-01   6.11816406e-01
    1.03515625e-01   4.61425781e-01   6.54296875e-01   7.31933594e-01
    1.14074707e-01   4.27246094e-01   4.31884766e-01   2.93457031e-01
    5.85937500e-01   2.14111328e-01  -3.55957031e-01   3.24462891e-01
    4.32373047e-01   4.70214844e-01   3.83300781e-01   4.67773438e-01
    4.66308594e-01   5.49804688e-01   1.22851562e+00   5.89355469e-01
    4.60693359e-01   1.32812500e-01  -1.92871094e-01   5.70800781e-01
    2.04687500e+00  -3.54003906e-02   5.61523438e-01  -8.31298828e-02
    2.82226562e-01   4.04052734e-01   5.62988281e-01   4.58496094e-01
    1.09863281e-03   4.55566406e-01   7.16552734e-02   8.01757812e-01
    2.82714844e-01   4.88037109e-01   7.84179688e-01   3.47900391e-01
    4.53613281e-01   3.97949219e-01   6.45019531e-01   5.61523438e-01
    1.14160156e+00   4.60693359e-01   3.88183594e-01   1.77050781e+00
    5.34179688e-01   1.77343750e+00   8.91601562e-01   2.03002930e-01
    9.10156250e-01  -1.08520508e-01   2.06250000e+00   4.58984375e-01
    8.03710938e-01   3.85498047e-01   2.70019531e-01   6.52832031e-01
    1.41113281e+00   6.16210938e-01   3.92822266e-01   3.98681641e-01
   -2.63183594e-01   8.39355469e-01   1.54785156e-01   8.12988281e-01
    6.76269531e-01   7.17773438e-01   7.21191406e-01   9.88281250e-01
    2.26684570e-01   3.95507812e-01   1.94580078e-01   9.11621094e-01
    7.11425781e-01   1.57958984e-01   4.42871094e-01   7.55371094e-01
    7.20703125e-01   2.07641602e-01   8.99902344e-01   5.09765625e-01
    1.41015625e+00   1.29394531e+00   6.99707031e-01   5.12695312e-01
    5.60546875e-01   1.08496094e+00   5.35644531e-01   6.34277344e-01
    4.57519531e-01   1.07910156e+00   5.78125000e-01   4.81445312e-01
    6.42578125e-01   7.01171875e-01   1.30004883e-01   4.41894531e-02
    3.70605469e-01   1.53125000e+00   6.32324219e-01   1.00683594e+00
    3.44238281e-01   4.96826172e-01   3.11523438e-01   2.40844727e-01
    6.98242188e-01   4.25537109e-01   9.02343750e-01   5.26855469e-01
    2.69287109e-01   5.44433594e-01   5.15625000e-01   5.58593750e-01
    3.18359375e-01   5.75195312e-01   3.87695312e-01   3.86230469e-01
    9.13696289e-02   3.19824219e-01   1.19433594e+00   2.81494141e-01
    5.93261719e-01   3.54003906e-03   2.73437500e-01  -4.28466797e-02
    2.83447266e-01   4.02832031e-01   1.00488281e+00   5.96191406e-01
    5.47851562e-01   5.94238281e-01   2.34863281e-01   6.31835938e-01
    9.08691406e-01   2.36938477e-01   5.33203125e-01   2.38403320e-01
   -9.73510742e-02   2.98583984e-01   3.28857422e-01   2.30468750e+00
    6.69921875e-01   1.01074219e+00  -2.25372314e-02   2.38525391e-01
    4.65576172e-01   5.94238281e-01   3.16894531e-01   7.65136719e-01
    4.81933594e-01  -8.81347656e-02   5.60546875e-01   6.56250000e-01
    3.06640625e-01   6.34765625e-01   5.30273438e-01   2.65869141e-01
    5.29296875e-01   7.88085938e-01  -3.64990234e-02   4.60205078e-01
    1.04687500e+00   5.49316406e-01   1.40747070e-01   6.55273438e-01
    2.39062500e+00   4.88281250e-01   5.63964844e-01   5.80566406e-01
    2.68554688e-01   1.12915039e-01   6.51367188e-01   7.86621094e-01
    6.21582031e-01   7.63671875e-01   8.77441406e-01   9.08203125e-02
   -2.89306641e-01   5.57617188e-01   6.29394531e-01   2.73437500e-01
    7.87109375e-01   6.94824219e-01   1.57910156e+00   1.07421875e+00
    3.85498047e-01   1.00195312e+00   6.98242188e-01   3.64501953e-01
    3.87451172e-01   6.90429688e-01   2.86407471e-02   3.21777344e-01
    5.89843750e-01   3.87207031e-01   5.32714844e-01   4.72167969e-01
    6.02050781e-01   2.27416992e-01   1.68945312e-01   9.58496094e-01
    5.72753906e-01   6.13281250e-01   7.26074219e-01   3.06640625e-01
    5.71899414e-02  -7.00073242e-02   4.29931641e-01   1.16406250e+00
    1.41723633e-01   8.13964844e-01   2.80664062e+00   3.28369141e-02
    4.93164062e-01   2.14599609e-01   5.39550781e-01   5.51269531e-01
    8.06152344e-01   7.84179688e-01   9.37988281e-01   2.72705078e-01
    9.29199219e-01   7.29980469e-01   4.20166016e-01   6.27929688e-01]]
After layer encoder_birnn_forward_l0_t4_o_output (1, 256) <class 'numpy.float16'> [[ 0.67236328  0.61181641  0.63134766  0.66113281  0.61376953  0.65576172
   0.77050781  0.6015625   0.64648438  0.63916016  0.61669922  0.63769531
   0.60253906  0.68798828  0.48999023  0.55517578  0.64208984  0.58056641
   0.76074219  0.66650391  0.5703125   0.50244141  0.73632812  0.66650391
   0.61962891  0.56103516  0.70654297  0.6484375   0.52587891  0.61328125
   0.65820312  0.67529297  0.52832031  0.60498047  0.60644531  0.57275391
   0.64257812  0.55322266  0.41186523  0.58056641  0.60644531  0.61523438
   0.59472656  0.61474609  0.61474609  0.63427734  0.7734375   0.64306641
   0.61328125  0.53320312  0.4519043   0.63916016  0.88574219  0.49121094
   0.63671875  0.47924805  0.5703125   0.59960938  0.63720703  0.61279297
   0.50048828  0.61181641  0.51806641  0.69042969  0.5703125   0.61962891
   0.68652344  0.5859375   0.61132812  0.59814453  0.65576172  0.63671875
   0.7578125   0.61328125  0.59570312  0.85449219  0.63037109  0.85498047
   0.70898438  0.55078125  0.71289062  0.47290039  0.88720703  0.61279297
   0.69091797  0.59521484  0.56689453  0.65771484  0.80371094  0.64941406
   0.59716797  0.59814453  0.43457031  0.69824219  0.53857422  0.69287109
   0.66308594  0.671875    0.67285156  0.72851562  0.55664062  0.59765625
   0.54833984  0.71337891  0.67089844  0.53955078  0.60888672  0.68017578
   0.67285156  0.55175781  0.7109375   0.62451172  0.80371094  0.78466797
   0.66796875  0.62548828  0.63671875  0.74755859  0.63085938  0.65332031
   0.61230469  0.74609375  0.640625    0.61816406  0.65527344  0.66845703
   0.53222656  0.51123047  0.59179688  0.82226562  0.65283203  0.73242188
   0.58544922  0.62158203  0.57714844  0.56005859  0.66796875  0.60498047
   0.71142578  0.62890625  0.56689453  0.6328125   0.62597656  0.63623047
   0.57910156  0.64013672  0.59570312  0.59521484  0.52294922  0.57910156
   0.76757812  0.56982422  0.64404297  0.50097656  0.56787109  0.48925781
   0.5703125   0.59960938  0.73193359  0.64501953  0.63378906  0.64453125
   0.55859375  0.65283203  0.71289062  0.55908203  0.63037109  0.55908203
   0.47558594  0.57421875  0.58154297  0.90917969  0.66162109  0.73339844
   0.49438477  0.55957031  0.61425781  0.64453125  0.57861328  0.68261719
   0.61816406  0.47802734  0.63671875  0.65820312  0.57617188  0.65380859
   0.62939453  0.56591797  0.62939453  0.6875      0.4909668   0.61328125
   0.74023438  0.63378906  0.53515625  0.65820312  0.91601562  0.61962891
   0.63720703  0.64111328  0.56689453  0.52832031  0.65722656  0.68701172
   0.65039062  0.68212891  0.70605469  0.52246094  0.42822266  0.63574219
   0.65234375  0.56787109  0.68701172  0.66699219  0.82910156  0.74560547
   0.59521484  0.73144531  0.66796875  0.59033203  0.59570312  0.66601562
   0.50732422  0.57958984  0.64355469  0.59570312  0.62988281  0.61572266
   0.64599609  0.55664062  0.54199219  0.72265625  0.63916016  0.64892578
   0.67382812  0.57617188  0.51416016  0.48242188  0.60595703  0.76220703
   0.53515625  0.69287109  0.94287109  0.50830078  0.62109375  0.55322266
   0.63183594  0.63427734  0.69140625  0.68652344  0.71875     0.56787109
   0.71679688  0.67480469  0.60351562  0.65185547]]
After layer encoder_birnn_forward_l0_t4_f_output (1, 256) <class 'numpy.float16'> [[ 0.68115234  0.50830078  0.54052734  0.58886719  0.5625      0.57861328
   0.68554688  0.56738281  0.76171875  0.55664062  0.68115234  0.58447266
   0.63427734  0.625       0.48779297  0.5859375   0.55615234  0.56591797
   0.68457031  0.60449219  0.53955078  0.48339844  0.68701172  0.55322266
   0.61865234  0.60009766  0.625       0.56542969  0.66552734  0.53417969
   0.64990234  0.62646484  0.59179688  0.61523438  0.70507812  0.58935547
   0.54589844  0.58300781  0.70996094  0.52099609  0.63330078  0.57861328
   0.68945312  0.47998047  0.51660156  0.46118164  0.69677734  0.59033203
   0.55859375  0.46435547  0.46191406  0.56494141  0.8515625   0.47094727
   0.66601562  0.47290039  0.55810547  0.58056641  0.60009766  0.62207031
   0.50634766  0.57568359  0.54345703  0.64453125  0.53662109  0.57275391
   0.62255859  0.66015625  0.58154297  0.70996094  0.47583008  0.5859375
   0.72216797  0.59130859  0.52636719  0.82958984  0.58203125  0.81054688
   0.63916016  0.42041016  0.64941406  0.42407227  0.81689453  0.61767578
   0.65136719  0.59179688  0.50048828  0.72070312  0.83154297  0.58056641
   0.54736328  0.59570312  0.50146484  0.59277344  0.47094727  0.51708984
   0.671875    0.65673828  0.67138672  0.65673828  0.53076172  0.45288086
   0.51611328  0.64794922  0.63671875  0.54492188  0.60791016  0.61132812
   0.58544922  0.56689453  0.64990234  0.69726562  0.73779297  0.78466797
   0.61572266  0.59472656  0.68066406  0.68505859  0.59130859  0.57910156
   0.59765625  0.70800781  0.60742188  0.57958984  0.67626953  0.60400391
   0.44848633  0.57861328  0.57519531  0.76806641  0.56982422  0.62646484
   0.53808594  0.54150391  0.58203125  0.66748047  0.61279297  0.42285156
   0.71728516  0.63134766  0.57958984  0.59912109  0.63427734  0.60888672
   0.60449219  0.66943359  0.55273438  0.59521484  0.66894531  0.61083984
   0.65576172  0.54345703  0.61425781  0.59228516  0.56835938  0.54638672
   0.66943359  0.54541016  0.703125    0.60400391  0.69677734  0.58984375
   0.66064453  0.64355469  0.64990234  0.54394531  0.54785156  0.56787109
   0.47900391  0.54443359  0.46630859  0.79052734  0.59179688  0.71972656
   0.50878906  0.53710938  0.55761719  0.63623047  0.46679688  0.66650391
   0.56298828  0.47802734  0.66015625  0.61279297  0.56884766  0.60595703
   0.66259766  0.6328125   0.59863281  0.63769531  0.43334961  0.59667969
   0.66845703  0.61669922  0.49682617  0.56933594  0.93457031  0.46533203
   0.60498047  0.48974609  0.59667969  0.60742188  0.57421875  0.70849609
   0.60839844  0.55859375  0.66699219  0.42260742  0.51269531  0.62792969
   0.64355469  0.58447266  0.62939453  0.60498047  0.77148438  0.68847656
   0.53710938  0.65136719  0.52539062  0.51953125  0.52783203  0.63867188
   0.47607422  0.62939453  0.57177734  0.72265625  0.45141602  0.55908203
   0.61914062  0.56298828  0.57128906  0.75732422  0.56298828  0.62207031
   0.65820312  0.61865234  0.51660156  0.53808594  0.54394531  0.73339844
   0.54150391  0.66601562  0.921875    0.4831543   0.56201172  0.48095703
   0.55419922  0.57617188  0.61621094  0.64111328  0.73242188  0.47949219
   0.69042969  0.59765625  0.56640625  0.61816406]]
After layer _mul2060_0 (1, 256) <class 'numpy.float16'> [[ 0.08581543  0.11151123 -0.18945312 -0.1060791   0.26025391 -0.03167725
   0.28710938 -0.04782104 -0.03955078 -0.05041504  0.1595459   0.16101074
   0.03948975 -0.24023438  0.04000854 -0.01599121  0.11114502  0.19067383
  -0.05096436  0.09472656 -0.08447266 -0.21350098 -0.30834961  0.11279297
  -0.08233643 -0.05419922 -0.27734375 -0.04354858 -0.21899414  0.11425781
   0.12298584 -0.0848999   0.265625   -0.06774902  0.42407227  0.0914917
   0.09863281 -0.35302734 -0.31420898  0.04891968 -0.06286621  0.21081543
  -0.10552979  0.15576172 -0.30957031 -0.08557129  0.01556396  0.16906738
   0.12078857  0.05212402  0.01751709  0.02087402 -0.09399414 -0.11981201
   0.3425293   0.16503906 -0.24841309 -0.05181885  0.10974121 -0.02372742
   0.15869141 -0.06262207  0.0562439   0.46850586 -0.13427734  0.02902222
   0.12463379  0.35522461  0.08843994 -0.24279785  0.08947754 -0.01820374
  -0.44775391  0.12548828  0.15893555  0.42285156  0.22607422 -0.69970703
   0.16430664 -0.18286133  0.30786133 -0.13952637  0.03179932  0.07391357
  -0.14770508 -0.21044922  0.02572632 -0.38500977  0.08862305 -0.00324249
   0.10369873  0.10021973 -0.18859863 -0.10113525 -0.20483398 -0.03915405
  -0.19238281 -0.35522461  0.1784668   0.09820557 -0.11669922 -0.01101685
  -0.02645874  0.21386719 -0.20031738 -0.18200684  0.16418457  0.16540527
   0.14147949  0.13891602 -0.2824707  -0.25048828  0.546875    0.54394531
  -0.12792969  0.23803711  0.15881348  0.09985352  0.11413574  0.0486145
   0.01124573 -0.27734375  0.26025391 -0.10321045  0.51318359  0.00551224
   0.20996094  0.14892578 -0.23425293 -0.45385742  0.05029297  0.22692871
   0.0725708  -0.05194092  0.25244141  0.31176758  0.05258179  0.0970459
  -0.40478516 -0.06799316 -0.03356934  0.32495117 -0.29541016 -0.05993652
   0.22814941  0.02536011  0.15722656 -0.04299927  0.33911133 -0.07830811
   0.35961914 -0.18261719  0.40283203  0.16369629  0.08062744 -0.26708984
   0.35083008 -0.03988647  0.2121582   0.16503906  0.52050781  0.09332275
   0.1348877   0.25634766 -0.11279297  0.08886719 -0.02731323  0.24401855
  -0.1307373  -0.1628418   0.04867554  0.75537109 -0.10809326  0.40795898
  -0.1472168  -0.21972656  0.0526123   0.0562439  -0.0869751  -0.04394531
   0.31054688  0.16601562  0.14489746  0.17785645 -0.02041626 -0.20727539
  -0.11633301  0.27709961  0.11065674 -0.13623047  0.14599609 -0.19946289
  -0.26123047  0.24523926  0.06222534 -0.29003906 -0.01506042 -0.2088623
   0.20568848 -0.00850677  0.06756592 -0.25366211 -0.26025391 -0.17956543
  -0.1071167  -0.02453613  0.24768066  0.03445435  0.07373047  0.08093262
  -0.105896    0.15319824  0.12683105  0.10528564  0.52832031 -0.28955078
  -0.13024902 -0.30566406 -0.07196045 -0.07611084 -0.07366943  0.17138672
   0.18701172 -0.34448242  0.08276367 -0.57958984 -0.17822266 -0.10247803
   0.11700439 -0.02511597 -0.08013916 -0.53173828 -0.08685303  0.30541992
  -0.19091797  0.01098633  0.2310791   0.12219238 -0.07427979  0.4855957
   0.1472168   0.29174805 -0.84912109 -0.19177246  0.24682617 -0.13012695
   0.0859375  -0.08917236 -0.2244873   0.14038086 -0.4362793  -0.0319519
  -0.19250488 -0.1661377   0.00796509  0.14196777]]
After layer encoder_birnn_forward_l0_t4_i_output (1, 256) <class 'numpy.float16'> [[ 0.59472656  0.56982422  0.56591797  0.55273438  0.6328125   0.62158203
   0.70507812  0.52050781  0.44799805  0.58496094  0.56689453  0.61621094
   0.49682617  0.65380859  0.45410156  0.53955078  0.56152344  0.59570312
   0.63232422  0.56689453  0.50048828  0.38061523  0.59228516  0.57177734
   0.54833984  0.53417969  0.65039062  0.51416016  0.62011719  0.60351562
   0.60498047  0.61230469  0.67578125  0.58349609  0.74560547  0.51269531
   0.5546875   0.76708984  0.68798828  0.42675781  0.46533203  0.59521484
   0.65039062  0.54931641  0.73095703  0.59277344  0.56689453  0.61474609
   0.54345703  0.47680664  0.45263672  0.45776367  0.88037109  0.5625
   0.69238281  0.53417969  0.65771484  0.4909668   0.56201172  0.35717773
   0.56884766  0.57910156  0.49951172  0.68115234  0.51757812  0.52685547
   0.62451172  0.71240234  0.61425781  0.67578125  0.47363281  0.37329102
   0.75585938  0.59326172  0.60058594  0.75732422  0.62939453  0.83349609
   0.58935547  0.46313477  0.65283203  0.59228516  0.62939453  0.48730469
   0.67285156  0.62255859  0.55371094  0.72021484  0.68847656  0.46679688
   0.578125    0.47094727  0.46606445  0.58886719  0.4440918   0.40771484
   0.67773438  0.69091797  0.65771484  0.59912109  0.53564453  0.45532227
   0.57324219  0.69677734  0.64990234  0.55957031  0.51904297  0.55957031
   0.50878906  0.55224609  0.69287109  0.66015625  0.80419922  0.84619141
   0.62939453  0.6484375   0.59814453  0.66210938  0.53662109  0.48828125
   0.4675293   0.66894531  0.75341797  0.56054688  0.76660156  0.54394531
   0.57080078  0.56982422  0.56054688  0.78369141  0.44311523  0.63574219
   0.55664062  0.52880859  0.65478516  0.60009766  0.61425781  0.41015625
   0.63183594  0.48413086  0.50878906  0.68066406  0.62695312  0.51318359
   0.59716797  0.40332031  0.5078125   0.42333984  0.64941406  0.48266602
   0.73974609  0.63232422  0.73583984  0.68359375  0.51953125  0.65917969
   0.60888672  0.44726562  0.66796875  0.63867188  0.77587891  0.47827148
   0.63330078  0.64257812  0.61523438  0.51660156  0.52685547  0.59033203
   0.49243164  0.57080078  0.43432617  0.91552734  0.56738281  0.71289062
   0.61328125  0.55029297  0.47631836  0.42114258  0.48706055  0.56005859
   0.70507812  0.58300781  0.59619141  0.55517578  0.4597168   0.59863281
   0.50976562  0.67773438  0.60839844  0.60449219  0.42529297  0.54052734
   0.72363281  0.56738281  0.58203125  0.67138672  0.88330078  0.69238281
   0.60888672  0.53710938  0.55712891  0.65136719  0.59228516  0.57910156
   0.59814453  0.49780273  0.63183594  0.4465332   0.46533203  0.57470703
   0.61035156  0.55908203  0.65087891  0.57470703  0.78515625  0.64941406
   0.55517578  0.69677734  0.58740234  0.43261719  0.53710938  0.56103516
   0.60693359  0.61572266  0.6015625   0.85351562  0.61816406  0.50341797
   0.51904297  0.51757812  0.41162109  0.83349609  0.55859375  0.69140625
   0.59179688  0.49731445  0.58349609  0.45361328  0.54589844  0.71484375
   0.54638672  0.64501953  0.93212891  0.5859375   0.67333984  0.61767578
   0.56445312  0.55273438  0.62744141  0.57080078  0.73632812  0.42016602
   0.66845703  0.59667969  0.44238281  0.5703125 ]]
After layer encoder_birnn_forward_l0_t4_c_output (1, 256) <class 'numpy.float16'> [[ 0.20715332  0.41040039 -0.64404297 -0.30224609  0.78173828 -0.13037109
   0.71826172 -0.015625   -0.27905273 -0.0838623   0.52148438  0.5625
   0.15942383 -0.66455078  0.11761475  0.01089478  0.42626953  0.64306641
  -0.06884766  0.33251953 -0.23303223 -0.90234375 -0.83105469  0.4362793
  -0.19433594 -0.12231445 -0.73681641 -0.05566406 -0.65429688  0.49145508
   0.39672852 -0.2479248   0.67236328 -0.30126953  0.89111328  0.35839844
   0.38989258 -0.89306641 -0.76220703  0.06671143 -0.07629395  0.78222656
  -0.14953613  0.69677734 -0.93408203 -0.41796875 -0.05892944  0.47192383
   0.45141602  0.31005859 -0.01730347 -0.00639343 -0.46337891 -0.49072266
   0.8125      0.63916016 -0.83789062 -0.1583252   0.50634766 -0.0020752
   0.67675781 -0.15344238  0.16040039  0.96875    -0.55957031  0.09759521
   0.484375    0.80224609  0.33178711 -0.68603516  0.46630859  0.08282471
  -0.88037109  0.3503418   0.57226562  0.81005859  0.72167969 -0.95556641
   0.52539062 -0.83984375  0.83740234 -0.60302734 -0.1204834   0.14587402
  -0.37402344 -0.71582031  0.15539551 -0.82861328  0.14941406 -0.09875488
   0.48974609  0.33764648 -0.78759766 -0.34790039 -0.90722656 -0.40454102
  -0.54150391 -0.86669922  0.51464844  0.18933105 -0.54394531 -0.07806396
  -0.01314545  0.56152344 -0.50097656 -0.70410156  0.47949219  0.41894531
   0.43164062  0.46630859 -0.76171875 -0.69921875  0.93603516  0.90380859
  -0.24279785  0.73339844  0.43188477  0.15722656  0.37524414  0.12744141
   0.08776855 -0.640625    0.72265625 -0.3684082   0.94189453 -0.11419678
   0.86425781  0.50927734 -0.78466797 -0.87304688  0.22790527  0.61474609
   0.3059082  -0.19628906  0.74609375  0.81542969  0.30175781  0.61035156
  -0.86523438 -0.32983398 -0.01216125  0.86572266 -0.81152344 -0.12866211
   0.75390625 -0.01403809  0.61083984 -0.03610229  0.86621094 -0.1862793
   0.87207031 -0.58349609  0.91845703  0.60400391  0.26538086 -0.84619141
   0.87695312 -0.07983398  0.61132812  0.62255859  0.95849609  0.140625
   0.29345703  0.72265625 -0.19885254  0.24511719 -0.03363037  0.78759766
  -0.54248047 -0.53613281  0.21557617  0.96972656 -0.33813477  0.89746094
  -0.59472656 -0.83496094  0.13635254  0.13903809 -0.43505859 -0.15356445
   0.85693359  0.71875     0.42333984  0.53564453 -0.01586914 -0.63378906
  -0.38378906  0.78662109  0.41918945 -0.44946289  0.81738281 -0.63378906
  -0.67773438  0.78125     0.25830078 -0.84423828 -0.19433594 -0.78222656
   0.64208984 -0.15283203  0.05157471 -0.69140625 -0.86425781 -0.50488281
  -0.22119141 -0.20617676  0.75830078  0.11279297  0.31689453  0.10821533
  -0.2890625   0.48339844  0.42358398  0.34985352  0.91943359 -0.75878906
  -0.51025391 -0.79394531 -0.32568359 -0.40332031 -0.30273438  0.49560547
   0.73632812 -0.88574219  0.27563477 -0.93945312 -0.74121094 -0.31860352
   0.33837891 -0.02201843 -0.32983398 -0.88525391 -0.28222656  0.81933594
  -0.53417969 -0.02005005  0.78759766  0.47875977 -0.15380859  0.95263672
   0.64550781  0.73388672 -0.95947266 -0.80810547  0.77929688 -0.54931641
   0.35424805 -0.25830078 -0.66796875  0.48754883 -0.83154297 -0.1619873
  -0.47290039 -0.4921875  -0.06860352  0.34472656]]
After layer _mul2061_0 (1, 256) <class 'numpy.float16'> [[  1.23229980e-01   2.33886719e-01  -3.64501953e-01  -1.67114258e-01
    4.94628906e-01  -8.10546875e-02   5.06347656e-01  -8.13293457e-03
   -1.25000000e-01  -4.90417480e-02   2.95654297e-01   3.46679688e-01
    7.92236328e-02  -4.34570312e-01   5.34057617e-02   5.87844849e-03
    2.39379883e-01   3.83056641e-01  -4.35485840e-02   1.88476562e-01
   -1.16638184e-01  -3.43505859e-01  -4.92187500e-01   2.49511719e-01
   -1.06567383e-01  -6.53076172e-02  -4.79248047e-01  -2.86254883e-02
   -4.05761719e-01   2.96630859e-01   2.39990234e-01  -1.51855469e-01
    4.54345703e-01  -1.75781250e-01   6.64550781e-01   1.83715820e-01
    2.16308594e-01  -6.85058594e-01  -5.24414062e-01   2.84729004e-02
   -3.54919434e-02   4.65576172e-01  -9.72290039e-02   3.82812500e-01
   -6.82617188e-01  -2.47802734e-01  -3.34167480e-02   2.90039062e-01
    2.45361328e-01   1.47827148e-01  -7.83538818e-03  -2.92587280e-03
   -4.07958984e-01  -2.76123047e-01   5.62500000e-01   3.41308594e-01
   -5.51269531e-01  -7.77587891e-02   2.84667969e-01  -7.41004944e-04
    3.85009766e-01  -8.88671875e-02   8.01391602e-02   6.59667969e-01
   -2.89550781e-01   5.14221191e-02   3.02490234e-01   5.71289062e-01
    2.03857422e-01  -4.63623047e-01   2.20825195e-01   3.09143066e-02
   -6.65527344e-01   2.07885742e-01   3.43750000e-01   6.13281250e-01
    4.54101562e-01  -7.96386719e-01   3.09570312e-01  -3.88916016e-01
    5.46875000e-01  -3.57177734e-01  -7.58056641e-02   7.11059570e-02
   -2.51708984e-01  -4.45556641e-01   8.60595703e-02  -5.96679688e-01
    1.02844238e-01  -4.61120605e-02   2.83203125e-01   1.59057617e-01
   -3.67187500e-01  -2.04833984e-01  -4.02832031e-01  -1.64916992e-01
   -3.66943359e-01  -5.98632812e-01   3.38378906e-01   1.13403320e-01
   -2.91259766e-01  -3.55529785e-02  -7.53402710e-03   3.91357422e-01
   -3.25683594e-01  -3.94042969e-01   2.48901367e-01   2.34375000e-01
    2.19604492e-01   2.57568359e-01  -5.27832031e-01  -4.61669922e-01
    7.52929688e-01   7.64648438e-01  -1.52832031e-01   4.75585938e-01
    2.58300781e-01   1.04125977e-01   2.01416016e-01   6.22253418e-02
    4.10461426e-02  -4.28466797e-01   5.44433594e-01  -2.06542969e-01
    7.22167969e-01  -6.21032715e-02   4.93408203e-01   2.90283203e-01
   -4.39941406e-01  -6.84082031e-01   1.01013184e-01   3.90869141e-01
    1.70288086e-01  -1.03820801e-01   4.88525391e-01   4.89257812e-01
    1.85302734e-01   2.50244141e-01  -5.46875000e-01  -1.59667969e-01
   -6.18743896e-03   5.89355469e-01  -5.08789062e-01  -6.60400391e-02
    4.50195312e-01  -5.66101074e-03   3.10302734e-01  -1.52816772e-02
    5.62500000e-01  -8.99047852e-02   6.45019531e-01  -3.68896484e-01
    6.75781250e-01   4.12841797e-01   1.37817383e-01  -5.57617188e-01
    5.34179688e-01  -3.57055664e-02   4.08447266e-01   3.97705078e-01
    7.43652344e-01   6.72607422e-02   1.85791016e-01   4.64355469e-01
   -1.22314453e-01   1.26586914e-01  -1.77154541e-02   4.64843750e-01
   -2.67089844e-01  -3.05908203e-01   9.36279297e-02   8.87695312e-01
   -1.91894531e-01   6.39648438e-01  -3.64746094e-01  -4.59472656e-01
    6.49414062e-02   5.85632324e-02  -2.11914062e-01  -8.59985352e-02
    6.04003906e-01   4.18945312e-01   2.52441406e-01   2.97363281e-01
   -7.29370117e-03  -3.79394531e-01  -1.95678711e-01   5.33203125e-01
    2.55126953e-01  -2.71728516e-01   3.47656250e-01  -3.42529297e-01
   -4.90478516e-01   4.43359375e-01   1.50390625e-01  -5.66894531e-01
   -1.71630859e-01  -5.41503906e-01   3.90869141e-01  -8.20922852e-02
    2.87322998e-02  -4.50439453e-01  -5.11718750e-01  -2.92480469e-01
   -1.32324219e-01  -1.02661133e-01   4.79003906e-01   5.03540039e-02
    1.47460938e-01   6.21948242e-02  -1.76391602e-01   2.70263672e-01
    2.75634766e-01   2.01049805e-01   7.21679688e-01  -4.92675781e-01
   -2.83203125e-01  -5.53222656e-01  -1.91284180e-01  -1.74438477e-01
   -1.62597656e-01   2.78076172e-01   4.47021484e-01  -5.45410156e-01
    1.65771484e-01  -8.01757812e-01  -4.58251953e-01  -1.60400391e-01
    1.75659180e-01  -1.13983154e-02  -1.35742188e-01  -7.37792969e-01
   -1.57592773e-01   5.66406250e-01  -3.16162109e-01  -9.97161865e-03
    4.59472656e-01   2.17163086e-01  -8.39843750e-02   6.81152344e-01
    3.52783203e-01   4.73388672e-01  -8.94531250e-01  -4.73388672e-01
    5.24902344e-01  -3.39355469e-01   1.99951172e-01  -1.42822266e-01
   -4.19189453e-01   2.78320312e-01  -6.12304688e-01  -6.80541992e-02
   -3.16162109e-01  -2.93701172e-01  -3.03497314e-02   1.96655273e-01]]
After layer encoder_birnn_forward_l0_t4_state_0 (1, 256) <class 'numpy.float16'> [[  2.08984375e-01   3.45458984e-01  -5.53710938e-01  -2.73193359e-01
    7.54882812e-01  -1.12731934e-01   7.93457031e-01  -5.59692383e-02
   -1.64550781e-01  -9.94873047e-02   4.55078125e-01   5.07812500e-01
    1.18713379e-01  -6.74804688e-01   9.33837891e-02  -1.01165771e-02
    3.50585938e-01   5.73730469e-01  -9.44824219e-02   2.83203125e-01
   -2.01171875e-01  -5.57128906e-01  -8.00781250e-01   3.62304688e-01
   -1.88964844e-01  -1.19506836e-01  -7.56835938e-01  -7.21435547e-02
   -6.25000000e-01   4.10888672e-01   3.63037109e-01  -2.36816406e-01
    7.19726562e-01  -2.43530273e-01   1.08886719e+00   2.75146484e-01
    3.14941406e-01  -1.03808594e+00  -8.38867188e-01   7.73925781e-02
   -9.83886719e-02   6.76269531e-01  -2.02758789e-01   5.38574219e-01
   -9.92187500e-01  -3.33496094e-01  -1.78527832e-02   4.58984375e-01
    3.66210938e-01   1.99951172e-01   9.68170166e-03   1.79443359e-02
   -5.01953125e-01  -3.95996094e-01   9.05273438e-01   5.06347656e-01
   -7.99804688e-01  -1.29638672e-01   3.94531250e-01  -2.44750977e-02
    5.43945312e-01  -1.51489258e-01   1.36352539e-01   1.12792969e+00
   -4.23828125e-01   8.04443359e-02   4.27246094e-01   9.26757812e-01
    2.92236328e-01  -7.06542969e-01   3.10302734e-01   1.27105713e-02
   -1.11328125e+00   3.33496094e-01   5.02929688e-01   1.03613281e+00
    6.80175781e-01  -1.49609375e+00   4.73876953e-01  -5.71777344e-01
    8.54492188e-01  -4.96582031e-01  -4.40063477e-02   1.45019531e-01
   -3.99414062e-01  -6.56250000e-01   1.11816406e-01  -9.81445312e-01
    1.91406250e-01  -4.93469238e-02   3.86962891e-01   2.59277344e-01
   -5.55664062e-01  -3.05908203e-01  -6.07421875e-01  -2.04101562e-01
   -5.59570312e-01  -9.54101562e-01   5.16601562e-01   2.11669922e-01
   -4.07958984e-01  -4.65698242e-02  -3.39965820e-02   6.05468750e-01
   -5.25878906e-01  -5.76171875e-01   4.13085938e-01   3.99902344e-01
    3.61083984e-01   3.96484375e-01  -8.10546875e-01  -7.11914062e-01
    1.29980469e+00   1.30859375e+00  -2.80761719e-01   7.13867188e-01
    4.16992188e-01   2.03979492e-01   3.15429688e-01   1.10839844e-01
    5.23071289e-02  -7.06054688e-01   8.04687500e-01  -3.09814453e-01
    1.23535156e+00  -5.65795898e-02   7.03125000e-01   4.39208984e-01
   -6.74316406e-01  -1.13769531e+00   1.51367188e-01   6.17675781e-01
    2.42919922e-01  -1.55761719e-01   7.41210938e-01   8.00781250e-01
    2.37915039e-01   3.47167969e-01  -9.51660156e-01  -2.27661133e-01
   -3.97644043e-02   9.14062500e-01  -8.04199219e-01  -1.25976562e-01
    6.78222656e-01   1.96990967e-02   4.67529297e-01  -5.82885742e-02
    9.01367188e-01  -1.68212891e-01   1.00488281e+00  -5.51757812e-01
    1.07812500e+00   5.76660156e-01   2.18505859e-01  -8.24707031e-01
    8.84765625e-01  -7.55615234e-02   6.20605469e-01   5.62500000e-01
    1.26367188e+00   1.60644531e-01   3.20800781e-01   7.20703125e-01
   -2.35107422e-01   2.15454102e-01  -4.50439453e-02   7.08984375e-01
   -3.97949219e-01  -4.68750000e-01   1.42333984e-01   1.64257812e+00
   -3.00048828e-01   1.04785156e+00  -5.11718750e-01  -6.79199219e-01
    1.17553711e-01   1.14807129e-01  -2.98828125e-01  -1.29882812e-01
    9.14550781e-01   5.84960938e-01   3.97460938e-01   4.75097656e-01
   -2.77099609e-02  -5.86914062e-01  -3.12011719e-01   8.10546875e-01
    3.65722656e-01  -4.07958984e-01   4.93652344e-01  -5.41992188e-01
   -7.51953125e-01   6.88476562e-01   2.12646484e-01  -8.56933594e-01
   -1.86645508e-01  -7.50488281e-01   5.96679688e-01  -9.05761719e-02
    9.63134766e-02  -7.04101562e-01  -7.71972656e-01  -4.72167969e-01
   -2.39501953e-01  -1.27197266e-01   7.26562500e-01   8.48388672e-02
    2.21191406e-01   1.43066406e-01  -2.82226562e-01   4.23339844e-01
    4.02343750e-01   3.06396484e-01   1.25000000e+00  -7.82226562e-01
   -4.13574219e-01  -8.58886719e-01  -2.63183594e-01  -2.50488281e-01
   -2.36328125e-01   4.49462891e-01   6.33789062e-01  -8.89648438e-01
    2.48535156e-01  -1.38085938e+00  -6.36718750e-01  -2.62939453e-01
    2.92724609e-01  -3.64990234e-02  -2.15820312e-01  -1.26953125e+00
   -2.44384766e-01   8.72070312e-01  -5.06835938e-01   1.01470947e-03
    6.90429688e-01   3.39355469e-01  -1.58203125e-01   1.16699219e+00
    5.00000000e-01   7.65136719e-01  -1.74414062e+00  -6.65039062e-01
    7.71484375e-01  -4.69482422e-01   2.85888672e-01  -2.31933594e-01
   -6.43554688e-01   4.18701172e-01  -1.04882812e+00  -9.99755859e-02
   -5.08789062e-01  -4.59960938e-01  -2.23846436e-02   3.38623047e-01]]
After layer activation1030_output (1, 256) <class 'numpy.float16'> [[ 0.20605469  0.33227539 -0.50341797 -0.26660156  0.63818359 -0.11224365
   0.66015625 -0.0559082  -0.16308594 -0.09918213  0.42602539  0.46826172
   0.11816406 -0.58789062  0.09313965 -0.01011658  0.33691406  0.51806641
  -0.09417725  0.27587891 -0.19848633 -0.50585938 -0.66455078  0.34716797
  -0.18676758 -0.11895752 -0.63916016 -0.07202148 -0.5546875   0.38916016
   0.34790039 -0.23254395  0.61669922 -0.23876953  0.79638672  0.26831055
   0.30493164 -0.77734375 -0.68505859  0.07720947 -0.0980835   0.58886719
  -0.20007324  0.49194336 -0.75830078 -0.32177734 -0.01785278  0.42919922
   0.35058594  0.1973877   0.0096817   0.01794434 -0.46362305 -0.37646484
   0.71875     0.46704102 -0.6640625  -0.12890625  0.37524414 -0.0244751
   0.49584961 -0.15039062  0.13549805  0.81054688 -0.40014648  0.08026123
   0.40307617  0.72900391  0.28417969 -0.60839844  0.30078125  0.01271057
  -0.80517578  0.32177734  0.46435547  0.77636719  0.59179688 -0.90429688
   0.44140625 -0.51660156  0.69335938 -0.45947266 -0.04397583  0.14404297
  -0.37939453 -0.57568359  0.11132812 -0.75390625  0.18908691 -0.04931641
   0.36865234  0.25366211 -0.50488281 -0.29663086 -0.54248047 -0.20129395
  -0.5078125  -0.74169922  0.47509766  0.20861816 -0.38671875 -0.04653931
  -0.03399658  0.54101562 -0.48217773 -0.52001953  0.39111328  0.37988281
   0.34619141  0.37695312 -0.66992188 -0.61181641  0.86181641  0.86376953
  -0.27368164  0.61328125  0.39428711  0.20117188  0.30541992  0.1104126
   0.05224609 -0.60839844  0.66650391 -0.30029297  0.84423828 -0.05651855
   0.60644531  0.41308594 -0.58789062 -0.81347656  0.15026855  0.54931641
   0.23828125 -0.15454102  0.62988281  0.66455078  0.23352051  0.33374023
  -0.74072266 -0.22375488 -0.03973389  0.72314453 -0.66650391 -0.12536621
   0.59033203  0.0196991   0.4362793  -0.05822754  0.71679688 -0.16662598
   0.76367188 -0.50195312  0.79248047  0.52001953  0.21508789 -0.67773438
   0.70898438 -0.07543945  0.55175781  0.50976562  0.85205078  0.15930176
   0.31030273  0.6171875  -0.23083496  0.2121582  -0.04501343  0.60986328
  -0.37817383 -0.43725586  0.14135742  0.92773438 -0.29125977  0.78076172
  -0.47119141 -0.59082031  0.11700439  0.11431885 -0.2902832  -0.12915039
   0.72314453  0.52636719  0.37768555  0.44238281 -0.02770996 -0.52783203
  -0.30224609  0.66992188  0.3503418  -0.38671875  0.45703125 -0.49438477
  -0.63623047  0.59716797  0.20947266 -0.69482422 -0.18444824 -0.63525391
   0.53466797 -0.09033203  0.0960083  -0.60693359 -0.64794922 -0.43994141
  -0.23498535 -0.12646484  0.62109375  0.08465576  0.21765137  0.14208984
  -0.27490234  0.3996582   0.38183594  0.29711914  0.84814453 -0.65380859
  -0.39160156 -0.69580078 -0.25732422 -0.24536133 -0.23205566  0.42138672
   0.56054688 -0.71142578  0.24353027 -0.88134766 -0.5625     -0.25708008
   0.28466797 -0.03646851 -0.21252441 -0.85351562 -0.23962402  0.70263672
  -0.4675293   0.00101471  0.59814453  0.3269043  -0.15686035  0.82324219
   0.4621582   0.64404297 -0.94091797 -0.58154297  0.64794922 -0.43774414
   0.27832031 -0.22790527 -0.56738281  0.39575195 -0.78125    -0.09967041
  -0.46899414 -0.42993164 -0.02238464  0.32617188]]
After layer encoder_birnn_forward_l0_t4_out_0 (1, 256) <class 'numpy.float16'> [[  1.38549805e-01   2.03247070e-01  -3.17871094e-01  -1.76269531e-01
    3.91601562e-01  -7.36083984e-02   5.08789062e-01  -3.36303711e-02
   -1.05407715e-01  -6.34155273e-02   2.62695312e-01   2.98583984e-01
    7.12280273e-02  -4.04541016e-01   4.56237793e-02  -5.61523438e-03
    2.16308594e-01   3.00781250e-01  -7.16552734e-02   1.83837891e-01
   -1.13220215e-01  -2.54150391e-01  -4.89257812e-01   2.31445312e-01
   -1.15722656e-01  -6.67114258e-02  -4.51660156e-01  -4.66918945e-02
   -2.91748047e-01   2.38647461e-01   2.29003906e-01  -1.56982422e-01
    3.25927734e-01  -1.44409180e-01   4.82910156e-01   1.53686523e-01
    1.95922852e-01  -4.29931641e-01  -2.82226562e-01   4.48303223e-02
   -5.94787598e-02   3.62304688e-01  -1.19018555e-01   3.02490234e-01
   -4.66064453e-01  -2.04101562e-01  -1.38092041e-02   2.76123047e-01
    2.14965820e-01   1.05224609e-01   4.37545776e-03   1.14669800e-02
   -4.10644531e-01  -1.84936523e-01   4.57519531e-01   2.23876953e-01
   -3.78662109e-01  -7.72705078e-02   2.39135742e-01  -1.49993896e-02
    2.48168945e-01  -9.20410156e-02   7.01904297e-02   5.59570312e-01
   -2.28149414e-01   4.97436523e-02   2.76611328e-01   4.27246094e-01
    1.73706055e-01  -3.64013672e-01   1.97265625e-01   8.09478760e-03
   -6.10351562e-01   1.97387695e-01   2.76611328e-01   6.63574219e-01
    3.73046875e-01  -7.72949219e-01   3.12988281e-01  -2.84423828e-01
    4.94384766e-01  -2.17285156e-01  -3.90014648e-02   8.82568359e-02
   -2.62207031e-01  -3.42773438e-01   6.31103516e-02  -4.95849609e-01
    1.51977539e-01  -3.20129395e-02   2.20092773e-01   1.51733398e-01
   -2.19360352e-01  -2.07153320e-01  -2.92236328e-01  -1.39526367e-01
   -3.36669922e-01  -4.98291016e-01   3.19580078e-01   1.51977539e-01
   -2.15209961e-01  -2.78167725e-02  -1.86462402e-02   3.85986328e-01
   -3.23486328e-01  -2.80517578e-01   2.38159180e-01   2.58300781e-01
    2.32910156e-01   2.08007812e-01  -4.76318359e-01  -3.82080078e-01
    6.92871094e-01   6.77734375e-01  -1.82861328e-01   3.83544922e-01
    2.50976562e-01   1.50390625e-01   1.92626953e-01   7.21435547e-02
    3.19824219e-02  -4.53857422e-01   4.27001953e-01  -1.85668945e-01
    5.53222656e-01  -3.77807617e-02   3.22753906e-01   2.11181641e-01
   -3.47900391e-01  -6.68945312e-01   9.80834961e-02   4.02343750e-01
    1.39526367e-01  -9.60693359e-02   3.63525391e-01   3.72070312e-01
    1.56005859e-01   2.01904297e-01  -5.26855469e-01  -1.40747070e-01
   -2.25219727e-02   4.57519531e-01  -4.17236328e-01  -7.97729492e-02
    3.41796875e-01   1.26113892e-02   2.60009766e-01  -3.46679688e-02
    3.74755859e-01  -9.64965820e-02   5.85937500e-01  -2.86132812e-01
    5.10253906e-01   2.60498047e-01   1.22131348e-01  -3.31542969e-01
    4.04296875e-01  -4.52270508e-02   4.03808594e-01   3.28857422e-01
    5.40039062e-01   1.02661133e-01   1.73339844e-01   4.02832031e-01
   -1.64550781e-01   1.18591309e-01  -2.83813477e-02   3.41064453e-01
   -1.79809570e-01  -2.50976562e-01   8.22143555e-02   8.43261719e-01
   -1.92749023e-01   5.72753906e-01  -2.32910156e-01  -3.30566406e-01
    7.18994141e-02   7.36694336e-02  -1.67968750e-01  -8.81347656e-02
    4.47021484e-01   2.51708984e-01   2.40478516e-01   2.91259766e-01
   -1.59606934e-02  -3.45214844e-01  -1.90185547e-01   3.79150391e-01
    2.20458984e-01  -2.65869141e-01   2.24365234e-01  -3.03222656e-01
   -4.70947266e-01   3.78417969e-01   1.12121582e-01  -4.57275391e-01
   -1.68945312e-01  -3.93554688e-01   3.40576172e-01  -5.79223633e-02
    5.44128418e-02  -3.20556641e-01  -4.25781250e-01  -3.02246094e-01
   -1.52832031e-01  -8.62426758e-02   4.38476562e-01   4.42199707e-02
    9.32006836e-02   9.03320312e-02  -1.79321289e-01   2.26928711e-01
    2.62207031e-01   1.98120117e-01   7.03125000e-01  -4.87548828e-01
   -2.33032227e-01  -5.08789062e-01  -1.71875000e-01  -1.44897461e-01
   -1.38183594e-01   2.80761719e-01   2.84423828e-01  -4.12353516e-01
    1.56738281e-01  -5.24902344e-01  -3.54248047e-01  -1.58325195e-01
    1.83837891e-01  -2.02941895e-02  -1.15173340e-01  -6.16699219e-01
   -1.53198242e-01   4.56054688e-01  -3.14941406e-01   5.84602356e-04
    3.07617188e-01   1.57714844e-01  -9.50317383e-02   6.27441406e-01
    2.47314453e-01   4.46289062e-01  -8.87207031e-01  -2.95654297e-01
    4.02343750e-01  -2.42187500e-01   1.75903320e-01  -1.44531250e-01
   -3.92333984e-01   2.71728516e-01  -5.61523438e-01  -5.66101074e-02
   -3.36181641e-01  -2.90039062e-01  -1.35116577e-02   2.12646484e-01]]
After layer expand_dims1036_0 (1, 1, 256) <class 'numpy.float16'> [[[  1.38549805e-01   2.03247070e-01  -3.17871094e-01  -1.76269531e-01
     3.91601562e-01  -7.36083984e-02   5.08789062e-01  -3.36303711e-02
    -1.05407715e-01  -6.34155273e-02   2.62695312e-01   2.98583984e-01
     7.12280273e-02  -4.04541016e-01   4.56237793e-02  -5.61523438e-03
     2.16308594e-01   3.00781250e-01  -7.16552734e-02   1.83837891e-01
    -1.13220215e-01  -2.54150391e-01  -4.89257812e-01   2.31445312e-01
    -1.15722656e-01  -6.67114258e-02  -4.51660156e-01  -4.66918945e-02
    -2.91748047e-01   2.38647461e-01   2.29003906e-01  -1.56982422e-01
     3.25927734e-01  -1.44409180e-01   4.82910156e-01   1.53686523e-01
     1.95922852e-01  -4.29931641e-01  -2.82226562e-01   4.48303223e-02
    -5.94787598e-02   3.62304688e-01  -1.19018555e-01   3.02490234e-01
    -4.66064453e-01  -2.04101562e-01  -1.38092041e-02   2.76123047e-01
     2.14965820e-01   1.05224609e-01   4.37545776e-03   1.14669800e-02
    -4.10644531e-01  -1.84936523e-01   4.57519531e-01   2.23876953e-01
    -3.78662109e-01  -7.72705078e-02   2.39135742e-01  -1.49993896e-02
     2.48168945e-01  -9.20410156e-02   7.01904297e-02   5.59570312e-01
    -2.28149414e-01   4.97436523e-02   2.76611328e-01   4.27246094e-01
     1.73706055e-01  -3.64013672e-01   1.97265625e-01   8.09478760e-03
    -6.10351562e-01   1.97387695e-01   2.76611328e-01   6.63574219e-01
     3.73046875e-01  -7.72949219e-01   3.12988281e-01  -2.84423828e-01
     4.94384766e-01  -2.17285156e-01  -3.90014648e-02   8.82568359e-02
    -2.62207031e-01  -3.42773438e-01   6.31103516e-02  -4.95849609e-01
     1.51977539e-01  -3.20129395e-02   2.20092773e-01   1.51733398e-01
    -2.19360352e-01  -2.07153320e-01  -2.92236328e-01  -1.39526367e-01
    -3.36669922e-01  -4.98291016e-01   3.19580078e-01   1.51977539e-01
    -2.15209961e-01  -2.78167725e-02  -1.86462402e-02   3.85986328e-01
    -3.23486328e-01  -2.80517578e-01   2.38159180e-01   2.58300781e-01
     2.32910156e-01   2.08007812e-01  -4.76318359e-01  -3.82080078e-01
     6.92871094e-01   6.77734375e-01  -1.82861328e-01   3.83544922e-01
     2.50976562e-01   1.50390625e-01   1.92626953e-01   7.21435547e-02
     3.19824219e-02  -4.53857422e-01   4.27001953e-01  -1.85668945e-01
     5.53222656e-01  -3.77807617e-02   3.22753906e-01   2.11181641e-01
    -3.47900391e-01  -6.68945312e-01   9.80834961e-02   4.02343750e-01
     1.39526367e-01  -9.60693359e-02   3.63525391e-01   3.72070312e-01
     1.56005859e-01   2.01904297e-01  -5.26855469e-01  -1.40747070e-01
    -2.25219727e-02   4.57519531e-01  -4.17236328e-01  -7.97729492e-02
     3.41796875e-01   1.26113892e-02   2.60009766e-01  -3.46679688e-02
     3.74755859e-01  -9.64965820e-02   5.85937500e-01  -2.86132812e-01
     5.10253906e-01   2.60498047e-01   1.22131348e-01  -3.31542969e-01
     4.04296875e-01  -4.52270508e-02   4.03808594e-01   3.28857422e-01
     5.40039062e-01   1.02661133e-01   1.73339844e-01   4.02832031e-01
    -1.64550781e-01   1.18591309e-01  -2.83813477e-02   3.41064453e-01
    -1.79809570e-01  -2.50976562e-01   8.22143555e-02   8.43261719e-01
    -1.92749023e-01   5.72753906e-01  -2.32910156e-01  -3.30566406e-01
     7.18994141e-02   7.36694336e-02  -1.67968750e-01  -8.81347656e-02
     4.47021484e-01   2.51708984e-01   2.40478516e-01   2.91259766e-01
    -1.59606934e-02  -3.45214844e-01  -1.90185547e-01   3.79150391e-01
     2.20458984e-01  -2.65869141e-01   2.24365234e-01  -3.03222656e-01
    -4.70947266e-01   3.78417969e-01   1.12121582e-01  -4.57275391e-01
    -1.68945312e-01  -3.93554688e-01   3.40576172e-01  -5.79223633e-02
     5.44128418e-02  -3.20556641e-01  -4.25781250e-01  -3.02246094e-01
    -1.52832031e-01  -8.62426758e-02   4.38476562e-01   4.42199707e-02
     9.32006836e-02   9.03320312e-02  -1.79321289e-01   2.26928711e-01
     2.62207031e-01   1.98120117e-01   7.03125000e-01  -4.87548828e-01
    -2.33032227e-01  -5.08789062e-01  -1.71875000e-01  -1.44897461e-01
    -1.38183594e-01   2.80761719e-01   2.84423828e-01  -4.12353516e-01
     1.56738281e-01  -5.24902344e-01  -3.54248047e-01  -1.58325195e-01
     1.83837891e-01  -2.02941895e-02  -1.15173340e-01  -6.16699219e-01
    -1.53198242e-01   4.56054688e-01  -3.14941406e-01   5.84602356e-04
     3.07617188e-01   1.57714844e-01  -9.50317383e-02   6.27441406e-01
     2.47314453e-01   4.46289062e-01  -8.87207031e-01  -2.95654297e-01
     4.02343750e-01  -2.42187500e-01   1.75903320e-01  -1.44531250e-01
    -3.92333984e-01   2.71728516e-01  -5.61523438e-01  -5.66101074e-02
    -3.36181641e-01  -2.90039062e-01  -1.35116577e-02   2.12646484e-01]]]
After layer encoder_birnn_forward_l0_t5_i2h_output (1, 1024) <class 'numpy.float16'> [[ 0.0737915  -0.0458374   0.06152344 ...,  0.03591919  0.03396606
   0.02903748]]
After layer encoder_birnn_forward_l0_t5_h2h_output (1, 1024) <class 'numpy.float16'> [[ 0.50732422  0.53271484  0.32373047 ...,  1.11523438  0.57421875
   0.93164062]]
After layer _plus1031_0 (1, 1024) <class 'numpy.float16'> [[ 0.58105469  0.48681641  0.38525391 ...,  1.15136719  0.60839844
   0.96044922]]
After layer encoder_birnn_forward_l0_t5_slice_output0 (1, 256) <class 'numpy.float16'> [[ 0.58105469  0.48681641  0.38525391  0.36694336  0.82421875  0.79931641
   1.421875    0.07305908 -0.3984375   0.53466797  0.43701172  0.77685547
  -0.06072998  0.97216797 -0.38452148  0.22314453  0.39282227  0.62451172
   0.78222656  0.42724609 -0.02960205 -0.87744141  0.55615234  0.41845703
   0.25878906  0.21704102  0.91552734  0.03170776  0.73779297  0.70117188
   0.68847656  0.64013672  1.07421875  0.64257812  1.7578125   0.0736084
   0.34741211  1.85546875  1.26464844 -0.62597656 -0.29980469  0.56835938
   1.07617188  0.23706055  1.66015625  0.57763672  0.37329102  0.66992188
   0.23950195 -0.16943359 -0.28393555 -0.28735352  3.26171875  0.3527832
   1.27539062  0.11083984  1.07324219  0.01983643  0.42138672 -0.99023438
   0.42138672  0.42382812 -0.10498047  1.21289062  0.03918457  0.16015625
   0.83496094  1.4609375   0.73632812  1.21289062 -0.18945312 -0.93554688
   1.86523438  0.60498047  0.53271484  1.89453125  0.81103516  2.609375
   0.58691406 -0.41943359  1.07421875  0.54003906  0.73779297 -0.14770508
   1.1171875   0.78662109  0.35595703  1.52441406  1.2109375  -0.24682617
   0.56640625 -0.1887207  -0.21264648  0.55419922 -0.4609375  -0.72900391
   1.13769531  1.25683594  1.03320312  0.57080078  0.24853516 -0.31201172
   0.44140625  1.35839844  0.89306641  0.28393555  0.11065674  0.30029297
  -0.02099609  0.24243164  1.24121094  1.05078125  2.25195312  2.76757812
   0.78222656  0.96875     0.55175781  1.02539062  0.26391602 -0.22070312
  -0.24084473  1.16601562  1.84570312  0.40527344  1.83105469  0.27490234
   0.43798828  0.45361328  0.31152344  2.0234375  -0.38867188  0.92333984
   0.44995117  0.23632812  0.984375    0.69042969  0.72509766 -0.61230469
   0.83496094 -0.08557129  0.06286621  1.23535156  0.81640625  0.04263306
   0.63671875 -0.64990234  0.0319519  -0.41357422  1.03417969 -0.12634277
   1.6640625   0.86572266  1.640625    1.24609375  0.08032227  1.05175781
   0.70361328 -0.31201172  1.10546875  0.91162109  1.95019531 -0.18310547
   0.84277344  0.95507812  0.73779297  0.04095459  0.15795898  0.57568359
  -0.10614014  0.42602539 -0.45458984  3.90039062  0.45605469  1.39941406
   0.68896484  0.31884766 -0.18640137 -0.49951172 -0.08300781  0.40356445
   1.37402344  0.48095703  0.56445312  0.31152344 -0.26855469  0.64160156
   0.09307861  1.12695312  0.74316406  0.6484375  -0.5234375   0.19421387
   1.5234375   0.4128418   0.50439453  1.10742188  3.19335938  1.265625
   0.73242188  0.18212891  0.31982422  0.94189453  0.60351562  0.66699219
   0.61083984 -0.01722717  0.890625   -0.36694336 -0.33789062  0.45581055
   0.72363281  0.39379883  1.08398438  0.484375    2.09570312  1.08496094
   0.35302734  1.37207031  0.58886719 -0.41235352  0.25878906  0.40161133
   0.56445312  0.75244141  0.62207031  2.9140625   0.76660156 -0.0692749
   0.03286743  0.05810547 -0.59375     2.57421875  0.40429688  1.27539062
   0.65185547 -0.06512451  0.48803711 -0.3215332   0.1875      1.53710938
   0.28759766  0.88134766  4.3046875   0.55712891  1.11816406  0.73535156
   0.42382812  0.30224609  0.83398438  0.46728516  1.59082031 -0.56054688
   1.09375     0.63818359 -0.40063477  0.41918945]]
After layer encoder_birnn_forward_l0_t5_slice_output1 (1, 256) <class 'numpy.float16'> [[  1.15332031e+00   7.48901367e-02   2.11914062e-01   5.19531250e-01
    3.78173828e-01   4.54101562e-01   1.32421875e+00   3.75732422e-01
    1.88769531e+00   3.34472656e-01   1.27343750e+00   5.58593750e-01
    8.85253906e-01   8.49609375e-01  -1.52099609e-01   5.02929688e-01
    4.32373047e-01   3.80859375e-01   1.14453125e+00   6.65039062e-01
    1.73095703e-01  -1.74316406e-01   1.25195312e+00   2.67822266e-01
    7.34863281e-01   6.40625000e-01   7.70019531e-01   3.84765625e-01
    1.04394531e+00   2.49633789e-01   1.04492188e+00   8.76953125e-01
    5.48828125e-01   7.17773438e-01   1.42187500e+00   4.64843750e-01
    2.27050781e-01   6.08886719e-01   1.49023438e+00   8.55712891e-02
    8.28613281e-01   5.14648438e-01   1.27929688e+00  -1.56005859e-01
    1.14379883e-01  -2.78564453e-01   1.35253906e+00   6.47460938e-01
    3.00292969e-01  -2.09838867e-01  -2.71972656e-01   4.52392578e-01
    2.71875000e+00  -2.18139648e-01   1.10058594e+00  -2.85156250e-01
    3.29101562e-01   5.69335938e-01   6.53808594e-01   7.75390625e-01
    2.90527344e-02   4.88769531e-01   1.97265625e-01   9.27246094e-01
    2.51953125e-01   5.01464844e-01   8.33984375e-01   9.75585938e-01
    5.09765625e-01   1.43652344e+00  -8.76464844e-02   5.61523438e-01
    1.53710938e+00   5.68359375e-01   1.37207031e-01   2.55859375e+00
    4.37011719e-01   2.40820312e+00   8.51562500e-01  -5.54199219e-01
    1.02050781e+00  -4.89501953e-01   2.20312500e+00   8.22265625e-01
    9.97070312e-01   6.89453125e-01   8.94546509e-04   1.49804688e+00
    2.51367188e+00   4.20410156e-01   2.87109375e-01   6.42089844e-01
   -1.34353638e-02   6.31347656e-01  -1.90063477e-01   9.40551758e-02
    1.18750000e+00   1.08203125e+00   1.11132812e+00   1.13671875e+00
    2.18139648e-01  -2.70751953e-01   6.88476562e-02   1.01562500e+00
    9.16503906e-01   2.67822266e-01   6.50878906e-01   7.33398438e-01
    5.24414062e-01   4.12597656e-01   1.01562500e+00   1.35546875e+00
    1.67871094e+00   2.00585938e+00   7.39257812e-01   5.89355469e-01
    1.11328125e+00   1.22656250e+00   5.78613281e-01   4.82910156e-01
    6.35742188e-01   1.39941406e+00   7.53417969e-01   4.94628906e-01
    1.14160156e+00   6.82128906e-01  -3.84765625e-01   4.94628906e-01
    5.21972656e-01   1.98144531e+00   4.80224609e-01   8.39843750e-01
    2.23022461e-01   2.93945312e-01   5.22949219e-01   1.00781250e+00
    8.68164062e-01  -4.99023438e-01   1.45800781e+00   8.93066406e-01
    4.95849609e-01   6.64550781e-01   8.46191406e-01   7.35839844e-01
    7.74902344e-01   1.07226562e+00   3.31054688e-01   6.58203125e-01
    1.17871094e+00   6.92382812e-01   1.00781250e+00   2.73681641e-01
    6.88964844e-01   7.07031250e-01   4.71679688e-01   3.27148438e-01
    1.14843750e+00   3.39843750e-01   1.37597656e+00   6.99707031e-01
    1.31250000e+00   6.18652344e-01   1.02539062e+00   9.00390625e-01
    9.82421875e-01   3.19580078e-01   3.54980469e-01   4.42626953e-01
   -1.82006836e-01   2.61718750e-01  -2.49023438e-01   2.08203125e+00
    5.65917969e-01   1.50878906e+00   7.98339844e-02   2.16552734e-01
    4.19677734e-01   9.31152344e-01  -1.46728516e-01   1.19042969e+00
    3.87207031e-01  -1.53930664e-01   1.06542969e+00   7.71484375e-01
    4.79248047e-01   6.69921875e-01   1.04003906e+00   8.29101562e-01
    6.92871094e-01   9.46777344e-01  -4.91210938e-01   6.01074219e-01
    1.23144531e+00   7.85644531e-01  -7.48291016e-02   4.05273438e-01
    4.18750000e+00  -1.87744141e-01   6.89453125e-01  -8.67919922e-02
    5.24414062e-01   7.41699219e-01   5.00976562e-01   1.45019531e+00
    6.62597656e-01   3.43750000e-01   1.16113281e+00  -4.50195312e-01
    5.98144531e-03   9.26269531e-01   9.22363281e-01   5.52734375e-01
    8.82812500e-01   6.59667969e-01   2.00390625e+00   1.33398438e+00
    2.49267578e-01   1.01171875e+00   6.40869141e-02   6.68945312e-02
    2.60009766e-01   8.56933594e-01  -1.31713867e-01   8.68164062e-01
    5.15625000e-01   1.48535156e+00  -4.23828125e-01   4.32128906e-01
    7.38281250e-01   4.51171875e-01   4.19677734e-01   1.80273438e+00
    3.81835938e-01   7.62695312e-01   1.07910156e+00   7.40234375e-01
    2.16918945e-01   2.16064453e-01   3.28125000e-01   1.64355469e+00
    2.69287109e-01   1.11816406e+00   4.09375000e+00  -1.44531250e-01
    4.62646484e-01  -1.80297852e-01   2.99072266e-01   5.16113281e-01
    7.56835938e-01   8.99414062e-01   1.57324219e+00  -1.52343750e-01
    1.29882812e+00   5.82031250e-01   4.32617188e-01   7.43164062e-01]]
After layer encoder_birnn_forward_l0_t5_slice_output2 (1, 256) <class 'numpy.float16'> [[  3.19091797e-01   6.23535156e-01  -1.22753906e+00  -4.54345703e-01
    1.65820312e+00  -1.74316406e-01   1.45312500e+00   4.63867188e-02
   -5.03417969e-01  -9.57641602e-02   9.20898438e-01   1.00195312e+00
    2.69287109e-01  -1.26855469e+00   1.51489258e-01   2.28271484e-02
    6.63085938e-01   1.18164062e+00  -1.07177734e-01   5.52734375e-01
   -2.69042969e-01  -2.32031250e+00  -1.99316406e+00   7.53417969e-01
   -2.44506836e-01  -1.79199219e-01  -1.55468750e+00  -4.24499512e-02
   -1.31054688e+00   8.88183594e-01   6.73339844e-01  -3.93310547e-01
    1.22460938e+00  -5.28320312e-01   2.34765625e+00   6.00585938e-01
    6.30859375e-01  -2.31640625e+00  -1.65917969e+00  -2.50244141e-02
   -7.54394531e-02   1.79882812e+00  -1.90185547e-01   1.39746094e+00
   -2.75976562e+00  -6.83593750e-01  -1.06567383e-01   7.34863281e-01
    7.88574219e-01   4.86572266e-01  -5.79223633e-02   2.45666504e-03
   -9.37988281e-01  -8.28613281e-01   1.80664062e+00   1.09765625e+00
   -2.02343750e+00  -2.17285156e-01   1.01757812e+00   4.74548340e-02
    1.35742188e+00  -1.50512695e-01   2.60742188e-01   3.38476562e+00
   -1.02246094e+00   1.26586914e-01   9.16992188e-01   1.70312500e+00
    5.08789062e-01  -1.45898438e+00   7.47070312e-01   1.44897461e-01
   -2.24218750e+00   5.29296875e-01   9.76562500e-01   1.82519531e+00
    1.50390625e+00  -3.07617188e+00   9.48730469e-01  -1.93554688e+00
    2.02734375e+00  -1.03027344e+00  -1.92749023e-01   2.08251953e-01
   -6.05957031e-01  -1.52832031e+00   3.00292969e-01  -1.97753906e+00
    1.91284180e-01  -1.65405273e-01   9.05761719e-01   5.46386719e-01
   -1.68066406e+00  -5.91308594e-01  -2.50195312e+00  -7.11914062e-01
   -9.48242188e-01  -2.15820312e+00   9.08203125e-01   2.56103516e-01
   -1.03125000e+00  -1.25366211e-01   3.04412842e-03   9.78515625e-01
   -7.71484375e-01  -1.46582031e+00   6.84082031e-01   6.54296875e-01
    6.23535156e-01   8.04687500e-01  -1.66601562e+00  -1.39257812e+00
    2.75781250e+00   2.47070312e+00  -2.74169922e-01   1.51660156e+00
    7.10449219e-01   2.41210938e-01   5.87890625e-01   1.50634766e-01
    1.94946289e-01  -1.21972656e+00   1.48242188e+00  -6.27929688e-01
    2.79882812e+00  -3.07373047e-01   2.11523438e+00   8.81347656e-01
   -1.73437500e+00  -2.24218750e+00   3.53515625e-01   1.06640625e+00
    4.98291016e-01  -3.14941406e-01   1.54394531e+00   1.85156250e+00
    5.73242188e-01   1.25292969e+00  -2.16210938e+00  -5.86914062e-01
    1.18713379e-02   2.13671875e+00  -1.81542969e+00  -1.81152344e-01
    1.62011719e+00  -6.46972656e-03   1.16699219e+00   2.71606445e-02
    2.12890625e+00  -2.47192383e-01   2.24609375e+00  -9.99511719e-01
    2.54492188e+00   1.24609375e+00   4.45312500e-01  -2.03320312e+00
    2.15625000e+00  -5.96313477e-02   1.18554688e+00   1.20312500e+00
    3.16406250e+00   8.49609375e-02   4.66308594e-01   1.44824219e+00
   -2.65136719e-01   3.11035156e-01  -6.82983398e-02   1.60937500e+00
   -9.02343750e-01  -8.97949219e-01   3.30078125e-01   3.34960938e+00
   -5.56152344e-01   2.39648438e+00  -1.12109375e+00  -1.99414062e+00
    2.43408203e-01   1.86279297e-01  -7.59765625e-01  -2.51464844e-01
    2.07617188e+00   1.45703125e+00   6.91406250e-01   9.32617188e-01
   -1.49841309e-02  -1.14355469e+00  -6.28417969e-01   1.79589844e+00
    7.54882812e-01  -7.76855469e-01   1.83984375e+00  -1.17675781e+00
   -1.36328125e+00   1.72265625e+00   4.00390625e-01  -2.00585938e+00
   -3.66210938e-01  -1.69140625e+00   1.21777344e+00  -2.94433594e-01
    2.05078125e-02  -1.34179688e+00  -2.21093750e+00  -8.89160156e-01
   -3.19091797e-01  -2.92968750e-01   1.64257812e+00   9.56420898e-02
    5.03417969e-01   1.44775391e-01  -4.65820312e-01   7.97851562e-01
    7.24121094e-01   5.33203125e-01   2.57812500e+00  -1.62500000e+00
   -9.16015625e-01  -1.80175781e+00  -5.65917969e-01  -7.20214844e-01
   -4.86572266e-01   8.08593750e-01   1.52148438e+00  -2.30078125e+00
    4.39453125e-01  -2.86328125e+00  -1.54296875e+00  -4.95117188e-01
    4.73388672e-01  -3.56445312e-02  -5.33691406e-01  -2.23437500e+00
   -3.71826172e-01   1.94238281e+00  -8.69140625e-01  -4.69360352e-02
    1.64257812e+00   8.48632812e-01  -1.84448242e-01   3.10742188e+00
    1.30664062e+00   1.45312500e+00  -3.24804688e+00  -1.83007812e+00
    1.70996094e+00  -1.00195312e+00   5.29296875e-01  -4.06738281e-01
   -1.24023438e+00   8.95996094e-01  -1.87500000e+00  -2.03613281e-01
   -8.17382812e-01  -7.84179688e-01  -1.19628906e-01   5.30273438e-01]]
After layer encoder_birnn_forward_l0_t5_slice_output3 (1, 256) <class 'numpy.float16'> [[  1.14843750e+00   6.89453125e-01   7.72460938e-01   1.03710938e+00
    7.16796875e-01   1.02929688e+00   2.03710938e+00   6.13769531e-01
    9.38476562e-01   8.28613281e-01   8.08593750e-01   8.90136719e-01
    6.55761719e-01   1.35058594e+00  -8.16650391e-02   2.88818359e-01
    9.04296875e-01   4.78271484e-01   1.84277344e+00   1.07128906e+00
    5.28320312e-01  -2.92358398e-02   1.63476562e+00   1.11132812e+00
    6.75292969e-01   4.33105469e-01   1.39160156e+00   9.35546875e-01
    1.65283203e-01   7.91015625e-01   1.09960938e+00   1.09082031e+00
    1.08154297e-01   6.79199219e-01   6.59667969e-01   3.91113281e-01
    9.36523438e-01   3.25439453e-01  -6.38183594e-01   5.22949219e-01
    6.12792969e-01   7.48535156e-01   6.69433594e-01   7.47558594e-01
    7.48046875e-01   8.67187500e-01   1.95605469e+00   9.67285156e-01
    7.15332031e-01   1.92138672e-01  -3.74023438e-01   9.25292969e-01
    3.31054688e+00  -1.25854492e-01   9.03808594e-01  -1.15661621e-01
    4.29931641e-01   6.59179688e-01   9.41894531e-01   6.51855469e-01
    2.20336914e-02   5.92773438e-01   1.43188477e-01   1.29003906e+00
    4.44580078e-01   7.60253906e-01   1.21386719e+00   5.44433594e-01
    7.33886719e-01   6.02539062e-01   1.00488281e+00   8.87695312e-01
    1.81152344e+00   7.80273438e-01   6.04980469e-01   2.90234375e+00
    8.36914062e-01   2.76757812e+00   1.35839844e+00   2.30590820e-01
    1.52832031e+00  -2.04833984e-01   3.35156250e+00   7.31445312e-01
    1.25488281e+00   5.92773438e-01   4.75341797e-01   9.89257812e-01
    2.19140625e+00   1.01855469e+00   6.30859375e-01   7.45117188e-01
   -4.66552734e-01   1.34472656e+00   2.58789062e-01   1.14453125e+00
    1.03417969e+00   1.11621094e+00   1.07421875e+00   1.57519531e+00
    3.36914062e-01   6.17187500e-01   2.51464844e-01   1.49511719e+00
    1.11816406e+00   3.13964844e-01   7.61718750e-01   1.12890625e+00
    1.17089844e+00   2.60742188e-01   1.45996094e+00   8.52050781e-01
    2.20507812e+00   2.00781250e+00   1.09179688e+00   8.26171875e-01
    8.75000000e-01   1.73925781e+00   8.44238281e-01   9.96093750e-01
    7.17773438e-01   1.77636719e+00   9.50195312e-01   7.83203125e-01
    1.04296875e+00   1.16113281e+00   1.22985840e-01   1.12304688e-01
    6.07421875e-01   2.47656250e+00   9.95605469e-01   1.60449219e+00
    5.80078125e-01   7.87597656e-01   4.74609375e-01   4.16015625e-01
    1.13476562e+00   6.45996094e-01   1.36328125e+00   8.57421875e-01
    4.43115234e-01   8.55468750e-01   7.97851562e-01   9.07226562e-01
    5.03417969e-01   1.01074219e+00   6.66015625e-01   6.18652344e-01
    1.15173340e-01   4.24072266e-01   1.94140625e+00   4.33593750e-01
    9.47753906e-01   7.02514648e-02   4.02832031e-01  -6.89697266e-02
    4.80468750e-01   6.76269531e-01   1.70117188e+00   9.05761719e-01
    8.28125000e-01   9.91699219e-01   2.91748047e-01   1.05468750e+00
    1.50781250e+00   3.62304688e-01   8.53515625e-01   3.47656250e-01
   -1.89453125e-01   4.46289062e-01   5.60058594e-01   3.67773438e+00
    1.03320312e+00   1.53808594e+00  -1.22070312e-04   3.33007812e-01
    7.40234375e-01   9.33593750e-01   5.00000000e-01   1.24609375e+00
    7.56835938e-01  -1.09558105e-01   9.64843750e-01   1.03027344e+00
    4.76562500e-01   9.93652344e-01   8.21289062e-01   4.50195312e-01
    9.17480469e-01   1.28906250e+00  -1.00341797e-01   7.53417969e-01
    1.72460938e+00   8.17871094e-01   2.23266602e-01   1.01757812e+00
    3.74609375e+00   6.83593750e-01   8.79882812e-01   9.31640625e-01
    4.04785156e-01   2.07153320e-01   1.00976562e+00   1.36816406e+00
    1.02539062e+00   1.17382812e+00   1.36816406e+00   1.29760742e-01
   -4.66796875e-01   8.20312500e-01   1.00292969e+00   4.58984375e-01
    1.34765625e+00   1.13281250e+00   2.54687500e+00   1.65234375e+00
    5.44433594e-01   1.58300781e+00   1.11035156e+00   5.92773438e-01
    6.36718750e-01   1.06738281e+00   6.83593750e-03   4.17480469e-01
    1.02148438e+00   6.22558594e-01   8.81347656e-01   7.65625000e-01
    9.20410156e-01   4.22851562e-01   3.35937500e-01   1.52148438e+00
    9.69238281e-01   9.69238281e-01   1.14941406e+00   5.48339844e-01
    1.11145020e-01  -1.50512695e-01   7.06542969e-01   1.92285156e+00
    1.24023438e-01   1.31054688e+00   4.64062500e+00   1.39282227e-01
    7.46093750e-01   2.43774414e-01   8.35937500e-01   9.06250000e-01
    1.37207031e+00   1.21679688e+00   1.52050781e+00   4.28466797e-01
    1.51074219e+00   1.15136719e+00   6.08398438e-01   9.60449219e-01]]
After layer encoder_birnn_forward_l0_t5_o_output (1, 256) <class 'numpy.float16'> [[ 0.75927734  0.66601562  0.68408203  0.73828125  0.671875    0.73681641
   0.88476562  0.64892578  0.71875     0.69628906  0.69189453  0.70898438
   0.65820312  0.79443359  0.47949219  0.57177734  0.71191406  0.6171875
   0.86328125  0.74462891  0.62890625  0.49267578  0.83691406  0.75244141
   0.66259766  0.60644531  0.80078125  0.71826172  0.54101562  0.68798828
   0.75        0.74853516  0.52685547  0.66357422  0.65917969  0.59667969
   0.71826172  0.58056641  0.34570312  0.62792969  0.6484375   0.67871094
   0.66113281  0.67871094  0.67871094  0.70410156  0.87597656  0.72460938
   0.67138672  0.54785156  0.4074707   0.71630859  0.96484375  0.46850586
   0.71191406  0.47119141  0.60595703  0.65917969  0.71923828  0.65722656
   0.50537109  0.64404297  0.53564453  0.78417969  0.609375    0.68164062
   0.77099609  0.6328125   0.67578125  0.64599609  0.73193359  0.70849609
   0.859375    0.68554688  0.64697266  0.94775391  0.69775391  0.94091797
   0.79541016  0.55761719  0.82177734  0.44897461  0.96630859  0.67529297
   0.77832031  0.64404297  0.61669922  0.72900391  0.89941406  0.73486328
   0.65283203  0.67822266  0.38549805  0.79345703  0.56445312  0.75830078
   0.73779297  0.75341797  0.74560547  0.82861328  0.58349609  0.64941406
   0.5625      0.81689453  0.75341797  0.57763672  0.68164062  0.75585938
   0.76318359  0.56494141  0.81152344  0.70117188  0.90087891  0.88183594
   0.74853516  0.6953125   0.70556641  0.85058594  0.69921875  0.73046875
   0.671875    0.85546875  0.72119141  0.68652344  0.73925781  0.76171875
   0.53076172  0.52783203  0.64746094  0.92236328  0.72998047  0.83251953
   0.64111328  0.6875      0.61669922  0.60253906  0.75683594  0.65625
   0.79638672  0.70214844  0.60888672  0.70166016  0.68945312  0.71240234
   0.62304688  0.73339844  0.66064453  0.64990234  0.52880859  0.60449219
   0.87451172  0.60693359  0.72070312  0.51757812  0.59960938  0.48266602
   0.61767578  0.66308594  0.84570312  0.71191406  0.69580078  0.72949219
   0.57226562  0.74169922  0.81884766  0.58935547  0.70117188  0.5859375
   0.45288086  0.60986328  0.63623047  0.97558594  0.73730469  0.82324219
   0.5         0.58251953  0.67724609  0.71777344  0.62255859  0.77685547
   0.68066406  0.47265625  0.72412109  0.73681641  0.61669922  0.72998047
   0.69433594  0.61083984  0.71435547  0.78417969  0.47485352  0.6796875
   0.84863281  0.69384766  0.55566406  0.734375    0.97705078  0.66455078
   0.70703125  0.71728516  0.59960938  0.55175781  0.73291016  0.796875
   0.73583984  0.76367188  0.796875    0.53222656  0.38525391  0.69433594
   0.73144531  0.61279297  0.79394531  0.75634766  0.92724609  0.83935547
   0.6328125   0.82958984  0.75195312  0.64404297  0.65380859  0.74414062
   0.50195312  0.60302734  0.73535156  0.65087891  0.70703125  0.68261719
   0.71533203  0.60400391  0.58300781  0.82080078  0.72509766  0.72509766
   0.75927734  0.63378906  0.52783203  0.46240234  0.66943359  0.87255859
   0.53076172  0.78759766  0.99023438  0.53466797  0.67822266  0.56054688
   0.69775391  0.71240234  0.79785156  0.77148438  0.82080078  0.60546875
   0.81933594  0.75976562  0.64746094  0.72314453]]
After layer encoder_birnn_forward_l0_t5_f_output (1, 256) <class 'numpy.float16'> [[ 0.76025391  0.51855469  0.55273438  0.62695312  0.59326172  0.61181641
   0.79003906  0.59277344  0.86865234  0.58300781  0.78125     0.63623047
   0.70800781  0.70068359  0.4621582   0.62304688  0.60644531  0.59423828
   0.75830078  0.66015625  0.54296875  0.45654297  0.77783203  0.56640625
   0.67578125  0.65478516  0.68359375  0.59521484  0.73974609  0.56201172
   0.73974609  0.70605469  0.63378906  0.671875    0.80566406  0.61425781
   0.55664062  0.64746094  0.81591797  0.52148438  0.69628906  0.62597656
   0.78222656  0.46118164  0.52832031  0.4309082   0.79443359  0.65625
   0.57470703  0.44775391  0.43237305  0.61132812  0.93798828  0.44580078
   0.75048828  0.42919922  0.58154297  0.63867188  0.65771484  0.68457031
   0.50732422  0.61962891  0.54931641  0.71630859  0.5625      0.62304688
   0.69726562  0.72607422  0.62451172  0.80810547  0.47802734  0.63671875
   0.82324219  0.63818359  0.53417969  0.92822266  0.60742188  0.91748047
   0.70068359  0.36499023  0.73486328  0.38012695  0.90039062  0.69482422
   0.73046875  0.66601562  0.5         0.81738281  0.92529297  0.60351562
   0.57128906  0.65527344  0.49658203  0.65283203  0.45263672  0.5234375
   0.76611328  0.74707031  0.75244141  0.75683594  0.55419922  0.43261719
   0.51708984  0.73388672  0.71435547  0.56640625  0.65722656  0.67578125
   0.62841797  0.6015625   0.73388672  0.79492188  0.84277344  0.88134766
   0.67675781  0.64306641  0.75292969  0.7734375   0.640625    0.61865234
   0.65380859  0.80224609  0.6796875   0.62109375  0.7578125   0.6640625
   0.4050293   0.62109375  0.62744141  0.87890625  0.61767578  0.69824219
   0.55566406  0.57275391  0.62792969  0.73242188  0.70458984  0.37768555
   0.81103516  0.70947266  0.62158203  0.66015625  0.69970703  0.67626953
   0.68457031  0.74511719  0.58203125  0.65869141  0.76464844  0.66650391
   0.73242188  0.56787109  0.66552734  0.66992188  0.61572266  0.58105469
   0.75927734  0.58398438  0.79833984  0.66796875  0.78808594  0.64990234
   0.73583984  0.7109375   0.72753906  0.57910156  0.58789062  0.60888672
   0.45458984  0.56494141  0.43798828  0.88916016  0.63769531  0.81884766
   0.52001953  0.55371094  0.60351562  0.71728516  0.46337891  0.76660156
   0.59570312  0.46166992  0.74365234  0.68408203  0.61767578  0.66162109
   0.73876953  0.69628906  0.66650391  0.72070312  0.37963867  0.64599609
   0.77392578  0.68701172  0.48120117  0.60009766  0.98486328  0.453125
   0.66601562  0.47827148  0.62841797  0.67724609  0.62255859  0.81005859
   0.65966797  0.58496094  0.76171875  0.3894043   0.50146484  0.71630859
   0.71533203  0.63476562  0.70751953  0.65917969  0.88134766  0.79150391
   0.56201172  0.73339844  0.51611328  0.51660156  0.56445312  0.70214844
   0.46704102  0.70458984  0.62597656  0.81542969  0.39550781  0.60644531
   0.67675781  0.61083984  0.60351562  0.85839844  0.59423828  0.68212891
   0.74609375  0.67724609  0.55419922  0.55371094  0.58154297  0.83789062
   0.56689453  0.75341797  0.98339844  0.46386719  0.61376953  0.45507812
   0.57421875  0.62646484  0.68066406  0.7109375   0.828125    0.46191406
   0.78564453  0.64160156  0.60644531  0.67773438]]
After layer _mul2062_0 (1, 256) <class 'numpy.float16'> [[  1.58935547e-01   1.79199219e-01  -3.06152344e-01  -1.71264648e-01
    4.47753906e-01  -6.89697266e-02   6.26953125e-01  -3.31726074e-02
   -1.42944336e-01  -5.80139160e-02   3.55468750e-01   3.22998047e-01
    8.40454102e-02  -4.72900391e-01   4.31518555e-02  -6.30187988e-03
    2.12646484e-01   3.40820312e-01  -7.16552734e-02   1.87011719e-01
   -1.09252930e-01  -2.54394531e-01  -6.23046875e-01   2.05200195e-01
   -1.27685547e-01  -7.82470703e-02  -5.17578125e-01  -4.29382324e-02
   -4.62402344e-01   2.30957031e-01   2.68554688e-01  -1.67236328e-01
    4.56054688e-01  -1.63574219e-01   8.77441406e-01   1.69067383e-01
    1.75292969e-01  -6.72363281e-01  -6.84570312e-01   4.03442383e-02
   -6.84814453e-02   4.23339844e-01  -1.58569336e-01   2.48413086e-01
   -5.24414062e-01  -1.43676758e-01  -1.41830444e-02   3.01269531e-01
    2.10449219e-01   8.95385742e-02   4.18472290e-03   1.09710693e-02
   -4.70947266e-01  -1.76513672e-01   6.79199219e-01   2.17285156e-01
   -4.65087891e-01  -8.28247070e-02   2.59521484e-01  -1.67541504e-02
    2.75878906e-01  -9.38720703e-02   7.48901367e-02   8.08105469e-01
   -2.38403320e-01   5.01098633e-02   2.97851562e-01   6.72851562e-01
    1.82495117e-01  -5.70800781e-01   1.48315430e-01   8.09478760e-03
   -9.16503906e-01   2.12890625e-01   2.68554688e-01   9.61914062e-01
    4.13085938e-01  -1.37304688e+00   3.32031250e-01  -2.08740234e-01
    6.27929688e-01  -1.88720703e-01  -3.96118164e-02   1.00769043e-01
   -2.91748047e-01  -4.37011719e-01   5.59082031e-02  -8.02246094e-01
    1.77124023e-01  -2.97851562e-02   2.21069336e-01   1.69921875e-01
   -2.75878906e-01  -1.99707031e-01  -2.74902344e-01  -1.06811523e-01
   -4.28710938e-01  -7.12890625e-01   3.88671875e-01   1.60156250e-01
   -2.26074219e-01  -2.01416016e-02  -1.75781250e-02   4.44335938e-01
   -3.75732422e-01  -3.26416016e-01   2.71484375e-01   2.70263672e-01
    2.26928711e-01   2.38525391e-01  -5.94726562e-01  -5.65917969e-01
    1.09570312e+00   1.15332031e+00  -1.90063477e-01   4.58984375e-01
    3.13964844e-01   1.57714844e-01   2.02026367e-01   6.85424805e-02
    3.42102051e-02  -5.66406250e-01   5.46875000e-01  -1.92382812e-01
    9.36035156e-01  -3.75671387e-02   2.84667969e-01   2.72705078e-01
   -4.23095703e-01  -1.00000000e+00   9.35058594e-02   4.31396484e-01
    1.35009766e-01  -8.92333984e-02   4.65332031e-01   5.86425781e-01
    1.67602539e-01   1.31103516e-01  -7.71972656e-01  -1.61499023e-01
   -2.47192383e-02   6.03515625e-01  -5.62500000e-01  -8.52050781e-02
    4.64355469e-01   1.46789551e-02   2.72216797e-01  -3.83911133e-02
    6.89453125e-01  -1.12121582e-01   7.35839844e-01  -3.13232422e-01
    7.17285156e-01   3.86230469e-01   1.34521484e-01  -4.79248047e-01
    6.71875000e-01  -4.41284180e-02   4.95361328e-01   3.75732422e-01
    9.96093750e-01   1.04431152e-01   2.36083984e-01   5.12207031e-01
   -1.71020508e-01   1.24755859e-01  -2.64739990e-02   4.31640625e-01
   -1.80908203e-01  -2.64892578e-01   6.23474121e-02   1.46093750e+00
   -1.91284180e-01   8.57910156e-01  -2.66113281e-01  -3.75976562e-01
    7.09228516e-02   8.23364258e-02  -1.38427734e-01  -9.95483398e-02
    5.44921875e-01   2.70019531e-01   2.95654297e-01   3.24951172e-01
   -1.71203613e-02  -3.88427734e-01  -2.30468750e-01   5.64453125e-01
    2.43774414e-01  -2.93945312e-01   1.87377930e-01  -3.50097656e-01
   -5.82031250e-01   4.72900391e-01   1.02355957e-01  -5.14160156e-01
   -1.83837891e-01  -3.40087891e-01   3.97460938e-01  -4.33349609e-02
    6.05163574e-02  -4.76806641e-01  -4.80712891e-01  -3.82568359e-01
   -1.57958984e-01  -7.44018555e-02   5.53222656e-01   3.30505371e-02
    1.10900879e-01   1.02478027e-01  -2.01904297e-01   2.68798828e-01
    2.84667969e-01   2.02026367e-01   1.10156250e+00  -6.19140625e-01
   -2.32421875e-01  -6.29882812e-01  -1.35864258e-01  -1.29394531e-01
   -1.33422852e-01   3.15673828e-01   2.95898438e-01  -6.26953125e-01
    1.55517578e-01  -1.12597656e+00  -2.51708984e-01  -1.59423828e-01
    1.98120117e-01  -2.22930908e-02  -1.30249023e-01  -1.08984375e+00
   -1.45263672e-01   5.94726562e-01  -3.78173828e-01   6.87122345e-04
    3.82568359e-01   1.87866211e-01  -9.19799805e-02   9.78027344e-01
    2.83447266e-01   5.76660156e-01  -1.71484375e+00  -3.08593750e-01
    4.73632812e-01  -2.13623047e-01   1.64184570e-01  -1.45263672e-01
   -4.37988281e-01   2.97607422e-01  -8.68652344e-01  -4.61730957e-02
   -3.99658203e-01  -2.95166016e-01  -1.35726929e-02   2.29492188e-01]]
After layer encoder_birnn_forward_l0_t5_i_output (1, 256) <class 'numpy.float16'> [[ 0.64111328  0.61914062  0.59521484  0.59082031  0.6953125   0.68994141
   0.80566406  0.51806641  0.40161133  0.63037109  0.60742188  0.68505859
   0.48486328  0.72558594  0.4050293   0.55566406  0.59716797  0.65136719
   0.68603516  0.60498047  0.49267578  0.29370117  0.63574219  0.60302734
   0.56445312  0.55419922  0.71435547  0.5078125   0.67626953  0.66845703
   0.66552734  0.65478516  0.74560547  0.65527344  0.85302734  0.51855469
   0.5859375   0.86474609  0.77978516  0.34838867  0.42553711  0.63818359
   0.74560547  0.55908203  0.84033203  0.640625    0.59228516  0.66162109
   0.55957031  0.45776367  0.42944336  0.42871094  0.96289062  0.58740234
   0.78173828  0.52783203  0.74511719  0.50488281  0.60400391  0.27075195
   0.60400391  0.60449219  0.47387695  0.77099609  0.50976562  0.54003906
   0.69726562  0.81152344  0.67626953  0.77099609  0.45288086  0.28173828
   0.86572266  0.64697266  0.62988281  0.86914062  0.69238281  0.93164062
   0.64257812  0.39672852  0.74560547  0.63183594  0.67626953  0.46313477
   0.75341797  0.68701172  0.58789062  0.82128906  0.77050781  0.4387207
   0.63769531  0.45288086  0.44702148  0.63525391  0.38671875  0.32543945
   0.75732422  0.77832031  0.73730469  0.63916016  0.56201172  0.42260742
   0.60839844  0.79541016  0.70947266  0.5703125   0.52783203  0.57470703
   0.49487305  0.56054688  0.77587891  0.74072266  0.90478516  0.94091797
   0.68603516  0.72509766  0.63476562  0.73583984  0.56542969  0.44506836
   0.44018555  0.76220703  0.86376953  0.60009766  0.86181641  0.56835938
   0.60791016  0.61132812  0.57714844  0.88330078  0.40405273  0.71582031
   0.61083984  0.55859375  0.72802734  0.66601562  0.67382812  0.3515625
   0.69726562  0.47851562  0.515625    0.77490234  0.69335938  0.51074219
   0.65380859  0.34301758  0.5078125   0.39794922  0.73779297  0.46850586
   0.84082031  0.70361328  0.83740234  0.77685547  0.52001953  0.74121094
   0.66894531  0.42260742  0.75146484  0.71337891  0.87548828  0.4543457
   0.69921875  0.72216797  0.67626953  0.51025391  0.53955078  0.64013672
   0.47338867  0.60498047  0.38818359  0.97998047  0.61230469  0.80224609
   0.66552734  0.57910156  0.45361328  0.37768555  0.47924805  0.59960938
   0.79785156  0.61816406  0.63769531  0.57714844  0.43334961  0.65527344
   0.5234375   0.75537109  0.67773438  0.65673828  0.37207031  0.54833984
   0.82080078  0.6015625   0.62353516  0.75146484  0.96044922  0.77978516
   0.67529297  0.54541016  0.57910156  0.71923828  0.64648438  0.66064453
   0.64794922  0.49560547  0.70898438  0.40917969  0.41625977  0.61181641
   0.67333984  0.59716797  0.74707031  0.61865234  0.890625    0.74755859
   0.58740234  0.79785156  0.64306641  0.3984375   0.56445312  0.59912109
   0.63769531  0.6796875   0.65087891  0.94873047  0.68261719  0.48266602
   0.50830078  0.51464844  0.35571289  0.92919922  0.59960938  0.78173828
   0.65722656  0.48364258  0.61962891  0.42041016  0.546875    0.82324219
   0.57128906  0.70703125  0.98681641  0.63574219  0.75341797  0.67578125
   0.60449219  0.57519531  0.69726562  0.61474609  0.83056641  0.36352539
   0.74902344  0.65429688  0.40112305  0.60351562]]
After layer encoder_birnn_forward_l0_t5_c_output (1, 256) <class 'numpy.float16'> [[ 0.30859375  0.55371094 -0.84179688 -0.42553711  0.93017578 -0.17260742
   0.89648438  0.0463562  -0.46484375 -0.09545898  0.7265625   0.76220703
   0.26293945 -0.85351562  0.15039062  0.02282715  0.58056641  0.828125
  -0.10675049  0.50244141 -0.26269531 -0.98095703 -0.96337891  0.63720703
  -0.23974609 -0.17724609 -0.91455078 -0.04241943 -0.86425781  0.71044922
   0.58740234 -0.37426758  0.84082031 -0.48413086  0.98193359  0.53759766
   0.55859375 -0.98095703 -0.93017578 -0.02502441 -0.07531738  0.94677734
  -0.18786621  0.88476562 -0.9921875  -0.59375    -0.10614014  0.62597656
   0.65771484  0.45141602 -0.05786133  0.00245667 -0.734375   -0.6796875
   0.94726562  0.79980469 -0.96582031 -0.21398926  0.76904297  0.04742432
   0.87597656 -0.14941406  0.25488281  0.99755859 -0.77099609  0.12585449
   0.72460938  0.93603516  0.46899414 -0.89746094  0.63330078  0.1439209
  -0.97753906  0.48486328  0.75146484  0.94921875  0.90576172 -0.99560547
   0.73925781 -0.95898438  0.96582031 -0.77392578 -0.19042969  0.20532227
  -0.54150391 -0.91015625  0.29150391 -0.96240234  0.18896484 -0.16394043
   0.71923828  0.49780273 -0.93310547 -0.53076172 -0.98681641 -0.61181641
  -0.73876953 -0.97363281  0.72021484  0.25073242 -0.77441406 -0.12469482
   0.00304413  0.75244141 -0.64794922 -0.89892578  0.59423828  0.57470703
   0.55371094  0.66650391 -0.93115234 -0.88378906  0.9921875   0.98583984
  -0.26757812  0.90820312  0.61083984  0.23669434  0.52832031  0.14953613
   0.19250488 -0.83935547  0.90185547 -0.55664062  0.99267578 -0.2980957
   0.97119141  0.70703125 -0.93945312 -0.97753906  0.33959961  0.78808594
   0.46069336 -0.30493164  0.91259766  0.95166016  0.51757812  0.84912109
  -0.97363281 -0.52783203  0.01187134  0.97265625 -0.94824219 -0.17919922
   0.92480469 -0.00646973  0.82324219  0.02716064  0.97216797 -0.24230957
   0.97802734 -0.76123047  0.98779297  0.84716797  0.41796875 -0.96630859
   0.97363281 -0.05957031  0.82910156  0.83447266  0.99658203  0.08477783
   0.43530273  0.89550781 -0.2590332   0.30126953 -0.06817627  0.92285156
  -0.71728516 -0.71533203  0.31860352  0.99755859 -0.50488281  0.98339844
  -0.80810547 -0.96337891  0.23876953  0.1842041  -0.64111328 -0.24633789
   0.96923828  0.89697266  0.59912109  0.73193359 -0.01498413 -0.81542969
  -0.55712891  0.94628906  0.63818359 -0.65087891  0.95068359 -0.82666016
  -0.87695312  0.93798828  0.38037109 -0.96435547 -0.35058594 -0.93408203
   0.83886719 -0.28613281  0.02050781 -0.87207031 -0.97607422 -0.7109375
  -0.30859375 -0.28491211  0.92773438  0.09533691  0.46484375  0.14379883
  -0.43481445  0.66259766  0.61962891  0.48779297  0.98876953 -0.92529297
  -0.72412109 -0.94677734 -0.51220703 -0.6171875  -0.45141602  0.66894531
   0.90917969 -0.97998047  0.41308594 -0.99365234 -0.91259766 -0.45825195
   0.44091797 -0.03564453 -0.48828125 -0.97753906 -0.35546875  0.95996094
  -0.70117188 -0.04690552  0.92773438  0.69042969 -0.18237305  0.99609375
   0.86328125  0.89648438 -0.99707031 -0.94970703  0.93652344 -0.76220703
   0.48486328 -0.38574219 -0.84570312  0.71435547 -0.95410156 -0.20080566
  -0.67382812 -0.65527344 -0.11907959  0.4855957 ]]
After layer _mul2063_0 (1, 256) <class 'numpy.float16'> [[ 0.19787598  0.34277344 -0.50097656 -0.25146484  0.64697266 -0.11907959
   0.72216797  0.02401733 -0.18664551 -0.06018066  0.44140625  0.52197266
   0.12744141 -0.61914062  0.06091309  0.01268768  0.34667969  0.53955078
  -0.07324219  0.30395508 -0.12939453 -0.28808594 -0.61230469  0.38427734
  -0.13537598 -0.09820557 -0.65332031 -0.02154541 -0.58447266  0.47485352
   0.39086914 -0.24511719  0.62695312 -0.31713867  0.83740234  0.27880859
   0.32739258 -0.84814453 -0.72509766 -0.0087204  -0.03204346  0.60400391
  -0.14001465  0.49462891 -0.83398438 -0.38037109 -0.06286621  0.4140625
   0.36791992  0.20666504 -0.02484131  0.00105286 -0.70703125 -0.39916992
   0.74072266  0.42211914 -0.71972656 -0.10803223  0.46459961  0.01284027
   0.52929688 -0.09033203  0.12078857  0.76904297 -0.39306641  0.06799316
   0.50537109  0.75976562  0.31713867 -0.69189453  0.28686523  0.04055786
  -0.84619141  0.3137207   0.47338867  0.82519531  0.62695312 -0.92773438
   0.47509766 -0.38037109  0.72021484 -0.48901367 -0.12878418  0.09509277
  -0.40795898 -0.62548828  0.17138672 -0.79052734  0.14562988 -0.07189941
   0.45874023  0.22546387 -0.41723633 -0.3371582  -0.3815918  -0.19909668
  -0.55957031 -0.7578125   0.53125     0.16027832 -0.43530273 -0.05270386
   0.00185204  0.59863281 -0.4597168  -0.51269531  0.3137207   0.33032227
   0.27392578  0.37353516 -0.72265625 -0.65478516  0.89794922  0.92773438
  -0.18359375  0.65869141  0.38769531  0.17419434  0.29882812  0.06652832
   0.0847168  -0.63964844  0.77880859 -0.33398438  0.85546875 -0.16943359
   0.59033203  0.43212891 -0.54199219 -0.86328125  0.13720703  0.56396484
   0.28149414 -0.17028809  0.66455078  0.63378906  0.34887695  0.29858398
  -0.67871094 -0.25268555  0.00612259  0.75390625 -0.65771484 -0.09155273
   0.60449219 -0.00222015  0.41796875  0.01081085  0.71728516 -0.11352539
   0.82226562 -0.53564453  0.82714844  0.65820312  0.21740723 -0.71630859
   0.65136719 -0.025177    0.62304688  0.59521484  0.87255859  0.03851318
   0.30444336  0.64648438 -0.1751709   0.15368652 -0.03677368  0.59082031
  -0.33959961 -0.43286133  0.12365723  0.97753906 -0.30908203  0.7890625
  -0.53759766 -0.55810547  0.1083374   0.06958008 -0.30737305 -0.14770508
   0.7734375   0.5546875   0.38208008  0.42236328 -0.00649261 -0.53417969
  -0.29150391  0.71484375  0.43261719 -0.42749023  0.35375977 -0.45336914
  -0.71972656  0.56445312  0.23718262 -0.72460938 -0.33666992 -0.72851562
   0.56640625 -0.15600586  0.01187897 -0.62744141 -0.63085938 -0.46972656
  -0.19995117 -0.14123535  0.65771484  0.03900146  0.19348145  0.08795166
  -0.29272461  0.39575195  0.46289062  0.30175781  0.88085938 -0.69189453
  -0.42529297 -0.75537109 -0.3293457  -0.24584961 -0.25488281  0.40087891
   0.57958984 -0.66601562  0.26879883 -0.94287109 -0.62304688 -0.22119141
   0.22412109 -0.01834106 -0.17370605 -0.90820312 -0.21313477  0.75048828
  -0.4609375  -0.02268982  0.57470703  0.2902832  -0.09973145  0.81982422
   0.49316406  0.63378906 -0.98388672 -0.60400391  0.70556641 -0.51513672
   0.29321289 -0.22192383 -0.58984375  0.43920898 -0.79248047 -0.07299805
  -0.50488281 -0.42871094 -0.04776001  0.29296875]]
After layer encoder_birnn_forward_l0_t5_state_0 (1, 256) <class 'numpy.float16'> [[ 0.35693359  0.52197266 -0.80712891 -0.42285156  1.09472656 -0.18798828
   1.34960938 -0.00915527 -0.32958984 -0.11816406  0.796875    0.84472656
   0.21142578 -1.09179688  0.10406494  0.0063858   0.55957031  0.88037109
  -0.14489746  0.4909668  -0.23864746 -0.54248047 -1.23535156  0.58935547
  -0.26318359 -0.17651367 -1.17089844 -0.06445312 -1.046875    0.70605469
   0.65917969 -0.41235352  1.08300781 -0.48071289  1.71484375  0.44775391
   0.50292969 -1.52050781 -1.41015625  0.03161621 -0.1005249   1.02734375
  -0.29858398  0.74316406 -1.35839844 -0.52392578 -0.07702637  0.71533203
   0.578125    0.29614258 -0.0206604   0.01202393 -1.17773438 -0.57568359
   1.41992188  0.63964844 -1.18457031 -0.19091797  0.72412109 -0.00391388
   0.80517578 -0.1842041   0.19567871  1.57714844 -0.63134766  0.11810303
   0.80322266  1.43261719  0.49951172 -1.26269531  0.43505859  0.04864502
  -1.76269531  0.52636719  0.7421875   1.78710938  1.04003906 -2.30078125
   0.80712891 -0.58886719  1.34765625 -0.67773438 -0.16845703  0.19580078
  -0.69970703 -1.0625      0.22729492 -1.59277344  0.32275391 -0.10168457
   0.6796875   0.39550781 -0.69335938 -0.53710938 -0.65625    -0.3059082
  -0.98828125 -1.47070312  0.91992188  0.3203125  -0.66113281 -0.07287598
  -0.01573181  1.04296875 -0.83544922 -0.83886719  0.58496094  0.60058594
   0.50097656  0.61230469 -1.31738281 -1.22070312  1.99414062  2.08203125
  -0.37353516  1.1171875   0.70166016  0.33203125  0.50097656  0.13500977
   0.11889648 -1.20605469  1.32617188 -0.52636719  1.79101562 -0.20703125
   0.875       0.70507812 -0.96484375 -1.86328125  0.23071289  0.99511719
   0.41650391 -0.25952148  1.12988281  1.22070312  0.51660156  0.4296875
  -1.45117188 -0.4140625  -0.01860046  1.35742188 -1.22070312 -0.17675781
   1.06835938  0.0124588   0.69042969 -0.02758789  1.40625    -0.22558594
   1.55859375 -0.84863281  1.54492188  1.04492188  0.35205078 -1.1953125
   1.32324219 -0.06933594  1.11816406  0.97070312  1.86914062  0.14294434
   0.54052734  1.15820312 -0.34619141  0.27832031 -0.06323242  1.02246094
  -0.52050781 -0.69775391  0.18603516  2.4375     -0.50048828  1.64648438
  -0.80371094 -0.93408203  0.17919922  0.15185547 -0.44580078 -0.24731445
   1.31835938  0.82470703  0.67773438  0.74707031 -0.02362061 -0.92285156
  -0.52197266  1.27929688  0.67626953 -0.72167969  0.54101562 -0.80371094
  -1.30175781  1.03710938  0.33959961 -1.23828125 -0.52050781 -1.06835938
   0.96386719 -0.19934082  0.0723877  -1.10449219 -1.11132812 -0.85253906
  -0.35791016 -0.21557617  1.2109375   0.07202148  0.30444336  0.19042969
  -0.49462891  0.66455078  0.74755859  0.50390625  1.98242188 -1.31054688
  -0.65771484 -1.38476562 -0.46533203 -0.37524414 -0.38818359  0.71679688
   0.87548828 -1.29296875  0.42431641 -2.06835938 -0.875      -0.38061523
   0.42236328 -0.04064941 -0.30395508 -1.99804688 -0.35839844  1.34570312
  -0.83886719 -0.02200317  0.95703125  0.47802734 -0.19165039  1.79785156
   0.77636719  1.2109375  -2.69921875 -0.91259766  1.1796875  -0.72851562
   0.45751953 -0.3671875  -1.02734375  0.73681641 -1.66113281 -0.11914062
  -0.90429688 -0.72363281 -0.06134033  0.52246094]]
After layer activation1031_output (1, 256) <class 'numpy.float16'> [[ 0.3425293   0.47924805 -0.66796875 -0.39941406  0.79882812 -0.18579102
   0.87402344 -0.00915527 -0.31811523 -0.11761475  0.66210938  0.68847656
   0.20837402 -0.79736328  0.10369873  0.0063858   0.5078125   0.70654297
  -0.1439209   0.45507812 -0.23425293 -0.49487305 -0.84423828  0.52929688
  -0.25732422 -0.17468262 -0.82470703 -0.06439209 -0.78076172  0.60839844
   0.57763672 -0.39038086  0.79443359 -0.44677734  0.93701172  0.42016602
   0.46435547 -0.90869141 -0.88769531  0.03161621 -0.10015869  0.77294922
  -0.29003906  0.63085938 -0.87597656 -0.48071289 -0.0769043   0.61376953
   0.52148438  0.2878418  -0.0206604   0.01202393 -0.82666016 -0.51953125
   0.88964844  0.56445312 -0.82910156 -0.18859863  0.61962891 -0.00391388
   0.66699219 -0.18212891  0.1932373   0.91796875 -0.55908203  0.11755371
   0.66601562  0.89208984  0.46166992 -0.8515625   0.40942383  0.0486145
  -0.94287109  0.48266602  0.63037109  0.9453125   0.77783203 -0.97998047
   0.66796875 -0.52929688  0.87353516 -0.58984375 -0.16687012  0.19335938
  -0.60400391 -0.78662109  0.22351074 -0.92041016  0.31201172 -0.10131836
   0.59130859  0.3762207  -0.60009766 -0.49072266 -0.57568359 -0.29663086
  -0.75683594 -0.89990234  0.72607422  0.30981445 -0.57910156 -0.07275391
  -0.01573181  0.77929688 -0.68359375 -0.68505859  0.52636719  0.53759766
   0.46289062  0.54589844 -0.86621094 -0.83984375  0.96337891  0.96923828
  -0.35717773  0.80664062  0.60546875  0.3203125   0.46289062  0.13415527
   0.11834717 -0.83544922  0.86816406 -0.48266602  0.94580078 -0.20410156
   0.70410156  0.60742188 -0.74658203 -0.953125    0.22668457  0.75976562
   0.39404297 -0.25390625  0.81103516  0.83984375  0.47509766  0.4050293
  -0.89599609 -0.3918457  -0.01860046  0.87597656 -0.83984375 -0.17492676
   0.7890625   0.0124588   0.59814453 -0.02758789  0.88671875 -0.22180176
   0.91503906 -0.69042969  0.91308594  0.77978516  0.33813477 -0.83203125
   0.86767578 -0.06921387  0.80712891  0.74902344  0.95361328  0.14196777
   0.4934082   0.8203125  -0.33300781  0.27124023 -0.06317139  0.77099609
  -0.47802734 -0.60302734  0.18395996  0.98486328 -0.46240234  0.92822266
  -0.66601562 -0.73242188  0.17724609  0.15075684 -0.41845703 -0.24243164
   0.86621094  0.67773438  0.58984375  0.63330078 -0.02362061 -0.72705078
  -0.47924805  0.85644531  0.58886719 -0.61816406  0.49365234 -0.66601562
  -0.86230469  0.77685547  0.32714844 -0.84472656 -0.47802734 -0.7890625
   0.74609375 -0.19677734  0.07226562 -0.80224609 -0.8046875  -0.69238281
  -0.34326172 -0.21228027  0.83691406  0.07189941  0.29541016  0.18811035
  -0.45776367  0.58154297  0.63378906  0.46508789  0.96289062 -0.86425781
  -0.57666016 -0.88183594 -0.43432617 -0.35864258 -0.36987305  0.61474609
   0.70410156 -0.85986328  0.40063477 -0.96875    -0.70410156 -0.36328125
   0.39892578 -0.0406189  -0.29492188 -0.96386719 -0.34375     0.87304688
  -0.68505859 -0.02200317  0.74316406  0.44458008 -0.18933105  0.94677734
   0.65039062  0.83691406 -0.99121094 -0.72216797  0.82714844 -0.62207031
   0.42797852 -0.3515625  -0.77294922  0.62744141 -0.93017578 -0.11859131
  -0.71826172 -0.61914062 -0.06124878  0.47949219]]
After layer encoder_birnn_forward_l0_t5_out_0 (1, 256) <class 'numpy.float16'> [[ 0.26000977  0.3190918  -0.45703125 -0.29492188  0.53662109 -0.13684082
   0.7734375  -0.00593948 -0.2286377  -0.08190918  0.45800781  0.48803711
   0.13720703 -0.63330078  0.04971313  0.00365067  0.36157227  0.43603516
  -0.12426758  0.33886719 -0.14733887 -0.24377441 -0.70654297  0.39819336
  -0.17053223 -0.10595703 -0.66064453 -0.04626465 -0.42236328  0.41845703
   0.43310547 -0.29223633  0.41845703 -0.29638672  0.61767578  0.25073242
   0.33349609 -0.52734375 -0.30688477  0.01985168 -0.06494141  0.52441406
  -0.19177246  0.42822266 -0.59472656 -0.33837891 -0.06738281  0.44482422
   0.35009766  0.15771484 -0.00841522  0.00861359 -0.79736328 -0.2434082
   0.63330078  0.26586914 -0.50244141 -0.12432861  0.44555664 -0.00257301
   0.3371582  -0.11730957  0.10351562  0.71972656 -0.34057617  0.08013916
   0.51367188  0.56445312  0.31201172 -0.55029297  0.29956055  0.03445435
  -0.81005859  0.33081055  0.40771484  0.89599609  0.54296875 -0.921875
   0.53125    -0.29516602  0.71777344 -0.26489258 -0.16125488  0.13061523
  -0.47021484 -0.50683594  0.13781738 -0.67089844  0.28051758 -0.07446289
   0.38598633  0.25512695 -0.23132324 -0.3894043  -0.32495117 -0.22497559
  -0.55859375 -0.67822266  0.54150391  0.25683594 -0.33789062 -0.04724121
  -0.0088501   0.63671875 -0.51513672 -0.39575195  0.35888672  0.40625
   0.35327148  0.30834961 -0.703125   -0.58886719  0.86767578  0.85449219
  -0.26733398  0.56103516  0.42724609  0.27246094  0.32373047  0.09802246
   0.07952881 -0.71484375  0.62597656 -0.33129883  0.69921875 -0.15551758
   0.3737793   0.32055664 -0.48339844 -0.87890625  0.16552734  0.63232422
   0.25268555 -0.17456055  0.5         0.50585938  0.35961914  0.26586914
  -0.71337891 -0.27514648 -0.01132202  0.61474609 -0.57910156 -0.12463379
   0.49169922  0.00914001  0.39526367 -0.01792908  0.46899414 -0.1340332
   0.80029297 -0.41894531  0.65820312  0.40356445  0.20275879 -0.40161133
   0.53613281 -0.04589844  0.68261719  0.53320312  0.66357422  0.10357666
   0.2824707   0.60839844 -0.27270508  0.15991211 -0.04428101  0.45166016
  -0.21643066 -0.36767578  0.11706543  0.9609375  -0.34082031  0.76416016
  -0.33300781 -0.42675781  0.12005615  0.10821533 -0.26049805 -0.18835449
   0.58935547  0.3203125   0.42700195  0.46655273 -0.01456451 -0.53076172
  -0.33276367  0.52294922  0.4206543  -0.48486328  0.234375   -0.45263672
  -0.73193359  0.5390625   0.1817627  -0.62011719 -0.46704102 -0.52441406
   0.52734375 -0.14111328  0.04333496 -0.44262695 -0.58984375 -0.55175781
  -0.25268555 -0.16210938  0.66699219  0.03826904  0.11383057  0.13061523
  -0.3347168   0.35644531  0.50341797  0.35180664  0.89306641 -0.72558594
  -0.36499023 -0.73144531 -0.32666016 -0.23095703 -0.24182129  0.45751953
   0.35351562 -0.51855469  0.29467773 -0.63037109 -0.49780273 -0.2479248
   0.28540039 -0.02453613 -0.17199707 -0.79101562 -0.24926758  0.6328125
  -0.52001953 -0.01394653  0.39233398  0.20556641 -0.12670898  0.82617188
   0.34521484  0.65917969 -0.98144531 -0.38623047  0.56103516 -0.34863281
   0.29858398 -0.25048828 -0.61669922  0.48413086 -0.76367188 -0.07177734
  -0.58837891 -0.47045898 -0.03964233  0.34667969]]
After layer expand_dims1037_0 (1, 1, 256) <class 'numpy.float16'> [[[ 0.26000977  0.3190918  -0.45703125 -0.29492188  0.53662109 -0.13684082
    0.7734375  -0.00593948 -0.2286377  -0.08190918  0.45800781  0.48803711
    0.13720703 -0.63330078  0.04971313  0.00365067  0.36157227  0.43603516
   -0.12426758  0.33886719 -0.14733887 -0.24377441 -0.70654297  0.39819336
   -0.17053223 -0.10595703 -0.66064453 -0.04626465 -0.42236328  0.41845703
    0.43310547 -0.29223633  0.41845703 -0.29638672  0.61767578  0.25073242
    0.33349609 -0.52734375 -0.30688477  0.01985168 -0.06494141  0.52441406
   -0.19177246  0.42822266 -0.59472656 -0.33837891 -0.06738281  0.44482422
    0.35009766  0.15771484 -0.00841522  0.00861359 -0.79736328 -0.2434082
    0.63330078  0.26586914 -0.50244141 -0.12432861  0.44555664 -0.00257301
    0.3371582  -0.11730957  0.10351562  0.71972656 -0.34057617  0.08013916
    0.51367188  0.56445312  0.31201172 -0.55029297  0.29956055  0.03445435
   -0.81005859  0.33081055  0.40771484  0.89599609  0.54296875 -0.921875
    0.53125    -0.29516602  0.71777344 -0.26489258 -0.16125488  0.13061523
   -0.47021484 -0.50683594  0.13781738 -0.67089844  0.28051758 -0.07446289
    0.38598633  0.25512695 -0.23132324 -0.3894043  -0.32495117 -0.22497559
   -0.55859375 -0.67822266  0.54150391  0.25683594 -0.33789062 -0.04724121
   -0.0088501   0.63671875 -0.51513672 -0.39575195  0.35888672  0.40625
    0.35327148  0.30834961 -0.703125   -0.58886719  0.86767578  0.85449219
   -0.26733398  0.56103516  0.42724609  0.27246094  0.32373047  0.09802246
    0.07952881 -0.71484375  0.62597656 -0.33129883  0.69921875 -0.15551758
    0.3737793   0.32055664 -0.48339844 -0.87890625  0.16552734  0.63232422
    0.25268555 -0.17456055  0.5         0.50585938  0.35961914  0.26586914
   -0.71337891 -0.27514648 -0.01132202  0.61474609 -0.57910156 -0.12463379
    0.49169922  0.00914001  0.39526367 -0.01792908  0.46899414 -0.1340332
    0.80029297 -0.41894531  0.65820312  0.40356445  0.20275879 -0.40161133
    0.53613281 -0.04589844  0.68261719  0.53320312  0.66357422  0.10357666
    0.2824707   0.60839844 -0.27270508  0.15991211 -0.04428101  0.45166016
   -0.21643066 -0.36767578  0.11706543  0.9609375  -0.34082031  0.76416016
   -0.33300781 -0.42675781  0.12005615  0.10821533 -0.26049805 -0.18835449
    0.58935547  0.3203125   0.42700195  0.46655273 -0.01456451 -0.53076172
   -0.33276367  0.52294922  0.4206543  -0.48486328  0.234375   -0.45263672
   -0.73193359  0.5390625   0.1817627  -0.62011719 -0.46704102 -0.52441406
    0.52734375 -0.14111328  0.04333496 -0.44262695 -0.58984375 -0.55175781
   -0.25268555 -0.16210938  0.66699219  0.03826904  0.11383057  0.13061523
   -0.3347168   0.35644531  0.50341797  0.35180664  0.89306641 -0.72558594
   -0.36499023 -0.73144531 -0.32666016 -0.23095703 -0.24182129  0.45751953
    0.35351562 -0.51855469  0.29467773 -0.63037109 -0.49780273 -0.2479248
    0.28540039 -0.02453613 -0.17199707 -0.79101562 -0.24926758  0.6328125
   -0.52001953 -0.01394653  0.39233398  0.20556641 -0.12670898  0.82617188
    0.34521484  0.65917969 -0.98144531 -0.38623047  0.56103516 -0.34863281
    0.29858398 -0.25048828 -0.61669922  0.48413086 -0.76367188 -0.07177734
   -0.58837891 -0.47045898 -0.03964233  0.34667969]]]
After layer encoder_birnn_forward_l0_t6_i2h_output (1, 1024) <class 'numpy.float16'> [[ 0.0737915  -0.0458374   0.06152344 ...,  0.03591919  0.03396606
   0.02903748]]
After layer encoder_birnn_forward_l0_t6_h2h_output (1, 1024) <class 'numpy.float16'> [[ 0.76269531  0.76074219  0.50585938 ...,  1.56640625  0.80029297
   1.27539062]]
After layer _plus1032_0 (1, 1024) <class 'numpy.float16'> [[ 0.83642578  0.71484375  0.56738281 ...,  1.60253906  0.83447266
   1.3046875 ]]
After layer encoder_birnn_forward_l0_t6_slice_output0 (1, 256) <class 'numpy.float16'> [[ 0.83642578  0.71484375  0.56738281  0.53076172  1.14746094  1.08105469
   2.02929688  0.09057617 -0.65234375  0.73046875  0.65820312  1.13867188
  -0.12109375  1.35449219 -0.609375    0.29150391  0.4855957   0.88964844
   1.07714844  0.58789062 -0.02490234 -1.26855469  0.72607422  0.52685547
   0.32275391  0.33276367  1.22851562 -0.01654053  1.01660156  1.07324219
   0.93945312  0.78564453  1.48242188  0.9453125   2.55078125  0.13598633
   0.45263672  2.56054688  1.80273438 -1.05273438 -0.46069336  0.79003906
   1.65820312  0.19311523  2.4140625   0.76416016  0.50634766  0.89990234
   0.34887695 -0.26196289 -0.35498047 -0.41943359  4.66015625  0.47241211
   1.80957031  0.06030273  1.55664062  0.12011719  0.62646484 -1.39257812
   0.55273438  0.46533203 -0.20800781  1.74902344  0.06323242  0.21740723
   1.21875     2.05078125  1.00878906  1.73046875 -0.30200195 -1.3515625
   2.66015625  0.84472656  0.66894531  2.70703125  1.12304688  3.72265625
   0.87109375 -0.77832031  1.59472656  0.72705078  0.99755859 -0.20446777
   1.56542969  1.08789062  0.51953125  2.21289062  1.69238281 -0.3371582
   0.88769531 -0.26489258 -0.29248047  0.80859375 -0.72705078 -1.17285156
   1.56445312  1.828125    1.45019531  0.77099609  0.40625    -0.46679688
   0.61328125  1.93847656  1.15820312  0.36352539  0.14001465  0.35449219
  -0.13696289  0.22290039  1.72167969  1.48046875  3.171875    3.91015625
   1.08398438  1.35742188  0.69140625  1.42089844  0.3737793  -0.39086914
  -0.35058594  1.68945312  2.67382812  0.61962891  2.5234375   0.3515625
   0.65039062  0.703125    0.41064453  2.77734375 -0.53857422  1.34375
   0.73144531  0.35351562  1.41308594  1.07128906  0.99804688 -0.89111328
   1.17285156 -0.08587646  0.15344238  1.77636719  1.1640625   0.03918457
   0.91357422 -0.92382812  0.06518555 -0.45849609  1.50683594 -0.20202637
   2.34179688  1.2734375   2.3828125   1.79199219  0.13635254  1.51269531
   0.98046875 -0.38867188  1.5078125   1.27050781  2.69726562 -0.27148438
   1.18359375  1.37011719  1.07421875 -0.0168457   0.22033691  0.83154297
  -0.20141602  0.57324219 -0.66699219  5.55078125  0.62792969  1.90527344
   0.95996094  0.38476562 -0.30883789 -0.68066406 -0.05004883  0.60791016
   1.93652344  0.62207031  0.76513672  0.43408203 -0.35473633  0.90087891
   0.17614746  1.57421875  1.08691406  0.90234375 -0.74462891  0.26904297
   2.06445312  0.60009766  0.65820312  1.56542969  4.46484375  1.80664062
   1.06738281  0.22290039  0.42724609  1.29589844  0.86572266  1.04589844
   0.84863281 -0.01104736  1.25488281 -0.5625     -0.57958984  0.63232422
   1.04492188  0.58154297  1.66699219  0.72607422  2.96875     1.60351562
   0.52441406  2.015625    0.81396484 -0.63623047  0.40771484  0.55957031
   0.74511719  1.05371094  0.89208984  4.19140625  1.03027344 -0.1697998
  -0.02270508 -0.00914001 -0.78613281  3.57421875  0.57177734  1.83007812
   1.03613281 -0.10809326  0.60791016 -0.45751953  0.13232422  2.22851562
   0.43481445  1.17382812  6.12890625  0.8125      1.51269531  1.01464844
   0.59326172  0.40820312  1.21777344  0.62255859  2.22851562 -0.85351562
   1.4921875   0.86279297 -0.51123047  0.57421875]]
After layer encoder_birnn_forward_l0_t6_slice_output1 (1, 256) <class 'numpy.float16'> [[  1.61523438e+00   1.33544922e-01   2.99072266e-01   6.89453125e-01
    5.32714844e-01   6.34765625e-01   1.94726562e+00   5.30761719e-01
    2.65429688e+00   4.81933594e-01   1.84472656e+00   7.76367188e-01
    1.24316406e+00   1.21777344e+00  -2.63671875e-01   6.44531250e-01
    6.60156250e-01   5.21972656e-01   1.53906250e+00   9.71191406e-01
    1.92626953e-01  -3.17138672e-01   1.75097656e+00   3.29101562e-01
    9.68261719e-01   9.04785156e-01   1.10742188e+00   5.64941406e-01
    1.40722656e+00   3.96728516e-01   1.50390625e+00   1.25390625e+00
    7.54882812e-01   9.34082031e-01   2.08203125e+00   5.55175781e-01
    2.78320312e-01   8.72070312e-01   2.13671875e+00   1.97753906e-02
    1.14062500e+00   7.56835938e-01   1.84179688e+00  -2.59033203e-01
    1.84692383e-01  -4.31396484e-01   1.95117188e+00   9.46777344e-01
    3.75000000e-01  -2.86132812e-01  -4.10888672e-01   7.06542969e-01
    3.80468750e+00  -3.79394531e-01   1.55175781e+00  -5.20507812e-01
    4.49218750e-01   8.55468750e-01   9.21386719e-01   1.16699219e+00
   -6.77490234e-03   6.54296875e-01   2.74169922e-01   1.34375000e+00
    3.75732422e-01   7.60253906e-01   1.20898438e+00   1.29003906e+00
    7.00195312e-01   2.02539062e+00  -6.37817383e-02   9.03808594e-01
    2.21289062e+00   8.23242188e-01   2.08984375e-01   3.63281250e+00
    5.70800781e-01   3.45312500e+00   1.17480469e+00  -7.88574219e-01
    1.57128906e+00  -6.80664062e-01   2.92382812e+00   1.20312500e+00
    1.43554688e+00   1.05761719e+00   3.38439941e-02   2.06835938e+00
    3.55664062e+00   5.18066406e-01   3.68164062e-01   9.51660156e-01
   -8.53271484e-02   9.25781250e-01  -2.79052734e-01   7.37915039e-02
    1.72070312e+00   1.57128906e+00   1.52343750e+00   1.65625000e+00
    3.33740234e-01  -3.44970703e-01   6.59179688e-02   1.47167969e+00
    1.34667969e+00   4.02832031e-01   8.65234375e-01   1.05664062e+00
    7.95898438e-01   6.09863281e-01   1.44433594e+00   1.95214844e+00
    2.42382812e+00   2.77148438e+00   1.13281250e+00   7.84179688e-01
    1.43652344e+00   1.72363281e+00   7.74414062e-01   6.51855469e-01
    9.02832031e-01   1.98046875e+00   1.08007812e+00   7.11425781e-01
    1.57617188e+00   9.98046875e-01  -6.51367188e-01   7.20703125e-01
    7.68554688e-01   2.79687500e+00   6.85546875e-01   1.22558594e+00
    3.11279297e-01   4.79492188e-01   6.95800781e-01   1.27539062e+00
    1.40234375e+00  -6.98730469e-01   2.05859375e+00   1.30859375e+00
    7.14843750e-01   9.93652344e-01   1.17871094e+00   1.08300781e+00
    1.18847656e+00   1.45605469e+00   4.92675781e-01   9.87792969e-01
    1.70410156e+00   9.28222656e-01   1.42968750e+00   4.08203125e-01
    9.50683594e-01   1.08691406e+00   7.19238281e-01   5.31250000e-01
    1.67187500e+00   5.62988281e-01   1.90136719e+00   9.88769531e-01
    1.89062500e+00   9.49707031e-01   1.43164062e+00   1.20703125e+00
    1.39160156e+00   4.64111328e-01   5.67871094e-01   6.92382812e-01
   -3.30078125e-01   3.69628906e-01  -3.96484375e-01   2.87890625e+00
    7.61230469e-01   2.09960938e+00   1.50146484e-01   3.55468750e-01
    6.69433594e-01   1.36718750e+00  -1.71142578e-01   1.78808594e+00
    6.24023438e-01  -2.35473633e-01   1.48730469e+00   1.09472656e+00
    7.73437500e-01   9.31640625e-01   1.45800781e+00   1.10156250e+00
    1.00781250e+00   1.34375000e+00  -7.26562500e-01   8.33496094e-01
    1.81933594e+00   1.09179688e+00  -1.01440430e-01   5.80078125e-01
    5.80859375e+00  -2.10205078e-01   9.82421875e-01  -1.39160156e-01
    6.24511719e-01   1.07812500e+00   7.00195312e-01   2.06835938e+00
    9.30175781e-01   4.98535156e-01   1.64453125e+00  -5.94726562e-01
   -1.21520996e-01   1.38867188e+00   1.31347656e+00   7.91015625e-01
    1.25488281e+00   9.43359375e-01   2.85156250e+00   1.95214844e+00
    3.70849609e-01   1.46484375e+00   2.23999023e-02   3.23486328e-03
    4.46044922e-01   1.17285156e+00  -1.11083984e-01   1.25097656e+00
    8.27148438e-01   2.10351562e+00  -7.20703125e-01   6.41113281e-01
    9.82421875e-01   6.70410156e-01   5.80566406e-01   2.55078125e+00
    4.63378906e-01   1.04394531e+00   1.59179688e+00   9.95117188e-01
    4.33105469e-01   2.62207031e-01   5.19042969e-01   2.35546875e+00
    3.58154297e-01   1.59765625e+00   5.85937500e+00  -2.64160156e-01
    7.76367188e-01  -2.79785156e-01   4.03320312e-01   7.72949219e-01
    1.05273438e+00   1.19140625e+00   2.16406250e+00  -2.31445312e-01
    1.82617188e+00   8.18359375e-01   6.50390625e-01   1.03808594e+00]]
After layer encoder_birnn_forward_l0_t6_slice_output2 (1, 256) <class 'numpy.float16'> [[  4.60693359e-01   7.60253906e-01  -1.79980469e+00  -6.71875000e-01
    2.34765625e+00  -1.73828125e-01   2.06054688e+00   2.02026367e-02
   -6.74804688e-01  -1.60400391e-01   1.31835938e+00   1.40429688e+00
    3.73291016e-01  -1.78613281e+00   2.31811523e-01  -2.91442871e-03
    8.93554688e-01   1.63085938e+00  -2.86376953e-01   8.13476562e-01
   -3.09082031e-01  -3.23242188e+00  -2.81835938e+00   1.06933594e+00
   -3.26416016e-01  -3.05419922e-01  -2.27734375e+00  -6.64672852e-02
   -1.96191406e+00   1.23730469e+00   9.80957031e-01  -5.62500000e-01
    1.74414062e+00  -7.25585938e-01   3.38085938e+00   8.48632812e-01
    8.31054688e-01  -3.28320312e+00  -2.38671875e+00  -1.27319336e-01
   -1.13403320e-01   2.61328125e+00  -3.32519531e-01   1.98535156e+00
   -3.91210938e+00  -9.15527344e-01  -7.77587891e-02   9.94140625e-01
    1.14160156e+00   6.59667969e-01  -1.12304688e-02   5.27954102e-02
   -1.34472656e+00  -1.14550781e+00   2.53515625e+00   1.47265625e+00
   -2.92773438e+00  -3.08105469e-01   1.50683594e+00   7.59277344e-02
    1.95214844e+00  -1.56616211e-01   3.95019531e-01   4.84765625e+00
   -1.48632812e+00   1.44897461e-01   1.35253906e+00   2.36718750e+00
    6.35742188e-01  -2.13671875e+00   9.48730469e-01   1.09252930e-01
   -3.18359375e+00   7.44628906e-01   1.31542969e+00   2.53125000e+00
    2.18945312e+00  -4.38281250e+00   1.36523438e+00  -2.76757812e+00
    2.97265625e+00  -1.38378906e+00  -1.56005859e-01   3.74511719e-01
   -9.02832031e-01  -2.20117188e+00   4.27734375e-01  -2.87304688e+00
    2.53173828e-01  -1.92993164e-01   1.30566406e+00   7.88574219e-01
   -2.38476562e+00  -8.27148438e-01  -3.53320312e+00  -8.92578125e-01
   -1.31445312e+00  -3.07617188e+00   1.29492188e+00   3.71826172e-01
   -1.54589844e+00  -1.50390625e-01  -5.64575195e-02   1.39062500e+00
   -1.03027344e+00  -2.16015625e+00   8.67187500e-01   9.49218750e-01
    7.99316406e-01   1.18750000e+00  -2.47460938e+00  -1.92480469e+00
    3.87304688e+00   3.57226562e+00  -3.45458984e-01   2.19726562e+00
    1.04003906e+00   4.09667969e-01   7.61718750e-01   2.26562500e-01
    3.18359375e-01  -1.72070312e+00   2.12890625e+00  -9.03808594e-01
    3.96093750e+00  -5.62500000e-01   2.98828125e+00   1.27441406e+00
   -2.47656250e+00  -3.20117188e+00   4.83398438e-01   1.42773438e+00
    7.02636719e-01  -4.65332031e-01   2.22656250e+00   2.64257812e+00
    8.95996094e-01   1.89648438e+00  -3.11914062e+00  -8.07617188e-01
   -4.45251465e-02   3.05078125e+00  -2.58984375e+00  -3.00537109e-01
    2.30859375e+00   5.25207520e-02   1.73046875e+00   6.15844727e-02
    3.02734375e+00  -3.26171875e-01   3.25781250e+00  -1.41601562e+00
    3.58203125e+00   1.82519531e+00   6.50390625e-01  -2.88085938e+00
    2.97460938e+00  -8.20312500e-02   1.72070312e+00   1.69531250e+00
    4.50390625e+00   4.73632812e-02   7.23632812e-01   2.05273438e+00
   -3.73046875e-01   3.75976562e-01  -1.58691406e-01   2.17578125e+00
   -1.27246094e+00  -1.24902344e+00   4.50683594e-01   4.67968750e+00
   -8.36914062e-01   3.45312500e+00  -1.66406250e+00  -2.92187500e+00
    4.13574219e-01   2.36572266e-01  -1.11425781e+00  -3.64501953e-01
    2.94531250e+00   2.05273438e+00   9.55566406e-01   1.31738281e+00
   -6.06994629e-02  -1.58398438e+00  -8.77441406e-01   2.66601562e+00
    1.16406250e+00  -1.10644531e+00   2.57812500e+00  -1.65429688e+00
   -1.98144531e+00   2.44726562e+00   5.75195312e-01  -2.85156250e+00
   -4.09179688e-01  -2.40625000e+00   1.73339844e+00  -3.95751953e-01
    4.07104492e-02  -1.90820312e+00  -3.22265625e+00  -1.28515625e+00
   -4.91210938e-01  -2.52685547e-01   2.37890625e+00   6.22253418e-02
    6.72363281e-01   2.96630859e-01  -6.67480469e-01   1.12792969e+00
    1.02441406e+00   7.24609375e-01   3.64843750e+00  -2.32421875e+00
   -1.30761719e+00  -2.66796875e+00  -8.09570312e-01  -1.08007812e+00
   -7.03125000e-01   1.10351562e+00   2.21093750e+00  -3.31250000e+00
    6.23535156e-01  -4.15625000e+00  -2.21679688e+00  -6.81152344e-01
    6.46484375e-01  -1.08764648e-01  -7.72949219e-01  -3.18359375e+00
   -4.86572266e-01   2.82226562e+00  -1.15234375e+00  -1.76696777e-02
    2.26757812e+00   1.23730469e+00  -2.81005859e-01   4.40625000e+00
    1.92578125e+00   2.01757812e+00  -4.60156250e+00  -2.57812500e+00
    2.44726562e+00  -1.46582031e+00   6.26953125e-01  -5.72753906e-01
   -1.67968750e+00   1.31347656e+00  -2.66601562e+00  -2.31933594e-01
   -1.20019531e+00  -1.02539062e+00  -7.64160156e-02   7.98828125e-01]]
After layer encoder_birnn_forward_l0_t6_slice_output3 (1, 256) <class 'numpy.float16'> [[ 1.6796875   0.95214844  1.03027344  1.46191406  0.98828125  1.47753906
   2.93945312  0.88378906  1.30761719  1.0703125   1.23144531  1.19921875
   0.97460938  1.94238281 -0.14233398  0.34814453  1.21875     0.68847656
   2.640625    1.45117188  0.82910156 -0.1126709   2.27148438  1.59570312
   0.86669922  0.73828125  1.97070312  1.28710938  0.21875     1.15429688
   1.6328125   1.47070312  0.13244629  0.94042969  0.93603516  0.54394531
   1.34570312  0.48852539 -0.93798828  0.74072266  0.77148438  1.04980469
   0.98193359  1.046875    1.06542969  1.22167969  2.671875    1.42675781
   0.9921875   0.25341797 -0.5546875   1.35742188  4.7109375  -0.23352051
   1.32519531 -0.20385742  0.65039062  0.95458984  1.37597656  0.88134766
   0.08349609  0.6875      0.24182129  1.87304688  0.66796875  1.05761719
   1.703125    0.78271484  1.10546875  0.81347656  1.37402344  1.27929688
   2.51367188  1.125       0.84228516  4.171875    1.19921875  3.83007812
   1.83691406  0.23083496  2.19726562 -0.30004883  4.734375    1.00683594
   1.7265625   0.80371094  0.71484375  1.359375    3.02539062  1.48828125
   0.88769531  1.15820312 -0.7109375   1.89257812  0.37988281  1.421875
   1.44726562  1.5546875   1.44140625  2.265625    0.46289062  0.84277344
   0.33666992  2.18554688  1.56738281  0.47338867  1.15234375  1.53808594
   1.70214844  0.33398438  2.06835938  1.27050781  3.08984375  2.77539062
   1.53808594  1.15039062  1.23046875  2.484375    1.20996094  1.3671875
   0.95654297  2.57226562  1.4296875   1.08984375  1.48339844  1.66699219
   0.09289551  0.24731445  0.89941406  3.5234375   1.41699219  2.28515625
   0.87890625  1.11132812  0.64794922  0.66064453  1.63671875  0.81982422
   1.84765625  1.30371094  0.66601562  1.25        1.09277344  1.32714844
   0.70654297  1.56152344  0.99951172  0.90722656  0.16137695  0.55322266
   2.8203125   0.6328125   1.32128906  0.13928223  0.59082031 -0.05786133
   0.69677734  1.05664062  2.49023438  1.26464844  1.10546875  1.46289062
   0.31420898  1.578125    2.20117188  0.47851562  1.22558594  0.44360352
  -0.31225586  0.625       0.74560547  5.15625     1.41210938  2.125
   0.08929443  0.49023438  1.109375    1.34375     0.71630859  1.85546875
   1.08007812 -0.08557129  1.4140625   1.47460938  0.65527344  1.37011719
   1.15625     0.68359375  1.34960938  1.7890625  -0.19836426  1.0703125
   2.484375    1.03613281  0.34887695  1.38671875  5.1953125   0.91503906
   1.23339844  1.3125      0.53662109  0.37548828  1.41015625  2.00390625
   1.48144531  1.60644531  1.9296875   0.12060547 -0.68945312  1.13085938
   1.43359375  0.65429688  1.98925781  1.62011719  3.63476562  2.31640625
   0.74121094  2.24609375  1.54394531  0.80908203  0.89501953  1.48730469
  -0.05401611  0.50097656  1.50488281  0.90136719  1.24804688  1.12597656
   1.26757812  0.71337891  0.57958984  2.17382812  1.40527344  1.33789062
   1.62304688  0.87011719  0.20410156 -0.1920166   1.01953125  2.7734375
   0.14807129  1.86914062  6.6640625   0.26904297  1.06738281  0.27197266
   1.18847656  1.31933594  2.03515625  1.6640625   2.12304688  0.62548828
   2.16796875  1.60253906  0.83447266  1.3046875 ]]
After layer encoder_birnn_forward_l0_t6_o_output (1, 256) <class 'numpy.float16'> [[ 0.84277344  0.72167969  0.73681641  0.81201172  0.72851562  0.81396484
   0.94970703  0.70751953  0.78710938  0.74462891  0.77392578  0.76855469
   0.72607422  0.87451172  0.46435547  0.5859375   0.77197266  0.66552734
   0.93359375  0.81005859  0.69628906  0.47192383  0.90625     0.83154297
   0.70410156  0.67675781  0.87792969  0.78369141  0.5546875   0.76025391
   0.83642578  0.81298828  0.53320312  0.71923828  0.71826172  0.6328125
   0.79345703  0.61962891  0.28125     0.67724609  0.68408203  0.74072266
   0.72753906  0.74023438  0.74365234  0.77246094  0.93554688  0.80615234
   0.72949219  0.56298828  0.36474609  0.79541016  0.99121094  0.44189453
   0.79003906  0.44921875  0.65722656  0.72216797  0.79833984  0.70703125
   0.52099609  0.66552734  0.56005859  0.86669922  0.66113281  0.7421875
   0.84570312  0.68603516  0.75146484  0.69287109  0.79785156  0.78222656
   0.92529297  0.75488281  0.69873047  0.98486328  0.76855469  0.97851562
   0.86279297  0.55761719  0.89990234  0.42553711  0.99121094  0.73242188
   0.84912109  0.69091797  0.67138672  0.79589844  0.95361328  0.81591797
   0.70849609  0.76123047  0.3293457   0.86914062  0.59375     0.80566406
   0.80957031  0.82568359  0.80859375  0.90576172  0.61376953  0.69921875
   0.58349609  0.89892578  0.82763672  0.61621094  0.75976562  0.82324219
   0.84570312  0.58251953  0.88769531  0.78076172  0.95654297  0.94140625
   0.82324219  0.75976562  0.77392578  0.92285156  0.77050781  0.796875
   0.72265625  0.92919922  0.80664062  0.74853516  0.81494141  0.84130859
   0.5234375   0.56152344  0.7109375   0.97119141  0.8046875   0.90771484
   0.70654297  0.75244141  0.65673828  0.65917969  0.83691406  0.69433594
   0.86376953  0.78662109  0.66064453  0.77734375  0.74902344  0.79052734
   0.66943359  0.82666016  0.73095703  0.71240234  0.54003906  0.63476562
   0.94384766  0.65332031  0.78955078  0.53466797  0.64355469  0.4855957
   0.66748047  0.7421875   0.92333984  0.77978516  0.75146484  0.81201172
   0.578125    0.82910156  0.90039062  0.6171875   0.77294922  0.60888672
   0.42260742  0.65136719  0.67822266  0.99414062  0.80419922  0.89306641
   0.52246094  0.62011719  0.75195312  0.79296875  0.671875    0.86474609
   0.74658203  0.47851562  0.80419922  0.81396484  0.65820312  0.79736328
   0.76074219  0.66455078  0.79394531  0.85693359  0.45068359  0.74462891
   0.92285156  0.73828125  0.58642578  0.80029297  0.99462891  0.71386719
   0.77441406  0.78808594  0.63085938  0.59277344  0.80371094  0.88134766
   0.81494141  0.83300781  0.87304688  0.53027344  0.33422852  0.75585938
   0.80761719  0.65820312  0.87988281  0.83496094  0.97412109  0.91015625
   0.67724609  0.90429688  0.82421875  0.69189453  0.70996094  0.81542969
   0.48657227  0.62255859  0.81835938  0.71142578  0.77685547  0.75488281
   0.78027344  0.67138672  0.64111328  0.89794922  0.80322266  0.79199219
   0.83544922  0.70458984  0.55078125  0.45214844  0.73486328  0.94140625
   0.53710938  0.86621094  0.99853516  0.56689453  0.74414062  0.56738281
   0.76660156  0.7890625   0.88427734  0.84082031  0.89306641  0.65136719
   0.89746094  0.83251953  0.69726562  0.78662109]]
After layer encoder_birnn_forward_l0_t6_f_output (1, 256) <class 'numpy.float16'> [[ 0.83398438  0.53320312  0.57421875  0.66601562  0.62988281  0.65380859
   0.875       0.62988281  0.93408203  0.61816406  0.86328125  0.68505859
   0.77587891  0.77148438  0.43457031  0.65576172  0.65917969  0.62744141
   0.82324219  0.72558594  0.54785156  0.42138672  0.85205078  0.58154297
   0.72460938  0.71191406  0.75146484  0.63769531  0.80322266  0.59814453
   0.81835938  0.77783203  0.68017578  0.71777344  0.88916016  0.63525391
   0.56933594  0.70507812  0.89453125  0.50488281  0.7578125   0.68066406
   0.86328125  0.43554688  0.54589844  0.39379883  0.87548828  0.72070312
   0.59277344  0.42895508  0.39868164  0.66943359  0.97802734  0.40625
   0.82519531  0.37280273  0.61035156  0.70166016  0.71533203  0.76269531
   0.49829102  0.65820312  0.56835938  0.79296875  0.59277344  0.68164062
   0.77001953  0.78417969  0.66845703  0.88330078  0.48413086  0.71191406
   0.90136719  0.69482422  0.55224609  0.97412109  0.63916016  0.96923828
   0.76416016  0.3125      0.828125    0.33618164  0.94921875  0.76904297
   0.80761719  0.7421875   0.50830078  0.88769531  0.97216797  0.62646484
   0.59082031  0.72167969  0.47875977  0.71630859  0.43066406  0.51855469
   0.84814453  0.828125    0.82080078  0.83984375  0.58251953  0.41455078
   0.51660156  0.81347656  0.79345703  0.59960938  0.70361328  0.7421875
   0.68896484  0.64794922  0.80908203  0.87548828  0.91845703  0.94091797
   0.75634766  0.68652344  0.80810547  0.84863281  0.68457031  0.65722656
   0.71142578  0.87890625  0.74658203  0.67089844  0.82861328  0.73046875
   0.34277344  0.67285156  0.68310547  0.94238281  0.66503906  0.77294922
   0.57714844  0.61767578  0.66748047  0.78173828  0.80273438  0.33203125
   0.88671875  0.78710938  0.67138672  0.72998047  0.76464844  0.74707031
   0.76660156  0.81103516  0.62060547  0.72851562  0.84619141  0.71679688
   0.80664062  0.60058594  0.72119141  0.74755859  0.67236328  0.62988281
   0.84179688  0.63720703  0.87011719  0.72900391  0.86865234  0.72119141
   0.80712891  0.76953125  0.80078125  0.61376953  0.63818359  0.66650391
   0.41821289  0.59130859  0.40209961  0.94677734  0.68164062  0.890625
   0.53759766  0.58789062  0.66113281  0.796875    0.45727539  0.85693359
   0.65136719  0.44140625  0.81542969  0.74951172  0.68408203  0.71728516
   0.81103516  0.75048828  0.73242188  0.79296875  0.32592773  0.69726562
   0.86035156  0.74853516  0.47460938  0.64111328  0.99707031  0.44775391
   0.72753906  0.46533203  0.65136719  0.74609375  0.66845703  0.88769531
   0.71728516  0.62207031  0.83837891  0.35546875  0.46972656  0.80029297
   0.78808594  0.68798828  0.77832031  0.71972656  0.9453125   0.87548828
   0.59179688  0.8125      0.50537109  0.50097656  0.60986328  0.76367188
   0.47216797  0.77734375  0.69580078  0.89111328  0.32714844  0.65478516
   0.72753906  0.66162109  0.64111328  0.92773438  0.61376953  0.73974609
   0.83105469  0.72998047  0.60644531  0.56494141  0.62695312  0.91357422
   0.58837891  0.83154297  0.99707031  0.43432617  0.68505859  0.43041992
   0.59960938  0.68408203  0.74121094  0.76708984  0.89697266  0.44238281
   0.86132812  0.69384766  0.65722656  0.73828125]]
After layer _mul2064_0 (1, 256) <class 'numpy.float16'> [[ 0.29760742  0.27832031 -0.46337891 -0.28173828  0.68945312 -0.1229248
   1.18066406 -0.00576782 -0.30786133 -0.07305908  0.68798828  0.57861328
   0.1640625  -0.84228516  0.04522705  0.00418854  0.36889648  0.55224609
  -0.1192627   0.35620117 -0.1307373  -0.2286377  -1.05273438  0.34277344
  -0.19067383 -0.12561035 -0.87988281 -0.04110718 -0.84082031  0.42236328
   0.53955078 -0.32080078  0.73681641 -0.3449707   1.52441406  0.28442383
   0.28637695 -1.07226562 -1.26171875  0.01596069 -0.07617188  0.69921875
  -0.2578125   0.32373047 -0.74169922 -0.20629883 -0.06744385  0.515625
   0.34277344  0.1270752  -0.00823975  0.00804901 -1.15234375 -0.23388672
   1.171875    0.23840332 -0.72314453 -0.13391113  0.51806641 -0.002985
   0.40112305 -0.12121582  0.11120605  1.25097656 -0.37426758  0.08050537
   0.61865234  1.12304688  0.33398438 -1.11523438  0.21057129  0.03463745
  -1.58886719  0.36572266  0.40991211  1.74121094  0.66455078 -2.23046875
   0.61669922 -0.18408203  1.11621094 -0.2277832  -0.15991211  0.15063477
  -0.56494141 -0.78857422  0.11553955 -1.4140625   0.3137207  -0.0637207
   0.40161133  0.28540039 -0.33203125 -0.38476562 -0.28271484 -0.15856934
  -0.83837891 -1.21777344  0.75488281  0.26904297 -0.38500977 -0.0302124
  -0.00812531  0.84863281 -0.66308594 -0.50292969  0.41162109  0.44580078
   0.34521484  0.39672852 -1.06542969 -1.06835938  1.83105469  1.95898438
  -0.2824707   0.76708984  0.56689453  0.28173828  0.34301758  0.08874512
   0.08459473 -1.05957031  0.99023438 -0.35302734  1.484375   -0.15124512
   0.29980469  0.47436523 -0.65917969 -1.75585938  0.15344238  0.76904297
   0.24035645 -0.16027832  0.75439453  0.95410156  0.41479492  0.1427002
  -1.28710938 -0.32592773 -0.01248932  0.99072266 -0.93359375 -0.13208008
   0.81884766  0.01010132  0.4284668  -0.02009583  1.19042969 -0.16174316
   1.25683594 -0.50976562  1.11425781  0.78125     0.23669434 -0.75292969
   1.11425781 -0.04418945  0.97314453  0.70751953  1.62402344  0.10308838
   0.4362793   0.89111328 -0.27734375  0.17077637 -0.04034424  0.68164062
  -0.21765137 -0.41259766  0.0748291   2.30859375 -0.34106445  1.46679688
  -0.43212891 -0.54931641  0.11846924  0.12103271 -0.20385742 -0.21191406
   0.85888672  0.36401367  0.55273438  0.56005859 -0.01615906 -0.66210938
  -0.42333984  0.95996094  0.49536133 -0.57226562  0.1763916  -0.56054688
  -1.12011719  0.77636719  0.16113281 -0.79394531 -0.51904297 -0.47827148
   0.70117188 -0.09277344  0.04714966 -0.82421875 -0.74267578 -0.75683594
  -0.25683594 -0.13415527  1.015625    0.02560425  0.14294434  0.15234375
  -0.38989258  0.45727539  0.58203125  0.36279297  1.87402344 -1.14746094
  -0.38916016 -1.125      -0.23510742 -0.18798828 -0.23669434  0.54736328
   0.41333008 -1.00488281  0.29516602 -1.84277344 -0.28613281 -0.24926758
   0.30737305 -0.02690125 -0.19482422 -1.85351562 -0.2199707   0.99560547
  -0.69726562 -0.0160675   0.58056641  0.27001953 -0.12017822  1.64257812
   0.45678711  1.00683594 -2.69140625 -0.39648438  0.80810547 -0.31347656
   0.27441406 -0.2512207  -0.76171875  0.56542969 -1.49023438 -0.05270386
  -0.77880859 -0.50195312 -0.04031372  0.38574219]]
After layer encoder_birnn_forward_l0_t6_i_output (1, 256) <class 'numpy.float16'> [[ 0.69775391  0.67138672  0.63818359  0.62988281  0.75927734  0.74658203
   0.88378906  0.52246094  0.3425293   0.67480469  0.65869141  0.75732422
   0.46972656  0.79492188  0.35229492  0.57226562  0.61914062  0.70898438
   0.74609375  0.64306641  0.49389648  0.21948242  0.67382812  0.62890625
   0.58007812  0.58251953  0.7734375   0.49584961  0.734375    0.74511719
   0.71875     0.68701172  0.81494141  0.72021484  0.92773438  0.53417969
   0.61132812  0.92822266  0.85839844  0.25878906  0.38671875  0.68798828
   0.83984375  0.54833984  0.91796875  0.68212891  0.62402344  0.7109375
   0.58642578  0.43481445  0.41210938  0.39672852  0.99072266  0.61572266
   0.859375    0.51513672  0.82568359  0.52978516  0.65185547  0.19897461
   0.63476562  0.61425781  0.44824219  0.85205078  0.515625    0.55419922
   0.77197266  0.88623047  0.73291016  0.84960938  0.42504883  0.20556641
   0.93457031  0.69921875  0.66113281  0.9375      0.75439453  0.9765625
   0.70507812  0.31469727  0.83105469  0.67431641  0.73046875  0.44897461
   0.82714844  0.74804688  0.62695312  0.90136719  0.84472656  0.41650391
   0.70849609  0.43408203  0.42749023  0.69189453  0.32592773  0.23632812
   0.82714844  0.86132812  0.81005859  0.68359375  0.60009766  0.38525391
   0.64892578  0.87402344  0.76123047  0.58984375  0.53515625  0.58789062
   0.46582031  0.55566406  0.84814453  0.81445312  0.95996094  0.98046875
   0.74707031  0.79541016  0.66650391  0.80566406  0.59228516  0.40356445
   0.41333008  0.84423828  0.93554688  0.64990234  0.92578125  0.58691406
   0.65722656  0.66894531  0.60107422  0.94140625  0.3684082   0.79296875
   0.67529297  0.58740234  0.80419922  0.74462891  0.73046875  0.29077148
   0.76367188  0.47851562  0.53808594  0.85546875  0.76220703  0.50976562
   0.71386719  0.28417969  0.51611328  0.38745117  0.81835938  0.44970703
   0.91210938  0.78125     0.91552734  0.85693359  0.53417969  0.81933594
   0.72705078  0.40405273  0.81884766  0.78076172  0.93701172  0.43261719
   0.765625    0.79736328  0.74560547  0.49584961  0.5546875   0.69677734
   0.44970703  0.63964844  0.33911133  0.99609375  0.65185547  0.87060547
   0.72314453  0.59521484  0.42333984  0.33618164  0.48754883  0.64746094
   0.87402344  0.65087891  0.68261719  0.60693359  0.41235352  0.7109375
   0.54394531  0.82861328  0.74755859  0.71142578  0.32202148  0.56689453
   0.88720703  0.64550781  0.65869141  0.82714844  0.98876953  0.85888672
   0.74414062  0.55566406  0.60498047  0.78515625  0.70361328  0.73974609
   0.70019531  0.49731445  0.77832031  0.36303711  0.35913086  0.65283203
   0.73974609  0.64160156  0.84130859  0.67382812  0.95117188  0.83251953
   0.62841797  0.88232422  0.69287109  0.34619141  0.60058594  0.63623047
   0.67822266  0.74169922  0.70947266  0.98486328  0.73681641  0.45776367
   0.49438477  0.49780273  0.31298828  0.97265625  0.63916016  0.86181641
   0.73828125  0.47290039  0.64746094  0.38769531  0.53320312  0.90283203
   0.60693359  0.76367188  0.99804688  0.69287109  0.81933594  0.73388672
   0.64404297  0.60058594  0.77148438  0.65087891  0.90283203  0.29858398
   0.81640625  0.703125    0.375       0.63964844]]
After layer encoder_birnn_forward_l0_t6_c_output (1, 256) <class 'numpy.float16'> [[ 0.43066406  0.64111328 -0.94677734 -0.58642578  0.98193359 -0.17211914
   0.96826172  0.02020264 -0.58789062 -0.15905762  0.86621094  0.88623047
   0.35693359 -0.9453125   0.2277832  -0.00291443  0.71337891  0.92626953
  -0.27880859  0.67138672 -0.29956055 -0.99707031 -0.99267578  0.7890625
  -0.31518555 -0.29638672 -0.97900391 -0.06634521 -0.96142578  0.84472656
   0.75341797 -0.50976562  0.94091797 -0.62011719  0.99755859  0.69042969
   0.68115234 -0.99707031 -0.98339844 -0.12658691 -0.11291504  0.98925781
  -0.32080078  0.96289062 -0.99902344 -0.72363281 -0.07757568  0.75927734
   0.81494141  0.578125   -0.01123047  0.05273438 -0.87304688 -0.81640625
   0.98730469  0.89990234 -0.99414062 -0.29882812  0.90625     0.07580566
   0.96044922 -0.15539551  0.37573242  1.         -0.90283203  0.1439209
   0.87451172  0.98242188  0.56201172 -0.97265625  0.73925781  0.10882568
  -0.99658203  0.63183594  0.86572266  0.98730469  0.97509766 -0.99951172
   0.87744141 -0.9921875   0.99462891 -0.88183594 -0.15478516  0.35791016
  -0.71777344 -0.97558594  0.40332031 -0.99365234  0.2479248  -0.19067383
   0.86328125  0.65771484 -0.98339844 -0.67871094 -0.99853516 -0.71289062
  -0.86523438 -0.99560547  0.86035156  0.35546875 -0.91308594 -0.14929199
  -0.05639648  0.88330078 -0.77392578 -0.97363281  0.69970703  0.73925781
   0.66357422  0.82958984 -0.98583984 -0.95849609  0.99902344  0.99853516
  -0.33227539  0.97558594  0.77783203  0.38818359  0.64208984  0.22277832
   0.30810547 -0.93798828  0.97216797 -0.71826172  0.99951172 -0.50976562
   0.99511719  0.85498047 -0.98583984 -0.99658203  0.44897461  0.89111328
   0.60595703 -0.43432617  0.97705078  0.98974609  0.71435547  0.95605469
  -0.99609375 -0.66845703 -0.04449463  0.99560547 -0.98876953 -0.29174805
   0.98046875  0.05245972  0.93896484  0.06149292  0.99511719 -0.31518555
   0.99707031 -0.88867188  0.99853516  0.94921875  0.57177734 -0.99365234
   0.99462891 -0.08184814  0.93798828  0.93505859  0.99951172  0.04733276
   0.61914062  0.96777344 -0.35668945  0.35913086 -0.15734863  0.97460938
  -0.85449219 -0.84814453  0.42236328  1.         -0.68408203  0.99804688
  -0.93066406 -0.99414062  0.39160156  0.2322998  -0.80566406 -0.34912109
   0.99462891  0.96777344  0.7421875   0.86621094 -0.06063843 -0.91943359
  -0.70507812  0.99023438  0.82226562 -0.80273438  0.98876953 -0.9296875
  -0.96289062  0.98535156  0.51904297 -0.99316406 -0.38769531 -0.98388672
   0.93945312 -0.3762207   0.04067993 -0.95703125 -0.99707031 -0.85791016
  -0.45507812 -0.24743652  0.98291016  0.06213379  0.58642578  0.28833008
  -0.58349609  0.81054688  0.77148438  0.61962891  0.99853516 -0.98095703
  -0.86376953 -0.99023438 -0.66943359 -0.79345703 -0.60644531  0.80175781
   0.97607422 -0.99755859  0.55371094 -0.99951172 -0.9765625  -0.59228516
   0.56933594 -0.1083374  -0.6484375  -0.99658203 -0.45141602  0.99316406
  -0.81835938 -0.01766968  0.97900391  0.84472656 -0.27392578  0.99951172
   0.95849609  0.96533203 -1.         -0.98876953  0.98535156 -0.89892578
   0.55615234 -0.51757812 -0.93261719  0.86523438 -0.99023438 -0.22790527
  -0.83349609 -0.77197266 -0.07629395  0.66357422]]
After layer _mul2065_0 (1, 256) <class 'numpy.float16'> [[ 0.30053711  0.43041992 -0.60400391 -0.36938477  0.74560547 -0.12854004
   0.85595703  0.01055145 -0.20141602 -0.10736084  0.57080078  0.67138672
   0.16760254 -0.75146484  0.08026123 -0.00166798  0.44165039  0.65673828
  -0.20800781  0.43164062 -0.14794922 -0.21887207 -0.66894531  0.49633789
  -0.18286133 -0.17260742 -0.75732422 -0.03289795 -0.70605469  0.62939453
   0.54150391 -0.35009766  0.76660156 -0.4465332   0.92529297  0.36889648
   0.41650391 -0.92529297 -0.84423828 -0.03274536 -0.04367065  0.68066406
  -0.26953125  0.52783203 -0.91699219 -0.49365234 -0.04840088  0.54003906
   0.4777832   0.25146484 -0.00462723  0.0209198  -0.86474609 -0.50244141
   0.84863281  0.46362305 -0.82080078 -0.1583252   0.59082031  0.01508331
   0.60986328 -0.09545898  0.16845703  0.85205078 -0.46557617  0.07977295
   0.67529297  0.87060547  0.41186523 -0.82617188  0.31420898  0.02236938
  -0.93115234  0.44189453  0.57226562  0.92578125  0.73583984 -0.97607422
   0.61865234 -0.31225586  0.82666016 -0.59472656 -0.11303711  0.16064453
  -0.59375    -0.72998047  0.25292969 -0.89550781  0.20947266 -0.07940674
   0.61181641  0.28540039 -0.42041016 -0.46948242 -0.32543945 -0.16845703
  -0.71582031 -0.85742188  0.69677734  0.24304199 -0.54785156 -0.05752563
  -0.03659058  0.77197266 -0.58935547 -0.57421875  0.37451172  0.43457031
   0.30908203  0.4609375  -0.8359375  -0.78076172  0.95898438  0.97900391
  -0.24829102  0.77587891  0.51855469  0.31274414  0.38037109  0.08990479
   0.12731934 -0.79199219  0.90966797 -0.46679688  0.92529297 -0.29907227
   0.65380859  0.57177734 -0.59277344 -0.93798828  0.16540527  0.70654297
   0.40917969 -0.25512695  0.78564453  0.73681641  0.52197266  0.27807617
  -0.76074219 -0.31982422 -0.02394104  0.8515625  -0.75341797 -0.14868164
   0.69970703  0.01490784  0.48461914  0.02381897  0.81445312 -0.14172363
   0.90966797 -0.69433594  0.9140625   0.81347656  0.30541992 -0.81396484
   0.72314453 -0.03308105  0.76806641  0.72998047  0.93652344  0.02047729
   0.47412109  0.77148438 -0.26586914  0.17810059 -0.08728027  0.67919922
  -0.38427734 -0.54248047  0.14318848  0.99609375 -0.44580078  0.86914062
  -0.67285156 -0.59179688  0.16577148  0.078125   -0.39282227 -0.22607422
   0.86914062  0.62988281  0.50683594  0.52587891 -0.02500916 -0.65380859
  -0.38354492  0.8203125   0.61474609 -0.57128906  0.31835938 -0.52685547
  -0.85449219  0.63623047  0.34179688 -0.82128906 -0.38330078 -0.84521484
   0.69921875 -0.20910645  0.02461243 -0.75146484 -0.70166016 -0.63476562
  -0.31860352 -0.12304688  0.76513672  0.02255249  0.21057129  0.18823242
  -0.43164062  0.52001953  0.64892578  0.41748047  0.94970703 -0.81689453
  -0.54296875 -0.87353516 -0.46386719 -0.2746582  -0.36425781  0.51025391
   0.66210938 -0.73974609  0.39282227 -0.984375   -0.71972656 -0.27124023
   0.28149414 -0.05392456 -0.20300293 -0.96923828 -0.28857422  0.85595703
  -0.60400391 -0.00835419  0.63378906  0.32739258 -0.14611816  0.90234375
   0.58154297  0.73730469 -0.99804688 -0.68505859  0.80712891 -0.65966797
   0.3581543  -0.31079102 -0.71972656  0.56298828 -0.89404297 -0.0680542
  -0.68066406 -0.54296875 -0.02861023  0.42456055]]
After layer encoder_birnn_forward_l0_t6_state_0 (1, 256) <class 'numpy.float16'> [[  5.98144531e-01   7.08984375e-01  -1.06738281e+00  -6.51367188e-01
    1.43554688e+00  -2.51464844e-01   2.03710938e+00   4.78363037e-03
   -5.09277344e-01  -1.80419922e-01   1.25878906e+00   1.25000000e+00
    3.31542969e-01  -1.59375000e+00   1.25488281e-01   2.52151489e-03
    8.10546875e-01   1.20898438e+00  -3.27148438e-01   7.88085938e-01
   -2.78808594e-01  -4.47509766e-01  -1.72167969e+00   8.38867188e-01
   -3.73535156e-01  -2.98339844e-01  -1.63671875e+00  -7.39746094e-02
   -1.54687500e+00   1.05175781e+00   1.08105469e+00  -6.70898438e-01
    1.50390625e+00  -7.91503906e-01   2.44921875e+00   6.53320312e-01
    7.03125000e-01  -1.99804688e+00  -2.10546875e+00  -1.67846680e-02
   -1.19873047e-01   1.37988281e+00  -5.27343750e-01   8.51562500e-01
   -1.65820312e+00  -7.00195312e-01  -1.15844727e-01   1.05566406e+00
    8.20312500e-01   3.78417969e-01  -1.28631592e-02   2.89611816e-02
   -2.01757812e+00  -7.36328125e-01   2.01953125e+00   7.02148438e-01
   -1.54394531e+00  -2.92236328e-01   1.10937500e+00   1.21002197e-02
    1.01074219e+00  -2.16674805e-01   2.79785156e-01   2.10351562e+00
   -8.39843750e-01   1.60278320e-01   1.29394531e+00   1.99414062e+00
    7.46093750e-01  -1.94140625e+00   5.24902344e-01   5.70068359e-02
   -2.51953125e+00   8.07617188e-01   9.82421875e-01   2.66796875e+00
    1.40039062e+00  -3.20703125e+00   1.23535156e+00  -4.96337891e-01
    1.94335938e+00  -8.22265625e-01  -2.72949219e-01   3.11279297e-01
   -1.15820312e+00  -1.51855469e+00   3.68408203e-01  -2.30859375e+00
    5.23437500e-01  -1.43066406e-01   1.01367188e+00   5.70800781e-01
   -7.52441406e-01  -8.54492188e-01  -6.08398438e-01  -3.27148438e-01
   -1.55468750e+00  -2.07421875e+00   1.45117188e+00   5.12207031e-01
   -9.32617188e-01  -8.77685547e-02  -4.47082520e-02   1.62109375e+00
   -1.25195312e+00  -1.07714844e+00   7.86132812e-01   8.80371094e-01
    6.54296875e-01   8.57421875e-01  -1.90136719e+00  -1.84960938e+00
    2.78906250e+00   2.93750000e+00  -5.30761719e-01   1.54296875e+00
    1.08593750e+00   5.94726562e-01   7.23632812e-01   1.78710938e-01
    2.11914062e-01  -1.85156250e+00   1.90039062e+00  -8.19824219e-01
    2.41015625e+00  -4.50195312e-01   9.53613281e-01   1.04589844e+00
   -1.25195312e+00  -2.69335938e+00   3.18847656e-01   1.47558594e+00
    6.49414062e-01  -4.15527344e-01   1.54003906e+00   1.69140625e+00
    9.36523438e-01   4.20898438e-01  -2.04687500e+00  -6.45507812e-01
   -3.64379883e-02   1.84179688e+00  -1.68750000e+00  -2.80761719e-01
    1.51855469e+00   2.50091553e-02   9.13085938e-01   3.72314453e-03
    2.00390625e+00  -3.03466797e-01   2.16601562e+00  -1.20410156e+00
    2.02734375e+00   1.59472656e+00   5.41992188e-01  -1.56640625e+00
    1.83789062e+00  -7.72705078e-02   1.74121094e+00   1.43750000e+00
    2.56054688e+00   1.23535156e-01   9.10156250e-01   1.66210938e+00
   -5.42968750e-01   3.48876953e-01  -1.27685547e-01   1.36132812e+00
   -6.02050781e-01  -9.55078125e-01   2.18017578e-01   3.30468750e+00
   -7.87109375e-01   2.33593750e+00  -1.10546875e+00  -1.14062500e+00
    2.84179688e-01   1.99218750e-01  -5.96679688e-01  -4.37988281e-01
    1.72851562e+00   9.94140625e-01   1.05957031e+00   1.08593750e+00
   -4.11682129e-02  -1.31640625e+00  -8.06640625e-01   1.78027344e+00
    1.11035156e+00  -1.14355469e+00   4.94628906e-01  -1.08789062e+00
   -1.97460938e+00   1.41210938e+00   5.02929688e-01  -1.61523438e+00
   -9.02343750e-01  -1.32324219e+00   1.40039062e+00  -3.01757812e-01
    7.17773438e-02  -1.57617188e+00  -1.44433594e+00  -1.39160156e+00
   -5.75195312e-01  -2.57324219e-01   1.78125000e+00   4.81567383e-02
    3.53515625e-01   3.40576172e-01  -8.21289062e-01   9.77539062e-01
    1.23046875e+00   7.80273438e-01   2.82421875e+00  -1.96484375e+00
   -9.32128906e-01  -1.99804688e+00  -6.99218750e-01  -4.62646484e-01
   -6.01074219e-01   1.05761719e+00   1.07519531e+00  -1.74414062e+00
    6.87988281e-01  -2.82812500e+00  -1.00585938e+00  -5.20507812e-01
    5.88867188e-01  -8.08105469e-02  -3.97949219e-01  -2.82226562e+00
   -5.08789062e-01   1.85156250e+00  -1.30078125e+00  -2.44140625e-02
    1.21484375e+00   5.97656250e-01  -2.66357422e-01   2.54492188e+00
    1.03808594e+00   1.74414062e+00  -3.68945312e+00  -1.08203125e+00
    1.61523438e+00  -9.73144531e-01   6.32812500e-01  -5.62011719e-01
   -1.48144531e+00   1.12890625e+00  -2.38476562e+00  -1.20727539e-01
   -1.45898438e+00  -1.04492188e+00  -6.89086914e-02   8.10546875e-01]]
After layer activation1032_output (1, 256) <class 'numpy.float16'> [[ 0.53564453  0.60986328 -0.78857422 -0.57275391  0.89257812 -0.24633789
   0.96679688  0.00478363 -0.46948242 -0.1784668   0.85058594  0.84814453
   0.31982422 -0.92089844  0.12481689  0.00252151  0.66992188  0.83642578
  -0.31591797  0.65722656 -0.27172852 -0.41992188 -0.93798828  0.68505859
  -0.35717773 -0.28979492 -0.92724609 -0.07385254 -0.91308594  0.78271484
   0.79345703 -0.58544922  0.90576172 -0.65917969  0.98535156  0.57373047
   0.60644531 -0.96386719 -0.97070312 -0.01678467 -0.11932373  0.88085938
  -0.48339844  0.69189453 -0.93017578 -0.60449219 -0.11535645  0.78417969
   0.67529297  0.36132812 -0.01286316  0.02894592 -0.96533203 -0.62695312
   0.96533203  0.60595703 -0.91259766 -0.28417969  0.80371094  0.01210022
   0.76611328 -0.21337891  0.27270508  0.97070312 -0.68554688  0.15893555
   0.86035156  0.96337891  0.6328125  -0.95947266  0.48144531  0.0569458
  -0.98730469  0.66845703  0.75390625  0.99023438  0.88525391 -0.99658203
   0.84423828 -0.45922852  0.95996094 -0.67626953 -0.26635742  0.30151367
  -0.8203125  -0.90820312  0.35253906 -0.98046875  0.48046875 -0.14208984
   0.76708984  0.51611328 -0.63671875 -0.69335938 -0.54296875 -0.31591797
  -0.91455078 -0.96875     0.89599609  0.47167969 -0.73193359 -0.08752441
  -0.04467773  0.92480469 -0.84863281 -0.79199219  0.65625     0.70654297
   0.57470703  0.69482422 -0.95654297 -0.95166016  0.99267578  0.99462891
  -0.48608398  0.91259766  0.79541016  0.53320312  0.61914062  0.17687988
   0.20874023 -0.95166016  0.95605469 -0.67480469  0.98388672 -0.42211914
   0.74121094  0.78027344 -0.84863281 -0.99072266  0.30834961  0.90087891
   0.57128906 -0.39306641  0.91210938  0.93408203  0.73339844  0.39770508
  -0.96728516 -0.56884766 -0.03640747  0.95117188 -0.93359375 -0.27368164
   0.90820312  0.02500916  0.72265625  0.00372314  0.96435547 -0.29443359
   0.97412109 -0.83496094  0.96582031  0.92089844  0.49438477 -0.91650391
   0.95068359 -0.0770874   0.94042969  0.89306641  0.98828125  0.1229248
   0.72119141  0.93066406 -0.49511719  0.33544922 -0.12695312  0.87646484
  -0.53857422 -0.7421875   0.21459961  0.99707031 -0.65673828  0.98144531
  -0.80224609 -0.81445312  0.27685547  0.19665527 -0.53466797 -0.41186523
   0.93896484  0.75927734  0.78564453  0.79541016 -0.0411377  -0.86572266
  -0.66796875  0.94482422  0.80419922 -0.81542969  0.45776367 -0.79589844
  -0.96240234  0.88818359  0.46435547 -0.92382812 -0.71728516 -0.86767578
   0.88525391 -0.29296875  0.07165527 -0.91796875 -0.89453125 -0.88330078
  -0.51904297 -0.25170898  0.94482422  0.04812622  0.33959961  0.32788086
  -0.67578125  0.75195312  0.84277344  0.65283203  0.99316406 -0.96142578
  -0.73144531 -0.96386719 -0.60400391 -0.43212891 -0.53759766  0.78466797
   0.79150391 -0.94091797  0.59667969 -0.99316406 -0.76416016 -0.47802734
   0.52929688 -0.08062744 -0.37817383 -0.99316406 -0.46899414  0.95166016
  -0.86181641 -0.02441406  0.83789062  0.53515625 -0.26025391  0.98779297
   0.77734375  0.94091797 -0.99853516 -0.79394531  0.92382812 -0.75
   0.56005859 -0.50927734 -0.90185547  0.81054688 -0.98339844 -0.12011719
  -0.89746094 -0.77978516 -0.06878662  0.66992188]]
After layer encoder_birnn_forward_l0_t6_out_0 (1, 256) <class 'numpy.float16'> [[ 0.45141602  0.44018555 -0.58105469 -0.46508789  0.65039062 -0.20056152
   0.91796875  0.00338364 -0.36962891 -0.13293457  0.65820312  0.65185547
   0.23217773 -0.80517578  0.05795288  0.00147724  0.51708984  0.55664062
  -0.29492188  0.53222656 -0.18920898 -0.19812012 -0.85009766  0.56982422
  -0.25146484 -0.19616699 -0.81396484 -0.05789185 -0.50634766  0.59521484
   0.66357422 -0.47607422  0.48291016 -0.47412109  0.70751953  0.36303711
   0.48120117 -0.59716797 -0.27294922 -0.0113678  -0.081604    0.65234375
  -0.35180664  0.51220703 -0.69189453 -0.46704102 -0.10791016  0.63232422
   0.49267578  0.20336914 -0.00469208  0.02302551 -0.95703125 -0.27709961
   0.76269531  0.2722168  -0.59960938 -0.2052002   0.64160156  0.00855255
   0.39916992 -0.14196777  0.15270996  0.84130859 -0.453125    0.11798096
   0.72753906  0.66113281  0.47558594 -0.66455078  0.3840332   0.04455566
  -0.91357422  0.50439453  0.52685547  0.97509766  0.68017578 -0.97509766
   0.72851562 -0.25610352  0.86376953 -0.2878418  -0.26391602  0.2208252
  -0.69677734 -0.62744141  0.23669434 -0.78027344  0.45825195 -0.11590576
   0.54345703  0.39282227 -0.2097168  -0.60253906 -0.32226562 -0.25463867
  -0.74023438 -0.79980469  0.72460938  0.42724609 -0.44921875 -0.06118774
  -0.02606201  0.83154297 -0.70214844 -0.48803711  0.49853516  0.58154297
   0.48608398  0.40478516 -0.84912109 -0.74316406  0.94970703  0.93652344
  -0.40014648  0.69335938  0.61572266  0.4921875   0.47705078  0.14099121
   0.15087891 -0.88427734  0.77099609 -0.50488281  0.80175781 -0.35522461
   0.38793945  0.43823242 -0.60351562 -0.96240234  0.24816895  0.81787109
   0.40356445 -0.2956543   0.59912109  0.61572266  0.61376953  0.27612305
  -0.83544922 -0.44750977 -0.02404785  0.73925781 -0.69921875 -0.21630859
   0.60791016  0.02067566  0.52832031  0.00265312  0.52099609 -0.18688965
   0.91943359 -0.54541016  0.76269531  0.49243164  0.31811523 -0.44506836
   0.63476562 -0.05722046  0.86816406  0.69628906  0.74267578  0.09979248
   0.41699219  0.77148438 -0.44580078  0.20703125 -0.09814453  0.53369141
  -0.22766113 -0.48339844  0.14550781  0.99121094 -0.52832031  0.87646484
  -0.41918945 -0.50488281  0.20812988  0.15588379 -0.35913086 -0.35620117
   0.70117188  0.36328125  0.63183594  0.64746094 -0.02708435 -0.69042969
  -0.50830078  0.62792969  0.63867188 -0.69873047  0.20629883 -0.59277344
  -0.88818359  0.65576172  0.2722168  -0.73925781 -0.71337891 -0.61962891
   0.68554688 -0.23083496  0.04519653 -0.54394531 -0.71875    -0.77832031
  -0.4230957  -0.2097168   0.82470703  0.0255127   0.11352539  0.24780273
  -0.54589844  0.49487305  0.74169922  0.54492188  0.96728516 -0.875
  -0.49536133 -0.87158203 -0.49780273 -0.29907227 -0.3815918   0.63964844
   0.38500977 -0.5859375   0.48828125 -0.70654297 -0.59375    -0.36083984
   0.41308594 -0.05413818 -0.24243164 -0.89160156 -0.37670898  0.75390625
  -0.72021484 -0.01719666  0.46142578  0.24194336 -0.19128418  0.9296875
   0.41748047  0.81494141 -0.99707031 -0.45019531  0.6875     -0.42553711
   0.42944336 -0.40185547 -0.79736328  0.68164062 -0.87841797 -0.07824707
  -0.80566406 -0.64941406 -0.04797363  0.52685547]]
After layer expand_dims1038_0 (1, 1, 256) <class 'numpy.float16'> [[[ 0.45141602  0.44018555 -0.58105469 -0.46508789  0.65039062 -0.20056152
    0.91796875  0.00338364 -0.36962891 -0.13293457  0.65820312  0.65185547
    0.23217773 -0.80517578  0.05795288  0.00147724  0.51708984  0.55664062
   -0.29492188  0.53222656 -0.18920898 -0.19812012 -0.85009766  0.56982422
   -0.25146484 -0.19616699 -0.81396484 -0.05789185 -0.50634766  0.59521484
    0.66357422 -0.47607422  0.48291016 -0.47412109  0.70751953  0.36303711
    0.48120117 -0.59716797 -0.27294922 -0.0113678  -0.081604    0.65234375
   -0.35180664  0.51220703 -0.69189453 -0.46704102 -0.10791016  0.63232422
    0.49267578  0.20336914 -0.00469208  0.02302551 -0.95703125 -0.27709961
    0.76269531  0.2722168  -0.59960938 -0.2052002   0.64160156  0.00855255
    0.39916992 -0.14196777  0.15270996  0.84130859 -0.453125    0.11798096
    0.72753906  0.66113281  0.47558594 -0.66455078  0.3840332   0.04455566
   -0.91357422  0.50439453  0.52685547  0.97509766  0.68017578 -0.97509766
    0.72851562 -0.25610352  0.86376953 -0.2878418  -0.26391602  0.2208252
   -0.69677734 -0.62744141  0.23669434 -0.78027344  0.45825195 -0.11590576
    0.54345703  0.39282227 -0.2097168  -0.60253906 -0.32226562 -0.25463867
   -0.74023438 -0.79980469  0.72460938  0.42724609 -0.44921875 -0.06118774
   -0.02606201  0.83154297 -0.70214844 -0.48803711  0.49853516  0.58154297
    0.48608398  0.40478516 -0.84912109 -0.74316406  0.94970703  0.93652344
   -0.40014648  0.69335938  0.61572266  0.4921875   0.47705078  0.14099121
    0.15087891 -0.88427734  0.77099609 -0.50488281  0.80175781 -0.35522461
    0.38793945  0.43823242 -0.60351562 -0.96240234  0.24816895  0.81787109
    0.40356445 -0.2956543   0.59912109  0.61572266  0.61376953  0.27612305
   -0.83544922 -0.44750977 -0.02404785  0.73925781 -0.69921875 -0.21630859
    0.60791016  0.02067566  0.52832031  0.00265312  0.52099609 -0.18688965
    0.91943359 -0.54541016  0.76269531  0.49243164  0.31811523 -0.44506836
    0.63476562 -0.05722046  0.86816406  0.69628906  0.74267578  0.09979248
    0.41699219  0.77148438 -0.44580078  0.20703125 -0.09814453  0.53369141
   -0.22766113 -0.48339844  0.14550781  0.99121094 -0.52832031  0.87646484
   -0.41918945 -0.50488281  0.20812988  0.15588379 -0.35913086 -0.35620117
    0.70117188  0.36328125  0.63183594  0.64746094 -0.02708435 -0.69042969
   -0.50830078  0.62792969  0.63867188 -0.69873047  0.20629883 -0.59277344
   -0.88818359  0.65576172  0.2722168  -0.73925781 -0.71337891 -0.61962891
    0.68554688 -0.23083496  0.04519653 -0.54394531 -0.71875    -0.77832031
   -0.4230957  -0.2097168   0.82470703  0.0255127   0.11352539  0.24780273
   -0.54589844  0.49487305  0.74169922  0.54492188  0.96728516 -0.875
   -0.49536133 -0.87158203 -0.49780273 -0.29907227 -0.3815918   0.63964844
    0.38500977 -0.5859375   0.48828125 -0.70654297 -0.59375    -0.36083984
    0.41308594 -0.05413818 -0.24243164 -0.89160156 -0.37670898  0.75390625
   -0.72021484 -0.01719666  0.46142578  0.24194336 -0.19128418  0.9296875
    0.41748047  0.81494141 -0.99707031 -0.45019531  0.6875     -0.42553711
    0.42944336 -0.40185547 -0.79736328  0.68164062 -0.87841797 -0.07824707
   -0.80566406 -0.64941406 -0.04797363  0.52685547]]]
After layer encoder_birnn_forward_l0_t7_i2h_output (1, 1024) <class 'numpy.float16'> [[ 0.0737915  -0.0458374   0.06152344 ...,  0.03591919  0.03396606
   0.02903748]]
After layer encoder_birnn_forward_l0_t7_h2h_output (1, 1024) <class 'numpy.float16'> [[ 1.03710938  0.96728516  0.69189453 ...,  1.98144531  1.05078125
   1.6171875 ]]
After layer _plus1033_0 (1, 1024) <class 'numpy.float16'> [[ 1.11132812  0.92138672  0.75341797 ...,  2.01757812  1.08496094
   1.64648438]]
After layer encoder_birnn_forward_l0_t7_slice_output0 (1, 256) <class 'numpy.float16'> [[ 1.11132812  0.92138672  0.75341797  0.68994141  1.46972656  1.296875
   2.5546875   0.18212891 -0.94628906  0.87988281  0.87304688  1.44921875
  -0.13623047  1.72070312 -0.77636719  0.33520508  0.5         1.13476562
   1.41699219  0.71044922  0.03662109 -1.58691406  0.86767578  0.61865234
   0.37451172  0.46728516  1.52539062 -0.05090332  1.26855469  1.45703125
   1.1875      0.89941406  1.87695312  1.16699219  3.3203125   0.22961426
   0.51464844  3.18945312  2.3125     -1.4609375  -0.57421875  1.00390625
   2.22460938  0.09686279  3.0859375   0.921875    0.63378906  1.12890625
   0.46826172 -0.35717773 -0.41723633 -0.53955078  5.8828125   0.58300781
   2.29296875 -0.02429199  2.04296875  0.21911621  0.82519531 -1.70898438
   0.60058594  0.46875    -0.27124023  2.265625    0.15478516  0.25097656
   1.54980469  2.57617188  1.2109375   2.171875   -0.42138672 -1.65527344
   3.31054688  1.04980469  0.79443359  3.38867188  1.40917969  4.69921875
   1.15039062 -1.12597656  2.0859375   0.90917969  1.28613281 -0.2064209
   1.99609375  1.34765625  0.69482422  2.859375    2.14648438 -0.38696289
   1.17578125 -0.3527832  -0.35839844  1.07910156 -1.01953125 -1.58398438
   1.953125    2.42578125  1.80273438  0.97949219  0.60742188 -0.62451172
   0.75146484  2.46679688  1.3671875   0.52294922  0.14135742  0.41333008
  -0.21508789  0.20507812  2.1953125   1.90625     4.00390625  4.875
   1.390625    1.70019531  0.81835938  1.8203125   0.43505859 -0.48364258
  -0.41333008  2.12890625  3.44140625  0.85205078  3.17382812  0.43652344
   0.84423828  0.96582031  0.53027344  3.40234375 -0.63623047  1.69433594
   0.97363281  0.41870117  1.86035156  1.45996094  1.25976562 -1.19628906
   1.4765625  -0.06274414  0.2722168   2.2578125   1.48925781  0.0447998
   1.15820312 -1.1796875   0.12023926 -0.48144531  1.89257812 -0.29248047
   2.95507812  1.671875    3.08984375  2.29882812  0.22241211  1.98144531
   1.23144531 -0.42431641  1.81640625  1.57324219  3.375      -0.30322266
   1.53710938  1.76367188  1.41210938 -0.07324219  0.29467773  1.10058594
  -0.29394531  0.69824219 -0.85449219  6.99609375  0.74462891  2.34570312
   1.22070312  0.39428711 -0.42651367 -0.82666016  0.03311157  0.80419922
   2.42382812  0.73974609  0.9921875   0.58642578 -0.38232422  1.13183594
   0.27368164  2.0390625   1.40722656  1.15820312 -0.93017578  0.38964844
   2.45703125  0.80566406  0.74560547  1.98925781  5.58203125  2.31640625
   1.36425781  0.2421875   0.57568359  1.68261719  1.09472656  1.30371094
   1.09082031  0.00995636  1.56542969 -0.76025391 -0.79736328  0.79833984
   1.3515625   0.78222656  2.21484375  0.96826172  3.73242188  2.04492188
   0.70556641  2.61914062  0.95703125 -0.93164062  0.55517578  0.67480469
   0.97851562  1.35449219  1.16992188  5.33203125  1.22949219 -0.23840332
  -0.05224609 -0.05834961 -0.90722656  4.4375      0.68652344  2.37109375
   1.4453125  -0.11175537  0.69628906 -0.53515625  0.05715942  2.81445312
   0.55371094  1.43652344  7.734375    1.04589844  1.84375     1.28417969
   0.73046875  0.50048828  1.58984375  0.71728516  2.83398438 -1.10742188
   1.84082031  0.99511719 -0.54394531  0.72705078]]
After layer encoder_birnn_forward_l0_t7_slice_output1 (1, 256) <class 'numpy.float16'> [[ 2.08984375  0.21582031  0.43652344  0.8515625   0.71386719  0.83837891
   2.51171875  0.74169922  3.31054688  0.69189453  2.36328125  0.96533203
   1.53027344  1.57519531 -0.37109375  0.75537109  0.83740234  0.69628906
   1.90820312  1.29589844  0.24462891 -0.48730469  2.18554688  0.43188477
   1.16210938  1.19140625  1.47265625  0.77050781  1.71777344  0.55566406
   1.921875    1.5703125   0.98486328  1.07519531  2.71875     0.68212891
   0.36694336  1.06738281  2.66796875 -0.07019043  1.42773438  0.96142578
   2.36523438 -0.37597656  0.25683594 -0.54980469  2.52929688  1.16015625
   0.48510742 -0.34765625 -0.54101562  0.99316406  4.8046875  -0.59228516
   1.97460938 -0.74853516  0.58837891  1.13085938  1.16210938  1.62402344
  -0.04766846  0.81884766  0.42993164  1.74609375  0.48217773  1.01367188
   1.55566406  1.61035156  0.86035156  2.51953125 -0.04354858  1.32519531
   2.8203125   1.10058594  0.31201172  4.5625      0.75292969  4.34375
   1.50390625 -0.98876953  2.15039062 -0.82910156  3.5859375   1.57324219
   1.86425781  1.38476562  0.11029053  2.54101562  4.53515625  0.67333984
   0.42919922  1.22167969 -0.1763916   1.19824219 -0.40942383  0.01286316
   2.22070312  2.00195312  1.88085938  2.0703125   0.4206543  -0.38891602
   0.05599976  1.89160156  1.77636719  0.58105469  1.04394531  1.36816406
   1.14257812  0.84326172  1.84667969  2.52148438  3.11523438  3.46679688
   1.58203125  0.95361328  1.68847656  2.22851562  0.92236328  0.83691406
   1.13769531  2.50390625  1.36035156  0.92578125  1.94433594  1.28515625
  -0.9609375   0.97265625  0.97363281  3.53125     0.88183594  1.62011719
   0.43798828  0.70263672  0.83789062  1.50195312  1.93261719 -0.87792969
   2.62109375  1.67382812  0.97558594  1.3046875   1.51171875  1.42773438
   1.58691406  1.83105469  0.66357422  1.30664062  2.15039062  1.16796875
   1.79589844  0.50097656  1.22265625  1.41601562  0.93603516  0.73095703
   2.1484375   0.81835938  2.36914062  1.25097656  2.46289062  1.29589844
   1.83105469  1.45605469  1.78515625  0.59472656  0.76757812  0.96484375
  -0.48095703  0.47412109 -0.55566406  3.54492188  0.93066406  2.63476562
   0.22143555  0.54833984  0.94921875  1.78222656 -0.2010498   2.34375
   0.92333984 -0.32666016  1.85839844  1.37890625  1.07324219  1.16503906
   1.83398438  1.33984375  1.31347656  1.65136719 -0.91308594  1.02539062
   2.32617188  1.35351562 -0.06054688  0.74853516  7.25390625 -0.21728516
   1.23632812 -0.23156738  0.69433594  1.3828125   0.88232422  2.578125
   1.20898438  0.68408203  2.02734375 -0.76806641 -0.29418945  1.79199219
   1.69726562  1.02832031  1.57519531  1.23242188  3.5859375   2.47070312
   0.51171875  1.90625     0.02957153 -0.11883545  0.59960938  1.47167969
  -0.02696228  1.62011719  1.12402344  2.73632812 -1.00878906  0.84375
   1.1875      0.84521484  0.76416016  3.26171875  0.53857422  1.26464844
   2.06835938  1.1875      0.61767578  0.30249023  0.68847656  3.00195312
   0.43530273  2.03515625  7.39453125 -0.39331055  1.13085938 -0.34521484
   0.515625    1.          1.34375     1.40625     2.66015625 -0.27905273
   2.3125      1.02636719  0.90380859  1.3359375 ]]
After layer encoder_birnn_forward_l0_t7_slice_output2 (1, 256) <class 'numpy.float16'> [[ 0.60644531  0.83740234 -2.37890625 -0.92773438  2.96289062 -0.17797852
   2.57617188 -0.12207031 -0.73730469 -0.26831055  1.70214844  1.74902344
   0.46069336 -2.24609375  0.34472656 -0.04937744  1.13964844  2.03125
  -0.57958984  1.08007812 -0.36230469 -4.11328125 -3.47070312  1.33203125
  -0.45068359 -0.45727539 -2.96289062 -0.13598633 -2.57226562  1.53417969
   1.29882812 -0.76367188  2.3046875  -0.8359375   4.328125    1.11816406
   0.98828125 -4.140625   -3.04492188 -0.17565918 -0.1829834   3.30664062
  -0.60791016  2.484375   -4.9140625  -1.09179688  0.05236816  1.27148438
   1.45898438  0.85449219  0.10369873  0.1182251  -1.59277344 -1.40917969
   3.19140625  1.86621094 -3.72460938 -0.3894043   1.89550781  0.04855347
   2.47851562 -0.22607422  0.50732422  6.13671875 -1.95605469  0.18151855
   1.703125    2.9921875   0.73925781 -2.69335938  1.09179688 -0.02679443
  -4.01171875  0.97949219  1.6328125   3.08789062  2.83398438 -5.515625
   1.75878906 -3.55664062  3.83984375 -1.70800781 -0.02069092  0.59423828
  -1.24511719 -2.72851562  0.49951172 -3.66601562  0.37158203 -0.1427002
   1.66015625  1.02929688 -3.03125    -1.01367188 -4.38671875 -0.93945312
  -1.625      -3.921875    1.67675781  0.5390625  -2.046875   -0.15551758
  -0.20336914  1.79589844 -1.31933594 -2.80859375  1.1015625   1.28222656
   1.01367188  1.58105469 -3.27148438 -2.38085938  4.8203125   4.59765625
  -0.49047852  2.86523438  1.45605469  0.63964844  0.86914062  0.35986328
   0.4128418  -2.16796875  2.7421875  -1.13867188  5.03125    -0.80322266
   3.75585938  1.69628906 -3.109375   -4.046875    0.58935547  1.73730469
   0.89599609 -0.60009766  2.88085938  3.3671875   1.20507812  2.45507812
  -3.97460938 -0.93701172 -0.17883301  3.85546875 -3.31445312 -0.45263672
   2.91601562  0.1418457   2.28515625  0.03765869  3.89648438 -0.41650391
   4.15234375 -1.88574219  4.4765625   2.31640625  0.82958984 -3.59765625
   3.71484375 -0.16455078  2.21484375  2.13476562  5.6796875   0.09484863
   1.02441406  2.63671875 -0.52734375  0.44580078 -0.27954102  2.6875
  -1.67089844 -1.60839844  0.54052734  5.8125     -1.15917969  4.45703125
  -2.20898438 -3.77929688  0.58203125  0.30102539 -1.44921875 -0.47143555
   3.70703125  2.57226562  1.21289062  1.66796875 -0.14794922 -2.
  -1.09667969  3.49609375  1.57910156 -1.40136719  3.25976562 -2.078125
  -2.55273438  3.08007812  0.76611328 -3.59570312 -0.24926758 -3.0390625
   2.20703125 -0.41699219  0.14672852 -2.44140625 -4.1015625  -1.63574219
  -0.71777344 -0.10693359  3.03320312  0.03607178  0.78515625  0.53857422
  -0.8515625   1.49804688  1.33398438  0.9140625   4.578125   -2.93164062
  -1.6171875  -3.50976562 -0.99951172 -1.39941406 -0.91894531  1.36914062
   2.8984375  -4.2109375   0.81884766 -5.34375    -2.83984375 -0.81298828
   0.86767578 -0.23522949 -1.046875   -4.0703125  -0.64599609  3.59765625
  -1.44921875  0.06573486  2.8359375   1.61816406 -0.41723633  5.4921875
   2.4921875   2.53710938 -5.67578125 -3.2265625   3.08203125 -1.94140625
   0.69140625 -0.71630859 -2.0703125   1.6875     -3.43164062 -0.25537109
  -1.59277344 -1.23828125  0.05953979  1.12207031]]
After layer encoder_birnn_forward_l0_t7_slice_output3 (1, 256) <class 'numpy.float16'> [[ 2.23046875  1.21582031  1.29882812  1.828125    1.2734375   1.89550781
   3.69921875  1.203125    1.63867188  1.28515625  1.64941406  1.48828125
   1.32910156  2.43554688 -0.20935059  0.42041016  1.51269531  0.90722656
   3.37890625  1.79882812  1.12890625 -0.24523926  2.80273438  2.0546875
   1.06347656  1.06738281  2.53710938  1.62988281  0.24890137  1.43164062
   2.17773438  1.84082031  0.18566895  1.171875    1.21484375  0.765625
   1.73730469  0.67138672 -1.16894531  0.92871094  0.92626953  1.30761719
   1.27050781  1.296875    1.36132812  1.51660156  3.28320312  1.87011719
   1.24511719  0.31933594 -0.68798828  1.77246094  5.9609375  -0.32568359
   1.71582031 -0.34472656  0.91113281  1.27734375  1.78417969  1.14160156
   0.14428711  0.7734375   0.30737305  2.43359375  0.90234375  1.34570312
   2.15625     1.02148438  1.49316406  0.97412109  1.70117188  1.66894531
   3.13476562  1.45605469  1.0703125   5.2734375   1.54003906  4.796875
   2.26757812  0.22497559  2.79101562 -0.36938477  5.97265625  1.25488281
   2.16992188  0.98535156  0.94384766  1.69921875  3.7890625   1.96191406
   1.12402344  1.54785156 -0.92675781  2.37890625  0.45166016  1.65722656
   1.84960938  1.97753906  1.77734375  2.92578125  0.56591797  1.03613281
   0.4777832   2.82421875  1.98730469  0.5859375   1.54199219  1.93066406
   2.203125    0.44262695  2.59960938  1.64941406  3.88085938  3.43945312
   1.97851562  1.47753906  1.58789062  3.18945312  1.57128906  1.71386719
   1.15429688  3.26953125  1.90332031  1.32421875  1.90917969  2.1171875
   0.03436279  0.44018555  1.21191406  4.46484375  1.78515625  2.8984375
   1.18066406  1.43359375  0.80126953  0.92138672  2.11914062  0.94189453
   2.296875    1.77636719  0.91357422  1.6328125   1.38476562  1.7734375
   0.9140625   2.109375    1.28027344  1.22363281  0.2265625   0.71777344
   3.63085938  0.83349609  1.64941406  0.17578125  0.83349609 -0.04937744
   0.88085938  1.45410156  3.22265625  1.62890625  1.31054688  1.88769531
   0.31713867  2.109375    2.8359375   0.57861328  1.61816406  0.51123047
  -0.45117188  0.79003906  0.85205078  6.4140625   1.71972656  2.6796875
   0.21801758  0.67089844  1.52246094  1.78027344  0.90380859  2.4453125
   1.36132812 -0.07727051  1.82617188  1.88867188  0.83251953  1.70410156
   1.49121094  0.89111328  1.76855469  2.20117188 -0.29272461  1.3828125
   3.14257812  1.16894531  0.50976562  1.69335938  6.5234375   1.15722656
   1.52050781  1.65332031  0.67675781  0.56787109  1.78710938  2.55859375
   1.88964844  1.98632812  2.45898438  0.09509277 -0.91699219  1.48144531
   1.87109375  0.80566406  2.578125    2.06445312  4.609375    2.91992188
   0.98974609  2.87890625  1.94042969  0.9453125   1.12597656  1.88378906
  -0.12347412  0.57080078  1.95019531  1.140625    1.53710938  1.50195312
   1.61523438  1.01367188  0.86083984  2.80078125  1.79199219  1.63378906
   2.0703125   1.18457031  0.33081055 -0.16687012  1.35644531  3.546875
   0.24291992  2.3828125   8.4453125   0.39550781  1.39453125  0.31201172
   1.54785156  1.72949219  2.64257812  2.0390625   2.60351562  0.82421875
   2.7578125   2.01757812  1.08496094  1.64648438]]
After layer encoder_birnn_forward_l0_t7_o_output (1, 256) <class 'numpy.float16'> [[ 0.90283203  0.77148438  0.78564453  0.86132812  0.78125     0.86914062
   0.97607422  0.76904297  0.83740234  0.78320312  0.83886719  0.81591797
   0.79052734  0.91943359  0.44775391  0.60351562  0.81933594  0.71240234
   0.96679688  0.85791016  0.75585938  0.43896484  0.94287109  0.88623047
   0.74316406  0.74414062  0.92675781  0.8359375   0.56201172  0.80712891
   0.8984375   0.86328125  0.54638672  0.76367188  0.77099609  0.68261719
   0.85058594  0.66162109  0.23706055  0.71679688  0.71630859  0.78710938
   0.78076172  0.78515625  0.79589844  0.81982422  0.96386719  0.86669922
   0.77636719  0.57910156  0.33447266  0.85498047  0.99755859  0.41918945
   0.84765625  0.41455078  0.71337891  0.78222656  0.85644531  0.7578125
   0.53613281  0.68408203  0.57617188  0.91943359  0.71142578  0.79345703
   0.89648438  0.73535156  0.81640625  0.72607422  0.84570312  0.84130859
   0.95849609  0.81103516  0.74462891  0.99511719  0.82324219  0.99169922
   0.90625     0.55615234  0.94238281  0.40869141  0.99755859  0.77832031
   0.89746094  0.72802734  0.71972656  0.84521484  0.97802734  0.87695312
   0.75488281  0.82470703  0.28369141  0.91503906  0.61083984  0.83984375
   0.86425781  0.87841797  0.85546875  0.94921875  0.63769531  0.73828125
   0.6171875   0.94384766  0.87939453  0.64257812  0.82373047  0.87353516
   0.90039062  0.60888672  0.93066406  0.83886719  0.97998047  0.96875
   0.87841797  0.81396484  0.83007812  0.96044922  0.828125    0.84716797
   0.76025391  0.96337891  0.87011719  0.79003906  0.87109375  0.89257812
   0.50878906  0.60839844  0.77050781  0.98876953  0.85644531  0.94775391
   0.76513672  0.80761719  0.69042969  0.71533203  0.89257812  0.71923828
   0.90869141  0.85546875  0.71386719  0.83642578  0.79980469  0.85498047
   0.71386719  0.89160156  0.78271484  0.77246094  0.55664062  0.671875
   0.97412109  0.69726562  0.83886719  0.54394531  0.69726562  0.48754883
   0.70703125  0.81054688  0.96191406  0.8359375   0.78759766  0.86865234
   0.57861328  0.89160156  0.94482422  0.640625    0.83447266  0.625
   0.38916016  0.68798828  0.70117188  0.99853516  0.84814453  0.93603516
   0.55419922  0.66162109  0.82080078  0.85595703  0.71191406  0.92041016
   0.79589844  0.48071289  0.86132812  0.86865234  0.69677734  0.84619141
   0.81640625  0.70898438  0.85449219  0.90039062  0.42724609  0.79931641
   0.95849609  0.76318359  0.62451172  0.84472656  0.99853516  0.76074219
   0.82080078  0.83935547  0.66308594  0.63818359  0.85644531  0.92822266
   0.86865234  0.87939453  0.92138672  0.52392578  0.28564453  0.81494141
   0.86669922  0.69140625  0.92919922  0.88720703  0.99023438  0.94873047
   0.72900391  0.94677734  0.87451172  0.72021484  0.75488281  0.86816406
   0.46923828  0.63916016  0.87548828  0.7578125   0.82324219  0.81787109
   0.83398438  0.73388672  0.70263672  0.94287109  0.85693359  0.83691406
   0.88818359  0.765625    0.58203125  0.45849609  0.79541016  0.97216797
   0.56054688  0.91552734  1.          0.59765625  0.80126953  0.57714844
   0.82470703  0.84912109  0.93359375  0.88476562  0.93115234  0.6953125
   0.94042969  0.8828125   0.74755859  0.83837891]]
After layer encoder_birnn_forward_l0_t7_f_output (1, 256) <class 'numpy.float16'> [[ 0.89013672  0.55371094  0.60742188  0.70068359  0.67138672  0.69824219
   0.92480469  0.67724609  0.96484375  0.66650391  0.9140625   0.72412109
   0.82226562  0.82861328  0.40820312  0.68017578  0.69775391  0.66748047
   0.87060547  0.78515625  0.56103516  0.38061523  0.89892578  0.60644531
   0.76171875  0.76708984  0.81347656  0.68359375  0.84765625  0.63525391
   0.87255859  0.82763672  0.72802734  0.74560547  0.93798828  0.6640625
   0.59082031  0.74414062  0.93505859  0.48242188  0.80664062  0.72363281
   0.9140625   0.40698242  0.56396484  0.3659668   0.92626953  0.76123047
   0.61914062  0.4140625   0.36791992  0.72949219  0.99169922  0.35620117
   0.87792969  0.32104492  0.64306641  0.75585938  0.76171875  0.83544922
   0.48803711  0.69384766  0.60595703  0.8515625   0.61816406  0.73388672
   0.82568359  0.83349609  0.70263672  0.92529297  0.48901367  0.79003906
   0.94384766  0.75048828  0.57714844  0.98974609  0.6796875   0.98730469
   0.81835938  0.27124023  0.89550781  0.30395508  0.97314453  0.828125
   0.86572266  0.79980469  0.52734375  0.92675781  0.98925781  0.66210938
   0.60546875  0.77246094  0.45605469  0.76806641  0.39916992  0.50341797
   0.90185547  0.88085938  0.86767578  0.88818359  0.60351562  0.40405273
   0.51416016  0.86914062  0.85546875  0.64111328  0.73974609  0.796875
   0.75830078  0.69921875  0.86376953  0.92578125  0.95751953  0.96972656
   0.82958984  0.72167969  0.84423828  0.90283203  0.71533203  0.69775391
   0.75732422  0.92431641  0.79589844  0.71630859  0.875       0.78320312
   0.27661133  0.72558594  0.72607422  0.97167969  0.70703125  0.83496094
   0.60791016  0.66894531  0.69824219  0.81787109  0.87353516  0.29370117
   0.93212891  0.84228516  0.72607422  0.78662109  0.81933594  0.80664062
   0.83007812  0.86181641  0.66015625  0.78710938  0.89550781  0.76269531
   0.85742188  0.62255859  0.77246094  0.8046875   0.71826172  0.67480469
   0.89550781  0.69384766  0.91455078  0.77734375  0.92138672  0.78515625
   0.86181641  0.81103516  0.85644531  0.64453125  0.68310547  0.72412109
   0.38208008  0.61621094  0.36450195  0.97216797  0.71728516  0.93310547
   0.55517578  0.63378906  0.72119141  0.85595703  0.44995117  0.91259766
   0.71582031  0.41894531  0.86523438  0.79882812  0.74511719  0.76220703
   0.86230469  0.79248047  0.78808594  0.83886719  0.28637695  0.73583984
   0.91113281  0.79492188  0.48486328  0.67871094  0.99951172  0.44580078
   0.77490234  0.44238281  0.66699219  0.79931641  0.70751953  0.92919922
   0.77001953  0.66455078  0.88378906  0.31689453  0.42700195  0.85693359
   0.84521484  0.73681641  0.82861328  0.77441406  0.97314453  0.921875
   0.625       0.87060547  0.50732422  0.47021484  0.64550781  0.81347656
   0.49316406  0.83496094  0.75488281  0.93896484  0.26733398  0.69921875
   0.76611328  0.69970703  0.68212891  0.96289062  0.63134766  0.77978516
   0.88769531  0.76611328  0.64990234  0.57519531  0.66552734  0.95263672
   0.60693359  0.88427734  0.99951172  0.40283203  0.75585938  0.41455078
   0.62597656  0.73095703  0.79296875  0.80322266  0.93457031  0.43066406
   0.90966797  0.73632812  0.71191406  0.79199219]]
After layer _mul2066_0 (1, 256) <class 'numpy.float16'> [[  5.32226562e-01   3.92578125e-01  -6.48437500e-01  -4.56298828e-01
    9.63867188e-01  -1.75537109e-01   1.88378906e+00   3.24058533e-03
   -4.91455078e-01  -1.20239258e-01   1.15039062e+00   9.05273438e-01
    2.72705078e-01  -1.32031250e+00   5.12390137e-02   1.71470642e-03
    5.65429688e-01   8.07128906e-01  -2.84912109e-01   6.18652344e-01
   -1.56372070e-01  -1.70288086e-01  -1.54785156e+00   5.08789062e-01
   -2.84423828e-01  -2.28881836e-01  -1.33105469e+00  -5.05676270e-02
   -1.31152344e+00   6.67968750e-01   9.43359375e-01  -5.55175781e-01
    1.09472656e+00  -5.90332031e-01   2.29687500e+00   4.33837891e-01
    4.15527344e-01  -1.48730469e+00  -1.96875000e+00  -8.09478760e-03
   -9.66796875e-02   9.98535156e-01  -4.81933594e-01   3.46679688e-01
   -9.35058594e-01  -2.56347656e-01  -1.07299805e-01   8.03710938e-01
    5.07812500e-01   1.56738281e-01  -4.73403931e-03   2.11334229e-02
   -2.00000000e+00  -2.62207031e-01   1.77343750e+00   2.25463867e-01
   -9.92675781e-01  -2.20947266e-01   8.45214844e-01   1.01089478e-02
    4.93164062e-01  -1.50390625e-01   1.69555664e-01   1.79101562e+00
   -5.19042969e-01   1.17614746e-01   1.06835938e+00   1.66210938e+00
    5.24414062e-01  -1.79589844e+00   2.56591797e-01   4.50439453e-02
   -2.37890625e+00   6.05957031e-01   5.66894531e-01   2.64062500e+00
    9.51660156e-01  -3.16601562e+00   1.01074219e+00  -1.34643555e-01
    1.74023438e+00  -2.49877930e-01  -2.65625000e-01   2.57812500e-01
   -1.00292969e+00  -1.21484375e+00   1.94335938e-01  -2.13867188e+00
    5.17578125e-01  -9.47265625e-02   6.13769531e-01   4.40917969e-01
   -3.43261719e-01  -6.56250000e-01  -2.42797852e-01  -1.64672852e-01
   -1.40234375e+00  -1.82714844e+00   1.25878906e+00   4.54833984e-01
   -5.62988281e-01  -3.54614258e-02  -2.29797363e-02   1.40917969e+00
   -1.07128906e+00  -6.90429688e-01   5.81542969e-01   7.01660156e-01
    4.96093750e-01   5.99609375e-01  -1.64257812e+00  -1.71191406e+00
    2.66992188e+00   2.84765625e+00  -4.40429688e-01   1.11328125e+00
    9.16992188e-01   5.37109375e-01   5.17578125e-01   1.24694824e-01
    1.60522461e-01  -1.71191406e+00   1.51269531e+00  -5.87402344e-01
    2.10937500e+00  -3.52539062e-01   2.63671875e-01   7.58789062e-01
   -9.09179688e-01  -2.61718750e+00   2.25463867e-01   1.23242188e+00
    3.94775391e-01  -2.78076172e-01   1.07519531e+00   1.38378906e+00
    8.17871094e-01   1.23596191e-01  -1.90820312e+00  -5.43945312e-01
   -2.64587402e-02   1.44921875e+00  -1.38281250e+00  -2.26440430e-01
    1.26074219e+00   2.15606689e-02   6.02539062e-01   2.92968750e-03
    1.79492188e+00  -2.31445312e-01   1.85742188e+00  -7.49511719e-01
    1.56640625e+00   1.28320312e+00   3.89404297e-01  -1.05664062e+00
    1.64550781e+00  -5.36193848e-02   1.59277344e+00   1.11718750e+00
    2.35937500e+00   9.69848633e-02   7.84179688e-01   1.34765625e+00
   -4.65087891e-01   2.24853516e-01  -8.72192383e-02   9.85839844e-01
   -2.29980469e-01  -5.88378906e-01   7.94677734e-02   3.21289062e+00
   -5.64453125e-01   2.17968750e+00  -6.13769531e-01  -7.23144531e-01
    2.04956055e-01   1.70532227e-01  -2.68554688e-01  -3.99658203e-01
    1.23730469e+00   4.16503906e-01   9.16992188e-01   8.67675781e-01
   -3.06701660e-02  -1.00292969e+00  -6.95800781e-01   1.41113281e+00
    8.75000000e-01  -9.59472656e-01   1.41601562e-01  -8.00292969e-01
   -1.79882812e+00   1.12207031e+00   2.43896484e-01  -1.09667969e+00
   -9.01855469e-01  -5.89843750e-01   1.08496094e+00  -1.33544922e-01
    4.78820801e-02  -1.25976562e+00  -1.02148438e+00  -1.29296875e+00
   -4.42871094e-01  -1.71020508e-01   1.57421875e+00   1.52587891e-02
    1.51000977e-01   2.91748047e-01  -6.94335938e-01   7.20214844e-01
    1.01953125e+00   6.04492188e-01   2.74804688e+00  -1.81152344e+00
   -5.82519531e-01  -1.73925781e+00  -3.54736328e-01  -2.17529297e-01
   -3.87939453e-01   8.60351562e-01   5.30273438e-01  -1.45605469e+00
    5.19531250e-01  -2.65625000e+00  -2.68798828e-01  -3.64013672e-01
    4.51171875e-01  -5.65490723e-02  -2.71484375e-01  -2.71679688e+00
   -3.21289062e-01   1.44335938e+00  -1.15429688e+00  -1.87072754e-02
    7.89550781e-01   3.43750000e-01  -1.77246094e-01   2.42382812e+00
    6.29882812e-01   1.54199219e+00  -3.68750000e+00  -4.35791016e-01
    1.22070312e+00  -4.03320312e-01   3.96240234e-01  -4.10888672e-01
   -1.17480469e+00   9.06738281e-01  -2.22851562e+00  -5.20019531e-02
   -1.32714844e+00  -7.69531250e-01  -4.90722656e-02   6.42089844e-01]]
After layer encoder_birnn_forward_l0_t7_i_output (1, 256) <class 'numpy.float16'> [[ 0.75244141  0.71533203  0.6796875   0.66601562  0.81298828  0.78515625
   0.92773438  0.54541016  0.27954102  0.70703125  0.70556641  0.81005859
   0.46606445  0.84814453  0.31518555  0.58300781  0.62255859  0.75683594
   0.8046875   0.67041016  0.50927734  0.1697998   0.70410156  0.64990234
   0.59277344  0.61474609  0.82128906  0.48730469  0.78027344  0.81103516
   0.76611328  0.7109375   0.8671875   0.76269531  0.96533203  0.55712891
   0.62597656  0.96044922  0.90966797  0.18835449  0.36035156  0.73193359
   0.90234375  0.52441406  0.95654297  0.71533203  0.65332031  0.75585938
   0.61474609  0.41162109  0.3972168   0.3684082   0.99707031  0.64160156
   0.90820312  0.49389648  0.88525391  0.5546875   0.6953125   0.15332031
   0.64599609  0.61523438  0.43261719  0.90576172  0.53857422  0.5625
   0.82470703  0.92919922  0.77050781  0.89746094  0.39624023  0.16040039
   0.96484375  0.74072266  0.68896484  0.96728516  0.80371094  0.99121094
   0.75976562  0.24487305  0.88964844  0.71289062  0.78369141  0.44848633
   0.88037109  0.79394531  0.66699219  0.94580078  0.89550781  0.40454102
   0.76416016  0.41259766  0.41137695  0.74609375  0.26513672  0.17028809
   0.87597656  0.91894531  0.85839844  0.72705078  0.64746094  0.34887695
   0.6796875   0.921875    0.796875    0.62792969  0.53515625  0.60205078
   0.4465332   0.55126953  0.89990234  0.87060547  0.98193359  0.9921875
   0.80078125  0.84570312  0.69384766  0.86083984  0.60693359  0.38134766
   0.39819336  0.89355469  0.96875     0.70117188  0.95996094  0.60742188
   0.69921875  0.72412109  0.62939453  0.96777344  0.34619141  0.84472656
   0.72607422  0.60302734  0.86523438  0.81152344  0.77880859  0.23217773
   0.81396484  0.484375    0.56787109  0.90527344  0.81591797  0.51123047
   0.76123047  0.23510742  0.52978516  0.38183594  0.86914062  0.42749023
   0.95068359  0.84179688  0.95654297  0.90869141  0.55517578  0.87890625
   0.77392578  0.39550781  0.86035156  0.828125    0.96679688  0.42480469
   0.82324219  0.85351562  0.80419922  0.48168945  0.57324219  0.75048828
   0.42700195  0.66796875  0.29858398  0.99902344  0.67822266  0.91259766
   0.77197266  0.59716797  0.39501953  0.30444336  0.50830078  0.69091797
   0.91845703  0.67675781  0.72949219  0.64257812  0.40551758  0.75634766
   0.56787109  0.88476562  0.80322266  0.76123047  0.28295898  0.59619141
   0.92089844  0.69140625  0.67822266  0.87988281  0.99609375  0.91015625
   0.79638672  0.56005859  0.64013672  0.84326172  0.74951172  0.78662109
   0.74853516  0.50244141  0.82714844  0.31860352  0.31054688  0.68945312
   0.79443359  0.68603516  0.90136719  0.72460938  0.9765625   0.88525391
   0.66943359  0.93212891  0.72265625  0.2824707   0.63525391  0.66259766
   0.72705078  0.79492188  0.76318359  0.99511719  0.77392578  0.44067383
   0.48706055  0.48535156  0.28759766  0.98828125  0.66503906  0.91455078
   0.80908203  0.47216797  0.66748047  0.36938477  0.51416016  0.94335938
   0.63476562  0.80810547  0.99951172  0.73974609  0.86328125  0.78320312
   0.67480469  0.62255859  0.83056641  0.671875    0.94433594  0.24829102
   0.86328125  0.72998047  0.3671875   0.67431641]]
After layer encoder_birnn_forward_l0_t7_c_output (1, 256) <class 'numpy.float16'> [[ 0.54150391  0.68457031 -0.98291016 -0.72949219  0.99462891 -0.17614746
   0.98828125 -0.12145996 -0.62744141 -0.26196289  0.93554688  0.94140625
   0.43066406 -0.97802734  0.33178711 -0.04934692  0.81445312  0.96630859
  -0.52246094  0.79345703 -0.34716797 -0.99951172 -0.99804688  0.86962891
  -0.42236328 -0.42797852 -0.99462891 -0.13513184 -0.98828125  0.91113281
   0.86132812 -0.64306641  0.98046875 -0.68359375  0.99951172  0.80712891
   0.75683594 -0.99951172 -0.99560547 -0.17382812 -0.1809082   0.99755859
  -0.54248047  0.98632812 -1.         -0.79736328  0.05230713  0.85400391
   0.89746094  0.69335938  0.10333252  0.11767578 -0.92041016 -0.88720703
   0.99658203  0.953125   -0.99902344 -0.37084961  0.95605469  0.04852295
   0.98583984 -0.22229004  0.46777344  1.         -0.9609375   0.17956543
   0.93603516  0.99511719  0.62890625 -0.99072266  0.79736328 -0.02679443
  -0.99951172  0.75292969  0.92626953  0.99609375  0.99316406 -1.
   0.94238281 -0.99853516  0.99902344 -0.93652344 -0.02069092  0.53271484
  -0.84667969 -0.99169922  0.46166992 -0.99853516  0.35546875 -0.14172363
   0.93017578  0.7734375  -0.99511719 -0.76708984 -0.99951172 -0.73486328
  -0.92529297 -0.99902344  0.93261719  0.4921875  -0.96728516 -0.15429688
  -0.20056152  0.94628906 -0.86669922 -0.99267578  0.80126953  0.85693359
   0.76708984  0.91894531 -0.99707031 -0.98291016  1.          1.
  -0.45458984  0.99365234  0.89697266  0.56445312  0.70117188  0.34521484
   0.39086914 -0.97412109  0.99169922 -0.81396484  1.         -0.66601562
   0.99902344  0.93505859 -0.99609375 -0.99951172  0.52929688  0.93994141
   0.71435547 -0.53710938  0.99365234  0.99755859  0.83496094  0.98535156
  -0.99951172 -0.73388672 -0.17700195  0.99902344 -0.99755859 -0.42407227
   0.99414062  0.14086914  0.97949219  0.03762817  0.99902344 -0.39404297
   0.99951172 -0.95507812  0.99951172  0.98095703  0.68017578 -0.99853516
   0.99902344 -0.16308594  0.9765625   0.97216797  1.          0.09454346
   0.77148438  0.98974609 -0.48339844  0.41845703 -0.27246094  0.99072266
  -0.93164062 -0.92285156  0.4934082   1.         -0.82080078  0.99951172
  -0.97607422 -0.99902344  0.52392578  0.29223633 -0.89550781 -0.43945312
   0.99902344  0.98828125  0.83740234  0.93115234 -0.14685059 -0.96386719
  -0.79931641  0.99804688  0.91845703 -0.88574219  0.99707031 -0.96923828
  -0.98779297  0.99560547  0.64453125 -0.99853516 -0.2442627  -0.99560547
   0.97607422 -0.39428711  0.14562988 -0.98486328 -0.99951172 -0.92675781
  -0.61572266 -0.10650635  0.99560547  0.03604126  0.65576172  0.49194336
  -0.69189453  0.90478516  0.87011719  0.72314453  1.         -0.99414062
  -0.92431641 -0.99804688 -0.76123047 -0.88525391 -0.72558594  0.87841797
   0.99414062 -0.99951172  0.67431641 -1.         -0.99316406 -0.67138672
   0.70019531 -0.23095703 -0.78076172 -0.99951172 -0.56884766  0.99853516
  -0.89550781  0.06561279  0.99316406  0.92431641 -0.39453125  1.
   0.98632812  0.98779297 -1.         -0.99707031  0.99560547 -0.95947266
   0.59912109 -0.61474609 -0.96875     0.93359375 -0.99804688 -0.25
  -0.92041016 -0.84472656  0.05947876  0.80810547]]
After layer _mul2067_0 (1, 256) <class 'numpy.float16'> [[ 0.4074707   0.48974609 -0.66796875 -0.48583984  0.80859375 -0.13830566
   0.91699219 -0.06622314 -0.17541504 -0.18518066  0.66015625  0.76269531
   0.20068359 -0.82958984  0.10455322 -0.02876282  0.50683594  0.73144531
  -0.42041016  0.53173828 -0.17675781 -0.16967773 -0.70263672  0.56494141
  -0.25024414 -0.26318359 -0.81689453 -0.06585693 -0.77099609  0.73876953
   0.65966797 -0.45727539  0.85009766 -0.52148438  0.96484375  0.44970703
   0.47387695 -0.95996094 -0.90576172 -0.03274536 -0.06518555  0.72998047
  -0.48950195  0.51708984 -0.95654297 -0.5703125   0.03417969  0.64550781
   0.55175781  0.28540039  0.04104614  0.04336548 -0.91748047 -0.56933594
   0.90527344  0.47070312 -0.88427734 -0.20568848  0.66455078  0.00743866
   0.63671875 -0.13671875  0.20239258  0.90576172 -0.51757812  0.10101318
   0.77197266  0.92480469  0.48461914 -0.88916016  0.31591797 -0.00429916
  -0.96435547  0.55761719  0.63818359  0.96337891  0.79833984 -0.99121094
   0.71582031 -0.24450684  0.88867188 -0.66748047 -0.01622009  0.2388916
  -0.74560547 -0.78759766  0.30786133 -0.94433594  0.31835938 -0.05734253
   0.7109375   0.3190918  -0.40942383 -0.57226562 -0.26489258 -0.12512207
  -0.81054688 -0.91796875  0.80078125  0.35791016 -0.62646484 -0.05383301
  -0.13635254  0.87255859 -0.69042969 -0.62353516  0.42871094  0.51611328
   0.3425293   0.50634766 -0.89746094 -0.85595703  0.98193359  0.9921875
  -0.36401367  0.84033203  0.62255859  0.48583984  0.42553711  0.1315918
   0.15563965 -0.87060547  0.9609375  -0.57080078  0.95996094 -0.40454102
   0.69873047  0.67724609 -0.62695312 -0.96728516  0.18322754  0.79394531
   0.51855469 -0.32397461  0.85986328  0.80957031  0.65039062  0.22875977
  -0.81347656 -0.35546875 -0.1005249   0.90429688 -0.81396484 -0.21679688
   0.75683594  0.03311157  0.51904297  0.01436615  0.86816406 -0.16845703
   0.95019531 -0.80419922  0.95605469  0.89160156  0.37768555 -0.87744141
   0.77294922 -0.06451416  0.84033203  0.80517578  0.96679688  0.04016113
   0.63525391  0.84472656 -0.38867188  0.20153809 -0.15612793  0.74365234
  -0.39770508 -0.61621094  0.14733887  0.99902344 -0.55664062  0.91210938
  -0.75341797 -0.59667969  0.20690918  0.08898926 -0.45507812 -0.30371094
   0.91748047  0.66894531  0.61083984  0.59814453 -0.05953979 -0.72900391
  -0.45385742  0.8828125   0.73779297 -0.67431641  0.28222656 -0.57763672
  -0.90966797  0.68847656  0.43725586 -0.87841797 -0.24328613 -0.90625
   0.77734375 -0.2208252   0.09320068 -0.83056641 -0.74902344 -0.72900391
  -0.4609375  -0.05352783  0.82373047  0.01148224  0.20361328  0.33911133
  -0.54980469  0.62060547  0.78417969  0.52392578  0.9765625  -0.87988281
  -0.61865234 -0.93017578 -0.55029297 -0.25       -0.4609375   0.58203125
   0.72265625 -0.79443359  0.51464844 -0.99511719 -0.76855469 -0.29589844
   0.34106445 -0.11212158 -0.2244873  -0.98779297 -0.37841797  0.91308594
  -0.72460938  0.03097534  0.66308594  0.34130859 -0.20288086  0.94335938
   0.62597656  0.79833984 -0.99951172 -0.73779297  0.859375   -0.75146484
   0.40429688 -0.3828125  -0.8046875   0.62744141 -0.94238281 -0.06207275
  -0.79443359 -0.61669922  0.02183533  0.54492188]]
After layer encoder_birnn_forward_l0_t7_state_0 (1, 256) <class 'numpy.float16'> [[ 0.93945312  0.88232422 -1.31640625 -0.94238281  1.77246094 -0.31396484
   2.80078125 -0.06298828 -0.66699219 -0.30541992  1.81054688  1.66796875
   0.47338867 -2.15039062  0.15576172 -0.02705383  1.07226562  1.5390625
  -0.70507812  1.15039062 -0.33300781 -0.33984375 -2.25        1.07421875
  -0.53466797 -0.4921875  -2.1484375  -0.11645508 -2.08203125  1.40625
   1.60351562 -1.01269531  1.9453125  -1.11132812  3.26171875  0.88378906
   0.88964844 -2.44726562 -2.875      -0.04083252 -0.16186523  1.72851562
  -0.97167969  0.86376953 -1.89160156 -0.82666016 -0.07312012  1.44921875
   1.05957031  0.44213867  0.03631592  0.06451416 -2.91796875 -0.83154297
   2.6796875   0.69628906 -1.87695312 -0.42675781  1.50976562  0.01754761
   1.12988281 -0.28710938  0.37207031  2.69726562 -1.03710938  0.21862793
   1.83984375  2.5859375   1.00878906 -2.68554688  0.57226562  0.04074097
  -3.34375     1.1640625   1.20507812  3.60351562  1.75       -4.15625
   1.7265625  -0.37915039  2.62890625 -0.91748047 -0.28173828  0.49658203
  -1.74804688 -2.00195312  0.50195312 -3.08203125  0.8359375  -0.15209961
   1.32421875  0.75976562 -0.75292969 -1.22851562 -0.5078125  -0.28979492
  -2.21289062 -2.74609375  2.05859375  0.8125     -1.18945312 -0.08929443
  -0.15930176  2.28125    -1.76171875 -1.31445312  1.00976562  1.21777344
   0.83886719  1.10546875 -2.5390625  -2.56835938  3.65234375  3.83984375
  -0.8046875   1.953125    1.5390625   1.0234375   0.94335938  0.25634766
   0.31616211 -2.58203125  2.47265625 -1.15820312  3.0703125  -0.75683594
   0.96240234  1.43554688 -1.53613281 -3.58398438  0.40869141  2.02734375
   0.91308594 -0.60205078  1.93554688  2.19335938  1.46875     0.35229492
  -2.72265625 -0.89941406 -0.12695312  2.35351562 -2.19726562 -0.44335938
   2.01757812  0.0546875   1.12109375  0.01730347  2.6640625  -0.39990234
   2.80859375 -1.55371094  2.5234375   2.17578125  0.76708984 -1.93359375
   2.41796875 -0.11816406  2.43359375  1.921875    3.32617188  0.13720703
   1.41992188  2.19140625 -0.85351562  0.42626953 -0.2434082   1.72949219
  -0.62792969 -1.20507812  0.22680664  4.2109375  -1.12109375  3.09179688
  -1.3671875  -1.3203125   0.41186523  0.25952148 -0.72363281 -0.703125
   2.15429688  1.0859375   1.52734375  1.46582031 -0.09020996 -1.73242188
  -1.14941406  2.29296875  1.61328125 -1.63378906  0.42382812 -1.37792969
  -2.70898438  1.81054688  0.68115234 -1.97460938 -1.14550781 -1.49609375
   1.86230469 -0.35449219  0.14111328 -2.08984375 -1.77050781 -2.02148438
  -0.90380859 -0.22460938  2.3984375   0.0267334   0.35449219  0.63085938
  -1.24414062  1.34082031  1.80371094  1.12890625  3.72460938 -2.69140625
  -1.20117188 -2.66992188 -0.90527344 -0.4675293  -0.84863281  1.44238281
   1.25292969 -2.25        1.03417969 -3.65234375 -1.03710938 -0.66015625
   0.79199219 -0.16870117 -0.49609375 -3.70507812 -0.69970703  2.35546875
  -1.87890625  0.01226807  1.453125    0.68505859 -0.38012695  3.3671875
   1.25585938  2.33984375 -4.6875     -1.17382812  2.08007812 -1.15429688
   0.80078125 -0.79394531 -1.97949219  1.53417969 -3.171875   -0.11407471
  -2.12109375 -1.38671875 -0.02723694  1.1875    ]]
After layer activation1033_output (1, 256) <class 'numpy.float16'> [[ 0.73486328  0.70751953 -0.86572266 -0.73632812  0.94384766 -0.30395508
   0.99267578 -0.06292725 -0.58300781 -0.29638672  0.94775391  0.93115234
   0.44091797 -0.97314453  0.15454102 -0.02705383  0.79052734  0.91210938
  -0.60742188  0.81787109 -0.32128906 -0.32739258 -0.97802734  0.79101562
  -0.48901367 -0.45605469 -0.97314453 -0.11590576 -0.96923828  0.88671875
   0.92236328 -0.76708984  0.95996094 -0.8046875   0.99707031  0.70849609
   0.71142578 -0.98535156 -0.99365234 -0.040802   -0.16052246  0.93896484
  -0.74951172  0.69824219 -0.95556641 -0.67871094 -0.07299805  0.89550781
   0.78564453  0.41552734  0.0362854   0.06445312 -0.99414062 -0.68115234
   0.99072266  0.60205078 -0.95410156 -0.40258789  0.90673828  0.01754761
   0.81103516 -0.27954102  0.35571289  0.99072266 -0.77685547  0.21520996
   0.95068359  0.98876953  0.76513672 -0.99072266  0.51708984  0.04071045
  -0.99755859  0.82226562  0.83496094  0.99853516  0.94140625 -0.99951172
   0.93847656 -0.36206055  0.98974609 -0.72460938 -0.27441406  0.45947266
  -0.94091797 -0.96435547  0.46362305 -0.99560547  0.68359375 -0.15087891
   0.86767578  0.64111328 -0.63671875 -0.84228516 -0.46826172 -0.28198242
  -0.9765625  -0.99169922  0.96777344  0.67089844 -0.83056641 -0.08905029
  -0.15795898  0.97949219 -0.94287109 -0.86523438  0.765625    0.83886719
   0.68505859  0.80224609 -0.98779297 -0.98828125  0.99853516  0.99902344
  -0.66650391  0.96044922  0.91210938  0.77148438  0.73681641  0.25097656
   0.30615234 -0.98876953  0.98583984 -0.8203125   0.99560547 -0.63916016
   0.74511719  0.89257812 -0.91162109 -0.99853516  0.38745117  0.96582031
   0.72265625 -0.53857422  0.95898438  0.97558594  0.89941406  0.33837891
  -0.99121094 -0.71582031 -0.1262207   0.98193359 -0.97558594 -0.41650391
   0.96533203  0.05462646  0.80810547  0.01730347  0.99023438 -0.37988281
   0.99267578 -0.91455078  0.98730469  0.97460938  0.64501953 -0.95898438
   0.984375   -0.11761475  0.98486328  0.95800781  0.99755859  0.13635254
   0.88964844  0.97509766 -0.69287109  0.40209961 -0.23876953  0.93896484
  -0.55664062 -0.83496094  0.22302246  0.99951172 -0.80810547  0.99609375
  -0.87792969 -0.86669922  0.39013672  0.25390625 -0.61914062 -0.60644531
   0.97363281  0.79541016  0.91015625  0.89892578 -0.08996582 -0.93945312
  -0.81738281  0.97998047  0.92382812 -0.92675781  0.40014648 -0.88037109
  -0.99121094  0.94775391  0.59228516 -0.96240234 -0.81640625 -0.90429688
   0.953125   -0.34033203  0.14013672 -0.96972656 -0.94384766 -0.96533203
  -0.71826172 -0.22094727  0.98339844  0.0267334   0.34033203  0.55859375
  -0.84667969  0.87207031  0.94726562  0.81054688  0.99902344 -0.99072266
  -0.83398438 -0.99023438 -0.71875    -0.4362793  -0.69042969  0.89404297
   0.84912109 -0.97802734  0.77539062 -0.99853516 -0.77685547 -0.57861328
   0.65966797 -0.16711426 -0.45898438 -0.99902344 -0.60400391  0.98193359
  -0.95458984  0.01226807  0.89648438  0.59472656 -0.36279297  0.99755859
   0.85009766  0.98144531 -1.         -0.82568359  0.96923828 -0.81933594
   0.66455078 -0.66064453 -0.96240234  0.91113281 -0.99658203 -0.11358643
  -0.97167969 -0.88232422 -0.02723694  0.82958984]]
After layer encoder_birnn_forward_l0_t7_out_0 (1, 256) <class 'numpy.float16'> [[ 0.66357422  0.54589844 -0.68017578 -0.63427734  0.73730469 -0.26416016
   0.96875    -0.04840088 -0.48828125 -0.23217773  0.79492188  0.75976562
   0.34863281 -0.89453125  0.06921387 -0.0163269   0.64794922  0.64990234
  -0.58740234  0.70166016 -0.24279785 -0.14367676 -0.92236328  0.70117188
  -0.36352539 -0.33935547 -0.90185547 -0.09686279 -0.54492188  0.71582031
   0.82861328 -0.66210938  0.52441406 -0.61474609  0.76855469  0.48364258
   0.60498047 -0.65185547 -0.2355957  -0.0292511  -0.11499023  0.73925781
  -0.58496094  0.54833984 -0.76074219 -0.55664062 -0.07037354  0.77636719
   0.60986328  0.24060059  0.01213837  0.05511475 -0.99169922 -0.28564453
   0.83984375  0.24963379 -0.68066406 -0.31494141  0.77636719  0.01329803
   0.43481445 -0.19128418  0.20495605  0.91113281 -0.55273438  0.17077637
   0.85205078  0.72705078  0.62451172 -0.71923828  0.43725586  0.03424072
  -0.95605469  0.66699219  0.62158203  0.99365234  0.77490234 -0.99121094
   0.85058594 -0.20141602  0.93261719 -0.29614258 -0.27368164  0.35766602
  -0.84423828 -0.70214844  0.33374023 -0.84130859  0.66845703 -0.13232422
   0.65478516  0.52880859 -0.18066406 -0.77050781 -0.28613281 -0.23681641
  -0.84423828 -0.87109375  0.828125    0.63671875 -0.52978516 -0.06573486
  -0.09747314  0.92431641 -0.82910156 -0.55615234  0.63085938  0.73291016
   0.61669922  0.48852539 -0.91943359 -0.82910156  0.97851562  0.96777344
  -0.58544922  0.78173828  0.75732422  0.74121094  0.61035156  0.21264648
   0.23278809 -0.95263672  0.85791016 -0.64794922  0.8671875  -0.5703125
   0.37915039  0.54296875 -0.70263672 -0.98730469  0.33178711  0.91552734
   0.55273438 -0.43505859  0.66210938  0.69775391  0.80273438  0.2434082
  -0.90087891 -0.61230469 -0.09008789  0.82128906 -0.78027344 -0.35620117
   0.68896484  0.04870605  0.63232422  0.0133667   0.55126953 -0.25512695
   0.96679688 -0.63769531  0.828125    0.53027344  0.44970703 -0.4675293
   0.69580078 -0.09533691  0.94726562  0.80078125  0.78564453  0.11846924
   0.51464844  0.86962891 -0.65478516  0.25756836 -0.19921875  0.58691406
  -0.2166748  -0.57421875  0.15637207  0.99804688 -0.68554688  0.93261719
  -0.48657227 -0.57324219  0.3203125   0.21728516 -0.44067383 -0.55810547
   0.77490234  0.38232422  0.78417969  0.78076172 -0.06268311 -0.79492188
  -0.66748047  0.69482422  0.78955078 -0.83447266  0.17102051 -0.70361328
  -0.95019531  0.72314453  0.36987305 -0.81298828 -0.81542969 -0.68798828
   0.78222656 -0.28564453  0.09289551 -0.61865234 -0.80859375 -0.89599609
  -0.62402344 -0.19433594  0.90625     0.01400757  0.097229    0.45532227
  -0.73388672  0.60302734  0.88037109  0.71923828  0.98925781 -0.93994141
  -0.60791016 -0.9375     -0.62841797 -0.31420898 -0.52099609  0.77636719
   0.3984375  -0.625       0.67871094 -0.75683594 -0.63964844 -0.47314453
   0.55029297 -0.12261963 -0.32250977 -0.94189453 -0.51757812  0.82177734
  -0.84765625  0.00939178  0.52197266  0.27270508 -0.28857422  0.96972656
   0.4765625   0.8984375  -1.         -0.4934082   0.77685547 -0.47290039
   0.54785156 -0.56103516 -0.8984375   0.80615234 -0.92773438 -0.07897949
  -0.91357422 -0.77880859 -0.02035522  0.6953125 ]]
After layer expand_dims1039_0 (1, 1, 256) <class 'numpy.float16'> [[[ 0.66357422  0.54589844 -0.68017578 -0.63427734  0.73730469 -0.26416016
    0.96875    -0.04840088 -0.48828125 -0.23217773  0.79492188  0.75976562
    0.34863281 -0.89453125  0.06921387 -0.0163269   0.64794922  0.64990234
   -0.58740234  0.70166016 -0.24279785 -0.14367676 -0.92236328  0.70117188
   -0.36352539 -0.33935547 -0.90185547 -0.09686279 -0.54492188  0.71582031
    0.82861328 -0.66210938  0.52441406 -0.61474609  0.76855469  0.48364258
    0.60498047 -0.65185547 -0.2355957  -0.0292511  -0.11499023  0.73925781
   -0.58496094  0.54833984 -0.76074219 -0.55664062 -0.07037354  0.77636719
    0.60986328  0.24060059  0.01213837  0.05511475 -0.99169922 -0.28564453
    0.83984375  0.24963379 -0.68066406 -0.31494141  0.77636719  0.01329803
    0.43481445 -0.19128418  0.20495605  0.91113281 -0.55273438  0.17077637
    0.85205078  0.72705078  0.62451172 -0.71923828  0.43725586  0.03424072
   -0.95605469  0.66699219  0.62158203  0.99365234  0.77490234 -0.99121094
    0.85058594 -0.20141602  0.93261719 -0.29614258 -0.27368164  0.35766602
   -0.84423828 -0.70214844  0.33374023 -0.84130859  0.66845703 -0.13232422
    0.65478516  0.52880859 -0.18066406 -0.77050781 -0.28613281 -0.23681641
   -0.84423828 -0.87109375  0.828125    0.63671875 -0.52978516 -0.06573486
   -0.09747314  0.92431641 -0.82910156 -0.55615234  0.63085938  0.73291016
    0.61669922  0.48852539 -0.91943359 -0.82910156  0.97851562  0.96777344
   -0.58544922  0.78173828  0.75732422  0.74121094  0.61035156  0.21264648
    0.23278809 -0.95263672  0.85791016 -0.64794922  0.8671875  -0.5703125
    0.37915039  0.54296875 -0.70263672 -0.98730469  0.33178711  0.91552734
    0.55273438 -0.43505859  0.66210938  0.69775391  0.80273438  0.2434082
   -0.90087891 -0.61230469 -0.09008789  0.82128906 -0.78027344 -0.35620117
    0.68896484  0.04870605  0.63232422  0.0133667   0.55126953 -0.25512695
    0.96679688 -0.63769531  0.828125    0.53027344  0.44970703 -0.4675293
    0.69580078 -0.09533691  0.94726562  0.80078125  0.78564453  0.11846924
    0.51464844  0.86962891 -0.65478516  0.25756836 -0.19921875  0.58691406
   -0.2166748  -0.57421875  0.15637207  0.99804688 -0.68554688  0.93261719
   -0.48657227 -0.57324219  0.3203125   0.21728516 -0.44067383 -0.55810547
    0.77490234  0.38232422  0.78417969  0.78076172 -0.06268311 -0.79492188
   -0.66748047  0.69482422  0.78955078 -0.83447266  0.17102051 -0.70361328
   -0.95019531  0.72314453  0.36987305 -0.81298828 -0.81542969 -0.68798828
    0.78222656 -0.28564453  0.09289551 -0.61865234 -0.80859375 -0.89599609
   -0.62402344 -0.19433594  0.90625     0.01400757  0.097229    0.45532227
   -0.73388672  0.60302734  0.88037109  0.71923828  0.98925781 -0.93994141
   -0.60791016 -0.9375     -0.62841797 -0.31420898 -0.52099609  0.77636719
    0.3984375  -0.625       0.67871094 -0.75683594 -0.63964844 -0.47314453
    0.55029297 -0.12261963 -0.32250977 -0.94189453 -0.51757812  0.82177734
   -0.84765625  0.00939178  0.52197266  0.27270508 -0.28857422  0.96972656
    0.4765625   0.8984375  -1.         -0.4934082   0.77685547 -0.47290039
    0.54785156 -0.56103516 -0.8984375   0.80615234 -0.92773438 -0.07897949
   -0.91357422 -0.77880859 -0.02035522  0.6953125 ]]]
After layer encoder_birnn_forward_l0_t8_i2h_output (1, 1024) <class 'numpy.float16'> [[ 0.0737915  -0.0458374   0.06152344 ...,  0.03591919  0.03396606
   0.02903748]]
After layer encoder_birnn_forward_l0_t8_h2h_output (1, 1024) <class 'numpy.float16'> [[ 1.28027344  1.12695312  0.84570312 ...,  2.33007812  1.29003906
   1.92871094]]
After layer _plus1034_0 (1, 1024) <class 'numpy.float16'> [[ 1.35449219  1.08105469  0.90722656 ...,  2.36523438  1.32421875
   1.95800781]]
After layer encoder_birnn_forward_l0_t8_slice_output0 (1, 256) <class 'numpy.float16'> [[  1.35449219e+00   1.08105469e+00   9.07226562e-01   8.30078125e-01
    1.73535156e+00   1.45605469e+00   2.93359375e+00   3.22265625e-01
   -1.23437500e+00   1.00390625e+00   1.04589844e+00   1.66308594e+00
   -1.01684570e-01   2.03710938e+00  -8.70605469e-01   3.56445312e-01
    4.77294922e-01   1.30175781e+00   1.74511719e+00   7.82714844e-01
    1.09130859e-01  -1.82324219e+00   9.69238281e-01   7.07519531e-01
    4.33593750e-01   6.01074219e-01   1.77343750e+00  -5.81054688e-02
    1.46972656e+00   1.77343750e+00   1.42773438e+00   9.81445312e-01
    2.21484375e+00   1.27929688e+00   3.98437500e+00   3.36914062e-01
    5.54687500e-01   3.67578125e+00   2.76367188e+00  -1.77539062e+00
   -6.46484375e-01   1.16210938e+00   2.67382812e+00   5.31005859e-03
    3.59765625e+00   1.04687500e+00   7.35351562e-01   1.33105469e+00
    5.67871094e-01  -4.35546875e-01  -4.75341797e-01  -6.08886719e-01
    6.80468750e+00   6.60156250e-01   2.67578125e+00  -1.30737305e-01
    2.47656250e+00   2.81494141e-01   9.92675781e-01  -1.91699219e+00
    5.96191406e-01   4.90234375e-01  -2.70996094e-01   2.67968750e+00
    2.66601562e-01   2.52441406e-01   1.78515625e+00   3.00585938e+00
    1.34667969e+00   2.49218750e+00  -5.26855469e-01  -1.85253906e+00
    3.75390625e+00   1.21582031e+00   8.88671875e-01   3.89062500e+00
    1.63964844e+00   5.43359375e+00   1.38769531e+00  -1.41601562e+00
    2.45312500e+00   1.07128906e+00   1.54687500e+00  -1.64062500e-01
    2.36523438e+00   1.57128906e+00   8.56933594e-01   3.36328125e+00
    2.52539062e+00  -4.00146484e-01   1.37695312e+00  -4.32861328e-01
   -4.09667969e-01   1.30664062e+00  -1.29589844e+00  -1.89355469e+00
    2.25781250e+00   2.95117188e+00   2.05273438e+00   1.15820312e+00
    8.12500000e-01  -7.86132812e-01   8.72558594e-01   2.88867188e+00
    1.50585938e+00   7.12890625e-01   1.16577148e-01   4.77783203e-01
   -2.04345703e-01   2.08007812e-01   2.61718750e+00   2.25781250e+00
    4.68359375e+00   5.57812500e+00   1.65234375e+00   1.96093750e+00
    9.27734375e-01   2.19140625e+00   4.62402344e-01  -5.06835938e-01
   -4.21386719e-01   2.44726562e+00   4.05078125e+00   1.04296875e+00
    3.73632812e+00   5.40527344e-01   9.81445312e-01   1.20019531e+00
    6.33300781e-01   3.88085938e+00  -6.73339844e-01   1.94042969e+00
    1.12988281e+00   4.27001953e-01   2.27343750e+00   1.77343750e+00
    1.48242188e+00  -1.48535156e+00   1.70898438e+00  -2.12554932e-02
    3.81591797e-01   2.64257812e+00   1.72656250e+00   5.01098633e-02
    1.34667969e+00  -1.39746094e+00   2.00927734e-01  -5.00488281e-01
    2.15039062e+00  -3.78173828e-01   3.44921875e+00   2.00585938e+00
    3.64062500e+00   2.70507812e+00   3.17138672e-01   2.38281250e+00
    1.44140625e+00  -4.04785156e-01   2.02343750e+00   1.78320312e+00
    3.94335938e+00  -2.73681641e-01   1.84472656e+00   2.08984375e+00
    1.71191406e+00  -9.75341797e-02   3.78173828e-01   1.34863281e+00
   -3.75488281e-01   8.10546875e-01  -9.74609375e-01   8.09375000e+00
    8.34472656e-01   2.71093750e+00   1.43945312e+00   3.92089844e-01
   -5.07812500e-01  -9.37988281e-01   1.15051270e-01   9.47753906e-01
    2.80078125e+00   8.43750000e-01   1.21484375e+00   7.46582031e-01
   -3.68652344e-01   1.29687500e+00   3.54248047e-01   2.45898438e+00
    1.66992188e+00   1.36132812e+00  -1.08789062e+00   5.40527344e-01
    2.71289062e+00   9.79492188e-01   7.75390625e-01   2.32226562e+00
    6.46875000e+00   2.71093750e+00   1.56933594e+00   2.42919922e-01
    7.28027344e-01   2.03710938e+00   1.25097656e+00   1.39453125e+00
    1.32226562e+00   4.69970703e-02   1.82421875e+00  -9.16503906e-01
   -9.73632812e-01   9.31640625e-01   1.60351562e+00   9.92675781e-01
    2.64062500e+00   1.16796875e+00   4.30078125e+00   2.35546875e+00
    8.63769531e-01   3.09960938e+00   1.05761719e+00  -1.23925781e+00
    6.70410156e-01   7.50976562e-01   1.22558594e+00   1.66113281e+00
    1.43359375e+00   6.21875000e+00   1.37109375e+00  -2.61230469e-01
   -4.71191406e-02  -5.38330078e-02  -9.89257812e-01   5.13671875e+00
    7.68066406e-01   2.82812500e+00   1.81835938e+00  -8.55712891e-02
    7.86132812e-01  -5.53222656e-01  -1.03149414e-02   3.24023438e+00
    6.15722656e-01   1.65625000e+00   8.96093750e+00   1.24218750e+00
    2.11718750e+00   1.51269531e+00   8.30566406e-01   5.68847656e-01
    1.88085938e+00   7.68066406e-01   3.32421875e+00  -1.28417969e+00
    2.13281250e+00   1.02832031e+00  -5.27832031e-01   8.73046875e-01]]
After layer encoder_birnn_forward_l0_t8_slice_output1 (1, 256) <class 'numpy.float16'> [[ 2.54101562  0.29980469  0.58642578  1.0078125   0.88525391  1.01855469
   2.95507812  0.95605469  3.78515625  0.93652344  2.7734375   1.10742188
   1.73242188  1.87988281 -0.49365234  0.84277344  0.96923828  0.89160156
   2.2265625   1.58398438  0.33886719 -0.67236328  2.54101562  0.57421875
   1.32617188  1.48046875  1.79003906  0.96289062  1.92578125  0.70947266
   2.27148438  1.80273438  1.21679688  1.14648438  3.234375    0.84765625
   0.48608398  1.20800781  3.04492188 -0.16381836  1.68554688  1.08203125
   2.7890625  -0.4921875   0.32250977 -0.63183594  3.00390625  1.2890625
   0.61132812 -0.39257812 -0.64941406  1.27734375  5.60546875 -0.81298828
   2.32617188 -0.94433594  0.71533203  1.36425781  1.32714844  2.04101562
  -0.05853271  0.9921875   0.63378906  2.06640625  0.57226562  1.23144531
   1.85449219  1.91308594  0.95361328  2.875      -0.03668213  1.74609375
   3.29296875  1.35058594  0.40576172  5.23828125  0.9453125   5.01171875
   1.81347656 -1.14941406  2.62695312 -0.9375      4.19140625  1.91601562
   2.21484375  1.640625    0.19250488  2.88476562  5.34765625  0.89453125
   0.46484375  1.41601562 -0.25415039  1.41113281 -0.57226562 -0.07214355
   2.62695312  2.3359375   2.16601562  2.36132812  0.46484375 -0.41918945
   0.05999756  2.2421875   2.13671875  0.76708984  1.18164062  1.62890625
   1.47851562  1.08105469  2.19140625  2.9921875   3.6796875   4.0234375
   1.98046875  1.08496094  1.87988281  2.671875    1.04296875  1.02539062
   1.31640625  2.91210938  1.58398438  1.09277344  2.21484375  1.49511719
  -1.24707031  1.19140625  1.13378906  4.1171875   1.06054688  1.97265625
   0.61279297  0.93164062  0.97216797  1.6953125   2.35742188 -1.01855469
   3.06054688  1.92578125  1.24414062  1.54101562  1.80957031  1.73925781
   1.9296875   2.16015625  0.81005859  1.57714844  2.47851562  1.38867188
   2.05664062  0.5234375   1.46875     1.64941406  1.09570312  0.88574219
   2.515625    1.06640625  2.76171875  1.47460938  2.94140625  1.6015625
   2.17382812  1.64941406  2.11914062  0.7109375   0.92578125  1.19824219
  -0.60742188  0.55273438 -0.70751953  4.015625    1.08105469  3.09375
   0.26879883  0.73779297  1.20703125  2.13085938 -0.22119141  2.77539062
   1.19824219 -0.40283203  2.140625    1.61425781  1.33007812  1.3359375
   2.11132812  1.54882812  1.56640625  1.83691406 -1.0234375   1.16894531
   2.69726562  1.57324219  0.02175903  0.87353516  8.4140625  -0.22766113
   1.44238281 -0.359375    0.75244141  1.63085938  1.03515625  2.91992188
   1.45117188  0.86669922  2.29101562 -0.94726562 -0.47265625  2.09570312
   2.015625    1.25585938  1.82519531  1.48144531  4.14453125  2.828125
   0.64599609  2.296875    0.08947754 -0.26538086  0.68310547  1.71972656
   0.07275391  1.93847656  1.375       3.31445312 -1.23339844  1.03125
   1.35449219  0.96728516  0.94335938  3.86914062  0.65087891  1.4140625
   2.45117188  1.32226562  0.74316406  0.37451172  0.8203125   3.49609375
   0.51269531  2.375       8.5703125  -0.49072266  1.46191406 -0.39306641
   0.62060547  1.17871094  1.60742188  1.58398438  3.02929688 -0.29931641
   2.72460938  1.18457031  1.15039062  1.59472656]]
After layer encoder_birnn_forward_l0_t8_slice_output2 (1, 256) <class 'numpy.float16'> [[ 0.73095703  0.89160156 -2.875      -1.18164062  3.42578125 -0.19604492
   2.95507812 -0.32055664 -0.68652344 -0.39355469  2.01367188  2.00195312
   0.51464844 -2.60742188  0.45947266 -0.0914917   1.37011719  2.33398438
  -0.88818359  1.32324219 -0.42236328 -4.8515625  -3.93164062  1.51171875
  -0.59277344 -0.5859375  -3.53710938 -0.22961426 -3.04101562  1.7734375
   1.58789062 -0.95751953  2.82617188 -0.86523438  5.09375     1.39355469
   1.10449219 -4.796875   -3.5625     -0.15612793 -0.25976562  3.82421875
  -0.93408203  2.85546875 -5.6796875  -1.19433594  0.24914551  1.53320312
   1.72265625  1.06933594  0.22363281  0.1895752  -1.67382812 -1.609375
   3.72265625  2.23242188 -4.34375    -0.43481445  2.15820312 -0.02799988
   2.87304688 -0.33105469  0.56835938  7.1328125  -2.36328125  0.25830078
   1.94238281  3.50195312  0.84179688 -3.05273438  1.18554688 -0.20117188
  -4.63671875  1.19921875  1.90917969  3.46484375  3.38867188 -6.35546875
   2.08007812 -4.1953125   4.5234375  -1.97558594  0.15234375  0.78076172
  -1.55859375 -3.0859375   0.53320312 -4.28515625  0.55078125 -0.04223633
   1.95019531  1.24023438 -3.53710938 -1.14160156 -5.0078125  -0.90332031
  -1.84472656 -4.609375    1.9921875   0.68554688 -2.45117188 -0.15441895
  -0.4050293   2.1171875  -1.61035156 -3.31445312  1.34082031  1.58398438
   1.24121094  1.90625    -3.94140625 -2.75585938  5.5390625   5.41796875
  -0.68945312  3.421875    1.89648438  0.88134766  0.91699219  0.52636719
   0.46923828 -2.55078125  3.23828125 -1.31640625  5.91015625 -0.99169922
   4.3203125   2.08398438 -3.57421875 -4.6875      0.67431641  1.99316406
   1.05566406 -0.67724609  3.42578125  3.953125    1.44238281  2.8671875
  -4.640625   -0.97167969 -0.33544922  4.4609375  -3.90625    -0.6015625
   3.38867188  0.23413086  2.72070312 -0.04016113  4.64453125 -0.52001953
   4.82421875 -2.33203125  5.17578125  2.71484375  0.96679688 -4.1328125
   4.33203125 -0.28466797  2.61523438  2.49414062  6.59765625  0.2076416
   1.29492188  3.15039062 -0.71826172  0.52978516 -0.41210938  3.1015625
  -2.02929688 -1.93457031  0.58837891  6.68359375 -1.46582031  5.30078125
  -2.66210938 -4.45703125  0.71972656  0.35888672 -1.72460938 -0.56201172
   4.3046875   2.96484375  1.46289062  1.96875    -0.23742676 -2.33398438
  -1.24609375  4.16015625  1.91992188 -1.63671875  3.84375    -2.40234375
  -3.00976562  3.57421875  0.93603516 -4.16015625  0.04605103 -3.5234375
   2.58984375 -0.39892578  0.32275391 -2.89648438 -4.7578125  -1.87402344
  -0.953125    0.08746338  3.5234375   0.02975464  0.84716797  0.81054688
  -1.00488281  1.85058594  1.609375    1.06738281  5.28125    -3.38476562
  -1.81347656 -4.21875    -1.12792969 -1.63964844 -1.10546875  1.57910156
   3.48632812 -4.88671875  1.02148438 -6.28515625 -3.36328125 -0.86865234
   1.07910156 -0.35791016 -1.32128906 -4.80078125 -0.8125      4.1953125
  -1.75976562  0.1628418   3.28710938  1.95605469 -0.55664062  6.29296875
   2.95117188  2.95703125 -6.421875   -3.734375    3.55859375 -2.36132812
   0.76074219 -0.83447266 -2.40039062  1.95605469 -4.0703125  -0.26245117
  -1.96484375 -1.41308594  0.22595215  1.43359375]]
After layer encoder_birnn_forward_l0_t8_slice_output3 (1, 256) <class 'numpy.float16'> [[ 2.71289062  1.48046875  1.53808594  2.1015625   1.55566406  2.23828125
   4.25390625  1.51171875  1.92382812  1.49121094  1.99609375  1.76367188
   1.64257812  2.78515625 -0.265625    0.51416016  1.77441406  1.11328125
   3.99023438  2.11328125  1.375      -0.40429688  3.19335938  2.43554688
   1.24023438  1.36035156  3.02734375  1.93652344  0.25634766  1.60351562
   2.67773438  2.1640625   0.2401123   1.36328125  1.453125    1.02929688
   2.06835938  0.82373047 -1.34570312  1.0546875   1.08984375  1.48828125
   1.52050781  1.46972656  1.59277344  1.72363281  3.79882812  2.21484375
   1.44824219  0.40258789 -0.77832031  2.11328125  6.91796875 -0.37939453
   2.01367188 -0.49902344  1.16113281  1.59082031  2.1171875   1.39257812
   0.18469238  0.85791016  0.33276367  2.90625     1.09179688  1.61328125
   2.5234375   1.2265625   1.80957031  1.08105469  1.9765625   2.0234375
   3.640625    1.75878906  1.28613281  6.08203125  1.81347656  5.6015625
   2.62890625  0.22399902  3.25585938 -0.41040039  6.94921875  1.48339844
   2.55664062  1.140625    1.12207031  1.97460938  4.40625     2.37695312
   1.32421875  1.87109375 -1.06933594  2.75        0.45581055  1.88769531
   2.1875      2.33789062  2.05664062  3.45898438  0.63769531  1.20898438
   0.66894531  3.33203125  2.32226562  0.65136719  1.86816406  2.26171875
   2.62109375  0.55419922  3.00585938  1.921875    4.48046875  3.921875
   2.36914062  1.77246094  1.91210938  3.76953125  1.86914062  2.03320312
   1.328125    3.78515625  2.2890625   1.48730469  2.265625    2.47265625
  -0.03991699  0.63671875  1.49707031  5.2109375   2.0625      3.37890625
   1.41894531  1.71386719  0.92773438  1.12988281  2.52539062  1.04199219
   2.67578125  2.1796875   1.16113281  1.9375      1.67578125  2.1796875
   1.13476562  2.56445312  1.48632812  1.56054688  0.29711914  0.890625
   4.2734375   1.00585938  1.89355469  0.20922852  1.09570312 -0.05194092
   1.04394531  1.80664062  3.8125      1.95800781  1.44726562  2.2109375
   0.32592773  2.54882812  3.3359375   0.64746094  1.98339844  0.5625
  -0.57861328  0.91845703  0.92578125  7.3359375   1.93847656  3.16015625
   0.34814453  0.81738281  1.90429688  2.18359375  1.03222656  2.91015625
   1.57226562 -0.11437988  2.171875    2.20703125  0.98535156  1.97753906
   1.78027344  1.02734375  2.125       2.52539062 -0.38085938  1.66992188
   3.63085938  1.26367188  0.66259766  1.92578125  7.625       1.36230469
   1.69726562  1.93164062  0.82128906  0.73730469  2.109375    2.96484375
   2.20117188  2.28515625  2.88671875  0.08361816 -1.09960938  1.83105469
   2.265625    0.89941406  3.05273438  2.40625     5.35546875  3.38867188
   1.26269531  3.38867188  2.27539062  1.0078125   1.33203125  2.21875
  -0.17700195  0.62451172  2.33203125  1.30957031  1.71191406  1.82714844
   1.94238281  1.2578125   1.109375    3.33007812  2.09570312  1.84570312
   2.4375      1.4453125   0.453125   -0.08154297  1.65722656  4.15234375
   0.37695312  2.78515625  9.7734375   0.5078125   1.66503906  0.33447266
   1.85546875  2.07226562  3.109375    2.30859375  2.93164062  0.98144531
   3.20898438  2.36523438  1.32421875  1.95800781]]
After layer encoder_birnn_forward_l0_t8_o_output (1, 256) <class 'numpy.float16'> [[ 0.93798828  0.81445312  0.82324219  0.89111328  0.82568359  0.90380859
   0.98583984  0.81933594  0.87255859  0.81640625  0.88037109  0.85351562
   0.83789062  0.94189453  0.43408203  0.62597656  0.85498047  0.75292969
   0.98193359  0.89208984  0.79833984  0.40039062  0.96044922  0.91943359
   0.77539062  0.79589844  0.95361328  0.87402344  0.56396484  0.83251953
   0.93554688  0.89697266  0.55957031  0.79638672  0.81054688  0.73681641
   0.88769531  0.69482422  0.20654297  0.74169922  0.74853516  0.81591797
   0.82080078  0.81298828  0.83105469  0.84863281  0.97802734  0.90136719
   0.80957031  0.59912109  0.31469727  0.89208984  0.99902344  0.40625
   0.88232422  0.37768555  0.76171875  0.83056641  0.89257812  0.80078125
   0.54589844  0.70214844  0.58251953  0.94824219  0.74853516  0.83398438
   0.92578125  0.7734375   0.859375    0.74658203  0.87841797  0.88330078
   0.97460938  0.85302734  0.78369141  0.99755859  0.85986328  0.99609375
   0.93261719  0.55566406  0.96289062  0.39892578  0.99902344  0.81494141
   0.92822266  0.7578125   0.75439453  0.87792969  0.98779297  0.91503906
   0.79003906  0.86669922  0.25561523  0.93994141  0.61181641  0.86865234
   0.89892578  0.91210938  0.88671875  0.96972656  0.65429688  0.77001953
   0.66113281  0.96533203  0.91064453  0.65722656  0.86621094  0.90576172
   0.93212891  0.63525391  0.95263672  0.87255859  0.98876953  0.98046875
   0.91455078  0.85498047  0.87109375  0.97753906  0.86621094  0.88427734
   0.79052734  0.97802734  0.90820312  0.81542969  0.90576172  0.92236328
   0.48999023  0.65380859  0.81689453  0.99462891  0.88720703  0.96679688
   0.80517578  0.84716797  0.71679688  0.75585938  0.92578125  0.73925781
   0.93554688  0.8984375   0.76171875  0.87402344  0.84228516  0.8984375
   0.75683594  0.92871094  0.81542969  0.82666016  0.57373047  0.70898438
   0.98632812  0.73242188  0.86914062  0.55224609  0.74951172  0.48706055
   0.73974609  0.85888672  0.97851562  0.87646484  0.80957031  0.90136719
   0.58056641  0.92773438  0.96582031  0.65625     0.87890625  0.63720703
   0.35913086  0.71484375  0.71630859  0.99951172  0.87402344  0.95947266
   0.5859375   0.69384766  0.87060547  0.89892578  0.73730469  0.94824219
   0.828125    0.47143555  0.89746094  0.90087891  0.72802734  0.87841797
   0.85595703  0.73632812  0.89306641  0.92578125  0.40600586  0.84179688
   0.97412109  0.77978516  0.65966797  0.87255859  0.99951172  0.79589844
   0.84521484  0.87353516  0.69433594  0.67626953  0.89160156  0.95117188
   0.90039062  0.90771484  0.94726562  0.52099609  0.24975586  0.86181641
   0.90576172  0.7109375   0.95507812  0.91748047  0.99511719  0.96728516
   0.77929688  0.96728516  0.90673828  0.73242188  0.79101562  0.90185547
   0.45581055  0.65136719  0.91162109  0.78759766  0.84716797  0.86132812
   0.87451172  0.77880859  0.75195312  0.96533203  0.890625    0.86376953
   0.91943359  0.80908203  0.61132812  0.47973633  0.83984375  0.984375
   0.59326172  0.94189453  1.          0.62451172  0.84082031  0.58300781
   0.86474609  0.88818359  0.95751953  0.90966797  0.94921875  0.72753906
   0.9609375   0.9140625   0.79003906  0.87646484]]
After layer encoder_birnn_forward_l0_t8_f_output (1, 256) <class 'numpy.float16'> [[ 0.92675781  0.57421875  0.64257812  0.73242188  0.70800781  0.73486328
   0.95068359  0.72216797  0.97802734  0.71826172  0.94140625  0.75146484
   0.84960938  0.86767578  0.37915039  0.69921875  0.72509766  0.70898438
   0.90283203  0.82958984  0.58398438  0.33789062  0.92675781  0.63964844
   0.79003906  0.81445312  0.85693359  0.72363281  0.87255859  0.67041016
   0.90625     0.85839844  0.77148438  0.75878906  0.96191406  0.70019531
   0.61914062  0.77001953  0.95458984  0.45922852  0.84375     0.74707031
   0.94189453  0.37939453  0.58007812  0.34716797  0.95263672  0.78417969
   0.6484375   0.40307617  0.34301758  0.78222656  0.99609375  0.30737305
   0.91113281  0.2800293   0.67138672  0.79638672  0.79052734  0.88525391
   0.48535156  0.72949219  0.65332031  0.88769531  0.63916016  0.77392578
   0.86474609  0.87158203  0.72167969  0.94677734  0.49072266  0.8515625
   0.96435547  0.79443359  0.60009766  0.99462891  0.72021484  0.99316406
   0.85986328  0.24060059  0.93261719  0.28149414  0.98486328  0.87158203
   0.90136719  0.83740234  0.54785156  0.94726562  0.99511719  0.70996094
   0.61425781  0.8046875   0.43676758  0.80371094  0.3605957   0.48193359
   0.93261719  0.91162109  0.89697266  0.9140625   0.61425781  0.39672852
   0.51513672  0.90380859  0.89453125  0.68310547  0.76513672  0.8359375
   0.81445312  0.74658203  0.89941406  0.95214844  0.97558594  0.98242188
   0.87890625  0.74755859  0.86767578  0.93554688  0.73925781  0.73583984
   0.78857422  0.94824219  0.82958984  0.74902344  0.90136719  0.81689453
   0.2232666   0.76708984  0.75634766  0.98388672  0.74267578  0.87792969
   0.6484375   0.71728516  0.72558594  0.84472656  0.91357422  0.26538086
   0.95507812  0.87255859  0.77636719  0.82373047  0.859375    0.85058594
   0.87304688  0.89648438  0.69189453  0.82861328  0.92285156  0.80029297
   0.88671875  0.62792969  0.81298828  0.83886719  0.74951172  0.70800781
   0.92529297  0.74414062  0.94042969  0.81396484  0.94970703  0.83203125
   0.89794922  0.83886719  0.89257812  0.67041016  0.71630859  0.76806641
   0.35253906  0.63476562  0.33007812  0.98242188  0.74658203  0.95654297
   0.56689453  0.67626953  0.76953125  0.89404297  0.44482422  0.94140625
   0.76806641  0.40063477  0.89501953  0.83398438  0.79101562  0.79199219
   0.89208984  0.82470703  0.82714844  0.86279297  0.2644043   0.76318359
   0.93701172  0.828125    0.50537109  0.70556641  1.          0.44335938
   0.80859375  0.41113281  0.6796875   0.83642578  0.73779297  0.94873047
   0.81005859  0.70410156  0.90820312  0.27954102  0.3840332   0.890625
   0.88232422  0.77832031  0.86132812  0.81494141  0.984375    0.94433594
   0.65625     0.90869141  0.52246094  0.43408203  0.66455078  0.84814453
   0.51806641  0.87402344  0.79833984  0.96484375  0.22558594  0.73730469
   0.79492188  0.72460938  0.71972656  0.97949219  0.65722656  0.80419922
   0.92041016  0.78955078  0.67773438  0.59277344  0.69433594  0.97070312
   0.62548828  0.91503906  1.          0.37963867  0.81201172  0.40307617
   0.65039062  0.76464844  0.83300781  0.82958984  0.95410156  0.42578125
   0.93847656  0.765625    0.75976562  0.83105469]]
After layer _mul2068_0 (1, 256) <class 'numpy.float16'> [[ 0.87060547  0.50683594 -0.84570312 -0.69042969  1.25488281 -0.23071289
   2.66210938 -0.04550171 -0.65234375 -0.21936035  1.70410156  1.25390625
   0.40209961 -1.86621094  0.05905151 -0.0189209   0.77734375  1.09082031
  -0.63671875  0.95458984 -0.19445801 -0.11480713 -2.0859375   0.68701172
  -0.42236328 -0.40087891 -1.84082031 -0.08428955 -1.81640625  0.94287109
   1.453125   -0.86914062  1.50097656 -0.84326172  3.13671875  0.61865234
   0.55078125 -1.88476562 -2.74414062 -0.01875305 -0.13659668  1.29101562
  -0.91503906  0.32763672 -1.09765625 -0.28710938 -0.06964111  1.13671875
   0.68701172  0.17822266  0.0124588   0.05047607 -2.90625    -0.25561523
   2.44140625  0.19494629 -1.25976562 -0.33984375  1.19335938  0.01553345
   0.54833984 -0.20947266  0.24304199  2.39453125 -0.66308594  0.16918945
   1.59082031  2.25390625  0.72802734 -2.54296875  0.28076172  0.03469849
  -3.22460938  0.92480469  0.72314453  3.58398438  1.26074219 -4.12890625
   1.484375   -0.09124756  2.45117188 -0.25830078 -0.27758789  0.43286133
  -1.57519531 -1.67675781  0.27490234 -2.91992188  0.83203125 -0.10797119
   0.81347656  0.61132812 -0.32885742 -0.98730469 -0.18310547 -0.13964844
  -2.06445312 -2.50390625  1.84667969  0.74267578 -0.73046875 -0.03543091
  -0.08209229  2.0625     -1.57617188 -0.89794922  0.77246094  1.01757812
   0.68310547  0.82519531 -2.28320312 -2.4453125   3.5625      3.77148438
  -0.70703125  1.45996094  1.33496094  0.95751953  0.69726562  0.18859863
   0.24926758 -2.44921875  2.05078125 -0.86767578  2.76757812 -0.61816406
   0.21484375  1.1015625  -1.16210938 -3.52539062  0.3034668   1.78027344
   0.59228516 -0.43188477  1.40429688  1.85253906  1.34179688  0.09350586
  -2.59960938 -0.78466797 -0.09857178  1.93847656 -1.88867188 -0.37719727
   1.76171875  0.04901123  0.77587891  0.01433563  2.45898438 -0.32006836
   2.49023438 -0.97558594  2.05078125  1.82519531  0.57470703 -1.36914062
   2.23828125 -0.08795166  2.2890625   1.56445312  3.15820312  0.11413574
   1.27539062  1.83789062 -0.76171875  0.28588867 -0.17431641  1.328125
  -0.22131348 -0.76513672  0.07489014  4.13671875 -0.83691406  2.95703125
  -0.77490234 -0.89306641  0.31689453  0.23205566 -0.32177734 -0.66210938
   1.65429688  0.43505859  1.3671875   1.22265625 -0.0713501  -1.37207031
  -1.02539062  1.890625    1.33398438 -1.40917969  0.11206055 -1.05175781
  -2.5390625   1.49902344  0.34423828 -1.39355469 -1.14550781 -0.66308594
   1.50585938 -0.14575195  0.09588623 -1.74804688 -1.30664062 -1.91796875
  -0.73193359 -0.15820312  2.17773438  0.00747299  0.1361084   0.56201172
  -1.09765625  1.04394531  1.55371094  0.91992188  3.66601562 -2.54101562
  -0.78808594 -2.42578125 -0.47290039 -0.20300293 -0.56396484  1.22363281
   0.64892578 -1.96679688  0.82568359 -3.5234375  -0.23400879 -0.48681641
   0.62939453 -0.12225342 -0.35693359 -3.62890625 -0.45996094  1.89453125
  -1.72949219  0.00968933  0.98486328  0.40600586 -0.26391602  3.26757812
   0.78564453  2.140625   -4.6875     -0.44555664  1.68945312 -0.46533203
   0.52099609 -0.60693359 -1.64941406  1.27246094 -3.02539062 -0.04858398
  -1.99023438 -1.06152344 -0.02069092  0.98681641]]
After layer encoder_birnn_forward_l0_t8_i_output (1, 256) <class 'numpy.float16'> [[ 0.79492188  0.74658203  0.71240234  0.69628906  0.85009766  0.81103516
   0.94970703  0.58007812  0.22546387  0.73193359  0.73974609  0.84082031
   0.47460938  0.88476562  0.29516602  0.58837891  0.6171875   0.78613281
   0.8515625   0.68603516  0.52734375  0.13903809  0.72509766  0.66992188
   0.60693359  0.64599609  0.85498047  0.4855957   0.81298828  0.85498047
   0.80664062  0.72753906  0.90136719  0.78222656  0.98193359  0.58349609
   0.63525391  0.97509766  0.94091797  0.14489746  0.34375     0.76171875
   0.93554688  0.50146484  0.97314453  0.74023438  0.67578125  0.79101562
   0.63818359  0.39282227  0.38330078  0.35229492  0.99902344  0.65917969
   0.93554688  0.46728516  0.92236328  0.56982422  0.72949219  0.12817383
   0.64501953  0.62011719  0.43261719  0.93603516  0.56640625  0.56298828
   0.85644531  0.95263672  0.79345703  0.92382812  0.37133789  0.13562012
   0.97705078  0.77148438  0.70849609  0.97998047  0.83740234  0.99560547
   0.80029297  0.1953125   0.92089844  0.74462891  0.82421875  0.45898438
   0.9140625   0.828125    0.70214844  0.96630859  0.92578125  0.40136719
   0.79833984  0.39355469  0.39892578  0.78710938  0.21484375  0.13085938
   0.90527344  0.95019531  0.88623047  0.76123047  0.69287109  0.31298828
   0.70507812  0.94726562  0.81835938  0.67089844  0.52929688  0.6171875
   0.44897461  0.55175781  0.93212891  0.90527344  0.99072266  0.99609375
   0.83935547  0.87646484  0.71679688  0.89941406  0.61376953  0.37597656
   0.39624023  0.92041016  0.98291016  0.73925781  0.9765625   0.63183594
   0.72753906  0.76855469  0.65332031  0.97998047  0.33764648  0.87451172
   0.75585938  0.60498047  0.90673828  0.85498047  0.81494141  0.18457031
   0.84667969  0.49462891  0.59423828  0.93359375  0.84912109  0.51269531
   0.79345703  0.19824219  0.55029297  0.37744141  0.89550781  0.40649414
   0.96923828  0.88134766  0.97460938  0.9375      0.57861328  0.91552734
   0.80859375  0.40014648  0.88330078  0.85595703  0.98095703  0.43188477
   0.86328125  0.89013672  0.84716797  0.47558594  0.59326172  0.79394531
   0.40722656  0.69238281  0.27392578  0.99951172  0.69726562  0.9375
   0.80859375  0.59667969  0.37573242  0.28125     0.52880859  0.72070312
   0.94287109  0.69921875  0.77099609  0.67822266  0.40893555  0.78515625
   0.58789062  0.92138672  0.84179688  0.79589844  0.25195312  0.63183594
   0.93798828  0.72705078  0.68457031  0.91064453  0.99853516  0.9375
   0.82763672  0.56054688  0.67431641  0.88476562  0.77734375  0.80126953
   0.78955078  0.51171875  0.86083984  0.28564453  0.27416992  0.71728516
   0.83251953  0.72949219  0.93359375  0.76269531  0.98681641  0.91357422
   0.70361328  0.95703125  0.7421875   0.22460938  0.66162109  0.67919922
   0.77294922  0.84033203  0.80761719  0.99804688  0.79736328  0.43505859
   0.48828125  0.48657227  0.27099609  0.99414062  0.68310547  0.94433594
   0.86035156  0.47851562  0.68701172  0.36523438  0.49731445  0.96240234
   0.64941406  0.83984375  1.          0.77587891  0.89257812  0.81933594
   0.69628906  0.63867188  0.86767578  0.68310547  0.96533203  0.21679688
   0.89404297  0.73681641  0.37109375  0.70556641]]
After layer encoder_birnn_forward_l0_t8_c_output (1, 256) <class 'numpy.float16'> [[ 0.62353516  0.71240234 -0.99365234 -0.828125    0.99804688 -0.19360352
   0.99462891 -0.31005859 -0.59570312 -0.37451172  0.96484375  0.96435547
   0.47363281 -0.98925781  0.4296875  -0.09124756  0.87890625  0.98144531
  -0.71044922  0.86767578 -0.39892578 -1.         -0.99902344  0.90722656
  -0.53173828 -0.52685547 -0.99853516 -0.22570801 -0.99560547  0.94384766
   0.91992188 -0.74316406  0.99316406 -0.69873047  1.          0.88378906
   0.80224609 -1.         -0.99853516 -0.15490723 -0.25415039  0.99902344
  -0.73242188  0.99316406 -1.         -0.83203125  0.24414062  0.91113281
   0.93798828  0.7890625   0.2199707   0.18737793 -0.93212891 -0.92285156
   0.99902344  0.97705078 -0.99951172 -0.40942383  0.97363281 -0.02799988
   0.99365234 -0.31958008  0.51416016  1.         -0.98242188  0.25268555
   0.95996094  0.99804688  0.68652344 -0.99560547  0.82910156 -0.19848633
  -1.          0.83349609  0.95703125  0.99804688  0.99755859 -1.
   0.96923828 -0.99951172  1.         -0.96240234  0.15112305  0.65332031
  -0.91503906 -0.99560547  0.48779297 -0.99951172  0.50097656 -0.04220581
   0.96044922  0.84570312 -0.99853516 -0.81494141 -1.         -0.71777344
  -0.95117188 -1.          0.96337891  0.59521484 -0.98535156 -0.15319824
  -0.38427734  0.97167969 -0.92333984 -0.99755859  0.87207031  0.91943359
   0.84570312  0.95654297 -0.99902344 -0.9921875   1.          1.
  -0.59765625  0.99804688  0.95605469  0.70703125  0.72460938  0.48266602
   0.4375     -0.98779297  0.99707031 -0.86572266  1.         -0.75830078
   0.99951172  0.96972656 -0.99853516 -1.          0.58789062  0.96337891
   0.78417969 -0.58984375  0.99804688  0.99902344  0.89404297  0.99365234
  -1.         -0.74951172 -0.32348633  0.99951172 -0.99902344 -0.53808594
   0.99755859  0.22998047  0.99121094 -0.04013062  1.         -0.4777832
   1.         -0.98144531  1.          0.99121094  0.74707031 -0.99951172
   0.99951172 -0.27709961  0.98925781  0.98632812  1.          0.20471191
   0.86035156  0.99609375 -0.61572266  0.48510742 -0.39038086  0.99609375
  -0.96582031 -0.95898438  0.52880859  1.         -0.89892578  1.
  -0.99023438 -0.99951172  0.61669922  0.34423828 -0.93847656 -0.50927734
   0.99951172  0.99462891  0.8984375   0.96191406 -0.23303223 -0.98144531
  -0.84716797  0.99951172  0.95800781 -0.92724609  0.99902344 -0.98388672
  -0.99511719  0.99853516  0.73339844 -0.99951172  0.04602051 -0.99804688
   0.98876953 -0.37915039  0.31201172 -0.99414062 -1.         -0.95410156
  -0.74121094  0.08721924  0.99804688  0.02973938  0.68945312  0.66992188
  -0.76367188  0.95166016  0.92285156  0.78857422  1.         -0.99755859
  -0.94824219 -0.99951172 -0.81054688 -0.92724609 -0.80224609  0.91845703
   0.99804688 -1.          0.77050781 -1.         -0.99755859 -0.70068359
   0.79296875 -0.34326172 -0.8671875  -1.         -0.67089844  0.99951172
  -0.94238281  0.16137695  0.99707031  0.9609375  -0.50537109  1.
   0.99462891  0.99462891 -1.         -0.99902344  0.99853516 -0.98242188
   0.64160156 -0.68310547 -0.98388672  0.9609375  -0.99951172 -0.2565918
  -0.96142578 -0.88818359  0.22216797  0.89257812]]
After layer _mul2069_0 (1, 256) <class 'numpy.float16'> [[ 0.49560547  0.53173828 -0.70800781 -0.57666016  0.84863281 -0.15698242
   0.94482422 -0.17980957 -0.13427734 -0.27416992  0.71386719  0.81103516
   0.22473145 -0.87548828  0.12683105 -0.05368042  0.54248047  0.77148438
  -0.60498047  0.59521484 -0.21032715 -0.13903809 -0.72460938  0.60791016
  -0.32275391 -0.34033203 -0.85351562 -0.10961914 -0.80957031  0.80712891
   0.7421875  -0.54052734  0.89501953 -0.54638672  0.98193359  0.515625
   0.50976562 -0.97509766 -0.93945312 -0.02244568 -0.08734131  0.76074219
  -0.68505859  0.49804688 -0.97314453 -0.61572266  0.16503906  0.72070312
   0.59863281  0.31005859  0.08428955  0.06604004 -0.93115234 -0.60839844
   0.93457031  0.45654297 -0.921875   -0.23327637  0.71044922 -0.00358963
   0.64111328 -0.19812012  0.22241211  0.93603516 -0.55664062  0.14221191
   0.82226562  0.95068359  0.54492188 -0.91992188  0.30786133 -0.0269165
  -0.97705078  0.64306641  0.67822266  0.97802734  0.83544922 -0.99560547
   0.77587891 -0.19519043  0.92089844 -0.71679688  0.12457275  0.29980469
  -0.83642578 -0.82470703  0.3425293  -0.96582031  0.46386719 -0.01693726
   0.76660156  0.33276367 -0.3984375  -0.64160156 -0.21484375 -0.09393311
  -0.86083984 -0.95019531  0.85400391  0.453125   -0.68261719 -0.04794312
  -0.27099609  0.92041016 -0.75585938 -0.66943359  0.46166992  0.56738281
   0.37963867  0.52783203 -0.93115234 -0.8984375   0.99072266  0.99609375
  -0.50146484  0.87451172  0.68505859  0.63574219  0.44482422  0.18151855
   0.17333984 -0.90917969  0.97998047 -0.64013672  0.9765625  -0.47900391
   0.72705078  0.74511719 -0.65234375 -0.97998047  0.19848633  0.84228516
   0.59277344 -0.35693359  0.90478516  0.85400391  0.72851562  0.18334961
  -0.84667969 -0.37084961 -0.19226074  0.93310547 -0.84814453 -0.27587891
   0.79150391  0.04559326  0.54541016 -0.01514435  0.89550781 -0.19421387
   0.96923828 -0.86523438  0.97460938  0.92919922  0.43237305 -0.91503906
   0.80810547 -0.11090088  0.87402344  0.84423828  0.98095703  0.08843994
   0.74267578  0.88671875 -0.52148438  0.23071289 -0.23156738  0.79101562
  -0.39331055 -0.6640625   0.14489746  0.99951172 -0.62695312  0.9375
  -0.80078125 -0.59619141  0.23168945  0.09680176 -0.49633789 -0.36694336
   0.94238281  0.6953125   0.69287109  0.65234375 -0.09527588 -0.77050781
  -0.49804688  0.92089844  0.80664062 -0.73779297  0.25170898 -0.62158203
  -0.93359375  0.72607422  0.50195312 -0.91015625  0.04595947 -0.93554688
   0.81835938 -0.21252441  0.21044922 -0.87939453 -0.77734375 -0.76464844
  -0.58544922  0.0446167   0.859375    0.00849152  0.18908691  0.48046875
  -0.63574219  0.69433594  0.86132812  0.6015625   0.98681641 -0.91113281
  -0.66699219 -0.95654297 -0.6015625  -0.20825195 -0.53076172  0.62402344
   0.77148438 -0.84033203  0.62207031 -0.99804688 -0.79541016 -0.30493164
   0.38720703 -0.16699219 -0.23498535 -0.99414062 -0.45825195  0.94384766
  -0.81054688  0.07720947  0.68505859  0.35107422 -0.2512207   0.96240234
   0.64599609  0.83544922 -1.         -0.77490234  0.89111328 -0.80517578
   0.44677734 -0.4362793  -0.85351562  0.65625    -0.96484375 -0.05563354
  -0.859375   -0.65429688  0.0824585   0.62988281]]
After layer encoder_birnn_forward_l0_t8_state_0 (1, 256) <class 'numpy.float16'> [[  1.36621094e+00   1.03906250e+00  -1.55371094e+00  -1.26757812e+00
    2.10351562e+00  -3.87695312e-01   3.60742188e+00  -2.25341797e-01
   -7.86621094e-01  -4.93652344e-01   2.41796875e+00   2.06445312e+00
    6.26953125e-01  -2.74218750e+00   1.85913086e-01  -7.26318359e-02
    1.32031250e+00   1.86230469e+00  -1.24218750e+00   1.54980469e+00
   -4.04785156e-01  -2.53906250e-01  -2.81054688e+00   1.29492188e+00
   -7.45117188e-01  -7.41210938e-01  -2.69531250e+00  -1.93847656e-01
   -2.62500000e+00   1.75000000e+00   2.19531250e+00  -1.41015625e+00
    2.39648438e+00  -1.38964844e+00   4.11718750e+00   1.13476562e+00
    1.06054688e+00  -2.85937500e+00  -3.68359375e+00  -4.11987305e-02
   -2.23876953e-01   2.05078125e+00  -1.59960938e+00   8.25683594e-01
   -2.07031250e+00  -9.02832031e-01   9.53979492e-02   1.85742188e+00
    1.28515625e+00   4.88281250e-01   9.67407227e-02   1.16516113e-01
   -3.83789062e+00  -8.64257812e-01   3.37500000e+00   6.51367188e-01
   -2.18164062e+00  -5.73242188e-01   1.90429688e+00   1.19476318e-02
    1.18945312e+00  -4.07714844e-01   4.65332031e-01   3.33007812e+00
   -1.21972656e+00   3.11523438e-01   2.41406250e+00   3.20507812e+00
    1.27343750e+00  -3.46289062e+00   5.88867188e-01   7.78198242e-03
   -4.20312500e+00   1.56835938e+00   1.40136719e+00   4.56250000e+00
    2.09570312e+00  -5.12500000e+00   2.25976562e+00  -2.86376953e-01
    3.37109375e+00  -9.75097656e-01  -1.53076172e-01   7.32421875e-01
   -2.41210938e+00  -2.50195312e+00   6.17187500e-01  -3.88671875e+00
    1.29589844e+00  -1.24877930e-01   1.58007812e+00   9.44335938e-01
   -7.27539062e-01  -1.62890625e+00  -3.97949219e-01  -2.33642578e-01
   -2.92578125e+00  -3.45312500e+00   2.70117188e+00   1.19531250e+00
   -1.41308594e+00  -8.33740234e-02  -3.53027344e-01   2.98242188e+00
   -2.33203125e+00  -1.56738281e+00   1.23437500e+00   1.58496094e+00
    1.06250000e+00   1.35351562e+00  -3.21484375e+00  -3.34375000e+00
    4.55468750e+00   4.76562500e+00  -1.20898438e+00   2.33398438e+00
    2.01953125e+00   1.59375000e+00   1.14257812e+00   3.70117188e-01
    4.22607422e-01  -3.35937500e+00   3.03125000e+00  -1.50781250e+00
    3.74414062e+00  -1.09765625e+00   9.41894531e-01   1.84667969e+00
   -1.81445312e+00  -4.50390625e+00   5.01953125e-01   2.62304688e+00
    1.18554688e+00  -7.89062500e-01   2.30859375e+00   2.70703125e+00
    2.07031250e+00   2.76855469e-01  -3.44531250e+00  -1.15527344e+00
   -2.90771484e-01   2.87109375e+00  -2.73632812e+00  -6.53320312e-01
    2.55273438e+00   9.46044922e-02   1.32128906e+00  -8.08715820e-04
    3.35546875e+00  -5.14160156e-01   3.45898438e+00  -1.84082031e+00
    3.02539062e+00   2.75390625e+00   1.00683594e+00  -2.28515625e+00
    3.04687500e+00  -1.98852539e-01   3.16406250e+00   2.40820312e+00
    4.14062500e+00   2.02636719e-01   2.01757812e+00   2.72460938e+00
   -1.28320312e+00   5.16601562e-01  -4.05761719e-01   2.11914062e+00
   -6.14746094e-01  -1.42968750e+00   2.19726562e-01   5.13671875e+00
   -1.46386719e+00   3.89453125e+00  -1.57617188e+00  -1.48925781e+00
    5.48828125e-01   3.28857422e-01  -8.18359375e-01  -1.02929688e+00
    2.59765625e+00   1.13085938e+00   2.06054688e+00   1.87500000e+00
   -1.66625977e-01  -2.14257812e+00  -1.52343750e+00   2.81250000e+00
    2.14062500e+00  -2.14648438e+00   3.63769531e-01  -1.67382812e+00
   -3.47265625e+00   2.22460938e+00   8.46191406e-01  -2.30468750e+00
   -1.09960938e+00  -1.59863281e+00   2.32421875e+00  -3.58398438e-01
    3.06396484e-01  -2.62695312e+00  -2.08398438e+00  -2.68359375e+00
   -1.31738281e+00  -1.13586426e-01   3.03710938e+00   1.59606934e-02
    3.25195312e-01   1.04296875e+00  -1.73339844e+00   1.73828125e+00
    2.41406250e+00   1.52148438e+00   4.65234375e+00  -3.45312500e+00
   -1.45507812e+00  -3.38281250e+00  -1.07421875e+00  -4.11132812e-01
   -1.09472656e+00   1.84765625e+00   1.41992188e+00  -2.80664062e+00
    1.44726562e+00  -4.52343750e+00  -1.02929688e+00  -7.91992188e-01
    1.01660156e+00  -2.89306641e-01  -5.91796875e-01  -4.62500000e+00
   -9.17968750e-01   2.83789062e+00  -2.53906250e+00   8.69140625e-02
    1.66992188e+00   7.56835938e-01  -5.15136719e-01   4.23046875e+00
    1.43164062e+00   2.97656250e+00  -5.68750000e+00  -1.22070312e+00
    2.58007812e+00  -1.27050781e+00   9.67773438e-01  -1.04296875e+00
   -2.50390625e+00   1.92871094e+00  -3.99023438e+00  -1.04248047e-01
   -2.84960938e+00  -1.71582031e+00   6.17675781e-02   1.61718750e+00]]
After layer activation1034_output (1, 256) <class 'numpy.float16'> [[  8.77929688e-01   7.77343750e-01  -9.14550781e-01  -8.53027344e-01
    9.70703125e-01  -3.69384766e-01   9.98535156e-01  -2.21557617e-01
   -6.56250000e-01  -4.57031250e-01   9.84375000e-01   9.68261719e-01
    5.56152344e-01  -9.91699219e-01   1.83837891e-01  -7.25097656e-02
    8.66699219e-01   9.53125000e-01  -8.46191406e-01   9.13574219e-01
   -3.84033203e-01  -2.48535156e-01  -9.92675781e-01   8.60351562e-01
   -6.32324219e-01  -6.29882812e-01  -9.90722656e-01  -1.91406250e-01
   -9.89746094e-01   9.41406250e-01   9.75585938e-01  -8.87695312e-01
    9.83398438e-01  -8.83300781e-01   9.99511719e-01   8.12500000e-01
    7.85644531e-01  -9.93652344e-01  -9.98535156e-01  -4.11682129e-02
   -2.20214844e-01   9.67285156e-01  -9.21386719e-01   6.78222656e-01
   -9.68750000e-01  -7.17773438e-01   9.50927734e-02   9.52636719e-01
    8.57910156e-01   4.52880859e-01   9.64355469e-02   1.15966797e-01
   -9.99023438e-01  -6.98242188e-01   9.97558594e-01   5.72753906e-01
   -9.74609375e-01  -5.17578125e-01   9.56542969e-01   1.19476318e-02
    8.30566406e-01  -3.86474609e-01   4.34326172e-01   9.97558594e-01
   -8.39355469e-01   3.01757812e-01   9.83886719e-01   9.96582031e-01
    8.54492188e-01  -9.98046875e-01   5.29296875e-01   7.78198242e-03
   -9.99511719e-01   9.16992188e-01   8.85742188e-01   1.00000000e+00
    9.70214844e-01  -1.00000000e+00   9.78515625e-01  -2.78808594e-01
    9.97558594e-01  -7.50976562e-01  -1.51855469e-01   6.24511719e-01
   -9.83886719e-01  -9.86816406e-01   5.49316406e-01  -9.99023438e-01
    8.60839844e-01  -1.24206543e-01   9.18457031e-01   7.37304688e-01
   -6.21582031e-01  -9.25781250e-01  -3.78173828e-01  -2.29492188e-01
   -9.94140625e-01  -9.98046875e-01   9.91210938e-01   8.32031250e-01
   -8.88183594e-01  -8.31909180e-02  -3.39111328e-01   9.95117188e-01
   -9.81445312e-01  -9.16503906e-01   8.43750000e-01   9.19433594e-01
    7.86621094e-01   8.75000000e-01  -9.96582031e-01  -9.97558594e-01
    1.00000000e+00   1.00000000e+00  -8.36425781e-01   9.81445312e-01
    9.65332031e-01   9.20898438e-01   8.15429688e-01   3.54003906e-01
    3.99169922e-01  -9.97558594e-01   9.95117188e-01  -9.06738281e-01
    9.99023438e-01  -7.99804688e-01   7.36328125e-01   9.51660156e-01
   -9.48242188e-01  -9.99511719e-01   4.63623047e-01   9.89746094e-01
    8.29101562e-01  -6.57714844e-01   9.80468750e-01   9.91210938e-01
    9.68750000e-01   2.70019531e-01  -9.98046875e-01  -8.19335938e-01
   -2.82958984e-01   9.93652344e-01  -9.91699219e-01  -5.73730469e-01
    9.87792969e-01   9.42993164e-02   8.67187500e-01  -8.08715820e-04
    9.97558594e-01  -4.73144531e-01   9.98046875e-01  -9.50683594e-01
    9.95117188e-01   9.91699219e-01   7.64648438e-01  -9.79492188e-01
    9.95605469e-01  -1.96289062e-01   9.96582031e-01   9.83886719e-01
    9.99511719e-01   1.99951172e-01   9.65332031e-01   9.91210938e-01
   -8.57421875e-01   4.75097656e-01  -3.84765625e-01   9.71679688e-01
   -5.47363281e-01  -8.91601562e-01   2.16308594e-01   1.00000000e+00
   -8.98437500e-01   9.99023438e-01  -9.17968750e-01  -9.03320312e-01
    4.99755859e-01   3.17382812e-01  -6.74316406e-01  -7.73437500e-01
    9.88769531e-01   8.11523438e-01   9.68261719e-01   9.54101562e-01
   -1.65161133e-01  -9.72656250e-01  -9.09179688e-01   9.92675781e-01
    9.72656250e-01  -9.73144531e-01   3.48632812e-01  -9.32128906e-01
   -9.98046875e-01   9.77050781e-01   6.88964844e-01  -9.80468750e-01
   -8.00292969e-01  -9.21386719e-01   9.80957031e-01  -3.43750000e-01
    2.97119141e-01  -9.89746094e-01  -9.69726562e-01  -9.90722656e-01
   -8.66210938e-01  -1.13098145e-01   9.95605469e-01   1.59606934e-02
    3.14208984e-01   7.79296875e-01  -9.39453125e-01   9.39941406e-01
    9.83886719e-01   9.09179688e-01   1.00000000e+00  -9.98046875e-01
   -8.96484375e-01  -9.97558594e-01  -7.91015625e-01  -3.89404297e-01
   -7.98828125e-01   9.51660156e-01   8.89648438e-01  -9.92675781e-01
    8.95019531e-01  -1.00000000e+00  -7.73437500e-01  -6.59667969e-01
    7.68554688e-01  -2.81494141e-01  -5.31250000e-01  -1.00000000e+00
   -7.25097656e-01   9.93164062e-01  -9.87792969e-01   8.66699219e-02
    9.31640625e-01   6.39160156e-01  -4.73876953e-01   9.99511719e-01
    8.92089844e-01   9.94628906e-01  -1.00000000e+00  -8.39843750e-01
    9.88769531e-01  -8.54003906e-01   7.47558594e-01  -7.79296875e-01
   -9.86816406e-01   9.58496094e-01  -9.99511719e-01  -1.03881836e-01
   -9.93164062e-01  -9.37500000e-01   6.16760254e-02   9.24316406e-01]]
After layer encoder_birnn_forward_l0_t8_out_0 (1, 256) <class 'numpy.float16'> [[  8.23730469e-01   6.33300781e-01  -7.52929688e-01  -7.60253906e-01
    8.01269531e-01  -3.33740234e-01   9.84375000e-01  -1.81518555e-01
   -5.72753906e-01  -3.73046875e-01   8.66699219e-01   8.26660156e-01
    4.66064453e-01  -9.34082031e-01   7.97729492e-02  -4.53796387e-02
    7.41210938e-01   7.17773438e-01  -8.31054688e-01   8.14941406e-01
   -3.06640625e-01  -9.94873047e-02  -9.53613281e-01   7.91015625e-01
   -4.90234375e-01  -5.01464844e-01  -9.44824219e-01  -1.67236328e-01
   -5.58105469e-01   7.83691406e-01   9.12597656e-01  -7.96386719e-01
    5.50292969e-01  -7.03613281e-01   8.10058594e-01   5.98632812e-01
    6.97265625e-01  -6.90429688e-01  -2.06298828e-01  -3.05328369e-02
   -1.64794922e-01   7.89062500e-01  -7.56347656e-01   5.51269531e-01
   -8.05175781e-01  -6.08886719e-01   9.30175781e-02   8.58886719e-01
    6.94335938e-01   2.71240234e-01   3.03497314e-02   1.03454590e-01
   -9.98046875e-01  -2.83691406e-01   8.80371094e-01   2.16308594e-01
   -7.42187500e-01  -4.29931641e-01   8.54003906e-01   9.56726074e-03
    4.53369141e-01  -2.71484375e-01   2.52929688e-01   9.45800781e-01
   -6.28417969e-01   2.51708984e-01   9.10644531e-01   7.70996094e-01
    7.34375000e-01  -7.45117188e-01   4.64843750e-01   6.87408447e-03
   -9.74121094e-01   7.82226562e-01   6.94335938e-01   9.97558594e-01
    8.34472656e-01  -9.96093750e-01   9.12597656e-01  -1.54907227e-01
    9.60449219e-01  -2.99560547e-01  -1.51733398e-01   5.08789062e-01
   -9.13085938e-01  -7.48046875e-01   4.14306641e-01  -8.76953125e-01
    8.50097656e-01  -1.13647461e-01   7.25585938e-01   6.39160156e-01
   -1.58935547e-01  -8.70117188e-01  -2.31323242e-01  -1.99340820e-01
   -8.93554688e-01  -9.10156250e-01   8.78906250e-01   8.06640625e-01
   -5.81054688e-01  -6.40869141e-02  -2.24243164e-01   9.60449219e-01
   -8.93554688e-01  -6.02539062e-01   7.30957031e-01   8.33007812e-01
    7.33398438e-01   5.55664062e-01  -9.49218750e-01  -8.70605469e-01
    9.88769531e-01   9.80468750e-01  -7.65136719e-01   8.39355469e-01
    8.40820312e-01   9.00390625e-01   7.06542969e-01   3.12988281e-01
    3.15673828e-01  -9.75585938e-01   9.03808594e-01  -7.39257812e-01
    9.04785156e-01  -7.37792969e-01   3.60839844e-01   6.22070312e-01
   -7.74414062e-01  -9.94140625e-01   4.11376953e-01   9.57031250e-01
    6.67480469e-01  -5.57128906e-01   7.02636719e-01   7.49023438e-01
    8.96972656e-01   1.99584961e-01  -9.33593750e-01  -7.36328125e-01
   -2.15576172e-01   8.68652344e-01  -8.35449219e-01  -5.15625000e-01
    7.47558594e-01   8.75854492e-02   7.07031250e-01  -6.68525696e-04
    5.72265625e-01  -3.35449219e-01   9.84375000e-01  -6.96289062e-01
    8.64746094e-01   5.47851562e-01   5.73242188e-01  -4.77050781e-01
    7.36328125e-01  -1.68579102e-01   9.75097656e-01   8.62304688e-01
    8.09082031e-01   1.80175781e-01   5.60546875e-01   9.19433594e-01
   -8.28125000e-01   3.11767578e-01  -3.38134766e-01   6.19140625e-01
   -1.96533203e-01  -6.37207031e-01   1.54907227e-01   9.99511719e-01
   -7.85156250e-01   9.58496094e-01  -5.38085938e-01  -6.26953125e-01
    4.35058594e-01   2.85400391e-01  -4.97070312e-01  -7.33398438e-01
    8.18847656e-01   3.82568359e-01   8.69140625e-01   8.59375000e-01
   -1.20239258e-01  -8.54492188e-01  -7.78320312e-01   7.30957031e-01
    8.68652344e-01  -9.00878906e-01   1.41601562e-01  -7.84667969e-01
   -9.72167969e-01   7.61718750e-01   4.54589844e-01  -8.55468750e-01
   -7.99804688e-01  -7.33398438e-01   8.29101562e-01  -3.00292969e-01
    2.06298828e-01  -6.69433594e-01  -8.64746094e-01  -9.42382812e-01
   -7.79785156e-01  -1.02661133e-01   9.42871094e-01   8.31604004e-03
    7.84912109e-02   6.71386719e-01  -8.51074219e-01   6.68457031e-01
    9.39453125e-01   8.33984375e-01   9.95117188e-01  -9.65332031e-01
   -6.98730469e-01  -9.64843750e-01  -7.17285156e-01  -2.85156250e-01
   -6.31835938e-01   8.58398438e-01   4.05517578e-01  -6.46484375e-01
    8.15917969e-01  -7.87597656e-01  -6.55273438e-01  -5.68359375e-01
    6.71875000e-01  -2.19238281e-01  -3.99414062e-01  -9.65332031e-01
   -6.45996094e-01   8.57910156e-01  -9.08203125e-01   7.01293945e-02
    5.69335938e-01   3.06640625e-01  -3.97949219e-01   9.83886719e-01
    5.29296875e-01   9.37011719e-01  -1.00000000e+00  -5.24414062e-01
    8.31542969e-01  -4.97802734e-01   6.46484375e-01  -6.92382812e-01
   -9.44824219e-01   8.72070312e-01  -9.48730469e-01  -7.55615234e-02
   -9.54589844e-01  -8.56933594e-01   4.87365723e-02   8.10058594e-01]]
After layer expand_dims1040_0 (1, 1, 256) <class 'numpy.float16'> [[[  8.23730469e-01   6.33300781e-01  -7.52929688e-01  -7.60253906e-01
     8.01269531e-01  -3.33740234e-01   9.84375000e-01  -1.81518555e-01
    -5.72753906e-01  -3.73046875e-01   8.66699219e-01   8.26660156e-01
     4.66064453e-01  -9.34082031e-01   7.97729492e-02  -4.53796387e-02
     7.41210938e-01   7.17773438e-01  -8.31054688e-01   8.14941406e-01
    -3.06640625e-01  -9.94873047e-02  -9.53613281e-01   7.91015625e-01
    -4.90234375e-01  -5.01464844e-01  -9.44824219e-01  -1.67236328e-01
    -5.58105469e-01   7.83691406e-01   9.12597656e-01  -7.96386719e-01
     5.50292969e-01  -7.03613281e-01   8.10058594e-01   5.98632812e-01
     6.97265625e-01  -6.90429688e-01  -2.06298828e-01  -3.05328369e-02
    -1.64794922e-01   7.89062500e-01  -7.56347656e-01   5.51269531e-01
    -8.05175781e-01  -6.08886719e-01   9.30175781e-02   8.58886719e-01
     6.94335938e-01   2.71240234e-01   3.03497314e-02   1.03454590e-01
    -9.98046875e-01  -2.83691406e-01   8.80371094e-01   2.16308594e-01
    -7.42187500e-01  -4.29931641e-01   8.54003906e-01   9.56726074e-03
     4.53369141e-01  -2.71484375e-01   2.52929688e-01   9.45800781e-01
    -6.28417969e-01   2.51708984e-01   9.10644531e-01   7.70996094e-01
     7.34375000e-01  -7.45117188e-01   4.64843750e-01   6.87408447e-03
    -9.74121094e-01   7.82226562e-01   6.94335938e-01   9.97558594e-01
     8.34472656e-01  -9.96093750e-01   9.12597656e-01  -1.54907227e-01
     9.60449219e-01  -2.99560547e-01  -1.51733398e-01   5.08789062e-01
    -9.13085938e-01  -7.48046875e-01   4.14306641e-01  -8.76953125e-01
     8.50097656e-01  -1.13647461e-01   7.25585938e-01   6.39160156e-01
    -1.58935547e-01  -8.70117188e-01  -2.31323242e-01  -1.99340820e-01
    -8.93554688e-01  -9.10156250e-01   8.78906250e-01   8.06640625e-01
    -5.81054688e-01  -6.40869141e-02  -2.24243164e-01   9.60449219e-01
    -8.93554688e-01  -6.02539062e-01   7.30957031e-01   8.33007812e-01
     7.33398438e-01   5.55664062e-01  -9.49218750e-01  -8.70605469e-01
     9.88769531e-01   9.80468750e-01  -7.65136719e-01   8.39355469e-01
     8.40820312e-01   9.00390625e-01   7.06542969e-01   3.12988281e-01
     3.15673828e-01  -9.75585938e-01   9.03808594e-01  -7.39257812e-01
     9.04785156e-01  -7.37792969e-01   3.60839844e-01   6.22070312e-01
    -7.74414062e-01  -9.94140625e-01   4.11376953e-01   9.57031250e-01
     6.67480469e-01  -5.57128906e-01   7.02636719e-01   7.49023438e-01
     8.96972656e-01   1.99584961e-01  -9.33593750e-01  -7.36328125e-01
    -2.15576172e-01   8.68652344e-01  -8.35449219e-01  -5.15625000e-01
     7.47558594e-01   8.75854492e-02   7.07031250e-01  -6.68525696e-04
     5.72265625e-01  -3.35449219e-01   9.84375000e-01  -6.96289062e-01
     8.64746094e-01   5.47851562e-01   5.73242188e-01  -4.77050781e-01
     7.36328125e-01  -1.68579102e-01   9.75097656e-01   8.62304688e-01
     8.09082031e-01   1.80175781e-01   5.60546875e-01   9.19433594e-01
    -8.28125000e-01   3.11767578e-01  -3.38134766e-01   6.19140625e-01
    -1.96533203e-01  -6.37207031e-01   1.54907227e-01   9.99511719e-01
    -7.85156250e-01   9.58496094e-01  -5.38085938e-01  -6.26953125e-01
     4.35058594e-01   2.85400391e-01  -4.97070312e-01  -7.33398438e-01
     8.18847656e-01   3.82568359e-01   8.69140625e-01   8.59375000e-01
    -1.20239258e-01  -8.54492188e-01  -7.78320312e-01   7.30957031e-01
     8.68652344e-01  -9.00878906e-01   1.41601562e-01  -7.84667969e-01
    -9.72167969e-01   7.61718750e-01   4.54589844e-01  -8.55468750e-01
    -7.99804688e-01  -7.33398438e-01   8.29101562e-01  -3.00292969e-01
     2.06298828e-01  -6.69433594e-01  -8.64746094e-01  -9.42382812e-01
    -7.79785156e-01  -1.02661133e-01   9.42871094e-01   8.31604004e-03
     7.84912109e-02   6.71386719e-01  -8.51074219e-01   6.68457031e-01
     9.39453125e-01   8.33984375e-01   9.95117188e-01  -9.65332031e-01
    -6.98730469e-01  -9.64843750e-01  -7.17285156e-01  -2.85156250e-01
    -6.31835938e-01   8.58398438e-01   4.05517578e-01  -6.46484375e-01
     8.15917969e-01  -7.87597656e-01  -6.55273438e-01  -5.68359375e-01
     6.71875000e-01  -2.19238281e-01  -3.99414062e-01  -9.65332031e-01
    -6.45996094e-01   8.57910156e-01  -9.08203125e-01   7.01293945e-02
     5.69335938e-01   3.06640625e-01  -3.97949219e-01   9.83886719e-01
     5.29296875e-01   9.37011719e-01  -1.00000000e+00  -5.24414062e-01
     8.31542969e-01  -4.97802734e-01   6.46484375e-01  -6.92382812e-01
    -9.44824219e-01   8.72070312e-01  -9.48730469e-01  -7.55615234e-02
    -9.54589844e-01  -8.56933594e-01   4.87365723e-02   8.10058594e-01]]]
After layer encoder_birnn_forward_l0_t9_i2h_output (1, 1024) <class 'numpy.float16'> [[ 0.0737915  -0.0458374   0.06152344 ...,  0.03591919  0.03396606
   0.02903748]]
After layer encoder_birnn_forward_l0_t9_h2h_output (1, 1024) <class 'numpy.float16'> [[ 1.45898438  1.24511719  0.97119141 ...,  2.59570312  1.50292969
   2.17578125]]
After layer _plus1035_0 (1, 1024) <class 'numpy.float16'> [[ 1.53320312  1.19921875  1.03320312 ...,  2.63085938  1.53710938
   2.20507812]]
After layer encoder_birnn_forward_l0_t9_slice_output0 (1, 256) <class 'numpy.float16'> [[ 1.53320312  1.19921875  1.03320312  0.92919922  1.94042969  1.56738281
   3.18945312  0.46289062 -1.46191406  1.11425781  1.17675781  1.80371094
  -0.05554199  2.296875   -0.93945312  0.38134766  0.45727539  1.39648438
   2.01367188  0.80517578  0.16906738 -2.          1.04394531  0.79736328
   0.50195312  0.72753906  1.95507812 -0.03399658  1.62109375  1.9921875
   1.625       1.04101562  2.48632812  1.31054688  4.49609375  0.43505859
   0.58886719  4.0234375   3.1484375  -1.99023438 -0.68359375  1.25976562
   3.00195312 -0.05932617  3.96484375  1.1484375   0.80957031  1.49414062
   0.65039062 -0.47827148 -0.51416016 -0.63085938  7.453125    0.70019531
   2.95703125 -0.23693848  2.81054688  0.29760742  1.11816406 -2.02929688
   0.58984375  0.53271484 -0.24047852  2.984375    0.35571289  0.22937012
   1.94335938  3.33984375  1.42578125  2.6953125  -0.59765625 -1.98828125
   4.02734375  1.35449219  0.95703125  4.2421875   1.81152344  5.94921875
   1.57714844 -1.62597656  2.70507812  1.19042969  1.75390625 -0.1003418
   2.625       1.76660156  0.98388672  3.71875     2.81835938 -0.36743164
   1.49511719 -0.48144531 -0.45800781  1.484375   -1.515625   -2.09570312
   2.48046875  3.37890625  2.2109375   1.29101562  0.95996094 -0.94140625
   0.99169922  3.18554688  1.61132812  0.8671875   0.08605957  0.52929688
  -0.13061523  0.22998047  2.97265625  2.51171875  5.2109375   6.0703125
   1.84570312  2.14453125  1.01171875  2.50976562  0.49926758 -0.51318359
  -0.38842773  2.65429688  4.48828125  1.15234375  4.1953125   0.64550781
   1.05761719  1.38378906  0.69677734  4.24609375 -0.66796875  2.1328125
   1.22265625  0.40625     2.63476562  1.99609375  1.66992188 -1.71972656
   1.87792969  0.01783752  0.47143555  2.93164062  1.87207031  0.05685425
   1.48535156 -1.546875    0.30053711 -0.49853516  2.32226562 -0.44311523
   3.83203125  2.27539062  4.015625    3.01367188  0.39892578  2.6796875
   1.61914062 -0.34277344  2.16992188  1.91992188  4.3828125  -0.21923828
   2.078125    2.328125    1.95214844 -0.09118652  0.45092773  1.55761719
  -0.45385742  0.90722656 -1.04980469  8.8671875   0.91162109  3.00195312
   1.60839844  0.41088867 -0.54443359 -1.0234375   0.15917969  1.03222656
   3.0859375   0.9453125   1.40234375  0.89746094 -0.35620117  1.38671875
   0.40063477  2.7890625   1.85546875  1.49316406 -1.21582031  0.69433594
   2.890625    1.125       0.78369141  2.55273438  7.15234375  2.99609375
   1.69824219  0.2253418   0.84814453  2.31640625  1.34765625  1.36523438
   1.52050781  0.09851074  2.02734375 -1.00878906 -1.10839844  1.03710938
   1.796875    1.19824219  2.94140625  1.31152344  4.70703125  2.54882812
   0.98046875  3.453125    1.140625   -1.52148438  0.74658203  0.80322266
   1.45410156  1.94824219  1.671875    6.83984375  1.45117188 -0.23400879
  -0.02020264 -0.01280212 -1.03808594  5.6875      0.84960938  3.17578125
   2.12695312 -0.01795959  0.88769531 -0.54541016 -0.04736328  3.55664062
   0.6484375   1.82128906  9.828125    1.41308594  2.35742188  1.67773438
   0.90380859  0.60107422  2.08398438  0.78564453  3.67382812 -1.39355469
   2.375       1.02148438 -0.48657227  1.01367188]]
After layer encoder_birnn_forward_l0_t9_slice_output1 (1, 256) <class 'numpy.float16'> [[ 2.94335938  0.38208008  0.71533203  1.171875    1.00878906  1.1640625
   3.2890625   1.15722656  4.08984375  1.16308594  3.06835938  1.20214844
   1.87890625  2.11523438 -0.62158203  0.92431641  1.07617188  1.08886719
   2.47851562  1.80273438  0.45825195 -0.84082031  2.82226562  0.71875
   1.46972656  1.73046875  2.03125     1.13378906  2.05273438  0.84228516
   2.54101562  1.97851562  1.43359375  1.18847656  3.6171875   1.01171875
   0.60839844  1.31152344  3.31054688 -0.25634766  1.90527344  1.14648438
   3.10546875 -0.58544922  0.36938477 -0.70800781  3.3515625   1.37402344
   0.73339844 -0.42431641 -0.73535156  1.51757812  6.18359375 -0.99414062
   2.60742188 -1.09960938  0.81201172  1.54492188  1.42773438  2.35351562
  -0.03771973  1.15820312  0.82421875  2.3046875   0.66650391  1.40332031
   2.09570312  2.171875    0.98486328  3.11523438 -0.03735352  2.13867188
   3.64453125  1.54785156  0.46899414  5.69140625  1.13085938  5.48828125
   2.0703125  -1.26367188  2.95898438 -1.02148438  4.7265625   2.18945312
   2.47460938  1.80761719  0.24609375  3.13085938  5.984375    1.16015625
   0.48803711  1.54492188 -0.32446289  1.56738281 -0.74023438 -0.1574707
   2.91210938  2.60351562  2.38085938  2.56835938  0.49023438 -0.43701172
   0.09161377  2.5234375   2.41796875  0.92822266  1.28515625  1.81933594
   1.74511719  1.28613281  2.4765625   3.3671875   4.1171875   4.4375
   2.28515625  1.17089844  2.04101562  3.0078125   1.14160156  1.20410156
   1.44238281  3.2109375   1.76855469  1.19433594  2.37890625  1.6484375
  -1.46972656  1.34179688  1.26367188  4.55078125  1.22070312  2.25976562
   0.7890625   1.13183594  1.11230469  1.85839844  2.64453125 -1.12597656
   3.36523438  2.08789062  1.46679688  1.68554688  2.05664062  2.00195312
   2.21679688  2.4375      0.90332031  1.79492188  2.71484375  1.56542969
   2.24609375  0.50927734  1.66210938  1.81835938  1.20996094  0.99902344
   2.77929688  1.27050781  3.07617188  1.66210938  3.30859375  1.84570312
   2.42773438  1.79785156  2.37695312  0.80957031  1.0546875   1.36816406
  -0.70214844  0.60546875 -0.82910156  4.32421875  1.21679688  3.4765625
   0.3034668   0.89501953  1.41503906  2.390625   -0.22460938  3.06835938
   1.42089844 -0.44189453  2.34375     1.78808594  1.53222656  1.45605469
   2.28320312  1.73828125  1.75195312  1.93164062 -1.06445312  1.27539062
   2.94921875  1.75390625  0.11669922  0.96289062  9.2890625  -0.24743652
   1.60742188 -0.47998047  0.82421875  1.81445312  1.13574219  3.15039062
   1.63085938  1.03125     2.48632812 -1.08886719 -0.63134766  2.30859375
   2.24804688  1.45996094  2.02148438  1.64941406  4.53125     3.05664062
   0.75634766  2.60742188  0.18200684 -0.4140625   0.71630859  1.91113281
   0.14929199  2.19140625  1.58789062  3.78710938 -1.38085938  1.18652344
   1.49414062  1.05371094  1.11523438  4.34375     0.78515625  1.5234375
   2.73632812  1.42773438  0.82519531  0.48071289  0.92431641  3.83398438
   0.58984375  2.609375    9.4140625  -0.54199219  1.72460938 -0.43017578
   0.72412109  1.31445312  1.83203125  1.74023438  3.296875   -0.30761719
   3.03125     1.3203125   1.37402344  1.81054688]]
After layer encoder_birnn_forward_l0_t9_slice_output2 (1, 256) <class 'numpy.float16'> [[ 0.83447266  0.93798828 -3.25976562 -1.41210938  3.74804688 -0.22558594
   3.22070312 -0.53076172 -0.56445312 -0.52001953  2.24414062  2.16992188
   0.5390625  -2.87109375  0.56054688 -0.13708496  1.55761719  2.5546875
  -1.17089844  1.52636719 -0.49755859 -5.42578125 -4.26171875  1.62207031
  -0.72851562 -0.69335938 -3.98046875 -0.32666016 -3.37109375  1.95117188
   1.80957031 -1.12011719  3.265625   -0.86132812  5.66796875  1.6484375
   1.17578125 -5.2734375  -3.94140625 -0.10791016 -0.33544922  4.1796875
  -1.23632812  3.14257812 -6.22265625 -1.24902344  0.44140625  1.73730469
   1.94140625  1.27050781  0.31469727  0.26245117 -1.65722656 -1.76367188
   4.12109375  2.54296875 -4.796875   -0.47851562  2.33984375 -0.12988281
   3.15429688 -0.43457031  0.60351562  7.859375   -2.67578125  0.35107422
   2.11328125  3.8671875   0.94335938 -3.25390625  1.25878906 -0.359375
  -5.0625      1.3984375   2.14648438  3.6953125   3.8203125  -6.92578125
   2.33984375 -4.67578125  5.015625   -2.18554688  0.31176758  0.90673828
  -1.79296875 -3.32421875  0.55908203 -4.73828125  0.73974609  0.06689453
   2.1875      1.42871094 -3.89257812 -1.22070312 -5.44140625 -0.8515625
  -1.99902344 -5.1328125   2.2265625   0.78710938 -2.74023438 -0.14782715
  -0.60546875  2.33789062 -1.86328125 -3.66992188  1.54492188  1.81738281
   1.44238281  2.14257812 -4.4453125  -3.0703125   6.07421875  6.01953125
  -0.88085938  3.83203125  2.2890625   1.09082031  0.94042969  0.69042969
   0.50292969 -2.86328125  3.61328125 -1.43652344  6.59375    -1.125
   4.703125    2.41015625 -3.88476562 -5.13671875  0.74609375  2.2109375
   1.18847656 -0.70605469  3.875       4.390625    1.58984375  3.14453125
  -5.125      -0.95361328 -0.47167969  4.89453125 -4.36328125 -0.72021484
   3.73632812  0.32348633  3.00195312 -0.15161133  5.2265625  -0.64501953
   5.2890625  -2.70703125  5.671875    3.0078125   1.07519531 -4.5234375
   4.81640625 -0.41186523  2.9140625   2.765625    7.265625    0.34667969
   1.51464844  3.53320312 -0.92236328  0.61425781 -0.5390625   3.41210938
  -2.31054688 -2.21875     0.61425781  7.3359375  -1.72460938  5.9296875
  -2.99609375 -4.94921875  0.84033203  0.39916992 -1.93945312 -0.63769531
   4.75390625  3.25976562  1.70410156  2.22851562 -0.31420898 -2.58789062
  -1.34472656  4.64453125  2.17578125 -1.82714844  4.31640625 -2.62890625
  -3.36132812  3.94335938  1.07617188 -4.55859375  0.3515625  -3.87109375
   2.89257812 -0.37133789  0.51513672 -3.24609375 -5.2109375  -2.         -1.171875
   0.2800293   3.859375    0.05706787  0.89257812  1.078125   -1.14550781
   2.14648438  1.82128906  1.19335938  5.7734375  -3.70703125 -1.94335938
  -4.7578125  -1.22363281 -1.81152344 -1.25292969  1.74609375  3.9453125
  -5.34765625  1.21875    -6.96484375 -3.7734375  -0.89404297  1.24121094
  -0.44384766 -1.56054688 -5.3671875  -0.96679688  4.64453125 -2.04296875
   0.26293945  3.61328125  2.21484375 -0.68652344  6.84375     3.296875
   3.26953125 -6.921875   -4.125       3.89453125 -2.69140625  0.85009766
  -0.92822266 -2.66601562  2.11132812 -4.55859375 -0.26367188 -2.31640625
  -1.54492188  0.37988281  1.69824219]]
After layer encoder_birnn_forward_l0_t9_slice_output3 (1, 256) <class 'numpy.float16'> [[  3.1015625    1.71679688   1.74121094   2.30078125   1.81835938
    2.50195312   4.6328125    1.75390625   2.1640625    1.69433594
    2.265625     1.99902344   1.875        3.02148438  -0.30810547
    0.60839844   1.9765625    1.30566406   4.4765625    2.37890625
    1.56054688  -0.55908203   3.46875      2.71484375   1.36914062
    1.60351562   3.40234375   2.18554688   0.23950195   1.703125
    3.09179688   2.41796875   0.28588867   1.52148438   1.64160156
    1.29101562   2.31835938   0.91113281  -1.50488281   1.13671875
    1.265625     1.59863281   1.70898438   1.57714844   1.75195312
    1.85351562   4.21875      2.44921875   1.60253906   0.51123047
   -0.84619141   2.38867188   7.59765625  -0.41064453   2.2265625
   -0.64794922   1.36230469   1.85253906   2.36523438   1.60058594
    0.20092773   0.92675781   0.34106445   3.28515625   1.23046875
    1.86328125   2.80859375   1.37988281   2.046875     1.15136719
    2.19921875   2.33398438   4.046875     2.01367188   1.48730469
    6.63671875   2.01367188   6.2265625    2.89453125   0.22680664
    3.5859375   -0.43066406   7.6875       1.69238281   2.86523438
    1.28027344   1.25488281   2.17382812   4.8828125    2.70703125
    1.49121094   2.11132812  -1.14257812   3.02929688   0.4128418
    2.109375     2.4453125    2.61328125   2.2734375    3.8515625
    0.69726562   1.35644531   0.87646484   3.70703125   2.56640625
    0.6953125    2.11328125   2.5078125    2.96289062   0.65478516
    3.30859375   2.09765625   4.89453125   4.23828125   2.67773438
    2.00976562   2.18164062   4.21484375   2.09375      2.30664062
    1.49414062   4.15234375   2.5625       1.61816406   2.54882812
    2.72851562  -0.0925293    0.79394531   1.734375     5.7734375
    2.26953125   3.73828125   1.58203125   1.94433594   1.02929688
    1.26855469   2.8359375    1.12207031   2.98046875   2.49023438
    1.39257812   2.14453125   1.92773438   2.49804688   1.35253906
    2.88867188   1.63476562   1.88964844   0.35351562   1.03515625
    4.74609375   1.13085938   2.0546875    0.25415039   1.33789062
   -0.06225586   1.19824219   2.11914062   4.24609375   2.234375
    1.54785156   2.4453125    0.3425293    2.88476562   3.70703125
    0.69140625   2.27148438   0.61279297  -0.6796875    1.00878906
    1.01074219   7.9765625    2.11328125   3.546875     0.45214844
    0.91552734   2.20898438   2.51171875   1.109375     3.23828125
    1.7265625   -0.17004395   2.44921875   2.41601562   1.11230469
    2.18164062   1.99609375   1.10058594   2.41796875   2.77929688
   -0.44165039   1.89941406   3.97460938   1.34863281   0.76171875
    2.11328125   8.4765625    1.51269531   1.79296875   2.14648438
    0.94677734   0.85791016   2.36523438   3.23828125   2.4296875
    2.515625     3.21484375   0.09655762  -1.23242188   2.13671875
    2.58398438   0.95800781   3.3984375    2.65234375   5.87109375
    3.73632812   1.51269531   3.76953125   2.52734375   1.02636719
    1.49707031   2.49023438  -0.19970703   0.671875     2.65039062
    1.41992188   1.79492188   2.08984375   2.22851562   1.44921875
    1.29882812   3.74804688   2.32226562   2.00976562   2.71484375
    1.65429688   0.54150391   0.01959229   1.86914062   4.58203125
    0.52880859   3.06640625  10.671875     0.60742188   1.86914062
    0.33642578   2.09179688   2.33203125   3.44335938   2.49609375
    3.14648438   1.08105469   3.51953125   2.63085938   1.53710938
    2.20507812]]
After layer encoder_birnn_forward_l0_t9_o_output (1, 256) <class 'numpy.float16'> [[ 0.95703125  0.84765625  0.85107422  0.90917969  0.86035156  0.92431641
   0.99023438  0.85253906  0.89697266  0.84472656  0.90576172  0.88085938
   0.8671875   0.95361328  0.42358398  0.64746094  0.87841797  0.78662109
   0.98876953  0.91503906  0.82666016  0.36376953  0.96972656  0.93798828
   0.79736328  0.83251953  0.96777344  0.89892578  0.55957031  0.84570312
   0.95654297  0.91796875  0.57080078  0.82080078  0.83789062  0.78417969
   0.91015625  0.71337891  0.18164062  0.75683594  0.77978516  0.83203125
   0.84667969  0.82861328  0.85205078  0.86474609  0.98535156  0.92041016
   0.83251953  0.625       0.30029297  0.91601562  0.99951172  0.39868164
   0.90283203  0.34350586  0.79589844  0.86425781  0.9140625   0.83203125
   0.55029297  0.71630859  0.58447266  0.96386719  0.77392578  0.86572266
   0.94335938  0.79882812  0.88574219  0.75976562  0.90039062  0.91162109
   0.98291016  0.88232422  0.81542969  0.99853516  0.88232422  0.99804688
   0.94775391  0.55664062  0.97314453  0.39404297  0.99951172  0.84472656
   0.94628906  0.78271484  0.77832031  0.89794922  0.99267578  0.9375
   0.81640625  0.89208984  0.24182129  0.95410156  0.6015625   0.89160156
   0.92041016  0.93164062  0.90673828  0.97900391  0.66748047  0.79541016
   0.70605469  0.97607422  0.92871094  0.66699219  0.89208984  0.92480469
   0.95068359  0.65820312  0.96484375  0.890625    0.99267578  0.98583984
   0.93554688  0.88183594  0.8984375   0.98535156  0.89013672  0.90966797
   0.81689453  0.984375    0.92822266  0.83447266  0.92773438  0.93847656
   0.47680664  0.68847656  0.85009766  0.99707031  0.90625     0.9765625
   0.82958984  0.875       0.73681641  0.78027344  0.94482422  0.75439453
   0.95166016  0.92333984  0.80078125  0.89501953  0.87304688  0.92382812
   0.79443359  0.94726562  0.83691406  0.86865234  0.58740234  0.73779297
   0.99121094  0.75585938  0.88623047  0.56298828  0.79199219  0.484375
   0.76806641  0.89257812  0.98583984  0.90332031  0.82470703  0.92041016
   0.58496094  0.94726562  0.97607422  0.66650391  0.90625     0.6484375
   0.33642578  0.73291016  0.73339844  0.99951172  0.89208984  0.97216797
   0.61132812  0.71435547  0.90087891  0.92480469  0.75195312  0.96240234
   0.84912109  0.45751953  0.92041016  0.91796875  0.75244141  0.8984375
   0.88037109  0.75048828  0.91796875  0.94140625  0.39135742  0.86962891
   0.98144531  0.79394531  0.68164062  0.89208984  1.          0.81933594
   0.85742188  0.89550781  0.72070312  0.70214844  0.9140625   0.96240234
   0.91894531  0.92529297  0.96142578  0.52392578  0.22570801  0.89453125
   0.9296875   0.72265625  0.96777344  0.93408203  0.99707031  0.9765625
   0.81933594  0.97753906  0.92626953  0.73632812  0.81689453  0.92333984
   0.45019531  0.66210938  0.93408203  0.80517578  0.85742188  0.89013672
   0.90283203  0.81005859  0.78564453  0.97705078  0.91064453  0.88183594
   0.93798828  0.83935547  0.63232422  0.50488281  0.86621094  0.98974609
   0.62939453  0.95556641  1.          0.64746094  0.86621094  0.58349609
   0.89013672  0.91162109  0.96923828  0.92382812  0.95898438  0.74658203
   0.97119141  0.93261719  0.82324219  0.90087891]]
After layer encoder_birnn_forward_l0_t9_f_output (1, 256) <class 'numpy.float16'> [[ 0.94970703  0.59423828  0.67138672  0.76367188  0.73291016  0.76220703
   0.96386719  0.76074219  0.98339844  0.76171875  0.95556641  0.76904297
   0.86767578  0.89257812  0.34936523  0.71582031  0.74560547  0.74804688
   0.92285156  0.85839844  0.61279297  0.30126953  0.94384766  0.67236328
   0.81298828  0.84960938  0.88427734  0.75634766  0.88623047  0.69873047
   0.92675781  0.87841797  0.80761719  0.76660156  0.97363281  0.73339844
   0.64746094  0.78759766  0.96484375  0.4362793   0.87060547  0.75878906
   0.95703125  0.35766602  0.59130859  0.33007812  0.96630859  0.79785156
   0.67578125  0.39550781  0.32397461  0.8203125   0.99804688  0.27001953
   0.93115234  0.24975586  0.69238281  0.82421875  0.80664062  0.91308594
   0.49047852  0.76123047  0.6953125   0.90917969  0.66064453  0.80273438
   0.890625    0.89746094  0.72802734  0.95751953  0.49072266  0.89453125
   0.97460938  0.82470703  0.61523438  0.99658203  0.75585938  0.99609375
   0.88818359  0.22033691  0.95068359  0.26464844  0.99121094  0.89941406
   0.92236328  0.85888672  0.56103516  0.95800781  0.99755859  0.76123047
   0.61962891  0.82421875  0.41967773  0.82763672  0.32299805  0.46069336
   0.94824219  0.93115234  0.91552734  0.92871094  0.62011719  0.39233398
   0.52294922  0.92578125  0.91796875  0.71679688  0.78320312  0.86035156
   0.8515625   0.78369141  0.92236328  0.96679688  0.98388672  0.98828125
   0.90771484  0.76318359  0.88525391  0.953125    0.7578125   0.76904297
   0.80859375  0.96142578  0.85449219  0.76757812  0.91503906  0.83886719
   0.18701172  0.79296875  0.77978516  0.98974609  0.77197266  0.90527344
   0.6875      0.75634766  0.75244141  0.86523438  0.93359375  0.24487305
   0.96679688  0.88964844  0.8125      0.84375     0.88671875  0.88085938
   0.90185547  0.91943359  0.71142578  0.85742188  0.93798828  0.82714844
   0.90429688  0.62451172  0.84033203  0.86035156  0.77050781  0.73095703
   0.94140625  0.78076172  0.95605469  0.84033203  0.96484375  0.86376953
   0.91894531  0.85791016  0.91503906  0.69189453  0.74169922  0.796875
   0.33129883  0.64697266  0.30395508  0.98681641  0.77148438  0.97021484
   0.57519531  0.70996094  0.8046875   0.91601562  0.4440918   0.95556641
   0.80566406  0.39135742  0.91259766  0.85693359  0.82226562  0.81103516
   0.90771484  0.85058594  0.85205078  0.87353516  0.25634766  0.78173828
   0.95019531  0.85253906  0.52929688  0.72363281  1.          0.43847656
   0.83300781  0.38232422  0.6953125   0.85986328  0.75683594  0.95898438
   0.83642578  0.73730469  0.92333984  0.25195312  0.34716797  0.90966797
   0.90429688  0.81152344  0.8828125   0.83886719  0.98925781  0.95507812
   0.68066406  0.93115234  0.54541016  0.39794922  0.671875    0.87109375
   0.53710938  0.89941406  0.83007812  0.97802734  0.20092773  0.76611328
   0.81689453  0.74169922  0.75292969  0.98730469  0.68701172  0.82080078
   0.93896484  0.80664062  0.6953125   0.61767578  0.71582031  0.97900391
   0.64355469  0.93164062  1.          0.36767578  0.84863281  0.39404297
   0.67333984  0.78808594  0.86181641  0.85058594  0.96435547  0.42358398
   0.95410156  0.7890625   0.79785156  0.859375  ]]
After layer _mul2070_0 (1, 256) <class 'numpy.float16'> [[  1.29785156e+00   6.17675781e-01  -1.04296875e+00  -9.67773438e-01
    1.54199219e+00  -2.95410156e-01   3.47656250e+00  -1.71386719e-01
   -7.73437500e-01  -3.75976562e-01   2.31054688e+00   1.58789062e+00
    5.43945312e-01  -2.44726562e+00   6.49414062e-02  -5.20019531e-02
    9.84375000e-01   1.39355469e+00  -1.14648438e+00   1.33007812e+00
   -2.48046875e-01  -7.64770508e-02  -2.65234375e+00   8.70605469e-01
   -6.05957031e-01  -6.29882812e-01  -2.38281250e+00  -1.46606445e-01
   -2.32617188e+00   1.22265625e+00   2.03515625e+00  -1.23828125e+00
    1.93554688e+00  -1.06542969e+00   4.00781250e+00   8.32031250e-01
    6.86523438e-01  -2.25195312e+00  -3.55468750e+00  -1.79748535e-02
   -1.94946289e-01   1.55566406e+00  -1.53125000e+00   2.95410156e-01
   -1.22460938e+00  -2.98095703e-01   9.21630859e-02   1.48242188e+00
    8.68652344e-01   1.93115234e-01   3.13415527e-02   9.55810547e-02
   -3.83007812e+00  -2.33398438e-01   3.14257812e+00   1.62719727e-01
   -1.51074219e+00  -4.72412109e-01   1.53613281e+00   1.09100342e-02
    5.83496094e-01  -3.10302734e-01   3.23486328e-01   3.02734375e+00
   -8.05664062e-01   2.50000000e-01   2.15039062e+00   2.87695312e+00
    9.27246094e-01  -3.31640625e+00   2.89062500e-01   6.96182251e-03
   -4.09765625e+00   1.29296875e+00   8.62304688e-01   4.54687500e+00
    1.58398438e+00  -5.10546875e+00   2.00781250e+00  -6.31103516e-02
    3.20507812e+00  -2.58056641e-01  -1.51733398e-01   6.58691406e-01
   -2.22460938e+00  -2.14843750e+00   3.46191406e-01  -3.72265625e+00
    1.29296875e+00  -9.50317383e-02   9.79003906e-01   7.78320312e-01
   -3.05419922e-01  -1.34765625e+00  -1.28540039e-01  -1.07666016e-01
   -2.77343750e+00  -3.21484375e+00   2.47265625e+00   1.11035156e+00
   -8.76464844e-01  -3.27148438e-02  -1.84570312e-01   2.76171875e+00
   -2.14062500e+00  -1.12304688e+00   9.66796875e-01   1.36328125e+00
    9.04785156e-01   1.06054688e+00  -2.96484375e+00  -3.23242188e+00
    4.48046875e+00   4.71093750e+00  -1.09765625e+00   1.78125000e+00
    1.78808594e+00   1.51953125e+00   8.65722656e-01   2.84667969e-01
    3.41796875e-01  -3.23046875e+00   2.58984375e+00  -1.15722656e+00
    3.42578125e+00  -9.20898438e-01   1.76147461e-01   1.46484375e+00
   -1.41503906e+00  -4.45703125e+00   3.87451172e-01   2.37500000e+00
    8.14941406e-01  -5.96679688e-01   1.73730469e+00   2.34179688e+00
    1.93261719e+00   6.78100586e-02  -3.33007812e+00  -1.02734375e+00
   -2.36206055e-01   2.42187500e+00  -2.42578125e+00  -5.75683594e-01
    2.30273438e+00   8.69750977e-02   9.39941406e-01  -6.93321228e-04
    3.14648438e+00  -4.25292969e-01   3.12890625e+00  -1.14941406e+00
    2.54296875e+00   2.36914062e+00   7.75878906e-01  -1.66992188e+00
    2.86914062e+00  -1.55273438e-01   3.02539062e+00   2.02343750e+00
    3.99414062e+00   1.75048828e-01   1.85449219e+00   2.33789062e+00
   -1.17382812e+00   3.57421875e-01  -3.01025391e-01   1.68847656e+00
   -2.03613281e-01  -9.24804688e-01   6.67724609e-02   5.07031250e+00
   -1.12890625e+00   3.77929688e+00  -9.06738281e-01  -1.05761719e+00
    4.41650391e-01   3.01269531e-01  -3.63525391e-01  -9.83398438e-01
    2.09375000e+00   4.42626953e-01   1.88085938e+00   1.60644531e+00
   -1.36962891e-01  -1.73730469e+00  -1.38281250e+00   2.39257812e+00
    1.82421875e+00  -1.87500000e+00   9.32617188e-02  -1.30859375e+00
   -3.29882812e+00   1.89648438e+00   4.47998047e-01  -1.66796875e+00
   -1.09960938e+00  -7.01171875e-01   1.93652344e+00  -1.37084961e-01
    2.13012695e-01  -2.25976562e+00  -1.57714844e+00  -2.57421875e+00
   -1.10156250e+00  -8.37402344e-02   2.80468750e+00   4.02069092e-03
    1.12915039e-01   9.48730469e-01  -1.56738281e+00   1.41113281e+00
    2.13085938e+00   1.27636719e+00   4.60156250e+00  -3.29882812e+00
   -9.90234375e-01  -3.15039062e+00  -5.85937500e-01  -1.63574219e-01
   -7.35351562e-01   1.60937500e+00   7.62695312e-01  -2.52343750e+00
    1.20117188e+00  -4.42578125e+00  -2.06787109e-01  -6.06933594e-01
    8.30566406e-01  -2.14599609e-01  -4.45556641e-01  -4.56640625e+00
   -6.30859375e-01   2.33007812e+00  -2.38476562e+00   7.01293945e-02
    1.16113281e+00   4.67529297e-01  -3.68652344e-01   4.14062500e+00
    9.21386719e-01   2.77343750e+00  -5.68750000e+00  -4.48730469e-01
    2.18945312e+00  -5.00488281e-01   6.51855469e-01  -8.21777344e-01
   -2.15820312e+00   1.64062500e+00  -3.84765625e+00  -4.41589355e-02
   -2.71875000e+00  -1.35351562e+00   4.92858887e-02   1.38964844e+00]]
After layer encoder_birnn_forward_l0_t9_i_output (1, 256) <class 'numpy.float16'> [[ 0.82226562  0.76855469  0.73730469  0.71679688  0.87451172  0.82763672
   0.96044922  0.61376953  0.18823242  0.75292969  0.76416016  0.85839844
   0.48608398  0.90869141  0.28100586  0.59423828  0.61230469  0.80175781
   0.88232422  0.69091797  0.54199219  0.11920166  0.73974609  0.68945312
   0.62304688  0.67431641  0.87597656  0.49145508  0.83496094  0.87988281
   0.83544922  0.73925781  0.92333984  0.78759766  0.98876953  0.60693359
   0.64306641  0.98242188  0.95898438  0.12023926  0.33544922  0.77880859
   0.95263672  0.48510742  0.98144531  0.75927734  0.69189453  0.81689453
   0.65722656  0.38256836  0.37426758  0.34741211  0.99951172  0.66845703
   0.95068359  0.44116211  0.94335938  0.57373047  0.75341797  0.1161499
   0.64355469  0.62988281  0.44018555  0.95166016  0.58789062  0.55712891
   0.87451172  0.96582031  0.80615234  0.93652344  0.35498047  0.12042236
   0.98242188  0.79492188  0.72265625  0.98583984  0.859375    0.99755859
   0.82861328  0.16442871  0.9375      0.76660156  0.85253906  0.47485352
   0.93261719  0.85400391  0.72802734  0.97607422  0.94384766  0.40917969
   0.81689453  0.38183594  0.38745117  0.81542969  0.18005371  0.10949707
   0.92285156  0.96679688  0.90136719  0.78417969  0.72314453  0.28051758
   0.72949219  0.96044922  0.83349609  0.70410156  0.52148438  0.62939453
   0.46728516  0.55712891  0.95117188  0.92480469  0.99462891  0.99755859
   0.86376953  0.89501953  0.73339844  0.92480469  0.62207031  0.37451172
   0.40405273  0.93408203  0.98876953  0.75976562  0.98535156  0.65576172
   0.7421875   0.79980469  0.66748047  0.98583984  0.33886719  0.89404297
   0.77246094  0.60009766  0.93310547  0.88037109  0.84179688  0.15185547
   0.8671875   0.50439453  0.61572266  0.94921875  0.86669922  0.51416016
   0.81542969  0.17553711  0.57470703  0.37792969  0.91064453  0.39111328
   0.97900391  0.90673828  0.98242188  0.953125    0.59863281  0.93603516
   0.83447266  0.41503906  0.89746094  0.87207031  0.98779297  0.4453125
   0.88867188  0.91113281  0.87548828  0.47729492  0.61083984  0.82617188
   0.38842773  0.71240234  0.25927734  1.          0.71337891  0.95263672
   0.83300781  0.60107422  0.3671875   0.2644043   0.53955078  0.73730469
   0.95654297  0.72021484  0.80273438  0.71044922  0.41186523  0.80029297
   0.59863281  0.94189453  0.86474609  0.81640625  0.2286377   0.66699219
   0.94726562  0.75488281  0.68652344  0.92773438  0.99902344  0.95263672
   0.84521484  0.55615234  0.70019531  0.91015625  0.79394531  0.79638672
   0.82080078  0.52441406  0.88378906  0.26733398  0.24816895  0.73828125
   0.85791016  0.76806641  0.94970703  0.78759766  0.99121094  0.92773438
   0.72705078  0.96923828  0.7578125   0.17919922  0.67822266  0.69042969
   0.81054688  0.87548828  0.84179688  0.99902344  0.81005859  0.44165039
   0.49487305  0.49682617  0.26147461  0.99658203  0.70068359  0.95996094
   0.89355469  0.49560547  0.70849609  0.36694336  0.48828125  0.97216797
   0.65673828  0.86083984  1.          0.80419922  0.91357422  0.84277344
   0.71191406  0.64599609  0.88916016  0.68701172  0.97509766  0.19885254
   0.91503906  0.73535156  0.38061523  0.73388672]]
After layer encoder_birnn_forward_l0_t9_c_output (1, 256) <class 'numpy.float16'> [[ 0.68310547  0.734375   -0.99707031 -0.88818359  0.99902344 -0.22180176
   0.99658203 -0.48608398 -0.51123047 -0.4777832   0.97753906  0.97412109
   0.4921875  -0.99365234  0.50830078 -0.13623047  0.91503906  0.98779297
  -0.82470703  0.90966797 -0.46020508 -1.         -0.99951172  0.92480469
  -0.62207031 -0.60009766 -0.99951172 -0.31542969 -0.99755859  0.96044922
   0.94775391 -0.80761719  0.99707031 -0.69677734  1.          0.92871094
   0.82617188 -1.         -0.99902344 -0.10748291 -0.32348633  0.99951172
  -0.84423828  0.99609375 -1.         -0.84814453  0.41479492  0.93994141
   0.95947266  0.85400391  0.3046875   0.2565918  -0.9296875  -0.94287109
   0.99951172  0.98779297 -1.         -0.44506836  0.98144531 -0.12915039
   0.99658203 -0.40917969  0.53955078  1.         -0.99072266  0.33740234
   0.97119141  0.99902344  0.73681641 -0.99707031  0.85058594 -0.34472656
  -1.          0.88525391  0.97314453  0.99853516  0.99902344 -1.
   0.98144531 -1.          1.         -0.97509766  0.30200195  0.71972656
  -0.94628906 -0.99755859  0.50732422 -1.          0.62890625  0.06677246
   0.97509766  0.89160156 -0.99902344 -0.83984375 -1.         -0.69189453
  -0.96386719 -1.          0.97705078  0.65673828 -0.99169922 -0.14672852
  -0.54101562  0.98144531 -0.953125   -0.99853516  0.91308594  0.94873047
   0.89404297  0.97265625 -0.99951172 -0.99560547  1.          1.
  -0.70703125  0.99902344  0.97949219  0.79736328  0.73535156  0.59814453
   0.46435547 -0.99365234  0.99853516 -0.89306641  1.         -0.80908203
   1.          0.98388672 -0.99902344 -1.          0.6328125   0.97607422
   0.83007812 -0.60839844  0.99902344  0.99951172  0.91992188  0.99609375
  -1.         -0.74121094 -0.43945312  1.         -0.99951172 -0.6171875
   0.99902344  0.31274414  0.99511719 -0.1505127   1.         -0.56835938
   1.         -0.99121094  1.          0.99511719  0.79150391 -1.          1.
  -0.39013672  0.99414062  0.9921875   1.          0.33349609  0.90771484
   0.99853516 -0.72705078  0.546875   -0.4921875   0.99804688 -0.98046875
  -0.9765625   0.546875    1.         -0.93847656  1.         -0.99511719
  -1.          0.68603516  0.37915039 -0.95947266 -0.56347656  1.
   0.99707031  0.93603516  0.97705078 -0.30419922 -0.98876953 -0.87304688
   1.          0.97460938 -0.94970703  0.99951172 -0.98974609 -0.99755859
   0.99902344  0.79199219 -1.          0.33764648 -0.99902344  0.99365234
  -0.35522461  0.47387695 -0.99707031 -1.         -0.96386719 -0.82470703
   0.27294922  0.99902344  0.05700684  0.71289062  0.79248047 -0.81640625
   0.97314453  0.94873047  0.83154297  1.         -0.99902344 -0.95996094
  -1.         -0.84082031 -0.94775391 -0.84912109  0.94091797  0.99902344
  -1.          0.83935547 -1.         -0.99902344 -0.71337891  0.84570312
  -0.41674805 -0.91552734 -1.         -0.74707031  1.         -0.96679688
   0.25708008  0.99853516  0.9765625  -0.59570312  1.          0.99707031
   0.99707031 -1.         -0.99951172  0.99902344 -0.99072266  0.69091797
  -0.72998047 -0.99023438  0.97119141 -1.         -0.2578125  -0.98095703
  -0.91308594  0.36254883  0.93505859]]
After layer _mul2071_0 (1, 256) <class 'numpy.float16'> [[ 0.56152344  0.56445312 -0.73535156 -0.63671875  0.87353516 -0.18359375
   0.95703125 -0.29833984 -0.09625244 -0.35961914  0.74707031  0.83642578
   0.23925781 -0.90283203  0.14282227 -0.08093262  0.56005859  0.79199219
  -0.72753906  0.62841797 -0.24938965 -0.11920166 -0.73925781  0.63769531
  -0.38769531 -0.40454102 -0.87548828 -0.1550293  -0.83300781  0.84521484
   0.79199219 -0.59716797  0.92041016 -0.54882812  0.98876953  0.56347656
   0.53125    -0.98242188 -0.95800781 -0.01292419 -0.10852051  0.77832031
  -0.80419922  0.4831543  -0.98144531 -0.64404297  0.28710938  0.76806641
   0.63037109  0.32666016  0.11401367  0.08917236 -0.92919922 -0.63037109
   0.95019531  0.43579102 -0.94335938 -0.25537109  0.73925781 -0.01499939
   0.64111328 -0.2578125   0.23754883  0.95166016 -0.58251953  0.18798828
   0.84912109  0.96484375  0.59375    -0.93359375  0.30200195 -0.04150391
  -0.98242188  0.70361328  0.703125    0.984375    0.85839844 -0.99755859
   0.81347656 -0.16442871  0.9375     -0.74755859  0.25756836  0.34179688
  -0.88232422 -0.85205078  0.36938477 -0.97607422  0.59375     0.02732849
   0.79638672  0.34033203 -0.38696289 -0.68505859 -0.18005371 -0.07574463
  -0.88964844 -0.96679688  0.88085938  0.51513672 -0.71728516 -0.04116821
  -0.39477539  0.94287109 -0.79443359 -0.703125    0.47607422  0.59716797
   0.41772461  0.54199219 -0.95068359 -0.92089844  0.99462891  0.99755859
  -0.61083984  0.89404297  0.71826172  0.73730469  0.45751953  0.22399902
   0.18762207 -0.92822266  0.98730469 -0.67871094  0.98535156 -0.53076172
   0.7421875   0.78710938 -0.66699219 -0.98583984  0.21447754  0.87255859
   0.64111328 -0.36499023  0.93212891  0.87988281  0.77441406  0.15124512
  -0.8671875  -0.3737793  -0.27050781  0.94921875 -0.86621094 -0.31738281
   0.81445312  0.05490112  0.57177734 -0.05688477  0.91064453 -0.22229004
   0.97900391 -0.89892578  0.98242188  0.94824219  0.47387695 -0.93603516
   0.83447266 -0.16186523  0.89208984  0.86523438  0.98779297  0.14855957
   0.80664062  0.90966797 -0.63671875  0.26098633 -0.30053711  0.82470703
  -0.38085938 -0.69580078  0.1418457   1.         -0.66943359  0.95263672
  -0.82910156 -0.60107422  0.25195312  0.10021973 -0.51757812 -0.41552734
   0.95654297  0.71826172  0.75146484  0.69433594 -0.12524414 -0.79150391
  -0.52246094  0.94189453  0.84277344 -0.77539062  0.22851562 -0.66015625
  -0.94482422  0.75390625  0.54394531 -0.92773438  0.33740234 -0.95166016
   0.83984375 -0.19750977  0.33178711 -0.90771484 -0.79394531 -0.76757812
  -0.67675781  0.14318848  0.8828125   0.01524353  0.17687988  0.58496094
  -0.70019531  0.74755859  0.90087891  0.65478516  0.99121094 -0.92675781
  -0.69775391 -0.96923828 -0.63720703 -0.1697998  -0.57568359  0.64941406
   0.80957031 -0.87548828  0.70654297 -0.99902344 -0.80908203 -0.31518555
   0.41845703 -0.20703125 -0.23937988 -0.99658203 -0.5234375   0.95996094
  -0.86376953  0.12744141  0.70751953  0.35839844 -0.29077148  0.97216797
   0.65478516  0.85839844 -1.         -0.80371094  0.91259766 -0.83496094
   0.49194336 -0.47167969 -0.88037109  0.66699219 -0.97509766 -0.05126953
  -0.89746094 -0.67138672  0.13793945  0.68603516]]
After layer encoder_birnn_forward_l0_t9_state_0 (1, 256) <class 'numpy.float16'> [[  1.85937500e+00   1.18164062e+00  -1.77832031e+00  -1.60449219e+00
    2.41601562e+00  -4.79003906e-01   4.43359375e+00  -4.69726562e-01
   -8.69628906e-01  -7.35351562e-01   3.05859375e+00   2.42382812e+00
    7.83203125e-01  -3.34960938e+00   2.07763672e-01  -1.32934570e-01
    1.54492188e+00   2.18554688e+00  -1.87402344e+00   1.95898438e+00
   -4.97558594e-01  -1.95678711e-01  -3.39062500e+00   1.50781250e+00
   -9.93652344e-01  -1.03417969e+00  -3.25781250e+00  -3.01757812e-01
   -3.16015625e+00   2.06835938e+00   2.82812500e+00  -1.83593750e+00
    2.85546875e+00  -1.61425781e+00   4.99609375e+00   1.39550781e+00
    1.21777344e+00  -3.23437500e+00  -4.51171875e+00  -3.08990479e-02
   -3.03466797e-01   2.33398438e+00  -2.33593750e+00   7.78320312e-01
   -2.20703125e+00  -9.42382812e-01   3.79394531e-01   2.25000000e+00
    1.49902344e+00   5.19531250e-01   1.45385742e-01   1.84814453e-01
   -4.75781250e+00  -8.63769531e-01   4.09375000e+00   5.98632812e-01
   -2.45312500e+00  -7.27539062e-01   2.27539062e+00  -4.08935547e-03
    1.22460938e+00  -5.68359375e-01   5.61035156e-01   3.97851562e+00
   -1.38867188e+00   4.37988281e-01   3.00000000e+00   3.84179688e+00
    1.52148438e+00  -4.25000000e+00   5.90820312e-01  -3.45458984e-02
   -5.07812500e+00   1.99609375e+00   1.56542969e+00   5.53125000e+00
    2.44140625e+00  -6.10156250e+00   2.82031250e+00  -2.27539062e-01
    4.14062500e+00  -1.00585938e+00   1.05834961e-01   1.00000000e+00
   -3.10742188e+00  -3.00000000e+00   7.15820312e-01  -4.69921875e+00
    1.88671875e+00  -6.76879883e-02   1.77539062e+00   1.11914062e+00
   -6.92382812e-01  -2.03320312e+00  -3.08593750e-01  -1.83349609e-01
   -3.66406250e+00  -4.17968750e+00   3.35351562e+00   1.62500000e+00
   -1.59375000e+00  -7.38525391e-02  -5.79101562e-01   3.70507812e+00
   -2.93554688e+00  -1.82617188e+00   1.44335938e+00   1.96093750e+00
    1.32226562e+00   1.60253906e+00  -3.91601562e+00  -4.15234375e+00
    5.47656250e+00   5.70703125e+00  -1.70898438e+00   2.67578125e+00
    2.50585938e+00   2.25781250e+00   1.32324219e+00   5.08789062e-01
    5.29296875e-01  -4.16015625e+00   3.57812500e+00  -1.83593750e+00
    4.41015625e+00  -1.45117188e+00   9.18457031e-01   2.25195312e+00
   -2.08203125e+00  -5.44140625e+00   6.02050781e-01   3.24804688e+00
    1.45605469e+00  -9.61914062e-01   2.66992188e+00   3.22265625e+00
    2.70703125e+00   2.18994141e-01  -4.19531250e+00  -1.40136719e+00
   -5.06835938e-01   3.37109375e+00  -3.29296875e+00  -8.93066406e-01
    3.11718750e+00   1.41845703e-01   1.51171875e+00  -5.75866699e-02
    4.05859375e+00  -6.47460938e-01   4.10937500e+00  -2.04882812e+00
    3.52539062e+00   3.31640625e+00   1.25000000e+00  -2.60546875e+00
    3.70312500e+00  -3.17138672e-01   3.91796875e+00   2.88867188e+00
    4.98046875e+00   3.23730469e-01   2.66015625e+00   3.24804688e+00
   -1.81054688e+00   6.18164062e-01  -6.01562500e-01   2.51367188e+00
   -5.84472656e-01  -1.62109375e+00   2.08618164e-01   6.07031250e+00
   -1.79882812e+00   4.73046875e+00  -1.73632812e+00  -1.65820312e+00
    6.93359375e-01   4.01367188e-01  -8.80859375e-01  -1.39843750e+00
    3.05078125e+00   1.16113281e+00   2.63281250e+00   2.30078125e+00
   -2.62207031e-01  -2.52929688e+00  -1.90527344e+00   3.33398438e+00
    2.66796875e+00  -2.65039062e+00   3.21777344e-01  -1.96875000e+00
   -4.24218750e+00   2.65039062e+00   9.92187500e-01  -2.59570312e+00
   -7.62207031e-01  -1.65234375e+00   2.77734375e+00  -3.34472656e-01
    5.44921875e-01  -3.16796875e+00  -2.37109375e+00  -3.34179688e+00
   -1.77832031e+00   5.94482422e-02   3.68750000e+00   1.92565918e-02
    2.89794922e-01   1.53320312e+00  -2.26757812e+00   2.15820312e+00
    3.03125000e+00   1.93164062e+00   5.59375000e+00  -4.22656250e+00
   -1.68750000e+00  -4.12109375e+00  -1.22265625e+00  -3.33496094e-01
   -1.31054688e+00   2.25781250e+00   1.57226562e+00  -3.39843750e+00
    1.90820312e+00  -5.42578125e+00  -1.01562500e+00  -9.21875000e-01
    1.24902344e+00  -4.21630859e-01  -6.85058594e-01  -5.56250000e+00
   -1.15429688e+00   3.28906250e+00  -3.24804688e+00   1.97509766e-01
    1.86914062e+00   8.26171875e-01  -6.59179688e-01   5.11328125e+00
    1.57617188e+00   3.63281250e+00  -6.68750000e+00  -1.25195312e+00
    3.10156250e+00  -1.33593750e+00   1.14355469e+00  -1.29296875e+00
   -3.03906250e+00   2.30859375e+00  -4.82421875e+00  -9.54589844e-02
   -3.61718750e+00  -2.02539062e+00   1.87255859e-01   2.07617188e+00]]
After layer activation1035_output (1, 256) <class 'numpy.float16'> [[ 0.95263672  0.828125   -0.94433594 -0.92236328  0.984375   -0.44555664
   0.99951172 -0.43798828 -0.70117188 -0.62646484  0.99560547  0.984375
   0.65478516 -0.99755859  0.20483398 -0.13220215  0.91308594  0.97509766
  -0.95410156  0.9609375  -0.46020508 -0.1932373  -0.99755859  0.90673828
  -0.75878906 -0.77539062 -0.99707031 -0.29296875 -0.99658203  0.96875
   0.99316406 -0.95019531  0.99316406 -0.92382812  1.          0.88427734
   0.83886719 -0.99707031 -1.         -0.03088379 -0.29443359  0.98144531
  -0.98144531  0.65185547 -0.97607422 -0.73632812  0.36206055  0.97802734
   0.90478516  0.47729492  0.14440918  0.18273926 -1.         -0.69824219
   0.99951172  0.53613281 -0.98535156 -0.62158203  0.97900391 -0.00408936
   0.84082031 -0.51416016  0.50878906  0.99951172 -0.8828125   0.41186523
   0.99511719  0.99902344  0.90917969 -0.99951172  0.53027344 -0.0345459
  -1.          0.96386719  0.91650391  1.          0.98486328 -1.
   0.99316406 -0.22363281  0.99951172 -0.76416016  0.10546875  0.76171875
  -0.99609375 -0.99511719  0.61425781 -1.          0.95507812 -0.06756592
   0.94433594  0.80712891 -0.59960938 -0.96630859 -0.29907227 -0.18127441
  -0.99853516 -0.99951172  0.99755859  0.92529297 -0.92089844 -0.07373047
  -0.52197266  0.99902344 -0.99414062 -0.94921875  0.89453125  0.9609375
   0.8671875   0.921875   -0.99902344 -0.99951172  1.          1.
  -0.93652344  0.99072266  0.98681641  0.97851562  0.86767578  0.46899414
   0.48486328 -0.99951172  0.99853516 -0.95019531  0.99951172 -0.89599609
   0.72509766  0.97802734 -0.96923828 -1.          0.53857422  0.99707031
   0.89697266 -0.74511719  0.99023438  0.99707031  0.99121094  0.21557617
  -0.99951172 -0.88574219 -0.4675293   0.99755859 -0.99707031 -0.71289062
   0.99609375  0.14086914  0.90722656 -0.05752563  0.99951172 -0.56982422
   0.99951172 -0.96728516  0.99804688  0.99755859  0.84814453 -0.98925781
   0.99902344 -0.30688477  0.99902344  0.99365234  1.          0.31298828
   0.99023438  0.99707031 -0.94775391  0.54980469 -0.53808594  0.98681641
  -0.52587891 -0.92480469  0.20568848  1.         -0.94677734  1.
  -0.93994141 -0.93017578  0.60009766  0.38110352 -0.70703125 -0.88525391
   0.99560547  0.82128906  0.98974609  0.97998047 -0.25634766 -0.98730469
  -0.95654297  0.99755859  0.99023438 -0.99023438  0.31103516 -0.96191406
  -0.99951172  0.99023438  0.75830078 -0.98876953 -0.64257812 -0.92919922
   0.9921875  -0.32250977  0.49682617 -0.99658203 -0.98291016 -0.99755859
  -0.94433594  0.05938721  0.99853516  0.01925659  0.28198242  0.91113281
  -0.97900391  0.97363281  0.99511719  0.95898438  1.         -0.99951172
  -0.93359375 -0.99951172 -0.84033203 -0.32177734 -0.86425781  0.97851562
   0.91748047 -0.99755859  0.95703125 -1.         -0.76806641 -0.7265625
   0.84814453 -0.39819336 -0.59472656 -1.         -0.81933594  0.99707031
  -0.99707031  0.19494629  0.95361328  0.67822266 -0.57763672  1.
   0.91796875  0.99853516 -1.         -0.84863281  0.99609375 -0.87060547
   0.81542969 -0.85986328 -0.99560547  0.98046875 -1.         -0.09515381
  -0.99853516 -0.96582031  0.18505859  0.96923828]]
After layer encoder_birnn_forward_l0_t9_out_0 (1, 256) <class 'numpy.float16'> [[ 0.91162109  0.70214844 -0.80371094 -0.83837891  0.84667969 -0.41186523
   0.98974609 -0.37329102 -0.62890625 -0.52929688  0.90185547  0.8671875
   0.56787109 -0.95117188  0.08679199 -0.08557129  0.80224609  0.76708984
  -0.94335938  0.87939453 -0.38037109 -0.0703125  -0.96728516  0.85058594
  -0.60498047 -0.64550781 -0.96484375 -0.26342773 -0.55761719  0.81933594
   0.95019531 -0.87207031  0.56689453 -0.75830078  0.83789062  0.69335938
   0.76367188 -0.71142578 -0.18164062 -0.02337646 -0.22961426  0.81640625
  -0.83105469  0.54003906 -0.83154297 -0.63671875  0.35668945  0.90039062
   0.75341797  0.29833984  0.04336548  0.1673584  -0.99951172 -0.27832031
   0.90234375  0.1842041  -0.78417969 -0.53710938  0.89501953 -0.00340271
   0.46264648 -0.3684082   0.29736328  0.96337891 -0.68310547  0.35644531
   0.93896484  0.79785156  0.80517578 -0.75927734  0.47753906 -0.03149414
  -0.98291016  0.85058594  0.74755859  0.99853516  0.86914062 -0.99804688
   0.94140625 -0.12451172  0.97265625 -0.30102539  0.10540771  0.64355469
  -0.94238281 -0.77880859  0.47802734 -0.89794922  0.94824219 -0.06335449
   0.77099609  0.72021484 -0.14501953 -0.921875   -0.17993164 -0.16162109
  -0.91894531 -0.93115234  0.90429688  0.90576172 -0.61474609 -0.05865479
  -0.36865234  0.97509766 -0.92333984 -0.63330078  0.79785156  0.88867188
   0.82421875  0.60693359 -0.96386719 -0.89013672  0.99267578  0.98583984
  -0.87597656  0.87353516  0.88671875  0.96435547  0.77246094  0.42651367
   0.39599609 -0.98388672  0.92675781 -0.79296875  0.92724609 -0.84082031
   0.34570312  0.67333984 -0.82373047 -0.99707031  0.48803711  0.97363281
   0.74414062 -0.65185547  0.72949219  0.77783203  0.93652344  0.16259766
  -0.95117188 -0.81787109 -0.37426758  0.89306641 -0.87060547 -0.65869141
   0.79150391  0.13342285  0.75927734 -0.04995728  0.58691406 -0.42041016
   0.99072266 -0.73095703  0.88427734  0.56152344  0.671875   -0.47924805
   0.76708984 -0.27392578  0.98486328  0.89746094  0.82470703  0.28808594
   0.57910156  0.94433594 -0.92529297  0.36645508 -0.48754883  0.63964844
  -0.17687988 -0.67773438  0.15087891  0.99951172 -0.84472656  0.97216797
  -0.57470703 -0.66455078  0.54052734  0.35253906 -0.53173828 -0.85205078
   0.84521484  0.37573242  0.91113281  0.89941406 -0.19287109 -0.88720703
  -0.84228516  0.74853516  0.90917969 -0.93212891  0.1217041  -0.83642578
  -0.98095703  0.78613281  0.51708984 -0.88183594 -0.64257812 -0.76123047
   0.85058594 -0.28881836  0.3581543  -0.69970703 -0.8984375  -0.95996094
  -0.86767578  0.05496216  0.95996094  0.01008606  0.06365967  0.81494141
  -0.91015625  0.70361328  0.96289062  0.89599609  0.99707031 -0.97607422
  -0.76513672 -0.97705078 -0.77832031 -0.23693848 -0.70605469  0.90332031
   0.41308594 -0.66064453  0.89404297 -0.80517578 -0.65869141 -0.64697266
   0.765625   -0.32250977 -0.46728516 -0.97705078 -0.74609375  0.87939453
  -0.93505859  0.16357422  0.60302734  0.3425293  -0.50048828  0.98974609
   0.57763672  0.95410156 -1.         -0.54931641  0.86279297 -0.5078125
   0.72607422 -0.78369141 -0.96484375  0.90576172 -0.95898438 -0.07104492
  -0.96972656 -0.90087891  0.15234375  0.87304688]]
After layer expand_dims1041_0 (1, 1, 256) <class 'numpy.float16'> [[[ 0.91162109  0.70214844 -0.80371094 -0.83837891  0.84667969 -0.41186523
    0.98974609 -0.37329102 -0.62890625 -0.52929688  0.90185547  0.8671875
    0.56787109 -0.95117188  0.08679199 -0.08557129  0.80224609  0.76708984
   -0.94335938  0.87939453 -0.38037109 -0.0703125  -0.96728516  0.85058594
   -0.60498047 -0.64550781 -0.96484375 -0.26342773 -0.55761719  0.81933594
    0.95019531 -0.87207031  0.56689453 -0.75830078  0.83789062  0.69335938
    0.76367188 -0.71142578 -0.18164062 -0.02337646 -0.22961426  0.81640625
   -0.83105469  0.54003906 -0.83154297 -0.63671875  0.35668945  0.90039062
    0.75341797  0.29833984  0.04336548  0.1673584  -0.99951172 -0.27832031
    0.90234375  0.1842041  -0.78417969 -0.53710938  0.89501953 -0.00340271
    0.46264648 -0.3684082   0.29736328  0.96337891 -0.68310547  0.35644531
    0.93896484  0.79785156  0.80517578 -0.75927734  0.47753906 -0.03149414
   -0.98291016  0.85058594  0.74755859  0.99853516  0.86914062 -0.99804688
    0.94140625 -0.12451172  0.97265625 -0.30102539  0.10540771  0.64355469
   -0.94238281 -0.77880859  0.47802734 -0.89794922  0.94824219 -0.06335449
    0.77099609  0.72021484 -0.14501953 -0.921875   -0.17993164 -0.16162109
   -0.91894531 -0.93115234  0.90429688  0.90576172 -0.61474609 -0.05865479
   -0.36865234  0.97509766 -0.92333984 -0.63330078  0.79785156  0.88867188
    0.82421875  0.60693359 -0.96386719 -0.89013672  0.99267578  0.98583984
   -0.87597656  0.87353516  0.88671875  0.96435547  0.77246094  0.42651367
    0.39599609 -0.98388672  0.92675781 -0.79296875  0.92724609 -0.84082031
    0.34570312  0.67333984 -0.82373047 -0.99707031  0.48803711  0.97363281
    0.74414062 -0.65185547  0.72949219  0.77783203  0.93652344  0.16259766
   -0.95117188 -0.81787109 -0.37426758  0.89306641 -0.87060547 -0.65869141
    0.79150391  0.13342285  0.75927734 -0.04995728  0.58691406 -0.42041016
    0.99072266 -0.73095703  0.88427734  0.56152344  0.671875   -0.47924805
    0.76708984 -0.27392578  0.98486328  0.89746094  0.82470703  0.28808594
    0.57910156  0.94433594 -0.92529297  0.36645508 -0.48754883  0.63964844
   -0.17687988 -0.67773438  0.15087891  0.99951172 -0.84472656  0.97216797
   -0.57470703 -0.66455078  0.54052734  0.35253906 -0.53173828 -0.85205078
    0.84521484  0.37573242  0.91113281  0.89941406 -0.19287109 -0.88720703
   -0.84228516  0.74853516  0.90917969 -0.93212891  0.1217041  -0.83642578
   -0.98095703  0.78613281  0.51708984 -0.88183594 -0.64257812 -0.76123047
    0.85058594 -0.28881836  0.3581543  -0.69970703 -0.8984375  -0.95996094
   -0.86767578  0.05496216  0.95996094  0.01008606  0.06365967  0.81494141
   -0.91015625  0.70361328  0.96289062  0.89599609  0.99707031 -0.97607422
   -0.76513672 -0.97705078 -0.77832031 -0.23693848 -0.70605469  0.90332031
    0.41308594 -0.66064453  0.89404297 -0.80517578 -0.65869141 -0.64697266
    0.765625   -0.32250977 -0.46728516 -0.97705078 -0.74609375  0.87939453
   -0.93505859  0.16357422  0.60302734  0.3425293  -0.50048828  0.98974609
    0.57763672  0.95410156 -1.         -0.54931641  0.86279297 -0.5078125
    0.72607422 -0.78369141 -0.96484375  0.90576172 -0.95898438 -0.07104492
   -0.96972656 -0.90087891  0.15234375  0.87304688]]]
After layer concat4_output (10, 1, 256) <class 'numpy.float16'> [[[  3.44657898e-03   2.28118896e-02  -6.56890869e-03 ...,  -2.98614502e-02
     1.76086426e-02   2.84433365e-04]]

 [[  2.75878906e-02   5.06896973e-02  -5.15441895e-02 ...,  -4.17785645e-02
     6.65664673e-03   5.03234863e-02]]

 [[  4.40368652e-02   7.92236328e-02  -1.12670898e-01 ...,  -9.00878906e-02
     1.31530762e-02   8.59375000e-02]]

 ...,
 [[  6.63574219e-01   5.45898438e-01  -6.80175781e-01 ...,  -7.78808594e-01
    -2.03552246e-02   6.95312500e-01]]

 [[  8.23730469e-01   6.33300781e-01  -7.52929688e-01 ...,  -8.56933594e-01
     4.87365723e-02   8.10058594e-01]]

 [[  9.11621094e-01   7.02148438e-01  -8.03710938e-01 ...,  -9.00878906e-01
     1.52343750e-01   8.73046875e-01]]]
After layer _zeros2_0 (1,) <class 'numpy.int32'> [0]
After layer broadcast_not_equal2_0 (1, 10) <class 'numpy.int32'> [[1 1 0 0 0 0 0 0 0 0]]
After layer sum2_0 (1,) <class 'numpy.int32'> [2]
After layer cast2_0 (1,) <class 'numpy.float16'> [ 2.]
After layer sequencereverse4_output (10, 1, 256) <class 'numpy.float16'> [[[-0.06872559 -0.00477982 -0.00354767 ..., -0.06140137 -0.04299927
    0.03726196]]

 [[-0.00175095 -0.0164032  -0.0703125  ...,  0.00574493 -0.01233673
    0.0269928 ]]

 [[ 0.06011963  0.00928497  0.03005981 ...,  0.06628418  0.02203369
   -0.06420898]]

 ...,
 [[ 0.06011963  0.00928497  0.03005981 ...,  0.06628418  0.02203369
   -0.06420898]]

 [[ 0.06011963  0.00928497  0.03005981 ...,  0.06628418  0.02203369
   -0.06420898]]

 [[ 0.06011963  0.00928497  0.03005981 ...,  0.06628418  0.02203369
   -0.06420898]]]
After layer split5_output0 (1, 256) <class 'numpy.float16'> [[-0.06872559 -0.00477982 -0.00354767 -0.01820374 -0.01612854  0.08428955
  -0.06951904  0.00264549 -0.06427002  0.05566406  0.03616333  0.06744385
   0.01268768  0.02503967 -0.00322533  0.00941467 -0.03817749 -0.01480103
  -0.06390381 -0.00082541 -0.04299927  0.05258179 -0.03115845 -0.04760742
  -0.01341248  0.00824738 -0.03616333  0.05459595 -0.00548172 -0.08770752
  -0.0380249   0.02459717 -0.05517578 -0.06402588  0.06884766  0.07977295
   0.03912354  0.04818726  0.09075928  0.02204895 -0.09381104 -0.05026245
  -0.06982422  0.02409363 -0.0067482  -0.00616837 -0.02383423  0.05352783
   0.08691406 -0.06396484  0.04638672  0.08349609 -0.03488159 -0.09228516
   0.08404541  0.07086182 -0.04742432  0.02374268 -0.08935547  0.07965088
  -0.07897949  0.03561401  0.06286621  0.06707764  0.015625   -0.04220581
  -0.03765869 -0.01841736  0.00150776 -0.01802063 -0.09423828  0.07720947
   0.03140259 -0.0836792  -0.0725708  -0.04382324  0.00515366 -0.00694656
  -0.05938721  0.03411865  0.09222412  0.04168701  0.03198242 -0.00574875
   0.02363586  0.07275391 -0.0791626   0.0692749  -0.04470825 -0.06378174
   0.07495117 -0.0425415   0.09332275  0.08538818 -0.06231689  0.05157471
   0.04559326 -0.07385254 -0.03271484 -0.040802   -0.05093384  0.03372192
   0.0453186   0.01898193  0.02832031  0.02198792 -0.05975342  0.02789307
  -0.06890869  0.07781982 -0.0451355   0.06726074  0.01552582  0.02284241
   0.0793457   0.09033203  0.05105591  0.06140137  0.00379372  0.02333069
   0.078125    0.01802063  0.04208374  0.05169678  0.08758545 -0.04968262
   0.06512451  0.0064621   0.02359009  0.01506805 -0.03088379  0.0725708
   0.00184059  0.07592773  0.04055786  0.07019043  0.01560211  0.06787109
  -0.00635147  0.01701355 -0.00484848 -0.06152344  0.08978271  0.06109619
  -0.08135986  0.07098389 -0.08624268  0.07788086 -0.02548218 -0.02539062
  -0.04089355 -0.03823853  0.07440186  0.04370117 -0.01373291  0.02972412
   0.03491211 -0.03488159  0.07348633  0.02772522 -0.07122803  0.04489136
   0.03134155  0.06896973  0.00819397 -0.05523682 -0.03001404 -0.08703613
   0.08984375 -0.02163696  0.07391357  0.08508301 -0.06445312 -0.05703735
  -0.01725769  0.02288818  0.09173584  0.0064621   0.05944824  0.07824707
  -0.03109741 -0.05822754 -0.04455566 -0.07830811 -0.03317261 -0.07208252
  -0.04022217  0.0355835   0.06433105 -0.06378174 -0.0163269   0.03146362
  -0.04788208 -0.08764648 -0.06896973  0.06286621 -0.09527588 -0.08459473
  -0.05029297 -0.09246826  0.03024292 -0.03356934  0.05667114 -0.00226593
   0.08392334  0.02262878 -0.0247345  -0.0089798   0.05606079 -0.07501221
  -0.04611206 -0.04418945  0.05441284  0.00803375  0.09259033 -0.03710938
  -0.08795166 -0.04641724  0.01368713  0.02748108  0.03753662  0.06182861
  -0.07946777 -0.02145386 -0.02024841  0.03305054 -0.00712204  0.07513428
  -0.07617188 -0.00623322 -0.02082825 -0.00763702 -0.03875732 -0.00661469
  -0.03726196 -0.07226562  0.08209229  0.00625992  0.04260254  0.09307861
  -0.07598877  0.05856323 -0.05401611  0.09051514 -0.02059937  0.02522278
  -0.07348633 -0.07568359  0.03039551 -0.06561279  0.02690125  0.06768799
   0.07397461 -0.06140137 -0.04299927  0.03726196]]
After layer split5_output1 (1, 256) <class 'numpy.float16'> [[ -1.75094604e-03  -1.64031982e-02  -7.03125000e-02   3.06243896e-02
   -5.19409180e-02  -2.61383057e-02  -1.62506104e-02  -4.49218750e-02
   -7.18593597e-04   2.31018066e-02   5.72814941e-02  -7.00073242e-02
    8.66088867e-02  -6.09436035e-02   4.63867188e-02  -8.91723633e-02
   -3.99169922e-02   4.47692871e-02   6.22863770e-02   3.35388184e-02
    4.08935547e-02  -1.47018433e-02  -5.96618652e-02  -4.84924316e-02
   -1.29013062e-02   4.08325195e-02  -7.45239258e-02  -4.81262207e-02
    1.84936523e-02   6.60400391e-02  -8.18634033e-03  -8.49609375e-02
    7.13500977e-02   2.64892578e-02  -5.14221191e-02   8.77685547e-02
   -3.56292725e-03   4.24804688e-02   4.79507446e-03   8.68530273e-02
    5.55419922e-02  -5.71899414e-02  -6.66379929e-05  -5.02014160e-02
   -6.50024414e-02  -7.35473633e-02  -6.50024414e-02   6.91604614e-03
   -4.83703613e-02   3.69567871e-02   3.84826660e-02  -8.99658203e-02
   -7.94677734e-02  -2.89154053e-02   1.76086426e-02  -2.56958008e-02
   -8.03222656e-02  -8.96930695e-04  -2.29644775e-02   6.87255859e-02
    7.87353516e-02   8.48388672e-02  -8.77075195e-02   3.80859375e-02
    4.70275879e-02   1.64794922e-02   4.80041504e-02   5.49621582e-02
    1.05895996e-02   3.70483398e-02  -2.94036865e-02   1.57165527e-02
    8.14056396e-03   2.80456543e-02  -9.49707031e-02   4.28161621e-02
   -3.33557129e-02   3.94287109e-02   2.30865479e-02  -6.39343262e-03
    6.87789917e-03  -6.32324219e-02   4.43115234e-02   5.30700684e-02
    7.01293945e-02   9.04541016e-02   5.86853027e-02  -2.09197998e-02
   -5.39245605e-02  -9.89913940e-04  -1.98669434e-02  -4.91638184e-02
    8.55712891e-02  -7.08007812e-02   4.53186035e-02   2.46276855e-02
   -3.30505371e-02   6.35375977e-02   9.27734375e-02   6.46972656e-02
    4.85534668e-02   2.13165283e-02  -7.03735352e-02   3.72314453e-02
   -9.88769531e-03  -5.31921387e-02  -3.93390656e-05   6.41479492e-02
    2.13012695e-02  -9.07592773e-02   7.87963867e-02  -9.22851562e-02
   -1.34811401e-02   9.36889648e-02  -4.03747559e-02   3.54919434e-02
    2.44140625e-02   3.03497314e-02  -9.39941406e-02  -3.61633301e-02
   -7.84301758e-02  -6.00433350e-03  -8.94775391e-02  -7.80029297e-02
    6.12792969e-02   6.24084473e-02  -5.09948730e-02   7.50732422e-02
   -1.14898682e-02   5.39855957e-02   1.90429688e-02  -1.08413696e-02
    1.87683105e-02   5.22155762e-02   3.15246582e-02  -6.48193359e-02
    8.28857422e-02  -9.52148438e-02  -2.36511230e-02  -6.02111816e-02
    6.54296875e-02   2.20794678e-02   5.34362793e-02   9.44824219e-02
    4.73937988e-02   6.45141602e-02  -5.77697754e-02   2.14233398e-02
   -2.18963623e-02   6.32934570e-02   3.09143066e-02  -6.65283203e-02
   -2.84881592e-02   7.99560547e-02  -2.42004395e-02  -9.03320312e-02
   -4.91027832e-02  -4.82788086e-02  -5.17272949e-02  -8.64257812e-02
   -7.20596313e-03  -3.64685059e-02  -7.72857666e-03  -1.00860596e-02
   -9.68170166e-03  -7.68432617e-02   8.88671875e-02  -4.43420410e-02
   -3.70788574e-02   1.91192627e-02  -2.69317627e-02  -7.25708008e-02
   -1.19781494e-03   5.15747070e-02  -9.18579102e-02   2.07977295e-02
    3.40576172e-02  -7.94677734e-02   3.50952148e-02   7.12890625e-02
   -3.65295410e-02   8.11157227e-02   5.85937500e-02  -1.91040039e-02
    7.52639771e-03  -5.55725098e-02   6.59561157e-03   8.09936523e-02
    1.13449097e-02   3.52783203e-02  -2.69622803e-02  -7.88574219e-02
    9.19342041e-03   4.10461426e-02  -1.50489807e-03   6.55746460e-03
    1.35345459e-02  -9.20410156e-02   1.93328857e-02  -8.72802734e-02
    7.85522461e-02  -7.56835938e-02  -3.75671387e-02   7.18383789e-02
   -6.65283203e-02  -1.42364502e-02  -4.59289551e-03  -2.31323242e-02
   -7.43865967e-03   1.91879272e-03  -2.13165283e-02   9.43756104e-03
    9.24072266e-02   3.81774902e-02  -1.27105713e-02   5.32836914e-02
    3.09906006e-02  -5.84716797e-02   5.46569824e-02   6.27441406e-02
   -2.81066895e-02  -8.21533203e-02   7.26928711e-02  -1.46560669e-02
   -7.08618164e-02  -6.82373047e-02   6.75659180e-02  -7.94677734e-02
    5.14831543e-02   1.47018433e-02   6.58569336e-02  -7.11059570e-02
   -4.29687500e-02   4.22973633e-02  -1.16195679e-02   6.43310547e-02
    6.09130859e-02  -6.90078735e-03  -6.05163574e-02   2.84881592e-02
   -6.09130859e-02  -6.51855469e-02  -3.97949219e-02   3.13415527e-02
    2.64892578e-02   1.49688721e-02  -3.68118286e-03  -5.97534180e-02
    4.87518311e-03  -9.42993164e-02   4.44335938e-02  -8.22143555e-02
    3.35083008e-02   5.74493408e-03  -1.23367310e-02   2.69927979e-02]]
After layer split5_output2 (1, 256) <class 'numpy.float16'> [[ 0.06011963  0.00928497  0.03005981 -0.03009033 -0.03494263  0.00979614
   0.04443359  0.0892334  -0.0647583   0.06057739 -0.03366089 -0.0413208
   0.05426025  0.00199127 -0.04977417 -0.01615906  0.02236938  0.04937744
  -0.07427979  0.01543427  0.03674316 -0.07714844  0.00384521  0.04898071
   0.04669189  0.0435791   0.05166626 -0.03117371  0.00643921 -0.0916748
  -0.06555176  0.04605103  0.03308105 -0.02362061 -0.05386353  0.05136108
  -0.05328369  0.00138664  0.0087204   0.0222168  -0.08197021  0.01593018
  -0.09448242 -0.01968384 -0.05157471 -0.02156067  0.09191895 -0.0456543
  -0.01366425  0.02568054  0.05508423 -0.06210327 -0.06109619  0.09179688
   0.034729    0.00032783  0.08184814 -0.00460052 -0.06396484 -0.07873535
  -0.07684326  0.03585815  0.03106689 -0.02568054 -0.09423828  0.09216309
   0.05581665 -0.07940674 -0.00190926  0.01980591 -0.01357269 -0.07611084
  -0.03887939 -0.06494141 -0.03253174  0.00991821  0.06130981  0.06057739
  -0.02391052 -0.05252075  0.05300903 -0.06097412  0.06945801  0.03237915
   0.07281494 -0.03497314  0.01681519 -0.01838684  0.03123474  0.05499268
   0.03588867 -0.06677246  0.01105499  0.08728027  0.07897949 -0.04669189
   0.01126862  0.08270264  0.07562256 -0.08111572 -0.07165527  0.0562439
   0.09436035  0.03012085  0.07299805  0.05389404 -0.06439209  0.03515625
   0.09405518  0.03613281 -0.04663086 -0.00576401 -0.03102112  0.0838623
  -0.04074097 -0.05682373 -0.0304718  -0.04257202  0.06616211  0.08886719
  -0.08056641 -0.00977325  0.0760498  -0.06884766 -0.05273438  0.04104614
   0.0186615   0.05349731 -0.05892944  0.05801392  0.07830811  0.00614548
  -0.06091309  0.04446411  0.00978851  0.00144386 -0.07788086  0.08276367
   0.07202148  0.08605957 -0.04882812  0.00289917  0.03555298  0.07757568
  -0.07965088  0.03540039 -0.0254364  -0.05508423  0.05841064 -0.03363037
   0.07727051  0.02099609  0.07696533 -0.0352478  -0.06634521 -0.01145172
  -0.05770874  0.02613831  0.06896973  0.02345276 -0.03134155 -0.03076172
  -0.0869751  -0.05670166 -0.04318237  0.01870728  0.06878662  0.08166504
   0.05862427  0.06976318  0.01977539 -0.0680542   0.07312012  0.04721069
   0.04644775  0.06045532 -0.07788086 -0.02279663  0.00743866  0.01916504
   0.05877686 -0.05581665  0.02497864  0.08215332 -0.04962158 -0.04550171
  -0.07220459  0.02761841 -0.00298882 -0.01675415  0.06939697 -0.08612061
   0.09387207  0.06481934  0.00206184  0.08013916 -0.00548172  0.01785278
   0.04898071 -0.06671143 -0.00177479 -0.04730225  0.02372742  0.05212402
  -0.06420898 -0.0300293  -0.04797363 -0.05340576 -0.06292725 -0.07714844
   0.0657959  -0.03717041 -0.0149765   0.06335449 -0.04147339 -0.05319214
   0.00527573  0.01927185  0.01180267  0.0838623   0.00623322 -0.00313187
   0.09326172  0.03146362  0.00914001  0.09161377  0.06488037 -0.06155396
   0.02760315 -0.06207275 -0.06124878 -0.01649475  0.06549072 -0.01605225
  -0.0793457  -0.02545166 -0.08441162 -0.04592896 -0.06707764  0.06787109
  -0.00608063  0.02279663 -0.0328064   0.04278564 -0.05740356 -0.04873657
   0.06732178 -0.05264282 -0.06866455  0.07745361 -0.03759766 -0.0319519
  -0.05053711  0.06628418  0.02203369 -0.06420898]]
After layer split5_output3 (1, 256) <class 'numpy.float16'> [[ 0.06011963  0.00928497  0.03005981 -0.03009033 -0.03494263  0.00979614
   0.04443359  0.0892334  -0.0647583   0.06057739 -0.03366089 -0.0413208
   0.05426025  0.00199127 -0.04977417 -0.01615906  0.02236938  0.04937744
  -0.07427979  0.01543427  0.03674316 -0.07714844  0.00384521  0.04898071
   0.04669189  0.0435791   0.05166626 -0.03117371  0.00643921 -0.0916748
  -0.06555176  0.04605103  0.03308105 -0.02362061 -0.05386353  0.05136108
  -0.05328369  0.00138664  0.0087204   0.0222168  -0.08197021  0.01593018
  -0.09448242 -0.01968384 -0.05157471 -0.02156067  0.09191895 -0.0456543
  -0.01366425  0.02568054  0.05508423 -0.06210327 -0.06109619  0.09179688
   0.034729    0.00032783  0.08184814 -0.00460052 -0.06396484 -0.07873535
  -0.07684326  0.03585815  0.03106689 -0.02568054 -0.09423828  0.09216309
   0.05581665 -0.07940674 -0.00190926  0.01980591 -0.01357269 -0.07611084
  -0.03887939 -0.06494141 -0.03253174  0.00991821  0.06130981  0.06057739
  -0.02391052 -0.05252075  0.05300903 -0.06097412  0.06945801  0.03237915
   0.07281494 -0.03497314  0.01681519 -0.01838684  0.03123474  0.05499268
   0.03588867 -0.06677246  0.01105499  0.08728027  0.07897949 -0.04669189
   0.01126862  0.08270264  0.07562256 -0.08111572 -0.07165527  0.0562439
   0.09436035  0.03012085  0.07299805  0.05389404 -0.06439209  0.03515625
   0.09405518  0.03613281 -0.04663086 -0.00576401 -0.03102112  0.0838623
  -0.04074097 -0.05682373 -0.0304718  -0.04257202  0.06616211  0.08886719
  -0.08056641 -0.00977325  0.0760498  -0.06884766 -0.05273438  0.04104614
   0.0186615   0.05349731 -0.05892944  0.05801392  0.07830811  0.00614548
  -0.06091309  0.04446411  0.00978851  0.00144386 -0.07788086  0.08276367
   0.07202148  0.08605957 -0.04882812  0.00289917  0.03555298  0.07757568
  -0.07965088  0.03540039 -0.0254364  -0.05508423  0.05841064 -0.03363037
   0.07727051  0.02099609  0.07696533 -0.0352478  -0.06634521 -0.01145172
  -0.05770874  0.02613831  0.06896973  0.02345276 -0.03134155 -0.03076172
  -0.0869751  -0.05670166 -0.04318237  0.01870728  0.06878662  0.08166504
   0.05862427  0.06976318  0.01977539 -0.0680542   0.07312012  0.04721069
   0.04644775  0.06045532 -0.07788086 -0.02279663  0.00743866  0.01916504
   0.05877686 -0.05581665  0.02497864  0.08215332 -0.04962158 -0.04550171
  -0.07220459  0.02761841 -0.00298882 -0.01675415  0.06939697 -0.08612061
   0.09387207  0.06481934  0.00206184  0.08013916 -0.00548172  0.01785278
   0.04898071 -0.06671143 -0.00177479 -0.04730225  0.02372742  0.05212402
  -0.06420898 -0.0300293  -0.04797363 -0.05340576 -0.06292725 -0.07714844
   0.0657959  -0.03717041 -0.0149765   0.06335449 -0.04147339 -0.05319214
   0.00527573  0.01927185  0.01180267  0.0838623   0.00623322 -0.00313187
   0.09326172  0.03146362  0.00914001  0.09161377  0.06488037 -0.06155396
   0.02760315 -0.06207275 -0.06124878 -0.01649475  0.06549072 -0.01605225
  -0.0793457  -0.02545166 -0.08441162 -0.04592896 -0.06707764  0.06787109
  -0.00608063  0.02279663 -0.0328064   0.04278564 -0.05740356 -0.04873657
   0.06732178 -0.05264282 -0.06866455  0.07745361 -0.03759766 -0.0319519
  -0.05053711  0.06628418  0.02203369 -0.06420898]]
After layer split5_output4 (1, 256) <class 'numpy.float16'> [[ 0.06011963  0.00928497  0.03005981 -0.03009033 -0.03494263  0.00979614
   0.04443359  0.0892334  -0.0647583   0.06057739 -0.03366089 -0.0413208
   0.05426025  0.00199127 -0.04977417 -0.01615906  0.02236938  0.04937744
  -0.07427979  0.01543427  0.03674316 -0.07714844  0.00384521  0.04898071
   0.04669189  0.0435791   0.05166626 -0.03117371  0.00643921 -0.0916748
  -0.06555176  0.04605103  0.03308105 -0.02362061 -0.05386353  0.05136108
  -0.05328369  0.00138664  0.0087204   0.0222168  -0.08197021  0.01593018
  -0.09448242 -0.01968384 -0.05157471 -0.02156067  0.09191895 -0.0456543
  -0.01366425  0.02568054  0.05508423 -0.06210327 -0.06109619  0.09179688
   0.034729    0.00032783  0.08184814 -0.00460052 -0.06396484 -0.07873535
  -0.07684326  0.03585815  0.03106689 -0.02568054 -0.09423828  0.09216309
   0.05581665 -0.07940674 -0.00190926  0.01980591 -0.01357269 -0.07611084
  -0.03887939 -0.06494141 -0.03253174  0.00991821  0.06130981  0.06057739
  -0.02391052 -0.05252075  0.05300903 -0.06097412  0.06945801  0.03237915
   0.07281494 -0.03497314  0.01681519 -0.01838684  0.03123474  0.05499268
   0.03588867 -0.06677246  0.01105499  0.08728027  0.07897949 -0.04669189
   0.01126862  0.08270264  0.07562256 -0.08111572 -0.07165527  0.0562439
   0.09436035  0.03012085  0.07299805  0.05389404 -0.06439209  0.03515625
   0.09405518  0.03613281 -0.04663086 -0.00576401 -0.03102112  0.0838623
  -0.04074097 -0.05682373 -0.0304718  -0.04257202  0.06616211  0.08886719
  -0.08056641 -0.00977325  0.0760498  -0.06884766 -0.05273438  0.04104614
   0.0186615   0.05349731 -0.05892944  0.05801392  0.07830811  0.00614548
  -0.06091309  0.04446411  0.00978851  0.00144386 -0.07788086  0.08276367
   0.07202148  0.08605957 -0.04882812  0.00289917  0.03555298  0.07757568
  -0.07965088  0.03540039 -0.0254364  -0.05508423  0.05841064 -0.03363037
   0.07727051  0.02099609  0.07696533 -0.0352478  -0.06634521 -0.01145172
  -0.05770874  0.02613831  0.06896973  0.02345276 -0.03134155 -0.03076172
  -0.0869751  -0.05670166 -0.04318237  0.01870728  0.06878662  0.08166504
   0.05862427  0.06976318  0.01977539 -0.0680542   0.07312012  0.04721069
   0.04644775  0.06045532 -0.07788086 -0.02279663  0.00743866  0.01916504
   0.05877686 -0.05581665  0.02497864  0.08215332 -0.04962158 -0.04550171
  -0.07220459  0.02761841 -0.00298882 -0.01675415  0.06939697 -0.08612061
   0.09387207  0.06481934  0.00206184  0.08013916 -0.00548172  0.01785278
   0.04898071 -0.06671143 -0.00177479 -0.04730225  0.02372742  0.05212402
  -0.06420898 -0.0300293  -0.04797363 -0.05340576 -0.06292725 -0.07714844
   0.0657959  -0.03717041 -0.0149765   0.06335449 -0.04147339 -0.05319214
   0.00527573  0.01927185  0.01180267  0.0838623   0.00623322 -0.00313187
   0.09326172  0.03146362  0.00914001  0.09161377  0.06488037 -0.06155396
   0.02760315 -0.06207275 -0.06124878 -0.01649475  0.06549072 -0.01605225
  -0.0793457  -0.02545166 -0.08441162 -0.04592896 -0.06707764  0.06787109
  -0.00608063  0.02279663 -0.0328064   0.04278564 -0.05740356 -0.04873657
   0.06732178 -0.05264282 -0.06866455  0.07745361 -0.03759766 -0.0319519
  -0.05053711  0.06628418  0.02203369 -0.06420898]]
After layer split5_output5 (1, 256) <class 'numpy.float16'> [[ 0.06011963  0.00928497  0.03005981 -0.03009033 -0.03494263  0.00979614
   0.04443359  0.0892334  -0.0647583   0.06057739 -0.03366089 -0.0413208
   0.05426025  0.00199127 -0.04977417 -0.01615906  0.02236938  0.04937744
  -0.07427979  0.01543427  0.03674316 -0.07714844  0.00384521  0.04898071
   0.04669189  0.0435791   0.05166626 -0.03117371  0.00643921 -0.0916748
  -0.06555176  0.04605103  0.03308105 -0.02362061 -0.05386353  0.05136108
  -0.05328369  0.00138664  0.0087204   0.0222168  -0.08197021  0.01593018
  -0.09448242 -0.01968384 -0.05157471 -0.02156067  0.09191895 -0.0456543
  -0.01366425  0.02568054  0.05508423 -0.06210327 -0.06109619  0.09179688
   0.034729    0.00032783  0.08184814 -0.00460052 -0.06396484 -0.07873535
  -0.07684326  0.03585815  0.03106689 -0.02568054 -0.09423828  0.09216309
   0.05581665 -0.07940674 -0.00190926  0.01980591 -0.01357269 -0.07611084
  -0.03887939 -0.06494141 -0.03253174  0.00991821  0.06130981  0.06057739
  -0.02391052 -0.05252075  0.05300903 -0.06097412  0.06945801  0.03237915
   0.07281494 -0.03497314  0.01681519 -0.01838684  0.03123474  0.05499268
   0.03588867 -0.06677246  0.01105499  0.08728027  0.07897949 -0.04669189
   0.01126862  0.08270264  0.07562256 -0.08111572 -0.07165527  0.0562439
   0.09436035  0.03012085  0.07299805  0.05389404 -0.06439209  0.03515625
   0.09405518  0.03613281 -0.04663086 -0.00576401 -0.03102112  0.0838623
  -0.04074097 -0.05682373 -0.0304718  -0.04257202  0.06616211  0.08886719
  -0.08056641 -0.00977325  0.0760498  -0.06884766 -0.05273438  0.04104614
   0.0186615   0.05349731 -0.05892944  0.05801392  0.07830811  0.00614548
  -0.06091309  0.04446411  0.00978851  0.00144386 -0.07788086  0.08276367
   0.07202148  0.08605957 -0.04882812  0.00289917  0.03555298  0.07757568
  -0.07965088  0.03540039 -0.0254364  -0.05508423  0.05841064 -0.03363037
   0.07727051  0.02099609  0.07696533 -0.0352478  -0.06634521 -0.01145172
  -0.05770874  0.02613831  0.06896973  0.02345276 -0.03134155 -0.03076172
  -0.0869751  -0.05670166 -0.04318237  0.01870728  0.06878662  0.08166504
   0.05862427  0.06976318  0.01977539 -0.0680542   0.07312012  0.04721069
   0.04644775  0.06045532 -0.07788086 -0.02279663  0.00743866  0.01916504
   0.05877686 -0.05581665  0.02497864  0.08215332 -0.04962158 -0.04550171
  -0.07220459  0.02761841 -0.00298882 -0.01675415  0.06939697 -0.08612061
   0.09387207  0.06481934  0.00206184  0.08013916 -0.00548172  0.01785278
   0.04898071 -0.06671143 -0.00177479 -0.04730225  0.02372742  0.05212402
  -0.06420898 -0.0300293  -0.04797363 -0.05340576 -0.06292725 -0.07714844
   0.0657959  -0.03717041 -0.0149765   0.06335449 -0.04147339 -0.05319214
   0.00527573  0.01927185  0.01180267  0.0838623   0.00623322 -0.00313187
   0.09326172  0.03146362  0.00914001  0.09161377  0.06488037 -0.06155396
   0.02760315 -0.06207275 -0.06124878 -0.01649475  0.06549072 -0.01605225
  -0.0793457  -0.02545166 -0.08441162 -0.04592896 -0.06707764  0.06787109
  -0.00608063  0.02279663 -0.0328064   0.04278564 -0.05740356 -0.04873657
   0.06732178 -0.05264282 -0.06866455  0.07745361 -0.03759766 -0.0319519
  -0.05053711  0.06628418  0.02203369 -0.06420898]]
After layer split5_output6 (1, 256) <class 'numpy.float16'> [[ 0.06011963  0.00928497  0.03005981 -0.03009033 -0.03494263  0.00979614
   0.04443359  0.0892334  -0.0647583   0.06057739 -0.03366089 -0.0413208
   0.05426025  0.00199127 -0.04977417 -0.01615906  0.02236938  0.04937744
  -0.07427979  0.01543427  0.03674316 -0.07714844  0.00384521  0.04898071
   0.04669189  0.0435791   0.05166626 -0.03117371  0.00643921 -0.0916748
  -0.06555176  0.04605103  0.03308105 -0.02362061 -0.05386353  0.05136108
  -0.05328369  0.00138664  0.0087204   0.0222168  -0.08197021  0.01593018
  -0.09448242 -0.01968384 -0.05157471 -0.02156067  0.09191895 -0.0456543
  -0.01366425  0.02568054  0.05508423 -0.06210327 -0.06109619  0.09179688
   0.034729    0.00032783  0.08184814 -0.00460052 -0.06396484 -0.07873535
  -0.07684326  0.03585815  0.03106689 -0.02568054 -0.09423828  0.09216309
   0.05581665 -0.07940674 -0.00190926  0.01980591 -0.01357269 -0.07611084
  -0.03887939 -0.06494141 -0.03253174  0.00991821  0.06130981  0.06057739
  -0.02391052 -0.05252075  0.05300903 -0.06097412  0.06945801  0.03237915
   0.07281494 -0.03497314  0.01681519 -0.01838684  0.03123474  0.05499268
   0.03588867 -0.06677246  0.01105499  0.08728027  0.07897949 -0.04669189
   0.01126862  0.08270264  0.07562256 -0.08111572 -0.07165527  0.0562439
   0.09436035  0.03012085  0.07299805  0.05389404 -0.06439209  0.03515625
   0.09405518  0.03613281 -0.04663086 -0.00576401 -0.03102112  0.0838623
  -0.04074097 -0.05682373 -0.0304718  -0.04257202  0.06616211  0.08886719
  -0.08056641 -0.00977325  0.0760498  -0.06884766 -0.05273438  0.04104614
   0.0186615   0.05349731 -0.05892944  0.05801392  0.07830811  0.00614548
  -0.06091309  0.04446411  0.00978851  0.00144386 -0.07788086  0.08276367
   0.07202148  0.08605957 -0.04882812  0.00289917  0.03555298  0.07757568
  -0.07965088  0.03540039 -0.0254364  -0.05508423  0.05841064 -0.03363037
   0.07727051  0.02099609  0.07696533 -0.0352478  -0.06634521 -0.01145172
  -0.05770874  0.02613831  0.06896973  0.02345276 -0.03134155 -0.03076172
  -0.0869751  -0.05670166 -0.04318237  0.01870728  0.06878662  0.08166504
   0.05862427  0.06976318  0.01977539 -0.0680542   0.07312012  0.04721069
   0.04644775  0.06045532 -0.07788086 -0.02279663  0.00743866  0.01916504
   0.05877686 -0.05581665  0.02497864  0.08215332 -0.04962158 -0.04550171
  -0.07220459  0.02761841 -0.00298882 -0.01675415  0.06939697 -0.08612061
   0.09387207  0.06481934  0.00206184  0.08013916 -0.00548172  0.01785278
   0.04898071 -0.06671143 -0.00177479 -0.04730225  0.02372742  0.05212402
  -0.06420898 -0.0300293  -0.04797363 -0.05340576 -0.06292725 -0.07714844
   0.0657959  -0.03717041 -0.0149765   0.06335449 -0.04147339 -0.05319214
   0.00527573  0.01927185  0.01180267  0.0838623   0.00623322 -0.00313187
   0.09326172  0.03146362  0.00914001  0.09161377  0.06488037 -0.06155396
   0.02760315 -0.06207275 -0.06124878 -0.01649475  0.06549072 -0.01605225
  -0.0793457  -0.02545166 -0.08441162 -0.04592896 -0.06707764  0.06787109
  -0.00608063  0.02279663 -0.0328064   0.04278564 -0.05740356 -0.04873657
   0.06732178 -0.05264282 -0.06866455  0.07745361 -0.03759766 -0.0319519
  -0.05053711  0.06628418  0.02203369 -0.06420898]]
After layer split5_output7 (1, 256) <class 'numpy.float16'> [[ 0.06011963  0.00928497  0.03005981 -0.03009033 -0.03494263  0.00979614
   0.04443359  0.0892334  -0.0647583   0.06057739 -0.03366089 -0.0413208
   0.05426025  0.00199127 -0.04977417 -0.01615906  0.02236938  0.04937744
  -0.07427979  0.01543427  0.03674316 -0.07714844  0.00384521  0.04898071
   0.04669189  0.0435791   0.05166626 -0.03117371  0.00643921 -0.0916748
  -0.06555176  0.04605103  0.03308105 -0.02362061 -0.05386353  0.05136108
  -0.05328369  0.00138664  0.0087204   0.0222168  -0.08197021  0.01593018
  -0.09448242 -0.01968384 -0.05157471 -0.02156067  0.09191895 -0.0456543
  -0.01366425  0.02568054  0.05508423 -0.06210327 -0.06109619  0.09179688
   0.034729    0.00032783  0.08184814 -0.00460052 -0.06396484 -0.07873535
  -0.07684326  0.03585815  0.03106689 -0.02568054 -0.09423828  0.09216309
   0.05581665 -0.07940674 -0.00190926  0.01980591 -0.01357269 -0.07611084
  -0.03887939 -0.06494141 -0.03253174  0.00991821  0.06130981  0.06057739
  -0.02391052 -0.05252075  0.05300903 -0.06097412  0.06945801  0.03237915
   0.07281494 -0.03497314  0.01681519 -0.01838684  0.03123474  0.05499268
   0.03588867 -0.06677246  0.01105499  0.08728027  0.07897949 -0.04669189
   0.01126862  0.08270264  0.07562256 -0.08111572 -0.07165527  0.0562439
   0.09436035  0.03012085  0.07299805  0.05389404 -0.06439209  0.03515625
   0.09405518  0.03613281 -0.04663086 -0.00576401 -0.03102112  0.0838623
  -0.04074097 -0.05682373 -0.0304718  -0.04257202  0.06616211  0.08886719
  -0.08056641 -0.00977325  0.0760498  -0.06884766 -0.05273438  0.04104614
   0.0186615   0.05349731 -0.05892944  0.05801392  0.07830811  0.00614548
  -0.06091309  0.04446411  0.00978851  0.00144386 -0.07788086  0.08276367
   0.07202148  0.08605957 -0.04882812  0.00289917  0.03555298  0.07757568
  -0.07965088  0.03540039 -0.0254364  -0.05508423  0.05841064 -0.03363037
   0.07727051  0.02099609  0.07696533 -0.0352478  -0.06634521 -0.01145172
  -0.05770874  0.02613831  0.06896973  0.02345276 -0.03134155 -0.03076172
  -0.0869751  -0.05670166 -0.04318237  0.01870728  0.06878662  0.08166504
   0.05862427  0.06976318  0.01977539 -0.0680542   0.07312012  0.04721069
   0.04644775  0.06045532 -0.07788086 -0.02279663  0.00743866  0.01916504
   0.05877686 -0.05581665  0.02497864  0.08215332 -0.04962158 -0.04550171
  -0.07220459  0.02761841 -0.00298882 -0.01675415  0.06939697 -0.08612061
   0.09387207  0.06481934  0.00206184  0.08013916 -0.00548172  0.01785278
   0.04898071 -0.06671143 -0.00177479 -0.04730225  0.02372742  0.05212402
  -0.06420898 -0.0300293  -0.04797363 -0.05340576 -0.06292725 -0.07714844
   0.0657959  -0.03717041 -0.0149765   0.06335449 -0.04147339 -0.05319214
   0.00527573  0.01927185  0.01180267  0.0838623   0.00623322 -0.00313187
   0.09326172  0.03146362  0.00914001  0.09161377  0.06488037 -0.06155396
   0.02760315 -0.06207275 -0.06124878 -0.01649475  0.06549072 -0.01605225
  -0.0793457  -0.02545166 -0.08441162 -0.04592896 -0.06707764  0.06787109
  -0.00608063  0.02279663 -0.0328064   0.04278564 -0.05740356 -0.04873657
   0.06732178 -0.05264282 -0.06866455  0.07745361 -0.03759766 -0.0319519
  -0.05053711  0.06628418  0.02203369 -0.06420898]]
After layer split5_output8 (1, 256) <class 'numpy.float16'> [[ 0.06011963  0.00928497  0.03005981 -0.03009033 -0.03494263  0.00979614
   0.04443359  0.0892334  -0.0647583   0.06057739 -0.03366089 -0.0413208
   0.05426025  0.00199127 -0.04977417 -0.01615906  0.02236938  0.04937744
  -0.07427979  0.01543427  0.03674316 -0.07714844  0.00384521  0.04898071
   0.04669189  0.0435791   0.05166626 -0.03117371  0.00643921 -0.0916748
  -0.06555176  0.04605103  0.03308105 -0.02362061 -0.05386353  0.05136108
  -0.05328369  0.00138664  0.0087204   0.0222168  -0.08197021  0.01593018
  -0.09448242 -0.01968384 -0.05157471 -0.02156067  0.09191895 -0.0456543
  -0.01366425  0.02568054  0.05508423 -0.06210327 -0.06109619  0.09179688
   0.034729    0.00032783  0.08184814 -0.00460052 -0.06396484 -0.07873535
  -0.07684326  0.03585815  0.03106689 -0.02568054 -0.09423828  0.09216309
   0.05581665 -0.07940674 -0.00190926  0.01980591 -0.01357269 -0.07611084
  -0.03887939 -0.06494141 -0.03253174  0.00991821  0.06130981  0.06057739
  -0.02391052 -0.05252075  0.05300903 -0.06097412  0.06945801  0.03237915
   0.07281494 -0.03497314  0.01681519 -0.01838684  0.03123474  0.05499268
   0.03588867 -0.06677246  0.01105499  0.08728027  0.07897949 -0.04669189
   0.01126862  0.08270264  0.07562256 -0.08111572 -0.07165527  0.0562439
   0.09436035  0.03012085  0.07299805  0.05389404 -0.06439209  0.03515625
   0.09405518  0.03613281 -0.04663086 -0.00576401 -0.03102112  0.0838623
  -0.04074097 -0.05682373 -0.0304718  -0.04257202  0.06616211  0.08886719
  -0.08056641 -0.00977325  0.0760498  -0.06884766 -0.05273438  0.04104614
   0.0186615   0.05349731 -0.05892944  0.05801392  0.07830811  0.00614548
  -0.06091309  0.04446411  0.00978851  0.00144386 -0.07788086  0.08276367
   0.07202148  0.08605957 -0.04882812  0.00289917  0.03555298  0.07757568
  -0.07965088  0.03540039 -0.0254364  -0.05508423  0.05841064 -0.03363037
   0.07727051  0.02099609  0.07696533 -0.0352478  -0.06634521 -0.01145172
  -0.05770874  0.02613831  0.06896973  0.02345276 -0.03134155 -0.03076172
  -0.0869751  -0.05670166 -0.04318237  0.01870728  0.06878662  0.08166504
   0.05862427  0.06976318  0.01977539 -0.0680542   0.07312012  0.04721069
   0.04644775  0.06045532 -0.07788086 -0.02279663  0.00743866  0.01916504
   0.05877686 -0.05581665  0.02497864  0.08215332 -0.04962158 -0.04550171
  -0.07220459  0.02761841 -0.00298882 -0.01675415  0.06939697 -0.08612061
   0.09387207  0.06481934  0.00206184  0.08013916 -0.00548172  0.01785278
   0.04898071 -0.06671143 -0.00177479 -0.04730225  0.02372742  0.05212402
  -0.06420898 -0.0300293  -0.04797363 -0.05340576 -0.06292725 -0.07714844
   0.0657959  -0.03717041 -0.0149765   0.06335449 -0.04147339 -0.05319214
   0.00527573  0.01927185  0.01180267  0.0838623   0.00623322 -0.00313187
   0.09326172  0.03146362  0.00914001  0.09161377  0.06488037 -0.06155396
   0.02760315 -0.06207275 -0.06124878 -0.01649475  0.06549072 -0.01605225
  -0.0793457  -0.02545166 -0.08441162 -0.04592896 -0.06707764  0.06787109
  -0.00608063  0.02279663 -0.0328064   0.04278564 -0.05740356 -0.04873657
   0.06732178 -0.05264282 -0.06866455  0.07745361 -0.03759766 -0.0319519
  -0.05053711  0.06628418  0.02203369 -0.06420898]]
After layer split5_output9 (1, 256) <class 'numpy.float16'> [[ 0.06011963  0.00928497  0.03005981 -0.03009033 -0.03494263  0.00979614
   0.04443359  0.0892334  -0.0647583   0.06057739 -0.03366089 -0.0413208
   0.05426025  0.00199127 -0.04977417 -0.01615906  0.02236938  0.04937744
  -0.07427979  0.01543427  0.03674316 -0.07714844  0.00384521  0.04898071
   0.04669189  0.0435791   0.05166626 -0.03117371  0.00643921 -0.0916748
  -0.06555176  0.04605103  0.03308105 -0.02362061 -0.05386353  0.05136108
  -0.05328369  0.00138664  0.0087204   0.0222168  -0.08197021  0.01593018
  -0.09448242 -0.01968384 -0.05157471 -0.02156067  0.09191895 -0.0456543
  -0.01366425  0.02568054  0.05508423 -0.06210327 -0.06109619  0.09179688
   0.034729    0.00032783  0.08184814 -0.00460052 -0.06396484 -0.07873535
  -0.07684326  0.03585815  0.03106689 -0.02568054 -0.09423828  0.09216309
   0.05581665 -0.07940674 -0.00190926  0.01980591 -0.01357269 -0.07611084
  -0.03887939 -0.06494141 -0.03253174  0.00991821  0.06130981  0.06057739
  -0.02391052 -0.05252075  0.05300903 -0.06097412  0.06945801  0.03237915
   0.07281494 -0.03497314  0.01681519 -0.01838684  0.03123474  0.05499268
   0.03588867 -0.06677246  0.01105499  0.08728027  0.07897949 -0.04669189
   0.01126862  0.08270264  0.07562256 -0.08111572 -0.07165527  0.0562439
   0.09436035  0.03012085  0.07299805  0.05389404 -0.06439209  0.03515625
   0.09405518  0.03613281 -0.04663086 -0.00576401 -0.03102112  0.0838623
  -0.04074097 -0.05682373 -0.0304718  -0.04257202  0.06616211  0.08886719
  -0.08056641 -0.00977325  0.0760498  -0.06884766 -0.05273438  0.04104614
   0.0186615   0.05349731 -0.05892944  0.05801392  0.07830811  0.00614548
  -0.06091309  0.04446411  0.00978851  0.00144386 -0.07788086  0.08276367
   0.07202148  0.08605957 -0.04882812  0.00289917  0.03555298  0.07757568
  -0.07965088  0.03540039 -0.0254364  -0.05508423  0.05841064 -0.03363037
   0.07727051  0.02099609  0.07696533 -0.0352478  -0.06634521 -0.01145172
  -0.05770874  0.02613831  0.06896973  0.02345276 -0.03134155 -0.03076172
  -0.0869751  -0.05670166 -0.04318237  0.01870728  0.06878662  0.08166504
   0.05862427  0.06976318  0.01977539 -0.0680542   0.07312012  0.04721069
   0.04644775  0.06045532 -0.07788086 -0.02279663  0.00743866  0.01916504
   0.05877686 -0.05581665  0.02497864  0.08215332 -0.04962158 -0.04550171
  -0.07220459  0.02761841 -0.00298882 -0.01675415  0.06939697 -0.08612061
   0.09387207  0.06481934  0.00206184  0.08013916 -0.00548172  0.01785278
   0.04898071 -0.06671143 -0.00177479 -0.04730225  0.02372742  0.05212402
  -0.06420898 -0.0300293  -0.04797363 -0.05340576 -0.06292725 -0.07714844
   0.0657959  -0.03717041 -0.0149765   0.06335449 -0.04147339 -0.05319214
   0.00527573  0.01927185  0.01180267  0.0838623   0.00623322 -0.00313187
   0.09326172  0.03146362  0.00914001  0.09161377  0.06488037 -0.06155396
   0.02760315 -0.06207275 -0.06124878 -0.01649475  0.06549072 -0.01605225
  -0.0793457  -0.02545166 -0.08441162 -0.04592896 -0.06707764  0.06787109
  -0.00608063  0.02279663 -0.0328064   0.04278564 -0.05740356 -0.04873657
   0.06732178 -0.05264282 -0.06866455  0.07745361 -0.03759766 -0.0319519
  -0.05053711  0.06628418  0.02203369 -0.06420898]]
After layer encoder_birnn_reverse_l0_t0_i2h_output (1, 1024) <class 'numpy.float16'> [[ 0.08496094  0.07232666 -0.05630493 ..., -0.00508881 -0.01011658
  -0.04168701]]
After layer encoder_birnn_reverse_l0_begin_state_0_0 (1, 256) <class 'numpy.float16'> [[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
   0.  0.  0.  0.]]
After layer encoder_birnn_reverse_l0_t0_h2h_output (1, 1024) <class 'numpy.float16'> [[ 0.01889038  0.01239777  0.0041008  ...,  0.01309967  0.02073669
   0.01248932]]
After layer _plus1036_0 (1, 1024) <class 'numpy.float16'> [[ 0.10388184  0.0847168  -0.05221558 ...,  0.00801086  0.01062012
  -0.02920532]]
After layer encoder_birnn_reverse_l0_t0_slice_output0 (1, 256) <class 'numpy.float16'> [[ 0.10388184  0.0847168  -0.05221558  0.05218506 -0.00299072 -0.01617432
   0.01570129  0.18200684  0.18286133 -0.01379395  0.05358887  0.08862305
   0.0960083   0.00598145  0.08544922  0.04367065 -0.02102661  0.02593994
  -0.05157471  0.01480103  0.09417725 -0.02033997  0.08728027 -0.09234619
  -0.03436279  0.05880737  0.03353882 -0.02044678  0.09851074  0.01593018
   0.07263184  0.01285553 -0.00259399  0.00421906 -0.02935791  0.00082397
   0.04721069  0.02958679  0.08734131  0.06204224  0.17785645  0.06176758
   0.06298828  0.00222778  0.03765869  0.01904297  0.03787231  0.05981445
  -0.05804443  0.04827881  0.03314209 -0.00537109  0.16821289  0.1104126
   0.14257812  0.01293945 -0.0196228   0.08959961  0.02294922  0.1036377
   0.00444031  0.04074097 -0.05126953  0.02923584  0.11334229  0.01316071
   0.07519531 -0.00964355  0.08233643  0.23815918  0.09533691  0.06536865
   0.00494385 -0.02705383  0.03076172  0.1385498   0.0692749   0.0670166
   0.06671143  0.04833984  0.0369873   0.06689453 -0.01009369  0.00354004
   0.09906006  0.10540771  0.10717773  0.13806152 -0.08007812  0.21984863
   0.15185547  0.10882568  0.0147171  -0.00624084  0.0690918   0.09576416
   0.11810303  0.14086914 -0.07476807  0.06445312  0.05444336  0.03646851
   0.07519531  0.06164551  0.13574219  0.11090088 -0.02911377 -0.02726746
   0.00817871  0.10913086  0.0458374   0.09869385  0.05725098  0.00894165
   0.09088135  0.21618652 -0.06323242 -0.01360321  0.20898438  0.13391113
   0.07092285  0.04779053  0.05767822  0.09448242  0.06793213  0.0218811
   0.06161499  0.13342285 -0.03210449 -0.05978394  0.11071777  0.21508789
   0.01631165 -0.00637436  0.07537842  0.01939392 -0.07183838  0.02612305
  -0.01974487 -0.05758667  0.08538818  0.01141357  0.04614258  0.00598907
   0.11395264  0.02059937  0.10473633  0.02902222  0.04177856 -0.00262451
   0.00415039  0.05477905  0.05511475 -0.01068115  0.03512573  0.12316895
  -0.02108765  0.09484863  0.0770874  -0.01309204 -0.00598145  0.00035667
   0.05371094  0.0043869  -0.01291656  0.08569336  0.06097412  0.03155518
   0.01654053 -0.04968262  0.02630615  0.03161621  0.07171631  0.23291016
   0.08093262  0.14477539  0.00567627  0.07232666  0.09844971  0.08276367
   0.02377319  0.0362854   0.0329895   0.07427979  0.12438965  0.0189209
   0.05029297  0.04455566  0.28417969  0.09289551  0.04702759 -0.03723145
  -0.11749268 -0.01829529  0.26318359  0.046875    0.03240967  0.09466553
   0.02828979  0.09216309  0.10632324  0.09454346  0.09106445  0.03375244
   0.00669861  0.01499939  0.06829834 -0.03070068  0.07965088  0.05215454
   0.01251221  0.14196777  0.00097656 -0.00692749  0.12817383  0.11712646
   0.04684448  0.06298828  0.0793457   0.12268066 -0.00497437  0.13720703
   0.07543945  0.05529785  0.05895996 -0.03347778  0.06445312  0.12481689
   0.05908203  0.26879883 -0.01690674  0.02151489 -0.03939819  0.03643799
   0.01487732  0.05429077  0.09716797 -0.02290344  0.14489746 -0.05230713
   0.06689453  0.0065155   0.23022461  0.17468262 -0.01455688  0.02294922
   0.05426025  0.11645508  0.0949707   0.10888672  0.10540771  0.16223145
   0.03323364  0.07531738 -0.06518555 -0.03390503]]
After layer encoder_birnn_reverse_l0_t0_slice_output1 (1, 256) <class 'numpy.float16'> [[  1.53686523e-01   1.01379395e-01   1.00097656e-01   4.52270508e-02
    1.09436035e-01   9.79614258e-02   6.45751953e-02   9.55810547e-02
    2.67089844e-01   4.23278809e-02  -5.38330078e-02   3.01666260e-02
    2.54211426e-02   6.22558594e-02   3.02124023e-03   1.15600586e-01
    3.73229980e-02   5.60607910e-02   8.85009766e-02   2.77404785e-02
    8.58154297e-02   5.50231934e-02   2.31689453e-01   7.13500977e-02
    8.30688477e-02   8.10546875e-02   5.85021973e-02  -2.20031738e-02
    5.07812500e-02   3.65600586e-02   1.52587891e-03   3.36914062e-02
    3.17382812e-02   7.51953125e-02   5.18798828e-02  -2.80761719e-02
   -4.72412109e-02  -2.64892578e-02   8.45947266e-02   6.67724609e-02
    6.24694824e-02   1.05407715e-01   5.24597168e-02  -1.33361816e-02
    3.53698730e-02  -2.45666504e-03   4.40979004e-02   9.92431641e-02
    7.59277344e-02   2.45666504e-02   7.73925781e-02   8.00170898e-02
    1.27319336e-01   1.88232422e-01   1.11206055e-01  -1.20697021e-02
    5.61218262e-02   3.11584473e-02   4.26940918e-02   1.11328125e-01
    3.49121094e-02   6.53686523e-02   3.20434570e-02   7.23876953e-02
    5.66101074e-02  -5.80444336e-02   1.44531250e-01   8.31909180e-02
    4.58984375e-02   9.43603516e-02  -8.60595703e-03   9.13085938e-02
    3.79028320e-02  -2.92968750e-02   4.34265137e-02   2.12890625e-01
    1.19018555e-03   6.49414062e-02   2.40783691e-02   2.86865234e-02
    8.41064453e-02   3.35693359e-02   3.63464355e-02   5.87158203e-02
    1.20361328e-01   3.35083008e-02   6.64672852e-02   3.43017578e-02
   -1.01013184e-02   1.56494141e-01   1.98120117e-01   2.07519531e-02
   -3.86962891e-02   4.65087891e-02   1.76086426e-02   7.29980469e-02
    2.53448486e-02   1.94335938e-01   6.17370605e-02   1.26464844e-01
    8.53271484e-02   1.28326416e-02   3.78112793e-02   5.67932129e-02
    2.18963623e-02   7.02514648e-02   4.99877930e-02   1.11206055e-01
    1.23962402e-01   1.36962891e-01  -4.11987305e-03   1.74102783e-02
    9.23919678e-03   4.70581055e-02   8.53881836e-02   7.71484375e-02
    2.30102539e-02   1.23596191e-02   1.72241211e-01   8.66699219e-02
    1.55273438e-01   1.55563354e-02   1.11770630e-02   4.19311523e-02
    3.24707031e-02   5.62133789e-02  -2.38647461e-02  -4.96673584e-03
    7.87963867e-02   1.34963989e-02   5.80749512e-02   1.79199219e-01
    1.41967773e-01   1.87377930e-02   1.63421631e-02   4.57763672e-05
    4.15039062e-03   9.08813477e-02   9.59777832e-03  -4.49218750e-02
    5.09033203e-02   5.48706055e-02   5.65490723e-02   6.41479492e-02
    7.43103027e-03   1.13159180e-01  -1.58386230e-02   1.39648438e-01
    3.74145508e-02   1.08215332e-01   6.67114258e-02  -4.05578613e-02
    3.73840332e-03  -1.25854492e-01   6.21337891e-02  -2.65502930e-02
    8.02612305e-02   1.13769531e-01   8.64257812e-02   1.23352051e-01
    1.16027832e-01  -1.97753906e-02   1.00891113e-01   1.43066406e-01
    8.59985352e-02   4.88586426e-02   8.45947266e-02  -2.15148926e-02
    1.08703613e-01   1.15051270e-01   3.98254395e-02   6.99462891e-02
    8.72802734e-02   1.16333008e-01   1.35131836e-01   4.14276123e-03
    6.95800781e-02  -6.38427734e-02   1.22802734e-01   1.01623535e-01
   -2.94799805e-02   1.21643066e-01   9.20410156e-02   7.08007812e-03
    3.50341797e-02   4.09240723e-02   9.91210938e-02   1.13098145e-01
    1.86279297e-01   8.00781250e-02  -2.73437500e-02  -2.63366699e-02
    1.78375244e-02   5.91430664e-02   2.31933594e-01   9.60083008e-02
    1.22314453e-01   1.28173828e-01   3.32641602e-02   3.83911133e-02
    4.08935547e-03   8.02612305e-02   1.59057617e-01   5.61828613e-02
   -7.65991211e-03   8.43505859e-02  -4.63867188e-02   2.68096924e-02
    3.52783203e-02   5.90209961e-02   7.32421875e-02   9.79003906e-02
    2.09197998e-02   3.09143066e-02   1.03027344e-01   8.49609375e-02
    1.02539062e-01   2.70690918e-02   7.00073242e-02   1.81121826e-02
   -3.76586914e-02  -9.88769531e-03  -4.45251465e-02  -2.09655762e-02
    9.86938477e-02  -1.81579590e-02   5.07812500e-02   4.18090820e-02
    1.50512695e-01   2.27905273e-01   6.37817383e-02   5.27954102e-02
    7.80029297e-02   1.03530884e-02   1.31072998e-02  -3.01666260e-02
    3.18603516e-02  -6.75964355e-03   4.62036133e-02   4.52423096e-03
    6.45141602e-02   7.63549805e-02   2.18994141e-01   1.06689453e-01
   -3.33786011e-03   7.49969482e-03   1.04064941e-01  -3.98254395e-02
    1.55151367e-01  -2.07519531e-03   9.82666016e-02  -3.47595215e-02
    1.65863037e-02   8.99658203e-02   3.71704102e-02   5.31005859e-02]]
After layer encoder_birnn_reverse_l0_t0_slice_output2 (1, 256) <class 'numpy.float16'> [[-0.11193848 -0.04428101 -0.0614624  -0.10742188  0.00270844 -0.19519043
   0.05923462  0.02554321 -0.04299927 -0.11541748 -0.03564453  0.07745361
   0.07293701 -0.09576416  0.08172607 -0.04928589  0.04852295  0.04016113
   0.06646729 -0.03125     0.06280518 -0.11914062  0.02110291  0.09307861
   0.01397705 -0.00252533 -0.19250488 -0.01655579  0.01693726 -0.07501221
   0.05181885 -0.05886841  0.06365967 -0.03546143  0.04467773 -0.00675583
  -0.15844727 -0.02070618 -0.10302734 -0.0045929   0.02787781  0.02357483
   0.11132812  0.0112915   0.12561035 -0.08837891  0.08972168 -0.07324219
  -0.01211548 -0.14782715 -0.14575195 -0.05297852  0.03125     0.07214355
  -0.0094986   0.05349731 -0.105896    0.11535645  0.03616333 -0.12060547
  -0.08416748 -0.01834106 -0.05551147 -0.09051514  0.12200928 -0.09417725
   0.0847168  -0.0014801  -0.10955811 -0.05783081 -0.14331055  0.04815674
   0.02603149 -0.07025146  0.01821899 -0.08807373 -0.0680542  -0.09106445
  -0.03692627 -0.0406189  -0.10449219 -0.02436829 -0.07019043 -0.12231445
  -0.08361816  0.07116699 -0.04901123  0.0531311  -0.04174805 -0.12683105
   0.09454346  0.00395203  0.05108643 -0.05389404  0.05627441 -0.00469208
   0.04180908  0.06842041  0.02542114  0.0307312   0.04626465  0.08520508
  -0.13830566  0.05645752 -0.0581665   0.02508545 -0.02140808 -0.12756348
   0.09613037 -0.01370239  0.1036377   0.20300293 -0.00484085  0.0604248
  -0.0463562  -0.01913452 -0.05828857 -0.12457275  0.00137329  0.07183838
   0.04089355  0.0791626  -0.06140137 -0.03884888  0.11712646 -0.09594727
  -0.0579834  -0.01800537  0.08483887  0.16235352  0.08966064  0.09350586
   0.00637054  0.09020996  0.02738953  0.07183838  0.05062866 -0.01651001
   0.06896973  0.13647461 -0.10211182 -0.02746582  0.05566406 -0.09204102
  -0.12805176  0.07354736  0.15588379 -0.0970459   0.01580811 -0.02197266
  -0.07885742 -0.02182007  0.02662659  0.01387024  0.02023315 -0.09942627
  -0.11889648  0.06137085  0.11077881  0.08459473 -0.04620361 -0.05267334
   0.04611206  0.03833008  0.04083252  0.03125     0.06210327 -0.12670898
   0.0022583  -0.09356689 -0.04071045  0.0736084  -0.03894043 -0.02243042
  -0.06152344  0.04754639  0.24462891 -0.04074097 -0.16320801 -0.05426025
  -0.0089035  -0.01631165 -0.09295654 -0.00868988  0.19628906 -0.08325195
   0.01850891 -0.11114502  0.05014038 -0.07226562  0.02416992  0.13671875
  -0.00414276  0.0166626  -0.0534668   0.04541016 -0.11474609 -0.09863281
   0.04452515  0.04794312 -0.04959106  0.09832764  0.12139893 -0.05386353
   0.09527588 -0.01792908 -0.06762695  0.03811646  0.13244629 -0.07067871
  -0.01087952  0.03466797  0.10223389 -0.09210205  0.04718018 -0.07196045
   0.01010895 -0.0045433  -0.05554199  0.105896    0.11975098 -0.0475769
  -0.06210327 -0.01345825 -0.03778076 -0.02612305 -0.02592468  0.07897949
  -0.0139389   0.02908325 -0.0043335   0.08007812  0.08587646  0.025177
  -0.0446167   0.11218262 -0.07958984 -0.01651001 -0.04330444  0.07714844
   0.03872681 -0.05062866  0.05664062  0.03894043 -0.11004639  0.04138184
   0.01490784  0.00746918 -0.10571289  0.05541992  0.05407715  0.05334473
   0.13720703 -0.05072021  0.0430603  -0.07232666]]
After layer encoder_birnn_reverse_l0_t0_slice_output3 (1, 256) <class 'numpy.float16'> [[  3.01513672e-02   7.18383789e-02   2.35443115e-02   7.00073242e-02
    7.12280273e-02   1.34033203e-01   4.00390625e-02   1.35253906e-01
    1.56494141e-01   5.33142090e-02  -4.86755371e-02   1.32324219e-01
    3.96728516e-02   4.04663086e-02   1.07055664e-01   9.00268555e-03
   -3.14331055e-02   2.35595703e-02  -9.00268555e-02   8.12377930e-02
    7.39135742e-02   9.18579102e-03   8.25195312e-02  -3.66821289e-02
    4.07714844e-02  -4.95605469e-02   7.62329102e-02   3.77197266e-02
    5.75561523e-02   7.39746094e-02  -4.30908203e-02   9.44519043e-03
   -2.21557617e-02   6.86035156e-02   3.93066406e-02  -8.23974609e-03
    1.63879395e-02   8.89282227e-02   3.27453613e-02   1.95800781e-01
    2.06420898e-01   1.61376953e-01   8.17260742e-02   2.19726562e-03
    4.66613770e-02   5.87463379e-02   7.56225586e-02   2.31933594e-03
    6.86035156e-02   4.85229492e-02   1.10229492e-01  -1.30844116e-02
    1.09985352e-01   1.19079590e-01   1.37451172e-01   5.00793457e-02
   -2.38189697e-02   6.49414062e-02   7.93457031e-02   5.20019531e-02
    4.91333008e-02   1.31469727e-01   8.16040039e-02   4.70581055e-02
    5.19409180e-02   1.13677979e-02   1.63574219e-01  -4.82177734e-03
    1.29150391e-01   1.71264648e-01   1.22192383e-01  -1.49993896e-02
   -3.21350098e-02   1.16943359e-01   2.25372314e-02   1.50756836e-01
    2.78625488e-02  -4.79125977e-03   1.15173340e-01   7.81860352e-02
    7.38525391e-03   5.64575195e-02  -2.60162354e-02   4.32128906e-02
    3.66821289e-02   8.28552246e-03  -5.97839355e-02   8.86230469e-02
    1.19171143e-02   2.09960938e-01   1.52221680e-01   6.87255859e-02
   -1.47094727e-02   1.06628418e-01   3.07159424e-02   8.83178711e-02
    6.82983398e-02   8.55712891e-02   1.01318359e-02   3.69262695e-03
    4.59594727e-02   9.05609131e-03   4.80957031e-02   2.08587646e-02
    1.40747070e-01   6.39648438e-02   8.94927979e-03   1.10900879e-01
    1.39160156e-01   9.07592773e-02   8.67919922e-02   1.63696289e-01
    4.09240723e-02   1.27685547e-01   4.39453125e-02   4.17785645e-02
    4.58984375e-02   3.93371582e-02   2.04345703e-01   5.89294434e-02
    4.63867188e-02   2.96325684e-02   1.07543945e-01   9.80224609e-02
    4.64172363e-02   8.89587402e-03  -7.62939453e-05  -5.82885742e-02
    1.33300781e-01   2.24609375e-02   8.19091797e-02   2.32421875e-01
   -3.37829590e-02   5.74951172e-02   1.17126465e-01   7.40966797e-02
    8.33740234e-02   4.55932617e-02   5.16357422e-02   6.35986328e-02
    5.33142090e-02   7.84912109e-02   1.39892578e-01   1.07543945e-01
    4.35180664e-02   9.55810547e-02   9.75341797e-02   9.11254883e-02
   -1.71203613e-02   1.04858398e-01   9.50317383e-02  -3.09906006e-02
    3.80249023e-02   7.81860352e-02   4.63256836e-02   8.42895508e-02
    7.54394531e-02   1.92016602e-01   1.32446289e-01   6.03027344e-02
    8.04443359e-02   8.37402344e-02   1.01684570e-01   8.47167969e-02
    8.29467773e-02  -8.14208984e-02   6.85424805e-02  -2.10571289e-03
    1.80541992e-01   5.21545410e-02   7.16552734e-02   3.92761230e-02
    8.75244141e-02   1.26098633e-01   7.44628906e-02   6.73217773e-02
    3.84521484e-02   7.69042969e-03   6.54907227e-02   5.50842285e-03
   -1.17492676e-03   2.43072510e-02  -5.12390137e-02   1.24328613e-01
    1.54541016e-01  -1.34735107e-02   7.90405273e-02   1.52740479e-02
    3.40820312e-01   1.09924316e-01   1.02111816e-01  -7.87353516e-02
    7.85522461e-02   1.21154785e-01   3.33496094e-01  -1.69067383e-02
   -9.07135010e-03   1.14257812e-01   3.20129395e-02  -6.95800781e-03
    3.68652344e-02   1.67724609e-01   8.67309570e-02   1.58081055e-02
    1.09741211e-01   1.01196289e-01   3.44848633e-02   5.21850586e-02
    4.60205078e-02   5.79223633e-02   2.44140625e-01   8.67309570e-02
    2.39562988e-02   6.89697266e-02   8.54492188e-02   4.92553711e-02
    3.58581543e-02   1.04064941e-01   5.56030273e-02   1.53442383e-01
    5.73730469e-02   8.86230469e-02   4.27246094e-02   3.12194824e-02
    6.83593750e-02  -5.77087402e-02   8.12377930e-02   6.40258789e-02
    2.11547852e-01   2.31933594e-01  -1.28555298e-03   5.87768555e-02
    3.13415527e-02   6.81762695e-02   9.14916992e-02   4.32739258e-02
    8.28552246e-03  -2.45666504e-02   4.39453125e-02   3.99169922e-02
    7.91015625e-02   8.74023438e-02   2.17529297e-01   2.18017578e-01
    5.93261719e-02   3.19213867e-02   3.22265625e-02   8.89892578e-02
    2.00195312e-01   8.23974609e-04   1.60217285e-02   1.48803711e-01
    8.39233398e-02   8.01086426e-03   1.06201172e-02  -2.92053223e-02]]
After layer encoder_birnn_reverse_l0_t0_o_output (1, 256) <class 'numpy.float16'> [[ 0.50732422  0.51806641  0.50585938  0.51757812  0.51757812  0.53369141
   0.50976562  0.53369141  0.5390625   0.51318359  0.48779297  0.53320312
   0.50976562  0.51025391  0.52685547  0.50244141  0.4921875   0.50585938
   0.47753906  0.52050781  0.51855469  0.50244141  0.52050781  0.49072266
   0.51025391  0.48754883  0.51904297  0.50927734  0.51416016  0.51855469
   0.48925781  0.50244141  0.49438477  0.51708984  0.50976562  0.49804688
   0.50390625  0.52246094  0.50830078  0.54882812  0.55126953  0.54003906
   0.52050781  0.50048828  0.51171875  0.51464844  0.51904297  0.50048828
   0.51708984  0.51220703  0.52734375  0.49682617  0.52734375  0.52978516
   0.53417969  0.51269531  0.49414062  0.51611328  0.52001953  0.51318359
   0.51220703  0.53271484  0.52050781  0.51171875  0.51318359  0.50292969
   0.54101562  0.4987793   0.53222656  0.54248047  0.53027344  0.49633789
   0.49194336  0.52929688  0.50585938  0.53759766  0.50683594  0.4987793
   0.52880859  0.51953125  0.50195312  0.51416016  0.4934082   0.51074219
   0.50927734  0.50195312  0.48510742  0.52197266  0.50292969  0.55224609
   0.53808594  0.51708984  0.49633789  0.52685547  0.5078125   0.52197266
   0.51708984  0.52148438  0.50244141  0.50097656  0.51171875  0.50244141
   0.51220703  0.50537109  0.53515625  0.51611328  0.50244141  0.52783203
   0.53466797  0.52246094  0.52148438  0.54101562  0.51025391  0.53173828
   0.51074219  0.51025391  0.51123047  0.50976562  0.55078125  0.51464844
   0.51171875  0.50732422  0.52685547  0.52441406  0.51171875  0.50244141
   0.5         0.48535156  0.53320312  0.50537109  0.52050781  0.55761719
   0.49145508  0.51416016  0.52929688  0.51855469  0.52099609  0.51123047
   0.51269531  0.51611328  0.51318359  0.51953125  0.53515625  0.52685547
   0.51074219  0.52392578  0.52441406  0.52294922  0.49560547  0.52636719
   0.52392578  0.4921875   0.50927734  0.51953125  0.51171875  0.52099609
   0.51904297  0.54785156  0.53320312  0.51513672  0.52001953  0.52099609
   0.52539062  0.52099609  0.52050781  0.47973633  0.51708984  0.49951172
   0.54492188  0.51318359  0.51806641  0.50976562  0.52197266  0.53125
   0.51855469  0.51660156  0.50976562  0.50195312  0.51660156  0.50146484
   0.49975586  0.50585938  0.48730469  0.53125     0.53857422  0.49658203
   0.51953125  0.50390625  0.58447266  0.52734375  0.52539062  0.48022461
   0.51953125  0.53027344  0.58251953  0.49584961  0.49780273  0.52832031
   0.5078125   0.49829102  0.50927734  0.54199219  0.52148438  0.50390625
   0.52734375  0.52539062  0.50878906  0.51318359  0.51171875  0.51464844
   0.56054688  0.52148438  0.50585938  0.51708984  0.52148438  0.51220703
   0.50878906  0.52587891  0.51367188  0.53808594  0.51416016  0.52197266
   0.51074219  0.5078125   0.51708984  0.4855957   0.52050781  0.51611328
   0.55273438  0.55761719  0.49975586  0.51464844  0.5078125   0.51708984
   0.52294922  0.51074219  0.50195312  0.49389648  0.51074219  0.50976562
   0.51953125  0.52197266  0.55419922  0.55419922  0.51464844  0.5078125
   0.5078125   0.52246094  0.54980469  0.5         0.50390625  0.53710938
   0.52099609  0.50195312  0.50244141  0.49267578]]
After layer encoder_birnn_reverse_l0_t0_f_output (1, 256) <class 'numpy.float16'> [[ 0.53857422  0.52539062  0.52490234  0.51123047  0.52734375  0.52441406
   0.51611328  0.52392578  0.56640625  0.51074219  0.48657227  0.50732422
   0.50634766  0.515625    0.50097656  0.52880859  0.50927734  0.51416016
   0.52197266  0.50683594  0.52148438  0.51367188  0.55761719  0.51806641
   0.52099609  0.52001953  0.51464844  0.49438477  0.51269531  0.50927734
   0.50048828  0.50830078  0.5078125   0.51855469  0.51318359  0.49291992
   0.48828125  0.4934082   0.52099609  0.51660156  0.515625    0.52636719
   0.51318359  0.49658203  0.50878906  0.49926758  0.51123047  0.52490234
   0.51904297  0.50634766  0.51953125  0.52001953  0.53173828  0.546875
   0.52783203  0.49707031  0.51416016  0.5078125   0.51074219  0.52783203
   0.50878906  0.51611328  0.5078125   0.51806641  0.51416016  0.4855957
   0.53613281  0.52099609  0.51123047  0.5234375   0.49780273  0.52294922
   0.50927734  0.49267578  0.51074219  0.55322266  0.50048828  0.51611328
   0.50585938  0.50732422  0.52099609  0.50830078  0.50927734  0.51464844
   0.53027344  0.50830078  0.51660156  0.50878906  0.49755859  0.5390625
   0.54931641  0.50537109  0.49023438  0.51171875  0.50439453  0.51806641
   0.50634766  0.54833984  0.515625    0.53173828  0.52148438  0.50341797
   0.50927734  0.51416016  0.50537109  0.51757812  0.51269531  0.52783203
   0.53076172  0.53417969  0.49902344  0.50439453  0.50244141  0.51171875
   0.52148438  0.51904297  0.50585938  0.50292969  0.54296875  0.52148438
   0.53857422  0.50390625  0.50292969  0.51025391  0.50830078  0.51416016
   0.49414062  0.4987793   0.51953125  0.50341797  0.51464844  0.54492188
   0.53564453  0.50488281  0.50390625  0.5         0.50097656  0.52246094
   0.50244141  0.48876953  0.51269531  0.51367188  0.51416016  0.51611328
   0.50195312  0.52832031  0.49609375  0.53466797  0.50927734  0.52685547
   0.51660156  0.48974609  0.50097656  0.46850586  0.515625    0.4934082
   0.52001953  0.52832031  0.52148438  0.53076172  0.52880859  0.49511719
   0.52539062  0.53564453  0.52148438  0.51220703  0.52099609  0.49462891
   0.52734375  0.52880859  0.50976562  0.51757812  0.52197266  0.52880859
   0.53369141  0.50097656  0.51757812  0.48413086  0.53076172  0.52539062
   0.49267578  0.53027344  0.52294922  0.50195312  0.50878906  0.51025391
   0.52490234  0.52832031  0.54638672  0.52001953  0.49316406  0.4934082
   0.50439453  0.51464844  0.55761719  0.52392578  0.53076172  0.53222656
   0.50830078  0.50976562  0.50097656  0.52001953  0.53955078  0.51416016
   0.49804688  0.52099609  0.48852539  0.50683594  0.50878906  0.51464844
   0.51806641  0.52441406  0.50537109  0.5078125   0.52587891  0.52099609
   0.52539062  0.50683594  0.51757812  0.50439453  0.49047852  0.49755859
   0.48876953  0.49487305  0.52441406  0.49536133  0.51269531  0.51025391
   0.53759766  0.55664062  0.51611328  0.51318359  0.51953125  0.50244141
   0.50341797  0.49243164  0.5078125   0.49829102  0.51171875  0.50097656
   0.51611328  0.51904297  0.5546875   0.52685547  0.49926758  0.50195312
   0.52587891  0.48999023  0.53857422  0.49951172  0.52441406  0.49121094
   0.50390625  0.52246094  0.50927734  0.51318359]]
After layer encoder_birnn_reverse_l0_begin_state_1_0 (1, 256) <class 'numpy.float16'> [[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
   0.  0.  0.  0.]]
After layer _mul2072_0 (1, 256) <class 'numpy.float16'> [[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
   0.  0.  0.  0.]]
After layer encoder_birnn_reverse_l0_t0_i_output (1, 256) <class 'numpy.float16'> [[ 0.52587891  0.52099609  0.48706055  0.51318359  0.49926758  0.49584961
   0.50390625  0.54541016  0.54541016  0.49658203  0.51318359  0.52197266
   0.52392578  0.50146484  0.52148438  0.51074219  0.49462891  0.50634766
   0.48706055  0.50390625  0.5234375   0.49487305  0.52197266  0.47705078
   0.49145508  0.51464844  0.50830078  0.49487305  0.52441406  0.50390625
   0.51806641  0.50341797  0.49926758  0.50097656  0.49267578  0.5
   0.51171875  0.50732422  0.52197266  0.515625    0.54443359  0.515625
   0.515625    0.50048828  0.50927734  0.50488281  0.50927734  0.51513672
   0.4855957   0.51220703  0.50830078  0.49853516  0.54199219  0.52734375
   0.53564453  0.50341797  0.49511719  0.52246094  0.50585938  0.52587891
   0.50097656  0.51025391  0.48730469  0.50732422  0.52832031  0.50341797
   0.51855469  0.49755859  0.52050781  0.55908203  0.52392578  0.51611328
   0.50146484  0.49316406  0.5078125   0.53466797  0.51708984  0.51660156
   0.51660156  0.51220703  0.50927734  0.51660156  0.49755859  0.50097656
   0.52490234  0.52636719  0.52685547  0.53466797  0.47998047  0.5546875
   0.53808594  0.52734375  0.50390625  0.49853516  0.51708984  0.52392578
   0.52929688  0.53515625  0.48120117  0.51611328  0.51367188  0.50927734
   0.51855469  0.515625    0.53369141  0.52783203  0.49267578  0.49316406
   0.50195312  0.52734375  0.51123047  0.52441406  0.51416016  0.50244141
   0.52246094  0.55371094  0.48413086  0.49658203  0.55224609  0.53320312
   0.51757812  0.51171875  0.51464844  0.5234375   0.51708984  0.50537109
   0.515625    0.53320312  0.49194336  0.48510742  0.52783203  0.55371094
   0.50390625  0.49829102  0.51904297  0.50488281  0.48193359  0.50634766
   0.49511719  0.4855957   0.52148438  0.50292969  0.51171875  0.50146484
   0.52832031  0.50537109  0.52636719  0.50732422  0.51025391  0.49926758
   0.50097656  0.51367188  0.51367188  0.49731445  0.50878906  0.53076172
   0.49462891  0.52392578  0.51904297  0.49682617  0.49853516  0.5
   0.51318359  0.50097656  0.49682617  0.52148438  0.51513672  0.5078125
   0.50390625  0.48754883  0.50634766  0.5078125   0.51806641  0.55810547
   0.52001953  0.53613281  0.50146484  0.51806641  0.52441406  0.52050781
   0.50585938  0.50927734  0.50830078  0.51855469  0.53125     0.50488281
   0.51269531  0.51123047  0.57080078  0.5234375   0.51171875  0.49072266
   0.47070312  0.49536133  0.56542969  0.51171875  0.50830078  0.5234375
   0.50683594  0.52294922  0.52636719  0.5234375   0.52294922  0.50830078
   0.50146484  0.50390625  0.51708984  0.49243164  0.52001953  0.51318359
   0.50292969  0.53564453  0.5         0.49829102  0.53222656  0.52929688
   0.51171875  0.515625    0.52001953  0.53076172  0.4987793   0.53417969
   0.51904297  0.51367188  0.51464844  0.49169922  0.51611328  0.53125
   0.51464844  0.56689453  0.49584961  0.50537109  0.49023438  0.50927734
   0.50390625  0.51367188  0.52441406  0.49438477  0.53613281  0.48681641
   0.51660156  0.50146484  0.55712891  0.54345703  0.49633789  0.50585938
   0.51367188  0.52929688  0.52392578  0.52734375  0.52636719  0.54052734
   0.50830078  0.51904297  0.48364258  0.49145508]]
After layer encoder_birnn_reverse_l0_t0_c_output (1, 256) <class 'numpy.float16'> [[-0.1114502  -0.04425049 -0.06137085 -0.10699463  0.00270844 -0.19274902
   0.05917358  0.02554321 -0.04296875 -0.1149292  -0.03564453  0.07727051
   0.07281494 -0.09545898  0.08154297 -0.04925537  0.04849243  0.04013062
   0.06634521 -0.03123474  0.06274414 -0.11859131  0.02110291  0.09283447
   0.01397705 -0.00252533 -0.19018555 -0.01655579  0.01693726 -0.07489014
   0.05175781 -0.05880737  0.06359863 -0.03546143  0.04464722 -0.00675583
  -0.15710449 -0.02070618 -0.10266113 -0.0045929   0.02787781  0.02357483
   0.11090088  0.0112915   0.12493896 -0.08813477  0.08947754 -0.07312012
  -0.01211548 -0.14672852 -0.14477539 -0.05291748  0.03123474  0.07202148
  -0.0094986   0.05343628 -0.10552979  0.11486816  0.03613281 -0.11999512
  -0.08398438 -0.01834106 -0.05545044 -0.090271    0.12139893 -0.09387207
   0.08453369 -0.0014801  -0.10913086 -0.05776978 -0.14233398  0.04812622
   0.02603149 -0.07012939  0.01821899 -0.08782959 -0.06793213 -0.09082031
  -0.03689575 -0.04058838 -0.10412598 -0.02436829 -0.07006836 -0.1217041
  -0.08343506  0.07104492 -0.04898071  0.05307007 -0.04171753 -0.12609863
   0.09423828  0.00395203  0.05105591 -0.05383301  0.05621338 -0.00469208
   0.04177856  0.06829834  0.02542114  0.03071594  0.04623413  0.08502197
  -0.13745117  0.05639648 -0.05810547  0.02508545 -0.02140808 -0.12683105
   0.0958252  -0.01370239  0.10327148  0.20031738 -0.00484085  0.06036377
  -0.04632568 -0.01913452 -0.05822754 -0.1239624   0.00137329  0.07171631
   0.04086304  0.07897949 -0.06130981 -0.03881836  0.11657715 -0.09564209
  -0.05792236 -0.01800537  0.08465576  0.16088867  0.0894165   0.09326172
   0.00637054  0.08996582  0.02738953  0.07171631  0.05059814 -0.01651001
   0.06884766  0.13562012 -0.10174561 -0.02746582  0.05560303 -0.09179688
  -0.12731934  0.07342529  0.15466309 -0.09674072  0.01580811 -0.02197266
  -0.07867432 -0.02182007  0.02662659  0.01387024  0.02023315 -0.09912109
  -0.11834717  0.0612793   0.11035156  0.08441162 -0.0461731  -0.0526123
   0.04608154  0.03829956  0.040802    0.03123474  0.06201172 -0.12597656
   0.0022583  -0.09332275 -0.04067993  0.07348633 -0.03890991 -0.02243042
  -0.06143188  0.04751587  0.23986816 -0.04071045 -0.16174316 -0.05419922
  -0.0089035  -0.01631165 -0.0927124  -0.00868988  0.19384766 -0.08306885
   0.01850891 -0.11071777  0.05010986 -0.07214355  0.02416992  0.13586426
  -0.00414276  0.0166626  -0.05340576  0.04537964 -0.11425781 -0.09832764
   0.04449463  0.0479126  -0.04956055  0.09802246  0.12078857 -0.05380249
   0.0949707  -0.01792908 -0.06750488  0.03808594  0.13171387 -0.07055664
  -0.01087952  0.03466797  0.10186768 -0.09185791  0.04714966 -0.07183838
   0.01010895 -0.0045433  -0.05548096  0.10552979  0.11920166 -0.04754639
  -0.06201172 -0.01345825 -0.03775024 -0.02612305 -0.02592468  0.07879639
  -0.0139389   0.02906799 -0.0043335   0.07989502  0.08569336  0.025177
  -0.04458618  0.11169434 -0.07940674 -0.01651001 -0.04327393  0.07696533
   0.03869629 -0.05059814  0.05657959  0.03890991 -0.10961914  0.04135132
   0.01490784  0.00746918 -0.10534668  0.05535889  0.05401611  0.05328369
   0.13635254 -0.0506897   0.04302979 -0.07220459]]
After layer _mul2073_0 (1, 256) <class 'numpy.float16'> [[-0.05862427 -0.02305603 -0.02989197 -0.05490112  0.00135231 -0.09558105
   0.02981567  0.01393127 -0.0234375  -0.05706787 -0.01829529  0.04034424
   0.03814697 -0.04788208  0.04251099 -0.02516174  0.02398682  0.02032471
   0.03231812 -0.01573181  0.03283691 -0.0586853   0.01101685  0.04428101
   0.00687027 -0.00129986 -0.09667969 -0.00819397  0.00888062 -0.03775024
   0.02680969 -0.02960205  0.03173828 -0.01776123  0.02200317 -0.00337791
  -0.0803833  -0.01050568 -0.05358887 -0.00236893  0.01517487  0.01215363
   0.05718994  0.00564957  0.06359863 -0.04449463  0.04556274 -0.03765869
  -0.00588226 -0.07513428 -0.0736084  -0.02638245  0.016922    0.03799438
  -0.00508881  0.02690125 -0.05224609  0.06002808  0.01828003 -0.06311035
  -0.04208374 -0.00936127 -0.02702332 -0.04580688  0.06414795 -0.04727173
   0.04382324 -0.00073624 -0.05679321 -0.0322876  -0.07458496  0.02484131
   0.01305389 -0.03457642  0.00925446 -0.04696655 -0.03512573 -0.04690552
  -0.01905823 -0.02078247 -0.05303955 -0.0125885  -0.03485107 -0.06097412
  -0.04379272  0.03738403 -0.02580261  0.02838135 -0.02001953 -0.06994629
   0.05072021  0.00208473  0.02572632 -0.02684021  0.02906799 -0.00245857
   0.02210999  0.03656006  0.01222992  0.01585388  0.02374268  0.04330444
  -0.07128906  0.02908325 -0.03100586  0.01324463 -0.01054382 -0.06256104
   0.0480957  -0.00722504  0.05279541  0.1050415  -0.00248909  0.03033447
  -0.02420044 -0.01059723 -0.02818298 -0.06155396  0.00075817  0.03823853
   0.02114868  0.04040527 -0.03155518 -0.02032471  0.06027222 -0.04833984
  -0.02986145 -0.00959778  0.04165649  0.07806396  0.04721069  0.05163574
   0.00321007  0.04483032  0.01421356  0.03619385  0.02438354 -0.00836182
   0.03408813  0.06585693 -0.05307007 -0.01381683  0.02845764 -0.04602051
  -0.06726074  0.03710938  0.0814209  -0.04907227  0.00806427 -0.01097107
  -0.03942871 -0.01120758  0.0136795   0.00689697  0.01029205 -0.0526123
  -0.05853271  0.03210449  0.05728149  0.04193115 -0.02302551 -0.02630615
   0.02365112  0.0191803   0.02027893  0.01628113  0.0319519  -0.06396484
   0.00113773 -0.04550171 -0.02059937  0.037323   -0.02015686 -0.01251984
  -0.0319519   0.02548218  0.12030029 -0.02108765 -0.08483887 -0.0282135
  -0.00450516 -0.00830841 -0.04711914 -0.00450516  0.10296631 -0.04193115
   0.00949097 -0.05661011  0.02861023 -0.03775024  0.01236725  0.06665039
  -0.00195026  0.008255   -0.03019714  0.02322388 -0.05807495 -0.05148315
   0.02255249  0.02505493 -0.02609253  0.05130005  0.06317139 -0.02734375
   0.04763794 -0.0090332  -0.03491211  0.01875305  0.06848145 -0.03619385
  -0.00547028  0.01856995  0.05093384 -0.04577637  0.02510071 -0.0380249
   0.00517273 -0.00234222 -0.02885437  0.05599976  0.05944824 -0.02540588
  -0.03219604 -0.00691223 -0.01942444 -0.0128479  -0.01338196  0.04187012
  -0.00717545  0.01647949 -0.00214958  0.04037476  0.04202271  0.01282501
  -0.02246094  0.05737305 -0.04165649 -0.00816345 -0.02319336  0.03747559
   0.01998901 -0.02537537  0.03152466  0.02114868 -0.05441284  0.0209198
   0.0076561   0.00395203 -0.0552063   0.02919006  0.02842712  0.02880859
   0.06933594 -0.02630615  0.02081299 -0.03549194]]
After layer encoder_birnn_reverse_l0_t0_state_0 (1, 256) <class 'numpy.float16'> [[-0.05862427 -0.02305603 -0.02989197 -0.05490112  0.00135231 -0.09558105
   0.02981567  0.01393127 -0.0234375  -0.05706787 -0.01829529  0.04034424
   0.03814697 -0.04788208  0.04251099 -0.02516174  0.02398682  0.02032471
   0.03231812 -0.01573181  0.03283691 -0.0586853   0.01101685  0.04428101
   0.00687027 -0.00129986 -0.09667969 -0.00819397  0.00888062 -0.03775024
   0.02680969 -0.02960205  0.03173828 -0.01776123  0.02200317 -0.00337791
  -0.0803833  -0.01050568 -0.05358887 -0.00236893  0.01517487  0.01215363
   0.05718994  0.00564957  0.06359863 -0.04449463  0.04556274 -0.03765869
  -0.00588226 -0.07513428 -0.0736084  -0.02638245  0.016922    0.03799438
  -0.00508881  0.02690125 -0.05224609  0.06002808  0.01828003 -0.06311035
  -0.04208374 -0.00936127 -0.02702332 -0.04580688  0.06414795 -0.04727173
   0.04382324 -0.00073624 -0.05679321 -0.0322876  -0.07458496  0.02484131
   0.01305389 -0.03457642  0.00925446 -0.04696655 -0.03512573 -0.04690552
  -0.01905823 -0.02078247 -0.05303955 -0.0125885  -0.03485107 -0.06097412
  -0.04379272  0.03738403 -0.02580261  0.02838135 -0.02001953 -0.06994629
   0.05072021  0.00208473  0.02572632 -0.02684021  0.02906799 -0.00245857
   0.02210999  0.03656006  0.01222992  0.01585388  0.02374268  0.04330444
  -0.07128906  0.02908325 -0.03100586  0.01324463 -0.01054382 -0.06256104
   0.0480957  -0.00722504  0.05279541  0.1050415  -0.00248909  0.03033447
  -0.02420044 -0.01059723 -0.02818298 -0.06155396  0.00075817  0.03823853
   0.02114868  0.04040527 -0.03155518 -0.02032471  0.06027222 -0.04833984
  -0.02986145 -0.00959778  0.04165649  0.07806396  0.04721069  0.05163574
   0.00321007  0.04483032  0.01421356  0.03619385  0.02438354 -0.00836182
   0.03408813  0.06585693 -0.05307007 -0.01381683  0.02845764 -0.04602051
  -0.06726074  0.03710938  0.0814209  -0.04907227  0.00806427 -0.01097107
  -0.03942871 -0.01120758  0.0136795   0.00689697  0.01029205 -0.0526123
  -0.05853271  0.03210449  0.05728149  0.04193115 -0.02302551 -0.02630615
   0.02365112  0.0191803   0.02027893  0.01628113  0.0319519  -0.06396484
   0.00113773 -0.04550171 -0.02059937  0.037323   -0.02015686 -0.01251984
  -0.0319519   0.02548218  0.12030029 -0.02108765 -0.08483887 -0.0282135
  -0.00450516 -0.00830841 -0.04711914 -0.00450516  0.10296631 -0.04193115
   0.00949097 -0.05661011  0.02861023 -0.03775024  0.01236725  0.06665039
  -0.00195026  0.008255   -0.03019714  0.02322388 -0.05807495 -0.05148315
   0.02255249  0.02505493 -0.02609253  0.05130005  0.06317139 -0.02734375
   0.04763794 -0.0090332  -0.03491211  0.01875305  0.06848145 -0.03619385
  -0.00547028  0.01856995  0.05093384 -0.04577637  0.02510071 -0.0380249
   0.00517273 -0.00234222 -0.02885437  0.05599976  0.05944824 -0.02540588
  -0.03219604 -0.00691223 -0.01942444 -0.0128479  -0.01338196  0.04187012
  -0.00717545  0.01647949 -0.00214958  0.04037476  0.04202271  0.01282501
  -0.02246094  0.05737305 -0.04165649 -0.00816345 -0.02319336  0.03747559
   0.01998901 -0.02537537  0.03152466  0.02114868 -0.05441284  0.0209198
   0.0076561   0.00395203 -0.0552063   0.02919006  0.02842712  0.02880859
   0.06933594 -0.02630615  0.02081299 -0.03549194]]
After layer activation1036_output (1, 256) <class 'numpy.float16'> [[-0.05856323 -0.02305603 -0.02987671 -0.05484009  0.00135231 -0.09527588
   0.02980042  0.01393127 -0.0234375  -0.05700684 -0.01829529  0.04031372
   0.03811646 -0.04785156  0.04248047 -0.02516174  0.02398682  0.02032471
   0.03231812 -0.01573181  0.03283691 -0.05862427  0.01101685  0.04425049
   0.00687027 -0.00129986 -0.09637451 -0.00819397  0.00888062 -0.03771973
   0.02680969 -0.02958679  0.03173828 -0.01776123  0.02200317 -0.00337791
  -0.0802002  -0.01050568 -0.05352783 -0.00236893  0.01517487  0.01215363
   0.05712891  0.00564957  0.0635376  -0.04446411  0.04553223 -0.03762817
  -0.00588226 -0.07501221 -0.07348633 -0.02638245  0.016922    0.03796387
  -0.00508881  0.02690125 -0.05218506  0.05996704  0.01828003 -0.06304932
  -0.04205322 -0.00936127 -0.02702332 -0.04577637  0.06408691 -0.04724121
   0.04379272 -0.00073624 -0.05673218 -0.0322876  -0.07446289  0.02484131
   0.01305389 -0.03457642  0.00925446 -0.04693604 -0.03512573 -0.046875
  -0.01905823 -0.02078247 -0.05297852 -0.0125885  -0.03485107 -0.06091309
  -0.04376221  0.03735352 -0.02580261  0.02838135 -0.02001953 -0.06982422
   0.0506897   0.00208473  0.02572632 -0.02684021  0.02905273 -0.00245857
   0.02210999  0.03652954  0.01222992  0.01585388  0.02374268  0.04327393
  -0.07116699  0.02906799 -0.0309906   0.01324463 -0.01054382 -0.06246948
   0.04806519 -0.00722504  0.05273438  0.10467529 -0.00248909  0.03031921
  -0.02420044 -0.01059723 -0.02818298 -0.0614624   0.00075817  0.03820801
   0.02114868  0.04037476 -0.03155518 -0.02032471  0.06021118 -0.04830933
  -0.02984619 -0.00959778  0.04162598  0.07788086  0.04718018  0.05157471
   0.00321007  0.0447998   0.01421356  0.03616333  0.02438354 -0.00836182
   0.03408813  0.06573486 -0.05300903 -0.01381683  0.02844238 -0.04598999
  -0.06713867  0.03707886  0.08123779 -0.04904175  0.00806427 -0.01097107
  -0.03939819 -0.01120758  0.0136795   0.00689697  0.01029205 -0.05255127
  -0.05847168  0.03210449  0.05722046  0.04190063 -0.02302551 -0.02630615
   0.02365112  0.0191803   0.02027893  0.01628113  0.0319519  -0.06390381
   0.00113773 -0.04547119 -0.02059937  0.03729248 -0.02015686 -0.01251984
  -0.0319519   0.02548218  0.11975098 -0.02108765 -0.08465576 -0.0282135
  -0.00450516 -0.00830841 -0.04708862 -0.00450516  0.1026001  -0.04190063
   0.00949097 -0.05654907  0.02859497 -0.03771973  0.01236725  0.06652832
  -0.00195026  0.008255   -0.03018188  0.02322388 -0.05801392 -0.05145264
   0.02255249  0.02505493 -0.02609253  0.05126953  0.06311035 -0.02734375
   0.04760742 -0.0090332  -0.03491211  0.01875305  0.06835938 -0.03616333
  -0.00547028  0.01856995  0.05090332 -0.04574585  0.02510071 -0.03799438
   0.00517273 -0.00234222 -0.02883911  0.05593872  0.05938721 -0.02540588
  -0.03219604 -0.00691223 -0.01942444 -0.0128479  -0.01338196  0.0418396
  -0.00717545  0.01647949 -0.00214958  0.04034424  0.04199219  0.01282501
  -0.02246094  0.05731201 -0.04162598 -0.00816345 -0.02319336  0.03744507
   0.01998901 -0.02537537  0.03152466  0.02114868 -0.05435181  0.0209198
   0.0076561   0.00395203 -0.05514526  0.0291748   0.02841187  0.02879333
   0.06921387 -0.02630615  0.02081299 -0.03549194]]
After layer encoder_birnn_reverse_l0_t0_out_0 (1, 256) <class 'numpy.float16'> [[-0.02970886 -0.01194763 -0.01511383 -0.02838135  0.0007     -0.05084229
   0.01519012  0.00743484 -0.01263428 -0.0292511  -0.00892639  0.02149963
   0.01942444 -0.02441406  0.02238464 -0.01264191  0.01180267  0.01028442
   0.01543427 -0.00818634  0.01702881 -0.02944946  0.00573349  0.02171326
   0.00350571 -0.00063372 -0.05001831 -0.00417328  0.00456619 -0.01956177
   0.01311493 -0.01486206  0.01568604 -0.00918579  0.01121521 -0.00168228
  -0.04040527 -0.00548935 -0.02720642 -0.00129986  0.00836182  0.00656509
   0.02973938  0.00282669  0.03250122 -0.02288818  0.02363586 -0.01882935
  -0.00304222 -0.03842163 -0.03875732 -0.0131073   0.00892639  0.02011108
  -0.00271797  0.01379395 -0.02578735  0.03094482  0.00950623 -0.03234863
  -0.02154541 -0.00498581 -0.0140686  -0.02342224  0.03289795 -0.02375793
   0.0236969  -0.00036716 -0.03019714 -0.01751709 -0.03948975  0.0123291
   0.00642014 -0.01829529  0.00468063 -0.02523804 -0.01780701 -0.02337646
  -0.01007843 -0.01079559 -0.02659607 -0.00647354 -0.01719666 -0.03111267
  -0.02229309  0.01875305 -0.01251984  0.01481628 -0.0100708  -0.03857422
   0.02728271  0.00107765  0.01277161 -0.01413727  0.01475525 -0.00128365
   0.01143646  0.01904297  0.00614548  0.0079422   0.012146    0.02174377
  -0.03643799  0.01468658 -0.0165863   0.00683594 -0.00529861 -0.03295898
   0.0256958  -0.00377464  0.02749634  0.05664062 -0.00127029  0.01612854
  -0.01235962 -0.00540543 -0.0144043  -0.03134155  0.00041747  0.01966858
   0.01081848  0.02047729 -0.01663208 -0.01065826  0.0308075  -0.02427673
  -0.0149231  -0.00465775  0.02220154  0.03936768  0.02455139  0.02876282
   0.00157738  0.02304077  0.00752258  0.01875305  0.01270294 -0.00427628
   0.01747131  0.03393555 -0.02720642 -0.00717926  0.01522064 -0.02423096
  -0.03430176  0.01942444  0.04260254 -0.02565002  0.0039978  -0.00577545
  -0.02064514 -0.00551605  0.00696564  0.00358391  0.0052681  -0.02737427
  -0.03034973  0.01759338  0.03051758  0.02159119 -0.01197052 -0.01370239
   0.01242828  0.00999451  0.01055908  0.0078125   0.01652527 -0.03192139
   0.00061989 -0.02333069 -0.01067352  0.01901245 -0.01052094 -0.00665283
  -0.01657104  0.01316071  0.06103516 -0.01058197 -0.04373169 -0.0141449
  -0.00225067 -0.0042038  -0.02294922 -0.00239372  0.05526733 -0.02081299
   0.0049324  -0.02848816  0.01670837 -0.01989746  0.00649643  0.0319519
  -0.0010128   0.00437927 -0.01757812  0.01151276 -0.02888489 -0.0271759
   0.01145172  0.01248169 -0.01329041  0.02778625  0.03289795 -0.01377869
   0.02510071 -0.00474548 -0.01776123  0.00962067  0.03497314 -0.01861572
  -0.00306702  0.0096817   0.02575684 -0.02365112  0.01309204 -0.01945496
   0.00263214 -0.00123215 -0.01481628  0.03010559  0.03053284 -0.01325989
  -0.01644897 -0.00350952 -0.01004791 -0.00623703 -0.00696564  0.02159119
  -0.00396729  0.00918579 -0.00107384  0.02076721  0.02133179  0.00662994
  -0.01174927  0.02926636 -0.02088928 -0.00403214 -0.01184845  0.01908875
   0.01038361 -0.01324463  0.01747131  0.01171875 -0.02796936  0.01062012
   0.00388718  0.00206566 -0.03031921  0.0145874   0.01432037  0.01546478
   0.03607178 -0.01320648  0.0104599  -0.01748657]]
After layer expand_dims1042_0 (1, 1, 256) <class 'numpy.float16'> [[[-0.02970886 -0.01194763 -0.01511383 -0.02838135  0.0007     -0.05084229
    0.01519012  0.00743484 -0.01263428 -0.0292511  -0.00892639  0.02149963
    0.01942444 -0.02441406  0.02238464 -0.01264191  0.01180267  0.01028442
    0.01543427 -0.00818634  0.01702881 -0.02944946  0.00573349  0.02171326
    0.00350571 -0.00063372 -0.05001831 -0.00417328  0.00456619 -0.01956177
    0.01311493 -0.01486206  0.01568604 -0.00918579  0.01121521 -0.00168228
   -0.04040527 -0.00548935 -0.02720642 -0.00129986  0.00836182  0.00656509
    0.02973938  0.00282669  0.03250122 -0.02288818  0.02363586 -0.01882935
   -0.00304222 -0.03842163 -0.03875732 -0.0131073   0.00892639  0.02011108
   -0.00271797  0.01379395 -0.02578735  0.03094482  0.00950623 -0.03234863
   -0.02154541 -0.00498581 -0.0140686  -0.02342224  0.03289795 -0.02375793
    0.0236969  -0.00036716 -0.03019714 -0.01751709 -0.03948975  0.0123291
    0.00642014 -0.01829529  0.00468063 -0.02523804 -0.01780701 -0.02337646
   -0.01007843 -0.01079559 -0.02659607 -0.00647354 -0.01719666 -0.03111267
   -0.02229309  0.01875305 -0.01251984  0.01481628 -0.0100708  -0.03857422
    0.02728271  0.00107765  0.01277161 -0.01413727  0.01475525 -0.00128365
    0.01143646  0.01904297  0.00614548  0.0079422   0.012146    0.02174377
   -0.03643799  0.01468658 -0.0165863   0.00683594 -0.00529861 -0.03295898
    0.0256958  -0.00377464  0.02749634  0.05664062 -0.00127029  0.01612854
   -0.01235962 -0.00540543 -0.0144043  -0.03134155  0.00041747  0.01966858
    0.01081848  0.02047729 -0.01663208 -0.01065826  0.0308075  -0.02427673
   -0.0149231  -0.00465775  0.02220154  0.03936768  0.02455139  0.02876282
    0.00157738  0.02304077  0.00752258  0.01875305  0.01270294 -0.00427628
    0.01747131  0.03393555 -0.02720642 -0.00717926  0.01522064 -0.02423096
   -0.03430176  0.01942444  0.04260254 -0.02565002  0.0039978  -0.00577545
   -0.02064514 -0.00551605  0.00696564  0.00358391  0.0052681  -0.02737427
   -0.03034973  0.01759338  0.03051758  0.02159119 -0.01197052 -0.01370239
    0.01242828  0.00999451  0.01055908  0.0078125   0.01652527 -0.03192139
    0.00061989 -0.02333069 -0.01067352  0.01901245 -0.01052094 -0.00665283
   -0.01657104  0.01316071  0.06103516 -0.01058197 -0.04373169 -0.0141449
   -0.00225067 -0.0042038  -0.02294922 -0.00239372  0.05526733 -0.02081299
    0.0049324  -0.02848816  0.01670837 -0.01989746  0.00649643  0.0319519
   -0.0010128   0.00437927 -0.01757812  0.01151276 -0.02888489 -0.0271759
    0.01145172  0.01248169 -0.01329041  0.02778625  0.03289795 -0.01377869
    0.02510071 -0.00474548 -0.01776123  0.00962067  0.03497314 -0.01861572
   -0.00306702  0.0096817   0.02575684 -0.02365112  0.01309204 -0.01945496
    0.00263214 -0.00123215 -0.01481628  0.03010559  0.03053284 -0.01325989
   -0.01644897 -0.00350952 -0.01004791 -0.00623703 -0.00696564  0.02159119
   -0.00396729  0.00918579 -0.00107384  0.02076721  0.02133179  0.00662994
   -0.01174927  0.02926636 -0.02088928 -0.00403214 -0.01184845  0.01908875
    0.01038361 -0.01324463  0.01747131  0.01171875 -0.02796936  0.01062012
    0.00388718  0.00206566 -0.03031921  0.0145874   0.01432037  0.01546478
    0.03607178 -0.01320648  0.0104599  -0.01748657]]]
After layer encoder_birnn_reverse_l0_t1_i2h_output (1, 1024) <class 'numpy.float16'> [[-0.01039124  0.04135132 -0.00705338 ..., -0.0114975  -0.03637695
   0.08447266]]
After layer encoder_birnn_reverse_l0_t1_h2h_output (1, 1024) <class 'numpy.float16'> [[ 0.00780487  0.02444458 -0.00254059 ...,  0.03500366  0.03723145
   0.03427124]]
After layer _plus1037_0 (1, 1024) <class 'numpy.float16'> [[-0.00258636  0.0657959  -0.00959778 ...,  0.02349854  0.00085449
   0.11877441]]
After layer encoder_birnn_reverse_l0_t1_slice_output0 (1, 256) <class 'numpy.float16'> [[-0.00258636  0.0657959  -0.00959778  0.04681396  0.04006958  0.01611328
  -0.02850342 -0.01243591 -0.00778198  0.06115723  0.03619385  0.0546875
  -0.0581665   0.02278137  0.08392334  0.03967285 -0.08581543 -0.09777832
   0.03903198 -0.03369141  0.1161499   0.09423828 -0.0880127  -0.020401
   0.13623047 -0.01257324 -0.01495361 -0.00120544  0.03631592  0.0970459
   0.03314209 -0.06549072  0.17126465  0.05554199  0.08508301  0.0814209
   0.01956177  0.03424072  0.09741211  0.10015869  0.0982666   0.0368042
  -0.03173828  0.02429199  0.02761841  0.03918457  0.11572266 -0.02462769
   0.02713013  0.01274872  0.09356689  0.13671875  0.06121826  0.14257812
   0.17651367  0.06039429 -0.06082153 -0.0557251  -0.05462646  0.04486084
   0.04138184  0.00716019 -0.02581787  0.11358643  0.07568359  0.05685425
   0.14855957 -0.06835938  0.15649414  0.07092285  0.0824585  -0.00836182
   0.02301025  0.05609131  0.10083008  0.27758789  0.01086426 -0.00674438
  -0.04159546 -0.0191803   0.04095459  0.07397461  0.00076294  0.03485107
   0.05975342  0.00924683  0.06549072  0.0430603   0.19018555 -0.04550171
   0.10571289 -0.05221558  0.01070404 -0.04370117  0.01039886  0.008255
  -0.0473938   0.21472168 -0.11480713  0.0302124   0.06555176  0.01480865
   0.09814453  0.04974365  0.05316162  0.0131073   0.0557251   0.00640869
   0.08178711  0.06787109 -0.05456543  0.0770874   0.04351807  0.20678711
   0.04333496  0.1361084  -0.03015137 -0.021698    0.12213135  0.01249695
   0.05175781  0.02822876  0.04400635  0.05804443  0.06604004  0.13024902
  -0.05117798 -0.00300598  0.09234619 -0.10668945  0.13061523  0.24987793
   0.1171875   0.015625    0.12548828  0.04754639 -0.08148193  0.07745361
  -0.10144043 -0.11834717 -0.01408386  0.08081055  0.01470947 -0.09564209
  -0.0289917   0.16809082  0.01403809 -0.01211548  0.01663208  0.04760742
   0.00813293  0.05725098 -0.02510071 -0.02832031  0.01390076  0.20666504
   0.01529694  0.08093262  0.05145264 -0.00147247  0.13000488 -0.00660706
   0.0592041   0.02008057 -0.00382233  0.10418701 -0.03601074  0.05032349
   0.11590576 -0.08343506 -0.00312805  0.11993408  0.07617188  0.13049316
   0.11114502 -0.05551147  0.00860596  0.07299805 -0.01306152 -0.00392151
   0.03625488 -0.01052094  0.04101562 -0.01971436  0.05010986  0.081604
   0.08050537  0.00463867  0.24658203 -0.00622559 -0.00386047  0.04486084
  -0.05081177 -0.11132812  0.06616211 -0.00622559 -0.04464722 -0.03622437
   0.0982666  -0.05264282  0.04049683  0.24462891  0.10681152  0.00549316
   0.07531738  0.07885742  0.02441406 -0.02157593 -0.01301575  0.08642578
   0.10394287  0.15759277 -0.00660706  0.1517334   0.07287598 -0.07080078
   0.07067871 -0.17504883  0.07061768  0.1328125  -0.02296448 -0.03265381
   0.09442139 -0.01675415 -0.03857422  0.09106445 -0.02151489 -0.03710938
  -0.11883545  0.20532227  0.11224365 -0.05010986  0.13525391 -0.03417969
   0.06695557  0.07489014 -0.01655579  0.03851318  0.00675964 -0.02914429
  -0.09594727 -0.04241943  0.1965332   0.23791504  0.01748657 -0.03985596
  -0.03631592  0.00491333  0.07043457  0.05639648  0.02612305 -0.00527954
  -0.03536987  0.05310059  0.02096558  0.10925293]]
After layer encoder_birnn_reverse_l0_t1_slice_output1 (1, 256) <class 'numpy.float16'> [[ -1.69830322e-02   3.21655273e-02   8.39843750e-02   5.90209961e-02
    8.38623047e-02   5.29785156e-02   1.19750977e-01  -6.79931641e-02
    1.65893555e-01   6.02111816e-02   6.70166016e-02   1.62109375e-01
    4.03747559e-02   9.94262695e-02   5.95092773e-02   1.43188477e-01
    7.72705078e-02   1.44042969e-01   5.89904785e-02   1.04492188e-01
    1.41357422e-01   1.77001953e-03   3.03955078e-01   8.36181641e-02
   -1.89208984e-02   9.48486328e-02   1.63269043e-02   1.50375366e-02
    8.11767578e-02  -4.11987305e-02   7.50732422e-02   7.26318359e-02
    1.38183594e-01   3.21044922e-02  -2.70080566e-03  -4.87976074e-02
    8.88671875e-02   1.76269531e-01   1.60675049e-02   5.78613281e-02
   -2.70385742e-02   6.45141602e-02   1.23535156e-01   1.60400391e-01
    4.87060547e-02   2.03247070e-02   1.07421875e-01   8.19091797e-02
    1.36260986e-02   5.09643555e-02   6.31103516e-02   7.27539062e-02
    5.93566895e-02   9.83886719e-02   1.58691406e-01   2.01568604e-02
    2.16674805e-03   6.59790039e-02   2.88085938e-02   6.65283203e-02
    4.63867188e-02   1.20849609e-01   5.87463379e-03   4.04968262e-02
    6.76269531e-02   1.41601562e-01   2.00683594e-01   9.48486328e-02
   -4.43725586e-02   8.14208984e-02   1.07238770e-01   6.71997070e-02
    3.42102051e-02  -3.06396484e-02   1.28662109e-01   1.55273438e-01
    8.32519531e-02  -1.34277344e-03   6.84814453e-02   1.04431152e-01
    4.52880859e-02   1.01867676e-01  -3.23486328e-02  -2.85797119e-02
    1.04064941e-02   1.17187500e-01   3.44238281e-02   7.53173828e-02
    1.09130859e-01  -4.94384766e-03   2.06787109e-01   9.49096680e-02
    7.22045898e-02   6.54907227e-02   7.42797852e-02  -6.21032715e-02
    1.09405518e-02   1.53442383e-01  -2.70690918e-02   3.36608887e-02
    1.12609863e-02   4.60205078e-02   2.27355957e-02   1.41845703e-01
    1.38854980e-03  -3.76892090e-02   1.44119263e-02   1.13891602e-01
    7.49206543e-03   7.49206543e-03   7.95288086e-02   5.63354492e-02
    4.08935547e-02   1.26586914e-01   5.98144531e-02   9.69238281e-02
    2.95562744e-02   1.83105469e-03   5.70678711e-02   1.71051025e-02
    1.44287109e-01   2.46704102e-01   7.03735352e-02   5.62133789e-02
   -1.51672363e-02   7.53784180e-02   4.61730957e-02   4.51660156e-02
    1.08642578e-02  -2.22320557e-02   1.23291016e-01   1.49902344e-01
    5.48095703e-02   1.64184570e-02   1.11145020e-01   9.00878906e-02
    1.57958984e-01   7.91625977e-02   6.26220703e-02   7.11059570e-02
    1.91345215e-02   1.10656738e-01   1.06079102e-01   7.32421875e-02
    1.20773315e-02   2.78625488e-02  -4.86145020e-02   5.17272949e-02
    6.35986328e-02   4.96215820e-02   8.91113281e-02   7.14111328e-02
    1.58447266e-01   8.15429688e-02   4.93164062e-02   1.33666992e-01
    5.09033203e-02   2.44140625e-04   5.03540039e-02   1.42822266e-01
    4.78515625e-02   5.37109375e-02   4.80041504e-02   1.51977539e-01
   -3.36303711e-02   5.60913086e-02   3.31542969e-01   2.90527344e-02
   -1.15966797e-01   4.49523926e-02   1.20788574e-01   8.53271484e-02
    4.34265137e-02   1.93603516e-01   5.02319336e-02   2.02636719e-02
    7.59277344e-02   2.99682617e-02   7.52258301e-03  -3.87573242e-03
   -1.93786621e-02   1.03027344e-01   8.55712891e-02   9.23156738e-04
    5.79223633e-02  -4.93774414e-02   5.39855957e-02   6.01806641e-02
    4.95605469e-02  -4.38537598e-02   9.57641602e-02   7.46459961e-02
    1.08398438e-01   2.90527344e-02   1.52343750e-01  -4.09851074e-02
    2.38037109e-02   4.78210449e-02   6.26220703e-02   1.80969238e-02
    9.60693359e-02   4.62646484e-02   8.33740234e-02   1.30615234e-01
    4.77600098e-02   4.99267578e-02   1.67694092e-02   1.42089844e-01
    6.07299805e-03   1.06628418e-01   7.58666992e-02   1.65283203e-01
   -7.06481934e-03   1.08154297e-01  -4.83703613e-02   2.09350586e-02
    2.14843750e-01   4.80346680e-02   1.33544922e-01   1.08703613e-01
   -2.89916992e-02  -1.96838379e-02   1.42089844e-01   6.68945312e-02
    7.50732422e-02   9.16748047e-02   4.70886230e-02   3.39355469e-02
    2.11425781e-01   1.16516113e-01   1.43432617e-02   3.48815918e-02
    7.18994141e-02   3.06243896e-02  -6.93359375e-02   1.51855469e-01
    8.70361328e-02   9.39941406e-02   5.45349121e-02   8.39843750e-02
    1.51672363e-02   1.88232422e-01   1.71386719e-01   1.35864258e-01
   -5.83190918e-02   3.20739746e-02   8.62121582e-03   1.06811523e-04
    8.10546875e-02   4.77600098e-02   1.40869141e-01   4.27551270e-02
    9.14306641e-02   3.75671387e-02   1.34033203e-01  -4.32739258e-02]]
After layer encoder_birnn_reverse_l0_t1_slice_output2 (1, 256) <class 'numpy.float16'> [[-0.04382324 -0.03056335  0.09216309  0.09973145  0.10400391  0.03582764
   0.01156616 -0.00546265 -0.0838623  -0.12121582 -0.05328369  0.00741577
   0.07202148 -0.06323242  0.08306885 -0.11199951 -0.00616455 -0.06112671
  -0.00163269  0.08630371  0.11120605 -0.0736084   0.03717041  0.01383972
   0.02415466  0.00818634 -0.05084229  0.02420044 -0.04586792 -0.03231812
   0.06811523 -0.12133789  0.05029297 -0.08044434  0.03024292 -0.12597656
  -0.01245117 -0.08361816  0.02114868  0.05032349  0.1104126   0.00927734
   0.03424072  0.02111816  0.05847168 -0.08935547  0.04058838  0.00628662
  -0.00476074  0.09295654 -0.00460815 -0.07080078 -0.0836792   0.01751709
   0.06970215 -0.06585693 -0.04541016  0.13452148  0.02761841 -0.07141113
  -0.09564209 -0.03662109 -0.01473236  0.01171875  0.14331055 -0.01971436
   0.10235596  0.09741211 -0.02502441  0.00987244 -0.14086914  0.09802246
   0.02682495 -0.04675293  0.13232422  0.01197052 -0.17163086 -0.0506897
  -0.08062744 -0.03756714 -0.00854492 -0.0892334   0.01983643 -0.11181641
  -0.09576416  0.04064941 -0.02401733  0.04193115 -0.04794312  0.03405762
   0.03262329  0.03372192  0.02259827 -0.06237793 -0.0512085  -0.02537537
  -0.01150513 -0.11767578 -0.01068115 -0.06262207  0.11572266  0.02450562
  -0.04403687  0.01061249 -0.0512085   0.08764648 -0.02545166  0.02658081
  -0.01965332 -0.01348877  0.08361816  0.01469421  0.0206604   0.07958984
  -0.08111572  0.03234863 -0.05560303 -0.05264282  0.090271    0.04296875
   0.03479004  0.08166504  0.01591492 -0.09259033  0.03265381 -0.11743164
   0.1282959  -0.12414551 -0.02122498  0.10168457  0.06555176 -0.09051514
   0.04998779 -0.15039062  0.06866455  0.05273438  0.08947754  0.12695312
  -0.07080078  0.0385437  -0.00653076 -0.04620361  0.11114502  0.00613403
   0.05670166  0.01629639  0.03930664 -0.07818604  0.01959229  0.04498291
  -0.01675415 -0.00661469 -0.08483887 -0.0446167   0.07244873  0.06057739
  -0.0199585   0.00082397 -0.01548767  0.0413208  -0.20825195 -0.0880127
  -0.0435791  -0.03115845 -0.02816772  0.0892334  -0.04052734 -0.12463379
  -0.16394043 -0.07702637 -0.10235596  0.05181885 -0.01635742 -0.0826416
   0.05621338 -0.01332855  0.08978271 -0.08520508 -0.03546143 -0.02787781
   0.13195801  0.05670166  0.0871582  -0.00693512  0.04473877 -0.05004883
   0.01208496 -0.10046387  0.04956055 -0.00820923  0.21777344  0.05499268
  -0.0645752  -0.00241089 -0.15454102  0.05221558 -0.08959961 -0.10632324
   0.03997803  0.10510254 -0.04321289 -0.0958252   0.08630371 -0.01132202
   0.07531738 -0.03497314  0.02560425 -0.01811218  0.17053223 -0.09429932
   0.02874756  0.08892822  0.02429199  0.02880859 -0.08300781 -0.05703735
  -0.02658081 -0.00204468  0.07965088  0.05551147  0.01997375  0.04205322
   0.09777832 -0.07592773  0.01100159  0.00976562  0.02409363 -0.03295898
   0.02185059 -0.00173187 -0.08117676 -0.02392578  0.04760742  0.02020264
  -0.06604004 -0.02243042 -0.03942871  0.0428772  -0.08117676  0.01553345
  -0.01594543 -0.05889893 -0.00157166 -0.12573242 -0.02850342 -0.06097412
  -0.01728821 -0.01467896  0.0166626   0.15087891  0.1574707   0.02302551
  -0.01547241 -0.00341797  0.01483154 -0.09344482]]
After layer encoder_birnn_reverse_l0_t1_slice_output3 (1, 256) <class 'numpy.float16'> [[ 0.06793213  0.12902832  0.0284729   0.10083008  0.11547852  0.01702881
   0.13537598  0.07556152  0.18457031  0.08612061 -0.00533295  0.05078125
   0.09161377  0.02729797  0.06695557  0.04040527  0.05020142  0.0690918
   0.02574158  0.09191895 -0.03833008  0.03674316  0.27587891  0.06274414
   0.03829956  0.08581543  0.11096191 -0.00069427  0.03265381  0.12927246
   0.05255127  0.05773926  0.20141602  0.0305481   0.06671143  0.04046631
   0.01053619  0.06469727 -0.02104187  0.00302124  0.18652344  0.04974365
   0.04367065 -0.01589966 -0.00469971  0.10473633  0.13745117  0.01379395
   0.00843811  0.02728271  0.0333252   0.02392578 -0.05053711  0.11523438
   0.13256836  0.03387451 -0.07781982  0.05044556 -0.0030365   0.12213135
   0.08966064  0.1081543   0.02185059  0.11010742  0.07629395  0.06677246
   0.30712891  0.09863281  0.07427979  0.19042969 -0.01754761  0.02189636
   0.01742554  0.01605225  0.06744385  0.17553711  0.0958252  -0.00085449
   0.05276489  0.06799316  0.03686523  0.09973145  0.08972168  0.03173828
   0.08728027  0.07513428  0.04504395  0.07397461  0.1229248   0.07299805
   0.15551758 -0.01304626  0.01262665 -0.00921631 -0.01689148  0.09674072
   0.02168274  0.23681641  0.0009613  -0.00715637  0.13305664 -0.04968262
   0.03056335 -0.00378418  0.03503418  0.06500244 -0.04223633  0.08642578
   0.03118896  0.08251953  0.00097656  0.06396484 -0.00740814  0.08642578
   0.05578613  0.08856201 -0.06567383  0.04147339  0.12426758  0.04998779
   0.06008911 -0.01715088 -0.00970459  0.0871582   0.04296875  0.00175476
   0.0925293  -0.03100586  0.02990723  0.01603699  0.08972168  0.27587891
   0.07409668  0.12219238  0.11230469  0.0075531   0.05731201  0.03649902
  -0.00469971 -0.02789307  0.05273438  0.04202271  0.06021118  0.02941895
   0.10620117  0.00152588  0.07568359 -0.0199585   0.08251953  0.04946899
   0.01748657 -0.10235596 -0.01519775  0.02337646  0.04968262  0.12438965
   0.01983643  0.15393066  0.02754211  0.11505127  0.09039307  0.01358032
   0.14282227  0.07287598  0.15820312 -0.01022339  0.2388916   0.12145996
  -0.01591492 -0.14013672  0.06231689  0.09967041  0.05627441  0.26025391
   0.17224121  0.07305908  0.06112671  0.11657715 -0.01045227  0.
  -0.04293823 -0.01976013  0.06384277 -0.03005981  0.08886719  0.16577148
  -0.05105591  0.05322266  0.24523926  0.03314209 -0.07330322  0.1385498
   0.08666992 -0.00143433  0.08453369 -0.0308075   0.10186768  0.08093262
   0.08203125  0.0254364   0.12927246  0.23657227  0.12145996  0.09631348
   0.07006836  0.06243896 -0.01564026 -0.01879883  0.02357483  0.1451416
   0.04779053  0.2467041   0.08642578  0.02606201  0.06274414  0.02676392
  -0.029953    0.00390625 -0.01441956  0.03009033  0.02526855  0.01483154
   0.04498291  0.04486084  0.10736084  0.09283447  0.04696655  0.05990601
   0.16491699  0.24523926  0.05136108  0.01156616  0.04577637  0.01272583
   0.09130859  0.01759338  0.03811646 -0.02545166  0.20654297  0.08410645
  -0.11096191  0.0916748   0.1953125   0.36962891  0.02832031  0.14489746
  -0.00793457  0.07043457  0.06066895 -0.06036377  0.00701904  0.07019043
   0.11169434  0.02349854  0.00085449  0.11877441]]
After layer encoder_birnn_reverse_l0_t1_o_output (1, 256) <class 'numpy.float16'> [[ 0.51708984  0.53222656  0.50732422  0.52539062  0.52880859  0.50439453
   0.53369141  0.51904297  0.54589844  0.52148438  0.4987793   0.51269531
   0.52294922  0.50683594  0.51660156  0.51025391  0.51269531  0.51708984
   0.50634766  0.52294922  0.49047852  0.50927734  0.56835938  0.515625
   0.50976562  0.52148438  0.52783203  0.49975586  0.50830078  0.53222656
   0.51318359  0.51464844  0.55029297  0.5078125   0.51660156  0.51025391
   0.50244141  0.51611328  0.49462891  0.50097656  0.54638672  0.51220703
   0.51074219  0.49609375  0.4987793   0.52636719  0.53417969  0.50341797
   0.50195312  0.50683594  0.50830078  0.50585938  0.48730469  0.52880859
   0.53320312  0.50830078  0.48046875  0.51269531  0.49926758  0.53027344
   0.52246094  0.52685547  0.50537109  0.52734375  0.51904297  0.51660156
   0.57617188  0.52441406  0.51855469  0.54736328  0.49560547  0.50537109
   0.50439453  0.50390625  0.51708984  0.54394531  0.52392578  0.49975586
   0.51318359  0.51708984  0.50927734  0.52490234  0.52246094  0.5078125
   0.52197266  0.51855469  0.51123047  0.51855469  0.53076172  0.51806641
   0.53857422  0.49682617  0.50292969  0.49780273  0.49584961  0.52392578
   0.50537109  0.55908203  0.5         0.49829102  0.53320312  0.48754883
   0.5078125   0.49902344  0.50878906  0.51611328  0.48950195  0.52148438
   0.5078125   0.52050781  0.5         0.51611328  0.49804688  0.52148438
   0.51416016  0.52197266  0.48364258  0.51025391  0.53125     0.51269531
   0.51513672  0.49560547  0.49755859  0.52197266  0.51074219  0.50048828
   0.52294922  0.4921875   0.50732422  0.50390625  0.52246094  0.56835938
   0.51855469  0.53027344  0.52783203  0.50195312  0.51416016  0.50927734
   0.4987793   0.49291992  0.51318359  0.51074219  0.51513672  0.50732422
   0.52636719  0.50048828  0.51904297  0.49511719  0.52050781  0.51220703
   0.50439453  0.47436523  0.49609375  0.50585938  0.51220703  0.53125
   0.50488281  0.53857422  0.50683594  0.52880859  0.52246094  0.50341797
   0.53564453  0.51806641  0.53955078  0.49755859  0.55957031  0.53027344
   0.49609375  0.46508789  0.515625    0.52490234  0.51416016  0.56494141
   0.54296875  0.51806641  0.51513672  0.52929688  0.49731445  0.5
   0.48925781  0.49511719  0.51611328  0.49243164  0.52197266  0.54150391
   0.48730469  0.51318359  0.56103516  0.50830078  0.48168945  0.53466797
   0.52148438  0.49975586  0.52099609  0.4921875   0.52539062  0.52001953
   0.52050781  0.50634766  0.53222656  0.55908203  0.53027344  0.52392578
   0.51757812  0.515625    0.49609375  0.49536133  0.50585938  0.53613281
   0.51171875  0.56152344  0.52148438  0.50634766  0.515625    0.50683594
   0.49243164  0.50097656  0.49633789  0.50732422  0.50634766  0.50390625
   0.51123047  0.51123047  0.52685547  0.52294922  0.51171875  0.51513672
   0.54101562  0.56103516  0.51269531  0.50292969  0.51123047  0.50341797
   0.52294922  0.50439453  0.50976562  0.49365234  0.55126953  0.52099609
   0.47216797  0.52294922  0.54882812  0.59130859  0.50683594  0.53613281
   0.49804688  0.51757812  0.51513672  0.48486328  0.50195312  0.51757812
   0.52783203  0.50585938  0.5         0.52978516]]
After layer encoder_birnn_reverse_l0_t1_f_output (1, 256) <class 'numpy.float16'> [[ 0.49584961  0.5078125   0.52099609  0.51464844  0.52099609  0.51318359
   0.52978516  0.48291016  0.54150391  0.51513672  0.51660156  0.54052734
   0.51025391  0.52490234  0.51464844  0.53564453  0.51953125  0.53613281
   0.51464844  0.52587891  0.53515625  0.50048828  0.57519531  0.52099609
   0.49536133  0.52392578  0.50390625  0.50390625  0.52050781  0.48974609
   0.51855469  0.51806641  0.53466797  0.5078125   0.49926758  0.48779297
   0.52197266  0.54394531  0.50390625  0.51464844  0.49316406  0.51611328
   0.53076172  0.54003906  0.51220703  0.50488281  0.52685547  0.52050781
   0.50341797  0.51269531  0.515625    0.51806641  0.51464844  0.52441406
   0.53955078  0.50488281  0.50048828  0.51660156  0.50732422  0.51660156
   0.51171875  0.53027344  0.50146484  0.51025391  0.51708984  0.53515625
   0.54980469  0.52392578  0.48901367  0.52050781  0.52685547  0.51660156
   0.50878906  0.49243164  0.53222656  0.53857422  0.52099609  0.49975586
   0.51708984  0.52587891  0.51123047  0.52539062  0.49194336  0.49291992
   0.50244141  0.52929688  0.50878906  0.51904297  0.52734375  0.4987793
   0.55126953  0.52392578  0.51806641  0.51660156  0.51855469  0.484375
   0.50292969  0.53808594  0.49316406  0.50830078  0.50292969  0.51171875
   0.50585938  0.53564453  0.50048828  0.49047852  0.50341797  0.52832031
   0.50195312  0.50195312  0.52001953  0.51416016  0.51025391  0.53173828
   0.51513672  0.52441406  0.50732422  0.50048828  0.51416016  0.50439453
   0.53613281  0.56152344  0.51757812  0.51416016  0.49609375  0.51904297
   0.51171875  0.51123047  0.50292969  0.49438477  0.53076172  0.53759766
   0.51367188  0.50390625  0.52783203  0.52246094  0.53955078  0.52001953
   0.515625    0.51757812  0.50488281  0.52783203  0.52636719  0.51806641
   0.50292969  0.50683594  0.48779297  0.51269531  0.51611328  0.51220703
   0.52246094  0.51806641  0.53955078  0.52050781  0.51220703  0.53320312
   0.51269531  0.5         0.51269531  0.53564453  0.51171875  0.51318359
   0.51220703  0.53808594  0.49169922  0.51416016  0.58203125  0.50732422
   0.47094727  0.51123047  0.53027344  0.52148438  0.51074219  0.54833984
   0.51269531  0.50488281  0.51904297  0.50732422  0.50195312  0.49902344
   0.49511719  0.52587891  0.52148438  0.5         0.51464844  0.48754883
   0.51367188  0.51513672  0.51220703  0.48901367  0.52392578  0.51855469
   0.52685547  0.50732422  0.53808594  0.48974609  0.50585938  0.51171875
   0.515625    0.50439453  0.52392578  0.51171875  0.52099609  0.53271484
   0.51171875  0.51269531  0.50439453  0.53564453  0.50146484  0.52685547
   0.51904297  0.54101562  0.49829102  0.52685547  0.48779297  0.50537109
   0.55371094  0.51220703  0.53320312  0.52734375  0.49267578  0.49511719
   0.53564453  0.51660156  0.51855469  0.52294922  0.51171875  0.50830078
   0.55273438  0.52929688  0.50341797  0.50878906  0.51806641  0.5078125
   0.48266602  0.53808594  0.52197266  0.5234375   0.51367188  0.52099609
   0.50390625  0.546875    0.54296875  0.53369141  0.48535156  0.5078125
   0.50195312  0.5         0.52001953  0.51171875  0.53515625  0.51074219
   0.52294922  0.50927734  0.53369141  0.48925781]]
After layer _mul2074_0 (1, 256) <class 'numpy.float16'> [[-0.02906799 -0.01171112 -0.01557159 -0.02825928  0.00070477 -0.04904175
   0.01579285  0.00672913 -0.01269531 -0.02940369 -0.00945282  0.02180481
   0.01947021 -0.02513123  0.0218811  -0.01348114  0.0124588   0.01089478
   0.01663208 -0.00827026  0.01757812 -0.02937317  0.00633621  0.02307129
   0.00340271 -0.00068092 -0.04870605 -0.0041275   0.00462341 -0.01849365
   0.01390076 -0.01533508  0.01696777 -0.00901794  0.01098633 -0.00164795
  -0.04196167 -0.00571442 -0.02700806 -0.0012188   0.00748444  0.00627136
   0.03034973  0.00305176  0.03256226 -0.02246094  0.02400208 -0.01960754
  -0.00296211 -0.03851318 -0.03796387 -0.01366425  0.00870514  0.01992798
  -0.00274658  0.01358032 -0.02615356  0.03100586  0.00927734 -0.03259277
  -0.02153015 -0.00496292 -0.0135498  -0.02337646  0.03317261 -0.02529907
   0.02409363 -0.00038576 -0.027771   -0.01679993 -0.03930664  0.01283264
   0.00664139 -0.01702881  0.00492477 -0.02529907 -0.01829529 -0.0234375
  -0.00985718 -0.01092529 -0.02711487 -0.00661469 -0.01715088 -0.03005981
  -0.02200317  0.01979065 -0.01313019  0.01473236 -0.01055908 -0.03488159
   0.0279541   0.00109196  0.01332855 -0.01386261  0.01507568 -0.00119114
   0.01111603  0.01966858  0.00603104  0.00805664  0.01194     0.02215576
  -0.03607178  0.01557922 -0.01551819  0.00649643 -0.00530624 -0.03305054
   0.0241394  -0.00362587  0.02745056  0.05401611 -0.00127029  0.01612854
  -0.01246643 -0.00555801 -0.01429749 -0.0308075   0.00038981  0.01928711
   0.01133728  0.02268982 -0.0163269  -0.01045227  0.02990723 -0.02508545
  -0.01528168 -0.0049057   0.02095032  0.03860474  0.02505493  0.02775574
   0.0016489   0.02258301  0.00750351  0.01890564  0.01315308 -0.00434875
   0.01757812  0.03408813 -0.02679443 -0.0072937   0.0149765  -0.02383423
  -0.03381348  0.01881409  0.03970337 -0.02516174  0.00416183 -0.00561905
  -0.02059937 -0.00580597  0.00738144  0.00358963  0.00527191 -0.02804565
  -0.03001404  0.01605225  0.02937317  0.02246094 -0.01177979 -0.0134964
   0.01211548  0.01032257  0.00997162  0.00836945  0.01860046 -0.03244019
   0.00053596 -0.02325439 -0.01092529  0.01947021 -0.01029205 -0.00686646
  -0.01638794  0.01286316  0.06243896 -0.01069641 -0.04257202 -0.01407623
  -0.00222969 -0.00436783 -0.02456665 -0.00225258  0.05297852 -0.02044678
   0.00487518 -0.02915955  0.01465607 -0.01846313  0.00648117  0.03457642
  -0.00102711  0.00418854 -0.01625061  0.01137543 -0.02937317 -0.02635193
   0.0116272   0.01263428 -0.01367188  0.02624512  0.03289795 -0.01456451
   0.02438354 -0.00463104 -0.01760864  0.01004791  0.03433228 -0.01907349
  -0.00284004  0.01004791  0.02537537 -0.02412415  0.01224518 -0.01921082
   0.00286484 -0.00119972 -0.01538849  0.02952576  0.02928162 -0.01258087
  -0.01724243 -0.00357056 -0.0100708  -0.00671768 -0.00684738  0.02128601
  -0.00396729  0.0087204  -0.00108242  0.02053833  0.02177429  0.00651169
  -0.01084137  0.03086853 -0.02174377 -0.00427246 -0.01191711  0.01953125
   0.0100708  -0.01387787  0.01712036  0.01128387 -0.02641296  0.01062012
   0.00384331  0.00197601 -0.02870178  0.01493835  0.01521301  0.0147171
   0.03625488 -0.01339722  0.0111084  -0.0173645 ]]
After layer encoder_birnn_reverse_l0_t1_i_output (1, 256) <class 'numpy.float16'> [[ 0.49926758  0.51660156  0.49755859  0.51171875  0.51025391  0.50390625
   0.49291992  0.49682617  0.49804688  0.51513672  0.50927734  0.51367188
   0.48535156  0.50585938  0.52099609  0.50976562  0.47851562  0.47558594
   0.50976562  0.49169922  0.52880859  0.5234375   0.47802734  0.49487305
   0.53417969  0.49682617  0.49633789  0.49975586  0.50927734  0.52441406
   0.50830078  0.48364258  0.54248047  0.51367188  0.52148438  0.52050781
   0.50488281  0.50878906  0.52441406  0.52490234  0.52441406  0.50927734
   0.4921875   0.50585938  0.50683594  0.50976562  0.52880859  0.49389648
   0.50683594  0.50341797  0.5234375   0.53417969  0.51513672  0.53564453
   0.54394531  0.51513672  0.48486328  0.48608398  0.48632812  0.51123047
   0.51025391  0.50195312  0.49365234  0.52832031  0.51904297  0.51416016
   0.53710938  0.48291016  0.5390625   0.51757812  0.52050781  0.49780273
   0.50585938  0.51416016  0.52539062  0.56884766  0.50292969  0.49829102
   0.48950195  0.49511719  0.51025391  0.51855469  0.5         0.50878906
   0.51513672  0.50244141  0.51660156  0.51074219  0.54736328  0.48852539
   0.52636719  0.48706055  0.50244141  0.48901367  0.50244141  0.50195312
   0.48803711  0.55371094  0.47143555  0.50732422  0.51660156  0.50390625
   0.52441406  0.51220703  0.51318359  0.50341797  0.51416016  0.50146484
   0.52050781  0.51708984  0.48632812  0.51904297  0.51074219  0.55126953
   0.51074219  0.53417969  0.49243164  0.49462891  0.53027344  0.50292969
   0.51269531  0.50683594  0.51123047  0.51464844  0.51660156  0.53271484
   0.48730469  0.49926758  0.52294922  0.47338867  0.53271484  0.56201172
   0.52929688  0.50390625  0.53125     0.51171875  0.47973633  0.51953125
   0.47460938  0.47045898  0.49658203  0.52001953  0.50390625  0.47607422
   0.49267578  0.54199219  0.50341797  0.49707031  0.50439453  0.51171875
   0.50195312  0.51416016  0.49365234  0.49291992  0.50341797  0.55126953
   0.50390625  0.52001953  0.51269531  0.49951172  0.53222656  0.49829102
   0.51464844  0.50488281  0.49902344  0.52587891  0.4909668   0.51269531
   0.52880859  0.47924805  0.49926758  0.52978516  0.51904297  0.53271484
   0.52783203  0.48608398  0.50195312  0.51806641  0.49682617  0.49902344
   0.50927734  0.49731445  0.51025391  0.49511719  0.51269531  0.52050781
   0.52001953  0.50097656  0.56152344  0.49853516  0.49902344  0.51123047
   0.48730469  0.47216797  0.51660156  0.49853516  0.48876953  0.4909668
   0.52441406  0.48681641  0.51025391  0.56103516  0.52685547  0.50146484
   0.51904297  0.51953125  0.50585938  0.49462891  0.49682617  0.52148438
   0.52587891  0.53955078  0.49829102  0.53808594  0.51806641  0.48242188
   0.51757812  0.45629883  0.51757812  0.53320312  0.49414062  0.49194336
   0.5234375   0.49584961  0.49047852  0.52294922  0.49462891  0.49072266
   0.47021484  0.55126953  0.52783203  0.48754883  0.53369141  0.49145508
   0.51660156  0.51855469  0.49584961  0.50976562  0.50146484  0.49267578
   0.47607422  0.48950195  0.54882812  0.55908203  0.50439453  0.48999023
   0.4909668   0.50146484  0.51757812  0.51416016  0.50634766  0.4987793
   0.49121094  0.51318359  0.50537109  0.52734375]]
After layer encoder_birnn_reverse_l0_t1_c_output (1, 256) <class 'numpy.float16'> [[-0.04379272 -0.0305481   0.09191895  0.09942627  0.1036377   0.03579712
   0.01156616 -0.00546265 -0.0836792  -0.12060547 -0.05322266  0.00741577
   0.07189941 -0.06317139  0.08288574 -0.11151123 -0.00616455 -0.06106567
  -0.00163269  0.08605957  0.11077881 -0.07348633  0.03713989  0.01383972
   0.02415466  0.00818634 -0.05081177  0.02420044 -0.0458374  -0.03231812
   0.06799316 -0.12072754  0.05026245 -0.08026123  0.03022766 -0.12536621
  -0.01245117 -0.08343506  0.02114868  0.05029297  0.10998535  0.00927734
   0.03424072  0.02111816  0.05841064 -0.08911133  0.04055786  0.00628662
  -0.00476074  0.0927124  -0.00460815 -0.07067871 -0.08349609  0.01751709
   0.06958008 -0.06573486 -0.04537964  0.13366699  0.02761841 -0.07128906
  -0.09533691 -0.03659058 -0.01473236  0.01171875  0.14233398 -0.01971436
   0.10198975  0.09710693 -0.02502441  0.00987244 -0.13989258  0.09771729
   0.02682495 -0.04672241  0.1315918   0.01197052 -0.16992188 -0.05065918
  -0.08044434 -0.03753662 -0.00854492 -0.08898926  0.01983643 -0.11132812
  -0.09545898  0.0406189  -0.02401733  0.04190063 -0.0479126   0.03405762
   0.03262329  0.03372192  0.02259827 -0.06228638 -0.05117798 -0.02537537
  -0.01150513 -0.11712646 -0.01068115 -0.06256104  0.11523438  0.02450562
  -0.04400635  0.01061249 -0.05117798  0.08740234 -0.02545166  0.02658081
  -0.01965332 -0.01348877  0.08343506  0.01469421  0.0206604   0.07940674
  -0.08093262  0.03234863 -0.05554199 -0.05258179  0.09002686  0.04293823
   0.03479004  0.08148193  0.01591492 -0.09234619  0.03265381 -0.11688232
   0.12756348 -0.12353516 -0.02122498  0.10131836  0.06542969 -0.090271
   0.04995728 -0.14929199  0.06854248  0.05267334  0.0892334   0.1262207
  -0.07067871  0.03851318 -0.00653076 -0.0461731   0.11071777  0.00613403
   0.05664062  0.01629639  0.03927612 -0.07800293  0.01959229  0.04495239
  -0.01675415 -0.00661469 -0.08465576 -0.04458618  0.07232666  0.06051636
  -0.0199585   0.00082397 -0.01548767  0.04129028 -0.20532227 -0.08776855
  -0.04354858 -0.03114319 -0.02816772  0.08898926 -0.04049683 -0.1239624
  -0.16247559 -0.0769043  -0.10198975  0.05175781 -0.01635742 -0.0824585
   0.05615234 -0.01332855  0.08953857 -0.08502197 -0.03546143 -0.02787781
   0.13122559  0.05664062  0.08691406 -0.00693512  0.04470825 -0.05001831
   0.01208496 -0.10009766  0.04953003 -0.00820923  0.21435547  0.05493164
  -0.06451416 -0.00241089 -0.15332031  0.05215454 -0.08935547 -0.105896
   0.03994751  0.10473633 -0.04318237 -0.09552002  0.08605957 -0.01132202
   0.07519531 -0.03497314  0.02560425 -0.01811218  0.16894531 -0.09399414
   0.0287323   0.08868408  0.02429199  0.02879333 -0.08282471 -0.05697632
  -0.02658081 -0.00204468  0.07946777  0.05545044  0.01997375  0.04202271
   0.09747314 -0.07580566  0.01100159  0.00976562  0.02409363 -0.03295898
   0.02185059 -0.00173187 -0.08099365 -0.02392578  0.0475769   0.02020264
  -0.06591797 -0.02243042 -0.03939819  0.04284668 -0.08099365  0.01553345
  -0.01594543 -0.05883789 -0.00157166 -0.12512207 -0.02848816 -0.06091309
  -0.01728821 -0.01467896  0.0166626   0.14978027  0.15612793  0.02302551
  -0.01547241 -0.00341797  0.01483154 -0.09320068]]
After layer _mul2075_0 (1, 256) <class 'numpy.float16'> [[-0.02186584 -0.01577759  0.04574585  0.0508728   0.05288696  0.01803589
   0.00570297 -0.00271416 -0.04168701 -0.06213379 -0.02709961  0.00380898
   0.03488159 -0.0319519   0.04318237 -0.05685425 -0.00295067 -0.02903748
  -0.00083208  0.04232788  0.05859375 -0.03845215  0.01776123  0.00684738
   0.01290131  0.00406647 -0.02522278  0.01209259 -0.02334595 -0.01695251
   0.0345459  -0.05838013  0.02726746 -0.04122925  0.01576233 -0.06524658
  -0.00628662 -0.04244995  0.01109314  0.02639771  0.05767822  0.00472641
   0.0168457   0.01068115  0.02960205 -0.04544067  0.02145386  0.00310516
  -0.0024128   0.04666138 -0.0024128  -0.03775024 -0.04299927  0.00938416
   0.0378418  -0.03387451 -0.02200317  0.06500244  0.01343536 -0.03643799
  -0.04864502 -0.01837158 -0.00727081  0.00619125  0.07385254 -0.01013947
   0.05477905  0.04690552 -0.01348877  0.00510788 -0.07281494  0.04864502
   0.01357269 -0.02401733  0.06915283  0.00680923 -0.08544922 -0.02523804
  -0.03936768 -0.01858521 -0.0043602  -0.04614258  0.00991821 -0.05664062
  -0.04916382  0.020401   -0.0124054   0.02139282 -0.02622986  0.01663208
   0.01716614  0.01641846  0.01135254 -0.03045654 -0.02571106 -0.01273346
  -0.00561523 -0.06488037 -0.0050354  -0.03173828  0.05953979  0.01235199
  -0.02307129  0.00543594 -0.02626038  0.04400635 -0.01308441  0.01332855
  -0.01023102 -0.00697327  0.04058838  0.00762558  0.01055145  0.04376221
  -0.0413208   0.01727295 -0.02734375 -0.02600098  0.04772949  0.02159119
   0.01783752  0.04129028  0.00813293 -0.04751587  0.01687622 -0.06225586
   0.06216431 -0.06167603 -0.01110077  0.04797363  0.03485107 -0.05072021
   0.02644348 -0.07525635  0.03640747  0.02694702  0.04281616  0.06555176
  -0.03353882  0.01811218 -0.00324249 -0.02401733  0.05578613  0.00292015
   0.02790833  0.00883484  0.01977539 -0.03878784  0.00988007  0.02301025
  -0.00840759 -0.0034008  -0.04177856 -0.02197266  0.03640747  0.03335571
  -0.01005554  0.00042844 -0.0079422   0.02062988 -0.10925293 -0.04373169
  -0.02241516 -0.01571655 -0.01405334  0.04678345 -0.0198822  -0.0635376
  -0.0859375  -0.03686523 -0.05093384  0.02742004 -0.00849152 -0.04391479
   0.02963257 -0.00647736  0.04495239 -0.04403687 -0.0176239  -0.01390839
   0.0668335   0.02816772  0.04434204 -0.00343323  0.0229187  -0.02603149
   0.00628281 -0.05014038  0.02781677 -0.00409317  0.10699463  0.02807617
  -0.03143311 -0.00113869 -0.07922363  0.02600098 -0.04367065 -0.05200195
   0.02095032  0.05099487 -0.02203369 -0.05358887  0.04534912 -0.00567627
   0.03903198 -0.01817322  0.01295471 -0.00895691  0.08392334 -0.04901123
   0.0151062   0.04785156  0.01210785  0.0154953  -0.04290771 -0.02748108
  -0.0137558  -0.00093317  0.0411377   0.02957153  0.00987244  0.02067566
   0.05102539 -0.03759766  0.0053978   0.00510788  0.01191711 -0.01617432
   0.01027679 -0.00095463 -0.04275513 -0.01166534  0.02539062  0.00992584
  -0.03405762 -0.01163483 -0.01953125  0.02183533 -0.0406189   0.00765228
  -0.00759125 -0.02880859 -0.0008626  -0.06994629 -0.01436615 -0.02984619
  -0.00849152 -0.00736237  0.00862122  0.07702637  0.07904053  0.01148224
  -0.00759888 -0.00175381  0.00749588 -0.04916382]]
After layer encoder_birnn_reverse_l0_t1_state_0 (1, 256) <class 'numpy.float16'> [[-0.05093384 -0.02749634  0.03018188  0.02261353  0.05358887 -0.03100586
   0.02149963  0.00401306 -0.05438232 -0.09155273 -0.03656006  0.02561951
   0.05435181 -0.05706787  0.06506348 -0.0703125   0.00950623 -0.0181427
   0.01579285  0.03405762  0.07617188 -0.06781006  0.02409363  0.02992249
   0.01629639  0.00338554 -0.07391357  0.00796509 -0.01872253 -0.03546143
   0.04846191 -0.07373047  0.04425049 -0.05023193  0.02674866 -0.06689453
  -0.04824829 -0.04815674 -0.01591492  0.025177    0.06518555  0.01100159
   0.04718018  0.01373291  0.06216431 -0.06787109  0.04547119 -0.01651001
  -0.00537491  0.00814819 -0.04037476 -0.05142212 -0.03430176  0.02931213
   0.03509521 -0.02029419 -0.04815674  0.0960083   0.02270508 -0.06903076
  -0.07019043 -0.02333069 -0.02081299 -0.0171814   0.10705566 -0.03543091
   0.07885742  0.04650879 -0.04125977 -0.01168823 -0.11212158  0.0614624
   0.0202179  -0.04104614  0.07409668 -0.01849365 -0.10375977 -0.04867554
  -0.04922485 -0.0295105  -0.03146362 -0.05276489 -0.00723267 -0.08666992
  -0.07116699  0.04019165 -0.02554321  0.03613281 -0.0368042  -0.01824951
   0.04510498  0.01751709  0.02468872 -0.04431152 -0.01063538 -0.01392365
   0.00550079 -0.04522705  0.00099564 -0.02368164  0.07147217  0.03451538
  -0.05914307  0.02101135 -0.04177856  0.05050659 -0.01838684 -0.01971436
   0.01390839 -0.01059723  0.0680542   0.06164551  0.00927734  0.05987549
  -0.05377197  0.01171875 -0.04162598 -0.05682373  0.04812622  0.04089355
   0.0291748   0.06396484 -0.00819397 -0.0579834   0.04678345 -0.08734131
   0.046875   -0.06658936  0.00984955  0.08654785  0.05990601 -0.02296448
   0.02809143 -0.05267334  0.04391479  0.0458374   0.05596924  0.06121826
  -0.01596069  0.05218506 -0.0300293  -0.03131104  0.07073975 -0.0209198
  -0.00590515  0.02764893  0.05947876 -0.06396484  0.01403809  0.01739502
  -0.02900696 -0.00920868 -0.03439331 -0.01838684  0.04168701  0.00531006
  -0.04006958  0.01647949  0.02142334  0.04309082 -0.12103271 -0.05722046
  -0.01029968 -0.00539398 -0.00408173  0.05514526 -0.00128174 -0.09594727
  -0.08538818 -0.06011963 -0.06185913  0.046875   -0.01878357 -0.05078125
   0.01324463  0.0063858   0.10742188 -0.05474854 -0.06018066 -0.02798462
   0.0645752   0.02380371  0.01977539 -0.0056839   0.07592773 -0.04647827
   0.01115417 -0.07928467  0.04248047 -0.02255249  0.11346436  0.06262207
  -0.0324707   0.00304985 -0.09545898  0.03738403 -0.07305908 -0.07836914
   0.03259277  0.06359863 -0.03570557 -0.02734375  0.07824707 -0.02023315
   0.06341553 -0.02279663 -0.00465393  0.001091    0.11828613 -0.06811523
   0.01226807  0.05789185  0.03747559 -0.00862885 -0.03067017 -0.04669189
  -0.01089478 -0.00213242  0.02575684  0.05908203  0.03915405  0.00809479
   0.03378296 -0.04116821 -0.004673   -0.0016098   0.00506973  0.00511169
   0.00630951  0.00776672 -0.04382324  0.00887299  0.04718018  0.01643372
  -0.04489136  0.01922607 -0.04125977  0.01756287 -0.05255127  0.02719116
   0.00247955 -0.04269409  0.01625061 -0.05865479 -0.04077148 -0.01922607
  -0.0046463  -0.00538635 -0.02008057  0.09197998  0.09423828  0.02619934
   0.02865601 -0.01515198  0.01860046 -0.06652832]]
After layer activation1037_output (1, 256) <class 'numpy.float16'> [[-0.05090332 -0.02749634  0.03016663  0.02261353  0.05352783 -0.0309906
   0.02149963  0.00401306 -0.05432129 -0.09130859 -0.03652954  0.02561951
   0.05429077 -0.05700684  0.06494141 -0.07019043  0.00950623 -0.0181427
   0.01579285  0.03405762  0.0760498  -0.06768799  0.02409363  0.02990723
   0.01629639  0.00338554 -0.0737915   0.00796509 -0.01872253 -0.03546143
   0.0484314  -0.0736084   0.04421997 -0.05020142  0.02674866 -0.06677246
  -0.04821777 -0.04812622 -0.01591492  0.025177    0.06506348  0.01100159
   0.04714966  0.01373291  0.06207275 -0.06774902  0.04544067 -0.01651001
  -0.00537491  0.00814819 -0.04034424 -0.0513916  -0.03430176  0.02929688
   0.03509521 -0.02029419 -0.04812622  0.09570312  0.02270508 -0.06890869
  -0.07006836 -0.02333069 -0.02081299 -0.0171814   0.10662842 -0.03543091
   0.07867432  0.04647827 -0.04122925 -0.01168823 -0.1116333   0.06137085
   0.0202179  -0.04101562  0.07397461 -0.01849365 -0.10339355 -0.04864502
  -0.04919434 -0.02949524 -0.03146362 -0.05270386 -0.00723267 -0.08642578
  -0.07104492  0.04016113 -0.02554321  0.03610229 -0.03677368 -0.01824951
   0.04507446  0.01751709  0.02468872 -0.04428101 -0.01063538 -0.01392365
   0.00550079 -0.04519653  0.00099564 -0.02368164  0.0713501   0.03451538
  -0.05908203  0.02101135 -0.04174805  0.05047607 -0.01838684 -0.01971436
   0.01390839 -0.01059723  0.06793213  0.06155396  0.00927734  0.05981445
  -0.05371094  0.01171875 -0.04159546 -0.0567627   0.0480957   0.04086304
   0.02915955  0.06390381 -0.00819397 -0.05792236  0.04675293 -0.08709717
   0.04684448 -0.06646729  0.00984955  0.08630371  0.05984497 -0.02296448
   0.02809143 -0.0526123   0.04388428  0.04580688  0.0559082   0.06112671
  -0.01596069  0.05212402 -0.03001404 -0.03131104  0.07061768 -0.0209198
  -0.00590515  0.02764893  0.05941772 -0.06390381  0.01403809  0.01739502
  -0.0289917  -0.00920868 -0.03439331 -0.01838684  0.04165649  0.00531006
  -0.04003906  0.01647949  0.02142334  0.0430603  -0.12042236 -0.05715942
  -0.01029968 -0.00539398 -0.00408173  0.05508423 -0.00128174 -0.09564209
  -0.08520508 -0.06005859 -0.06176758  0.04684448 -0.01878357 -0.05075073
   0.01324463  0.0063858   0.10699463 -0.0546875  -0.06011963 -0.02798462
   0.06451416  0.02380371  0.01977539 -0.0056839   0.07580566 -0.04644775
   0.01115417 -0.07910156  0.04244995 -0.02255249  0.11297607  0.06256104
  -0.0324707   0.00304985 -0.09515381  0.03735352 -0.07293701 -0.07818604
   0.03259277  0.0635376  -0.03570557 -0.02734375  0.07806396 -0.02023315
   0.06335449 -0.02279663 -0.00465393  0.001091    0.11773682 -0.06799316
   0.01226807  0.05783081  0.03744507 -0.00862885 -0.03065491 -0.04666138
  -0.01089478 -0.00213242  0.02575684  0.059021    0.03912354  0.00809479
   0.03378296 -0.0411377  -0.004673   -0.0016098   0.00506973  0.00511169
   0.00630951  0.00776672 -0.04379272  0.00887299  0.04714966  0.01643372
  -0.04486084  0.01922607 -0.04122925  0.01756287 -0.05249023  0.02719116
   0.00247955 -0.04266357  0.01625061 -0.05859375 -0.04074097 -0.01922607
  -0.0046463  -0.00538635 -0.02008057  0.09173584  0.09393311  0.02619934
   0.02864075 -0.01515198  0.01860046 -0.06640625]]
After layer encoder_birnn_reverse_l0_t1_out_0 (1, 256) <class 'numpy.float16'> [[-0.02632141 -0.01463318  0.01530457  0.01187897  0.02830505 -0.015625
   0.01147461  0.00208282 -0.02964783 -0.04760742 -0.01821899  0.01313782
   0.02839661 -0.02890015  0.03353882 -0.03582764  0.00487518 -0.00938416
   0.00799561  0.01780701  0.03729248 -0.03448486  0.01369476  0.01541901
   0.00830841  0.00176525 -0.03894043  0.00397873 -0.00951385 -0.01887512
   0.02485657 -0.03787231  0.02433777 -0.02549744  0.01381683 -0.03405762
  -0.02423096 -0.02484131 -0.00787354  0.01261139  0.03555298  0.00563431
   0.02407837  0.00681305  0.03096008 -0.03567505  0.02427673 -0.00830841
  -0.0026989   0.00413132 -0.02050781 -0.02600098 -0.01670837  0.0154953
   0.01870728 -0.01031494 -0.02311707  0.04907227  0.01133728 -0.03652954
  -0.03662109 -0.01229095 -0.01052094 -0.00906372  0.05535889 -0.01831055
   0.0453186   0.02436829 -0.02137756 -0.00639725 -0.05532837  0.03102112
   0.0102005  -0.0206604   0.03823853 -0.01006317 -0.0541687  -0.02430725
  -0.0252533  -0.01525116 -0.01602173 -0.02766418 -0.00377846 -0.04388428
  -0.03707886  0.02082825 -0.01306152  0.01872253 -0.01951599 -0.00945282
   0.02427673  0.00870514  0.01241302 -0.02204895 -0.00527191 -0.0072937
   0.00277901 -0.02526855  0.00049782 -0.01180267  0.03805542  0.01683044
  -0.02999878  0.01048279 -0.02124023  0.02604675 -0.00900269 -0.01028442
   0.007061   -0.00551605  0.03396606  0.0317688   0.0046196   0.03118896
  -0.02761841  0.00611877 -0.02011108 -0.02896118  0.02554321  0.02095032
   0.01502228  0.03167725 -0.00407791 -0.03022766  0.02388    -0.0435791
   0.02449036 -0.03271484  0.00499725  0.04348755  0.03128052 -0.01305389
   0.01456451 -0.02789307  0.02316284  0.022995    0.02874756  0.03112793
  -0.00795746  0.0256958  -0.01540375 -0.01599121  0.03637695 -0.01061249
  -0.00310898  0.01383972  0.03083801 -0.03164673  0.00730515  0.00891113
  -0.01462555 -0.00436783 -0.01705933 -0.00930023  0.02133179  0.00282097
  -0.0202179   0.00887299  0.01085663  0.02276611 -0.06292725 -0.02877808
  -0.00551605 -0.00279427 -0.00220299  0.02740479 -0.00071716 -0.05072021
  -0.04226685 -0.02793884 -0.03186035  0.02458191 -0.00965881 -0.02867126
   0.0071907   0.00330734  0.05511475 -0.02894592 -0.02989197 -0.01399231
   0.03155518  0.01178741  0.01020813 -0.00279808  0.0395813  -0.02514648
   0.00543594 -0.04058838  0.02381897 -0.01146698  0.05441284  0.03344727
  -0.01693726  0.00152397 -0.04956055  0.01838684 -0.03833008 -0.04064941
   0.01696777  0.03216553 -0.01899719 -0.01528931  0.04138184 -0.01059723
   0.03277588 -0.0117569  -0.00230789  0.00054026  0.05957031 -0.03646851
   0.00627899  0.0324707   0.01953125 -0.00436783 -0.01580811 -0.02365112
  -0.00536346 -0.00106812  0.01278687  0.02993774  0.01980591  0.00407791
   0.01727295 -0.02102661 -0.00246239 -0.00084162  0.00259399  0.00263405
   0.00341415  0.00435638 -0.02244568  0.0044632   0.02410889  0.00827026
  -0.02345276  0.00969696 -0.02101135  0.00866699 -0.02893066  0.01416779
   0.00117111 -0.02230835  0.00891876 -0.03463745 -0.02064514 -0.01030731
  -0.00231361 -0.00278854 -0.01034546  0.04446411  0.04714966  0.01355743
   0.01511383 -0.00766373  0.00930023 -0.03518677]]
After layer expand_dims1043_0 (1, 1, 256) <class 'numpy.float16'> [[[-0.02632141 -0.01463318  0.01530457  0.01187897  0.02830505 -0.015625
    0.01147461  0.00208282 -0.02964783 -0.04760742 -0.01821899  0.01313782
    0.02839661 -0.02890015  0.03353882 -0.03582764  0.00487518 -0.00938416
    0.00799561  0.01780701  0.03729248 -0.03448486  0.01369476  0.01541901
    0.00830841  0.00176525 -0.03894043  0.00397873 -0.00951385 -0.01887512
    0.02485657 -0.03787231  0.02433777 -0.02549744  0.01381683 -0.03405762
   -0.02423096 -0.02484131 -0.00787354  0.01261139  0.03555298  0.00563431
    0.02407837  0.00681305  0.03096008 -0.03567505  0.02427673 -0.00830841
   -0.0026989   0.00413132 -0.02050781 -0.02600098 -0.01670837  0.0154953
    0.01870728 -0.01031494 -0.02311707  0.04907227  0.01133728 -0.03652954
   -0.03662109 -0.01229095 -0.01052094 -0.00906372  0.05535889 -0.01831055
    0.0453186   0.02436829 -0.02137756 -0.00639725 -0.05532837  0.03102112
    0.0102005  -0.0206604   0.03823853 -0.01006317 -0.0541687  -0.02430725
   -0.0252533  -0.01525116 -0.01602173 -0.02766418 -0.00377846 -0.04388428
   -0.03707886  0.02082825 -0.01306152  0.01872253 -0.01951599 -0.00945282
    0.02427673  0.00870514  0.01241302 -0.02204895 -0.00527191 -0.0072937
    0.00277901 -0.02526855  0.00049782 -0.01180267  0.03805542  0.01683044
   -0.02999878  0.01048279 -0.02124023  0.02604675 -0.00900269 -0.01028442
    0.007061   -0.00551605  0.03396606  0.0317688   0.0046196   0.03118896
   -0.02761841  0.00611877 -0.02011108 -0.02896118  0.02554321  0.02095032
    0.01502228  0.03167725 -0.00407791 -0.03022766  0.02388    -0.0435791
    0.02449036 -0.03271484  0.00499725  0.04348755  0.03128052 -0.01305389
    0.01456451 -0.02789307  0.02316284  0.022995    0.02874756  0.03112793
   -0.00795746  0.0256958  -0.01540375 -0.01599121  0.03637695 -0.01061249
   -0.00310898  0.01383972  0.03083801 -0.03164673  0.00730515  0.00891113
   -0.01462555 -0.00436783 -0.01705933 -0.00930023  0.02133179  0.00282097
   -0.0202179   0.00887299  0.01085663  0.02276611 -0.06292725 -0.02877808
   -0.00551605 -0.00279427 -0.00220299  0.02740479 -0.00071716 -0.05072021
   -0.04226685 -0.02793884 -0.03186035  0.02458191 -0.00965881 -0.02867126
    0.0071907   0.00330734  0.05511475 -0.02894592 -0.02989197 -0.01399231
    0.03155518  0.01178741  0.01020813 -0.00279808  0.0395813  -0.02514648
    0.00543594 -0.04058838  0.02381897 -0.01146698  0.05441284  0.03344727
   -0.01693726  0.00152397 -0.04956055  0.01838684 -0.03833008 -0.04064941
    0.01696777  0.03216553 -0.01899719 -0.01528931  0.04138184 -0.01059723
    0.03277588 -0.0117569  -0.00230789  0.00054026  0.05957031 -0.03646851
    0.00627899  0.0324707   0.01953125 -0.00436783 -0.01580811 -0.02365112
   -0.00536346 -0.00106812  0.01278687  0.02993774  0.01980591  0.00407791
    0.01727295 -0.02102661 -0.00246239 -0.00084162  0.00259399  0.00263405
    0.00341415  0.00435638 -0.02244568  0.0044632   0.02410889  0.00827026
   -0.02345276  0.00969696 -0.02101135  0.00866699 -0.02893066  0.01416779
    0.00117111 -0.02230835  0.00891876 -0.03463745 -0.02064514 -0.01030731
   -0.00231361 -0.00278854 -0.01034546  0.04446411  0.04714966  0.01355743
    0.01511383 -0.00766373  0.00930023 -0.03518677]]]
After layer encoder_birnn_reverse_l0_t2_i2h_output (1, 1024) <class 'numpy.float16'> [[-0.0128479  -0.04095459  0.03787231 ...,  0.06970215 -0.04626465
   0.03759766]]
After layer encoder_birnn_reverse_l0_t2_h2h_output (1, 1024) <class 'numpy.float16'> [[ 0.02049255  0.03256226  0.00370407 ...,  0.05358887  0.05169678
   0.04724121]]
After layer _plus1038_0 (1, 1024) <class 'numpy.float16'> [[ 0.00764465 -0.00839233  0.04156494 ...,  0.12329102  0.00543213
   0.08483887]]
After layer encoder_birnn_reverse_l0_t2_slice_output0 (1, 256) <class 'numpy.float16'> [[  7.64465332e-03  -8.39233398e-03   4.15649414e-02  -2.11181641e-02
    7.61718750e-02   2.72369385e-02   6.82373047e-02   3.14941406e-02
    7.11669922e-02   5.62438965e-02  -4.23889160e-02   4.12597656e-02
    2.73742676e-02   5.65795898e-02   2.19726562e-03   2.18017578e-01
   -2.86560059e-02  -4.06799316e-02   1.99890137e-02  -2.73590088e-02
    8.63037109e-02   6.82983398e-02  -5.89599609e-02  -5.25512695e-02
    8.30078125e-02  -8.94775391e-02  -2.20336914e-02  -5.95092773e-03
    5.54504395e-02   7.75146484e-03  -5.44357300e-03  -5.08422852e-02
   -2.84576416e-02  -3.90014648e-02   7.11669922e-02  -7.22656250e-02
    6.20269775e-03  -9.08660889e-03  -4.34265137e-02  -2.62145996e-02
   -4.85534668e-02   6.26831055e-02  -5.59387207e-02   9.85717773e-03
    4.12597656e-02   4.47082520e-03   7.08007812e-02  -7.01904297e-02
    1.89666748e-02  -1.34887695e-02  -2.71301270e-02   7.85522461e-02
    2.39868164e-02   6.87255859e-02   2.15942383e-01   7.03735352e-02
   -2.94036865e-02  -9.84191895e-03  -1.25122070e-02  -2.43072510e-02
    5.75561523e-02  -4.45251465e-02   1.32568359e-01  -2.53143311e-02
   -9.53369141e-02  -4.93164062e-02   9.15527344e-02  -6.62231445e-03
   -1.46789551e-02   5.12695312e-02   9.03320312e-02  -1.65557861e-02
    6.40869141e-03   9.48333740e-03  -3.30505371e-02   1.02111816e-01
    1.23352051e-01   9.82666016e-02  -2.39257812e-02   3.01208496e-02
    2.45666504e-02   2.70690918e-02   8.66088867e-02  -1.33666992e-02
    1.44897461e-01   7.00073242e-02  -2.92968750e-02   1.83105469e-04
   -4.84924316e-02   1.67724609e-01   1.45385742e-01  -1.02539062e-02
   -7.91625977e-02   1.27319336e-01   6.40869141e-02   5.19409180e-02
   -2.02026367e-02   1.42089844e-01  -5.54809570e-02  -7.98950195e-02
   -2.37121582e-02   6.59179688e-02  -2.31323242e-02  -1.43798828e-01
   -1.43432617e-02  -7.91931152e-03  -1.29699707e-03  -1.18347168e-01
    4.27246094e-02   9.27734375e-02  -1.38061523e-01   6.24084473e-02
   -1.23138428e-02   1.29028320e-01  -9.99450684e-03   2.53417969e-01
   -2.12402344e-02   1.30462646e-02   1.23046875e-01  -1.23596191e-02
    1.89697266e-01  -9.25292969e-02  -1.36108398e-02   8.60595703e-02
   -5.13610840e-02   4.91027832e-02  -9.39331055e-02   4.72717285e-02
   -9.48333740e-03  -7.93457031e-04   1.15722656e-01   7.00683594e-02
    2.45056152e-02  -1.22909546e-02  -2.78320312e-02  -6.92749023e-03
    8.21533203e-02   1.34887695e-01   1.95007324e-02  -1.09252930e-02
   -3.16467285e-02  -5.50537109e-02   3.86047363e-02   7.30590820e-02
   -2.24609375e-02   7.90405273e-03   2.44140625e-02   7.51953125e-02
   -2.30865479e-02   6.10656738e-02   7.34863281e-02  -3.04718018e-02
    3.17382812e-03  -7.69653320e-02  -2.14538574e-02   1.80908203e-01
    4.09240723e-02   1.30981445e-01  -5.24902344e-03  -1.77459717e-02
    1.39770508e-01  -1.05285645e-03  -2.16979980e-02   5.63049316e-02
    3.73840332e-02  -3.44848633e-02   3.01208496e-02  -2.85797119e-02
    7.42797852e-02  -1.48773193e-02   3.43017578e-02   2.92663574e-02
    4.79888916e-03   7.91015625e-02   4.13818359e-02  -8.52050781e-02
    3.77197266e-02  -9.17358398e-02  -4.01000977e-02  -1.58233643e-02
    1.82495117e-02  -3.22875977e-02  -4.54711914e-02   4.79736328e-02
    1.00708008e-01  -2.98767090e-02  -1.62658691e-02  -5.31311035e-02
    1.44165039e-01   1.02966309e-01  -6.83593750e-03   2.46429443e-02
    3.23486328e-02   2.16979980e-02   1.65527344e-01   5.36193848e-02
    5.10253906e-02  -1.28662109e-01   4.68750000e-02   1.98669434e-02
   -5.61523438e-03   1.78710938e-01   6.14624023e-02   3.57055664e-03
    3.97338867e-02   6.92749023e-03   4.44030762e-03  -3.12194824e-02
   -2.93121338e-02   3.77502441e-02   1.85546875e-02   7.64160156e-02
    1.43432617e-02   7.62939453e-02   3.00292969e-02   8.53271484e-02
   -4.11987305e-03  -2.59399414e-02  -3.40270996e-03   7.65991211e-03
   -4.98962402e-02   8.27026367e-03   3.47290039e-02  -9.14306641e-02
    1.57470703e-02   8.31909180e-02  -2.86254883e-02  -5.85327148e-02
   -2.44140625e-02   1.96533203e-01  -2.14233398e-02  -1.25427246e-02
   -5.11169434e-03  -1.31759644e-02   3.27148438e-02   6.62841797e-02
   -6.77490234e-03   3.56445312e-02   2.58178711e-02  -3.95507812e-02
   -3.05786133e-02  -6.97021484e-02   1.42822266e-01   2.18750000e-01
   -2.44445801e-02   4.64172363e-02   5.19104004e-02  -5.82580566e-02
    3.73840332e-03   6.83593750e-02   1.21826172e-01   1.51367188e-02
   -5.72204590e-02   4.74243164e-02   2.95867920e-02  -3.41796875e-02]]
After layer encoder_birnn_reverse_l0_t2_slice_output1 (1, 256) <class 'numpy.float16'> [[ 0.10601807  0.01879883  0.07324219  0.04992676  0.02737427  0.05102539
   0.14611816 -0.04592896  0.24475098  0.08911133  0.13171387  0.06726074
   0.08483887  0.01829529  0.09362793  0.08917236  0.07177734 -0.03601074
  -0.09991455  0.03378296  0.0904541  -0.01049805  0.20581055  0.05358887
   0.09741211  0.08227539  0.11029053  0.10626221  0.07666016  0.00039673
   0.00134277 -0.02233887  0.19848633 -0.03594971 -0.00512695  0.02789307
  -0.05407715  0.05609131 -0.00038147  0.08203125  0.059021    0.0859375
   0.00343323  0.11291504  0.01168823  0.09320068  0.02877808 -0.03424072
   0.00071716  0.03308105  0.0390625   0.02926636  0.09130859  0.11132812
   0.14709473  0.08984375  0.01586914  0.06878662  0.03092957 -0.03564453
   0.00927734  0.04696655 -0.01402283  0.06634521 -0.00875854  0.12005615
   0.17053223  0.07104492 -0.04385376  0.03466797  0.06365967 -0.03271484
  -0.00386047  0.01037598  0.08654785  0.20410156  0.04919434  0.0100708
   0.02526855  0.06359863  0.18432617  0.1204834   0.02700806  0.02209473
   0.11791992  0.02615356  0.04821777  0.20410156  0.02845764 -0.05157471
   0.20385742  0.09320068  0.07476807  0.07714844 -0.02398682  0.0164032
   0.04327393  0.15441895 -0.08099365 -0.09692383  0.03646851  0.0189209
  -0.01107788  0.08508301  0.02542114 -0.01204681 -0.0668335   0.06329346
   0.01002502 -0.01980591 -0.03079224  0.01028442 -0.00808716  0.09155273
   0.10510254  0.16931152  0.0802002   0.10272217  0.17431641  0.08392334
   0.15454102  0.12426758  0.00628662  0.01629639  0.02716064 -0.0138855
   0.12365723 -0.0032196   0.08441162 -0.05477905  0.05441284  0.18383789
   0.0255127   0.14196777  0.11279297  0.10253906  0.02835083  0.00842285
   0.12536621  0.11047363 -0.06292725  0.08251953  0.07275391  0.04534912
   0.02047729  0.10321045 -0.00045776  0.01287842  0.00469971 -0.00906372
  -0.03369141  0.05578613  0.006073    0.06140137  0.09735107  0.16320801
   0.10961914  0.05255127 -0.00091553  0.10412598  0.18640137  0.07800293
  -0.0362854   0.07196045  0.02624512  0.01986694  0.20056152 -0.05993652
   0.00344849 -0.01800537  0.06103516  0.08056641 -0.06396484  0.15429688
   0.00691223  0.06756592  0.12939453  0.02276611  0.00915527  0.09277344
   0.08966064 -0.06567383  0.17041016 -0.03482056  0.03863525 -0.03027344
   0.02189636  0.12158203  0.13745117  0.00732422 -0.03640747  0.01950073
   0.14331055  0.13696289  0.10070801 -0.01057434 -0.02790833  0.02166748
   0.01947021  0.01334381  0.01245117  0.08996582  0.09771729 -0.04614258
   0.04644775 -0.08251953  0.00445557  0.12597656  0.02825928  0.03866577
   0.0447998   0.12023926 -0.04711914  0.02145386 -0.03268433 -0.04071045
   0.03729248  0.07574463  0.01437378  0.0869751  -0.08660889  0.00384521
   0.19335938  0.03186035  0.04644775 -0.0085144   0.02958679  0.01605225
   0.23498535  0.24450684 -0.00231934 -0.18164062  0.11877441  0.03466797
   0.05422974  0.00415039  0.03710938  0.08453369  0.00613403  0.09307861
   0.08428955 -0.01025391  0.09906006  0.22827148 -0.10211182 -0.01928711
   0.03372192 -0.08435059  0.0645752  -0.00193787  0.08966064 -0.0736084
   0.11663818 -0.02545166  0.12036133  0.0140686 ]]
After layer encoder_birnn_reverse_l0_t2_slice_output2 (1, 256) <class 'numpy.float16'> [[ -1.18225098e-01  -1.19262695e-01   3.47900391e-03   3.65600586e-02
    3.79638672e-02  -3.86962891e-02   4.27551270e-02   1.08398438e-01
    5.05981445e-02  -4.33349609e-02  -6.21337891e-02   9.25903320e-02
    9.38720703e-02  -3.45764160e-02   5.27954102e-02  -1.78100586e-01
    1.35345459e-02   5.37109375e-03   7.15332031e-02   4.78210449e-02
    1.62597656e-01  -1.64794922e-02   7.93457031e-04   8.38623047e-02
   -1.06079102e-01   3.75976562e-02   6.14318848e-02  -2.48107910e-02
   -1.32324219e-01  -7.69042969e-02   1.33056641e-02  -1.26708984e-01
   -3.72924805e-02   6.56127930e-03   1.05712891e-01  -1.16699219e-01
   -6.94580078e-02  -7.43103027e-03  -1.17309570e-01  -9.69848633e-02
    3.94287109e-02  -1.62841797e-01   1.09375000e-01   9.42382812e-02
    7.95898438e-02  -9.17968750e-02   3.91845703e-02  -7.75756836e-02
   -5.21850586e-03  -7.83691406e-02   5.13916016e-02  -8.77075195e-02
   -6.41479492e-02   6.61621094e-02   6.22558594e-02   3.41491699e-02
   -5.84106445e-02   1.53320312e-01   6.62841797e-02  -5.03540039e-02
   -3.83911133e-02  -9.97314453e-02  -4.67224121e-02   1.83105469e-04
    6.06994629e-02  -2.73590088e-02   4.12597656e-02  -7.09838867e-02
   -1.25488281e-01  -4.55627441e-02  -1.93359375e-01  -1.95312500e-02
    6.69555664e-02   4.35791016e-02   1.12304688e-01  -6.22558594e-02
    1.64794922e-03  -1.29150391e-01  -4.21752930e-02  -1.98669434e-02
   -8.53881836e-02   2.71759033e-02  -6.91528320e-02  -1.20971680e-01
   -2.09472656e-01   2.26440430e-02  -1.60400391e-01   3.91540527e-02
   -1.21337891e-01  -1.14135742e-01  -8.84399414e-02  -6.54907227e-02
   -3.48510742e-02  -1.93481445e-02  -4.08325195e-02   3.47290039e-02
    1.09130859e-01  -2.24304199e-02  -1.14624023e-01  -5.13610840e-02
    3.00598145e-02   1.20422363e-01  -7.03125000e-02   4.42199707e-02
    5.99670410e-02   6.90307617e-02  -4.68139648e-02  -4.01306152e-02
    1.49291992e-01  -1.52954102e-01   4.92248535e-02   1.03912354e-02
    4.76379395e-02   3.49731445e-02  -8.70361328e-02   2.28515625e-01
   -1.12060547e-01  -3.23486328e-02   2.85034180e-02  -4.41284180e-02
    1.16577148e-01   1.02294922e-01  -3.05328369e-02  -5.84106445e-02
    1.04370117e-01  -1.48925781e-01  -8.16650391e-02  -3.93371582e-02
   -3.48205566e-02  -3.55224609e-02   5.54809570e-02  -5.52978516e-02
    7.79418945e-02  -1.90734863e-02  -3.26538086e-03   5.25207520e-02
    1.10351562e-01   1.71264648e-01  -4.65393066e-03   5.07812500e-02
   -1.23596191e-02  -5.51452637e-02   1.03210449e-01   1.45187378e-02
   -1.24816895e-01   8.08715820e-02   3.88183594e-02  -1.18347168e-01
   -1.03393555e-01  -9.03930664e-02  -7.11669922e-02  -3.42407227e-02
   -2.76489258e-02  -1.03515625e-01  -4.02221680e-02   6.36596680e-02
   -9.08813477e-02   6.78710938e-02   5.27038574e-02   5.23681641e-02
   -1.47094727e-01  -7.41577148e-02   4.32739258e-02   1.46606445e-01
    1.99737549e-02   8.09326172e-02   7.69805908e-03  -7.03125000e-02
   -1.27441406e-01   2.08129883e-02  -6.50024414e-02   1.43432617e-02
   -1.93786621e-02  -1.22314453e-01  -2.11334229e-02   6.77490234e-02
    1.11694336e-01  -3.93066406e-02  -7.56835938e-02  -3.97644043e-02
    6.31103516e-02  -1.03454590e-02   2.80303955e-02  -2.97241211e-02
   -6.28662109e-02   7.13500977e-02   3.43933105e-02  -9.48486328e-02
    9.32617188e-02  -1.07727051e-01   1.38671875e-01  -3.02124023e-02
    3.20739746e-02  -1.15966797e-02  -1.11450195e-01  -1.13220215e-02
   -1.69677734e-01  -7.78808594e-02  -2.02331543e-02   2.50549316e-02
   -1.29638672e-01  -2.13623047e-04   1.60400391e-01  -7.04345703e-02
   -2.64434814e-02  -1.98364258e-04   4.98046875e-02  -5.77926636e-03
    7.11669922e-02  -9.02709961e-02  -1.55517578e-01  -4.82177734e-03
    1.87988281e-02  -1.19750977e-01  -5.82275391e-02  -6.87866211e-02
    2.37121582e-02  -4.31518555e-02  -6.22558594e-03   8.42285156e-02
   -4.05578613e-02  -9.66186523e-02   7.20214844e-02   1.16424561e-02
   -3.89099121e-03  -3.97033691e-02  -7.48443604e-03   4.49829102e-02
    5.94482422e-02  -2.81372070e-02  -1.33666992e-01   1.62597656e-01
    5.94177246e-02   9.35668945e-02  -6.61621094e-02   7.14721680e-02
   -1.19018555e-01   1.50909424e-02  -1.18530273e-01   1.36474609e-01
    3.51867676e-02  -3.18603516e-02   1.17492676e-02  -6.81152344e-02
   -3.61633301e-02  -8.61816406e-02  -5.73120117e-02  -1.29516602e-01
   -1.98364258e-04   2.04223633e-01   1.36718750e-01   8.71582031e-02
    6.31713867e-02  -6.12792969e-02  -4.88891602e-02  -1.15814209e-02]]
After layer encoder_birnn_reverse_l0_t2_slice_output3 (1, 256) <class 'numpy.float16'> [[  5.47485352e-02   1.18713379e-02  -1.70288086e-02   4.36096191e-02
    7.78808594e-02   1.84814453e-01   1.02722168e-01   1.33666992e-01
    2.70019531e-01   1.29150391e-01  -1.35955811e-02   7.16552734e-02
    1.16455078e-01  -3.59497070e-02   3.00903320e-02   9.27734375e-02
   -3.22875977e-02  -1.87072754e-02   2.56347656e-03  -2.67639160e-02
   -1.73950195e-02  -1.30126953e-01   2.05566406e-01   9.16748047e-02
    9.50927734e-02   1.08184814e-02  -2.42614746e-03   2.44750977e-02
   -5.88684082e-02   3.04870605e-02   8.97827148e-02   1.10168457e-01
    3.19213867e-02   1.37786865e-02  -2.74658203e-02   5.03540039e-03
    8.67919922e-02  -2.16979980e-02   9.97924805e-02   1.40380859e-02
    1.08459473e-01  -2.50854492e-02  -1.15966797e-03   2.01416016e-03
   -2.04772949e-02   7.14111328e-03   2.50244141e-02  -3.66821289e-02
    5.64880371e-02   4.02221680e-02   9.68017578e-02  -7.43408203e-02
    7.86743164e-02   6.01806641e-02   2.26562500e-01  -9.93041992e-02
    1.15173340e-01   2.82592773e-02   2.16979980e-02  -8.61816406e-02
    2.65960693e-02   1.52587891e-03   3.60717773e-02   1.29882812e-01
   -1.39617920e-02  -4.46777344e-02   1.24938965e-01   5.87768555e-02
    7.03735352e-02   1.19018555e-01   1.40380859e-02   4.90417480e-02
    3.50341797e-02  -2.82287598e-02   6.00585938e-02   2.34375000e-01
    1.03393555e-01   6.15234375e-02   9.48486328e-02   1.71752930e-01
    1.28417969e-01   1.73095703e-01   7.98950195e-02   1.37451172e-01
    9.70458984e-02   7.49511719e-02   4.01000977e-02   1.35986328e-01
    6.42089844e-02   1.46850586e-01   1.16210938e-01  -1.32675171e-02
   -8.52661133e-02   3.76281738e-02   6.28051758e-02   2.59399414e-02
    7.69042969e-02   1.50878906e-01  -1.05712891e-01  -4.03747559e-02
    2.69470215e-02  -9.83886719e-02  -2.02026367e-02  -5.80444336e-02
    3.81164551e-02   1.76544189e-02  -3.94897461e-02   1.28540039e-01
    3.89099121e-02   1.97143555e-01   7.61413574e-03   4.10156250e-02
   -6.66503906e-02   1.13037109e-01   4.60815430e-02   1.36718750e-01
   -8.34350586e-02  -4.24194336e-02   1.43310547e-01  -8.81347656e-02
    4.09851074e-02   7.49511719e-02   1.19445801e-01  -6.31713867e-03
   -8.17871094e-03   2.78015137e-02  -1.26495361e-02  -3.04107666e-02
   -5.09948730e-02  -2.63977051e-03   1.44042969e-02   1.67236328e-01
    2.57568359e-02   1.03271484e-01   1.87683105e-02  -4.49523926e-02
    1.04980469e-01   6.65893555e-02   1.11328125e-01   3.99169922e-02
   -6.85119629e-03   2.25372314e-02  -1.11083984e-01   3.06396484e-02
    1.66625977e-02   1.94091797e-02   1.04492188e-01   2.57263184e-02
    5.00488281e-02  -1.15356445e-02  -5.18798828e-04  -4.07104492e-02
    3.94897461e-02   1.26220703e-01   7.27539062e-02   9.16137695e-02
    4.19616699e-02   1.81396484e-01   3.90625000e-02   1.10778809e-01
    4.53796387e-02   3.50646973e-02  -3.33251953e-02   1.34033203e-01
    9.24072266e-02  -6.12182617e-02   1.81152344e-01   8.04443359e-02
   -5.81054688e-02   4.35791016e-02  -6.70776367e-02   7.48291016e-02
    8.92333984e-02   1.46240234e-01   5.88684082e-02   1.25366211e-01
    1.34521484e-01  -8.31604004e-03   1.06628418e-01  -7.01904297e-04
   -4.80651855e-02  -3.62548828e-02   4.87670898e-02   3.34167480e-03
   -1.29699707e-02   5.18188477e-02  -1.76696777e-02   8.18481445e-02
    1.02416992e-01  -2.33459473e-02   6.14624023e-02   1.22436523e-01
    5.32226562e-02  -1.44958496e-02   1.55273438e-01   5.72814941e-02
   -1.51062012e-02   6.77490234e-02   6.28662109e-02  -1.13220215e-02
    4.87060547e-02   2.11303711e-01   9.53369141e-02   1.30493164e-01
    7.33032227e-02   8.22753906e-02  -3.80249023e-02   1.89971924e-03
   -4.42199707e-02   1.20666504e-01  -2.63061523e-02   2.70507812e-01
    2.23999023e-02   1.22741699e-01   8.45336914e-02  -3.29589844e-03
    6.52465820e-02   1.34521484e-01  -3.98559570e-02  -5.46264648e-02
   -5.90820312e-02  -5.96618652e-02   1.04858398e-01   1.89208984e-03
    7.74536133e-02   7.88574219e-02   2.08282471e-02  -1.15051270e-02
    2.21191406e-01   2.15820312e-01   4.51354980e-02  -4.94995117e-02
    1.17797852e-02   6.10351562e-05  -1.76696777e-02   1.28479004e-02
   -2.09350586e-02   6.17675781e-02   9.77783203e-02   1.45874023e-02
   -1.82495117e-02   9.65576172e-02   1.96289062e-01   3.15429688e-01
   -6.43310547e-02   6.30493164e-02   9.91821289e-02  -9.55810547e-02
    5.41687012e-03   3.90625000e-02   8.87451172e-02  -5.23986816e-02
    7.33642578e-02   1.23291016e-01   5.43212891e-03   8.48388672e-02]]
After layer encoder_birnn_reverse_l0_t2_o_output (1, 256) <class 'numpy.float16'> [[ 0.51367188  0.50292969  0.49584961  0.51074219  0.51953125  0.54589844
   0.52587891  0.53320312  0.56689453  0.53222656  0.49658203  0.51806641
   0.52929688  0.4909668   0.50732422  0.52294922  0.49194336  0.49536133
   0.50048828  0.4934082   0.49560547  0.4675293   0.55126953  0.52294922
   0.52392578  0.50292969  0.49951172  0.50634766  0.48535156  0.5078125
   0.52246094  0.52734375  0.5078125   0.50341797  0.49316406  0.50146484
   0.52148438  0.49462891  0.52490234  0.50341797  0.52685547  0.49365234
   0.49975586  0.50048828  0.49487305  0.50195312  0.50634766  0.49072266
   0.51416016  0.51025391  0.52441406  0.48144531  0.51953125  0.51513672
   0.55664062  0.47509766  0.52880859  0.50683594  0.50537109  0.47851562
   0.50683594  0.50048828  0.50878906  0.53222656  0.49658203  0.48876953
   0.53125     0.51464844  0.51757812  0.52978516  0.50341797  0.51220703
   0.50878906  0.49291992  0.51513672  0.55810547  0.52587891  0.51513672
   0.52392578  0.54296875  0.53222656  0.54296875  0.52001953  0.53417969
   0.52441406  0.51855469  0.51025391  0.53417969  0.51611328  0.53662109
   0.52880859  0.49658203  0.47875977  0.50927734  0.515625    0.50634766
   0.51904297  0.53759766  0.47363281  0.48999023  0.50683594  0.4753418
   0.49487305  0.4855957   0.50976562  0.50439453  0.49023438  0.53222656
   0.50976562  0.54931641  0.50195312  0.51025391  0.48339844  0.52832031
   0.51171875  0.53417969  0.47924805  0.48950195  0.53564453  0.47802734
   0.51025391  0.51855469  0.52978516  0.49853516  0.49804688  0.50683594
   0.49682617  0.49243164  0.48730469  0.49926758  0.50341797  0.54150391
   0.50634766  0.52587891  0.50488281  0.48876953  0.52636719  0.51660156
   0.52783203  0.50976562  0.49829102  0.50585938  0.47216797  0.5078125
   0.50439453  0.50488281  0.52587891  0.50634766  0.51269531  0.49707031
   0.49975586  0.48974609  0.50976562  0.53173828  0.51806641  0.52294922
   0.51025391  0.54541016  0.50976562  0.52783203  0.51123047  0.50878906
   0.49169922  0.53369141  0.52294922  0.48461914  0.54492188  0.52001953
   0.4855957   0.51074219  0.4831543   0.51855469  0.52246094  0.53662109
   0.51464844  0.53125     0.53369141  0.49780273  0.52685547  0.49975586
   0.48803711  0.4909668   0.51220703  0.50097656  0.49682617  0.51318359
   0.49560547  0.52050781  0.52539062  0.49414062  0.51513672  0.53076172
   0.51318359  0.49633789  0.53857422  0.51416016  0.49633789  0.51708984
   0.515625    0.49707031  0.51220703  0.55273438  0.52392578  0.53271484
   0.51855469  0.52050781  0.49047852  0.50048828  0.48901367  0.53027344
   0.4934082   0.56738281  0.50537109  0.53076172  0.52099609  0.49926758
   0.51611328  0.53369141  0.48999023  0.48632812  0.48535156  0.48510742
   0.52636719  0.50048828  0.51953125  0.51953125  0.50537109  0.49707031
   0.55517578  0.55371094  0.51123047  0.48754883  0.50292969  0.5
   0.49560547  0.50341797  0.49487305  0.515625    0.52441406  0.50341797
   0.49536133  0.52392578  0.54882812  0.578125    0.48388672  0.515625
   0.52490234  0.47607422  0.50146484  0.50976562  0.52197266  0.48681641
   0.51855469  0.53076172  0.50146484  0.52099609]]
After layer encoder_birnn_reverse_l0_t2_f_output (1, 256) <class 'numpy.float16'> [[ 0.52636719  0.50488281  0.51806641  0.51269531  0.50683594  0.51269531
   0.53662109  0.48852539  0.56103516  0.52246094  0.53271484  0.51660156
   0.52099609  0.50439453  0.5234375   0.52246094  0.51806641  0.4909668
   0.47509766  0.50830078  0.52246094  0.49731445  0.55126953  0.51318359
   0.52441406  0.52050781  0.52734375  0.52636719  0.51904297  0.5
   0.50048828  0.49438477  0.54931641  0.4909668   0.4987793   0.50683594
   0.48657227  0.51416016  0.5         0.52050781  0.51464844  0.52148438
   0.50097656  0.52832031  0.50292969  0.5234375   0.50732422  0.49145508
   0.5         0.50830078  0.50976562  0.50732422  0.52294922  0.52783203
   0.53662109  0.52246094  0.50390625  0.51708984  0.5078125   0.49121094
   0.50244141  0.51171875  0.49658203  0.51660156  0.49780273  0.52978516
   0.54248047  0.51757812  0.48901367  0.50878906  0.51611328  0.49194336
   0.49902344  0.50244141  0.52148438  0.55078125  0.51220703  0.50244141
   0.50634766  0.51611328  0.54589844  0.53027344  0.50683594  0.50537109
   0.52929688  0.50634766  0.51220703  0.55078125  0.50732422  0.48706055
   0.55078125  0.5234375   0.51855469  0.51904297  0.49389648  0.50390625
   0.51074219  0.53857422  0.47973633  0.47583008  0.50927734  0.50488281
   0.49731445  0.52148438  0.50634766  0.49707031  0.48339844  0.515625
   0.50244141  0.49511719  0.4921875   0.50244141  0.49804688  0.52294922
   0.52636719  0.54199219  0.52001953  0.52587891  0.54345703  0.52099609
   0.53857422  0.53125     0.50146484  0.50390625  0.50683594  0.49658203
   0.53076172  0.49926758  0.52099609  0.48632812  0.51367188  0.54589844
   0.50634766  0.53564453  0.52832031  0.52539062  0.50732422  0.50195312
   0.53125     0.52783203  0.484375    0.52050781  0.51806641  0.51123047
   0.50488281  0.52587891  0.5         0.50341797  0.50097656  0.49780273
   0.49169922  0.51416016  0.50146484  0.51513672  0.52441406  0.54052734
   0.52734375  0.51318359  0.49975586  0.52587891  0.54638672  0.51953125
   0.4909668   0.51806641  0.50634766  0.50488281  0.54980469  0.48510742
   0.50097656  0.49560547  0.51513672  0.52001953  0.48413086  0.53857422
   0.50195312  0.51708984  0.53222656  0.50585938  0.50244141  0.52294922
   0.52246094  0.48364258  0.54248047  0.49121094  0.50976562  0.49243164
   0.50537109  0.53027344  0.53417969  0.50195312  0.4909668   0.50488281
   0.53564453  0.53417969  0.52539062  0.49731445  0.49291992  0.50537109
   0.50488281  0.50341797  0.50292969  0.52246094  0.52441406  0.48852539
   0.51171875  0.47949219  0.50097656  0.53125     0.50683594  0.50976562
   0.51123047  0.52978516  0.48828125  0.50537109  0.49194336  0.48974609
   0.50927734  0.51904297  0.50341797  0.52197266  0.47827148  0.50097656
   0.54833984  0.5078125   0.51171875  0.49780273  0.50732422  0.50390625
   0.55859375  0.56103516  0.49951172  0.45483398  0.52978516  0.50878906
   0.51367188  0.50097656  0.50927734  0.52099609  0.50146484  0.5234375
   0.52099609  0.49755859  0.52490234  0.55664062  0.47460938  0.49511719
   0.50830078  0.47900391  0.51611328  0.49951172  0.52246094  0.48168945
   0.52929688  0.49365234  0.53027344  0.50341797]]
After layer _mul2076_0 (1, 256) <class 'numpy.float16'> [[-0.02680969 -0.0138855   0.01564026  0.01159668  0.02716064 -0.01589966
   0.01153564  0.00196075 -0.03051758 -0.04782104 -0.01947021  0.013237
   0.02832031 -0.02877808  0.03405762 -0.03674316  0.00492477 -0.00891113
   0.00750351  0.01731873  0.03979492 -0.03372192  0.01328278  0.01535797
   0.00854492  0.00176239 -0.03897095  0.00419235 -0.00971985 -0.01773071
   0.02426147 -0.03643799  0.02430725 -0.0246582   0.01334381 -0.03390503
  -0.02348328 -0.02476501 -0.00795746  0.0131073   0.03353882  0.0057373
   0.02363586  0.00725555  0.03125    -0.03552246  0.02307129 -0.00811768
  -0.00268745  0.00414276 -0.02058411 -0.02609253 -0.01794434  0.01547241
   0.01882935 -0.01060486 -0.02426147  0.0496521   0.01152802 -0.03390503
  -0.03527832 -0.01194    -0.01033783 -0.00887299  0.05328369 -0.01876831
   0.04278564  0.02407837 -0.02017212 -0.00594711 -0.05786133  0.03024292
   0.01008606 -0.02062988  0.03863525 -0.01018524 -0.05316162 -0.02445984
  -0.0249176  -0.01522827 -0.0171814  -0.02798462 -0.00366592 -0.04379272
  -0.03765869  0.02035522 -0.01308441  0.01989746 -0.01867676 -0.00888824
   0.02484131  0.00917053  0.01280212 -0.022995   -0.00525284 -0.00701523
   0.00280952 -0.02435303  0.00047755 -0.01126862  0.03640747  0.01742554
  -0.02941895  0.01095581 -0.02114868  0.02510071 -0.00888824 -0.01016235
   0.00698853 -0.00524521  0.0335083   0.03097534  0.0046196   0.03131104
  -0.02830505  0.00635147 -0.02165222 -0.02987671  0.02615356  0.02130127
   0.01571655  0.03399658 -0.00410843 -0.02922058  0.02371216 -0.04336548
   0.02487183 -0.03323364  0.00513077  0.04208374  0.03077698 -0.0125351
   0.01422119 -0.0282135   0.02320862  0.02407837  0.02839661  0.0307312
  -0.00847626  0.02754211 -0.01454163 -0.01629639  0.03665161 -0.01069641
  -0.00298119  0.01454163  0.02973938 -0.03219604  0.0070343   0.00865936
  -0.01425934 -0.00473404 -0.01724243 -0.00946808  0.02186584  0.00287056
  -0.02113342  0.00845337  0.01070404  0.0226593  -0.06610107 -0.02972412
  -0.00505829 -0.00279427 -0.00206757  0.02784729 -0.00070477 -0.04653931
  -0.04278564 -0.02980042 -0.03186035  0.02438354 -0.00909424 -0.02734375
   0.00664902  0.00330162  0.05715942 -0.0276947  -0.03024292 -0.01463318
   0.03375244  0.01151276  0.01072693 -0.00279236  0.03869629 -0.02288818
   0.00563812 -0.04205322  0.02268982 -0.01132202  0.05569458  0.03161621
  -0.01739502  0.00162888 -0.05014038  0.01858521 -0.03601074 -0.03961182
   0.01644897  0.03201294 -0.01795959 -0.01428223  0.04104614 -0.0098877
   0.03244019 -0.01093292 -0.00233078  0.00057983  0.05993652 -0.034729
   0.00627136  0.03067017  0.01829529 -0.0043602  -0.01509094 -0.02287292
  -0.00554657 -0.00110722  0.01296997  0.03083801  0.01872253  0.00405502
   0.01852417 -0.02090454 -0.00239182 -0.00080156  0.00257111  0.00257492
   0.00352478  0.00435638 -0.02189636  0.00403595  0.0249939   0.00836182
  -0.02305603  0.0096283  -0.02101135  0.00914764 -0.02635193  0.01423645
   0.00129223 -0.02124023  0.00852966 -0.03265381 -0.01934814 -0.00952148
  -0.0023613  -0.00258064 -0.01036072  0.04595947  0.04922485  0.01261902
   0.01516724 -0.00748062  0.00986481 -0.03347778]]
After layer encoder_birnn_reverse_l0_t2_i_output (1, 256) <class 'numpy.float16'> [[ 0.50195312  0.49780273  0.51025391  0.49462891  0.51904297  0.50683594
   0.51708984  0.5078125   0.51757812  0.51416016  0.48950195  0.51025391
   0.50683594  0.51416016  0.50048828  0.55419922  0.49291992  0.48974609
   0.50488281  0.49316406  0.52148438  0.51708984  0.48535156  0.48681641
   0.52050781  0.47753906  0.49438477  0.49853516  0.51367188  0.50195312
   0.49853516  0.48730469  0.49291992  0.49023438  0.51757812  0.48193359
   0.50146484  0.49780273  0.48925781  0.4934082   0.48779297  0.515625
   0.48608398  0.50244141  0.51025391  0.50097656  0.51757812  0.48242188
   0.50488281  0.49658203  0.49316406  0.51953125  0.50585938  0.51708984
   0.55371094  0.51757812  0.49267578  0.49755859  0.49682617  0.49389648
   0.51416016  0.48876953  0.53320312  0.49365234  0.47607422  0.48779297
   0.52294922  0.49829102  0.49633789  0.51269531  0.52246094  0.49584961
   0.50146484  0.50244141  0.49169922  0.52539062  0.53076172  0.52441406
   0.49414062  0.50732422  0.50634766  0.50683594  0.52148438  0.49658203
   0.53613281  0.51757812  0.49267578  0.5         0.48779297  0.54199219
   0.53613281  0.49755859  0.48022461  0.53173828  0.51611328  0.51318359
   0.49487305  0.53564453  0.48608398  0.47998047  0.49414062  0.51660156
   0.49414062  0.46411133  0.49633789  0.49804688  0.49975586  0.47045898
   0.51074219  0.52294922  0.46557617  0.515625    0.49682617  0.53222656
   0.49755859  0.56298828  0.49462891  0.50341797  0.53076172  0.49682617
   0.54736328  0.47680664  0.49658203  0.52148438  0.48706055  0.51220703
   0.4765625   0.51171875  0.49755859  0.49975586  0.52880859  0.51757812
   0.50634766  0.49682617  0.49316406  0.49829102  0.52050781  0.53369141
   0.50488281  0.49731445  0.4921875   0.48632812  0.50976562  0.51806641
   0.49438477  0.50195312  0.50585938  0.51855469  0.49414062  0.51513672
   0.51855469  0.49243164  0.50097656  0.48071289  0.49462891  0.54492188
   0.51025391  0.53271484  0.4987793   0.49560547  0.53466797  0.49975586
   0.49462891  0.51416016  0.50927734  0.49145508  0.50732422  0.49291992
   0.51855469  0.49633789  0.50878906  0.50732422  0.50097656  0.51953125
   0.51025391  0.47875977  0.50927734  0.47705078  0.48999023  0.49609375
   0.50439453  0.49194336  0.48852539  0.51220703  0.52539062  0.49243164
   0.49584961  0.48681641  0.53613281  0.52587891  0.49829102  0.50634766
   0.50830078  0.50537109  0.54150391  0.51318359  0.51269531  0.46777344
   0.51171875  0.50488281  0.49853516  0.54443359  0.51513672  0.50097656
   0.50976562  0.50195312  0.50097656  0.4921875   0.49267578  0.50927734
   0.50439453  0.51904297  0.50341797  0.51904297  0.50732422  0.52148438
   0.49902344  0.4934082   0.49926758  0.50195312  0.48754883  0.50195312
   0.50878906  0.47705078  0.50390625  0.52099609  0.49291992  0.48535156
   0.49389648  0.54882812  0.49462891  0.49682617  0.4987793   0.49682617
   0.50830078  0.51660156  0.49829102  0.50878906  0.50634766  0.49023438
   0.49243164  0.48266602  0.53564453  0.5546875   0.49389648  0.51171875
   0.51318359  0.48535156  0.50097656  0.51708984  0.53027344  0.50390625
   0.4855957   0.51171875  0.50732422  0.49145508]]
After layer encoder_birnn_reverse_l0_t2_c_output (1, 256) <class 'numpy.float16'> [[ -1.17675781e-01  -1.18713379e-01   3.47900391e-03   3.65295410e-02
    3.79333496e-02  -3.86657715e-02   4.27246094e-02   1.07971191e-01
    5.05676270e-02  -4.33044434e-02  -6.20422363e-02   9.23461914e-02
    9.35668945e-02  -3.45764160e-02   5.27343750e-02  -1.76269531e-01
    1.35345459e-02   5.37109375e-03   7.14111328e-02   4.77905273e-02
    1.61132812e-01  -1.64794922e-02   7.93457031e-04   8.36791992e-02
   -1.05712891e-01   3.75671387e-02   6.13403320e-02  -2.48107910e-02
   -1.31591797e-01  -7.67822266e-02   1.33056641e-02  -1.25976562e-01
   -3.72619629e-02   6.56127930e-03   1.05346680e-01  -1.16149902e-01
   -6.93359375e-02  -7.43103027e-03  -1.16760254e-01  -9.66796875e-02
    3.93981934e-02  -1.61376953e-01   1.08947754e-01   9.39331055e-02
    7.94067383e-02  -9.15527344e-02   3.91540527e-02  -7.73925781e-02
   -5.21850586e-03  -7.81860352e-02   5.13610840e-02  -8.74633789e-02
   -6.40869141e-02   6.60400391e-02   6.21643066e-02   3.41491699e-02
   -5.83496094e-02   1.52099609e-01   6.61621094e-02  -5.03234863e-02
   -3.83605957e-02  -9.94262695e-02  -4.66918945e-02   1.83105469e-04
    6.06384277e-02  -2.73590088e-02   4.12292480e-02  -7.08618164e-02
   -1.24816895e-01  -4.55322266e-02  -1.91040039e-01  -1.95312500e-02
    6.68334961e-02   4.35485840e-02   1.11816406e-01  -6.21643066e-02
    1.64794922e-03  -1.28417969e-01  -4.21447754e-02  -1.98669434e-02
   -8.52050781e-02   2.71759033e-02  -6.90307617e-02  -1.20361328e-01
   -2.06420898e-01   2.26440430e-02  -1.59057617e-01   3.91235352e-02
   -1.20727539e-01  -1.13647461e-01  -8.81958008e-02  -6.53686523e-02
   -3.48510742e-02  -1.93481445e-02  -4.08020020e-02   3.47290039e-02
    1.08703613e-01  -2.24304199e-02  -1.14135742e-01  -5.13305664e-02
    3.00445557e-02   1.19873047e-01  -7.01904297e-02   4.41894531e-02
    5.99060059e-02   6.89086914e-02  -4.67834473e-02  -4.01000977e-02
    1.48193359e-01  -1.51733398e-01   4.91943359e-02   1.03912354e-02
    4.76074219e-02   3.49731445e-02  -8.67919922e-02   2.24609375e-01
   -1.11572266e-01  -3.23486328e-02   2.84881592e-02  -4.40979004e-02
    1.16027832e-01   1.01928711e-01  -3.05175781e-02  -5.83496094e-02
    1.04003906e-01  -1.47827148e-01  -8.14819336e-02  -3.93066406e-02
   -3.48205566e-02  -3.55224609e-02   5.54199219e-02  -5.52368164e-02
    7.77587891e-02  -1.90734863e-02  -3.26538086e-03   5.24597168e-02
    1.09924316e-01   1.69555664e-01  -4.65393066e-03   5.07507324e-02
   -1.23596191e-02  -5.50842285e-02   1.02844238e-01   1.45187378e-02
   -1.24145508e-01   8.06884766e-02   3.87878418e-02  -1.17797852e-01
   -1.03027344e-01  -9.01489258e-02  -7.10449219e-02  -3.42407227e-02
   -2.76489258e-02  -1.03149414e-01  -4.01916504e-02   6.35986328e-02
   -9.06372070e-02   6.77490234e-02   5.26428223e-02   5.23071289e-02
   -1.45996094e-01  -7.40356445e-02   4.32434082e-02   1.45507812e-01
    1.99737549e-02   8.07495117e-02   7.69805908e-03  -7.01904297e-02
   -1.26708984e-01   2.08129883e-02  -6.49414062e-02   1.43432617e-02
   -1.93786621e-02  -1.21704102e-01  -2.11334229e-02   6.76269531e-02
    1.11206055e-01  -3.92761230e-02  -7.55615234e-02  -3.97338867e-02
    6.30493164e-02  -1.03454590e-02   2.80303955e-02  -2.97088623e-02
   -6.28051758e-02   7.12280273e-02   3.43933105e-02  -9.45434570e-02
    9.30175781e-02  -1.07299805e-01   1.37817383e-01  -3.01971436e-02
    3.20739746e-02  -1.15966797e-02  -1.10961914e-01  -1.13220215e-02
   -1.68090820e-01  -7.76977539e-02  -2.02331543e-02   2.50549316e-02
   -1.28906250e-01  -2.13623047e-04   1.59057617e-01  -7.03125000e-02
   -2.64434814e-02  -1.98364258e-04   4.97741699e-02  -5.77926636e-03
    7.10449219e-02  -9.00268555e-02  -1.54296875e-01  -4.82177734e-03
    1.87988281e-02  -1.19201660e-01  -5.81665039e-02  -6.86645508e-02
    2.37121582e-02  -4.31213379e-02  -6.22558594e-03   8.40454102e-02
   -4.05273438e-02  -9.63134766e-02   7.18994141e-02   1.16424561e-02
   -3.89099121e-03  -3.96728516e-02  -7.48443604e-03   4.49523926e-02
    5.93872070e-02  -2.81372070e-02  -1.32934570e-01   1.61132812e-01
    5.93566895e-02   9.33227539e-02  -6.60400391e-02   7.13500977e-02
   -1.18469238e-01   1.50909424e-02  -1.17980957e-01   1.35620117e-01
    3.51867676e-02  -3.18603516e-02   1.17492676e-02  -6.79931641e-02
   -3.61328125e-02  -8.59985352e-02  -5.72509766e-02  -1.28784180e-01
   -1.98364258e-04   2.01416016e-01   1.35864258e-01   8.69140625e-02
    6.31103516e-02  -6.11877441e-02  -4.88586426e-02  -1.15814209e-02]]
After layer _mul2077_0 (1, 256) <class 'numpy.float16'> [[ -5.90820312e-02  -5.90820312e-02   1.77478790e-03   1.80664062e-02
    1.96838379e-02  -1.95922852e-02   2.20947266e-02   5.48400879e-02
    2.61688232e-02  -2.22625732e-02  -3.03649902e-02   4.71191406e-02
    4.74243164e-02  -1.77764893e-02   2.63977051e-02  -9.77172852e-02
    6.67190552e-03   2.63023376e-03   3.60412598e-02   2.35748291e-02
    8.40454102e-02  -8.52203369e-03   3.85046005e-04   4.07409668e-02
   -5.50231934e-02   1.79443359e-02   3.03192139e-02  -1.23672485e-02
   -6.75659180e-02  -3.85437012e-02   6.63375854e-03  -6.14013672e-02
   -1.83715820e-02   3.21578979e-03   5.45349121e-02  -5.59692383e-02
   -3.47595215e-02  -3.69834900e-03  -5.71289062e-02  -4.76989746e-02
    1.92108154e-02  -8.31909180e-02   5.29479980e-02   4.72106934e-02
    4.05273438e-02  -4.58679199e-02   2.02636719e-02  -3.73229980e-02
   -2.63404846e-03  -3.88183594e-02   2.53295898e-02  -4.54406738e-02
   -3.24096680e-02   3.41491699e-02   3.44238281e-02   1.76696777e-02
   -2.87475586e-02   7.56835938e-02   3.28674316e-02  -2.48565674e-02
   -1.97296143e-02  -4.85839844e-02  -2.49023438e-02   9.03606415e-05
    2.88696289e-02  -1.33438110e-02   2.15606689e-02  -3.53088379e-02
   -6.19506836e-02  -2.33459473e-02  -9.97924805e-02  -9.68170166e-03
    3.35083008e-02   2.18811035e-02   5.49926758e-02  -3.26538086e-02
    8.74519348e-04  -6.73217773e-02  -2.08282471e-02  -1.00784302e-02
   -4.31518555e-02   1.37710571e-02  -3.60107422e-02  -5.97839355e-02
   -1.10656738e-01   1.17187500e-02  -7.83691406e-02   1.95617676e-02
   -5.88989258e-02  -6.15844727e-02  -4.72717285e-02  -3.25317383e-02
   -1.67388916e-02  -1.02844238e-02  -2.10571289e-02   1.78222656e-02
    5.38024902e-02  -1.20162964e-02  -5.54809570e-02  -2.46429443e-02
    1.48468018e-02   6.19201660e-02  -3.46984863e-02   2.05078125e-02
    2.97393799e-02   3.43322754e-02  -2.33764648e-02  -1.88598633e-02
    7.56835938e-02  -7.93457031e-02   2.29034424e-02   5.35964966e-03
    2.36511230e-02   1.86157227e-02  -4.31823730e-02   1.26464844e-01
   -5.51757812e-02  -1.62811279e-02   1.51214600e-02  -2.19116211e-02
    6.35375977e-02   4.86145020e-02  -1.51519775e-02  -3.04260254e-02
    5.06591797e-02  -7.57446289e-02  -3.88183594e-02  -2.01110840e-02
   -1.73187256e-02  -1.77459717e-02   2.93121338e-02  -2.85949707e-02
    3.93676758e-02  -9.47570801e-03  -1.61075592e-03   2.61383057e-02
    5.72204590e-02   9.05151367e-02  -2.34985352e-03   2.52380371e-02
   -6.08444214e-03  -2.67944336e-02   5.24291992e-02   7.52258301e-03
   -6.13708496e-02   4.04968262e-02   1.96228027e-02  -6.10961914e-02
   -5.09033203e-02  -4.64477539e-02  -3.68347168e-02  -1.68609619e-02
   -1.38549805e-02  -4.95910645e-02  -1.98822021e-02   3.46679688e-02
   -4.62341309e-02   3.61022949e-02   2.62603760e-02   2.59246826e-02
   -7.80639648e-02  -3.69873047e-02   2.13928223e-02   7.48291016e-02
    1.01699829e-02   3.96728516e-02   3.90625000e-03  -3.46069336e-02
   -6.57348633e-02   1.03302002e-02  -3.30505371e-02   7.27844238e-03
   -9.70458984e-03  -6.32324219e-02  -1.07803345e-02   3.23791504e-02
    5.66406250e-02  -1.87377930e-02  -3.70178223e-02  -1.97143555e-02
    3.17993164e-02  -5.08880615e-03   1.36947632e-02  -1.52206421e-02
   -3.29895020e-02   3.50646973e-02   1.70593262e-02  -4.60205078e-02
    4.98657227e-02  -5.64270020e-02   6.86645508e-02  -1.52893066e-02
    1.62963867e-02  -5.85937500e-03  -6.00891113e-02  -5.80978394e-03
   -8.61816406e-02  -3.63464355e-02  -1.03530884e-02   1.26495361e-02
   -6.42700195e-02  -1.16288662e-04   8.19091797e-02  -3.52172852e-02
   -1.34811401e-02  -9.95397568e-05   2.49328613e-02  -2.84385681e-03
    3.50036621e-02  -4.58374023e-02  -7.78198242e-02  -2.50244141e-03
    9.46044922e-03  -6.18591309e-02  -2.95104980e-02  -3.57971191e-02
    1.18331909e-02  -2.12707520e-02  -3.10897827e-03   4.21752930e-02
   -1.97601318e-02  -4.83398438e-02   3.65905762e-02   5.55419922e-03
   -1.96075439e-03  -2.06756592e-02  -3.68881226e-03   2.18200684e-02
    2.93273926e-02  -1.54418945e-02  -6.57348633e-02   8.00781250e-02
    2.96020508e-02   4.63562012e-02  -3.35693359e-02   3.68652344e-02
   -5.90209961e-02   7.67898560e-03  -5.97534180e-02   6.64672852e-02
    1.73339844e-02  -1.53808594e-02   6.29425049e-03  -3.77197266e-02
   -1.78527832e-02  -4.40063477e-02  -2.93731689e-02  -6.25000000e-02
   -9.93609428e-05   1.04125977e-01   7.20214844e-02   4.37927246e-02
    3.06396484e-02  -3.13110352e-02  -2.47802734e-02  -5.69152832e-03]]
After layer encoder_birnn_reverse_l0_t2_state_0 (1, 256) <class 'numpy.float16'> [[-0.08587646 -0.07299805  0.01741028  0.02966309  0.04684448 -0.03549194
   0.03363037  0.05679321 -0.00434875 -0.07006836 -0.04983521  0.06036377
   0.07574463 -0.04656982  0.06045532 -0.13452148  0.01159668 -0.00627899
   0.04354858  0.04089355  0.12384033 -0.04223633  0.01366425  0.05609131
  -0.04647827  0.01971436 -0.00865173 -0.00817871 -0.07727051 -0.05627441
   0.03089905 -0.09783936  0.00593567 -0.0214386   0.06787109 -0.08984375
  -0.05822754 -0.02845764 -0.06506348 -0.03460693  0.05273438 -0.07745361
   0.07659912  0.05447388  0.07177734 -0.0814209   0.04333496 -0.04544067
  -0.0053215  -0.03466797  0.00474548 -0.0715332  -0.050354    0.04962158
   0.05325317  0.00706482 -0.05300903  0.12536621  0.04440308 -0.05877686
  -0.05499268 -0.06051636 -0.0352478  -0.00878143  0.08215332 -0.03210449
   0.06433105 -0.01123047 -0.08215332 -0.02929688 -0.15771484  0.02056885
   0.0435791   0.00125122  0.09362793 -0.04284668 -0.05227661 -0.09179688
  -0.04574585 -0.02529907 -0.06033325 -0.01421356 -0.03967285 -0.10357666
  -0.14831543  0.03207397 -0.09143066  0.03945923 -0.07757568 -0.07049561
  -0.02243042 -0.02336121 -0.00393677 -0.03326416 -0.02630615  0.01080322
   0.05661011 -0.03637695 -0.05499268 -0.03591919  0.05126953  0.0793457
  -0.06408691  0.03146362  0.0085907   0.05944824 -0.03225708 -0.02902222
   0.0826416  -0.08459473  0.05639648  0.03634644  0.02827454  0.04992676
  -0.07147217  0.1328125  -0.07684326 -0.04614258  0.04125977 -0.00061035
   0.07922363  0.0826416  -0.01925659 -0.05963135  0.07434082 -0.11914062
  -0.01394653 -0.05334473 -0.01219177  0.02433777  0.06008911 -0.0411377
   0.05358887 -0.03768921  0.02159119  0.05023193  0.08563232  0.12121582
  -0.01082611  0.05279541 -0.02062988 -0.04309082  0.08911133 -0.00317383
  -0.06433105  0.05505371  0.04937744 -0.09326172 -0.04388428 -0.03778076
  -0.05108643 -0.02159119 -0.03109741 -0.05905151  0.00198364  0.03753662
  -0.06738281  0.04455566  0.03695679  0.04858398 -0.14416504 -0.06671143
   0.0163269   0.07202148  0.00810242  0.06750488  0.00320053 -0.08117676
  -0.10852051 -0.01947021 -0.06494141  0.03167725 -0.01879883 -0.09057617
  -0.00413132  0.03567505  0.11376953 -0.04644775 -0.06726074 -0.03436279
   0.06555176  0.00642395  0.02441406 -0.01800537  0.00570679  0.01217651
   0.02270508 -0.08807373  0.0725708  -0.06774902  0.12438965  0.0163269
  -0.00109863 -0.0042305  -0.11022949  0.01277161 -0.12219238 -0.07592773
   0.00609589  0.04467773 -0.08221436 -0.01439667  0.1229248  -0.04510498
   0.01895142 -0.0110321   0.02259827 -0.00226402  0.0949707  -0.08056641
  -0.0715332   0.02816772  0.02775574 -0.06622314 -0.0446167  -0.05865479
   0.00628662 -0.02238464  0.00985718  0.07299805 -0.0010376  -0.04428101
   0.05511475 -0.01535034 -0.00435257 -0.02148438 -0.00111771  0.0243988
   0.03283691 -0.01108551 -0.08764648  0.08410645  0.05459595  0.05471802
  -0.05664062  0.04650879 -0.08001709  0.01683044 -0.08612061  0.08068848
   0.01863098 -0.03662109  0.01482391 -0.07037354 -0.03720093 -0.05352783
  -0.03173828 -0.06506348 -0.0104599   0.15014648  0.12121582  0.05639648
   0.04580688 -0.03878784 -0.01491547 -0.03918457]]
After layer activation1038_output (1, 256) <class 'numpy.float16'> [[-0.08569336 -0.07287598  0.01741028  0.02964783  0.04681396 -0.03549194
   0.03363037  0.05673218 -0.00434875 -0.06994629 -0.04980469  0.06030273
   0.07562256 -0.04653931  0.06039429 -0.13366699  0.01159668 -0.00627899
   0.04351807  0.04086304  0.12322998 -0.04220581  0.01366425  0.05603027
  -0.04644775  0.01971436 -0.00865173 -0.00817871 -0.0770874  -0.05621338
   0.03088379 -0.09753418  0.00593567 -0.0214386   0.06774902 -0.08959961
  -0.0581665  -0.02844238 -0.06494141 -0.03460693  0.05267334 -0.07727051
   0.07647705  0.05441284  0.07165527 -0.08123779  0.04330444 -0.04541016
  -0.0053215  -0.03466797  0.00474548 -0.07141113 -0.05032349  0.04959106
   0.05319214  0.00706482 -0.052948    0.12469482  0.04437256 -0.05871582
  -0.05493164 -0.06045532 -0.0352478  -0.00878143  0.08197021 -0.03210449
   0.06427002 -0.01123047 -0.08197021 -0.02928162 -0.15637207  0.02056885
   0.04354858  0.00125122  0.09338379 -0.04281616 -0.05221558 -0.09155273
  -0.04571533 -0.02529907 -0.06027222 -0.01421356 -0.03964233 -0.10321045
  -0.1472168   0.03207397 -0.09118652  0.03942871 -0.07739258 -0.07037354
  -0.02243042 -0.02336121 -0.00393677 -0.03326416 -0.02630615  0.01080322
   0.05654907 -0.03634644 -0.05493164 -0.03588867  0.05123901  0.0791626
  -0.06402588  0.03146362  0.0085907   0.05938721 -0.03225708 -0.02900696
   0.0824585  -0.08441162  0.05633545  0.03631592  0.02827454  0.04989624
  -0.0713501   0.13208008 -0.07672119 -0.04611206  0.04122925 -0.00061035
   0.07904053  0.0824585  -0.01925659 -0.05957031  0.07421875 -0.11859131
  -0.01394653 -0.05328369 -0.01219177  0.02433777  0.06002808 -0.04110718
   0.05352783 -0.03765869  0.02159119  0.05020142  0.08544922  0.12060547
  -0.01082611  0.05273438 -0.02062988 -0.0430603   0.08886719 -0.00317383
  -0.06427002  0.05499268  0.04934692 -0.09301758 -0.04385376 -0.03775024
  -0.05105591 -0.02159119 -0.03108215 -0.05899048  0.00198364  0.0375061
  -0.06726074  0.04452515  0.03692627  0.04855347 -0.14318848 -0.06658936
   0.0163269   0.07189941  0.00810242  0.06738281  0.00320053 -0.08099365
  -0.10809326 -0.01947021 -0.06488037  0.03167725 -0.01879883 -0.09033203
  -0.00413132  0.03567505  0.11328125 -0.04641724 -0.06713867 -0.03436279
   0.06542969  0.00642395  0.02441406 -0.01800537  0.00570679  0.01217651
   0.02270508 -0.08782959  0.07244873 -0.06762695  0.1237793   0.0163269
  -0.00109863 -0.0042305  -0.10980225  0.01277161 -0.12158203 -0.07580566
   0.00609589  0.04464722 -0.08203125 -0.01439667  0.12231445 -0.04507446
   0.01895142 -0.0110321   0.02259827 -0.00226402  0.09466553 -0.0803833
  -0.07141113  0.02816772  0.02775574 -0.06610107 -0.04458618 -0.05859375
   0.00628662 -0.02238464  0.00985718  0.07287598 -0.0010376  -0.04425049
   0.05505371 -0.01535034 -0.00435257 -0.02148438 -0.00111771  0.0243988
   0.03283691 -0.01108551 -0.08740234  0.08392334  0.05453491  0.05465698
  -0.05657959  0.04647827 -0.07983398  0.01683044 -0.0859375   0.08050537
   0.01863098 -0.03659058  0.01482391 -0.07025146 -0.03717041 -0.0534668
  -0.03173828 -0.06494141 -0.0104599   0.14904785  0.12060547  0.05633545
   0.04577637 -0.03875732 -0.01491547 -0.03915405]]
After layer encoder_birnn_reverse_l0_t2_out_0 (1, 256) <class 'numpy.float16'> [[-0.04400635 -0.03665161  0.00863647  0.01514435  0.02432251 -0.01937866
   0.01768494  0.03024292 -0.0024662  -0.03723145 -0.0247345   0.03123474
   0.04003906 -0.02284241  0.03063965 -0.06988525  0.00570679 -0.00311089
   0.02177429  0.02015686  0.06106567 -0.01972961  0.00753403  0.02929688
  -0.02433777  0.00991821 -0.00432205 -0.00414276 -0.03741455 -0.02854919
   0.01612854 -0.05142212  0.00301361 -0.01079559  0.03341675 -0.04492188
  -0.03033447 -0.0140686  -0.03408813 -0.01742554  0.02775574 -0.03814697
   0.03820801  0.02723694  0.03546143 -0.04077148  0.02192688 -0.02227783
  -0.00273705 -0.01768494  0.00248909 -0.03439331 -0.02613831  0.02554321
   0.02960205  0.00335693 -0.02799988  0.06317139  0.02243042 -0.02809143
  -0.02784729 -0.03025818 -0.01792908 -0.004673    0.04071045 -0.01568604
   0.03414917 -0.00577927 -0.04241943 -0.01551056 -0.07873535  0.01053619
   0.02215576  0.00061655  0.0480957  -0.02389526 -0.02746582 -0.04714966
  -0.0239563  -0.01373291 -0.03207397 -0.00771713 -0.02061462 -0.05514526
  -0.07720947  0.01663208 -0.04653931  0.02105713 -0.03994751 -0.03775024
  -0.01186371 -0.01160431 -0.00188446 -0.01693726 -0.01356506  0.00547028
   0.02935791 -0.01954651 -0.02601624 -0.01757812  0.02597046  0.03762817
  -0.03167725  0.01528168  0.00437927  0.029953   -0.01580811 -0.01544189
   0.04202271 -0.0463562   0.02827454  0.01852417  0.01366425  0.02636719
  -0.03649902  0.07055664 -0.03677368 -0.02256775  0.02207947 -0.00029182
   0.04034424  0.04275513 -0.0102005  -0.0296936   0.03695679 -0.06011963
  -0.00692749 -0.02624512 -0.00593948  0.01215363  0.0302124  -0.02226257
   0.02709961 -0.01980591  0.0109024   0.02453613  0.04498291  0.06231689
  -0.00571442  0.02688599 -0.01027679 -0.02178955  0.04196167 -0.00161171
  -0.03240967  0.027771    0.0259552  -0.04708862 -0.0224762  -0.01876831
  -0.0255127  -0.01057434 -0.01583862 -0.03137207  0.00102806  0.01960754
  -0.03433228  0.02429199  0.01882935  0.02563477 -0.07318115 -0.03387451
   0.00802612  0.0383606   0.00423813  0.03265381  0.00174427 -0.04211426
  -0.05249023 -0.0099411  -0.03134155  0.01643372 -0.00981903 -0.04846191
  -0.00212669  0.01895142  0.06045532 -0.02310181 -0.03536987 -0.01716614
   0.03192139  0.00315475  0.01250458 -0.00901794  0.00283623  0.00624847
   0.01125336 -0.04571533  0.03805542 -0.03341675  0.06378174  0.00866699
  -0.00056362 -0.00209999 -0.05914307  0.00656509 -0.06033325 -0.03918457
   0.00314331  0.02218628 -0.04202271 -0.00795746  0.06408691 -0.02401733
   0.00982666 -0.00574112  0.01108551 -0.00113297  0.04629517 -0.04263306
  -0.0352478   0.01597595  0.01403046 -0.03509521 -0.02322388 -0.0292511
   0.0032444  -0.01194763  0.00482941  0.03543091 -0.00050354 -0.02146912
   0.02897644 -0.0076828  -0.00226212 -0.0111618  -0.00056505  0.01213074
   0.01823425 -0.00613785 -0.04467773  0.04092407  0.02742004  0.02732849
  -0.02804565  0.02339172 -0.03952026  0.00867462 -0.04507446  0.04052734
   0.00923157 -0.01916504  0.00813293 -0.0406189  -0.01799011 -0.02757263
  -0.0166626  -0.03091431 -0.00524521  0.07598877  0.06292725  0.02742004
   0.02374268 -0.02056885 -0.00748062 -0.020401  ]]
After layer expand_dims1044_0 (1, 1, 256) <class 'numpy.float16'> [[[-0.04400635 -0.03665161  0.00863647  0.01514435  0.02432251 -0.01937866
    0.01768494  0.03024292 -0.0024662  -0.03723145 -0.0247345   0.03123474
    0.04003906 -0.02284241  0.03063965 -0.06988525  0.00570679 -0.00311089
    0.02177429  0.02015686  0.06106567 -0.01972961  0.00753403  0.02929688
   -0.02433777  0.00991821 -0.00432205 -0.00414276 -0.03741455 -0.02854919
    0.01612854 -0.05142212  0.00301361 -0.01079559  0.03341675 -0.04492188
   -0.03033447 -0.0140686  -0.03408813 -0.01742554  0.02775574 -0.03814697
    0.03820801  0.02723694  0.03546143 -0.04077148  0.02192688 -0.02227783
   -0.00273705 -0.01768494  0.00248909 -0.03439331 -0.02613831  0.02554321
    0.02960205  0.00335693 -0.02799988  0.06317139  0.02243042 -0.02809143
   -0.02784729 -0.03025818 -0.01792908 -0.004673    0.04071045 -0.01568604
    0.03414917 -0.00577927 -0.04241943 -0.01551056 -0.07873535  0.01053619
    0.02215576  0.00061655  0.0480957  -0.02389526 -0.02746582 -0.04714966
   -0.0239563  -0.01373291 -0.03207397 -0.00771713 -0.02061462 -0.05514526
   -0.07720947  0.01663208 -0.04653931  0.02105713 -0.03994751 -0.03775024
   -0.01186371 -0.01160431 -0.00188446 -0.01693726 -0.01356506  0.00547028
    0.02935791 -0.01954651 -0.02601624 -0.01757812  0.02597046  0.03762817
   -0.03167725  0.01528168  0.00437927  0.029953   -0.01580811 -0.01544189
    0.04202271 -0.0463562   0.02827454  0.01852417  0.01366425  0.02636719
   -0.03649902  0.07055664 -0.03677368 -0.02256775  0.02207947 -0.00029182
    0.04034424  0.04275513 -0.0102005  -0.0296936   0.03695679 -0.06011963
   -0.00692749 -0.02624512 -0.00593948  0.01215363  0.0302124  -0.02226257
    0.02709961 -0.01980591  0.0109024   0.02453613  0.04498291  0.06231689
   -0.00571442  0.02688599 -0.01027679 -0.02178955  0.04196167 -0.00161171
   -0.03240967  0.027771    0.0259552  -0.04708862 -0.0224762  -0.01876831
   -0.0255127  -0.01057434 -0.01583862 -0.03137207  0.00102806  0.01960754
   -0.03433228  0.02429199  0.01882935  0.02563477 -0.07318115 -0.03387451
    0.00802612  0.0383606   0.00423813  0.03265381  0.00174427 -0.04211426
   -0.05249023 -0.0099411  -0.03134155  0.01643372 -0.00981903 -0.04846191
   -0.00212669  0.01895142  0.06045532 -0.02310181 -0.03536987 -0.01716614
    0.03192139  0.00315475  0.01250458 -0.00901794  0.00283623  0.00624847
    0.01125336 -0.04571533  0.03805542 -0.03341675  0.06378174  0.00866699
   -0.00056362 -0.00209999 -0.05914307  0.00656509 -0.06033325 -0.03918457
    0.00314331  0.02218628 -0.04202271 -0.00795746  0.06408691 -0.02401733
    0.00982666 -0.00574112  0.01108551 -0.00113297  0.04629517 -0.04263306
   -0.0352478   0.01597595  0.01403046 -0.03509521 -0.02322388 -0.0292511
    0.0032444  -0.01194763  0.00482941  0.03543091 -0.00050354 -0.02146912
    0.02897644 -0.0076828  -0.00226212 -0.0111618  -0.00056505  0.01213074
    0.01823425 -0.00613785 -0.04467773  0.04092407  0.02742004  0.02732849
   -0.02804565  0.02339172 -0.03952026  0.00867462 -0.04507446  0.04052734
    0.00923157 -0.01916504  0.00813293 -0.0406189  -0.01799011 -0.02757263
   -0.0166626  -0.03091431 -0.00524521  0.07598877  0.06292725  0.02742004
    0.02374268 -0.02056885 -0.00748062 -0.020401  ]]]
After layer encoder_birnn_reverse_l0_t3_i2h_output (1, 1024) <class 'numpy.float16'> [[-0.0128479  -0.04095459  0.03787231 ...,  0.06970215 -0.04626465
   0.03759766]]
After layer encoder_birnn_reverse_l0_t3_h2h_output (1, 1024) <class 'numpy.float16'> [[ 0.01338196  0.03060913 -0.02444458 ...,  0.05984497  0.03833008
   0.03903198]]
After layer _plus1039_0 (1, 1024) <class 'numpy.float16'> [[ 0.00053406 -0.01034546  0.01342773 ...,  0.1295166  -0.00793457
   0.07666016]]
After layer encoder_birnn_reverse_l0_t3_slice_output0 (1, 256) <class 'numpy.float16'> [[  5.34057617e-04  -1.03454590e-02   1.34277344e-02  -1.90887451e-02
    6.86645508e-02   6.71386719e-03   5.17883301e-02   2.80303955e-02
    8.33740234e-02   5.13305664e-02  -3.73840332e-02   6.06079102e-02
    2.41394043e-02   5.10864258e-02  -6.71386719e-04   2.36938477e-01
   -6.44531250e-02  -5.05676270e-02   1.53198242e-02  -1.51977539e-02
    8.10546875e-02   4.27856445e-02  -7.29370117e-02  -3.96118164e-02
    8.94775391e-02  -1.08032227e-01  -2.68859863e-02  -1.67083740e-02
    4.28466797e-02  -9.47570801e-03   2.63977051e-03  -2.71301270e-02
   -3.46679688e-02  -4.53796387e-02   6.75048828e-02  -1.01928711e-01
   -2.65502930e-03  -4.63104248e-03  -6.15539551e-02  -3.85742188e-02
   -6.79321289e-02   4.36401367e-02  -5.42907715e-02   4.42504883e-03
    3.80859375e-02  -2.25830078e-03   6.52465820e-02  -7.18994141e-02
    1.02233887e-03   9.55200195e-03  -1.33666992e-02   8.89892578e-02
   -2.67944336e-02   6.53076172e-02   1.98608398e-01   8.66699219e-02
   -4.30603027e-02   4.53186035e-03  -4.04663086e-02  -2.39257812e-02
    6.34765625e-02  -3.98864746e-02   1.48803711e-01  -2.53143311e-02
   -1.05651855e-01  -4.30297852e-02   9.13085938e-02  -1.18865967e-02
   -4.00390625e-02   2.91137695e-02   9.18579102e-02  -2.29339600e-02
    6.28662109e-03   3.31878662e-03  -1.62353516e-02   7.93457031e-02
    1.24572754e-01   1.22802734e-01  -4.24194336e-03   3.90625000e-02
    2.58789062e-02   4.18701172e-02   8.63037109e-02  -1.50451660e-02
    1.53808594e-01   6.46972656e-02  -2.73437500e-02  -1.79901123e-02
   -3.47290039e-02   1.23046875e-01   1.25366211e-01  -2.19116211e-02
   -7.80029297e-02   1.02172852e-01   7.45239258e-02   4.86755371e-02
   -1.95465088e-02   1.15234375e-01  -7.23266602e-02  -9.38110352e-02
   -4.92858887e-02   7.21435547e-02  -1.28784180e-02  -1.39892578e-01
   -3.87573242e-02   2.42614746e-03  -1.39312744e-02  -1.12426758e-01
    4.66308594e-02   6.96411133e-02  -1.26586914e-01   4.60205078e-02
    6.48498535e-03   1.53320312e-01  -4.36401367e-03   2.71484375e-01
   -3.06396484e-02   9.61303711e-03   7.33642578e-02  -3.08837891e-02
    1.99707031e-01  -1.10473633e-01   6.10351562e-05   8.86230469e-02
   -4.69360352e-02   5.07812500e-02  -1.01562500e-01   5.99365234e-02
   -1.10931396e-02   1.89208984e-03   1.53808594e-01   6.82373047e-02
    3.05175781e-03  -2.45056152e-02  -5.15747070e-02  -3.32641602e-02
    8.53271484e-02   1.40869141e-01   1.10473633e-02  -1.70135498e-02
   -3.43933105e-02  -7.53173828e-02   6.08520508e-02   6.92138672e-02
   -3.25012207e-02  -6.71386719e-04   2.75878906e-02   6.20422363e-02
   -1.93176270e-02   5.56640625e-02   9.62524414e-02  -4.01611328e-02
    4.30297852e-03  -9.01489258e-02  -4.80346680e-02   1.86157227e-01
    3.58276367e-02   9.00878906e-02  -1.12304688e-02  -2.96325684e-02
    1.67114258e-01   9.21630859e-03  -3.52783203e-02   4.37622070e-02
    2.34985352e-02  -5.05981445e-02   1.96533203e-02  -3.74145508e-02
    6.28051758e-02  -2.89764404e-02   2.46887207e-02   3.48205566e-02
    7.53021240e-03   9.10034180e-02   3.55834961e-02  -9.94873047e-02
    3.58276367e-02  -1.03149414e-01  -4.28466797e-02  -2.19573975e-02
    2.75878906e-02  -5.29785156e-02  -2.96936035e-02   3.90930176e-02
    9.50317383e-02  -2.79541016e-02  -1.33438110e-02  -5.79528809e-02
    1.29882812e-01   7.67211914e-02  -1.40991211e-02   2.65502930e-03
    4.34570312e-02  -4.76074219e-03   1.10900879e-01   6.20727539e-02
    6.74438477e-02  -1.41479492e-01   4.54101562e-02   4.29077148e-02
   -2.99072266e-03   1.52221680e-01   6.18286133e-02   2.09350586e-02
    3.70178223e-02  -5.46264648e-03   4.88281250e-03  -4.38842773e-02
   -4.36706543e-02   4.52880859e-02   3.33251953e-02   8.56933594e-02
    1.99279785e-02   6.64062500e-02   2.17285156e-02   5.93872070e-02
   -5.04302979e-03  -2.37731934e-02   8.14819336e-03   8.43811035e-03
   -4.77600098e-02  -2.29492188e-02   5.44433594e-02  -7.51953125e-02
    1.46331787e-02   6.72607422e-02  -1.88293457e-02  -7.73925781e-02
   -4.05273438e-02   1.65283203e-01  -1.43890381e-02  -5.53588867e-02
   -1.61590576e-02  -2.92663574e-02   3.39355469e-02   6.45751953e-02
   -7.40814209e-03   6.66503906e-02   3.08990479e-02  -4.46166992e-02
   -5.46264648e-02  -9.53369141e-02   1.17736816e-01   2.28271484e-01
   -4.12292480e-02   3.63769531e-02   4.88281250e-04  -5.92346191e-02
    1.55334473e-02   3.49121094e-02   1.23535156e-01   1.42822266e-02
   -7.04956055e-02   4.84008789e-02   4.20837402e-02  -2.69775391e-02]]
After layer encoder_birnn_reverse_l0_t3_slice_output1 (1, 256) <class 'numpy.float16'> [[ 0.12634277  0.01922607  0.0802002   0.04785156  0.02468872  0.06182861
   0.15637207 -0.07098389  0.29150391  0.11315918  0.12347412  0.0838623
   0.08837891  0.01470947  0.10296631  0.10552979  0.08068848 -0.04641724
  -0.12219238  0.040802    0.10449219 -0.00515747  0.2578125   0.04754639
   0.10693359  0.07080078  0.11572266  0.10144043  0.09313965  0.02316284
   0.03662109 -0.00180054  0.20593262 -0.04785156 -0.01327515  0.01501465
  -0.05804443  0.07440186  0.01638794  0.09008789  0.01449585  0.09350586
   0.00784302  0.09509277  0.01693726  0.09448242  0.02841187 -0.07141113
   0.00666809  0.03781128  0.05377197  0.05654907  0.05297852  0.12261963
   0.10388184  0.07751465  0.03182983  0.07830811  0.01797485 -0.05639648
   0.03552246  0.03762817  0.019104    0.04986572 -0.01184082  0.11968994
   0.1796875   0.06066895 -0.07720947  0.00579834  0.06048584 -0.02404785
  -0.01371765  0.0222168   0.08673096  0.18920898  0.04833984  0.02276611
   0.0536499   0.06774902  0.19384766  0.13476562  0.03594971  0.03182983
   0.13110352  0.01515198  0.05755615  0.18457031  0.02790833 -0.08294678
   0.23864746  0.09326172  0.07550049  0.07232666 -0.03356934  0.02389526
   0.02998352  0.13037109 -0.11169434 -0.12915039 -0.00775146  0.01298523
   0.01345825  0.08666992  0.01428223 -0.01739502 -0.08410645  0.06872559
   0.04089355 -0.04788208 -0.01403809 -0.00771332  0.02127075  0.12890625
   0.09777832  0.1706543   0.08361816  0.10906982  0.13037109  0.09411621
   0.16381836  0.14050293  0.02371216  0.01574707  0.01312256 -0.01019287
   0.14599609 -0.00360107  0.09594727 -0.07897949  0.07385254  0.15869141
   0.01712036  0.13452148  0.08618164  0.08184814  0.02145386  0.02340698
   0.11303711  0.14257812 -0.07043457  0.07751465  0.06152344  0.03277588
   0.01800537  0.11791992  0.03314209  0.03103638  0.02832031 -0.01210022
  -0.02923584  0.05807495  0.012146    0.06854248  0.05755615  0.16833496
   0.09985352  0.01901245  0.01721191  0.11877441  0.19970703  0.07312012
  -0.03082275  0.07513428  0.03845215  0.00772858  0.22131348 -0.0486145
   0.00128174 -0.02871704  0.04653931  0.09906006 -0.05004883  0.17529297
  -0.01377869  0.08526611  0.14013672  0.00828552  0.01763916  0.10272217
   0.07904053 -0.06958008  0.19482422 -0.04058838  0.02127075 -0.01544189
   0.03256226  0.15063477  0.07049561 -0.02105713 -0.03396606  0.01980591
   0.15307617  0.13085938  0.0357666  -0.00482178 -0.02005005  0.00531006
   0.02398682  0.01393127  0.01708984  0.07629395  0.0814209  -0.04205322
   0.07446289 -0.10852051 -0.01135254  0.1295166  -0.01617432  0.06958008
   0.06549072  0.11419678 -0.04776001  0.01983643 -0.02445984 -0.05633545
   0.04898071  0.08319092 -0.00170517  0.09643555 -0.08807373 -0.01805115
   0.20263672  0.02832031  0.06445312 -0.0088501   0.01925659  0.02536011
   0.27734375  0.23876953  0.00653076 -0.21728516  0.13134766  0.03198242
   0.05032349  0.00311279  0.02064514  0.08319092  0.01766968  0.09375
   0.07867432  0.0090332   0.06817627  0.21850586 -0.11804199 -0.02404785
  -0.00482178 -0.06555176  0.07592773 -0.00848389  0.11816406 -0.11401367
   0.13391113 -0.02474976  0.12402344  0.00671387]]
After layer encoder_birnn_reverse_l0_t3_slice_output2 (1, 256) <class 'numpy.float16'> [[-0.14221191 -0.13122559 -0.00657654  0.03448486  0.04284668 -0.05532837
   0.04272461  0.09619141  0.05529785 -0.078125   -0.07128906  0.11602783
   0.08618164 -0.03137207  0.05755615 -0.20776367  0.0508728   0.02079773
   0.07794189  0.04995728  0.18347168 -0.04180908  0.0012207   0.07244873
  -0.10968018  0.03634644  0.06072998 -0.04351807 -0.13513184 -0.09832764
   0.03381348 -0.12670898 -0.02349854  0.01100159  0.11010742 -0.14050293
  -0.06713867 -0.00917053 -0.12304688 -0.10028076  0.0300293  -0.18347168
   0.12194824  0.08825684  0.08508301 -0.10369873  0.03503418 -0.07366943
  -0.01091003 -0.0892334   0.06542969 -0.10870361 -0.07720947  0.11010742
   0.04312134  0.02996826 -0.04071045  0.171875    0.0847168  -0.04736328
  -0.07250977 -0.10003662 -0.03050232 -0.01135254  0.0609436  -0.03253174
   0.03552246 -0.09887695 -0.11541748 -0.02362061 -0.23486328 -0.00033569
   0.06213379  0.03308105  0.12322998 -0.04632568 -0.02478027 -0.16821289
  -0.0557251  -0.03424072 -0.1038208   0.02503967 -0.07989502 -0.15124512
  -0.23339844  0.01455688 -0.14257812  0.03494263 -0.16320801 -0.11981201
  -0.10827637 -0.06222534 -0.03085327 -0.01378632 -0.04547119  0.04266357
   0.09820557 -0.03912354 -0.11035156 -0.06994629  0.02532959  0.13342285
  -0.06811523  0.04473877  0.05908203  0.12927246 -0.046875   -0.04943848
   0.15270996 -0.1776123   0.08068848  0.00471497  0.06378174  0.0770874
  -0.090271    0.24768066 -0.14160156 -0.06390381  0.04016113 -0.06201172
   0.14807129  0.08178711 -0.02560425 -0.08135986  0.10961914 -0.17163086
  -0.10437012 -0.06228638 -0.04537964 -0.03131104  0.0692749  -0.04174805
   0.07843018 -0.00065613  0.00033569  0.06726074  0.09362793  0.19775391
  -0.00600052  0.0569458  -0.00802612 -0.04971313  0.12347412  0.02166748
  -0.09991455  0.08972168  0.05780029 -0.1138916  -0.09802246 -0.11590576
  -0.0585022  -0.02920532 -0.04766846 -0.09075928 -0.01977539  0.06774902
  -0.11083984  0.05181885  0.0541687   0.06231689 -0.18945312 -0.07116699
   0.03041077  0.15527344  0.03030396  0.09313965  0.01550293 -0.05752563
  -0.16894531  0.01876831 -0.08673096  0.03533936 -0.0335083  -0.13745117
  -0.02362061  0.0736084   0.13598633 -0.0456543  -0.06274414 -0.03677368
   0.06811523  0.00537109  0.03479004 -0.03466797 -0.06152344  0.06719971
   0.04315186 -0.10021973  0.0970459  -0.12768555  0.17883301 -0.02122498
   0.0075531   0.01141357 -0.17871094 -0.00842285 -0.20422363 -0.09069824
  -0.03533936  0.05056763 -0.14941406 -0.02371216  0.1706543  -0.06036377
  -0.02293396 -0.02009583  0.06726074  0.00941467  0.1072998  -0.08532715
  -0.16210938 -0.00140381  0.02456665 -0.15991211 -0.05667114 -0.07965088
   0.02716064 -0.03814697 -0.02696228  0.1081543  -0.03970337 -0.09240723
   0.07104492  0.01928711  0.00457764 -0.05117798  0.00374413  0.03613281
   0.04394531 -0.01309967 -0.14196777  0.17089844  0.04974365  0.09204102
  -0.06872559  0.04489136 -0.10510254  0.01576233 -0.16210938  0.13220215
   0.02311707 -0.01977539  0.02120972 -0.05432129 -0.03710938 -0.07250977
  -0.05895996 -0.16125488  0.01316833  0.22033691  0.17651367  0.1026001
   0.05456543 -0.07147217 -0.04815674 -0.01048279]]
After layer encoder_birnn_reverse_l0_t3_slice_output3 (1, 256) <class 'numpy.float16'> [[  5.78002930e-02   2.37731934e-02  -1.50604248e-02   5.14221191e-02
    6.14624023e-02   1.97875977e-01   1.05590820e-01   1.29882812e-01
    3.16162109e-01   1.14318848e-01  -2.92358398e-02   5.99670410e-02
    1.43066406e-01  -3.02734375e-02   3.36303711e-02   1.00219727e-01
   -4.91943359e-02  -5.50537109e-02   1.93481445e-02  -2.27355957e-02
   -2.54058838e-02  -1.25244141e-01   2.19482422e-01   9.89990234e-02
    8.12377930e-02   2.63824463e-02   2.39562988e-03   7.27081299e-03
   -6.89086914e-02   2.19116211e-02   1.00341797e-01   1.03027344e-01
    2.99682617e-02   2.24151611e-02  -2.79693604e-02  -1.82952881e-02
    9.44213867e-02  -1.30920410e-02   8.93554688e-02   6.86645508e-03
    9.59472656e-02  -2.92053223e-02   9.76562500e-04   7.32421875e-04
   -2.49633789e-02   1.66931152e-02   1.97448730e-02  -4.90112305e-02
    3.91540527e-02   7.50122070e-02   8.92333984e-02  -5.11169434e-02
    2.18505859e-02   5.63964844e-02   1.94824219e-01  -1.09130859e-01
    1.25488281e-01   1.61743164e-02   2.54364014e-02  -1.03027344e-01
    3.47290039e-02   3.75366211e-02   3.22875977e-02   1.40625000e-01
   -1.31225586e-02  -5.82885742e-02   1.60888672e-01   5.62744141e-02
    4.29077148e-02   1.04125977e-01   1.75933838e-02   4.47082520e-02
    2.16064453e-02  -2.13317871e-02   7.96508789e-02   2.21679688e-01
    1.22497559e-01   4.79736328e-02   1.00219727e-01   1.90673828e-01
    1.48071289e-01   1.82495117e-01   7.98339844e-02   1.24877930e-01
    1.25732422e-01   6.13098145e-02   3.01818848e-02   1.23413086e-01
    6.83593750e-02   1.10839844e-01   1.35009766e-01  -3.07006836e-02
   -8.73413086e-02   3.34777832e-02   6.16455078e-02   3.56750488e-02
    7.38525391e-02   1.37207031e-01  -1.24389648e-01  -7.22045898e-02
    3.05175781e-05  -1.20971680e-01  -4.65698242e-02  -6.68945312e-02
    1.27563477e-02   1.43432617e-02  -3.57666016e-02   1.22619629e-01
    4.55017090e-02   1.84814453e-01   7.26318359e-03   5.04150391e-02
   -7.14111328e-02   1.19934082e-01   2.62451172e-02   1.38427734e-01
   -8.58154297e-02  -2.53906250e-02   1.09375000e-01  -6.89086914e-02
    3.13720703e-02   8.34960938e-02   1.01806641e-01   4.89807129e-03
   -2.85949707e-02   3.18908691e-02  -1.79748535e-02  -1.77917480e-02
   -3.72314453e-02  -4.56237793e-02   1.46179199e-02   1.78955078e-01
    1.07574463e-03   9.21020508e-02   3.13110352e-02  -5.41381836e-02
    1.13159180e-01   6.17675781e-02   1.08642578e-01   2.76336670e-02
    5.27954102e-03   9.00268555e-03  -9.66796875e-02   4.91943359e-02
    1.34963989e-02   2.23388672e-02   1.19934082e-01   3.63159180e-02
    4.36401367e-02  -1.30157471e-02  -1.78222656e-02  -3.17687988e-02
    4.97436523e-02   1.28173828e-01   4.07714844e-02   8.88671875e-02
    6.31103516e-02   1.41601562e-01   4.30908203e-02   1.19506836e-01
    6.15234375e-02   2.57873535e-02  -2.88696289e-02   1.39160156e-01
    8.48388672e-02  -6.12182617e-02   2.12158203e-01   9.34448242e-02
   -8.64868164e-02   3.04412842e-02  -7.80639648e-02   8.47167969e-02
    8.03222656e-02   1.68701172e-01   4.31823730e-02   1.44653320e-01
    1.39160156e-01  -3.35388184e-02   9.83276367e-02  -7.65991211e-03
   -8.05664062e-02  -4.50439453e-02   3.89099121e-02  -2.78320312e-02
   -2.78167725e-02   7.94067383e-02  -1.96533203e-02   8.89282227e-02
    5.12084961e-02  -5.32531738e-02   3.95507812e-02   1.31347656e-01
    4.93774414e-02  -2.62451172e-03   9.75341797e-02   5.69152832e-02
   -2.00195312e-02   6.21948242e-02   8.59985352e-02  -3.75366211e-03
    6.10351562e-02   2.19116211e-01   8.96606445e-02   1.34765625e-01
    8.07495117e-02   8.80737305e-02  -5.54199219e-02   2.50549316e-02
   -6.37207031e-02   1.42822266e-01  -1.75170898e-02   2.84912109e-01
    3.04565430e-02   1.31835938e-01   8.38623047e-02  -2.54821777e-02
    6.60400391e-02   1.52221680e-01  -3.32641602e-02  -5.02929688e-02
   -5.30090332e-02  -8.30688477e-02   1.22497559e-01   1.84783936e-02
    7.00683594e-02   9.27734375e-02   1.89666748e-02   1.19934082e-02
    2.54638672e-01   2.06176758e-01   2.76336670e-02  -8.31909180e-02
   -1.29165649e-02   9.76562500e-04  -1.72119141e-02   1.73797607e-02
   -3.13415527e-02   6.86035156e-02   9.91210938e-02   2.02331543e-02
   -5.78308105e-02   8.27026367e-02   1.48925781e-01   3.17382812e-01
   -8.93554688e-02   5.87158203e-02   7.20825195e-02  -1.06445312e-01
    2.38952637e-02   1.40686035e-02   8.94775391e-02  -6.28662109e-02
    8.52050781e-02   1.29516602e-01  -7.93457031e-03   7.66601562e-02]]
After layer encoder_birnn_reverse_l0_t3_o_output (1, 256) <class 'numpy.float16'> [[ 0.51464844  0.50585938  0.49633789  0.51269531  0.51513672  0.54931641
   0.52636719  0.53222656  0.57861328  0.52832031  0.49267578  0.51513672
   0.53564453  0.49243164  0.50830078  0.52490234  0.48779297  0.48632812
   0.50488281  0.49438477  0.49365234  0.46875     0.5546875   0.52490234
   0.52050781  0.50683594  0.50048828  0.50195312  0.48266602  0.50537109
   0.52490234  0.52587891  0.50732422  0.50537109  0.49291992  0.49536133
   0.5234375   0.49682617  0.52246094  0.50195312  0.52392578  0.49267578
   0.5         0.5         0.49365234  0.50439453  0.50488281  0.48779297
   0.50976562  0.51855469  0.52246094  0.48730469  0.50537109  0.51416016
   0.54833984  0.47265625  0.53125     0.50390625  0.50634766  0.47436523
   0.50878906  0.50927734  0.50830078  0.53515625  0.49682617  0.48535156
   0.54003906  0.51416016  0.51074219  0.52587891  0.50439453  0.51123047
   0.50537109  0.49462891  0.52001953  0.55517578  0.53076172  0.51220703
   0.52490234  0.54736328  0.53710938  0.54541016  0.52001953  0.53125
   0.53125     0.51513672  0.50732422  0.53076172  0.51708984  0.52783203
   0.53369141  0.49243164  0.47827148  0.50830078  0.515625    0.50878906
   0.51855469  0.53417969  0.46899414  0.48193359  0.5         0.46972656
   0.48828125  0.48339844  0.50341797  0.50341797  0.4909668   0.53076172
   0.51123047  0.54589844  0.50195312  0.51269531  0.48217773  0.52978516
   0.50634766  0.53466797  0.47851562  0.49365234  0.52734375  0.48266602
   0.5078125   0.52099609  0.52539062  0.50146484  0.49291992  0.5078125
   0.49560547  0.49560547  0.49072266  0.48852539  0.50341797  0.54443359
   0.50048828  0.52294922  0.5078125   0.48657227  0.52832031  0.515625
   0.52734375  0.50683594  0.50146484  0.50244141  0.47583008  0.51220703
   0.50341797  0.50537109  0.52978516  0.50927734  0.51074219  0.49682617
   0.49560547  0.49194336  0.51220703  0.53222656  0.51025391  0.52197266
   0.515625    0.53515625  0.51074219  0.52978516  0.51513672  0.50634766
   0.49267578  0.53466797  0.52099609  0.48461914  0.55273438  0.5234375
   0.47827148  0.5078125   0.48046875  0.52099609  0.52001953  0.54199219
   0.51074219  0.53613281  0.53466797  0.49169922  0.52441406  0.49804688
   0.47998047  0.48876953  0.50976562  0.49316406  0.49316406  0.52001953
   0.49511719  0.52246094  0.51269531  0.48657227  0.50976562  0.53271484
   0.51220703  0.49926758  0.52441406  0.51416016  0.49511719  0.515625
   0.52148438  0.49902344  0.51513672  0.5546875   0.52246094  0.53369141
   0.52001953  0.52197266  0.48608398  0.50634766  0.48413086  0.53564453
   0.49560547  0.57080078  0.5078125   0.53271484  0.52099609  0.49365234
   0.51660156  0.53808594  0.49169922  0.48754883  0.48681641  0.47924805
   0.53076172  0.50439453  0.51757812  0.52294922  0.50488281  0.50292969
   0.56347656  0.55126953  0.50683594  0.47924805  0.49682617  0.5
   0.49560547  0.50439453  0.4921875   0.51708984  0.52490234  0.50488281
   0.4855957   0.52050781  0.53710938  0.57861328  0.4777832   0.51464844
   0.51806641  0.47338867  0.50585938  0.50341797  0.52246094  0.484375
   0.52148438  0.53222656  0.49804688  0.51904297]]
After layer encoder_birnn_reverse_l0_t3_f_output (1, 256) <class 'numpy.float16'> [[ 0.53173828  0.50488281  0.52001953  0.51171875  0.50634766  0.515625
   0.5390625   0.48217773  0.57226562  0.52832031  0.53076172  0.52099609
   0.52197266  0.50390625  0.52587891  0.52636719  0.52001953  0.48828125
   0.46948242  0.51025391  0.52587891  0.4987793   0.56396484  0.51171875
   0.52685547  0.51757812  0.52880859  0.52539062  0.5234375   0.50585938
   0.50927734  0.49951172  0.55126953  0.48803711  0.49658203  0.50390625
   0.4855957   0.51855469  0.50390625  0.52246094  0.50341797  0.5234375
   0.50195312  0.52392578  0.50439453  0.5234375   0.50732422  0.48217773
   0.50146484  0.50927734  0.51367188  0.51416016  0.51318359  0.53076172
   0.52587891  0.51953125  0.5078125   0.51953125  0.50439453  0.48583984
   0.50878906  0.50927734  0.50488281  0.51269531  0.49707031  0.52978516
   0.54492188  0.51513672  0.48071289  0.50146484  0.51513672  0.49389648
   0.49658203  0.50537109  0.52148438  0.54736328  0.51220703  0.50585938
   0.51318359  0.51708984  0.54833984  0.53369141  0.50878906  0.5078125
   0.53271484  0.50390625  0.51416016  0.54589844  0.50683594  0.47924805
   0.55957031  0.5234375   0.51904297  0.51806641  0.49169922  0.50585938
   0.50732422  0.53271484  0.47216797  0.46777344  0.49804688  0.50341797
   0.50341797  0.52148438  0.50341797  0.49560547  0.47900391  0.51708984
   0.51025391  0.48803711  0.49658203  0.49804688  0.50537109  0.53222656
   0.52441406  0.54248047  0.52099609  0.52734375  0.53271484  0.5234375
   0.54101562  0.53515625  0.50585938  0.50390625  0.50341797  0.49755859
   0.53662109  0.49902344  0.52392578  0.48022461  0.51855469  0.53955078
   0.50439453  0.53369141  0.52148438  0.52050781  0.50537109  0.50585938
   0.52832031  0.53564453  0.48242188  0.51953125  0.51513672  0.50830078
   0.50439453  0.52929688  0.50830078  0.5078125   0.50683594  0.49707031
   0.49267578  0.51464844  0.50292969  0.51708984  0.51416016  0.54199219
   0.52490234  0.50488281  0.50439453  0.52978516  0.54980469  0.51806641
   0.4921875   0.51855469  0.50976562  0.50195312  0.55517578  0.48779297
   0.50048828  0.49291992  0.51171875  0.52490234  0.48754883  0.54394531
   0.49658203  0.52148438  0.53515625  0.50195312  0.50439453  0.52587891
   0.51953125  0.48266602  0.54833984  0.48974609  0.50537109  0.49609375
   0.50830078  0.53759766  0.51757812  0.49462891  0.49145508  0.50488281
   0.53808594  0.53271484  0.50878906  0.4987793   0.49487305  0.50146484
   0.50585938  0.50341797  0.50439453  0.51904297  0.52050781  0.48950195
   0.51855469  0.47290039  0.49707031  0.53222656  0.49584961  0.51757812
   0.51660156  0.52832031  0.48803711  0.50488281  0.49389648  0.48583984
   0.51220703  0.52099609  0.49951172  0.52392578  0.47802734  0.49560547
   0.55029297  0.50683594  0.51611328  0.49780273  0.50488281  0.50634766
   0.56884766  0.55957031  0.50146484  0.44580078  0.53271484  0.5078125
   0.51269531  0.50097656  0.50537109  0.52099609  0.50439453  0.5234375
   0.51953125  0.50244141  0.51708984  0.55419922  0.47045898  0.49389648
   0.4987793   0.48364258  0.51904297  0.49780273  0.52929688  0.47143555
   0.53320312  0.49389648  0.53076172  0.50146484]]
After layer _mul2078_0 (1, 256) <class 'numpy.float16'> [[-0.0456543  -0.03686523  0.00905609  0.0151825   0.02371216 -0.01829529
   0.01812744  0.02738953 -0.00248909 -0.03701782 -0.02644348  0.03146362
   0.03955078 -0.02346802  0.03179932 -0.07080078  0.00603104 -0.00306511
   0.02044678  0.02085876  0.06512451 -0.02107239  0.00770569  0.02870178
  -0.02449036  0.0102005  -0.00457382 -0.00429535 -0.04043579 -0.0284729
   0.01573181 -0.04885864  0.00327301 -0.0104599   0.03369141 -0.04528809
  -0.02827454 -0.01475525 -0.03277588 -0.01808167  0.02655029 -0.04052734
   0.03845215  0.02853394  0.03619385 -0.04263306  0.02198792 -0.02191162
  -0.00266838 -0.01765442  0.00243759 -0.03677368 -0.02584839  0.02633667
   0.02799988  0.00366974 -0.0269165   0.06512451  0.0223999  -0.02854919
  -0.02798462 -0.03082275 -0.01779175 -0.00450134  0.04083252 -0.01701355
   0.0350647  -0.0057869  -0.03948975 -0.01469421 -0.08123779  0.01016235
   0.02163696  0.00063229  0.04882812 -0.02345276 -0.02677917 -0.04644775
  -0.02348328 -0.01308441 -0.03308105 -0.00758743 -0.02018738 -0.0526123
  -0.07897949  0.01615906 -0.04699707  0.02154541 -0.03930664 -0.03378296
  -0.01255035 -0.01222992 -0.00204277 -0.01722717 -0.01293182  0.00546646
   0.02871704 -0.01937866 -0.02597046 -0.01679993  0.02552795  0.03994751
  -0.03225708  0.0164032   0.00432587  0.02946472 -0.01544952 -0.01500702
   0.04217529 -0.04129028  0.02799988  0.01809692  0.01428986  0.02656555
  -0.03747559  0.07202148 -0.04003906 -0.02433777  0.02197266 -0.00031948
   0.04284668  0.04421997 -0.00974274 -0.03004456  0.03741455 -0.05926514
  -0.00748444 -0.02662659 -0.0063858   0.01168823  0.03115845 -0.02220154
   0.02702332 -0.02011108  0.01126099  0.02615356  0.04327393  0.06130981
  -0.00571823  0.02827454 -0.00994873 -0.02238464  0.04589844 -0.00161362
  -0.03244019  0.02914429  0.02510071 -0.04736328 -0.02224731 -0.01878357
  -0.02516174 -0.0111084  -0.01564026 -0.03053284  0.00101948  0.02033997
  -0.03536987  0.02249146  0.01864624  0.02574158 -0.07928467 -0.0345459
   0.00803375  0.03735352  0.00413132  0.03387451  0.0017767  -0.03961182
  -0.05432129 -0.00959778 -0.03323364  0.01663208 -0.0091629  -0.04925537
  -0.00205231  0.01860046  0.06088257 -0.02331543 -0.03393555 -0.01806641
   0.03405762  0.00310135  0.01338959 -0.00881958  0.00288391  0.00604248
   0.01154327 -0.04736328  0.03756714 -0.0335083   0.06112671  0.00823975
  -0.00059128 -0.00225449 -0.05609131  0.00637054 -0.06045532 -0.03808594
   0.00308418  0.02249146 -0.04147339 -0.00747299  0.06396484 -0.02207947
   0.00982666 -0.00521851  0.01123047 -0.00120544  0.04708862 -0.04168701
  -0.03695679  0.01488495  0.01354218 -0.03344727 -0.02203369 -0.02850342
   0.0032196  -0.01166534  0.00492477  0.03823853 -0.00049591 -0.02194214
   0.03033447 -0.00778198 -0.00224686 -0.01069641 -0.0005641   0.01235199
   0.01867676 -0.0062027  -0.04394531  0.0375061   0.02908325  0.02778625
  -0.02903748  0.02330017 -0.04043579  0.00876617 -0.04342651  0.04223633
   0.0096817  -0.0184021   0.00766373 -0.03900146 -0.01750183 -0.02644348
  -0.01582336 -0.03146362 -0.00542831  0.07476807  0.06414795  0.02658081
   0.02442932 -0.01914978 -0.00791931 -0.01965332]]
After layer encoder_birnn_reverse_l0_t3_i_output (1, 256) <class 'numpy.float16'> [[ 0.5         0.49731445  0.50341797  0.49511719  0.51708984  0.50146484
   0.51318359  0.50683594  0.52099609  0.51269531  0.49072266  0.51513672
   0.50585938  0.51269531  0.49975586  0.55908203  0.48388672  0.48730469
   0.50390625  0.49609375  0.52001953  0.51074219  0.48168945  0.48999023
   0.52246094  0.47290039  0.49316406  0.49584961  0.51074219  0.49755859
   0.50048828  0.49316406  0.49145508  0.48876953  0.51708984  0.47460938
   0.49926758  0.4987793   0.48461914  0.49047852  0.48291016  0.51074219
   0.48632812  0.50097656  0.50927734  0.49951172  0.51611328  0.48193359
   0.50048828  0.50244141  0.49658203  0.52246094  0.4934082   0.51611328
   0.54931641  0.52148438  0.48925781  0.50097656  0.48999023  0.49414062
   0.515625    0.48999023  0.53710938  0.49365234  0.47363281  0.48925781
   0.52294922  0.49707031  0.48999023  0.50732422  0.52294922  0.49438477
   0.50146484  0.50097656  0.49584961  0.52001953  0.53125     0.53076172
   0.49902344  0.50976562  0.50634766  0.51025391  0.52148438  0.49633789
   0.53857422  0.51611328  0.49316406  0.49560547  0.49121094  0.53076172
   0.53125     0.49462891  0.48046875  0.52539062  0.51855469  0.51220703
   0.49511719  0.52880859  0.48193359  0.4765625   0.48779297  0.51806641
   0.49682617  0.46508789  0.49023438  0.50048828  0.49658203  0.47192383
   0.51171875  0.51757812  0.46850586  0.51171875  0.50146484  0.53808594
   0.49902344  0.56738281  0.49243164  0.50244141  0.51855469  0.4921875
   0.54980469  0.47241211  0.5         0.52197266  0.48828125  0.51269531
   0.47460938  0.51513672  0.49731445  0.50048828  0.53857422  0.51708984
   0.50097656  0.49389648  0.48706055  0.49169922  0.52148438  0.53515625
   0.50292969  0.49584961  0.49145508  0.48120117  0.51513672  0.51708984
   0.49194336  0.49975586  0.50683594  0.515625    0.49511719  0.51367188
   0.52392578  0.48999023  0.50097656  0.47753906  0.48803711  0.54638672
   0.50878906  0.52246094  0.49707031  0.49267578  0.54150391  0.50244141
   0.49121094  0.51074219  0.50585938  0.48730469  0.50488281  0.49072266
   0.515625    0.49267578  0.50634766  0.50878906  0.50195312  0.52294922
   0.50878906  0.47509766  0.50878906  0.47412109  0.48925781  0.49462891
   0.50683594  0.48681641  0.49267578  0.50976562  0.52392578  0.49291992
   0.49658203  0.4855957   0.53222656  0.51904297  0.49658203  0.50048828
   0.51074219  0.4987793   0.52783203  0.515625    0.51708984  0.46459961
   0.51123047  0.51074219  0.49926758  0.53808594  0.515625    0.50537109
   0.50927734  0.49853516  0.50097656  0.48901367  0.48901367  0.51123047
   0.50830078  0.52148438  0.50488281  0.51660156  0.50537109  0.51464844
   0.4987793   0.49414062  0.50195312  0.50195312  0.48803711  0.49438477
   0.51367188  0.48120117  0.50341797  0.51660156  0.49536133  0.48071289
   0.48999023  0.54101562  0.49633789  0.48608398  0.49584961  0.49267578
   0.50830078  0.51611328  0.49804688  0.51660156  0.5078125   0.48876953
   0.48632812  0.47607422  0.52929688  0.55664062  0.48974609  0.50927734
   0.5         0.48510742  0.50390625  0.50878906  0.53076172  0.50341797
   0.48242188  0.51220703  0.51074219  0.49316406]]
After layer encoder_birnn_reverse_l0_t3_c_output (1, 256) <class 'numpy.float16'> [[-0.14123535 -0.13049316 -0.00657654  0.03448486  0.04281616 -0.05526733
   0.04269409  0.09588623  0.05523682 -0.07794189 -0.07116699  0.11553955
   0.08599854 -0.03137207  0.05749512 -0.20483398  0.05084229  0.02079773
   0.07775879  0.04992676  0.18139648 -0.04177856  0.0012207   0.07232666
  -0.10925293  0.03631592  0.06066895 -0.04348755 -0.13427734 -0.09802246
   0.03381348 -0.12597656 -0.02349854  0.01100159  0.10968018 -0.13952637
  -0.0670166  -0.00917053 -0.12243652 -0.09997559  0.03001404 -0.18139648
   0.12133789  0.0880127   0.0848999  -0.10333252  0.03503418 -0.07354736
  -0.01091003 -0.08898926  0.06530762 -0.10827637 -0.07702637  0.10968018
   0.04309082  0.029953   -0.04067993  0.17016602  0.08453369 -0.04733276
  -0.0723877  -0.09973145 -0.03048706 -0.01135254  0.06088257 -0.03253174
   0.03552246 -0.09857178 -0.1149292  -0.02362061 -0.23059082 -0.00033569
   0.06204224  0.03308105  0.12261963 -0.04629517 -0.02478027 -0.16662598
  -0.05566406 -0.03424072 -0.10345459  0.02503967 -0.07971191 -0.15014648
  -0.22924805  0.01455688 -0.14160156  0.03494263 -0.16174316 -0.1192627
  -0.10784912 -0.06213379 -0.03083801 -0.01378632 -0.04544067  0.04263306
   0.09790039 -0.03909302 -0.10992432 -0.06982422  0.02532959  0.13269043
  -0.06799316  0.04470825  0.059021    0.12854004 -0.04684448 -0.04940796
   0.15148926 -0.17578125  0.08050537  0.00471497  0.0637207   0.07696533
  -0.09002686  0.24279785 -0.140625   -0.06384277  0.04013062 -0.06192017
   0.14697266  0.081604   -0.02560425 -0.08117676  0.10919189 -0.16992188
  -0.10400391 -0.06219482 -0.04534912 -0.03131104  0.06915283 -0.04171753
   0.07824707 -0.00065613  0.00033569  0.06713867  0.09338379  0.19519043
  -0.00600052  0.05688477 -0.00802612 -0.04968262  0.12286377  0.02166748
  -0.09960938  0.08947754  0.05773926 -0.11340332 -0.09771729 -0.11541748
  -0.05844116 -0.02919006 -0.04763794 -0.09051514 -0.01977539  0.06762695
  -0.1104126   0.05175781  0.05410767  0.06222534 -0.18725586 -0.07104492
   0.03039551  0.15405273  0.0302887   0.09289551  0.01550293 -0.0574646
  -0.1673584   0.01876831 -0.08648682  0.03533936 -0.0335083  -0.13659668
  -0.02362061  0.07348633  0.13513184 -0.04562378 -0.06268311 -0.03674316
   0.06799316  0.00537109  0.03479004 -0.03466797 -0.06143188  0.06707764
   0.04312134 -0.09991455  0.09674072 -0.12695312  0.17700195 -0.02122498
   0.0075531   0.01141357 -0.17687988 -0.00842285 -0.20141602 -0.0904541
  -0.03533936  0.05053711 -0.14831543 -0.02371216  0.16906738 -0.06030273
  -0.02293396 -0.02009583  0.06713867  0.00941467  0.10687256 -0.08514404
  -0.16064453 -0.00140381  0.02456665 -0.15856934 -0.05661011 -0.07946777
   0.02716064 -0.03811646 -0.02696228  0.10772705 -0.03967285 -0.09216309
   0.07092285  0.01928711  0.00457764 -0.05114746  0.00374413  0.03610229
   0.04391479 -0.01309967 -0.14099121  0.16931152  0.04971313  0.09179688
  -0.06860352  0.04486084 -0.10473633  0.01576233 -0.16064453  0.13146973
   0.02311707 -0.01977539  0.02120972 -0.05426025 -0.03707886 -0.0723877
  -0.05889893 -0.15991211  0.01316833  0.21679688  0.17468262  0.10223389
   0.05450439 -0.0713501  -0.04812622 -0.01048279]]
After layer _mul2079_0 (1, 256) <class 'numpy.float16'> [[-0.07061768 -0.06488037 -0.00331116  0.01707458  0.0221405  -0.02770996
   0.02191162  0.04858398  0.02877808 -0.03994751 -0.03491211  0.05950928
   0.04351807 -0.01608276  0.0287323  -0.11450195  0.02459717  0.01013184
   0.03918457  0.02476501  0.09429932 -0.02133179  0.00058794  0.03543091
  -0.05706787  0.0171814   0.02992249 -0.02156067 -0.06860352 -0.04876709
   0.016922   -0.06213379 -0.0115509   0.00537872  0.05670166 -0.06622314
  -0.03344727 -0.00457382 -0.05932617 -0.04904175  0.01449585 -0.09265137
   0.059021    0.0440979   0.04324341 -0.05160522  0.01808167 -0.03543091
  -0.00545883 -0.04470825  0.03244019 -0.05657959 -0.03799438  0.05661011
   0.02366638  0.01561737 -0.01989746  0.08526611  0.04141235 -0.02339172
  -0.037323   -0.04885864 -0.01637268 -0.00560379  0.02883911 -0.01591492
   0.01856995 -0.04901123 -0.05630493 -0.01198578 -0.12060547 -0.00016594
   0.03111267  0.01657104  0.06079102 -0.02407837 -0.01316833 -0.08843994
  -0.027771   -0.01745605 -0.05239868  0.01277924 -0.04156494 -0.07452393
  -0.12347412  0.00751114 -0.06982422  0.01731873 -0.07946777 -0.06329346
  -0.05728149 -0.0307312  -0.01481628 -0.00724411 -0.02355957  0.02183533
   0.04846191 -0.02067566 -0.05297852 -0.03326416  0.01235199  0.06872559
  -0.03378296  0.02079773  0.02893066  0.06433105 -0.02326965 -0.02331543
   0.07751465 -0.09100342  0.03771973  0.0024128   0.0319519   0.04141235
  -0.04492188  0.13781738 -0.0692749  -0.03207397  0.02081299 -0.0304718
   0.08081055  0.0385437  -0.01280212 -0.0423584   0.05331421 -0.08709717
  -0.04934692 -0.03204346 -0.02255249 -0.01567078  0.03723145 -0.02157593
   0.03921509 -0.00032401  0.00016356  0.03302002  0.04870605  0.10443115
  -0.00301743  0.0282135  -0.0039444  -0.02391052  0.06329346  0.01120758
  -0.04901123  0.04470825  0.02926636 -0.05847168 -0.04837036 -0.05929565
  -0.03062439 -0.01430511 -0.02386475 -0.04321289 -0.00965118  0.03695679
  -0.05618286  0.02703857  0.02690125  0.03065491 -0.10137939 -0.03570557
   0.01493073  0.07867432  0.01531982  0.04525757  0.00782776 -0.02819824
  -0.08630371  0.00924683 -0.04379272  0.01797485 -0.01681519 -0.07141113
  -0.0120163   0.03491211  0.06872559 -0.02163696 -0.03067017 -0.01817322
   0.03445435  0.00261497  0.01713562 -0.01766968 -0.03219604  0.03305054
   0.02140808 -0.04852295  0.05148315 -0.06591797  0.08789062 -0.01062012
   0.00385857  0.00569153 -0.09338379 -0.00434113 -0.10412598 -0.04202271
  -0.01806641  0.02581787 -0.07403564 -0.01275635  0.0871582  -0.0304718
  -0.0116806  -0.0100174   0.03363037  0.00460434  0.05227661 -0.04351807
  -0.08166504 -0.00073195  0.0124054  -0.08190918 -0.02861023 -0.04089355
   0.0135498  -0.01882935 -0.01353455  0.05407715 -0.0193634  -0.04556274
   0.03643799  0.00927734  0.00230408 -0.02642822  0.0018549   0.01734924
   0.02151489 -0.00708771 -0.07000732  0.08227539  0.02464294  0.04522705
  -0.03488159  0.02314758 -0.05215454  0.00814056 -0.081604    0.06427002
   0.01124573 -0.00941467  0.01122284 -0.03019714 -0.01815796 -0.03686523
  -0.02944946 -0.07757568  0.00663376  0.11029053  0.0927124   0.05145264
   0.02629089 -0.03656006 -0.02458191 -0.00516891]]
After layer encoder_birnn_reverse_l0_t3_state_0 (1, 256) <class 'numpy.float16'> [[ -1.16271973e-01  -1.01745605e-01   5.74493408e-03   3.22570801e-02
    4.58374023e-02  -4.60205078e-02   4.00390625e-02   7.59887695e-02
    2.62908936e-02  -7.69653320e-02  -6.13403320e-02   9.09423828e-02
    8.30688477e-02  -3.95507812e-02   6.05468750e-02  -1.85302734e-01
    3.06243896e-02   7.06481934e-03   5.96313477e-02   4.56237793e-02
    1.59423828e-01  -4.24194336e-02   8.29315186e-03   6.41479492e-02
   -8.15429688e-02   2.73742676e-02   2.53448486e-02  -2.58483887e-02
   -1.09008789e-01  -7.72705078e-02   3.26538086e-02  -1.10961914e-01
   -8.27789307e-03  -5.08117676e-03   9.03930664e-02  -1.11511230e-01
   -6.17065430e-02  -1.93328857e-02  -9.21020508e-02  -6.71386719e-02
    4.10461426e-02  -1.33178711e-01   9.74731445e-02   7.26318359e-02
    7.94677734e-02  -9.42382812e-02   4.00695801e-02  -5.73425293e-02
   -8.12530518e-03  -6.23779297e-02   3.48815918e-02  -9.33837891e-02
   -6.38427734e-02   8.29467773e-02   5.16662598e-02   1.92871094e-02
   -4.68139648e-02   1.50390625e-01   6.38427734e-02  -5.19409180e-02
   -6.53076172e-02  -7.97119141e-02  -3.41796875e-02  -1.01013184e-02
    6.97021484e-02  -3.29284668e-02   5.36499023e-02  -5.48095703e-02
   -9.58251953e-02  -2.66723633e-02  -2.01904297e-01   9.99450684e-03
    5.27343750e-02   1.71966553e-02   1.09619141e-01  -4.75463867e-02
   -3.99475098e-02  -1.34887695e-01  -5.12695312e-02  -3.05480957e-02
   -8.54492188e-02   5.19180298e-03  -6.17675781e-02  -1.27197266e-01
   -2.02392578e-01   2.36663818e-02  -1.16821289e-01   3.88793945e-02
   -1.18774414e-01  -9.70458984e-02  -6.98242188e-02  -4.29687500e-02
   -1.68609619e-02  -2.44750977e-02  -3.64990234e-02   2.72979736e-02
    7.71484375e-02  -4.00390625e-02  -7.89794922e-02  -5.00488281e-02
    3.78723145e-02   1.08642578e-01  -6.60400391e-02   3.72009277e-02
    3.32641602e-02   9.38110352e-02  -3.87268066e-02  -3.83300781e-02
    1.19689941e-01  -1.32324219e-01   6.57348633e-02   2.05078125e-02
    4.62341309e-02   6.79931641e-02  -8.23974609e-02   2.09838867e-01
   -1.09313965e-01  -5.63964844e-02   4.27856445e-02  -3.07922363e-02
    1.23657227e-01   8.27636719e-02  -2.25524902e-02  -7.23876953e-02
    9.06982422e-02  -1.46362305e-01  -5.68237305e-02  -5.86547852e-02
   -2.89306641e-02  -3.98254395e-03   6.83593750e-02  -4.37622070e-02
    6.62231445e-02  -2.04315186e-02   1.14212036e-02   5.91735840e-02
    9.19799805e-02   1.65771484e-01  -8.73565674e-03   5.64880371e-02
   -1.38931274e-02  -4.62951660e-02   1.09191895e-01   9.59777832e-03
   -8.14208984e-02   7.38525391e-02   5.43823242e-02  -1.05834961e-01
   -7.06176758e-02  -7.80639648e-02  -5.57861328e-02  -2.54211426e-02
   -3.94897461e-02  -7.37304688e-02  -8.62884521e-03   5.73120117e-02
   -9.15527344e-02   4.95300293e-02   4.55322266e-02   5.63964844e-02
   -1.80664062e-01  -7.02514648e-02   2.29644775e-02   1.16027832e-01
    1.94549561e-02   7.91015625e-02   9.60540771e-03  -6.78100586e-02
   -1.40625000e-01  -3.50952148e-04  -7.70263672e-02   3.46069336e-02
   -2.59704590e-02  -1.20666504e-01  -1.40686035e-02   5.35278320e-02
    1.29638672e-01  -4.49523926e-02  -6.45751953e-02  -3.62548828e-02
    6.84814453e-02   5.71441650e-03   3.05175781e-02  -2.64892578e-02
   -2.93121338e-02   3.90930176e-02   3.29589844e-02  -9.58862305e-02
    8.90502930e-02  -9.94262695e-02   1.49047852e-01  -2.38037109e-03
    3.26728821e-03   3.43704224e-03  -1.49414062e-01   2.02941895e-03
   -1.64550781e-01  -8.00781250e-02  -1.49841309e-02   4.83093262e-02
   -1.15478516e-01  -2.02331543e-02   1.51123047e-01  -5.25512695e-02
   -1.85394287e-03  -1.52359009e-02   4.48608398e-02   3.39889526e-03
    9.93652344e-02  -8.52050781e-02  -1.18652344e-01   1.41525269e-02
    2.59399414e-02  -1.15356445e-01  -5.06591797e-02  -6.93969727e-02
    1.67694092e-02  -3.04870605e-02  -8.60595703e-03   9.22851562e-02
   -1.98669434e-02  -6.75048828e-02   6.67724609e-02   1.49536133e-03
    5.72204590e-05  -3.71093750e-02   1.29127502e-03   2.96936035e-02
    4.01916504e-02  -1.32904053e-02  -1.13952637e-01   1.19750977e-01
    5.37109375e-02   7.29980469e-02  -6.39038086e-02   4.64477539e-02
   -9.25903320e-02   1.69067383e-02  -1.25000000e-01   1.06506348e-01
    2.09350586e-02  -2.78167725e-02   1.88903809e-02  -6.92138672e-02
   -3.56445312e-02  -6.32934570e-02  -4.52880859e-02  -1.09008789e-01
    1.20544434e-03   1.85058594e-01   1.56860352e-01   7.80029297e-02
    5.07202148e-02  -5.57250977e-02  -3.25012207e-02  -2.48260498e-02]]
After layer activation1039_output (1, 256) <class 'numpy.float16'> [[ -1.15722656e-01  -1.01379395e-01   5.74493408e-03   3.22570801e-02
    4.58068848e-02  -4.59899902e-02   4.00085449e-02   7.58666992e-02
    2.62908936e-02  -7.68432617e-02  -6.12487793e-02   9.06982422e-02
    8.28857422e-02  -3.95202637e-02   6.04858398e-02  -1.83227539e-01
    3.06091309e-02   7.06481934e-03   5.95703125e-02   4.55932617e-02
    1.58081055e-01  -4.23889160e-02   8.29315186e-03   6.40869141e-02
   -8.13598633e-02   2.73742676e-02   2.53448486e-02  -2.58483887e-02
   -1.08581543e-01  -7.70874023e-02   3.26538086e-02  -1.10534668e-01
   -8.27789307e-03  -5.08117676e-03   9.01489258e-02  -1.11022949e-01
   -6.16149902e-02  -1.93328857e-02  -9.18579102e-02  -6.70166016e-02
    4.10156250e-02  -1.32446289e-01   9.71679688e-02   7.25097656e-02
    7.92846680e-02  -9.39331055e-02   4.00390625e-02  -5.72814941e-02
   -8.12530518e-03  -6.22863770e-02   3.48815918e-02  -9.31396484e-02
   -6.37817383e-02   8.27636719e-02   5.16052246e-02   1.92871094e-02
   -4.67834473e-02   1.49291992e-01   6.37817383e-02  -5.18798828e-02
   -6.51855469e-02  -7.95288086e-02  -3.41796875e-02  -1.01013184e-02
    6.95800781e-02  -3.29284668e-02   5.35888672e-02  -5.47485352e-02
   -9.55200195e-02  -2.66723633e-02  -1.99218750e-01   9.99450684e-03
    5.26733398e-02   1.71966553e-02   1.09191895e-01  -4.75158691e-02
   -3.99169922e-02  -1.34033203e-01  -5.12390137e-02  -3.05328369e-02
   -8.52661133e-02   5.19180298e-03  -6.16760254e-02  -1.26464844e-01
   -1.99707031e-01   2.36663818e-02  -1.16271973e-01   3.88488770e-02
   -1.18225098e-01  -9.67407227e-02  -6.97021484e-02  -4.29382324e-02
   -1.68609619e-02  -2.44750977e-02  -3.64685059e-02   2.72979736e-02
    7.69653320e-02  -4.00085449e-02  -7.87963867e-02  -5.00183105e-02
    3.78417969e-02   1.08215332e-01  -6.59179688e-02   3.71704102e-02
    3.32641602e-02   9.35668945e-02  -3.86962891e-02  -3.82995605e-02
    1.19140625e-01  -1.31591797e-01   6.56127930e-02   2.05078125e-02
    4.62036133e-02   6.78710938e-02  -8.22143555e-02   2.06787109e-01
   -1.08886719e-01  -5.63354492e-02   4.27551270e-02  -3.07769775e-02
    1.23046875e-01   8.25805664e-02  -2.25524902e-02  -7.22656250e-02
    9.04541016e-02  -1.45385742e-01  -5.67626953e-02  -5.85937500e-02
   -2.89154053e-02  -3.98254395e-03   6.82373047e-02  -4.37316895e-02
    6.61010742e-02  -2.04315186e-02   1.14212036e-02   5.91125488e-02
    9.17358398e-02   1.64306641e-01  -8.73565674e-03   5.64270020e-02
   -1.38931274e-02  -4.62646484e-02   1.08764648e-01   9.59777832e-03
   -8.12377930e-02   7.37304688e-02   5.43212891e-02  -1.05468750e-01
   -7.04956055e-02  -7.78808594e-02  -5.57250977e-02  -2.54211426e-02
   -3.94592285e-02  -7.36083984e-02  -8.62884521e-03   5.72509766e-02
   -9.13085938e-02   4.94995117e-02   4.55017090e-02   5.63354492e-02
   -1.78710938e-01  -7.01293945e-02   2.29644775e-02   1.15539551e-01
    1.94549561e-02   7.89184570e-02   9.60540771e-03  -6.76879883e-02
   -1.39648438e-01  -3.50952148e-04  -7.69042969e-02   3.46069336e-02
   -2.59704590e-02  -1.20056152e-01  -1.40686035e-02   5.34667969e-02
    1.28906250e-01  -4.49218750e-02  -6.45141602e-02  -3.62243652e-02
    6.83593750e-02   5.71441650e-03   3.05023193e-02  -2.64892578e-02
   -2.92968750e-02   3.90625000e-02   3.29589844e-02  -9.55810547e-02
    8.88061523e-02  -9.91210938e-02   1.47949219e-01  -2.38037109e-03
    3.26728821e-03   3.43704224e-03  -1.48315430e-01   2.02941895e-03
   -1.63085938e-01  -7.98950195e-02  -1.49841309e-02   4.82788086e-02
   -1.14990234e-01  -2.02331543e-02   1.50024414e-01  -5.24902344e-02
   -1.85394287e-03  -1.52359009e-02   4.48303223e-02   3.39889526e-03
    9.90600586e-02  -8.50219727e-02  -1.18103027e-01   1.41525269e-02
    2.59399414e-02  -1.14868164e-01  -5.06286621e-02  -6.92749023e-02
    1.67694092e-02  -3.04718018e-02  -8.60595703e-03   9.20410156e-02
   -1.98669434e-02  -6.73828125e-02   6.66503906e-02   1.49536133e-03
    5.72204590e-05  -3.70788574e-02   1.29127502e-03   2.96783447e-02
    4.01611328e-02  -1.32904053e-02  -1.13464355e-01   1.19201660e-01
    5.36499023e-02   7.28759766e-02  -6.38427734e-02   4.64172363e-02
   -9.23461914e-02   1.69067383e-02  -1.24328613e-01   1.06079102e-01
    2.09350586e-02  -2.78167725e-02   1.88903809e-02  -6.90917969e-02
   -3.56445312e-02  -6.32324219e-02  -4.52575684e-02  -1.08581543e-01
    1.20544434e-03   1.82983398e-01   1.55639648e-01   7.78198242e-02
    5.06896973e-02  -5.56640625e-02  -3.25012207e-02  -2.48260498e-02]]
After layer encoder_birnn_reverse_l0_t3_out_0 (1, 256) <class 'numpy.float16'> [[ -5.95703125e-02  -5.12695312e-02   2.85148621e-03   1.65405273e-02
    2.35900879e-02  -2.52685547e-02   2.10571289e-02   4.03747559e-02
    1.52130127e-02  -4.05883789e-02  -3.01818848e-02   4.67224121e-02
    4.44030762e-02  -1.94549561e-02   3.07464600e-02  -9.61914062e-02
    1.49307251e-02   3.43513489e-03   3.00750732e-02   2.25372314e-02
    7.80639648e-02  -1.98669434e-02   4.60052490e-03   3.36303711e-02
   -4.23583984e-02   1.38778687e-02   1.26876831e-02  -1.29776001e-02
   -5.23986816e-02  -3.89709473e-02   1.71356201e-02  -5.81359863e-02
   -4.19998169e-03  -2.56729126e-03   4.44335938e-02  -5.49926758e-02
   -3.22570801e-02  -9.60540771e-03  -4.80041504e-02  -3.36303711e-02
    2.14843750e-02  -6.52465820e-02   4.85839844e-02   3.62548828e-02
    3.91540527e-02  -4.73937988e-02   2.02178955e-02  -2.79388428e-02
   -4.14276123e-03  -3.22875977e-02   1.82189941e-02  -4.53796387e-02
   -3.22265625e-02   4.25415039e-02   2.82897949e-02   9.11712646e-03
   -2.48565674e-02   7.52563477e-02   3.22875977e-02  -2.46124268e-02
   -3.31726074e-02  -4.04968262e-02  -1.73797607e-02  -5.40542603e-03
    3.45764160e-02  -1.59759521e-02   2.89459229e-02  -2.81524658e-02
   -4.87976074e-02  -1.40228271e-02  -1.00463867e-01   5.10787964e-03
    2.66265869e-02   8.50677490e-03   5.67932129e-02  -2.63824463e-02
   -2.11791992e-02  -6.86645508e-02  -2.69012451e-02  -1.67083740e-02
   -4.58068848e-02   2.83241272e-03  -3.20739746e-02  -6.71997070e-02
   -1.06079102e-01   1.21917725e-02  -5.89904785e-02   2.06146240e-02
   -6.11267090e-02  -5.10559082e-02  -3.72009277e-02  -2.11486816e-02
   -8.06427002e-03  -1.24435425e-02  -1.87988281e-02   1.38854980e-02
    3.99169922e-02  -2.13775635e-02  -3.69567871e-02  -2.41088867e-02
    1.89208984e-02   5.08422852e-02  -3.21960449e-02   1.79748535e-02
    1.67388916e-02   4.70886230e-02  -1.89971924e-02  -2.03247070e-02
    6.09130859e-02  -7.18383789e-02   3.29284668e-02   1.05133057e-02
    2.22778320e-02   3.59497070e-02  -4.16259766e-02   1.10534668e-01
   -5.20935059e-02  -2.78167725e-02   2.25524902e-02  -1.48544312e-02
    6.25000000e-02   4.30297852e-02  -1.18484497e-02  -3.62243652e-02
    4.45861816e-02  -7.38525391e-02  -2.81372070e-02  -2.90374756e-02
   -1.41906738e-02  -1.94549561e-03   3.43627930e-02  -2.38037109e-02
    3.30810547e-02  -1.06811523e-02   5.79833984e-03   2.87628174e-02
    4.84619141e-02   8.47167969e-02  -4.60815430e-03   2.85949707e-02
   -6.96563721e-03  -2.32391357e-02   5.17578125e-02   4.91714478e-03
   -4.08935547e-02   3.72619629e-02   2.87780762e-02  -5.37109375e-02
   -3.60107422e-02  -3.86962891e-02  -2.76184082e-02  -1.25045776e-02
   -2.02178955e-02  -3.91845703e-02  -4.40216064e-03   2.98767090e-02
   -4.70886230e-02   2.64892578e-02   2.32391357e-02   2.98461914e-02
   -9.20410156e-02  -3.55224609e-02   1.13143921e-02   6.17675781e-02
    1.01394653e-02   3.82385254e-02   5.31005859e-03  -3.54309082e-02
   -6.67724609e-02  -1.78217888e-04  -3.69567871e-02   1.80358887e-02
   -1.35040283e-02  -6.50634766e-02  -7.18688965e-03   2.86712646e-02
    6.89086914e-02  -2.20947266e-02  -3.38439941e-02  -1.80358887e-02
    3.28063965e-02   2.79235840e-03   1.55487061e-02  -1.30615234e-02
   -1.44500732e-02   2.03094482e-02   1.63116455e-02  -4.99267578e-02
    4.55322266e-02  -4.82177734e-02   7.54394531e-02  -1.26838684e-03
    1.67369843e-03   1.71566010e-03  -7.77587891e-02   1.04331970e-03
   -8.07495117e-02  -4.11987305e-02  -7.81250000e-03   2.40936279e-02
   -5.92346191e-02  -1.12228394e-02   7.83691406e-02  -2.80151367e-02
   -9.64164734e-04  -7.94982910e-03   2.17895508e-02   1.72138214e-03
    4.79431152e-02  -4.55322266e-02  -5.85327148e-02   8.07952881e-03
    1.31759644e-02  -6.11877441e-02  -2.63824463e-02  -3.42102051e-02
    8.65936279e-03  -1.64031982e-02  -4.23049927e-03   4.48608398e-02
   -9.67407227e-03  -3.22875977e-02   3.53698730e-02   7.54356384e-04
    2.96235085e-05  -1.93939209e-02   6.51836395e-04   1.49230957e-02
    2.26287842e-02  -7.32803345e-03  -5.74951172e-02   5.71289062e-02
    2.66571045e-02   3.64379883e-02  -3.16467285e-02   2.34069824e-02
   -4.54406738e-02   8.74328613e-03  -6.52465820e-02   5.35583496e-02
    1.01623535e-02  -1.44805908e-02   1.01470947e-02  -3.99780273e-02
   -1.70288086e-02  -3.25317383e-02  -2.34527588e-02  -5.13916016e-02
    6.09874725e-04   9.21020508e-02   8.12988281e-02   3.76892090e-02
    2.64282227e-02  -2.96325684e-02  -1.61895752e-02  -1.28860474e-02]]
After layer expand_dims1045_0 (1, 1, 256) <class 'numpy.float16'> [[[ -5.95703125e-02  -5.12695312e-02   2.85148621e-03   1.65405273e-02
     2.35900879e-02  -2.52685547e-02   2.10571289e-02   4.03747559e-02
     1.52130127e-02  -4.05883789e-02  -3.01818848e-02   4.67224121e-02
     4.44030762e-02  -1.94549561e-02   3.07464600e-02  -9.61914062e-02
     1.49307251e-02   3.43513489e-03   3.00750732e-02   2.25372314e-02
     7.80639648e-02  -1.98669434e-02   4.60052490e-03   3.36303711e-02
    -4.23583984e-02   1.38778687e-02   1.26876831e-02  -1.29776001e-02
    -5.23986816e-02  -3.89709473e-02   1.71356201e-02  -5.81359863e-02
    -4.19998169e-03  -2.56729126e-03   4.44335938e-02  -5.49926758e-02
    -3.22570801e-02  -9.60540771e-03  -4.80041504e-02  -3.36303711e-02
     2.14843750e-02  -6.52465820e-02   4.85839844e-02   3.62548828e-02
     3.91540527e-02  -4.73937988e-02   2.02178955e-02  -2.79388428e-02
    -4.14276123e-03  -3.22875977e-02   1.82189941e-02  -4.53796387e-02
    -3.22265625e-02   4.25415039e-02   2.82897949e-02   9.11712646e-03
    -2.48565674e-02   7.52563477e-02   3.22875977e-02  -2.46124268e-02
    -3.31726074e-02  -4.04968262e-02  -1.73797607e-02  -5.40542603e-03
     3.45764160e-02  -1.59759521e-02   2.89459229e-02  -2.81524658e-02
    -4.87976074e-02  -1.40228271e-02  -1.00463867e-01   5.10787964e-03
     2.66265869e-02   8.50677490e-03   5.67932129e-02  -2.63824463e-02
    -2.11791992e-02  -6.86645508e-02  -2.69012451e-02  -1.67083740e-02
    -4.58068848e-02   2.83241272e-03  -3.20739746e-02  -6.71997070e-02
    -1.06079102e-01   1.21917725e-02  -5.89904785e-02   2.06146240e-02
    -6.11267090e-02  -5.10559082e-02  -3.72009277e-02  -2.11486816e-02
    -8.06427002e-03  -1.24435425e-02  -1.87988281e-02   1.38854980e-02
     3.99169922e-02  -2.13775635e-02  -3.69567871e-02  -2.41088867e-02
     1.89208984e-02   5.08422852e-02  -3.21960449e-02   1.79748535e-02
     1.67388916e-02   4.70886230e-02  -1.89971924e-02  -2.03247070e-02
     6.09130859e-02  -7.18383789e-02   3.29284668e-02   1.05133057e-02
     2.22778320e-02   3.59497070e-02  -4.16259766e-02   1.10534668e-01
    -5.20935059e-02  -2.78167725e-02   2.25524902e-02  -1.48544312e-02
     6.25000000e-02   4.30297852e-02  -1.18484497e-02  -3.62243652e-02
     4.45861816e-02  -7.38525391e-02  -2.81372070e-02  -2.90374756e-02
    -1.41906738e-02  -1.94549561e-03   3.43627930e-02  -2.38037109e-02
     3.30810547e-02  -1.06811523e-02   5.79833984e-03   2.87628174e-02
     4.84619141e-02   8.47167969e-02  -4.60815430e-03   2.85949707e-02
    -6.96563721e-03  -2.32391357e-02   5.17578125e-02   4.91714478e-03
    -4.08935547e-02   3.72619629e-02   2.87780762e-02  -5.37109375e-02
    -3.60107422e-02  -3.86962891e-02  -2.76184082e-02  -1.25045776e-02
    -2.02178955e-02  -3.91845703e-02  -4.40216064e-03   2.98767090e-02
    -4.70886230e-02   2.64892578e-02   2.32391357e-02   2.98461914e-02
    -9.20410156e-02  -3.55224609e-02   1.13143921e-02   6.17675781e-02
     1.01394653e-02   3.82385254e-02   5.31005859e-03  -3.54309082e-02
    -6.67724609e-02  -1.78217888e-04  -3.69567871e-02   1.80358887e-02
    -1.35040283e-02  -6.50634766e-02  -7.18688965e-03   2.86712646e-02
     6.89086914e-02  -2.20947266e-02  -3.38439941e-02  -1.80358887e-02
     3.28063965e-02   2.79235840e-03   1.55487061e-02  -1.30615234e-02
    -1.44500732e-02   2.03094482e-02   1.63116455e-02  -4.99267578e-02
     4.55322266e-02  -4.82177734e-02   7.54394531e-02  -1.26838684e-03
     1.67369843e-03   1.71566010e-03  -7.77587891e-02   1.04331970e-03
    -8.07495117e-02  -4.11987305e-02  -7.81250000e-03   2.40936279e-02
    -5.92346191e-02  -1.12228394e-02   7.83691406e-02  -2.80151367e-02
    -9.64164734e-04  -7.94982910e-03   2.17895508e-02   1.72138214e-03
     4.79431152e-02  -4.55322266e-02  -5.85327148e-02   8.07952881e-03
     1.31759644e-02  -6.11877441e-02  -2.63824463e-02  -3.42102051e-02
     8.65936279e-03  -1.64031982e-02  -4.23049927e-03   4.48608398e-02
    -9.67407227e-03  -3.22875977e-02   3.53698730e-02   7.54356384e-04
     2.96235085e-05  -1.93939209e-02   6.51836395e-04   1.49230957e-02
     2.26287842e-02  -7.32803345e-03  -5.74951172e-02   5.71289062e-02
     2.66571045e-02   3.64379883e-02  -3.16467285e-02   2.34069824e-02
    -4.54406738e-02   8.74328613e-03  -6.52465820e-02   5.35583496e-02
     1.01623535e-02  -1.44805908e-02   1.01470947e-02  -3.99780273e-02
    -1.70288086e-02  -3.25317383e-02  -2.34527588e-02  -5.13916016e-02
     6.09874725e-04   9.21020508e-02   8.12988281e-02   3.76892090e-02
     2.64282227e-02  -2.96325684e-02  -1.61895752e-02  -1.28860474e-02]]]
After layer encoder_birnn_reverse_l0_t4_i2h_output (1, 1024) <class 'numpy.float16'> [[-0.0128479  -0.04095459  0.03787231 ...,  0.06970215 -0.04626465
   0.03759766]]
After layer encoder_birnn_reverse_l0_t4_h2h_output (1, 1024) <class 'numpy.float16'> [[ 0.00685883  0.02537537 -0.04446411 ...,  0.0637207   0.03656006
   0.03143311]]
After layer _plus1040_0 (1, 1024) <class 'numpy.float16'> [[-0.00598907 -0.01557922 -0.0065918  ...,  0.13342285 -0.00970459
   0.06903076]]
After layer encoder_birnn_reverse_l0_t4_slice_output0 (1, 256) <class 'numpy.float16'> [[-0.00598907 -0.01557922 -0.0065918  -0.02043152  0.05273438 -0.00769043
   0.03662109  0.02302551  0.0916748   0.05511475 -0.03704834  0.0769043
   0.01968384  0.04052734 -0.00128174  0.25683594 -0.09069824 -0.06155396
   0.01294708 -0.01197815  0.08435059  0.02606201 -0.08886719 -0.03936768
   0.08459473 -0.11859131 -0.03146362 -0.01846313  0.02975464 -0.01701355
   0.00244141 -0.01808167 -0.04241943 -0.04574585  0.0690918  -0.12316895
  -0.00894165 -0.00588226 -0.07208252 -0.05239868 -0.09289551  0.03314209
  -0.05383301  0.00143433  0.03570557 -0.00865173  0.06396484 -0.07543945
  -0.01455688  0.02047729  0.00054932  0.09649658 -0.07141113  0.06768799
   0.1862793   0.09851074 -0.0546875   0.01121521 -0.05831909 -0.02326965
   0.07049561 -0.04342651  0.15515137 -0.02677917 -0.11090088 -0.04116821
   0.09619141 -0.01765442 -0.05914307  0.01733398  0.09558105 -0.02320862
   0.00030518 -0.00642395 -0.00360107  0.06866455  0.12359619  0.14099121
   0.01113892  0.04382324  0.02529907  0.04589844  0.08581543 -0.01759338
   0.16003418  0.05807495 -0.02714539 -0.0390625  -0.02716064  0.09375
   0.11645508 -0.0194397  -0.0802002   0.09088135  0.07427979  0.04321289
  -0.02322388  0.08972168 -0.08728027 -0.10693359 -0.07275391  0.07543945
  -0.00177002 -0.13293457 -0.06451416  0.00700378 -0.02137756 -0.11065674
   0.05334473  0.04998779 -0.11999512  0.02978516  0.01753235  0.17956543
   0.00213623  0.28662109 -0.03546143  0.00845337  0.03942871 -0.03948975
   0.20495605 -0.12011719  0.00430298  0.0916748  -0.05206299  0.0536499
  -0.1149292   0.06762695 -0.01675415  0.00363159  0.18054199  0.06530762
  -0.00482178 -0.03463745 -0.06530762 -0.05841064  0.09375     0.14929199
   0.00076294 -0.01721191 -0.03768921 -0.09448242  0.07409668  0.06561279
  -0.03369141 -0.00384521  0.03045654  0.0592041  -0.01712036  0.05578613
   0.10913086 -0.05023193  0.00289917 -0.09405518 -0.06732178  0.18896484
   0.03259277  0.06359863 -0.01589966 -0.03253174  0.18933105  0.01014709
  -0.04724121  0.03448486  0.01548004 -0.06268311  0.01141357 -0.0435791
   0.05154419 -0.03930664  0.01335907  0.03872681  0.00553131  0.09851074
   0.02915955 -0.12109375  0.03485107 -0.1137085  -0.04876709 -0.02384949
   0.03613281 -0.06347656 -0.0177002   0.03207397  0.09429932 -0.02453613
  -0.01394653 -0.0597229   0.11724854  0.05993652 -0.02435303 -0.01583862
   0.0440979  -0.0244751   0.06231689  0.07263184  0.07983398 -0.15490723
   0.04376221  0.05895996  0.00109863  0.13122559  0.06512451  0.03625488
   0.02964783 -0.01654053  0.00131226 -0.05010986 -0.0553894   0.04669189
   0.04064941  0.09619141  0.02059937  0.06018066  0.01257324  0.03771973
  -0.00626373 -0.02276611  0.01678467  0.00437927 -0.0524292  -0.05065918
   0.07067871 -0.07202148  0.01300049  0.06280518 -0.02105713 -0.0892334
  -0.06286621  0.140625   -0.01106262 -0.08782959 -0.01991272 -0.040802
   0.03253174  0.06262207 -0.00674438  0.0770874   0.03071594 -0.04498291
  -0.07641602 -0.1159668   0.10455322  0.23291016 -0.05111694  0.02789307
  -0.03942871 -0.06494141  0.01760864  0.0153656   0.13525391  0.00552368
  -0.08551025  0.04821777  0.04931641 -0.01963806]]
After layer encoder_birnn_reverse_l0_t4_slice_output1 (1, 256) <class 'numpy.float16'> [[  1.38793945e-01   2.38342285e-02   8.95385742e-02   4.74243164e-02
    1.98669434e-02   7.01293945e-02   1.67968750e-01  -8.59985352e-02
    3.27636719e-01   1.33544922e-01   1.19689941e-01   1.02539062e-01
    9.91210938e-02   7.43103027e-03   1.10595703e-01   1.16638184e-01
    8.45947266e-02  -4.63256836e-02  -1.35864258e-01   5.19714355e-02
    1.16699219e-01   3.90625000e-03   3.09570312e-01   4.95605469e-02
    1.13769531e-01   6.87255859e-02   1.28051758e-01   9.41772461e-02
    1.04980469e-01   3.30505371e-02   5.76782227e-02   1.33972168e-02
    2.16552734e-01  -5.47485352e-02  -1.47094727e-02   1.22070312e-04
   -5.75561523e-02   9.51538086e-02   2.11791992e-02   9.19189453e-02
   -2.30712891e-02   9.96704102e-02   1.17645264e-02   8.99658203e-02
    2.45666504e-02   1.01806641e-01   3.04870605e-02  -9.50927734e-02
    2.70080566e-03   3.38134766e-02   6.15844727e-02   7.50732422e-02
    1.84326172e-02   1.31347656e-01   7.86132812e-02   6.77490234e-02
    4.04052734e-02   8.68530273e-02   9.65118408e-03  -7.49511719e-02
    5.74951172e-02   3.63159180e-02   4.16564941e-02   4.06188965e-02
   -1.62963867e-02   1.28417969e-01   1.91284180e-01   6.06079102e-02
   -1.04309082e-01  -1.59912109e-02   6.22558594e-02  -1.39770508e-02
   -2.80456543e-02   2.92968750e-02   9.24072266e-02   1.79931641e-01
    5.31005859e-02   3.73535156e-02   7.24487305e-02   7.33642578e-02
    2.04467773e-01   1.52709961e-01   3.78723145e-02   3.58581543e-02
    1.48315430e-01   5.99670410e-03   6.89086914e-02   1.77246094e-01
    3.10821533e-02  -1.14013672e-01   2.71484375e-01   9.11254883e-02
    7.71484375e-02   7.09838867e-02  -4.63867188e-02   2.18963623e-02
    1.77307129e-02   1.04431152e-01  -1.38305664e-01  -1.51977539e-01
   -3.87878418e-02   7.59887695e-03   2.66418457e-02   9.28955078e-02
    3.33404541e-03  -2.37426758e-02  -9.47265625e-02   6.89697266e-02
    6.32324219e-02  -7.61718750e-02   4.63867188e-03  -1.75018311e-02
    3.95202637e-02   1.60400391e-01   9.52758789e-02   1.78710938e-01
    9.19189453e-02   1.17980957e-01   9.57031250e-02   1.02172852e-01
    1.76147461e-01   1.52465820e-01   3.38134766e-02   1.67999268e-02
   -1.83105469e-03  -9.39941406e-03   1.61743164e-01  -5.11169434e-03
    1.01013184e-01  -9.27734375e-02   9.46044922e-02   1.41601562e-01
    1.37634277e-02   1.44287109e-01   7.20214844e-02   6.83593750e-02
    2.09045410e-02   3.78112793e-02   1.16088867e-01   1.70288086e-01
   -7.42797852e-02   6.62841797e-02   6.25610352e-02   2.89611816e-02
    2.66418457e-02   1.25732422e-01   5.69458008e-02   3.80554199e-02
    4.11987305e-02  -1.71203613e-02  -2.81066895e-02   6.29882812e-02
    2.24609375e-02   7.76367188e-02   2.90222168e-02   1.75048828e-01
    9.64965820e-02  -6.34765625e-03   3.44238281e-02   1.32812500e-01
    2.09960938e-01   7.64160156e-02  -3.16162109e-02   8.06884766e-02
    5.68847656e-02  -2.77709961e-03   2.43774414e-01  -4.06494141e-02
   -2.47192383e-03  -3.01208496e-02   3.72314453e-02   1.12792969e-01
   -3.88793945e-02   1.90429688e-01  -3.45458984e-02   1.00402832e-01
    1.52465820e-01  -4.54711914e-03   1.77001953e-02   1.07604980e-01
    7.83691406e-02  -7.09228516e-02   2.14111328e-01  -4.08020020e-02
    9.33837891e-03   3.66210938e-04   3.56750488e-02   1.72119141e-01
    2.05688477e-02  -4.25415039e-02  -3.33862305e-02   2.52075195e-02
    1.62841797e-01   1.38305664e-01  -2.34985352e-02  -1.00708008e-03
   -1.47399902e-02  -6.71386719e-03   2.68859863e-02   1.56250000e-02
    2.88696289e-02   6.40869141e-02   7.48291016e-02  -3.67431641e-02
    9.29565430e-02  -1.24023438e-01  -2.58789062e-02   1.40136719e-01
   -4.34570312e-02   8.68530273e-02   7.42797852e-02   1.08215332e-01
   -4.90112305e-02   2.17590332e-02  -1.95312500e-02  -7.18994141e-02
    5.49011230e-02   8.92944336e-02  -1.17340088e-02   1.05468750e-01
   -9.15527344e-02  -4.23583984e-02   2.20458984e-01   2.26287842e-02
    7.77587891e-02  -5.95092773e-03   1.72729492e-02   3.59497070e-02
    3.18115234e-01   2.26074219e-01   1.64184570e-02  -2.46215820e-01
    1.40625000e-01   3.24707031e-02   5.42297363e-02   1.22070312e-04
    1.12609863e-02   8.37402344e-02   2.98156738e-02   9.36279297e-02
    7.65380859e-02   2.67944336e-02   4.15039062e-02   2.15942383e-01
   -1.33056641e-01  -2.32543945e-02  -3.62548828e-02  -5.76782227e-02
    8.80126953e-02  -1.54724121e-02   1.41357422e-01  -1.44531250e-01
    1.44042969e-01  -1.98974609e-02   1.28540039e-01   3.17382812e-03]]
After layer encoder_birnn_reverse_l0_t4_slice_output2 (1, 256) <class 'numpy.float16'> [[-0.15405273 -0.13928223 -0.01786804  0.04064941  0.0383606  -0.06106567
   0.03424072  0.08618164  0.06402588 -0.10614014 -0.07928467  0.1418457
   0.08898926 -0.02644348  0.06481934 -0.23291016  0.07122803  0.02781677
   0.08831787  0.05300903  0.20935059 -0.05895996 -0.00564575  0.06036377
  -0.11724854  0.03579712  0.05926514 -0.05334473 -0.14379883 -0.11352539
   0.04248047 -0.12402344 -0.01165771  0.01037598  0.1184082  -0.15466309
  -0.06414795 -0.00450897 -0.12548828 -0.10650635  0.02514648 -0.20043945
   0.12878418  0.09265137  0.09136963 -0.11315918  0.0402832  -0.07208252
  -0.01378632 -0.10070801  0.07250977 -0.12573242 -0.0824585   0.14624023
   0.02960205  0.02400208 -0.0300293   0.19299316  0.10510254 -0.04754639
  -0.09698486 -0.10144043 -0.02304077 -0.02050781  0.06872559 -0.03649902
   0.03283691 -0.11224365 -0.11004639 -0.00857544 -0.26538086  0.01521301
   0.05273438  0.02742004  0.13378906 -0.03543091 -0.04528809 -0.20092773
  -0.06884766 -0.04208374 -0.12213135  0.01960754 -0.09173584 -0.17321777
  -0.26245117  0.01028442 -0.12445068  0.02642822 -0.19128418 -0.12036133
  -0.11938477 -0.06164551 -0.03048706 -0.00648499 -0.0513916   0.05178833
   0.09643555 -0.04672241 -0.10839844 -0.08972168  0.01977539  0.14440918
  -0.07043457  0.05001831  0.06298828  0.16638184 -0.04626465 -0.0479126
   0.16308594 -0.19873047  0.10510254 -0.0042572   0.08123779  0.10253906
  -0.09234619  0.27294922 -0.16601562 -0.08557129  0.0413208  -0.07080078
   0.16906738  0.07165527 -0.01837158 -0.09790039  0.10900879 -0.18481445
  -0.1192627  -0.07720947 -0.04937744 -0.02807617  0.09002686 -0.03186035
   0.0793457   0.0085144   0.00169373  0.07434082  0.08544922  0.22216797
  -0.00377655  0.06481934 -0.00354004 -0.04766846  0.14160156  0.02532959
  -0.09179688  0.10168457  0.07293701 -0.11224365 -0.10040283 -0.13452148
  -0.06164551 -0.02774048 -0.06756592 -0.08227539 -0.00857544  0.07629395
  -0.12585449  0.03527832  0.05471802  0.0723877  -0.22644043 -0.06677246
   0.02713013  0.16003418  0.03588867  0.10021973  0.01664734 -0.04766846
  -0.20654297  0.01782227 -0.10314941  0.05371094 -0.03845215 -0.15087891
  -0.02827454  0.07904053  0.15539551 -0.05178833 -0.05865479 -0.02856445
   0.07269287  0.01519775  0.04266357 -0.03811646 -0.06854248  0.05859375
   0.05029297 -0.10925293  0.09484863 -0.13598633  0.21008301 -0.01696777
  -0.00722504  0.02972412 -0.22363281 -0.00500488 -0.22949219 -0.1003418
  -0.03875732  0.0715332  -0.16821289 -0.03982544  0.18334961 -0.05987549
  -0.02078247 -0.03057861  0.07647705  0.01396179  0.13122559 -0.08099365
  -0.1751709  -0.00036621  0.03012085 -0.18969727 -0.06396484 -0.0904541
   0.03381348 -0.04174805 -0.0406189   0.12573242 -0.03588867 -0.08947754
   0.0814209   0.02630615  0.0123291  -0.05932617  0.00856018  0.0345459
   0.02987671 -0.0020237  -0.14953613  0.1784668   0.04214478  0.09228516
  -0.06964111  0.03289795 -0.09802246  0.02133179 -0.19873047  0.12939453
   0.01277161 -0.01121521  0.02828979 -0.050354   -0.0378418  -0.06292725
  -0.06188965 -0.18371582  0.02105713  0.23522949  0.21508789  0.11035156
   0.04525757 -0.07928467 -0.0546875  -0.00811768]]
After layer encoder_birnn_reverse_l0_t4_slice_output3 (1, 256) <class 'numpy.float16'> [[  6.04858398e-02   3.54919434e-02  -1.52359009e-02   5.88684082e-02
    4.98352051e-02   2.01782227e-01   1.03027344e-01   1.26464844e-01
    3.55468750e-01   1.14074707e-01  -4.27246094e-02   6.06689453e-02
    1.55761719e-01  -3.29589844e-02   3.91845703e-02   1.09069824e-01
   -5.69458008e-02  -7.61718750e-02   2.78930664e-02  -2.02941895e-02
   -3.43322754e-02  -1.26708984e-01   2.40844727e-01   1.03454590e-01
    6.92138672e-02   4.12597656e-02  -3.44848633e-03  -3.89862061e-03
   -8.21533203e-02   1.73034668e-02   1.07604980e-01   1.00341797e-01
    3.03955078e-02   2.61688232e-02  -2.62145996e-02  -3.34472656e-02
    1.00463867e-01  -1.02539062e-02   8.09326172e-02  -4.51660156e-03
    8.48388672e-02  -2.89001465e-02  -7.62939453e-05   1.43432617e-03
   -2.84423828e-02   2.46887207e-02   2.01721191e-02  -6.05773926e-02
    3.09143066e-02   9.73510742e-02   8.57543945e-02  -3.54919434e-02
   -2.33764648e-02   5.49926758e-02   1.74194336e-01  -1.11938477e-01
    1.36352539e-01   1.72729492e-02   2.80456543e-02  -1.11877441e-01
    4.82177734e-02   5.81665039e-02   2.89611816e-02   1.52587891e-01
   -9.69696045e-03  -6.07910156e-02   1.82861328e-01   5.70068359e-02
    2.20336914e-02   9.01489258e-02   1.82189941e-02   4.01306152e-02
    1.21459961e-02  -1.80053711e-02   9.80834961e-02   2.11425781e-01
    1.35498047e-01   4.29992676e-02   1.09375000e-01   2.02026367e-01
    1.60644531e-01   1.90917969e-01   8.71582031e-02   1.18041992e-01
    1.44897461e-01   5.57250977e-02   2.91137695e-02   1.09130859e-01
    7.29370117e-02   8.45336914e-02   1.47949219e-01  -3.98559570e-02
   -8.81347656e-02   3.02581787e-02   5.58471680e-02   3.52478027e-02
    6.84814453e-02   1.20483398e-01  -1.34765625e-01  -9.27734375e-02
   -2.41088867e-02  -1.33911133e-01  -6.38427734e-02  -7.71484375e-02
   -4.11987305e-03   1.13830566e-02  -3.58276367e-02   1.23107910e-01
    5.20935059e-02   1.62719727e-01   7.61413574e-03   5.47180176e-02
   -7.74536133e-02   1.29150391e-01   1.33361816e-02   1.44775391e-01
   -8.27636719e-02  -2.24304199e-02   8.16040039e-02  -5.98754883e-02
    2.78015137e-02   8.76464844e-02   9.22851562e-02   7.65991211e-03
   -4.21447754e-02   3.27758789e-02  -1.61437988e-02  -1.01928711e-02
   -2.83813477e-02  -7.49511719e-02   1.62963867e-02   1.83837891e-01
   -1.31683350e-02   9.28955078e-02   3.92761230e-02  -6.46972656e-02
    1.20727539e-01   5.97229004e-02   1.13464355e-01   2.62451172e-02
    1.16577148e-02   8.23974609e-04  -8.56933594e-02   6.16455078e-02
    4.96673584e-03   2.38037109e-02   1.37207031e-01   4.96826172e-02
    3.96118164e-02  -1.40991211e-02  -2.34985352e-02  -2.99682617e-02
    5.93261719e-02   1.30126953e-01   1.67846680e-02   8.34960938e-02
    8.02001953e-02   1.20300293e-01   4.29382324e-02   1.27319336e-01
    7.17773438e-02   2.55737305e-02  -2.09960938e-02   1.39404297e-01
    8.19091797e-02  -6.72607422e-02   2.39746094e-01   1.02050781e-01
   -1.09863281e-01   2.38342285e-02  -9.09423828e-02   9.60083008e-02
    8.03222656e-02   1.85546875e-01   3.05786133e-02   1.60156250e-01
    1.45019531e-01  -4.90112305e-02   8.92333984e-02  -1.15051270e-02
   -1.01074219e-01  -5.68847656e-02   4.02221680e-02  -5.24291992e-02
   -4.13513184e-02   1.05895996e-01  -2.06756592e-02   9.60083008e-02
    1.27563477e-02  -8.04443359e-02   2.69165039e-02   1.37207031e-01
    4.84008789e-02   7.50732422e-03   4.94384766e-02   5.77392578e-02
   -2.58178711e-02   5.49011230e-02   1.01440430e-01   5.92041016e-03
    6.98242188e-02   2.18627930e-01   8.86230469e-02   1.41601562e-01
    8.59985352e-02   9.06982422e-02  -6.64062500e-02   3.79943848e-02
   -8.12988281e-02   1.56005859e-01  -9.82666016e-03   2.91992188e-01
    4.30908203e-02   1.42333984e-01   8.93554688e-02  -4.00695801e-02
    6.23474121e-02   1.71020508e-01  -3.32031250e-02  -5.10253906e-02
   -4.69055176e-02  -1.09008789e-01   1.36962891e-01   2.58331299e-02
    6.89697266e-02   9.79003906e-02   1.10931396e-02   2.62756348e-02
    2.86132812e-01   1.95068359e-01   1.91345215e-02  -1.13586426e-01
   -2.33459473e-02   2.38037109e-03  -1.91040039e-02   2.04620361e-02
   -3.38134766e-02   7.19604492e-02   1.04736328e-01   2.67028809e-02
   -9.34448242e-02   8.11157227e-02   1.16333008e-01   3.18359375e-01
   -1.09069824e-01   5.78002930e-02   4.56542969e-02  -1.18530273e-01
    3.29284668e-02  -2.01416016e-03   9.61914062e-02  -7.53173828e-02
    9.46655273e-02   1.33422852e-01  -9.70458984e-03   6.90307617e-02]]
After layer encoder_birnn_reverse_l0_t4_o_output (1, 256) <class 'numpy.float16'> [[ 0.51513672  0.50878906  0.49609375  0.51464844  0.51269531  0.55029297
   0.52587891  0.53173828  0.58789062  0.52832031  0.48925781  0.51513672
   0.5390625   0.49169922  0.50976562  0.52734375  0.48583984  0.48095703
   0.50683594  0.49487305  0.49145508  0.46826172  0.56005859  0.52587891
   0.51708984  0.51025391  0.49902344  0.49902344  0.47949219  0.50439453
   0.52685547  0.52490234  0.5078125   0.50634766  0.4934082   0.49169922
   0.52490234  0.49755859  0.52001953  0.4987793   0.52099609  0.49267578
   0.5         0.50048828  0.49291992  0.50634766  0.50488281  0.48486328
   0.5078125   0.52441406  0.52148438  0.49121094  0.49414062  0.51367188
   0.54345703  0.47192383  0.53417969  0.50439453  0.50683594  0.47216797
   0.51220703  0.51464844  0.50732422  0.53808594  0.49755859  0.48486328
   0.54541016  0.51416016  0.50537109  0.52246094  0.50439453  0.51025391
   0.50292969  0.49560547  0.52441406  0.55273438  0.53369141  0.51074219
   0.52734375  0.55029297  0.54003906  0.54736328  0.52197266  0.52929688
   0.53613281  0.51416016  0.50732422  0.52734375  0.51806641  0.52099609
   0.53710938  0.48999023  0.47802734  0.50732422  0.51416016  0.50878906
   0.51708984  0.53027344  0.46630859  0.47680664  0.49389648  0.46655273
   0.48413086  0.48071289  0.49902344  0.50292969  0.4909668   0.53076172
   0.51318359  0.54052734  0.50195312  0.51367188  0.48071289  0.53222656
   0.50341797  0.53613281  0.47924805  0.49438477  0.52050781  0.48510742
   0.50683594  0.52197266  0.52294922  0.50195312  0.48950195  0.50830078
   0.49584961  0.49755859  0.49291992  0.48120117  0.50390625  0.54589844
   0.49682617  0.5234375   0.50976562  0.48388672  0.53027344  0.51513672
   0.52832031  0.50634766  0.50292969  0.5         0.47851562  0.515625
   0.50146484  0.50585938  0.53417969  0.51220703  0.50976562  0.49658203
   0.49414062  0.49243164  0.51464844  0.53271484  0.50439453  0.52099609
   0.52001953  0.53027344  0.51074219  0.53173828  0.51806641  0.50634766
   0.49487305  0.53466797  0.52050781  0.4831543   0.55957031  0.52539062
   0.47265625  0.50585938  0.47729492  0.52392578  0.52001953  0.54638672
   0.5078125   0.54003906  0.53613281  0.48779297  0.52246094  0.49707031
   0.47485352  0.48583984  0.51025391  0.48681641  0.48974609  0.52636719
   0.49487305  0.52392578  0.50341797  0.47998047  0.50683594  0.53417969
   0.51220703  0.50195312  0.51220703  0.51464844  0.49365234  0.51367188
   0.52539062  0.50146484  0.51757812  0.55419922  0.52197266  0.53515625
   0.52148438  0.52246094  0.48339844  0.50927734  0.47973633  0.5390625
   0.49755859  0.57226562  0.51074219  0.53564453  0.52246094  0.48999023
   0.515625    0.54248047  0.49169922  0.48730469  0.48828125  0.47265625
   0.53417969  0.50634766  0.51708984  0.52441406  0.50292969  0.50634766
   0.57128906  0.54882812  0.50488281  0.47167969  0.49414062  0.50048828
   0.49511719  0.50488281  0.49145508  0.51806641  0.52636719  0.50683594
   0.4765625   0.52050781  0.52880859  0.57910156  0.47265625  0.51464844
   0.51123047  0.47045898  0.50830078  0.49951172  0.52392578  0.48120117
   0.5234375   0.53320312  0.49755859  0.51708984]]
After layer encoder_birnn_reverse_l0_t4_f_output (1, 256) <class 'numpy.float16'> [[ 0.53466797  0.50585938  0.52246094  0.51171875  0.50488281  0.51757812
   0.54199219  0.47851562  0.58105469  0.53320312  0.52978516  0.52539062
   0.52490234  0.50195312  0.52783203  0.52929688  0.52099609  0.48852539
   0.46606445  0.51318359  0.52929688  0.50097656  0.57666016  0.51220703
   0.52832031  0.51708984  0.53173828  0.5234375   0.52636719  0.50830078
   0.51464844  0.50341797  0.55371094  0.48632812  0.49633789  0.5
   0.4855957   0.52392578  0.50537109  0.52294922  0.49414062  0.52490234
   0.50292969  0.52246094  0.50634766  0.52539062  0.5078125   0.47631836
   0.50048828  0.50830078  0.515625    0.51855469  0.50439453  0.53271484
   0.51953125  0.51708984  0.51025391  0.52148438  0.50244141  0.48120117
   0.51416016  0.50927734  0.51025391  0.51025391  0.49584961  0.53222656
   0.54785156  0.51513672  0.47387695  0.49609375  0.515625    0.49658203
   0.49291992  0.50732422  0.52294922  0.54492188  0.51318359  0.50927734
   0.51806641  0.51855469  0.55078125  0.53808594  0.50927734  0.50878906
   0.53710938  0.50146484  0.51708984  0.54443359  0.5078125   0.47143555
   0.56738281  0.52294922  0.51904297  0.51757812  0.48852539  0.50537109
   0.50439453  0.52587891  0.46557617  0.4621582   0.49023438  0.50195312
   0.50683594  0.5234375   0.50097656  0.49414062  0.47631836  0.51708984
   0.515625    0.48095703  0.50097656  0.49560547  0.50976562  0.54003906
   0.52392578  0.54443359  0.52294922  0.52929688  0.52392578  0.52539062
   0.54394531  0.53808594  0.50830078  0.50439453  0.49951172  0.49755859
   0.54052734  0.4987793   0.52539062  0.47680664  0.5234375   0.53515625
   0.50341797  0.53613281  0.51806641  0.51708984  0.50537109  0.50927734
   0.52880859  0.54248047  0.48144531  0.51660156  0.515625    0.50732422
   0.50683594  0.53125     0.51416016  0.50927734  0.51025391  0.49560547
   0.49291992  0.515625    0.50537109  0.51953125  0.50732422  0.54345703
   0.52392578  0.49853516  0.50878906  0.53320312  0.55224609  0.51904297
   0.4921875   0.52001953  0.51416016  0.49926758  0.56054688  0.48974609
   0.49926758  0.49243164  0.50927734  0.52832031  0.49023438  0.54736328
   0.49145508  0.52490234  0.53808594  0.4987793   0.50439453  0.52685547
   0.51953125  0.48217773  0.55322266  0.48974609  0.50244141  0.5
   0.50878906  0.54296875  0.50537109  0.48925781  0.49169922  0.50634766
   0.54052734  0.53466797  0.49414062  0.49975586  0.49633789  0.49829102
   0.50683594  0.50390625  0.50732422  0.51611328  0.51855469  0.49072266
   0.5234375   0.46899414  0.49365234  0.53515625  0.48925781  0.52148438
   0.51855469  0.52685547  0.48779297  0.50537109  0.49511719  0.48193359
   0.51367188  0.52246094  0.49707031  0.52636719  0.47705078  0.48950195
   0.5546875   0.50585938  0.51953125  0.49853516  0.50439453  0.50878906
   0.57910156  0.55615234  0.50390625  0.4387207   0.53515625  0.50830078
   0.51367188  0.5         0.50292969  0.52099609  0.50732422  0.5234375
   0.51904297  0.50683594  0.51025391  0.55371094  0.46679688  0.49414062
   0.4909668   0.4855957   0.52197266  0.49609375  0.53515625  0.46386719
   0.53613281  0.49511719  0.53222656  0.50097656]]
After layer _mul2080_0 (1, 256) <class 'numpy.float16'> [[ -6.21643066e-02  -5.14831543e-02   3.00216675e-03   1.65100098e-02
    2.31475830e-02  -2.38189697e-02   2.16979980e-02   3.63769531e-02
    1.52740479e-02  -4.10461426e-02  -3.25012207e-02   4.77905273e-02
    4.36096191e-02  -1.98516846e-02   3.19519043e-02  -9.80834961e-02
    1.59606934e-02   3.45039368e-03   2.77862549e-02   2.34069824e-02
    8.44116211e-02  -2.12554932e-02   4.78363037e-03   3.28674316e-02
   -4.30908203e-02   1.41525269e-02   1.34735107e-02  -1.35269165e-02
   -5.73730469e-02  -3.92761230e-02   1.67999268e-02  -5.58471680e-02
   -4.58526611e-03  -2.47192383e-03   4.48608398e-02  -5.57556152e-02
   -2.99682617e-02  -1.01318359e-02  -4.65393066e-02  -3.50952148e-02
    2.02789307e-02  -6.98852539e-02   4.90112305e-02   3.79333496e-02
    4.02526855e-02  -4.94995117e-02   2.03552246e-02  -2.73132324e-02
   -4.06646729e-03  -3.17077637e-02   1.79901123e-02  -4.84313965e-02
   -3.21960449e-02   4.41894531e-02   2.68402100e-02   9.97161865e-03
   -2.38800049e-02   7.84301758e-02   3.20739746e-02  -2.49938965e-02
   -3.35693359e-02  -4.05883789e-02  -1.74407959e-02  -5.15365601e-03
    3.45764160e-02  -1.75323486e-02   2.93884277e-02  -2.82287598e-02
   -4.54101562e-02  -1.32293701e-02  -1.04125977e-01   4.96292114e-03
    2.60009766e-02   8.72802734e-03   5.73120117e-02  -2.59094238e-02
   -2.05078125e-02  -6.87255859e-02  -2.65655518e-02  -1.58386230e-02
   -4.70581055e-02   2.79426575e-03  -3.14636230e-02  -6.46972656e-02
   -1.08703613e-01   1.18713379e-02  -6.03942871e-02   2.11639404e-02
   -6.03027344e-02  -4.57458496e-02  -3.96118164e-02  -2.24761963e-02
   -8.75091553e-03  -1.26647949e-02  -1.78375244e-02   1.37939453e-02
    3.89099121e-02  -2.10571289e-02  -3.67736816e-02  -2.31323242e-02
    1.85699463e-02   5.45349121e-02  -3.34777832e-02   1.94702148e-02
    1.66625977e-02   4.63562012e-02  -1.84478760e-02  -1.98211670e-02
    6.17065430e-02  -6.36596680e-02   3.29284668e-02   1.01623535e-02
    2.35748291e-02   3.67126465e-02  -4.31823730e-02   1.14257812e-01
   -5.71594238e-02  -2.98461914e-02   2.24151611e-02  -1.61743164e-02
    6.72607422e-02   4.45251465e-02  -1.14669800e-02  -3.64990234e-02
    4.53186035e-02  -7.28149414e-02  -3.07159424e-02  -2.92510986e-02
   -1.51977539e-02  -1.89876556e-03   3.57666016e-02  -2.34222412e-02
    3.33251953e-02  -1.09558105e-02   5.91659546e-03   3.05938721e-02
    4.64782715e-02   8.44116211e-02  -4.61959839e-03   3.06396484e-02
   -6.68716431e-03  -2.39105225e-02   5.63049316e-02   4.86755371e-03
   -4.12597656e-02   3.92456055e-02   2.79541016e-02  -5.38940430e-02
   -3.60412598e-02  -3.86962891e-02  -2.74963379e-02  -1.31072998e-02
   -1.99584961e-02  -3.82995605e-02  -4.37927246e-03   3.11431885e-02
   -4.79736328e-02   2.46887207e-02   2.31628418e-02   3.00750732e-02
   -9.97924805e-02  -3.64685059e-02   1.12991333e-02   6.03332520e-02
    1.00021362e-02   3.94897461e-02   5.38253784e-03  -3.32031250e-02
   -7.01904297e-02  -1.72853470e-04  -3.92150879e-02   1.82800293e-02
   -1.27334595e-02  -6.60400391e-02  -6.91223145e-03   2.80914307e-02
    6.97631836e-02  -2.24151611e-02  -3.25622559e-02  -1.91040039e-02
    3.55834961e-02   2.75611877e-03   1.68762207e-02  -1.29699707e-02
   -1.47247314e-02   1.95465088e-02   1.67694092e-02  -5.20629883e-02
    4.50134277e-02  -4.86450195e-02   7.33032227e-02  -1.20544434e-03
    1.76620483e-03   1.83773041e-03  -7.38525391e-02   1.01375580e-03
   -8.16650391e-02  -3.99169922e-02  -7.59506226e-03   2.43377686e-02
   -5.85937500e-02  -1.04446411e-02   7.83691406e-02  -2.57873535e-02
   -9.70363617e-04  -7.14492798e-03   2.21405029e-02   1.81865692e-03
    4.86145020e-02  -4.44335938e-02  -6.15234375e-02   7.45773315e-03
    1.26495361e-02  -5.82885742e-02  -2.50854492e-02  -3.34472656e-02
    8.61358643e-03  -1.59301758e-02  -4.27627563e-03   4.85839844e-02
   -9.47570801e-03  -3.30505371e-02   3.70483398e-02   7.56263733e-04
    2.97427177e-05  -1.84936523e-02   6.51359558e-04   1.51062012e-02
    2.32696533e-02  -7.39288330e-03  -5.74340820e-02   5.25512695e-02
    2.87475586e-02   3.71093750e-02  -3.28369141e-02   2.32238770e-02
   -4.65698242e-02   8.81195068e-03  -6.34155273e-02   5.57556152e-02
    1.08642578e-02  -1.40991211e-02   9.63592529e-03  -3.83300781e-02
   -1.66320801e-02  -3.12805176e-02  -2.22320557e-02  -5.29479980e-02
    6.29425049e-04   9.17968750e-02   8.39233398e-02   3.61938477e-02
    2.71911621e-02  -2.75878906e-02  -1.73034668e-02  -1.24359131e-02]]
After layer encoder_birnn_reverse_l0_t4_i_output (1, 256) <class 'numpy.float16'> [[ 0.49853516  0.49609375  0.49829102  0.49487305  0.51318359  0.49804688
   0.50927734  0.50585938  0.52294922  0.51367188  0.49072266  0.51904297
   0.50488281  0.51025391  0.49975586  0.56396484  0.47729492  0.48461914
   0.50341797  0.49707031  0.52099609  0.50634766  0.4777832   0.49023438
   0.52099609  0.47045898  0.4921875   0.49536133  0.50732422  0.49584961
   0.50048828  0.49536133  0.48950195  0.48852539  0.51708984  0.46923828
   0.49780273  0.49853516  0.48193359  0.48681641  0.47680664  0.50830078
   0.48657227  0.50048828  0.50878906  0.49780273  0.51611328  0.48120117
   0.49633789  0.50488281  0.5         0.52392578  0.48217773  0.51708984
   0.54638672  0.52441406  0.48632812  0.50292969  0.48535156  0.49414062
   0.51757812  0.48925781  0.53857422  0.4934082   0.47241211  0.48974609
   0.52392578  0.49560547  0.48510742  0.50439453  0.52392578  0.49414062
   0.5         0.49829102  0.49902344  0.51708984  0.53076172  0.53515625
   0.50292969  0.51074219  0.50634766  0.51123047  0.52148438  0.49560547
   0.54003906  0.51464844  0.49316406  0.49023438  0.49316406  0.5234375
   0.52929688  0.49511719  0.47998047  0.52246094  0.51855469  0.51074219
   0.49414062  0.52246094  0.47827148  0.47338867  0.48193359  0.51904297
   0.49951172  0.46679688  0.48388672  0.50195312  0.49462891  0.47241211
   0.51318359  0.51269531  0.4699707   0.50732422  0.50439453  0.54492188
   0.50048828  0.57128906  0.49121094  0.50195312  0.50976562  0.49023438
   0.55126953  0.4699707   0.50097656  0.52294922  0.48706055  0.51318359
   0.47119141  0.51708984  0.49584961  0.50097656  0.54492188  0.51611328
   0.4987793   0.49145508  0.48364258  0.48535156  0.5234375   0.53710938
   0.5         0.49560547  0.49047852  0.47631836  0.51855469  0.51660156
   0.49169922  0.49902344  0.5078125   0.51464844  0.49560547  0.51416016
   0.52734375  0.48754883  0.50048828  0.4765625   0.4831543   0.546875
   0.50830078  0.51611328  0.49609375  0.49194336  0.54736328  0.50244141
   0.48828125  0.50878906  0.50390625  0.484375    0.50292969  0.48901367
   0.51269531  0.49023438  0.50341797  0.50976562  0.50146484  0.52441406
   0.50732422  0.46972656  0.50878906  0.47167969  0.48779297  0.49414062
   0.50878906  0.48413086  0.49560547  0.5078125   0.5234375   0.49389648
   0.49658203  0.48510742  0.52929688  0.51513672  0.49389648  0.49609375
   0.51123047  0.49389648  0.515625    0.51806641  0.52001953  0.46142578
   0.51074219  0.51464844  0.50048828  0.53271484  0.51611328  0.50927734
   0.50732422  0.49584961  0.50048828  0.48754883  0.48608398  0.51171875
   0.51025391  0.52392578  0.50537109  0.51513672  0.50292969  0.50927734
   0.49853516  0.49438477  0.50439453  0.50097656  0.48681641  0.48730469
   0.51757812  0.48193359  0.50341797  0.515625    0.49462891  0.4777832
   0.484375    0.53515625  0.49731445  0.47802734  0.49511719  0.48974609
   0.50830078  0.515625    0.49829102  0.51904297  0.5078125   0.48876953
   0.48095703  0.47094727  0.52587891  0.55810547  0.48730469  0.50683594
   0.49023438  0.48388672  0.50439453  0.50390625  0.53369141  0.50146484
   0.47851562  0.51220703  0.51220703  0.49511719]]
After layer encoder_birnn_reverse_l0_t4_c_output (1, 256) <class 'numpy.float16'> [[-0.15283203 -0.13842773 -0.01786804  0.0406189   0.03833008 -0.06100464
   0.03424072  0.08599854  0.06396484 -0.10571289 -0.07910156  0.14086914
   0.08874512 -0.02644348  0.0647583  -0.22875977  0.07110596  0.02781677
   0.08807373  0.052948    0.20629883 -0.05889893 -0.00564575  0.06030273
  -0.11669922  0.0357666   0.0592041  -0.05328369 -0.14282227 -0.11303711
   0.04244995 -0.12341309 -0.01165771  0.01037598  0.11785889 -0.15344238
  -0.06408691 -0.00450897 -0.12481689 -0.1060791   0.02514648 -0.19775391
   0.12805176  0.09240723  0.09112549 -0.1126709   0.04025269 -0.07196045
  -0.01378632 -0.1003418   0.0723877  -0.12512207 -0.08227539  0.14526367
   0.02958679  0.02400208 -0.03001404  0.19067383  0.10473633 -0.04751587
  -0.09667969 -0.10107422 -0.02304077 -0.02050781  0.06860352 -0.03646851
   0.03283691 -0.11175537 -0.10961914 -0.00857544 -0.25927734  0.01521301
   0.05267334  0.02742004  0.13305664 -0.03543091 -0.04525757 -0.19824219
  -0.06872559 -0.04205322 -0.121521    0.01960754 -0.0914917  -0.17150879
  -0.2565918   0.01028442 -0.12384033  0.02642822 -0.18896484 -0.11981201
  -0.11883545 -0.06155396 -0.0304718  -0.00648499 -0.05136108  0.05172729
   0.09613037 -0.04669189 -0.10797119 -0.08947754  0.01977539  0.14343262
  -0.0703125   0.04998779  0.06292725  0.16491699 -0.04623413 -0.04788208
   0.16162109 -0.19616699  0.10473633 -0.0042572   0.08105469  0.10217285
  -0.09210205  0.26635742 -0.16455078 -0.08538818  0.04129028 -0.07067871
   0.16748047  0.0715332  -0.01837158 -0.09759521  0.10858154 -0.18273926
  -0.11871338 -0.07702637 -0.04934692 -0.02807617  0.08978271 -0.03186035
   0.0791626   0.0085144   0.00169373  0.07421875  0.08526611  0.21862793
  -0.00377655  0.0647583  -0.00354004 -0.04763794  0.140625    0.02532959
  -0.09155273  0.10131836  0.07281494 -0.11175537 -0.10003662 -0.13366699
  -0.06155396 -0.02774048 -0.06744385 -0.08209229 -0.00857544  0.07617188
  -0.12524414  0.03527832  0.05465698  0.07226562 -0.22265625 -0.06665039
   0.02713013  0.15869141  0.03585815  0.09991455  0.01664734 -0.04763794
  -0.20361328  0.01782227 -0.1027832   0.0536499  -0.03842163 -0.14978027
  -0.02827454  0.07885742  0.1541748  -0.05172729 -0.05859375 -0.02854919
   0.0725708   0.01519775  0.04263306 -0.03808594 -0.06842041  0.05853271
   0.05026245 -0.10882568  0.09454346 -0.13513184  0.20703125 -0.01696777
  -0.00722504  0.02970886 -0.2199707  -0.00500488 -0.22558594 -0.10003662
  -0.03872681  0.07141113 -0.16662598 -0.03979492  0.18127441 -0.05981445
  -0.02078247 -0.03056335  0.07635498  0.01396179  0.13049316 -0.08081055
  -0.17346191 -0.00036621  0.03010559 -0.1875     -0.06390381 -0.09020996
   0.03381348 -0.04171753 -0.04058838  0.12512207 -0.03585815 -0.0892334
   0.08123779  0.02630615  0.0123291  -0.05926514  0.00856018  0.0345459
   0.02986145 -0.0020237  -0.1484375   0.17663574  0.04211426  0.09204102
  -0.06951904  0.03289795 -0.09771729  0.02133179 -0.19616699  0.12866211
   0.01277161 -0.01121521  0.02828979 -0.05032349 -0.03781128 -0.06286621
  -0.0617981  -0.18164062  0.02105713  0.23095703  0.21179199  0.10992432
   0.04522705 -0.07910156 -0.05462646 -0.00811768]]
After layer _mul2081_0 (1, 256) <class 'numpy.float16'> [[-0.07617188 -0.06866455 -0.0089035   0.02009583  0.01966858 -0.03038025
   0.0174408   0.04351807  0.03344727 -0.05429077 -0.03881836  0.07312012
   0.0447998  -0.0134964   0.03234863 -0.12902832  0.03393555  0.01348114
   0.04434204  0.02632141  0.10748291 -0.02983093 -0.00269699  0.02955627
  -0.06079102  0.01683044  0.02914429 -0.02639771 -0.07244873 -0.05606079
   0.02124023 -0.06112671 -0.00570679  0.00506973  0.0609436  -0.07202148
  -0.03189087 -0.00224876 -0.06015015 -0.05163574  0.01199341 -0.1005249
   0.06231689  0.04623413  0.0463562  -0.05609131  0.02078247 -0.03463745
  -0.00684357 -0.05065918  0.03619385 -0.06555176 -0.03967285  0.07513428
   0.01615906  0.0125885  -0.01459503  0.09588623  0.05084229 -0.02348328
  -0.05004883 -0.04943848 -0.0124054  -0.01011658  0.03240967 -0.01785278
   0.01719666 -0.0553894  -0.05319214 -0.00432587 -0.13586426  0.00751877
   0.02633667  0.01366425  0.06640625 -0.01832581 -0.02401733 -0.1060791
  -0.03457642 -0.02148438 -0.06152344  0.01002502 -0.04769897 -0.08502197
  -0.1385498   0.00529099 -0.06106567  0.01295471 -0.09320068 -0.06274414
  -0.06292725 -0.0304718  -0.01462555 -0.00338745 -0.02662659  0.02641296
   0.04751587 -0.0243988  -0.05163574 -0.0423584   0.00952911  0.07446289
  -0.03512573  0.02333069  0.03045654  0.08276367 -0.02287292 -0.02261353
   0.08294678 -0.10058594  0.04922485 -0.00215912  0.04089355  0.05566406
  -0.04608154  0.15222168 -0.08081055 -0.04284668  0.02104187 -0.03463745
   0.09234619  0.03363037 -0.00920105 -0.05102539  0.05288696 -0.09375
  -0.05593872 -0.03982544 -0.0244751  -0.0140686   0.04891968 -0.01644897
   0.03948975  0.00418472  0.00081921  0.03601074  0.0446167   0.11743164
  -0.00188828  0.03210449 -0.00173664 -0.02268982  0.07293701  0.01308441
  -0.04501343  0.05056763  0.0369873  -0.05752563 -0.04959106 -0.06872559
  -0.0324707  -0.01352692 -0.03375244 -0.03912354 -0.00414276  0.04165649
  -0.06365967  0.01820374  0.02711487  0.03555298 -0.12188721 -0.03347778
   0.01324463  0.08074951  0.01806641  0.04840088  0.00836945 -0.02330017
  -0.10437012  0.00873566 -0.05175781  0.02734375 -0.01927185 -0.07855225
  -0.01434326  0.03704834  0.07843018 -0.0243988  -0.02857971 -0.01410675
   0.03692627  0.00735855  0.02113342 -0.01934814 -0.03582764  0.02891541
   0.02496338 -0.05279541  0.05004883 -0.06964111  0.10223389 -0.00841522
  -0.00369453  0.01467133 -0.11340332 -0.00259209 -0.11730957 -0.0461731
  -0.01977539  0.03674316 -0.08337402 -0.02119446  0.09356689 -0.03045654
  -0.01054382 -0.01515198  0.03820801  0.00680542  0.06341553 -0.04135132
  -0.08850098 -0.00019193  0.01521301 -0.09655762 -0.03213501 -0.04592896
   0.01686096 -0.02062988 -0.02047729  0.06268311 -0.01745605 -0.04348755
   0.04205322  0.01268005  0.00620651 -0.03056335  0.00423431  0.01651001
   0.01446533 -0.00108337 -0.0737915   0.08441162  0.02085876  0.04507446
  -0.03533936  0.01696777 -0.04870605  0.01107025 -0.09960938  0.06286621
   0.00614166 -0.00528336  0.01487732 -0.02809143 -0.01843262 -0.03186035
  -0.0302887  -0.08789062  0.01062012  0.11639404  0.11303711  0.05511475
   0.02163696 -0.04052734 -0.02798462 -0.00402069]]
After layer encoder_birnn_reverse_l0_t4_state_0 (1, 256) <class 'numpy.float16'> [[-0.13830566 -0.12011719 -0.00590134  0.03662109  0.04281616 -0.05419922
   0.03912354  0.07989502  0.04870605 -0.09533691 -0.07128906  0.12091064
   0.08837891 -0.03335571  0.06433105 -0.22705078  0.04989624  0.01693726
   0.07214355  0.04974365  0.19189453 -0.05108643  0.00208664  0.06243896
  -0.10388184  0.03097534  0.04260254 -0.03991699 -0.12988281 -0.09533691
   0.0380249  -0.11694336 -0.01029205  0.00259781  0.10583496 -0.12780762
  -0.06185913 -0.01238251 -0.10668945 -0.08673096  0.0322876  -0.17041016
   0.11132812  0.08416748  0.08660889 -0.10559082  0.0411377  -0.06195068
  -0.01091003 -0.08239746  0.05419922 -0.11401367 -0.07189941  0.11932373
   0.04299927  0.02255249 -0.03848267  0.17431641  0.08288574 -0.04846191
  -0.08361816 -0.09002686 -0.02984619 -0.01527405  0.0670166  -0.03540039
   0.04656982 -0.08361816 -0.09863281 -0.01754761 -0.23999023  0.01248169
   0.05233765  0.0223999   0.12371826 -0.04425049 -0.04452515 -0.17480469
  -0.06115723 -0.037323   -0.10858154  0.01281738 -0.0791626  -0.1496582
  -0.24731445  0.01716614 -0.12145996  0.03411865 -0.15356445 -0.10852051
  -0.10253906 -0.052948   -0.02337646 -0.01605225 -0.04446411  0.04022217
   0.08642578 -0.04547119 -0.08837891 -0.06549072  0.02810669  0.12902832
  -0.06860352  0.04278564  0.04711914  0.12915039 -0.0413208  -0.04241943
   0.14465332 -0.16430664  0.08215332  0.00800323  0.06445312  0.09240723
  -0.0892334   0.26660156 -0.13793945 -0.07269287  0.04345703 -0.05081177
   0.15966797  0.078125   -0.0206604  -0.08752441  0.09820557 -0.16650391
  -0.08666992 -0.0690918  -0.03967285 -0.01596069  0.0847168  -0.03985596
   0.07281494 -0.00677109  0.00673676  0.06658936  0.09106445  0.2019043
  -0.00650787  0.06274414 -0.00842285 -0.04660034  0.12927246  0.01794434
  -0.08630371  0.08984375  0.06494141 -0.1114502  -0.08563232 -0.10742188
  -0.05996704 -0.02664185 -0.05371094 -0.07739258 -0.00852203  0.07281494
  -0.1116333   0.04290771  0.05029297  0.06561279 -0.22167969 -0.06994629
   0.02453613  0.14111328  0.02807617  0.08789062  0.01374817 -0.05651855
  -0.17456055  0.00856018 -0.09094238  0.04562378 -0.03201294 -0.14453125
  -0.02125549  0.06512451  0.14819336 -0.04681396 -0.06115723 -0.03320312
   0.07250977  0.01011658  0.0380249  -0.03231812 -0.05053711  0.04846191
   0.04174805 -0.1048584   0.09509277 -0.11828613  0.17553711 -0.00962067
  -0.00192833  0.01651001 -0.18725586 -0.00157833 -0.19897461 -0.08605957
  -0.02737427  0.06109619 -0.14196777 -0.03164673  0.171875   -0.0562439
  -0.01151276 -0.02229309  0.06036377  0.00862122  0.11206055 -0.08581543
  -0.15002441  0.007267    0.02786255 -0.15478516 -0.05722046 -0.0793457
   0.02548218 -0.03656006 -0.02474976  0.11126709 -0.02693176 -0.07653809
   0.07910156  0.01343536  0.00623703 -0.04907227  0.00488663  0.03161621
   0.03771973 -0.00847626 -0.13122559  0.13696289  0.04962158  0.08215332
  -0.06817627  0.04019165 -0.09527588  0.0198822  -0.16308594  0.11865234
   0.01699829 -0.01937866  0.02450562 -0.06640625 -0.0350647  -0.06311035
  -0.05252075 -0.14086914  0.01124573  0.20825195  0.19702148  0.09130859
   0.04882812 -0.06811523 -0.04528809 -0.01644897]]
After layer activation1040_output (1, 256) <class 'numpy.float16'> [[-0.13745117 -0.11956787 -0.00590134  0.03659058  0.04278564 -0.05413818
   0.03909302  0.07971191  0.04867554 -0.09503174 -0.07116699  0.12030029
   0.08813477 -0.03335571  0.06427002 -0.2232666   0.04986572  0.01693726
   0.07202148  0.04971313  0.1895752  -0.05105591  0.00208664  0.06234741
  -0.10351562  0.03096008  0.04257202 -0.03988647 -0.12915039 -0.09503174
   0.03799438 -0.11639404 -0.01029205  0.00259781  0.10546875 -0.1270752
  -0.06176758 -0.01238251 -0.10626221 -0.08648682  0.0322876  -0.16882324
   0.11090088  0.08398438  0.08636475 -0.10522461  0.04110718 -0.06185913
  -0.01091003 -0.08221436  0.05413818 -0.11352539 -0.07177734  0.11877441
   0.04296875  0.02255249 -0.03845215  0.17260742  0.08270264 -0.0484314
  -0.08343506 -0.08978271 -0.02983093 -0.01527405  0.06689453 -0.03540039
   0.04653931 -0.08343506 -0.09832764 -0.01754761 -0.23547363  0.01248169
   0.05227661  0.0223999   0.12310791 -0.04421997 -0.04449463 -0.1730957
  -0.06109619 -0.03729248 -0.1081543   0.01281738 -0.07897949 -0.14855957
  -0.24243164  0.01716614 -0.12084961  0.03411865 -0.15234375 -0.10809326
  -0.10217285 -0.05288696 -0.02337646 -0.01605225 -0.04443359  0.04019165
   0.08618164 -0.04544067 -0.08813477 -0.06536865  0.02810669  0.1282959
  -0.06848145  0.04275513  0.04708862  0.12841797 -0.04129028 -0.04238892
   0.14367676 -0.1628418   0.08197021  0.00800323  0.06439209  0.09216309
  -0.08898926  0.26049805 -0.13708496 -0.0725708   0.04342651 -0.05078125
   0.1583252   0.07794189 -0.0206604  -0.08728027  0.09790039 -0.16503906
  -0.08642578 -0.06896973 -0.03964233 -0.01596069  0.08453369 -0.03982544
   0.07269287 -0.00677109  0.00673676  0.06646729  0.09082031  0.19921875
  -0.00650787  0.06268311 -0.00842285 -0.04656982  0.12854004  0.01794434
  -0.08605957  0.08959961  0.06488037 -0.11096191 -0.08544922 -0.10699463
  -0.05990601 -0.02664185 -0.0536499  -0.07720947 -0.00852203  0.07269287
  -0.11114502  0.0428772   0.05026245  0.06549072 -0.21813965 -0.06982422
   0.02453613  0.14013672  0.02807617  0.08764648  0.01374817 -0.05645752
  -0.17285156  0.00856018 -0.09069824  0.04559326 -0.03201294 -0.14355469
  -0.02125549  0.06500244  0.14709473 -0.04678345 -0.06109619 -0.03320312
   0.0723877   0.01011658  0.03799438 -0.03231812 -0.05050659  0.0484314
   0.04171753 -0.10449219  0.0947876  -0.11773682  0.17370605 -0.00962067
  -0.00192833  0.01651001 -0.18505859 -0.00157833 -0.19641113 -0.08587646
  -0.02737427  0.06103516 -0.14099121 -0.03164673  0.17016602 -0.05618286
  -0.01151276 -0.02229309  0.06030273  0.00862122  0.11157227 -0.08563232
  -0.14892578  0.007267    0.02786255 -0.15356445 -0.05715942 -0.0791626
   0.02548218 -0.03652954 -0.02474976  0.11083984 -0.02693176 -0.07641602
   0.07891846  0.01343536  0.00623703 -0.04904175  0.00488663  0.03161621
   0.03768921 -0.00847626 -0.13049316  0.1361084   0.04959106  0.08197021
  -0.0680542   0.04016113 -0.0949707   0.0198822  -0.16162109  0.11810303
   0.01699829 -0.01937866  0.02450562 -0.06628418 -0.0350647  -0.06304932
  -0.05245972 -0.13989258  0.01124573  0.20532227  0.19445801  0.09106445
   0.04879761 -0.06799316 -0.04525757 -0.01644897]]
After layer encoder_birnn_reverse_l0_t4_out_0 (1, 256) <class 'numpy.float16'> [[-0.07080078 -0.06082153 -0.00292778  0.01882935  0.02194214 -0.02978516
   0.02055359  0.04238892  0.02861023 -0.05020142 -0.03482056  0.0619812
   0.04751587 -0.0164032   0.03277588 -0.11773682  0.02423096  0.00814819
   0.03649902  0.02459717  0.09313965 -0.02391052  0.00116825  0.03277588
  -0.05352783  0.01579285  0.02124023 -0.01989746 -0.06192017 -0.04794312
   0.02001953 -0.06109619 -0.00522614  0.00131512  0.05203247 -0.06246948
  -0.03240967 -0.00616074 -0.05526733 -0.04315186  0.01681519 -0.08319092
   0.05545044  0.04202271  0.04257202 -0.05328369  0.02075195 -0.02999878
  -0.00553894 -0.04312134  0.02822876 -0.05575562 -0.03546143  0.06100464
   0.02334595  0.01064301 -0.02053833  0.08703613  0.04193115 -0.02287292
  -0.04272461 -0.04620361 -0.01513672 -0.00821686  0.03329468 -0.01716614
   0.02539062 -0.04290771 -0.04968262 -0.00917053 -0.11877441  0.00637054
   0.02629089  0.01110077  0.0645752  -0.02444458 -0.02374268 -0.08837891
  -0.03222656 -0.02052307 -0.05841064  0.00701523 -0.04122925 -0.07861328
  -0.13000488  0.00882721 -0.06130981  0.01799011 -0.07891846 -0.05630493
  -0.05487061 -0.02590942 -0.01117706 -0.00814056 -0.02284241  0.02044678
   0.04455566 -0.02409363 -0.04110718 -0.03117371  0.0138855   0.05984497
  -0.03314209  0.02055359  0.02349854  0.0645752  -0.02027893 -0.02249146
   0.07373047 -0.0880127   0.0411377   0.00411224  0.03096008  0.04904175
  -0.0447998   0.13964844 -0.06567383 -0.03588867  0.02259827 -0.02462769
   0.08026123  0.04067993 -0.01080322 -0.04382324  0.0479126  -0.0838623
  -0.04284668 -0.03430176 -0.01954651 -0.00767899  0.04260254 -0.02174377
   0.03610229 -0.00354385  0.00343323  0.03216553  0.04815674  0.1026001
  -0.00343895  0.03173828 -0.00423431 -0.02328491  0.06152344  0.00925446
  -0.04315186  0.0453186   0.03466797 -0.05682373 -0.04354858 -0.0531311
  -0.02960205 -0.01312256 -0.02761841 -0.0411377  -0.00429916  0.03787231
  -0.05780029  0.0227356   0.02566528  0.03482056 -0.11303711 -0.03536987
   0.012146    0.07495117  0.01461029  0.0423584   0.00769424 -0.02966309
  -0.08172607  0.00432968 -0.04330444  0.02388    -0.01664734 -0.07843018
  -0.01079559  0.03509521  0.07885742 -0.02282715 -0.03192139 -0.01651001
   0.03436279  0.00491333  0.01939392 -0.01573181 -0.0247345   0.02549744
   0.02064514 -0.05474854  0.04772949 -0.05651855  0.0880127  -0.0051384
  -0.00098801  0.00828552 -0.0947876  -0.00081205 -0.09698486 -0.0440979
  -0.01438141  0.03060913 -0.07299805 -0.01753235  0.08880615 -0.03005981
  -0.00600433 -0.01165009  0.02914429  0.00439072  0.05352783 -0.0461731
  -0.07409668  0.00415802  0.01422882 -0.08227539 -0.02986145 -0.03878784
   0.01313782 -0.01982117 -0.01216888  0.05401611 -0.01315308 -0.03613281
   0.04214478  0.00680161  0.00322533 -0.02571106  0.00245857  0.01600647
   0.02153015 -0.00465012 -0.06585693  0.06420898  0.02450562  0.04101562
  -0.03369141  0.02027893 -0.04666138  0.01029968 -0.08508301  0.05984497
   0.00810242 -0.01008606  0.01296234 -0.03839111 -0.01657104 -0.03244019
  -0.02682495 -0.0657959   0.00571442  0.10253906  0.10186768  0.04382324
   0.02554321 -0.03625488 -0.02252197 -0.00850677]]
After layer expand_dims1046_0 (1, 1, 256) <class 'numpy.float16'> [[[-0.07080078 -0.06082153 -0.00292778  0.01882935  0.02194214 -0.02978516
    0.02055359  0.04238892  0.02861023 -0.05020142 -0.03482056  0.0619812
    0.04751587 -0.0164032   0.03277588 -0.11773682  0.02423096  0.00814819
    0.03649902  0.02459717  0.09313965 -0.02391052  0.00116825  0.03277588
   -0.05352783  0.01579285  0.02124023 -0.01989746 -0.06192017 -0.04794312
    0.02001953 -0.06109619 -0.00522614  0.00131512  0.05203247 -0.06246948
   -0.03240967 -0.00616074 -0.05526733 -0.04315186  0.01681519 -0.08319092
    0.05545044  0.04202271  0.04257202 -0.05328369  0.02075195 -0.02999878
   -0.00553894 -0.04312134  0.02822876 -0.05575562 -0.03546143  0.06100464
    0.02334595  0.01064301 -0.02053833  0.08703613  0.04193115 -0.02287292
   -0.04272461 -0.04620361 -0.01513672 -0.00821686  0.03329468 -0.01716614
    0.02539062 -0.04290771 -0.04968262 -0.00917053 -0.11877441  0.00637054
    0.02629089  0.01110077  0.0645752  -0.02444458 -0.02374268 -0.08837891
   -0.03222656 -0.02052307 -0.05841064  0.00701523 -0.04122925 -0.07861328
   -0.13000488  0.00882721 -0.06130981  0.01799011 -0.07891846 -0.05630493
   -0.05487061 -0.02590942 -0.01117706 -0.00814056 -0.02284241  0.02044678
    0.04455566 -0.02409363 -0.04110718 -0.03117371  0.0138855   0.05984497
   -0.03314209  0.02055359  0.02349854  0.0645752  -0.02027893 -0.02249146
    0.07373047 -0.0880127   0.0411377   0.00411224  0.03096008  0.04904175
   -0.0447998   0.13964844 -0.06567383 -0.03588867  0.02259827 -0.02462769
    0.08026123  0.04067993 -0.01080322 -0.04382324  0.0479126  -0.0838623
   -0.04284668 -0.03430176 -0.01954651 -0.00767899  0.04260254 -0.02174377
    0.03610229 -0.00354385  0.00343323  0.03216553  0.04815674  0.1026001
   -0.00343895  0.03173828 -0.00423431 -0.02328491  0.06152344  0.00925446
   -0.04315186  0.0453186   0.03466797 -0.05682373 -0.04354858 -0.0531311
   -0.02960205 -0.01312256 -0.02761841 -0.0411377  -0.00429916  0.03787231
   -0.05780029  0.0227356   0.02566528  0.03482056 -0.11303711 -0.03536987
    0.012146    0.07495117  0.01461029  0.0423584   0.00769424 -0.02966309
   -0.08172607  0.00432968 -0.04330444  0.02388    -0.01664734 -0.07843018
   -0.01079559  0.03509521  0.07885742 -0.02282715 -0.03192139 -0.01651001
    0.03436279  0.00491333  0.01939392 -0.01573181 -0.0247345   0.02549744
    0.02064514 -0.05474854  0.04772949 -0.05651855  0.0880127  -0.0051384
   -0.00098801  0.00828552 -0.0947876  -0.00081205 -0.09698486 -0.0440979
   -0.01438141  0.03060913 -0.07299805 -0.01753235  0.08880615 -0.03005981
   -0.00600433 -0.01165009  0.02914429  0.00439072  0.05352783 -0.0461731
   -0.07409668  0.00415802  0.01422882 -0.08227539 -0.02986145 -0.03878784
    0.01313782 -0.01982117 -0.01216888  0.05401611 -0.01315308 -0.03613281
    0.04214478  0.00680161  0.00322533 -0.02571106  0.00245857  0.01600647
    0.02153015 -0.00465012 -0.06585693  0.06420898  0.02450562  0.04101562
   -0.03369141  0.02027893 -0.04666138  0.01029968 -0.08508301  0.05984497
    0.00810242 -0.01008606  0.01296234 -0.03839111 -0.01657104 -0.03244019
   -0.02682495 -0.0657959   0.00571442  0.10253906  0.10186768  0.04382324
    0.02554321 -0.03625488 -0.02252197 -0.00850677]]]
After layer encoder_birnn_reverse_l0_t5_i2h_output (1, 1024) <class 'numpy.float16'> [[-0.0128479  -0.04095459  0.03787231 ...,  0.06970215 -0.04626465
   0.03759766]]
After layer encoder_birnn_reverse_l0_t5_h2h_output (1, 1024) <class 'numpy.float16'> [[ 0.00193787  0.02038574 -0.05969238 ...,  0.06719971  0.03805542
   0.02572632]]
After layer _plus1041_0 (1, 1024) <class 'numpy.float16'> [[-0.01091003 -0.02056885 -0.02182007 ...,  0.13696289 -0.00820923
   0.06335449]]
After layer encoder_birnn_reverse_l0_t5_slice_output0 (1, 256) <class 'numpy.float16'> [[ -1.09100342e-02  -2.05688477e-02  -2.18200684e-02  -2.24456787e-02
    3.36303711e-02  -1.85546875e-02   2.25524902e-02   1.73950195e-02
    9.68017578e-02   6.11572266e-02  -3.97033691e-02   9.01489258e-02
    1.50909424e-02   3.07769775e-02  -1.52587891e-03   2.76855469e-01
   -1.09863281e-01  -7.26928711e-02   1.22451782e-02  -1.15051270e-02
    9.13085938e-02   1.46484375e-02  -1.06567383e-01  -4.36706543e-02
    7.65380859e-02  -1.24816895e-01  -3.38134766e-02  -1.62353516e-02
    1.78527832e-02  -2.02331543e-02  -1.60217285e-04  -1.41906738e-02
   -4.93469238e-02  -4.51354980e-02   7.37304688e-02  -1.39892578e-01
   -1.33056641e-02  -9.36126709e-03  -7.93457031e-02  -6.41479492e-02
   -1.18591309e-01   2.75573730e-02  -5.27648926e-02   1.28173828e-03
    3.31726074e-02  -1.35726929e-02   6.56738281e-02  -7.98339844e-02
   -2.81066895e-02   2.51770020e-02   1.22070312e-02   1.02355957e-01
   -1.10229492e-01   7.26318359e-02   1.79199219e-01   1.07666016e-01
   -6.40869141e-02   1.39617920e-02  -7.12890625e-02  -2.12554932e-02
    7.73315430e-02  -5.00793457e-02   1.57470703e-01  -2.79083252e-02
   -1.13769531e-01  -4.15344238e-02   1.02172852e-01  -2.14691162e-02
   -7.59277344e-02   8.85009766e-03   1.00341797e-01  -2.21099854e-02
   -7.08007812e-03  -1.58691406e-02   5.88989258e-03   6.24389648e-02
    1.22131348e-01   1.54663086e-01   2.37121582e-02   4.86450195e-02
    2.42004395e-02   4.66613770e-02   8.64257812e-02  -2.07214355e-02
    1.64550781e-01   5.05065918e-02  -2.71301270e-02  -5.80444336e-02
   -2.26135254e-02   7.43408203e-02   1.13769531e-01  -1.23596191e-02
   -8.30078125e-02   8.41064453e-02   7.22045898e-02   3.87573242e-02
   -2.72369385e-02   6.64672852e-02  -9.97924805e-02  -1.18408203e-01
   -9.38720703e-02   7.75146484e-02   7.75146484e-03  -1.26098633e-01
   -8.97216797e-02   8.77380371e-03  -2.58941650e-02  -1.10412598e-01
    6.03637695e-02   3.21044922e-02  -1.15051270e-01   1.50146484e-02
    2.48565674e-02   2.03613281e-01   7.75146484e-03   2.98828125e-01
   -3.55224609e-02   7.90405273e-03   1.69677734e-02  -4.59594727e-02
    2.09228516e-01  -1.25366211e-01   2.62451172e-03   9.50927734e-02
   -6.10351562e-02   5.88684082e-02  -1.27441406e-01   7.29370117e-02
   -2.28424072e-02   5.52368164e-03   2.00195312e-01   6.04858398e-02
   -7.81250000e-03  -4.25109863e-02  -7.46459961e-02  -8.05053711e-02
    1.03027344e-01   1.57104492e-01  -8.81958008e-03  -1.57165527e-02
   -4.02832031e-02  -1.11022949e-01   8.42895508e-02   6.19201660e-02
   -3.03192139e-02  -3.40270996e-03   3.30810547e-02   6.06689453e-02
   -1.50451660e-02   5.97534180e-02   1.17065430e-01  -5.89599609e-02
    8.54492188e-04  -9.46044922e-02  -8.41064453e-02   1.91894531e-01
    3.00903320e-02   4.33959961e-02  -1.97143555e-02  -3.26538086e-02
    2.08374023e-01   7.43103027e-03  -5.81359863e-02   2.76184082e-02
    1.04446411e-02  -7.06176758e-02   4.51660156e-03  -4.89501953e-02
    4.24194336e-02  -4.54101562e-02   2.83813477e-03   4.16564941e-02
    3.01361084e-03   1.02233887e-01   2.39410400e-02  -1.42822266e-01
    3.55834961e-02  -1.22375488e-01  -5.47485352e-02  -2.37579346e-02
    4.36401367e-02  -6.92138672e-02  -1.05895996e-02   2.73742676e-02
    9.64355469e-02  -2.10571289e-02  -1.59454346e-02  -5.94787598e-02
    1.07299805e-01   4.85839844e-02  -3.46374512e-02  -2.97241211e-02
    4.12597656e-02  -3.99780273e-02   1.93481445e-02   8.20922852e-02
    9.08813477e-02  -1.65527344e-01   4.27856445e-02   7.24487305e-02
    5.37109375e-03   1.15783691e-01   7.02514648e-02   5.01708984e-02
    2.15759277e-02  -2.59399414e-02  -3.39508057e-03  -5.28869629e-02
   -6.59179688e-02   4.50439453e-02   4.47998047e-02   1.07177734e-01
    2.05383301e-02   5.56640625e-02   3.54003906e-03   1.91650391e-02
   -6.97326660e-03  -2.22778320e-02   2.43530273e-02   3.89099121e-04
   -5.82885742e-02  -7.56835938e-02   8.47778320e-02  -7.42797852e-02
    9.12475586e-03   6.22558594e-02  -2.60314941e-02  -9.69238281e-02
   -8.62426758e-02   1.19873047e-01  -1.09405518e-02  -1.13342285e-01
   -2.09350586e-02  -4.86145020e-02   3.02429199e-02   6.10656738e-02
   -6.11114502e-03   8.04443359e-02   3.02734375e-02  -4.18090820e-02
   -9.64355469e-02  -1.32080078e-01   9.70458984e-02   2.35961914e-01
   -5.75866699e-02   2.22625732e-02  -7.10449219e-02  -7.17773438e-02
    1.61132812e-02   2.51770020e-03   1.48803711e-01  -3.75366211e-03
   -1.00524902e-01   4.90722656e-02   5.30395508e-02  -1.31988525e-02]]
After layer encoder_birnn_reverse_l0_t5_slice_output1 (1, 256) <class 'numpy.float16'> [[ 0.1472168   0.02975464  0.09863281  0.046875    0.01370239  0.07635498
   0.17932129 -0.09515381  0.35546875  0.15124512  0.11968994  0.1204834
   0.11096191  0.0004425   0.11755371  0.12695312  0.08660889 -0.04174805
  -0.14465332  0.06445312  0.12792969  0.01260376  0.35864258  0.05474854
   0.11901855  0.07147217  0.14294434  0.08746338  0.11437988  0.03787231
   0.0725708   0.02542114  0.22753906 -0.05749512 -0.01333618 -0.01190186
  -0.05700684  0.11566162  0.02264404  0.09118652 -0.05377197  0.1050415
   0.014328    0.09191895  0.03256226  0.11102295  0.03292847 -0.11199951
  -0.00395203  0.0271759   0.0668335   0.08813477 -0.01086426  0.14038086
   0.06506348  0.05975342  0.04632568  0.0947876   0.00272369 -0.08984375
   0.0769043   0.03790283  0.05886841  0.03417969 -0.02081299  0.13891602
   0.20251465  0.06604004 -0.12695312 -0.03289795  0.06567383 -0.00543213
  -0.04125977  0.03442383  0.10028076  0.17236328  0.05981445  0.05187988
   0.08691406  0.08099365  0.21459961  0.17089844  0.03781128  0.03494263
   0.16552734 -0.00152588  0.0802002   0.1739502   0.03503418 -0.14111328
   0.30078125  0.08795166  0.07885742  0.07128906 -0.05722046  0.01699829
   0.00640869  0.07965088 -0.16052246 -0.16784668 -0.06063843  0.00091553
   0.03646851  0.10083008 -0.00758362 -0.02883911 -0.10247803  0.06695557
   0.07995605 -0.10137939  0.02258301 -0.02320862  0.05221558  0.18725586
   0.09545898  0.18945312  0.10388184  0.12683105  0.07092285  0.10858154
   0.18945312  0.16296387  0.04034424  0.01779175 -0.01660156 -0.00872803
   0.17211914 -0.00602722  0.10345459 -0.1026001   0.11425781  0.13012695
   0.01341248  0.16015625  0.06323242  0.05810547  0.02218628  0.05001831
   0.12524414  0.19494629 -0.07531738  0.05459595  0.06872559  0.02912903
   0.03686523  0.12988281  0.07672119  0.0411377   0.04797363 -0.02276611
  -0.02792358  0.07006836  0.03363037  0.0881958   0.00701904  0.18115234
   0.09631348 -0.02783203  0.04974365  0.14453125  0.21923828  0.08288574
  -0.03295898  0.0871582   0.07550049 -0.01113892  0.26416016 -0.03479004
  -0.00549316 -0.02658081  0.03048706  0.12390137 -0.02954102  0.20239258
  -0.05010986  0.11383057  0.16333008 -0.01535034  0.01452637  0.11157227
   0.0803833  -0.07208252  0.22937012 -0.03887939  0.00154114  0.01556396
   0.0355835   0.18908691 -0.01550293 -0.05859375 -0.03430176  0.03366089
   0.17285156  0.14831543 -0.07574463  0.00238037 -0.00961304 -0.01391602
   0.02954102  0.01843262  0.0425415   0.05377197  0.07434082 -0.03158569
   0.10540771 -0.1340332  -0.03912354  0.15246582 -0.06237793  0.09759521
   0.078125    0.10534668 -0.05056763  0.02615356 -0.01629639 -0.0859375
   0.05880737  0.09442139 -0.01942444  0.11413574 -0.09539795 -0.06445312
   0.23950195  0.01631165  0.08746338 -0.00366211  0.01953125  0.04629517
   0.35522461  0.21337891  0.02697754 -0.27001953  0.14868164  0.03433228
   0.06246948 -0.00268555  0.00666809  0.08557129  0.04238892  0.09417725
   0.07299805  0.04138184  0.02093506  0.21691895 -0.1463623  -0.01968384
  -0.06048584 -0.05438232  0.10009766 -0.02301025  0.16015625 -0.16723633
   0.15087891 -0.01367188  0.13293457  0.00183105]]
After layer encoder_birnn_reverse_l0_t5_slice_output2 (1, 256) <class 'numpy.float16'> [[ -1.60400391e-01  -1.45141602e-01  -2.81219482e-02   4.94689941e-02
    2.99377441e-02  -6.25610352e-02   2.28881836e-02   7.76367188e-02
    7.53173828e-02  -1.30126953e-01  -8.50830078e-02   1.67968750e-01
    9.58251953e-02  -2.05993652e-02   7.31201172e-02  -2.54882812e-01
    8.31298828e-02   3.06854248e-02   9.92431641e-02   5.69458008e-02
    2.35229492e-01  -7.07397461e-02  -1.60217285e-02   4.96215820e-02
   -1.25732422e-01   3.49731445e-02   5.67016602e-02  -5.78002930e-02
   -1.53076172e-01  -1.25244141e-01   4.69360352e-02  -1.21215820e-01
   -2.80761719e-03   6.98852539e-03   1.27929688e-01  -1.63085938e-01
   -6.13098145e-02   1.46102905e-03  -1.27197266e-01  -1.13952637e-01
    2.16064453e-02  -2.14111328e-01   1.34765625e-01   1.02050781e-01
    9.68627930e-02  -1.22436523e-01   5.03540039e-02  -7.14111328e-02
   -1.69982910e-02  -1.10229492e-01   7.51953125e-02  -1.40380859e-01
   -8.17260742e-02   1.78100586e-01   1.43432617e-02   1.79748535e-02
   -2.16217041e-02   2.13745117e-01   1.23535156e-01  -4.91333008e-02
   -1.16577148e-01  -1.02539062e-01  -1.88293457e-02  -2.90527344e-02
    7.90405273e-02  -4.09545898e-02   3.17077637e-02  -1.19873047e-01
   -1.08215332e-01   1.92260742e-03  -2.90283203e-01   2.70843506e-02
    4.21752930e-02   2.48565674e-02   1.44042969e-01  -2.64434814e-02
   -6.09130859e-02  -2.28881836e-01  -8.17260742e-02  -4.88586426e-02
   -1.38671875e-01   1.26647949e-02  -1.03027344e-01  -1.90551758e-01
   -2.91259766e-01   7.20214844e-03  -1.07849121e-01   1.64489746e-02
   -2.13134766e-01  -1.15966797e-01  -1.28662109e-01  -6.10656738e-02
   -3.18603516e-02   1.14822388e-03  -5.55419922e-02   6.01196289e-02
    9.69238281e-02  -4.93469238e-02  -1.06933594e-01  -1.06811523e-01
    1.43432617e-02   1.54296875e-01  -7.45849609e-02   5.69763184e-02
    6.84814453e-02   1.91894531e-01  -4.69360352e-02  -4.26940918e-02
    1.76513672e-01  -2.13867188e-01   1.25854492e-01  -1.36413574e-02
    9.89379883e-02   1.22436523e-01  -9.25292969e-02   2.98828125e-01
   -1.86401367e-01  -1.01257324e-01   3.55834961e-02  -7.56835938e-02
    1.87866211e-01   6.62231445e-02  -1.02996826e-02  -1.10473633e-01
    1.05468750e-01  -1.95068359e-01  -1.30126953e-01  -8.78906250e-02
   -5.17883301e-02  -2.56042480e-02   1.12365723e-01  -2.33154297e-02
    8.11767578e-02   1.13372803e-02   5.34057617e-04   7.76977539e-02
    8.19702148e-02   2.44140625e-01   6.10351562e-05   7.32421875e-02
   -1.64794922e-03  -4.71801758e-02   1.56982422e-01   2.68249512e-02
   -9.22241211e-02   1.13769531e-01   8.70361328e-02  -1.12182617e-01
   -1.04797363e-01  -1.47827148e-01  -7.06787109e-02  -2.84118652e-02
   -8.47778320e-02  -7.81860352e-02  -3.90625000e-03   8.76464844e-02
   -1.38671875e-01   1.89819336e-02   5.64270020e-02   8.25195312e-02
   -2.60009766e-01  -6.26220703e-02   2.47497559e-02   1.63330078e-01
    3.98864746e-02   1.04003906e-01   1.40838623e-02  -4.04663086e-02
   -2.38281250e-01   1.54113770e-02  -1.16088867e-01   7.07397461e-02
   -3.79333496e-02  -1.61254883e-01  -3.54919434e-02   8.24584961e-02
    1.71997070e-01  -5.81359863e-02  -5.70678711e-02  -2.08435059e-02
    7.63549805e-02   2.19726562e-02   5.18798828e-02  -4.13208008e-02
   -7.78198242e-02   4.74853516e-02   5.61523438e-02  -1.20483398e-01
    8.79516602e-02  -1.37695312e-01   2.34863281e-01  -1.33666992e-02
   -1.61743164e-02   4.25109863e-02  -2.54638672e-01  -1.86157227e-03
   -2.50244141e-01  -1.09436035e-01  -3.75366211e-02   9.03320312e-02
   -1.86035156e-01  -5.22155762e-02   1.96899414e-01  -6.34765625e-02
   -2.08587646e-02  -3.68652344e-02   8.22753906e-02   1.53350830e-02
    1.47216797e-01  -7.74536133e-02  -1.90307617e-01   6.10351562e-05
    3.67736816e-02  -2.12280273e-01  -7.44018555e-02  -1.00463867e-01
    4.09545898e-02  -4.76684570e-02  -5.13916016e-02   1.41357422e-01
   -3.17077637e-02  -8.67919922e-02   9.70458984e-02   3.21960449e-02
    1.98669434e-02  -6.57348633e-02   1.07421875e-02   3.53698730e-02
    1.52893066e-02   9.91821289e-03  -1.56005859e-01   1.83593750e-01
    3.61938477e-02   9.27734375e-02  -7.14111328e-02   2.75268555e-02
   -9.50927734e-02   2.84423828e-02  -2.30834961e-01   1.30371094e-01
    2.50244141e-03  -4.25720215e-03   3.01513672e-02  -5.23681641e-02
   -3.79028320e-02  -5.51757812e-02  -6.66503906e-02  -2.00317383e-01
    2.77404785e-02   2.50000000e-01   2.51464844e-01   1.14562988e-01
    3.62548828e-02  -8.58154297e-02  -6.26220703e-02  -5.66101074e-03]]
After layer encoder_birnn_reverse_l0_t5_slice_output3 (1, 256) <class 'numpy.float16'> [[ 0.06427002  0.04611206 -0.01551819  0.06573486  0.04022217  0.20263672
   0.09838867  0.12298584  0.39038086  0.11877441 -0.05307007  0.0657959
   0.16271973 -0.03744507  0.04528809  0.11901855 -0.06054688 -0.08880615
   0.03381348 -0.01733398 -0.04129028 -0.13134766  0.26269531  0.10662842
   0.05804443  0.05523682 -0.01143646 -0.01207733 -0.09509277  0.01477051
   0.1116333   0.09973145  0.03253174  0.02915955 -0.02307129 -0.04437256
   0.10595703 -0.01043701  0.07287598 -0.01602173  0.07452393 -0.02841187
  -0.00175476  0.00357056 -0.03121948  0.03109741  0.02365112 -0.07159424
   0.02645874  0.11187744  0.08441162 -0.02313232 -0.059021    0.05505371
   0.16235352 -0.11138916  0.14648438  0.02209473  0.02941895 -0.11639404
   0.06152344  0.0725708   0.02700806  0.16308594 -0.00698853 -0.05908203
   0.19775391  0.05895996  0.00494385  0.07794189  0.01741028  0.03573608
   0.00527954 -0.01733398  0.11407471  0.20214844  0.14453125  0.04119873
   0.11938477  0.21008301  0.17114258  0.19836426  0.097229    0.11334229
   0.1583252   0.05352783  0.03277588  0.09606934  0.07800293  0.06451416
   0.15893555 -0.04501343 -0.09002686  0.02812195  0.04846191  0.03237915
   0.06268311  0.10229492 -0.1418457  -0.10827637 -0.04449463 -0.14282227
  -0.07623291 -0.08654785 -0.01702881  0.0087738  -0.03817749  0.12646484
   0.05770874  0.13989258  0.01068115  0.05648804 -0.0838623   0.13879395
   0.00476074  0.15161133 -0.07897949 -0.02505493  0.06134033 -0.056427
   0.02828979  0.09130859  0.08581543  0.00559998 -0.05303955  0.03436279
  -0.0110321  -0.00396729 -0.02252197 -0.09558105  0.01818848  0.18530273
  -0.020401    0.09869385  0.04489136 -0.07446289  0.12902832  0.05795288
   0.12121582  0.02973938  0.01577759 -0.00479126 -0.07781982  0.07202148
  -0.00321198  0.02587891  0.15380859  0.06396484  0.03591919 -0.01568604
  -0.02420044 -0.02993774  0.06951904  0.13330078 -0.0022583   0.07843018
   0.09460449  0.10626221  0.04150391  0.13464355  0.07861328  0.03030396
  -0.01196289  0.13879395  0.08209229 -0.07543945  0.26391602  0.10858154
  -0.12878418  0.02178955 -0.1038208   0.10791016  0.08551025  0.20092773
   0.01959229  0.17211914  0.15014648 -0.05953979  0.0802002  -0.01498413
  -0.11499023 -0.06958008  0.0461731  -0.07177734 -0.05368042  0.12878418
  -0.02282715  0.10406494 -0.01568604 -0.10266113  0.01873779  0.1418457
   0.05072021  0.01611328  0.00964355  0.06057739 -0.03062439  0.04919434
   0.11169434  0.01556396  0.07696533  0.21716309  0.09020996  0.14941406
   0.09051514  0.09240723 -0.07531738  0.04690552 -0.09619141  0.16625977
  -0.00366211  0.29833984  0.05639648  0.15258789  0.097229   -0.05157471
   0.05914307  0.18969727 -0.03417969 -0.0534668  -0.04138184 -0.13305664
   0.14990234  0.02891541  0.07055664  0.1003418   0.00357056  0.03591919
   0.31494141  0.18408203  0.01513672 -0.13769531 -0.02783203  0.00448608
  -0.02038574  0.02391052 -0.03253174  0.07641602  0.11096191  0.03427124
  -0.12469482  0.08398438  0.09429932  0.3203125  -0.12695312  0.05883789
   0.02276611 -0.13061523  0.03793335 -0.01350403  0.1048584  -0.08654785
   0.10339355  0.13696289 -0.00820923  0.06335449]]
After layer encoder_birnn_reverse_l0_t5_o_output (1, 256) <class 'numpy.float16'> [[ 0.51611328  0.51171875  0.49609375  0.51660156  0.51025391  0.55029297
   0.52441406  0.53076172  0.59619141  0.52978516  0.48681641  0.51660156
   0.54052734  0.49072266  0.51123047  0.52978516  0.48486328  0.4777832
   0.50830078  0.49560547  0.48974609  0.46728516  0.56542969  0.52685547
   0.51464844  0.51367188  0.49707031  0.49707031  0.47631836  0.50390625
   0.52783203  0.52490234  0.50830078  0.50732422  0.49414062  0.48901367
   0.52636719  0.49731445  0.51806641  0.49609375  0.51855469  0.49291992
   0.49951172  0.50097656  0.4921875   0.5078125   0.50585938  0.48217773
   0.50683594  0.52783203  0.52099609  0.49414062  0.48535156  0.51367188
   0.54052734  0.47216797  0.53662109  0.50537109  0.50732422  0.47094727
   0.51513672  0.51806641  0.50683594  0.54052734  0.49829102  0.48535156
   0.54931641  0.51464844  0.50146484  0.51953125  0.50439453  0.50878906
   0.50146484  0.49560547  0.52832031  0.55029297  0.53613281  0.51025391
   0.52978516  0.55224609  0.54248047  0.54931641  0.52441406  0.52832031
   0.53955078  0.51318359  0.50830078  0.52392578  0.51953125  0.51611328
   0.53955078  0.48876953  0.47753906  0.50683594  0.51220703  0.50830078
   0.515625    0.52539062  0.46459961  0.47290039  0.48876953  0.46435547
   0.48095703  0.47827148  0.49584961  0.50195312  0.49047852  0.53173828
   0.51464844  0.53515625  0.50244141  0.51416016  0.47900391  0.53466797
   0.50097656  0.53759766  0.48022461  0.49365234  0.51513672  0.48583984
   0.50683594  0.52294922  0.52148438  0.50146484  0.48681641  0.50878906
   0.49731445  0.49902344  0.49438477  0.47607422  0.50439453  0.54638672
   0.49487305  0.52441406  0.51123047  0.48144531  0.53222656  0.51464844
   0.53027344  0.50732422  0.50390625  0.4987793   0.48046875  0.51806641
   0.49926758  0.50634766  0.53857422  0.51611328  0.50878906  0.49609375
   0.49389648  0.49243164  0.51757812  0.53320312  0.49951172  0.51953125
   0.5234375   0.52636719  0.51025391  0.53369141  0.51953125  0.5078125
   0.49707031  0.53466797  0.52050781  0.48120117  0.56542969  0.52734375
   0.46777344  0.50537109  0.47412109  0.52685547  0.52148438  0.55029297
   0.50488281  0.54296875  0.53759766  0.48510742  0.52001953  0.49633789
   0.47119141  0.48266602  0.51171875  0.48217773  0.48657227  0.53222656
   0.49438477  0.52587891  0.49609375  0.47436523  0.50488281  0.53564453
   0.51269531  0.50390625  0.50244141  0.51513672  0.49243164  0.51220703
   0.52783203  0.50390625  0.51904297  0.55419922  0.52246094  0.53710938
   0.52246094  0.52294922  0.48120117  0.51171875  0.47607422  0.54150391
   0.49902344  0.57421875  0.51416016  0.53808594  0.52441406  0.48706055
   0.51464844  0.54736328  0.49145508  0.48657227  0.48974609  0.46679688
   0.53759766  0.50732422  0.51757812  0.52490234  0.50097656  0.50878906
   0.578125    0.54589844  0.50390625  0.46557617  0.49316406  0.50097656
   0.49487305  0.50585938  0.49194336  0.51904297  0.52783203  0.50878906
   0.46875     0.52099609  0.5234375   0.57958984  0.46826172  0.51464844
   0.50585938  0.46728516  0.50927734  0.49658203  0.52636719  0.47827148
   0.52587891  0.53417969  0.49804688  0.515625  ]]
After layer encoder_birnn_reverse_l0_t5_f_output (1, 256) <class 'numpy.float16'> [[ 0.53662109  0.50732422  0.52441406  0.51171875  0.50341797  0.51904297
   0.54492188  0.47631836  0.58789062  0.53759766  0.52978516  0.53027344
   0.52783203  0.5         0.52929688  0.53173828  0.52148438  0.48950195
   0.46386719  0.51611328  0.53173828  0.50292969  0.58886719  0.51367188
   0.52978516  0.51806641  0.53564453  0.52197266  0.52832031  0.50927734
   0.51806641  0.50634766  0.55664062  0.4855957   0.49658203  0.49707031
   0.48583984  0.52880859  0.50585938  0.52294922  0.48657227  0.52636719
   0.50341797  0.52294922  0.50830078  0.52783203  0.50830078  0.47192383
   0.49902344  0.50683594  0.51660156  0.52197266  0.49731445  0.53515625
   0.51611328  0.51513672  0.51171875  0.5234375   0.50048828  0.47753906
   0.51904297  0.50927734  0.51464844  0.50830078  0.49487305  0.53466797
   0.55029297  0.51660156  0.46826172  0.49169922  0.51660156  0.49853516
   0.48974609  0.50878906  0.52490234  0.54296875  0.51513672  0.51318359
   0.52148438  0.52001953  0.55322266  0.54248047  0.50927734  0.50878906
   0.54150391  0.49951172  0.52001953  0.54345703  0.50878906  0.46484375
   0.57470703  0.52197266  0.51953125  0.51757812  0.4855957   0.50439453
   0.50146484  0.52001953  0.45996094  0.45825195  0.48486328  0.5
   0.50927734  0.52539062  0.49804688  0.49267578  0.47436523  0.51660156
   0.52001953  0.47460938  0.50585938  0.49414062  0.51318359  0.546875
   0.52392578  0.54736328  0.52587891  0.53173828  0.51757812  0.52734375
   0.54736328  0.54052734  0.51025391  0.50439453  0.49584961  0.49780273
   0.54296875  0.49853516  0.52587891  0.47436523  0.52832031  0.53271484
   0.50341797  0.54003906  0.515625    0.51464844  0.50537109  0.51269531
   0.53125     0.54833984  0.48120117  0.51367188  0.51708984  0.50732422
   0.50927734  0.53222656  0.51904297  0.51025391  0.51220703  0.49438477
   0.49291992  0.51757812  0.50830078  0.52197266  0.50195312  0.54492188
   0.52392578  0.49316406  0.51220703  0.53613281  0.5546875   0.52050781
   0.49169922  0.52197266  0.51904297  0.49731445  0.56542969  0.49121094
   0.49853516  0.4934082   0.5078125   0.53076172  0.49267578  0.55029297
   0.48754883  0.52832031  0.54052734  0.49609375  0.50341797  0.52783203
   0.52001953  0.48193359  0.55712891  0.49023438  0.50048828  0.50390625
   0.50878906  0.54736328  0.49609375  0.48535156  0.49145508  0.50830078
   0.54296875  0.53710938  0.48095703  0.50048828  0.49755859  0.49658203
   0.50732422  0.50439453  0.51074219  0.51367188  0.51855469  0.4921875
   0.52636719  0.46655273  0.49023438  0.53808594  0.484375    0.52441406
   0.51953125  0.52636719  0.48730469  0.50634766  0.49584961  0.47851562
   0.51464844  0.5234375   0.49511719  0.52832031  0.47607422  0.48388672
   0.55957031  0.50390625  0.52197266  0.49902344  0.50488281  0.51171875
   0.58789062  0.55322266  0.50683594  0.43286133  0.53710938  0.50878906
   0.515625    0.49926758  0.50146484  0.52148438  0.51074219  0.5234375
   0.51806641  0.51025391  0.50537109  0.55419922  0.46337891  0.49511719
   0.48486328  0.48632812  0.52490234  0.49414062  0.54003906  0.45825195
   0.53759766  0.49658203  0.53320312  0.50048828]]
After layer _mul2082_0 (1, 256) <class 'numpy.float16'> [[-0.07421875 -0.0609436  -0.00309563  0.01873779  0.02156067 -0.02813721
   0.02131653  0.03805542  0.02864075 -0.05123901 -0.03778076  0.06408691
   0.04666138 -0.01667786  0.03405762 -0.12072754  0.02601624  0.00829315
   0.03347778  0.02568054  0.10205078 -0.0256958   0.00122833  0.03207397
  -0.05502319  0.01605225  0.02282715 -0.02082825 -0.06860352 -0.04855347
   0.0196991  -0.0592041  -0.00572968  0.00126171  0.05255127 -0.0635376
  -0.03005981 -0.00654984 -0.05395508 -0.04534912  0.01571655 -0.08972168
   0.05603027  0.04400635  0.04403687 -0.0557251   0.02090454 -0.02923584
  -0.00544357 -0.04174805  0.02799988 -0.05950928 -0.0357666   0.06384277
   0.02218628  0.01161957 -0.0196991   0.09124756  0.04147339 -0.02314758
  -0.043396   -0.0458374  -0.01535797 -0.00776291  0.03317261 -0.0189209
   0.02561951 -0.04318237 -0.0461731  -0.00862885 -0.1239624   0.00622177
   0.02563477  0.01139832  0.06494141 -0.02403259 -0.02293396 -0.08972168
  -0.03189087 -0.01940918 -0.06005859  0.00695419 -0.04031372 -0.07617188
  -0.13391113  0.00857544 -0.06317139  0.01853943 -0.078125   -0.05044556
  -0.05892944 -0.02763367 -0.012146   -0.00830841 -0.02159119  0.02029419
   0.04333496 -0.02365112 -0.04064941 -0.03001404  0.0136261   0.06451416
  -0.03494263  0.0224762   0.02346802  0.06365967 -0.01960754 -0.02191162
   0.07519531 -0.07800293  0.04156494  0.00395584  0.03308105  0.05053711
  -0.04675293  0.14587402 -0.07250977 -0.03866577  0.02249146 -0.02679443
   0.08740234  0.04223633 -0.01054382 -0.04415894  0.04870605 -0.08288574
  -0.04705811 -0.03445435 -0.02085876 -0.00757217  0.04476929 -0.02122498
   0.03665161 -0.00365639  0.00347328  0.03427124  0.04602051  0.10351562
  -0.00345802  0.03439331 -0.00405121 -0.02394104  0.0668335   0.00910187
  -0.04394531  0.04782104  0.03372192 -0.05685425 -0.04385376 -0.05310059
  -0.02955627 -0.01378632 -0.02729797 -0.04040527 -0.00427628  0.03967285
  -0.0585022   0.02116394  0.02575684  0.03518677 -0.12298584 -0.03640747
   0.01206207  0.07366943  0.01457214  0.04370117  0.00777435 -0.02775574
  -0.08703613  0.00422287 -0.0461731   0.0242157  -0.01577759 -0.07952881
  -0.01036072  0.03439331  0.08007812 -0.02322388 -0.03079224 -0.01753235
   0.03771973  0.00487518  0.0211792  -0.01583862 -0.02529907  0.02441406
   0.02124023 -0.05740356  0.04718018 -0.05740356  0.08624268 -0.00489044
  -0.00104713  0.00886536 -0.09008789 -0.00079012 -0.09899902 -0.04272461
  -0.0138855   0.03082275 -0.07250977 -0.01625061  0.08911133 -0.02767944
  -0.00606155 -0.01039886  0.02958679  0.00463867  0.05429077 -0.04501343
  -0.07794189  0.00382423  0.01358032 -0.07836914 -0.02836609 -0.03796387
   0.01311493 -0.01913452 -0.01225281  0.05877686 -0.01282501 -0.03704834
   0.04425049  0.00677109  0.00325584 -0.02449036  0.00246811  0.01617432
   0.02217102 -0.00468826 -0.06652832  0.05929565  0.0266571   0.04180908
  -0.03515625  0.02006531 -0.04779053  0.01036835 -0.08331299  0.06210327
   0.00880432 -0.0098877   0.01238251 -0.0368042  -0.01625061 -0.03125
  -0.02546692 -0.06848145  0.00590134  0.10290527  0.10638428  0.0418396
   0.02624512 -0.03381348 -0.02415466 -0.00823212]]
After layer encoder_birnn_reverse_l0_t5_i_output (1, 256) <class 'numpy.float16'> [[ 0.49731445  0.49487305  0.49462891  0.49438477  0.50830078  0.49536133
   0.50585938  0.50439453  0.52441406  0.51513672  0.48999023  0.52246094
   0.50390625  0.5078125   0.49951172  0.56884766  0.47265625  0.48193359
   0.50292969  0.49707031  0.52294922  0.50341797  0.47338867  0.48901367
   0.51904297  0.46875     0.49145508  0.49584961  0.50439453  0.49487305
   0.5         0.49633789  0.48754883  0.48876953  0.51855469  0.46508789
   0.49658203  0.49755859  0.48022461  0.48388672  0.47045898  0.50683594
   0.48681641  0.50048828  0.50830078  0.49658203  0.51660156  0.47998047
   0.49291992  0.50634766  0.50292969  0.52539062  0.47241211  0.51806641
   0.54492188  0.52685547  0.48388672  0.50341797  0.48217773  0.49462891
   0.51953125  0.48754883  0.5390625   0.49291992  0.47167969  0.48950195
   0.52539062  0.49462891  0.48095703  0.50244141  0.52490234  0.49438477
   0.49829102  0.49609375  0.50146484  0.515625    0.53027344  0.53857422
   0.50585938  0.51220703  0.50585938  0.51171875  0.52148438  0.49487305
   0.54101562  0.51269531  0.49316406  0.4855957   0.49438477  0.51855469
   0.52832031  0.49682617  0.47924805  0.52099609  0.51806641  0.50976562
   0.49316406  0.51660156  0.47509766  0.47045898  0.4765625   0.51953125
   0.50195312  0.46850586  0.47753906  0.50195312  0.4934082   0.47241211
   0.51513672  0.5078125   0.47119141  0.50390625  0.50634766  0.55078125
   0.50195312  0.57421875  0.49121094  0.50195312  0.50439453  0.48852539
   0.55224609  0.46875     0.50048828  0.52392578  0.48486328  0.51464844
   0.46826172  0.51806641  0.49438477  0.50146484  0.54980469  0.51513672
   0.49804688  0.48925781  0.48144531  0.47998047  0.52587891  0.5390625
   0.49780273  0.49609375  0.48999023  0.47216797  0.52099609  0.515625
   0.49243164  0.49926758  0.50830078  0.51513672  0.49633789  0.51513672
   0.52929688  0.48535156  0.5         0.47631836  0.47900391  0.54785156
   0.50732422  0.51074219  0.49511719  0.49194336  0.55175781  0.50195312
   0.48535156  0.50683594  0.50244141  0.48242188  0.50097656  0.48779297
   0.51074219  0.48876953  0.50048828  0.51025391  0.50097656  0.52539062
   0.50585938  0.46435547  0.50878906  0.46948242  0.48632812  0.49414062
   0.51074219  0.48266602  0.49731445  0.50683594  0.52392578  0.49462891
   0.49609375  0.48510742  0.52685547  0.51220703  0.49145508  0.49267578
   0.51025391  0.48999023  0.50488281  0.52050781  0.52246094  0.45874023
   0.51074219  0.51806641  0.50146484  0.52880859  0.51757812  0.51269531
   0.50537109  0.4934082   0.49926758  0.48681641  0.48364258  0.51123047
   0.51123047  0.52685547  0.50537109  0.51367188  0.50097656  0.50488281
   0.49829102  0.49438477  0.50585938  0.5         0.48535156  0.48120117
   0.52099609  0.48144531  0.50244141  0.515625    0.4934082   0.47583008
   0.47851562  0.52978516  0.49731445  0.47167969  0.49487305  0.48779297
   0.50732422  0.51513672  0.49853516  0.52001953  0.50732422  0.48950195
   0.47583008  0.46704102  0.52441406  0.55859375  0.4855957   0.50537109
   0.48217773  0.48217773  0.50390625  0.50048828  0.53710938  0.49902344
   0.47485352  0.51220703  0.51318359  0.49658203]]
After layer encoder_birnn_reverse_l0_t5_c_output (1, 256) <class 'numpy.float16'> [[ -1.59057617e-01  -1.44165039e-01  -2.81219482e-02   4.94384766e-02
    2.99224854e-02  -6.24694824e-02   2.28881836e-02   7.74536133e-02
    7.51953125e-02  -1.29394531e-01  -8.48999023e-02   1.66381836e-01
    9.55200195e-02  -2.05993652e-02   7.29980469e-02  -2.49511719e-01
    8.29467773e-02   3.06701660e-02   9.89379883e-02   5.68847656e-02
    2.30957031e-01  -7.06176758e-02  -1.60217285e-02   4.95910645e-02
   -1.25122070e-01   3.49731445e-02   5.66406250e-02  -5.77392578e-02
   -1.51855469e-01  -1.24572754e-01   4.69055176e-02  -1.20605469e-01
   -2.80761719e-03   6.98852539e-03   1.27197266e-01  -1.61621094e-01
   -6.12182617e-02   1.46102905e-03  -1.26464844e-01  -1.13464355e-01
    2.16064453e-02  -2.10937500e-01   1.33911133e-01   1.01684570e-01
    9.65576172e-02  -1.21826172e-01   5.03234863e-02  -7.12890625e-02
   -1.69982910e-02  -1.09802246e-01   7.50732422e-02  -1.39526367e-01
   -8.15429688e-02   1.76269531e-01   1.43432617e-02   1.79748535e-02
   -2.16217041e-02   2.10571289e-01   1.22924805e-01  -4.91027832e-02
   -1.16027832e-01  -1.02172852e-01  -1.88293457e-02  -2.90374756e-02
    7.88574219e-02  -4.09240723e-02   3.17077637e-02  -1.19323730e-01
   -1.07788086e-01   1.92260742e-03  -2.82470703e-01   2.70843506e-02
    4.21447754e-02   2.48565674e-02   1.43066406e-01  -2.64434814e-02
   -6.08520508e-02  -2.24975586e-01  -8.15429688e-02  -4.88281250e-02
   -1.37817383e-01   1.26647949e-02  -1.02661133e-01  -1.88232422e-01
   -2.83203125e-01   7.20214844e-03  -1.07421875e-01   1.64489746e-02
   -2.09960938e-01  -1.15478516e-01  -1.27929688e-01  -6.10046387e-02
   -3.18603516e-02   1.14822388e-03  -5.54809570e-02   6.00585938e-02
    9.66186523e-02  -4.93164062e-02  -1.06506348e-01  -1.06384277e-01
    1.43432617e-02   1.53076172e-01  -7.44628906e-02   5.69152832e-02
    6.83593750e-02   1.89575195e-01  -4.69055176e-02  -4.26635742e-02
    1.74682617e-01  -2.10693359e-01   1.25244141e-01  -1.36413574e-02
    9.86328125e-02   1.21826172e-01  -9.22851562e-02   2.90283203e-01
   -1.84326172e-01  -1.00891113e-01   3.55834961e-02  -7.55615234e-02
    1.85668945e-01   6.61010742e-02  -1.02996826e-02  -1.10046387e-01
    1.05102539e-01  -1.92626953e-01  -1.29394531e-01  -8.76464844e-02
   -5.17272949e-02  -2.56042480e-02   1.11877441e-01  -2.33154297e-02
    8.09936523e-02   1.13372803e-02   5.34057617e-04   7.75146484e-02
    8.17871094e-02   2.39379883e-01   6.10351562e-05   7.31201172e-02
   -1.64794922e-03  -4.71496582e-02   1.55761719e-01   2.68249512e-02
   -9.19799805e-02   1.13281250e-01   8.67919922e-02  -1.11694336e-01
   -1.04431152e-01  -1.46728516e-01  -7.05566406e-02  -2.83966064e-02
   -8.45947266e-02  -7.80029297e-02  -3.90625000e-03   8.74023438e-02
   -1.37817383e-01   1.89819336e-02   5.63659668e-02   8.23364258e-02
   -2.54394531e-01  -6.25610352e-02   2.47497559e-02   1.61865234e-01
    3.98559570e-02   1.03637695e-01   1.40838623e-02  -4.04357910e-02
   -2.33886719e-01   1.54113770e-02  -1.15600586e-01   7.06176758e-02
   -3.79028320e-02  -1.59912109e-01  -3.54919434e-02   8.22753906e-02
    1.70288086e-01  -5.80749512e-02  -5.70068359e-02  -2.08435059e-02
    7.62329102e-02   2.19726562e-02   5.18188477e-02  -4.12902832e-02
   -7.76367188e-02   4.74548340e-02   5.60913086e-02  -1.19934082e-01
    8.77075195e-02  -1.36840820e-01   2.30590820e-01  -1.33666992e-02
   -1.61743164e-02   4.24804688e-02  -2.49267578e-01  -1.86157227e-03
   -2.45117188e-01  -1.09008789e-01  -3.75061035e-02   9.00878906e-02
   -1.83959961e-01  -5.21545410e-02   1.94335938e-01  -6.34155273e-02
   -2.08587646e-02  -3.68347168e-02   8.20922852e-02   1.53350830e-02
    1.46118164e-01  -7.72705078e-02  -1.87988281e-01   6.10351562e-05
    3.67431641e-02  -2.09106445e-01  -7.42797852e-02  -1.00097656e-01
    4.09240723e-02  -4.76379395e-02  -5.13610840e-02   1.40380859e-01
   -3.17077637e-02  -8.65478516e-02   9.67407227e-02   3.21960449e-02
    1.98669434e-02  -6.56127930e-02   1.07421875e-02   3.53698730e-02
    1.52893066e-02   9.91821289e-03  -1.54785156e-01   1.81518555e-01
    3.61633301e-02   9.25292969e-02  -7.12890625e-02   2.75268555e-02
   -9.47875977e-02   2.84271240e-02  -2.26806641e-01   1.29638672e-01
    2.50244141e-03  -4.25720215e-03   3.01361084e-02  -5.23071289e-02
   -3.78723145e-02  -5.51147461e-02  -6.65283203e-02  -1.97631836e-01
    2.77404785e-02   2.44873047e-01   2.46337891e-01   1.14074707e-01
    3.62243652e-02  -8.56323242e-02  -6.25610352e-02  -5.66101074e-03]]
After layer _mul2083_0 (1, 256) <class 'numpy.float16'> [[ -7.91015625e-02  -7.13500977e-02  -1.39083862e-02   2.44445801e-02
    1.52130127e-02  -3.09448242e-02   1.15814209e-02   3.90625000e-02
    3.94287109e-02  -6.66503906e-02  -4.15954590e-02   8.69140625e-02
    4.81262207e-02  -1.04598999e-02   3.64685059e-02  -1.41967773e-01
    3.92150879e-02   1.47781372e-02   4.97436523e-02   2.82745361e-02
    1.20788574e-01  -3.55529785e-02  -7.58361816e-03   2.42462158e-02
   -6.49414062e-02   1.63879395e-02   2.78320312e-02  -2.86254883e-02
   -7.65991211e-02  -6.16455078e-02   2.34527588e-02  -5.98754883e-02
   -1.36852264e-03   3.41606140e-03   6.59790039e-02  -7.51953125e-02
   -3.03955078e-02   7.27176666e-04  -6.07299805e-02  -5.49011230e-02
    1.01623535e-02  -1.06933594e-01   6.51855469e-02   5.09033203e-02
    4.90722656e-02  -6.04858398e-02   2.60009766e-02  -3.42102051e-02
   -8.37707520e-03  -5.56030273e-02   3.77502441e-02  -7.33032227e-02
   -3.85131836e-02   9.13085938e-02   7.81250000e-03   9.46807861e-03
   -1.04598999e-02   1.06018066e-01   5.92651367e-02  -2.42919922e-02
   -6.02722168e-02  -4.98046875e-02  -1.01470947e-02  -1.43127441e-02
    3.72009277e-02  -2.00347900e-02   1.66625977e-02  -5.90209961e-02
   -5.18493652e-02   9.66072083e-04  -1.48315430e-01   1.33895874e-02
    2.09960938e-02   1.23291016e-02   7.17163086e-02  -1.36337280e-02
   -3.22570801e-02  -1.21154785e-01  -4.12597656e-02  -2.50091553e-02
   -6.97021484e-02   6.48117065e-03  -5.35278320e-02  -9.31396484e-02
   -1.53198242e-01   3.69262695e-03  -5.29785156e-02   7.98797607e-03
   -1.03820801e-01  -5.98754883e-02  -6.75659180e-02  -3.03039551e-02
   -1.52664185e-02   5.98430634e-04  -2.87475586e-02   3.06091309e-02
    4.76379395e-02  -2.54821777e-02  -5.05981445e-02  -5.00488281e-02
    6.83593750e-03   7.95288086e-02  -3.73840332e-02   2.66723633e-02
    3.26538086e-02   9.51538086e-02  -2.31475830e-02  -2.01568604e-02
    8.99658203e-02  -1.06994629e-01   5.90209961e-02  -6.87408447e-03
    4.99572754e-02   6.70776367e-02  -4.63256836e-02   1.66625977e-01
   -9.05151367e-02  -5.06286621e-02   1.79443359e-02  -3.69262695e-02
    1.02539062e-01   3.09906006e-02  -5.15365601e-03  -5.76477051e-02
    5.09643555e-02  -9.91210938e-02  -6.05773926e-02  -4.54101562e-02
   -2.55737305e-02  -1.28402710e-02   6.15234375e-02  -1.20086670e-02
    4.03442383e-02   5.54656982e-03   2.57015228e-04   3.72009277e-02
    4.29992676e-02   1.29028320e-01   3.03983688e-05   3.62854004e-02
   -8.07285309e-04  -2.22625732e-02   8.11767578e-02   1.38320923e-02
   -4.52880859e-02   5.65490723e-02   4.41284180e-02  -5.75256348e-02
   -5.18188477e-02  -7.55615234e-02  -3.73535156e-02  -1.37786865e-02
   -4.22973633e-02  -3.71398926e-02  -1.87110901e-03   4.78820801e-02
   -6.99462891e-02   9.69696045e-03   2.79083252e-02   4.04968262e-02
   -1.40380859e-01  -3.14025879e-02   1.20086670e-02   8.20312500e-02
    2.00195312e-02   4.99877930e-02   7.05718994e-03  -1.97296143e-02
   -1.19445801e-01   7.53402710e-03  -5.78613281e-02   3.60412598e-02
   -1.89819336e-02  -8.40454102e-02  -1.79595947e-02   3.82080078e-02
    8.66699219e-02  -2.72674561e-02  -2.77252197e-02  -1.02996826e-02
    3.89404297e-02   1.06048584e-02   2.57720947e-02  -2.09197998e-02
   -4.06799316e-02   2.34680176e-02   2.78320312e-02  -5.81665039e-02
    4.62036133e-02  -7.00683594e-02   1.13342285e-01  -6.58416748e-03
   -8.25500488e-03   2.08129883e-02  -1.25854492e-01  -9.68933105e-04
   -1.28051758e-01  -5.00183105e-02  -1.91497803e-02   4.66613770e-02
   -9.22241211e-02  -2.75726318e-02   1.00585938e-01  -3.25012207e-02
   -1.05438232e-02  -1.81732178e-02   4.09851074e-02   7.46536255e-03
    7.06787109e-02  -3.94897461e-02  -9.61303711e-02   3.21865082e-05
    1.85699463e-02  -1.07421875e-01  -3.72009277e-02  -5.05371094e-02
    2.03857422e-02  -2.35443115e-02  -2.59857178e-02   7.01904297e-02
   -1.53884888e-02  -4.16564941e-02   5.04150391e-02   1.55029297e-02
    9.97924805e-03  -3.38439941e-02   5.29861450e-03   1.68304443e-02
    7.31658936e-03   5.25283813e-03  -7.69653320e-02   8.56323242e-02
    1.78985596e-02   4.51354980e-02  -3.61633301e-02   1.41830444e-02
   -4.72412109e-02   1.47857666e-02  -1.15051270e-01   6.34765625e-02
    1.19113922e-03  -1.98745728e-03   1.58081055e-02  -2.92205811e-02
   -1.83868408e-02  -2.78472900e-02  -3.20739746e-02  -9.52758789e-02
    1.39770508e-02   1.22558594e-01   1.32324219e-01   5.69152832e-02
    1.71966553e-02  -4.38537598e-02  -3.21044922e-02  -2.81143188e-03]]
After layer encoder_birnn_reverse_l0_t5_state_0 (1, 256) <class 'numpy.float16'> [[-0.15332031 -0.13232422 -0.01699829  0.04318237  0.03677368 -0.05908203
   0.03289795  0.07714844  0.0680542  -0.11791992 -0.0793457   0.15100098
   0.0947876  -0.02713013  0.07055664 -0.26269531  0.06524658  0.02307129
   0.08325195  0.05395508  0.22290039 -0.06124878 -0.00635529  0.05633545
  -0.11999512  0.03244019  0.05065918 -0.04943848 -0.14526367 -0.11022949
   0.04315186 -0.11907959 -0.00709915  0.00467682  0.11853027 -0.13867188
  -0.06045532 -0.00582123 -0.11468506 -0.10021973  0.02587891 -0.19665527
   0.12121582  0.09490967  0.09313965 -0.11621094  0.04690552 -0.06347656
  -0.01382446 -0.09735107  0.06573486 -0.1328125  -0.07427979  0.15515137
   0.02999878  0.02108765 -0.03015137  0.19726562  0.10070801 -0.04742432
  -0.1036377  -0.09564209 -0.0255127  -0.02207947  0.07037354 -0.03894043
   0.04229736 -0.10217285 -0.09802246 -0.00766373 -0.2722168   0.01960754
   0.04663086  0.02372742  0.13671875 -0.03765869 -0.05517578 -0.2109375
  -0.07312012 -0.04443359 -0.12976074  0.01343536 -0.09387207 -0.16931152
  -0.28710938  0.01226807 -0.1161499   0.02651978 -0.18188477 -0.11035156
  -0.12646484 -0.05792236 -0.02740479 -0.0077095  -0.050354    0.05090332
   0.09094238 -0.0491333  -0.09124756 -0.08007812  0.02046204  0.14404297
  -0.07232666  0.0491333   0.05612183  0.15881348 -0.04275513 -0.04205322
   0.16516113 -0.18505859  0.10058594 -0.00291824  0.08300781  0.11761475
  -0.09307861  0.3125     -0.16308594 -0.08929443  0.04043579 -0.0637207
   0.18994141  0.07324219 -0.01570129 -0.10180664  0.09967041 -0.18200684
  -0.10766602 -0.07983398 -0.04644775 -0.02041626  0.10632324 -0.03323364
   0.07702637  0.00189018  0.00373077  0.07147217  0.08898926  0.23254395
  -0.00342751  0.07067871 -0.00485992 -0.04620361  0.14794922  0.02293396
  -0.0892334   0.10437012  0.07788086 -0.11437988 -0.09570312 -0.12866211
  -0.06689453 -0.02755737 -0.06958008 -0.07751465 -0.00614929  0.08752441
  -0.12841797  0.03085327  0.0536499   0.07568359 -0.26342773 -0.06781006
   0.02407837  0.15576172  0.03460693  0.09368896  0.01483154 -0.04748535
  -0.20654297  0.0117569  -0.10400391  0.0602417  -0.03475952 -0.16357422
  -0.02832031  0.07263184  0.16674805 -0.05047607 -0.05853271 -0.02783203
   0.07666016  0.01548004  0.04693604 -0.03674316 -0.065979    0.04788208
   0.04907227 -0.11560059  0.09338379 -0.12744141  0.19958496 -0.01147461
  -0.00930023  0.02967834 -0.21594238 -0.00175858 -0.22705078 -0.09277344
  -0.03302002  0.07751465 -0.16479492 -0.04382324  0.18969727 -0.06018066
  -0.01660156 -0.02856445  0.07055664  0.01210022  0.125      -0.08447266
  -0.17407227  0.00385666  0.03216553 -0.18579102 -0.06555176 -0.08850098
   0.0335083  -0.04266357 -0.03823853  0.12890625 -0.0282135  -0.07873535
   0.09466553  0.02227783  0.013237   -0.05834961  0.00776672  0.03302002
   0.02947998  0.00056458 -0.14355469  0.14489746  0.04455566  0.08691406
  -0.07128906  0.03424072 -0.09503174  0.02514648 -0.19836426  0.12561035
   0.00999451 -0.01187134  0.02819824 -0.06604004 -0.03463745 -0.05908203
  -0.05755615 -0.16381836  0.0198822   0.22546387  0.23876953  0.09875488
   0.04345703 -0.07763672 -0.05627441 -0.01104736]]
After layer activation1041_output (1, 256) <class 'numpy.float16'> [[-0.15209961 -0.1315918  -0.01699829  0.04315186  0.03674316 -0.059021
   0.03289795  0.07696533  0.06793213 -0.11737061 -0.0791626   0.14990234
   0.09448242 -0.02713013  0.07043457 -0.25683594  0.06512451  0.02307129
   0.08306885  0.05389404  0.21923828 -0.06115723 -0.00635529  0.05627441
  -0.1194458   0.03244019  0.05062866 -0.04940796 -0.14428711 -0.10980225
   0.04312134 -0.11853027 -0.00709915  0.00467682  0.11798096 -0.13781738
  -0.06039429 -0.00582123 -0.11419678 -0.09991455  0.02587891 -0.19421387
   0.12060547  0.09460449  0.09289551 -0.11566162  0.046875   -0.06341553
  -0.01382446 -0.0970459   0.06561279 -0.13208008 -0.07415771  0.15393066
   0.02998352  0.02108765 -0.03013611  0.19470215  0.1003418  -0.0473938
  -0.10327148 -0.09533691 -0.0255127  -0.02207947  0.07025146 -0.03890991
   0.04226685 -0.10180664 -0.09771729 -0.00766373 -0.265625    0.01960754
   0.04660034  0.02372742  0.13586426 -0.03762817 -0.05511475 -0.20788574
  -0.07299805 -0.04440308 -0.12902832  0.01343536 -0.09356689 -0.16772461
  -0.27954102  0.01226807 -0.11560059  0.02651978 -0.17993164 -0.10992432
  -0.12585449 -0.05786133 -0.02740479 -0.0077095  -0.05032349  0.0508728
   0.09069824 -0.04910278 -0.09100342 -0.07989502  0.02046204  0.14306641
  -0.07220459  0.04910278  0.05606079  0.1574707  -0.04272461 -0.04202271
   0.16369629 -0.1829834   0.10021973 -0.00291824  0.08282471  0.11706543
  -0.09283447  0.30273438 -0.16162109 -0.08905029  0.04040527 -0.06365967
   0.18774414  0.07312012 -0.01570129 -0.10144043  0.09936523 -0.18005371
  -0.10723877 -0.07965088 -0.04641724 -0.02041626  0.105896   -0.03323364
   0.0769043   0.00189018  0.00373077  0.0713501   0.08874512  0.22839355
  -0.00342751  0.07055664 -0.00485992 -0.0461731   0.14685059  0.02293396
  -0.08898926  0.10400391  0.07769775 -0.1138916  -0.09539795 -0.12792969
  -0.06677246 -0.02755737 -0.06945801 -0.07733154 -0.00614929  0.08728027
  -0.12768555  0.03083801  0.05358887  0.07556152 -0.25756836 -0.06768799
   0.02407837  0.15454102  0.03460693  0.09344482  0.01483154 -0.04745483
  -0.20361328  0.0117569  -0.1036377   0.06018066 -0.03475952 -0.16210938
  -0.02832031  0.07250977  0.16516113 -0.05044556 -0.05847168 -0.02783203
   0.07653809  0.01548004  0.04690552 -0.03671265 -0.06585693  0.04785156
   0.04904175 -0.1151123   0.09313965 -0.12670898  0.19702148 -0.01147461
  -0.00930023  0.02966309 -0.21264648 -0.00175858 -0.2232666  -0.0925293
  -0.03302002  0.07733154 -0.16333008 -0.04379272  0.1875     -0.06011963
  -0.01660156 -0.02854919  0.07043457  0.01210022  0.12432861 -0.08428955
  -0.17236328  0.00385666  0.03216553 -0.18371582 -0.06542969 -0.08825684
   0.0335083  -0.04263306 -0.03820801  0.12817383 -0.0282135  -0.07855225
   0.09436035  0.02227783  0.013237   -0.05828857  0.00776672  0.03302002
   0.02946472  0.00056458 -0.14257812  0.1439209   0.04452515  0.08666992
  -0.07116699  0.03424072 -0.09472656  0.02514648 -0.19580078  0.12493896
   0.00999451 -0.01187134  0.02819824 -0.06591797 -0.03463745 -0.059021
  -0.05749512 -0.16235352  0.0198822   0.22167969  0.234375    0.09844971
   0.04342651 -0.07745361 -0.05621338 -0.01104736]]
After layer encoder_birnn_reverse_l0_t5_out_0 (1, 256) <class 'numpy.float16'> [[-0.07849121 -0.06732178 -0.00843048  0.02229309  0.01875305 -0.0324707
   0.01725769  0.04086304  0.04049683 -0.06219482 -0.0385437   0.07745361
   0.05105591 -0.01331329  0.03601074 -0.1361084   0.03158569  0.01102448
   0.04223633  0.02670288  0.10736084 -0.02857971 -0.00359344  0.02964783
  -0.0614624   0.0166626   0.02516174 -0.02456665 -0.06872559 -0.05532837
   0.02276611 -0.06222534 -0.0036087   0.00237274  0.05828857 -0.06738281
  -0.03179932 -0.00289536 -0.05917358 -0.04956055  0.0134201  -0.09570312
   0.0602417   0.0473938   0.04571533 -0.05874634  0.02371216 -0.03057861
  -0.0070076  -0.05123901  0.03417969 -0.06524658 -0.03598022  0.07904053
   0.01620483  0.00995636 -0.01617432  0.09838867  0.05090332 -0.02232361
  -0.05319214 -0.04937744 -0.01293182 -0.01193237  0.03500366 -0.01889038
   0.02322388 -0.05239868 -0.04901123 -0.00398254 -0.1340332   0.00997925
   0.02336121  0.0117569   0.07177734 -0.02070618 -0.02955627 -0.1060791
  -0.03866577 -0.02452087 -0.07000732  0.00738144 -0.04907227 -0.08862305
  -0.15087891  0.00629425 -0.05874634  0.01389313 -0.09350586 -0.05673218
  -0.06793213 -0.02827454 -0.01308441 -0.00390625 -0.02577209  0.02586365
   0.04675293 -0.02580261 -0.04226685 -0.03778076  0.01000214  0.06640625
  -0.034729    0.02348328  0.02780151  0.07904053 -0.02095032 -0.02233887
   0.08422852 -0.09790039  0.050354   -0.00150013  0.03967285  0.06256104
  -0.04650879  0.16271973 -0.07763672 -0.04394531  0.02081299 -0.03092957
   0.09515381  0.03823853 -0.00818634 -0.0508728   0.04837036 -0.09161377
  -0.05334473 -0.03973389 -0.02294922 -0.00971985  0.05340576 -0.01815796
   0.03805542  0.00099087  0.00190735  0.03436279  0.04724121  0.11755371
  -0.0018177   0.03579712 -0.00244904 -0.02302551  0.07055664  0.01187897
  -0.04443359  0.05267334  0.0418396  -0.05877686 -0.04852295 -0.06347656
  -0.0329895  -0.01357269 -0.03594971 -0.04122925 -0.00307083  0.04534912
  -0.0668335   0.01623535  0.02734375  0.04031372 -0.13378906 -0.03436279
   0.01197052  0.0826416   0.01802063  0.04495239  0.0083847  -0.02502441
  -0.09521484  0.0059433  -0.0491333   0.03170776 -0.01812744 -0.0892334
  -0.01429749  0.03936768  0.08880615 -0.0244751  -0.03041077 -0.01381683
   0.03607178  0.00747299  0.02400208 -0.0177002  -0.03204346  0.02546692
   0.02424622 -0.06054688  0.04620361 -0.06011963  0.0994873  -0.00614548
  -0.00476837  0.01494598 -0.10687256 -0.00090599 -0.10992432 -0.0473938
  -0.01742554  0.03897095 -0.08477783 -0.02427673  0.09796143 -0.0322876
  -0.00867462 -0.01493073  0.03390503  0.00619125  0.0592041  -0.0456543
  -0.08599854  0.00221443  0.01654053 -0.09887695 -0.03430176 -0.04299927
   0.01724243 -0.02333069 -0.01878357  0.06237793 -0.01381683 -0.03668213
   0.05072021  0.01129913  0.0068512  -0.03059387  0.00389099  0.01679993
   0.01702881  0.00030828 -0.07183838  0.0670166   0.0219574   0.04342651
  -0.03521729  0.01731873 -0.04660034  0.01305389 -0.10333252  0.0635376
   0.00468445 -0.00618362  0.01476288 -0.03820801 -0.01622009 -0.03038025
  -0.02908325 -0.0758667   0.01012421  0.11010742  0.12335205  0.04708862
   0.02284241 -0.04138184 -0.02799988 -0.00569534]]
After layer expand_dims1047_0 (1, 1, 256) <class 'numpy.float16'> [[[-0.07849121 -0.06732178 -0.00843048  0.02229309  0.01875305 -0.0324707
    0.01725769  0.04086304  0.04049683 -0.06219482 -0.0385437   0.07745361
    0.05105591 -0.01331329  0.03601074 -0.1361084   0.03158569  0.01102448
    0.04223633  0.02670288  0.10736084 -0.02857971 -0.00359344  0.02964783
   -0.0614624   0.0166626   0.02516174 -0.02456665 -0.06872559 -0.05532837
    0.02276611 -0.06222534 -0.0036087   0.00237274  0.05828857 -0.06738281
   -0.03179932 -0.00289536 -0.05917358 -0.04956055  0.0134201  -0.09570312
    0.0602417   0.0473938   0.04571533 -0.05874634  0.02371216 -0.03057861
   -0.0070076  -0.05123901  0.03417969 -0.06524658 -0.03598022  0.07904053
    0.01620483  0.00995636 -0.01617432  0.09838867  0.05090332 -0.02232361
   -0.05319214 -0.04937744 -0.01293182 -0.01193237  0.03500366 -0.01889038
    0.02322388 -0.05239868 -0.04901123 -0.00398254 -0.1340332   0.00997925
    0.02336121  0.0117569   0.07177734 -0.02070618 -0.02955627 -0.1060791
   -0.03866577 -0.02452087 -0.07000732  0.00738144 -0.04907227 -0.08862305
   -0.15087891  0.00629425 -0.05874634  0.01389313 -0.09350586 -0.05673218
   -0.06793213 -0.02827454 -0.01308441 -0.00390625 -0.02577209  0.02586365
    0.04675293 -0.02580261 -0.04226685 -0.03778076  0.01000214  0.06640625
   -0.034729    0.02348328  0.02780151  0.07904053 -0.02095032 -0.02233887
    0.08422852 -0.09790039  0.050354   -0.00150013  0.03967285  0.06256104
   -0.04650879  0.16271973 -0.07763672 -0.04394531  0.02081299 -0.03092957
    0.09515381  0.03823853 -0.00818634 -0.0508728   0.04837036 -0.09161377
   -0.05334473 -0.03973389 -0.02294922 -0.00971985  0.05340576 -0.01815796
    0.03805542  0.00099087  0.00190735  0.03436279  0.04724121  0.11755371
   -0.0018177   0.03579712 -0.00244904 -0.02302551  0.07055664  0.01187897
   -0.04443359  0.05267334  0.0418396  -0.05877686 -0.04852295 -0.06347656
   -0.0329895  -0.01357269 -0.03594971 -0.04122925 -0.00307083  0.04534912
   -0.0668335   0.01623535  0.02734375  0.04031372 -0.13378906 -0.03436279
    0.01197052  0.0826416   0.01802063  0.04495239  0.0083847  -0.02502441
   -0.09521484  0.0059433  -0.0491333   0.03170776 -0.01812744 -0.0892334
   -0.01429749  0.03936768  0.08880615 -0.0244751  -0.03041077 -0.01381683
    0.03607178  0.00747299  0.02400208 -0.0177002  -0.03204346  0.02546692
    0.02424622 -0.06054688  0.04620361 -0.06011963  0.0994873  -0.00614548
   -0.00476837  0.01494598 -0.10687256 -0.00090599 -0.10992432 -0.0473938
   -0.01742554  0.03897095 -0.08477783 -0.02427673  0.09796143 -0.0322876
   -0.00867462 -0.01493073  0.03390503  0.00619125  0.0592041  -0.0456543
   -0.08599854  0.00221443  0.01654053 -0.09887695 -0.03430176 -0.04299927
    0.01724243 -0.02333069 -0.01878357  0.06237793 -0.01381683 -0.03668213
    0.05072021  0.01129913  0.0068512  -0.03059387  0.00389099  0.01679993
    0.01702881  0.00030828 -0.07183838  0.0670166   0.0219574   0.04342651
   -0.03521729  0.01731873 -0.04660034  0.01305389 -0.10333252  0.0635376
    0.00468445 -0.00618362  0.01476288 -0.03820801 -0.01622009 -0.03038025
   -0.02908325 -0.0758667   0.01012421  0.11010742  0.12335205  0.04708862
    0.02284241 -0.04138184 -0.02799988 -0.00569534]]]
After layer encoder_birnn_reverse_l0_t6_i2h_output (1, 1024) <class 'numpy.float16'> [[-0.0128479  -0.04095459  0.03787231 ...,  0.06970215 -0.04626465
   0.03759766]]
After layer encoder_birnn_reverse_l0_t6_h2h_output (1, 1024) <class 'numpy.float16'> [[-0.0010376   0.01634216 -0.07183838 ...,  0.07128906  0.04022217
   0.02212524]]
After layer _plus1042_0 (1, 1024) <class 'numpy.float16'> [[-0.0138855  -0.02461243 -0.03396606 ...,  0.14099121 -0.00604248
   0.0597229 ]]
After layer encoder_birnn_reverse_l0_t6_slice_output0 (1, 256) <class 'numpy.float16'> [[-0.0138855  -0.02461243 -0.03396606 -0.02484131  0.01330566 -0.02676392
   0.00927734  0.01158142  0.09899902  0.06713867 -0.04418945  0.10070801
   0.01073456  0.0231781  -0.00146484  0.29589844 -0.12402344 -0.08300781
   0.01238251 -0.01161957  0.10021973  0.00640869 -0.12438965 -0.04934692
   0.06793213 -0.12866211 -0.03417969 -0.01211548  0.00747681 -0.02139282
  -0.00347137 -0.01226807 -0.05496216 -0.04458618  0.07971191 -0.15368652
  -0.01617432 -0.01319122 -0.08502197 -0.07354736 -0.14379883  0.02505493
  -0.05114746  0.00296021  0.03091431 -0.01727295  0.0692749  -0.08422852
  -0.0397644   0.02651978  0.02130127  0.1072998  -0.14318848  0.07867432
   0.1776123   0.11572266 -0.07159424  0.01490784 -0.08166504 -0.01808167
   0.08398438 -0.05792236  0.15844727 -0.0279541  -0.1151123  -0.04238892
   0.1081543  -0.02320862 -0.09155273  0.00152588  0.10546875 -0.02087402
  -0.01422119 -0.02420044  0.01272583  0.05731201  0.1204834   0.16503906
   0.03445435  0.05487061  0.02352905  0.04684448  0.08850098 -0.02378845
   0.16748047  0.0423584  -0.0267334  -0.07470703 -0.01934814  0.0614624
   0.11474609 -0.00427246 -0.08526611  0.07910156  0.07098389  0.0357666
  -0.03034973  0.04559326 -0.11065674 -0.12805176 -0.1126709   0.07849121
   0.01501465 -0.11987305 -0.11315918  0.00889587 -0.02854919 -0.11065674
   0.06732178  0.01525879 -0.11035156  0.00177002  0.02986145  0.2253418
   0.01275635  0.30859375 -0.03210449  0.0075531   0.00317383 -0.05233765
   0.2142334  -0.12817383 -0.00274658  0.09887695 -0.0715332   0.06616211
  -0.13720703  0.07751465 -0.02813721  0.00750732  0.21594238  0.05438232
  -0.00888062 -0.04840088 -0.08203125 -0.09942627  0.1114502   0.16296387
  -0.01708984 -0.01391602 -0.04190063 -0.12512207  0.09289551  0.0579834
  -0.02410889 -0.00085449  0.03564453  0.06323242 -0.01248169  0.06622314
   0.12255859 -0.065979   -0.00108337 -0.09405518 -0.09973145  0.19543457
   0.02819824  0.02648926 -0.02255249 -0.03186035  0.22546387  0.00349426
  -0.06781006  0.02236938  0.00701904 -0.0760498  -0.00180054 -0.05371094
   0.03582764 -0.04870605 -0.00601196  0.04391479  0.00167084  0.10321045
   0.02067566 -0.16259766  0.03814697 -0.12963867 -0.06011963 -0.02209473
   0.050354   -0.07312012 -0.00738525  0.0249939   0.10003662 -0.01792908
  -0.0178833  -0.05783081  0.10076904  0.04089355 -0.04391479 -0.03936768
   0.03723145 -0.05236816 -0.01879883  0.08972168  0.10070801 -0.17321777
   0.04251099  0.08453369  0.00891113  0.10498047  0.07629395  0.06292725
   0.01407623 -0.03430176 -0.00842285 -0.05328369 -0.07507324  0.04217529
   0.04772949  0.1184082   0.02053833  0.05151367 -0.00466919  0.00256348
  -0.00699615 -0.0218811   0.03161621 -0.00248718 -0.06390381 -0.09851074
   0.09735107 -0.07855225  0.00354767  0.06341553 -0.03048706 -0.10235596
  -0.10870361  0.10186768 -0.01244354 -0.13354492 -0.02056885 -0.05361938
   0.02816772  0.06005859 -0.00566864  0.08227539  0.03143311 -0.03604126
  -0.11517334 -0.14453125  0.09350586  0.23815918 -0.06246948  0.019104
  -0.09631348 -0.07885742  0.01373291 -0.00691223  0.16149902 -0.01156616
  -0.11456299  0.05108643  0.05447388 -0.00723267]]
After layer encoder_birnn_reverse_l0_t6_slice_output1 (1, 256) <class 'numpy.float16'> [[ 0.15380859  0.03665161  0.10736084  0.04541016  0.00610352  0.08093262
   0.19018555 -0.10101318  0.37744141  0.16723633  0.12225342  0.13671875
   0.12213135 -0.00492859  0.12438965  0.1373291   0.08813477 -0.03512573
  -0.15014648  0.07739258  0.13867188  0.01992798  0.40356445  0.06173706
   0.12341309  0.07653809  0.15820312  0.08221436  0.12243652  0.04043579
   0.08459473  0.03530884  0.23852539 -0.05743408 -0.01077271 -0.01986694
  -0.05706787  0.13574219  0.02352905  0.08959961 -0.07873535  0.11047363
   0.01600647  0.09765625  0.04031372  0.12023926  0.03518677 -0.12487793
  -0.00997925  0.0202179   0.07116699  0.09796143 -0.03479004  0.14990234
   0.05999756  0.05358887  0.05151367  0.10235596 -0.00396729 -0.10192871
   0.09484863  0.04037476  0.07299805  0.02929688 -0.025177    0.1496582
   0.21350098  0.07470703 -0.14624023 -0.04669189  0.06933594  0.00140381
  -0.05200195  0.0390625   0.10876465  0.1652832   0.06677246  0.0657959
   0.09875488  0.09051514  0.22387695  0.18823242  0.03762817  0.03100586
   0.18151855 -0.00762177  0.09112549  0.171875    0.03875732 -0.16333008
   0.32666016  0.08447266  0.08044434  0.07232666 -0.06481934  0.01196289
  -0.0038147   0.05651855 -0.1784668  -0.17871094 -0.07617188 -0.00723267
   0.0451355   0.10900879 -0.01835632 -0.0328064  -0.10870361  0.06445312
   0.09289551 -0.12298584  0.0390625  -0.02670288  0.06228638  0.21044922
   0.09753418  0.20031738  0.11828613  0.13476562  0.05517578  0.11364746
   0.203125    0.17260742  0.04443359  0.01824951 -0.03082275 -0.0078125
   0.17871094 -0.00601959  0.10510254 -0.11096191  0.13220215  0.12261963
   0.01495361  0.17797852  0.05679321  0.04931641  0.02416992  0.06002808
   0.13708496  0.21765137 -0.07409668  0.04449463  0.07684326  0.03198242
   0.04623413  0.13183594  0.09429932  0.04272461  0.05126953 -0.02804565
  -0.02761841  0.07897949  0.04467773  0.10003662 -0.01062012  0.18652344
   0.09875488 -0.04699707  0.06317139  0.15478516  0.22802734  0.09069824
  -0.03320312  0.09381104  0.09283447 -0.01782227  0.28125    -0.03018188
  -0.00668335 -0.02026367  0.02560425  0.13378906 -0.02099609  0.21276855
  -0.06060791  0.12683105  0.17248535 -0.02420044  0.01031494  0.1159668
   0.08294678 -0.07366943  0.24194336 -0.03607178 -0.00352478  0.03015137
   0.03421021  0.20361328 -0.04016113 -0.0703125  -0.03607178  0.04415894
   0.18359375  0.15820312 -0.12091064  0.00595093 -0.00436401 -0.01733398
   0.03201294  0.02220154  0.05657959  0.04537964  0.07745361 -0.02630615
   0.11395264 -0.14099121 -0.05072021  0.16540527 -0.07678223  0.10540771
   0.07995605  0.10626221 -0.05227661  0.03137207 -0.01373291 -0.09924316
   0.06237793  0.09973145 -0.02626038  0.12310791 -0.09887695 -0.08343506
   0.25830078  0.00994873  0.09484863 -0.00231934  0.02441406  0.05593872
   0.38842773  0.20239258  0.03808594 -0.28955078  0.15600586  0.0369873
   0.07232666 -0.00476074  0.00508118  0.08874512  0.05532837  0.09576416
   0.06762695  0.05389404  0.00579834  0.22021484 -0.15820312 -0.01498413
  -0.07843018 -0.05285645  0.11193848 -0.03063965  0.17626953 -0.18395996
   0.15710449 -0.00732422  0.13708496  0.00186157]]
After layer encoder_birnn_reverse_l0_t6_slice_output2 (1, 256) <class 'numpy.float16'> [[-0.16430664 -0.14916992 -0.0369873   0.05828857  0.01989746 -0.06268311
   0.01104736  0.0690918   0.08862305 -0.15161133 -0.08898926  0.19311523
   0.10424805 -0.01383972  0.08154297 -0.27441406  0.09075928  0.03192139
   0.10894775  0.06158447  0.26049805 -0.0793457  -0.02804565  0.04058838
  -0.13378906  0.03414917  0.05310059 -0.05899048 -0.16088867 -0.13513184
   0.04962158 -0.11938477  0.00378418  0.0020752   0.13769531 -0.16796875
  -0.05880737  0.00675583 -0.12817383 -0.12145996  0.01794434 -0.22558594
   0.14086914  0.1138916   0.10217285 -0.13232422  0.06329346 -0.07128906
  -0.02122498 -0.11767578  0.07501221 -0.15307617 -0.07647705  0.20751953
  -0.00378418  0.01222992 -0.01399231  0.23291016  0.13903809 -0.05102539
  -0.13366699 -0.10308838 -0.015625   -0.03759766  0.09002686 -0.0456543
   0.03106689 -0.12481689 -0.10858154  0.00958252 -0.31274414  0.03631592
   0.03118896  0.02409363  0.15454102 -0.01789856 -0.07324219 -0.25341797
  -0.0947876  -0.05667114 -0.15429688  0.00546265 -0.1137085  -0.20544434
  -0.31860352  0.00411987 -0.09295654  0.0062561  -0.23242188 -0.10742188
  -0.13842773 -0.06018066 -0.03393555  0.00897217 -0.05737305  0.06738281
   0.09655762 -0.04815674 -0.10522461 -0.12023926  0.00970459  0.16357422
  -0.07983398  0.06494141  0.07440186  0.21105957 -0.04910278 -0.03646851
   0.19140625 -0.22338867  0.14465332 -0.02288818  0.11602783  0.14099121
  -0.09143066  0.32275391 -0.20397949 -0.112854    0.02423096 -0.07849121
   0.20666504  0.06292725 -0.00167847 -0.12097168  0.10046387 -0.20483398
  -0.13867188 -0.09674072 -0.05450439 -0.02307129  0.13525391 -0.015625
   0.0838623   0.00950623 -0.00228882  0.07897949  0.0814209   0.26416016
   0.00467682  0.08184814 -0.00244141 -0.04714966  0.1697998   0.02618408
  -0.0970459   0.12573242  0.10095215 -0.11315918 -0.10974121 -0.1574707
  -0.08203125 -0.02987671 -0.0993042  -0.07751465 -0.00418091  0.10064697
  -0.1496582   0.003479    0.05911255  0.09222412 -0.29077148 -0.05950928
   0.02101135  0.16650391  0.04379272  0.10571289  0.00899506 -0.03543091
  -0.2644043   0.01144409 -0.12670898  0.08734131 -0.03369141 -0.16845703
  -0.0447998   0.08349609  0.18676758 -0.06481934 -0.05593872 -0.01463318
   0.07922363  0.0269165   0.06213379 -0.04553223 -0.08789062  0.03509521
   0.06060791 -0.13317871  0.0770874  -0.13452148  0.25463867 -0.00918579
  -0.02163696  0.05050659 -0.27563477  0.00119019 -0.26831055 -0.11956787
  -0.03436279  0.10742188 -0.20239258 -0.06204224  0.21105957 -0.06903076
  -0.0226593  -0.04101562  0.08679199  0.01620483  0.15759277 -0.07458496
  -0.20605469  0.00097656  0.04428101 -0.23022461 -0.08642578 -0.10888672
   0.04818726 -0.05371094 -0.06115723  0.15661621 -0.02807617 -0.08349609
   0.11547852  0.03671265  0.0266571  -0.07128906  0.01194763  0.03747559
  -0.00045776  0.02313232 -0.16162109  0.18652344  0.03137207  0.09368896
  -0.07446289  0.0254364  -0.09490967  0.03631592 -0.26025391  0.13415527
  -0.00778198  0.00164795  0.02685547 -0.05792236 -0.03790283 -0.0480957
  -0.07312012 -0.2130127   0.03411865  0.26513672  0.28564453  0.11749268
   0.02813721 -0.0914917  -0.07012939 -0.00317383]]
After layer encoder_birnn_reverse_l0_t6_slice_output3 (1, 256) <class 'numpy.float16'> [[  6.94580078e-02   5.59387207e-02  -1.51824951e-02   7.15942383e-02
    3.17687988e-02   2.03491211e-01   9.31396484e-02   1.18957520e-01
    4.21386719e-01   1.25854492e-01  -6.08215332e-02   7.19604492e-02
    1.67968750e-01  -4.14428711e-02   5.12695312e-02   1.29394531e-01
   -6.21337891e-02  -9.61303711e-02   3.92456055e-02  -1.32751465e-02
   -4.59594727e-02  -1.37451172e-01   2.83203125e-01   1.09558105e-01
    4.78515625e-02   6.84814453e-02  -1.85699463e-02  -1.81732178e-02
   -1.06689453e-01   1.28173828e-02   1.14257812e-01   1.00708008e-01
    3.60717773e-02   3.27148438e-02  -1.94091797e-02  -5.31616211e-02
    1.11083984e-01  -1.14135742e-02   6.49414062e-02  -2.67333984e-02
    6.45141602e-02  -2.77404785e-02  -2.96020508e-03   6.71386719e-03
   -3.27758789e-02   3.64685059e-02   2.87475586e-02  -8.25195312e-02
    2.44140625e-02   1.21215820e-01   8.41064453e-02  -1.25122070e-02
   -8.70971680e-02   5.60913086e-02   1.58447266e-01  -1.09069824e-01
    1.55517578e-01   2.80761719e-02   2.96173096e-02  -1.18408203e-01
    7.37915039e-02   8.41674805e-02   2.64282227e-02   1.72363281e-01
   -5.80596924e-03  -5.56640625e-02   2.09228516e-01   6.15844727e-02
   -9.70458984e-03   6.73217773e-02   1.62506104e-02   3.25927734e-02
    3.66210938e-04  -1.77001953e-02   1.28173828e-01   1.93359375e-01
    1.50146484e-01   4.02221680e-02   1.28784180e-01   2.16918945e-01
    1.81152344e-01   2.04589844e-01   1.08398438e-01   1.09252930e-01
    1.68701172e-01   5.29174805e-02   3.90930176e-02   8.50830078e-02
    8.27636719e-02   4.90722656e-02   1.68945312e-01  -4.80651855e-02
   -9.31396484e-02   2.71453857e-02   4.06494141e-02   2.97698975e-02
    5.74951172e-02   8.41674805e-02  -1.47094727e-01  -1.20239258e-01
   -6.07299805e-02  -1.49414062e-01  -8.56323242e-02  -9.41162109e-02
   -2.75878906e-02   6.71386719e-03  -4.14733887e-02   1.30859375e-01
    6.25000000e-02   1.19445801e-01   1.66015625e-02   5.74951172e-02
   -9.00878906e-02   1.47705078e-01  -1.06811523e-03   1.57714844e-01
   -7.53173828e-02  -2.93579102e-02   4.81567383e-02  -5.57556152e-02
    3.13415527e-02   9.50927734e-02   8.11767578e-02   9.76562500e-04
   -6.25610352e-02   3.72009277e-02  -3.93676758e-03   1.77001953e-03
   -1.81274414e-02  -1.10351562e-01   2.07519531e-02   1.84814453e-01
   -2.33917236e-02   1.06933594e-01   4.86755371e-02  -8.31909180e-02
    1.37939453e-01   5.57556152e-02   1.30004883e-01   3.60107422e-02
    1.93481445e-02  -8.57543945e-03  -7.18383789e-02   8.15429688e-02
   -9.89532471e-03   2.91137695e-02   1.69189453e-01   7.78808594e-02
    3.25317383e-02  -1.78833008e-02  -2.27050781e-02  -3.00750732e-02
    8.03222656e-02   1.37695312e-01  -1.79443359e-02   7.45849609e-02
    1.07177734e-01   9.55200195e-02   4.00390625e-02   1.42333984e-01
    8.35571289e-02   3.81164551e-02  -2.92968750e-03   1.38793945e-01
    8.48999023e-02  -8.42285156e-02   2.85156250e-01   1.14562988e-01
   -1.43310547e-01   2.27203369e-02  -1.16210938e-01   1.19995117e-01
    9.42382812e-02   2.15820312e-01   1.03759766e-02   1.81152344e-01
    1.54541016e-01  -6.71386719e-02   7.18994141e-02  -1.84020996e-02
   -1.25366211e-01  -8.23364258e-02   5.41381836e-02  -8.71582031e-02
   -6.45141602e-02   1.48193359e-01  -2.67791748e-02   1.12670898e-01
   -3.61938477e-02  -1.20361328e-01   1.37329102e-02   1.45751953e-01
    5.51757812e-02   2.38647461e-02  -2.39257812e-02   6.50024414e-02
   -3.43933105e-02   4.49829102e-02   1.18591309e-01   2.49633789e-02
    8.32519531e-02   2.16918945e-01   9.32617188e-02   1.57104492e-01
    9.44213867e-02   9.38720703e-02  -8.39233398e-02   5.43518066e-02
   -1.09008789e-01   1.75415039e-01   1.46484375e-03   3.05664062e-01
    6.86645508e-02   1.62231445e-01   1.06140137e-01  -6.21337891e-02
    5.75256348e-02   2.08007812e-01  -3.44848633e-02  -5.61218262e-02
   -3.67431641e-02  -1.54296875e-01   1.62353516e-01   2.99835205e-02
    7.29980469e-02   1.02172852e-01  -1.67846680e-03   4.31213379e-02
    3.41796875e-01   1.73706055e-01   1.31683350e-02  -1.56250000e-01
   -2.99377441e-02   7.47680664e-03  -2.02941895e-02   2.85797119e-02
   -2.94799805e-02   8.28247070e-02   1.17553711e-01   4.26330566e-02
   -1.52343750e-01   8.80737305e-02   8.01391602e-02   3.23486328e-01
   -1.44531250e-01   6.07910156e-02   3.84521484e-03  -1.41967773e-01
    4.14733887e-02  -2.28424072e-02   1.13769531e-01  -9.57031250e-02
    1.12060547e-01   1.40991211e-01  -6.04248047e-03   5.97229004e-02]]
After layer encoder_birnn_reverse_l0_t6_o_output (1, 256) <class 'numpy.float16'> [[ 0.51757812  0.51416016  0.49609375  0.51806641  0.5078125   0.55078125
   0.5234375   0.52978516  0.60400391  0.53125     0.48486328  0.51806641
   0.54199219  0.48974609  0.51269531  0.53222656  0.484375    0.47607422
   0.50976562  0.49658203  0.48852539  0.46557617  0.5703125   0.52734375
   0.51171875  0.51708984  0.49536133  0.49536133  0.47338867  0.50341797
   0.52832031  0.52539062  0.50878906  0.50830078  0.49511719  0.48681641
   0.52783203  0.49707031  0.51611328  0.4934082   0.51611328  0.49316406
   0.49926758  0.50146484  0.49169922  0.50927734  0.50732422  0.47949219
   0.50585938  0.53027344  0.52099609  0.49682617  0.47827148  0.51416016
   0.53955078  0.47265625  0.53857422  0.50683594  0.50732422  0.47045898
   0.51855469  0.52099609  0.50683594  0.54296875  0.49853516  0.48608398
   0.55224609  0.515625    0.49755859  0.51660156  0.50390625  0.50830078
   0.5         0.49560547  0.53222656  0.54833984  0.53759766  0.51025391
   0.53222656  0.55419922  0.54492188  0.55078125  0.52685547  0.52734375
   0.54199219  0.51318359  0.50976562  0.52148438  0.52050781  0.51220703
   0.54199219  0.48803711  0.47680664  0.50683594  0.51025391  0.50732422
   0.51416016  0.52099609  0.46337891  0.4699707   0.48486328  0.46264648
   0.47851562  0.4765625   0.49316406  0.50146484  0.48974609  0.53271484
   0.515625    0.52978516  0.50390625  0.51416016  0.47753906  0.53662109
   0.49975586  0.53955078  0.48120117  0.49267578  0.51220703  0.48608398
   0.5078125   0.52392578  0.52050781  0.5         0.484375    0.50927734
   0.49902344  0.50048828  0.49536133  0.47241211  0.50537109  0.54589844
   0.49414062  0.52685547  0.51220703  0.47924805  0.53466797  0.51416016
   0.53222656  0.50878906  0.50488281  0.49780273  0.48193359  0.52050781
   0.49755859  0.50732422  0.54199219  0.51953125  0.50830078  0.49560547
   0.49438477  0.49243164  0.52001953  0.53417969  0.49560547  0.51855469
   0.52685547  0.52392578  0.50976562  0.53564453  0.52099609  0.50976562
   0.49926758  0.53466797  0.52099609  0.47900391  0.57080078  0.52880859
   0.46435547  0.50585938  0.47094727  0.52978516  0.5234375   0.55371094
   0.50244141  0.54492188  0.53857422  0.4831543   0.51806641  0.49536133
   0.46875     0.47949219  0.51367188  0.47827148  0.48388672  0.53710938
   0.4934082   0.52832031  0.4909668   0.4699707   0.50341797  0.53613281
   0.51367188  0.50585938  0.49414062  0.51611328  0.49145508  0.51123047
   0.52978516  0.50634766  0.52099609  0.55419922  0.5234375   0.5390625
   0.5234375   0.5234375   0.47900391  0.51367188  0.47265625  0.54394531
   0.50048828  0.57568359  0.51708984  0.54052734  0.52636719  0.484375
   0.51416016  0.55175781  0.49145508  0.48608398  0.49072266  0.46142578
   0.54052734  0.50732422  0.51806641  0.52539062  0.49951172  0.51074219
   0.58447266  0.54345703  0.50341797  0.4609375   0.49243164  0.50195312
   0.49487305  0.50732422  0.49267578  0.52050781  0.52929688  0.51074219
   0.46191406  0.52197266  0.52001953  0.58007812  0.46386719  0.51513672
   0.50097656  0.46459961  0.51025391  0.49438477  0.52832031  0.47607422
   0.52783203  0.53515625  0.49853516  0.51513672]]
After layer encoder_birnn_reverse_l0_t6_f_output (1, 256) <class 'numpy.float16'> [[ 0.53857422  0.50927734  0.52685547  0.51123047  0.50146484  0.52001953
   0.54736328  0.47485352  0.59326172  0.54150391  0.53076172  0.53417969
   0.53027344  0.4987793   0.53125     0.53417969  0.52197266  0.49121094
   0.46264648  0.51953125  0.53466797  0.50488281  0.59960938  0.515625
   0.53076172  0.51904297  0.53955078  0.52050781  0.53076172  0.51025391
   0.52099609  0.50878906  0.55957031  0.4855957   0.49731445  0.49511719
   0.48583984  0.53369141  0.50585938  0.52246094  0.48022461  0.52783203
   0.50390625  0.52441406  0.51025391  0.52978516  0.50878906  0.46875
   0.49755859  0.50488281  0.51757812  0.52441406  0.49121094  0.53759766
   0.51513672  0.51318359  0.51269531  0.52539062  0.49902344  0.47460938
   0.52392578  0.51025391  0.51806641  0.50732422  0.49365234  0.53710938
   0.55322266  0.51855469  0.46362305  0.48828125  0.51708984  0.50048828
   0.48706055  0.50976562  0.52734375  0.54101562  0.51660156  0.51660156
   0.52490234  0.52246094  0.55566406  0.546875    0.50927734  0.5078125
   0.54541016  0.49804688  0.52294922  0.54296875  0.50976562  0.45922852
   0.58105469  0.52099609  0.52001953  0.51806641  0.48388672  0.50292969
   0.49902344  0.51416016  0.45556641  0.45532227  0.48095703  0.49829102
   0.51123047  0.52734375  0.49536133  0.49169922  0.47290039  0.51611328
   0.5234375   0.46923828  0.50976562  0.4934082   0.515625    0.55224609
   0.52441406  0.54980469  0.52929688  0.53369141  0.51367188  0.52832031
   0.55078125  0.54296875  0.51123047  0.50439453  0.4921875   0.49804688
   0.54443359  0.49853516  0.52636719  0.47216797  0.53320312  0.53076172
   0.50390625  0.54443359  0.51416016  0.51220703  0.50585938  0.51513672
   0.53417969  0.55419922  0.48144531  0.51123047  0.51904297  0.5078125
   0.51171875  0.53271484  0.5234375   0.51074219  0.51269531  0.49291992
   0.49316406  0.51953125  0.51123047  0.52490234  0.49731445  0.54638672
   0.52490234  0.48828125  0.515625    0.53857422  0.55664062  0.52246094
   0.49169922  0.5234375   0.52294922  0.49560547  0.56982422  0.49243164
   0.49829102  0.49487305  0.50634766  0.53320312  0.49487305  0.55322266
   0.48486328  0.53173828  0.54296875  0.49389648  0.50244141  0.52880859
   0.52050781  0.48168945  0.56005859  0.4909668   0.49902344  0.50732422
   0.50878906  0.55078125  0.48999023  0.48242188  0.4909668   0.51123047
   0.54589844  0.53955078  0.46972656  0.50146484  0.49902344  0.49560547
   0.5078125   0.50537109  0.51416016  0.51123047  0.51953125  0.4934082
   0.52832031  0.46484375  0.48730469  0.54101562  0.48071289  0.52636719
   0.52001953  0.52636719  0.48681641  0.5078125   0.49658203  0.47509766
   0.515625    0.52490234  0.4934082   0.53076172  0.4753418   0.47924805
   0.56445312  0.50244141  0.52392578  0.49951172  0.50585938  0.51416016
   0.59570312  0.55029297  0.50927734  0.42822266  0.5390625   0.50927734
   0.51806641  0.4987793   0.50146484  0.52197266  0.51367188  0.52392578
   0.51708984  0.51367188  0.50146484  0.5546875   0.46044922  0.49633789
   0.48046875  0.48681641  0.52783203  0.49243164  0.54394531  0.45410156
   0.5390625   0.49804688  0.53417969  0.50048828]]
After layer _mul2084_0 (1, 256) <class 'numpy.float16'> [[-0.08258057 -0.06738281 -0.00895691  0.02207947  0.01844788 -0.0307312
   0.01800537  0.03662109  0.04037476 -0.06384277 -0.04211426  0.08068848
   0.05026245 -0.01353455  0.03747559 -0.14038086  0.03405762  0.01132965
   0.03851318  0.0280304   0.11920166 -0.03092957 -0.00381088  0.02905273
  -0.06365967  0.01683044  0.02732849 -0.02572632 -0.0770874  -0.0562439
   0.0224762  -0.06057739 -0.0039711   0.00227165  0.05895996 -0.06866455
  -0.02937317 -0.00310707 -0.05801392 -0.05236816  0.01242828 -0.1038208
   0.06109619  0.04977417  0.04751587 -0.06155396  0.02386475 -0.02975464
  -0.0068779  -0.04916382  0.0340271  -0.06964111 -0.03649902  0.08343506
   0.01545715  0.01081848 -0.01545715  0.1036377   0.05026245 -0.02250671
  -0.05429077 -0.04879761 -0.01321411 -0.01119995  0.034729   -0.0209198
   0.02340698 -0.05297852 -0.04544067 -0.00374222 -0.14074707  0.0098114
   0.02270508  0.01209259  0.07208252 -0.02037048 -0.02850342 -0.10894775
  -0.03839111 -0.02320862 -0.07208252  0.00734711 -0.04782104 -0.08599854
  -0.15661621  0.00611115 -0.06072998  0.01439667 -0.0927124  -0.0506897
  -0.07348633 -0.03018188 -0.01425171 -0.00399399 -0.02436829  0.02560425
   0.04537964 -0.02526855 -0.04156494 -0.03646851  0.00984192  0.07177734
  -0.0369873   0.02590942  0.02780151  0.07806396 -0.0202179  -0.021698
   0.08642578 -0.08685303  0.05126953 -0.00144005  0.04278564  0.06494141
  -0.04879761  0.171875   -0.08630371 -0.04766846  0.02076721 -0.03366089
   0.10461426  0.0397644  -0.00802612 -0.05136108  0.04904175 -0.09063721
  -0.05862427 -0.03979492 -0.02444458 -0.00964355  0.05670166 -0.01763916
   0.03881836  0.00102901  0.00191784  0.03662109  0.04501343  0.11981201
  -0.00183105  0.03918457 -0.00234032 -0.02362061  0.07678223  0.01164246
  -0.0456543   0.05560303  0.04077148 -0.05841064 -0.04907227 -0.06341553
  -0.0329895  -0.01432037 -0.0355835  -0.04067993 -0.00305748  0.04782104
  -0.06738281  0.01506805  0.02766418  0.04077148 -0.14660645 -0.03543091
   0.01184082  0.08154297  0.01809692  0.04644775  0.00845337 -0.02337646
  -0.10290527  0.00581741 -0.05267334  0.03213501 -0.01719666 -0.09051514
  -0.01373291  0.03863525  0.09051514 -0.02493286 -0.02940369 -0.0147171
   0.03991699  0.00745773  0.02629089 -0.01803589 -0.03292847  0.02429199
   0.02496338 -0.06365967  0.04574585 -0.06149292  0.09796143 -0.005867
  -0.00507736  0.01600647 -0.10144043 -0.00088167 -0.11328125 -0.04598999
  -0.01676941  0.03918457 -0.0847168  -0.0223999   0.09857178 -0.0296936
  -0.0087738  -0.01327515  0.03439331  0.00654602  0.06008911 -0.04446411
  -0.09051514  0.00202942  0.01565552 -0.09436035 -0.03256226 -0.04205322
   0.01727295 -0.0223999  -0.01885986  0.06842041 -0.01341248 -0.03771973
   0.05343628  0.01119232  0.00693512 -0.02914429  0.00392914  0.01698303
   0.01756287  0.00031066 -0.07312012  0.06204224  0.02401733  0.04425049
  -0.03692627  0.01707458 -0.04766846  0.01312256 -0.10186768  0.0657959
   0.00516891 -0.0060997   0.01413727 -0.03662109 -0.01594543 -0.02932739
  -0.02764893 -0.07977295  0.01049805  0.11102295  0.12988281  0.04483032
   0.02342224 -0.03866577 -0.03005981 -0.0055275 ]]
After layer encoder_birnn_reverse_l0_t6_i_output (1, 256) <class 'numpy.float16'> [[ 0.49658203  0.49389648  0.49145508  0.49389648  0.50341797  0.4934082
   0.50244141  0.50292969  0.52490234  0.51660156  0.48901367  0.52539062
   0.50244141  0.50585938  0.49975586  0.57324219  0.46899414  0.47924805
   0.50292969  0.49707031  0.52490234  0.50146484  0.46899414  0.48754883
   0.51708984  0.46777344  0.49145508  0.49707031  0.50195312  0.49462891
   0.49902344  0.49682617  0.48632812  0.48876953  0.52001953  0.46166992
   0.49584961  0.49658203  0.47875977  0.48168945  0.46411133  0.50634766
   0.48730469  0.50097656  0.5078125   0.49560547  0.51708984  0.47900391
   0.48999023  0.50683594  0.50537109  0.52685547  0.46435547  0.51953125
   0.54443359  0.52880859  0.48217773  0.50390625  0.47949219  0.49536133
   0.52099609  0.4855957   0.53955078  0.49291992  0.47119141  0.48950195
   0.52685547  0.49414062  0.47705078  0.50048828  0.52636719  0.49487305
   0.49633789  0.49389648  0.50341797  0.51416016  0.53027344  0.54101562
   0.50878906  0.51367188  0.50585938  0.51171875  0.52197266  0.49414062
   0.54199219  0.51074219  0.4934082   0.48144531  0.49511719  0.51513672
   0.52880859  0.49902344  0.47875977  0.51953125  0.51757812  0.50878906
   0.49243164  0.51123047  0.47241211  0.46801758  0.47192383  0.51953125
   0.50390625  0.4699707   0.47167969  0.50244141  0.49291992  0.47241211
   0.51660156  0.50390625  0.47241211  0.50048828  0.50732422  0.55615234
   0.50341797  0.57666016  0.49194336  0.50195312  0.50097656  0.48681641
   0.55322266  0.46801758  0.49926758  0.52490234  0.48217773  0.51660156
   0.46582031  0.51953125  0.49291992  0.50195312  0.55371094  0.51367188
   0.49780273  0.48779297  0.47949219  0.47509766  0.52783203  0.54052734
   0.49584961  0.49658203  0.48950195  0.46875     0.5234375   0.51464844
   0.49389648  0.49975586  0.50878906  0.515625    0.49682617  0.51660156
   0.53076172  0.48339844  0.49975586  0.4765625   0.47509766  0.54882812
   0.50683594  0.50683594  0.49438477  0.49194336  0.55615234  0.50097656
   0.4831543   0.50537109  0.50195312  0.48095703  0.49951172  0.48657227
   0.50878906  0.48779297  0.49853516  0.51074219  0.50048828  0.52587891
   0.50537109  0.45947266  0.50976562  0.4675293   0.48486328  0.49438477
   0.51269531  0.48168945  0.49804688  0.50634766  0.52490234  0.49560547
   0.49560547  0.4855957   0.52539062  0.51025391  0.48901367  0.49023438
   0.50927734  0.48681641  0.49536133  0.52246094  0.52539062  0.45678711
   0.51074219  0.52099609  0.50244141  0.52636719  0.51904297  0.515625
   0.50341797  0.49145508  0.49780273  0.48657227  0.48120117  0.51074219
   0.51171875  0.52978516  0.50537109  0.51269531  0.4987793   0.50048828
   0.49829102  0.49462891  0.5078125   0.49926758  0.48413086  0.4753418
   0.52441406  0.48046875  0.50097656  0.515625    0.49243164  0.47436523
   0.47290039  0.52539062  0.49682617  0.46655273  0.49487305  0.48657227
   0.50683594  0.51513672  0.49853516  0.52050781  0.5078125   0.4909668
   0.47119141  0.46386719  0.5234375   0.55908203  0.484375    0.50488281
   0.47583008  0.48022461  0.50341797  0.49829102  0.54052734  0.49707031
   0.47143555  0.51269531  0.51367188  0.49829102]]
After layer encoder_birnn_reverse_l0_t6_c_output (1, 256) <class 'numpy.float16'> [[-0.1628418  -0.14807129 -0.03695679  0.05822754  0.01989746 -0.06262207
   0.01104736  0.06896973  0.08837891 -0.1505127  -0.08874512  0.1907959
   0.10388184 -0.01383972  0.08135986 -0.26782227  0.09051514  0.03192139
   0.10852051  0.06149292  0.25488281 -0.0791626  -0.02804565  0.04055786
  -0.13305664  0.03414917  0.05303955 -0.05892944 -0.1595459  -0.13427734
   0.04959106 -0.11883545  0.00378418  0.0020752   0.13684082 -0.16638184
  -0.05874634  0.00675583 -0.12744141 -0.12084961  0.01794434 -0.22180176
   0.13989258  0.11340332  0.10180664 -0.1315918   0.06323242 -0.07116699
  -0.02122498 -0.11712646  0.07489014 -0.15185547 -0.07635498  0.20458984
  -0.00378418  0.01222992 -0.01399231  0.22875977  0.13818359 -0.05099487
  -0.13293457 -0.10272217 -0.015625   -0.03756714  0.08978271 -0.04562378
   0.03105164 -0.12414551 -0.1081543   0.00958252 -0.30297852  0.0362854
   0.03117371  0.02409363  0.15332031 -0.01789856 -0.07312012 -0.24816895
  -0.09448242 -0.05661011 -0.15307617  0.00546265 -0.11322021 -0.20263672
  -0.30834961  0.00411987 -0.0927124   0.0062561  -0.22827148 -0.10699463
  -0.13757324 -0.06011963 -0.03393555  0.00897217 -0.05731201  0.06726074
   0.09625244 -0.04812622 -0.1048584  -0.11968994  0.00970459  0.16210938
  -0.07965088  0.06488037  0.07427979  0.20800781 -0.04907227 -0.03643799
   0.18908691 -0.21972656  0.14367676 -0.02288818  0.11553955  0.14001465
  -0.09118652  0.31201172 -0.20117188 -0.11236572  0.02423096 -0.07830811
   0.20373535  0.06286621 -0.00167847 -0.12036133  0.10009766 -0.20202637
  -0.13781738 -0.09643555 -0.05444336 -0.02307129  0.13439941 -0.015625
   0.0836792   0.00950623 -0.00228882  0.07879639  0.08123779  0.25830078
   0.00467682  0.08166504 -0.00244141 -0.04711914  0.16821289  0.02618408
  -0.09674072  0.12512207  0.10058594 -0.1126709  -0.10931396 -0.15612793
  -0.08184814 -0.02986145 -0.09899902 -0.07733154 -0.00418091  0.10028076
  -0.14855957  0.003479    0.05905151  0.09197998 -0.28295898 -0.05944824
   0.02101135  0.16503906  0.04376221  0.10534668  0.00899506 -0.03543091
  -0.25830078  0.01144409 -0.12597656  0.08709717 -0.03369141 -0.16687012
  -0.04476929  0.08331299  0.18457031 -0.0647583  -0.05587769 -0.01463318
   0.07904053  0.0269165   0.06204224 -0.04550171 -0.08764648  0.03509521
   0.06054688 -0.13244629  0.07696533 -0.13366699  0.24926758 -0.00918579
  -0.02163696  0.05047607 -0.26879883  0.00119019 -0.26196289 -0.11901855
  -0.03436279  0.10699463 -0.19970703 -0.06195068  0.20800781 -0.06890869
  -0.0226593  -0.04098511  0.08654785  0.01620483  0.15625    -0.07446289
  -0.20324707  0.00097656  0.04425049 -0.22619629 -0.08618164 -0.10845947
   0.04815674 -0.0536499  -0.06109619  0.15539551 -0.02807617 -0.08331299
   0.11499023  0.03668213  0.0266571  -0.07116699  0.01194763  0.03744507
  -0.00045776  0.02313232 -0.16027832  0.18444824  0.03137207  0.09344482
  -0.07434082  0.0254364  -0.09460449  0.0362854  -0.25463867  0.13330078
  -0.00778198  0.00164795  0.02685547 -0.05786133 -0.03787231 -0.04806519
  -0.07299805 -0.20983887  0.03411865  0.2590332   0.27807617  0.11694336
   0.02813721 -0.09124756 -0.07000732 -0.00317383]]
After layer _mul2085_0 (1, 256) <class 'numpy.float16'> [[-0.08087158 -0.07312012 -0.01815796  0.02876282  0.0100174  -0.03089905
   0.00555038  0.03469849  0.04638672 -0.07775879 -0.043396    0.10021973
   0.05218506 -0.00699997  0.04064941 -0.15356445  0.04244995  0.01529694
   0.05456543  0.03056335  0.13378906 -0.03970337 -0.01315308  0.01977539
  -0.06878662  0.01597595  0.02606201 -0.02929688 -0.08007812 -0.06640625
   0.02474976 -0.05905151  0.00184059  0.00101471  0.07116699 -0.07684326
  -0.02912903  0.00335503 -0.06100464 -0.05819702  0.0083313  -0.11230469
   0.06817627  0.05682373  0.05169678 -0.06524658  0.03268433 -0.03408813
  -0.01039886 -0.05935669  0.0378418  -0.08001709 -0.03546143  0.10626221
  -0.00205994  0.00646591 -0.0067482   0.11529541  0.06628418 -0.0252533
  -0.0692749  -0.04989624 -0.00843048 -0.01852417  0.04229736 -0.02233887
   0.01635742 -0.06134033 -0.05160522  0.00479507 -0.15942383  0.01795959
   0.01547241  0.01190186  0.07720947 -0.00920105 -0.03878784 -0.13427734
  -0.04806519 -0.02908325 -0.07745361  0.00279617 -0.05911255 -0.10015869
  -0.16711426  0.00210381 -0.04574585  0.0030117  -0.11303711 -0.05511475
  -0.07275391 -0.02999878 -0.01625061  0.00466156 -0.02966309  0.03421021
   0.0473938  -0.02459717 -0.04953003 -0.05603027  0.00458145  0.08422852
  -0.04013062  0.03048706  0.03503418  0.10449219 -0.02418518 -0.01721191
   0.09765625 -0.11071777  0.06787109 -0.01145172  0.05862427  0.07788086
  -0.04589844  0.17993164 -0.09893799 -0.05639648  0.01213837 -0.03811646
   0.11273193  0.02941895 -0.0008378  -0.06317139  0.04827881 -0.10437012
  -0.06420898 -0.05010986 -0.02684021 -0.01158142  0.07440186 -0.00802612
   0.04165649  0.00463867 -0.00109768  0.03744507  0.0428772   0.13964844
   0.00231934  0.04055786 -0.00119495 -0.02209473  0.08807373  0.01347351
  -0.04779053  0.0625      0.05117798 -0.05810547 -0.05432129 -0.08062744
  -0.04345703 -0.01443481 -0.04946899 -0.03686523 -0.00198555  0.05502319
  -0.07531738  0.00176334  0.02919006  0.04525757 -0.15734863 -0.02978516
   0.01015472  0.08343506  0.02197266  0.05065918  0.00449371 -0.01724243
  -0.13146973  0.0055809  -0.06280518  0.04449463 -0.01686096 -0.08776855
  -0.02262878  0.03826904  0.09411621 -0.03027344 -0.02709961 -0.00723267
   0.04052734  0.01296234  0.03089905 -0.02304077 -0.04602051  0.01739502
   0.03001404 -0.06433105  0.04043579 -0.06817627  0.12188721 -0.00450134
  -0.01101685  0.02456665 -0.13317871  0.0006218  -0.13757324 -0.05435181
  -0.01754761  0.05575562 -0.1003418  -0.03262329  0.10797119 -0.03552246
  -0.01140594 -0.0201416   0.04309082  0.00788116  0.07519531 -0.0380249
  -0.10400391  0.00051737  0.02236938 -0.1159668  -0.04299927 -0.05429077
   0.02400208 -0.02653503 -0.03102112  0.07757568 -0.01359558 -0.03961182
   0.06030273  0.0176239   0.01335144 -0.03668213  0.00588226  0.01776123
  -0.00021648  0.01215363 -0.07965088  0.08605957  0.01552582  0.04547119
  -0.03768921  0.01309967 -0.04714966  0.01889038 -0.12927246  0.06542969
  -0.00366592  0.00076437  0.01405334 -0.03234863 -0.01834106 -0.02426147
  -0.034729   -0.10076904  0.0171814   0.12902832  0.15026855  0.05813599
   0.01326752 -0.04678345 -0.03594971 -0.00158119]]
After layer encoder_birnn_reverse_l0_t6_state_0 (1, 256) <class 'numpy.float16'> [[ -1.63452148e-01  -1.40502930e-01  -2.71148682e-02   5.08422852e-02
    2.84729004e-02  -6.16455078e-02   2.35595703e-02   7.12890625e-02
    8.67919922e-02  -1.41601562e-01  -8.55102539e-02   1.80908203e-01
    1.02416992e-01  -2.05383301e-02   7.81250000e-02  -2.93945312e-01
    7.65380859e-02   2.66265869e-02   9.30786133e-02   5.85937500e-02
    2.52929688e-01  -7.06176758e-02  -1.69677734e-02   4.88281250e-02
   -1.32446289e-01   3.28063965e-02   5.34057617e-02  -5.50231934e-02
   -1.57226562e-01  -1.22680664e-01   4.72412109e-02  -1.19628906e-01
   -2.13050842e-03   3.28636169e-03   1.30126953e-01  -1.45507812e-01
   -5.85021973e-02   2.47955322e-04  -1.19018555e-01  -1.10595703e-01
    2.07519531e-02  -2.16064453e-01   1.29272461e-01   1.06567383e-01
    9.92431641e-02  -1.26831055e-01   5.65490723e-02  -6.38427734e-02
   -1.72729492e-02  -1.08520508e-01   7.18994141e-02  -1.49658203e-01
   -7.19604492e-02   1.89697266e-01   1.33972168e-02   1.72882080e-02
   -2.22015381e-02   2.18994141e-01   1.16577148e-01  -4.77600098e-02
   -1.23535156e-01  -9.86938477e-02  -2.16369629e-02  -2.97241211e-02
    7.70263672e-02  -4.32739258e-02   3.97644043e-02  -1.14318848e-01
   -9.70458984e-02   1.05285645e-03  -3.00292969e-01   2.77709961e-02
    3.81774902e-02   2.39868164e-02   1.49291992e-01  -2.95715332e-02
   -6.72607422e-02  -2.43164062e-01  -8.64257812e-02  -5.23071289e-02
   -1.49536133e-01   1.01470947e-02  -1.06933594e-01  -1.86157227e-01
   -3.23730469e-01   8.21685791e-03  -1.06445312e-01   1.74102783e-02
   -2.05810547e-01  -1.05834961e-01  -1.46240234e-01  -6.01806641e-02
   -3.05023193e-02   6.67572021e-04  -5.40161133e-02   5.98144531e-02
    9.27734375e-02  -4.98657227e-02  -9.10644531e-02  -9.25292969e-02
    1.44195557e-02   1.56005859e-01  -7.71484375e-02   5.63964844e-02
    6.28662109e-02   1.82617188e-01  -4.44030762e-02  -3.89099121e-02
    1.84082031e-01  -1.97509766e-01   1.19140625e-01  -1.28936768e-02
    1.01440430e-01   1.42822266e-01  -9.47265625e-02   3.51806641e-01
   -1.85302734e-01  -1.04064941e-01   3.28979492e-02  -7.17773438e-02
    2.17285156e-01   6.92138672e-02  -8.86535645e-03  -1.14501953e-01
    9.72900391e-02  -1.95068359e-01  -1.22802734e-01  -8.99047852e-02
   -5.12695312e-02  -2.12249756e-02   1.31103516e-01  -2.56652832e-02
    8.04443359e-02   5.66864014e-03   8.20159912e-04   7.40966797e-02
    8.78906250e-02   2.59521484e-01   4.88281250e-04   7.97119141e-02
   -3.53622437e-03  -4.57153320e-02   1.64794922e-01   2.51159668e-02
   -9.34448242e-02   1.18103027e-01   9.19189453e-02  -1.16516113e-01
   -1.03393555e-01  -1.44042969e-01  -7.64160156e-02  -2.87475586e-02
   -8.50830078e-02  -7.75146484e-02  -5.04302979e-03   1.02844238e-01
   -1.42700195e-01   1.68304443e-02   5.68542480e-02   8.60595703e-02
   -3.03955078e-01  -6.51855469e-02   2.20031738e-02   1.65039062e-01
    4.00695801e-02   9.71069336e-02   1.29470825e-02  -4.06188965e-02
   -2.34375000e-01   1.13983154e-02  -1.15478516e-01   7.66601562e-02
   -3.40576172e-02  -1.78222656e-01  -3.63769531e-02   7.69042969e-02
    1.84570312e-01  -5.52062988e-02  -5.65185547e-02  -2.19421387e-02
    8.04443359e-02   2.04162598e-02   5.71899414e-02  -4.10766602e-02
   -7.89794922e-02   4.16870117e-02   5.49926758e-02  -1.27929688e-01
    8.61816406e-02  -1.29638672e-01   2.19848633e-01  -1.03683472e-02
   -1.60980225e-02   4.05883789e-02  -2.34619141e-01  -2.59876251e-04
   -2.50976562e-01  -1.00341797e-01  -3.43017578e-02   9.49707031e-02
   -1.85058594e-01  -5.50231934e-02   2.06542969e-01  -6.51855469e-02
   -2.01721191e-02  -3.34167480e-02   7.75146484e-02   1.44271851e-02
    1.35253906e-01  -8.25195312e-02  -1.94580078e-01   2.54631042e-03
    3.80249023e-02  -2.10327148e-01  -7.55615234e-02  -9.63134766e-02
    4.12597656e-02  -4.89501953e-02  -4.98657227e-02   1.45996094e-01
   -2.70080566e-02  -7.73315430e-02   1.13769531e-01   2.88085938e-02
    2.02941895e-02  -6.57958984e-02   9.81140137e-03   3.47290039e-02
    1.73492432e-02   1.24664307e-02  -1.52832031e-01   1.48071289e-01
    3.95507812e-02   8.97216797e-02  -7.45849609e-02   3.01818848e-02
   -9.48486328e-02   3.20129395e-02  -2.31201172e-01   1.31225586e-01
    1.50299072e-03  -5.33676147e-03   2.81982422e-02  -6.89697266e-02
   -3.43017578e-02  -5.35888672e-02  -6.23779297e-02  -1.80541992e-01
    2.76794434e-02   2.39990234e-01   2.80273438e-01   1.02966309e-01
    3.66821289e-02  -8.54492188e-02  -6.60400391e-02  -7.11059570e-03]]
After layer activation1042_output (1, 256) <class 'numpy.float16'> [[ -1.61987305e-01  -1.39526367e-01  -2.71148682e-02   5.08117676e-02
    2.84576416e-02  -6.15539551e-02   2.35595703e-02   7.11669922e-02
    8.65478516e-02  -1.40625000e-01  -8.53271484e-02   1.78955078e-01
    1.02050781e-01  -2.05383301e-02   7.79418945e-02  -2.85644531e-01
    7.64160156e-02   2.66265869e-02   9.28344727e-02   5.85327148e-02
    2.47680664e-01  -7.04956055e-02  -1.69677734e-02   4.87976074e-02
   -1.31713867e-01   3.28063965e-02   5.33447266e-02  -5.49621582e-02
   -1.55883789e-01  -1.22070312e-01   4.72106934e-02  -1.19079590e-01
   -2.13050842e-03   3.28636169e-03   1.29394531e-01  -1.44531250e-01
   -5.84411621e-02   2.47955322e-04  -1.18469238e-01  -1.10168457e-01
    2.07519531e-02  -2.12768555e-01   1.28540039e-01   1.06140137e-01
    9.89379883e-02  -1.26098633e-01   5.64880371e-02  -6.37817383e-02
   -1.72729492e-02  -1.08093262e-01   7.17773438e-02  -1.48559570e-01
   -7.18383789e-02   1.87500000e-01   1.33972168e-02   1.72882080e-02
   -2.22015381e-02   2.15576172e-01   1.16027832e-01  -4.77294922e-02
   -1.22924805e-01  -9.83886719e-02  -2.16369629e-02  -2.97088623e-02
    7.69042969e-02  -4.32434082e-02   3.97338867e-02  -1.13830566e-01
   -9.67407227e-02   1.05285645e-03  -2.91503906e-01   2.77709961e-02
    3.81469727e-02   2.39868164e-02   1.48193359e-01  -2.95562744e-02
   -6.71386719e-02  -2.38525391e-01  -8.61816406e-02  -5.22460938e-02
   -1.48437500e-01   1.01470947e-02  -1.06506348e-01  -1.84082031e-01
   -3.12988281e-01   8.21685791e-03  -1.06018066e-01   1.74102783e-02
   -2.03002930e-01  -1.05468750e-01  -1.45263672e-01  -6.01196289e-02
   -3.04870605e-02   6.67572021e-04  -5.39550781e-02   5.97534180e-02
    9.25292969e-02  -4.98352051e-02  -9.08203125e-02  -9.22851562e-02
    1.44195557e-02   1.54785156e-01  -7.69653320e-02   5.63354492e-02
    6.28051758e-02   1.80664062e-01  -4.43725586e-02  -3.88793945e-02
    1.82006836e-01  -1.94946289e-01   1.18591309e-01  -1.28936768e-02
    1.01074219e-01   1.41845703e-01  -9.44213867e-02   3.37890625e-01
   -1.83227539e-01  -1.03698730e-01   3.28979492e-02  -7.16552734e-02
    2.13989258e-01   6.90917969e-02  -8.86535645e-03  -1.14013672e-01
    9.69848633e-02  -1.92626953e-01  -1.22192383e-01  -8.96606445e-02
   -5.12390137e-02  -2.12249756e-02   1.30371094e-01  -2.56652832e-02
    8.02612305e-02   5.66864014e-03   8.20159912e-04   7.39746094e-02
    8.76464844e-02   2.53906250e-01   4.88281250e-04   7.95288086e-02
   -3.53622437e-03  -4.56848145e-02   1.63330078e-01   2.51159668e-02
   -9.32006836e-02   1.17553711e-01   9.16748047e-02  -1.15966797e-01
   -1.03027344e-01  -1.43066406e-01  -7.62939453e-02  -2.87322998e-02
   -8.48999023e-02  -7.73315430e-02  -5.04302979e-03   1.02478027e-01
   -1.41723633e-01   1.68304443e-02   5.67932129e-02   8.58764648e-02
   -2.94921875e-01  -6.50634766e-02   2.20031738e-02   1.63574219e-01
    4.00390625e-02   9.68017578e-02   1.29470825e-02  -4.05883789e-02
   -2.30224609e-01   1.13983154e-02  -1.14990234e-01   7.65380859e-02
   -3.40576172e-02  -1.76391602e-01  -3.63464355e-02   7.67822266e-02
    1.82495117e-01  -5.51452637e-02  -5.64575195e-02  -2.19421387e-02
    8.02612305e-02   2.04162598e-02   5.71289062e-02  -4.10461426e-02
   -7.87963867e-02   4.16564941e-02   5.49316406e-02  -1.27197266e-01
    8.59985352e-02  -1.28906250e-01   2.16430664e-01  -1.03683472e-02
   -1.60980225e-02   4.05578613e-02  -2.30346680e-01  -2.59876251e-04
   -2.45849609e-01  -1.00036621e-01  -3.43017578e-02   9.46655273e-02
   -1.82983398e-01  -5.49621582e-02   2.03613281e-01  -6.50634766e-02
   -2.01721191e-02  -3.34167480e-02   7.73315430e-02   1.44271851e-02
    1.34399414e-01  -8.23364258e-02  -1.92138672e-01   2.54631042e-03
    3.79943848e-02  -2.07275391e-01  -7.54394531e-02  -9.60083008e-02
    4.12292480e-02  -4.89196777e-02  -4.98352051e-02   1.45019531e-01
   -2.70080566e-02  -7.71484375e-02   1.13281250e-01   2.87933350e-02
    2.02941895e-02  -6.56738281e-02   9.81140137e-03   3.47290039e-02
    1.73492432e-02   1.24664307e-02  -1.51611328e-01   1.46972656e-01
    3.95202637e-02   8.94775391e-02  -7.44628906e-02   3.01666260e-02
   -9.45434570e-02   3.20129395e-02  -2.27172852e-01   1.30493164e-01
    1.50299072e-03  -5.33676147e-03   2.81982422e-02  -6.88476562e-02
   -3.43017578e-02  -5.35278320e-02  -6.22863770e-02  -1.78588867e-01
    2.76794434e-02   2.35473633e-01   2.73193359e-01   1.02600098e-01
    3.66516113e-02  -8.52661133e-02  -6.59179688e-02  -7.11059570e-03]]
After layer encoder_birnn_reverse_l0_t6_out_0 (1, 256) <class 'numpy.float16'> [[ -8.38623047e-02  -7.17163086e-02  -1.34506226e-02   2.63214111e-02
    1.44500732e-02  -3.39050293e-02   1.23291016e-02   3.76892090e-02
    5.22766113e-02  -7.47070312e-02  -4.13818359e-02   9.27124023e-02
    5.52978516e-02  -1.00555420e-02   3.99475098e-02  -1.51977539e-01
    3.70178223e-02   1.26724243e-02   4.73327637e-02   2.90679932e-02
    1.20971680e-01  -3.28063965e-02  -9.67407227e-03   2.57263184e-02
   -6.73828125e-02   1.69677734e-02   2.64282227e-02  -2.72216797e-02
   -7.37915039e-02  -6.14624023e-02   2.49481201e-02  -6.25610352e-02
   -1.08432770e-03   1.67083740e-03   6.40869141e-02  -7.03735352e-02
   -3.08532715e-02   1.23262405e-04  -6.11572266e-02  -5.43518066e-02
    1.07116699e-02  -1.04919434e-01   6.41479492e-02   5.32226562e-02
    4.86450195e-02  -6.42089844e-02   2.86560059e-02  -3.05786133e-02
   -8.73565674e-03  -5.73120117e-02   3.73840332e-02  -7.37915039e-02
   -3.43627930e-02   9.64355469e-02   7.22885132e-03   8.17108154e-03
   -1.19552612e-02   1.09252930e-01   5.88684082e-02  -2.24609375e-02
   -6.37207031e-02  -5.12695312e-02  -1.09634399e-02  -1.61285400e-02
    3.83300781e-02  -2.10266113e-02   2.19421387e-02  -5.86853027e-02
   -4.81262207e-02   5.44071198e-04  -1.46850586e-01   1.41143799e-02
    1.90734863e-02   1.18865967e-02   7.88574219e-02  -1.62048340e-02
   -3.61022949e-02  -1.21704102e-01  -4.58679199e-02  -2.89611816e-02
   -8.08715820e-02   5.58853149e-03  -5.61218262e-02  -9.70458984e-02
   -1.69677734e-01   4.21524048e-03  -5.40466309e-02   9.07897949e-03
   -1.05651855e-01  -5.40161133e-02  -7.87353516e-02  -2.93426514e-02
   -1.45339966e-02   3.38315964e-04  -2.75268555e-02   3.03192139e-02
    4.75769043e-02  -2.59704590e-02  -4.20837402e-02  -4.33654785e-02
    6.99234009e-03   7.15942383e-02  -3.68347168e-02   2.68402100e-02
    3.09753418e-02   9.05761719e-02  -2.17285156e-02  -2.07061768e-02
    9.38720703e-02  -1.03271484e-01   5.97534180e-02  -6.62994385e-03
    4.82788086e-02   7.61108398e-02  -4.71801758e-02   1.82250977e-01
   -8.81958008e-02  -5.10864258e-02   1.68457031e-02  -3.48205566e-02
    1.08642578e-01   3.61938477e-02  -4.61578369e-03  -5.70068359e-02
    4.69665527e-02  -9.80834961e-02  -6.09741211e-02  -4.48608398e-02
   -2.53753662e-02  -1.00250244e-02   6.58569336e-02  -1.40075684e-02
    3.96728516e-02   2.98690796e-03   4.20093536e-04   3.54614258e-02
    4.68750000e-02   1.30493164e-01   2.59876251e-04   4.04663086e-02
   -1.78527832e-03  -2.27355957e-02   7.87353516e-02   1.30767822e-02
   -4.63867188e-02   5.96313477e-02   4.96826172e-02  -6.02416992e-02
   -5.23681641e-02  -7.09228516e-02  -3.77197266e-02  -1.41448975e-02
   -4.41589355e-02  -4.13208008e-02  -2.49862671e-03   5.31311035e-02
   -7.46459961e-02   8.81958008e-03   2.89459229e-02   4.59899902e-02
   -1.53686523e-01  -3.31726074e-02   1.09863281e-02   8.74633789e-02
    2.08587646e-02   4.63562012e-02   7.38906860e-03  -2.14691162e-02
   -1.06933594e-01   5.76782227e-03  -5.41687012e-02   4.05578613e-02
   -1.78222656e-02  -9.76562500e-02  -1.82647705e-02   4.18395996e-02
    9.82666016e-02  -2.66418457e-02  -2.92510986e-02  -1.08718872e-02
    3.76281738e-02   9.78851318e-03   2.93426514e-02  -1.96380615e-02
   -3.81164551e-02   2.23693848e-02   2.70996094e-02  -6.71997070e-02
    4.22363281e-02  -6.05773926e-02   1.08947754e-01  -5.55801392e-03
   -8.27026367e-03   2.05230713e-02  -1.13830566e-01  -1.34110451e-04
   -1.20849609e-01  -5.11474609e-02  -1.81732178e-02   4.79431152e-02
   -9.53369141e-02  -3.04565430e-02   1.06567383e-01  -3.50646973e-02
   -1.05590820e-02  -1.74865723e-02   3.70483398e-02   7.41195679e-03
    6.35375977e-02  -4.47998047e-02  -9.61914062e-02   1.46579742e-03
    1.96533203e-02  -1.12060547e-01  -3.97033691e-02  -4.65087891e-02
    2.11944580e-02  -2.69927979e-02  -2.44903564e-02   7.04956055e-02
   -1.32522583e-02  -3.55834961e-02   6.12182617e-02   1.46102905e-02
    1.05133057e-02  -3.45153809e-02   4.90188599e-03   1.77307129e-02
    1.01394653e-02   6.77490234e-03  -7.62939453e-02   6.77490234e-02
    1.94549561e-02   4.49218750e-02  -3.68347168e-02   1.53045654e-02
   -4.65698242e-02   1.66625977e-02  -1.20239258e-01   6.66503906e-02
    6.94274902e-04  -2.78472900e-03   1.46636963e-02  -3.99475098e-02
   -1.59149170e-02  -2.75726318e-02  -3.12042236e-02  -8.29467773e-02
    1.41220093e-02   1.16394043e-01   1.44287109e-01   4.88586426e-02
    1.93481445e-02  -4.56237793e-02  -3.28674316e-02  -3.66210938e-03]]
After layer expand_dims1048_0 (1, 1, 256) <class 'numpy.float16'> [[[ -8.38623047e-02  -7.17163086e-02  -1.34506226e-02   2.63214111e-02
     1.44500732e-02  -3.39050293e-02   1.23291016e-02   3.76892090e-02
     5.22766113e-02  -7.47070312e-02  -4.13818359e-02   9.27124023e-02
     5.52978516e-02  -1.00555420e-02   3.99475098e-02  -1.51977539e-01
     3.70178223e-02   1.26724243e-02   4.73327637e-02   2.90679932e-02
     1.20971680e-01  -3.28063965e-02  -9.67407227e-03   2.57263184e-02
    -6.73828125e-02   1.69677734e-02   2.64282227e-02  -2.72216797e-02
    -7.37915039e-02  -6.14624023e-02   2.49481201e-02  -6.25610352e-02
    -1.08432770e-03   1.67083740e-03   6.40869141e-02  -7.03735352e-02
    -3.08532715e-02   1.23262405e-04  -6.11572266e-02  -5.43518066e-02
     1.07116699e-02  -1.04919434e-01   6.41479492e-02   5.32226562e-02
     4.86450195e-02  -6.42089844e-02   2.86560059e-02  -3.05786133e-02
    -8.73565674e-03  -5.73120117e-02   3.73840332e-02  -7.37915039e-02
    -3.43627930e-02   9.64355469e-02   7.22885132e-03   8.17108154e-03
    -1.19552612e-02   1.09252930e-01   5.88684082e-02  -2.24609375e-02
    -6.37207031e-02  -5.12695312e-02  -1.09634399e-02  -1.61285400e-02
     3.83300781e-02  -2.10266113e-02   2.19421387e-02  -5.86853027e-02
    -4.81262207e-02   5.44071198e-04  -1.46850586e-01   1.41143799e-02
     1.90734863e-02   1.18865967e-02   7.88574219e-02  -1.62048340e-02
    -3.61022949e-02  -1.21704102e-01  -4.58679199e-02  -2.89611816e-02
    -8.08715820e-02   5.58853149e-03  -5.61218262e-02  -9.70458984e-02
    -1.69677734e-01   4.21524048e-03  -5.40466309e-02   9.07897949e-03
    -1.05651855e-01  -5.40161133e-02  -7.87353516e-02  -2.93426514e-02
    -1.45339966e-02   3.38315964e-04  -2.75268555e-02   3.03192139e-02
     4.75769043e-02  -2.59704590e-02  -4.20837402e-02  -4.33654785e-02
     6.99234009e-03   7.15942383e-02  -3.68347168e-02   2.68402100e-02
     3.09753418e-02   9.05761719e-02  -2.17285156e-02  -2.07061768e-02
     9.38720703e-02  -1.03271484e-01   5.97534180e-02  -6.62994385e-03
     4.82788086e-02   7.61108398e-02  -4.71801758e-02   1.82250977e-01
    -8.81958008e-02  -5.10864258e-02   1.68457031e-02  -3.48205566e-02
     1.08642578e-01   3.61938477e-02  -4.61578369e-03  -5.70068359e-02
     4.69665527e-02  -9.80834961e-02  -6.09741211e-02  -4.48608398e-02
    -2.53753662e-02  -1.00250244e-02   6.58569336e-02  -1.40075684e-02
     3.96728516e-02   2.98690796e-03   4.20093536e-04   3.54614258e-02
     4.68750000e-02   1.30493164e-01   2.59876251e-04   4.04663086e-02
    -1.78527832e-03  -2.27355957e-02   7.87353516e-02   1.30767822e-02
    -4.63867188e-02   5.96313477e-02   4.96826172e-02  -6.02416992e-02
    -5.23681641e-02  -7.09228516e-02  -3.77197266e-02  -1.41448975e-02
    -4.41589355e-02  -4.13208008e-02  -2.49862671e-03   5.31311035e-02
    -7.46459961e-02   8.81958008e-03   2.89459229e-02   4.59899902e-02
    -1.53686523e-01  -3.31726074e-02   1.09863281e-02   8.74633789e-02
     2.08587646e-02   4.63562012e-02   7.38906860e-03  -2.14691162e-02
    -1.06933594e-01   5.76782227e-03  -5.41687012e-02   4.05578613e-02
    -1.78222656e-02  -9.76562500e-02  -1.82647705e-02   4.18395996e-02
     9.82666016e-02  -2.66418457e-02  -2.92510986e-02  -1.08718872e-02
     3.76281738e-02   9.78851318e-03   2.93426514e-02  -1.96380615e-02
    -3.81164551e-02   2.23693848e-02   2.70996094e-02  -6.71997070e-02
     4.22363281e-02  -6.05773926e-02   1.08947754e-01  -5.55801392e-03
    -8.27026367e-03   2.05230713e-02  -1.13830566e-01  -1.34110451e-04
    -1.20849609e-01  -5.11474609e-02  -1.81732178e-02   4.79431152e-02
    -9.53369141e-02  -3.04565430e-02   1.06567383e-01  -3.50646973e-02
    -1.05590820e-02  -1.74865723e-02   3.70483398e-02   7.41195679e-03
     6.35375977e-02  -4.47998047e-02  -9.61914062e-02   1.46579742e-03
     1.96533203e-02  -1.12060547e-01  -3.97033691e-02  -4.65087891e-02
     2.11944580e-02  -2.69927979e-02  -2.44903564e-02   7.04956055e-02
    -1.32522583e-02  -3.55834961e-02   6.12182617e-02   1.46102905e-02
     1.05133057e-02  -3.45153809e-02   4.90188599e-03   1.77307129e-02
     1.01394653e-02   6.77490234e-03  -7.62939453e-02   6.77490234e-02
     1.94549561e-02   4.49218750e-02  -3.68347168e-02   1.53045654e-02
    -4.65698242e-02   1.66625977e-02  -1.20239258e-01   6.66503906e-02
     6.94274902e-04  -2.78472900e-03   1.46636963e-02  -3.99475098e-02
    -1.59149170e-02  -2.75726318e-02  -3.12042236e-02  -8.29467773e-02
     1.41220093e-02   1.16394043e-01   1.44287109e-01   4.88586426e-02
     1.93481445e-02  -4.56237793e-02  -3.28674316e-02  -3.66210938e-03]]]
After layer encoder_birnn_reverse_l0_t7_i2h_output (1, 1024) <class 'numpy.float16'> [[-0.0128479  -0.04095459  0.03787231 ...,  0.06970215 -0.04626465
   0.03759766]]
After layer encoder_birnn_reverse_l0_t7_h2h_output (1, 1024) <class 'numpy.float16'> [[-0.00228882  0.01317596 -0.08190918 ...,  0.07623291  0.04241943
   0.02032471]]
After layer _plus1043_0 (1, 1024) <class 'numpy.float16'> [[-0.01513672 -0.027771   -0.04403687 ...,  0.14599609 -0.00384521
   0.05792236]]
After layer encoder_birnn_reverse_l0_t7_slice_output0 (1, 256) <class 'numpy.float16'> [[-0.01513672 -0.027771   -0.04403687 -0.02758789 -0.00744629 -0.0328064
  -0.00350952  0.0057373   0.09875488  0.07250977 -0.04971313  0.10919189
   0.00628662  0.01756287 -0.00128174  0.3137207  -0.13439941 -0.09204102
   0.01279449 -0.01158142  0.11022949  0.         -0.14172363 -0.05499268
   0.05944824 -0.13061523 -0.03289795 -0.00709534 -0.00158691 -0.02159119
  -0.00683594 -0.01132202 -0.05938721 -0.04421997  0.08636475 -0.16589355
  -0.01779175 -0.01669312 -0.08972168 -0.0814209  -0.16821289  0.02453613
  -0.04910278  0.0057373   0.02906799 -0.01998901  0.07397461 -0.08831787
  -0.05020142  0.02603149  0.02838135  0.11175537 -0.17126465  0.08532715
   0.18041992  0.12341309 -0.07733154  0.01533508 -0.09094238 -0.01405334
   0.09075928 -0.06610107  0.15942383 -0.02682495 -0.11547852 -0.04296875
   0.11401367 -0.02339172 -0.10644531 -0.00524902  0.1105957  -0.0196991
  -0.02056885 -0.03120422  0.01763916  0.05230713  0.11853027  0.17321777
   0.04434204  0.06274414  0.02359009  0.04736328  0.09143066 -0.02659607
   0.16906738  0.03399658 -0.02577209 -0.08966064 -0.0166626   0.05303955
   0.11779785  0.00354004 -0.08709717  0.07495117  0.07128906  0.0340271
  -0.0322876   0.02606201 -0.12054443 -0.1361084  -0.1295166   0.07806396
   0.02032471 -0.11413574 -0.13452148  0.00767517 -0.03001404 -0.11120605
   0.07427979 -0.0012207  -0.10540771 -0.01019287  0.0333252   0.24499512
   0.01745605  0.31640625 -0.02645874  0.00718689 -0.00402832 -0.05899048
   0.22033691 -0.12988281 -0.01049805  0.10308838 -0.0826416   0.07495117
  -0.14453125  0.08221436 -0.03234863  0.00949097  0.22924805  0.04742432
  -0.00906372 -0.0526123  -0.08837891 -0.11566162  0.11865234  0.16723633
  -0.02456665 -0.01224518 -0.04260254 -0.1373291   0.10015869  0.05404663
  -0.01603699  0.00311279  0.03805542  0.06567383 -0.00918579  0.07421875
   0.12695312 -0.07147217 -0.00254822 -0.09326172 -0.11456299  0.19970703
   0.02700806  0.01153564 -0.0244751  -0.03091431  0.24133301 -0.00080872
  -0.07617188  0.01834106  0.00479126 -0.08007812 -0.00787354 -0.05786133
   0.03140259 -0.050354   -0.01318359  0.04580688  0.00208282  0.10223389
   0.0193634  -0.18005371  0.04217529 -0.13598633 -0.06494141 -0.01914978
   0.05621338 -0.07635498 -0.0065918   0.02474976  0.10443115 -0.01541138
  -0.019104   -0.05517578  0.09759521  0.03540039 -0.05209351 -0.04577637
   0.03292847 -0.06237793 -0.05273438  0.09594727  0.10961914 -0.1784668
   0.04278564  0.09558105  0.0112915   0.09765625  0.08251953  0.0748291
   0.00743103 -0.04202271 -0.01350403 -0.05215454 -0.08300781  0.03887939
   0.05029297  0.13012695  0.02096558  0.04711914 -0.01193237 -0.01293945
  -0.00643158 -0.02130127  0.0390625  -0.00436401 -0.0690918  -0.11999512
   0.10888672 -0.08319092 -0.00327301  0.06567383 -0.03356934 -0.10668945
  -0.12963867  0.08575439 -0.01436615 -0.15039062 -0.01934814 -0.05667114
   0.02682495  0.05969238 -0.00531006  0.08441162  0.03433228 -0.02856445
  -0.13305664 -0.15490723  0.09301758  0.23999023 -0.06652832  0.01776123
  -0.11706543 -0.08618164  0.01138306 -0.0146637   0.17321777 -0.01748657
  -0.12719727  0.05389404  0.05456543 -0.00137329]]
After layer encoder_birnn_reverse_l0_t7_slice_output1 (1, 256) <class 'numpy.float16'> [[ 0.1595459   0.04440308  0.11602783  0.04278564 -0.00312805  0.08435059
   0.20056152 -0.10510254  0.39526367  0.18261719  0.12634277  0.15148926
   0.13244629 -0.00848389  0.13134766  0.14770508  0.08984375 -0.0274353
  -0.15307617  0.09094238  0.14904785  0.02600098  0.44506836  0.07000732
   0.12731934  0.08288574  0.17333984  0.07830811  0.12939453  0.04177856
   0.09527588  0.04379272  0.24926758 -0.05557251 -0.0078125  -0.0241394
  -0.05755615  0.15551758  0.02462769  0.08752441 -0.09936523  0.11639404
   0.0174408   0.10522461  0.04776001  0.12902832  0.03720093 -0.13500977
  -0.01437378  0.01368713  0.07543945  0.10614014 -0.05371094  0.15966797
   0.06164551  0.0491333   0.05670166  0.10974121 -0.01095581 -0.11181641
   0.11206055  0.0430603   0.08508301  0.02534485 -0.02946472  0.15979004
   0.22375488  0.08538818 -0.16308594 -0.05877686  0.07293701  0.00689697
  -0.06036377  0.0435791   0.11737061  0.15820312  0.07312012  0.07861328
   0.10870361  0.1015625   0.23205566  0.20458984  0.0380249   0.02519226
   0.19641113 -0.01257324  0.10144043  0.16967773  0.04211426 -0.1809082
   0.34912109  0.08105469  0.08215332  0.0737915  -0.0692749   0.00804138
  -0.01306152  0.03466797 -0.19287109 -0.18554688 -0.08740234 -0.0166626
   0.05331421  0.11694336 -0.02902222 -0.03582764 -0.11401367  0.06243896
   0.10321045 -0.14135742  0.05419922 -0.02893066  0.07104492  0.2310791
   0.10089111  0.21057129  0.13427734  0.14086914  0.04711914  0.11755371
   0.21679688  0.18164062  0.04669189  0.01846313 -0.04449463 -0.0067749
   0.18310547 -0.00528717  0.10705566 -0.11859131  0.14819336  0.11779785
   0.01780701  0.19580078  0.05157471  0.04119873  0.02664185  0.0682373
   0.15026855  0.23925781 -0.07110596  0.03643799  0.08587646  0.03692627
   0.05459595  0.13232422  0.11090088  0.0435791   0.0526123  -0.03277588
  -0.02706909  0.0892334   0.05548096  0.11291504 -0.02502441  0.19091797
   0.10314941 -0.0645752   0.07525635  0.1640625   0.23669434  0.09912109
  -0.03222656  0.10040283  0.10894775 -0.02331543  0.296875   -0.02624512
  -0.00598145 -0.01251221  0.02206421  0.14331055 -0.01245117  0.2220459
  -0.06658936  0.13977051  0.18017578 -0.03170776  0.00585938  0.12078857
   0.08544922 -0.07562256  0.25292969 -0.03283691 -0.00668335  0.04418945
   0.03265381  0.2166748  -0.05603027 -0.07861328 -0.03851318  0.05587769
   0.19433594  0.16796875 -0.15991211  0.00991821  0.00082397 -0.0177002
   0.03411865  0.02655029  0.07025146  0.03860474  0.08239746 -0.02035522
   0.12030029 -0.14624023 -0.06079102  0.17883301 -0.08862305  0.11175537
   0.08074951  0.11065674 -0.05395508  0.03652954 -0.01098633 -0.11169434
   0.06628418  0.10583496 -0.03265381  0.13256836 -0.10180664 -0.09960938
   0.27587891  0.00360107  0.10095215 -0.00146484  0.03115845  0.06506348
   0.41943359  0.19311523  0.04986572 -0.30493164  0.1628418   0.04037476
   0.08239746 -0.00628662  0.00541687  0.09313965  0.06835938  0.0982666
   0.06079102  0.06518555 -0.00494385  0.2253418  -0.16870117 -0.00985718
  -0.09130859 -0.05187988  0.12390137 -0.03799438  0.19055176 -0.19604492
   0.16345215 -0.00109863  0.14160156  0.00289917]]
After layer encoder_birnn_reverse_l0_t7_slice_output2 (1, 256) <class 'numpy.float16'> [[ -1.67236328e-01  -1.52099609e-01  -4.47387695e-02   6.62231445e-02
    9.26208496e-03  -6.30493164e-02  -3.05175781e-04   5.96008301e-02
    1.03759766e-01  -1.71875000e-01  -9.10644531e-02   2.16918945e-01
    1.13037109e-01  -6.17218018e-03   8.98437500e-02  -2.91748047e-01
    9.63134766e-02   3.26232910e-02   1.16882324e-01   6.67724609e-02
    2.85156250e-01  -8.58154297e-02  -4.09851074e-02   3.32946777e-02
   -1.41357422e-01   3.37219238e-02   4.83093262e-02  -5.81665039e-02
   -1.67480469e-01  -1.44042969e-01   5.14526367e-02  -1.18286133e-01
    8.78906250e-03  -3.92150879e-03   1.47216797e-01  -1.70532227e-01
   -5.69152832e-02   1.10778809e-02  -1.28784180e-01  -1.28662109e-01
    1.34887695e-02  -2.35351562e-01   1.47460938e-01   1.27319336e-01
    1.07604980e-01  -1.43188477e-01   7.81250000e-02  -7.15332031e-02
   -2.66876221e-02  -1.23413086e-01   7.29980469e-02  -1.65283203e-01
   -6.76269531e-02   2.35717773e-01  -2.47802734e-02   6.60705566e-03
   -6.77490234e-03   2.50732422e-01   1.51855469e-01  -5.27954102e-02
   -1.49780273e-01  -1.03454590e-01  -1.25656128e-02  -4.65698242e-02
    1.00646973e-01  -5.03540039e-02   3.03497314e-02  -1.28295898e-01
   -1.10412598e-01   1.55639648e-02  -3.34960938e-01   4.39453125e-02
    1.96838379e-02   2.42919922e-02   1.65283203e-01  -9.24682617e-03
   -8.34960938e-02  -2.75878906e-01  -1.07971191e-01  -6.62841797e-02
   -1.69555664e-01  -1.77001953e-03  -1.24145508e-01  -2.18872070e-01
   -3.44726562e-01   5.18798828e-04  -7.93457031e-02  -3.81469727e-03
   -2.50488281e-01  -9.55810547e-02  -1.49291992e-01  -5.95703125e-02
   -3.61022949e-02   1.69677734e-02  -5.73120117e-02   7.39746094e-02
    9.43603516e-02  -4.36096191e-02  -1.02722168e-01  -1.30249023e-01
    6.10351562e-03   1.72851562e-01  -8.54492188e-02   7.34863281e-02
    8.04443359e-02   2.26440430e-01  -5.24597168e-02  -3.00445557e-02
    2.07031250e-01  -2.28027344e-01   1.62231445e-01  -3.17993164e-02
    1.32080078e-01   1.59545898e-01  -8.92333984e-02   3.45458984e-01
   -2.19604492e-01  -1.21643066e-01   8.14056396e-03  -7.98950195e-02
    2.26562500e-01   6.04248047e-02   7.52258301e-03  -1.30615234e-01
    9.42382812e-02  -2.15087891e-01  -1.46118164e-01  -1.04797363e-01
   -5.76782227e-02  -1.96838379e-02   1.58203125e-01  -8.45336914e-03
    8.70971680e-02   4.21142578e-03  -6.13403320e-03   7.89184570e-02
    8.27636719e-02   2.82470703e-01   9.74273682e-03   9.05151367e-02
   -5.37109375e-03  -4.69360352e-02   1.80541992e-01   2.35137939e-02
   -1.04248047e-01   1.37817383e-01   1.15051270e-01  -1.14807129e-01
   -1.14990234e-01  -1.65039062e-01  -9.44824219e-02  -3.14941406e-02
   -1.11511230e-01  -7.91015625e-02  -8.48388672e-03   1.14685059e-01
   -1.59179688e-01  -1.08947754e-02   6.21643066e-02   1.01562500e-01
   -3.19824219e-01  -5.75256348e-02   1.56097412e-02   1.69921875e-01
    4.83093262e-02   1.05712891e-01   1.82533264e-03  -3.22265625e-02
   -2.85888672e-01   6.22558594e-03  -1.35498047e-01   1.04187012e-01
   -2.67944336e-02  -1.72607422e-01  -5.59082031e-02   8.26416016e-02
    2.00439453e-01  -7.20825195e-02  -5.45654297e-02  -9.96398926e-03
    8.16650391e-02   3.10668945e-02   7.32421875e-02  -5.12084961e-02
   -9.82666016e-02   2.20947266e-02   6.40258789e-02  -1.46850586e-01
    6.29272461e-02  -1.27197266e-01   2.70751953e-01  -4.24194336e-03
   -2.51464844e-02   5.48706055e-02  -2.89306641e-01   4.33349609e-03
   -2.85156250e-01  -1.31103516e-01  -3.02734375e-02   1.23168945e-01
   -2.18261719e-01  -6.97021484e-02   2.25341797e-01  -7.55004883e-02
   -2.54211426e-02  -4.40673828e-02   9.08813477e-02   1.77154541e-02
    1.63818359e-01  -7.21435547e-02  -2.21557617e-01   2.92968750e-03
    5.22766113e-02  -2.45117188e-01  -9.95483398e-02  -1.15722656e-01
    5.53894043e-02  -5.90820312e-02  -7.08007812e-02   1.71752930e-01
   -2.49633789e-02  -7.93457031e-02   1.35742188e-01   3.99169922e-02
    3.25317383e-02  -7.62939453e-02   1.29013062e-02   4.04968262e-02
   -1.74865723e-02   3.73840332e-02  -1.66503906e-01   1.88232422e-01
    2.74047852e-02   9.50317383e-02  -7.86132812e-02   2.53906250e-02
   -9.66796875e-02   4.48913574e-02  -2.88085938e-01   1.39892578e-01
   -1.79138184e-02   6.84356689e-03   1.93634033e-02  -6.51855469e-02
   -3.81469727e-02  -4.10156250e-02  -8.06884766e-02  -2.23144531e-01
    4.02526855e-02   2.81250000e-01   3.18603516e-01   1.20178223e-01
    2.09045410e-02  -9.65576172e-02  -7.66601562e-02  -8.54492188e-04]]
After layer encoder_birnn_reverse_l0_t7_slice_output3 (1, 256) <class 'numpy.float16'> [[ 0.07574463  0.06530762 -0.01383209  0.07666016  0.02426147  0.20532227
   0.08764648  0.11407471  0.44995117  0.13452148 -0.06665039  0.07775879
   0.17272949 -0.04443359  0.05700684  0.13952637 -0.06231689 -0.09979248
   0.04498291 -0.00805664 -0.04873657 -0.14404297  0.30273438  0.11297607
   0.03857422  0.08117676 -0.02368164 -0.02285767 -0.11694336  0.01086426
   0.11688232  0.10302734  0.04064941  0.03704834 -0.01556396 -0.06091309
   0.1159668  -0.01208496  0.05706787 -0.03674316  0.05438232 -0.02648926
  -0.0032196   0.01065063 -0.03274536  0.040802    0.03460693 -0.09368896
   0.02398682  0.12719727  0.08447266 -0.00317383 -0.10931396  0.05749512
   0.16125488 -0.10601807  0.16357422  0.03436279  0.02890015 -0.1192627
   0.08557129  0.09429932  0.02670288  0.18054199 -0.00619507 -0.05133057
   0.21948242  0.06469727 -0.02276611  0.05780029  0.01531982  0.03092957
  -0.00286865 -0.01834106  0.14147949  0.18444824  0.15307617  0.03927612
   0.13757324  0.22351074  0.19152832  0.20996094  0.12030029  0.10522461
   0.17773438  0.05303955  0.04678345  0.07543945  0.08703613  0.03741455
   0.17919922 -0.04995728 -0.097229    0.02720642  0.03295898  0.02807617
   0.05322266  0.06665039 -0.15112305 -0.12939453 -0.07330322 -0.15478516
  -0.09320068 -0.09985352 -0.03686523  0.00512695 -0.04476929  0.13549805
   0.06677246  0.10125732  0.02502441  0.05862427 -0.09594727  0.15539551
  -0.00488281  0.16320801 -0.07171631 -0.03369141  0.04144287 -0.05621338
   0.03585815  0.09893799  0.07818604 -0.00489807 -0.07128906  0.04095459
   0.00436401  0.00720215 -0.01434326 -0.12158203  0.02426147  0.18334961
  -0.0236969   0.11651611  0.05111694 -0.09082031  0.14758301  0.05303955
   0.13891602  0.04406738  0.02307129 -0.01104736 -0.06695557  0.09118652
  -0.01490021  0.03375244  0.18432617  0.09094238  0.0295105  -0.0206604
  -0.02024841 -0.02990723  0.09185791  0.14355469 -0.03112793  0.07177734
   0.11865234  0.08648682  0.03912354  0.15063477  0.08752441  0.04840088
   0.00567627  0.1394043   0.09008789 -0.09277344  0.30493164  0.1204834
  -0.1541748   0.02549744 -0.12792969  0.13220215  0.10534668  0.23022461
   0.00335693  0.18920898  0.15844727 -0.07269287  0.06463623 -0.02178955
  -0.13427734 -0.09490967  0.06317139 -0.09924316 -0.07366943  0.16503906
  -0.03265381  0.12127686 -0.050354   -0.13452148  0.01123047  0.1496582
   0.06091309  0.03112793 -0.05297852  0.07067871 -0.03747559  0.04199219
   0.12316895  0.03417969  0.0892334   0.21875     0.09692383  0.16455078
   0.09759521  0.09539795 -0.09283447  0.06137085 -0.12023926  0.18408203
   0.00579834  0.31518555  0.07952881  0.17089844  0.11560059 -0.07263184
   0.05761719  0.22607422 -0.03399658 -0.05828857 -0.03265381 -0.17285156
   0.17529297  0.029953    0.07556152  0.10388184 -0.00442505  0.04898071
   0.3671875   0.16381836  0.01208496 -0.17089844 -0.03103638  0.01159668
  -0.01878357  0.03460693 -0.02545166  0.09094238  0.125       0.05142212
  -0.17724609  0.09228516  0.07159424  0.32763672 -0.16186523  0.06317139
  -0.01165771 -0.15258789  0.04458618 -0.03083801  0.12243652 -0.1027832
   0.12078857  0.14599609 -0.00384521  0.05792236]]
After layer encoder_birnn_reverse_l0_t7_o_output (1, 256) <class 'numpy.float16'> [[ 0.51904297  0.51611328  0.49658203  0.51904297  0.50585938  0.55126953
   0.52197266  0.52832031  0.61083984  0.53369141  0.48339844  0.51953125
   0.54296875  0.48901367  0.51416016  0.53466797  0.484375    0.47509766
   0.51123047  0.49804688  0.48779297  0.46411133  0.57519531  0.52832031
   0.50976562  0.52050781  0.49414062  0.49438477  0.47070312  0.50292969
   0.52929688  0.52587891  0.51025391  0.50927734  0.49609375  0.48486328
   0.52880859  0.49707031  0.51416016  0.49072266  0.51367188  0.4934082
   0.49926758  0.50244141  0.49169922  0.51025391  0.50878906  0.4765625
   0.50585938  0.53173828  0.52099609  0.49926758  0.47265625  0.51416016
   0.54003906  0.47363281  0.54101562  0.50878906  0.50732422  0.47021484
   0.52148438  0.5234375   0.50683594  0.54492188  0.49853516  0.48706055
   0.5546875   0.51611328  0.49438477  0.51464844  0.50390625  0.5078125
   0.49926758  0.49536133  0.53515625  0.54589844  0.53808594  0.50976562
   0.53417969  0.55566406  0.54785156  0.55224609  0.53027344  0.52636719
   0.54443359  0.51318359  0.51171875  0.51904297  0.52197266  0.50927734
   0.54492188  0.48754883  0.47583008  0.50683594  0.50830078  0.50683594
   0.51318359  0.51660156  0.46240234  0.46777344  0.48168945  0.46142578
   0.47680664  0.47509766  0.49072266  0.50146484  0.48876953  0.53369141
   0.51660156  0.52539062  0.50634766  0.51464844  0.47607422  0.53857422
   0.4987793   0.54052734  0.48217773  0.49169922  0.51025391  0.48583984
   0.50878906  0.52490234  0.51953125  0.4987793   0.48217773  0.51025391
   0.50097656  0.50195312  0.49633789  0.46972656  0.50585938  0.54589844
   0.49414062  0.52929688  0.51269531  0.47729492  0.53662109  0.51318359
   0.53466797  0.51123047  0.50585938  0.49731445  0.4831543   0.52294922
   0.49633789  0.50830078  0.54589844  0.52294922  0.50732422  0.49487305
   0.49487305  0.49243164  0.52294922  0.53564453  0.4921875   0.51806641
   0.52978516  0.52148438  0.50976562  0.53759766  0.52197266  0.51220703
   0.50146484  0.53466797  0.52246094  0.47680664  0.57568359  0.53027344
   0.46142578  0.50634766  0.46801758  0.53320312  0.52636719  0.55712891
   0.50097656  0.54736328  0.53955078  0.48193359  0.51611328  0.49462891
   0.46655273  0.47631836  0.515625    0.47509766  0.48168945  0.54101562
   0.49194336  0.53027344  0.48730469  0.46630859  0.50292969  0.53710938
   0.51513672  0.5078125   0.48681641  0.51757812  0.49072266  0.51025391
   0.53076172  0.50830078  0.52246094  0.5546875   0.52441406  0.54101562
   0.52441406  0.52392578  0.47680664  0.51513672  0.4699707   0.54589844
   0.50146484  0.578125    0.52001953  0.54248047  0.52880859  0.48193359
   0.51416016  0.55615234  0.49145508  0.48535156  0.49194336  0.45678711
   0.54394531  0.50732422  0.51904297  0.52587891  0.4987793   0.51220703
   0.59082031  0.54101562  0.50292969  0.45727539  0.4921875   0.50292969
   0.49536133  0.50878906  0.49365234  0.52294922  0.53125     0.51269531
   0.45581055  0.52294922  0.51806641  0.58105469  0.4597168   0.515625
   0.49707031  0.46191406  0.51123047  0.4921875   0.53076172  0.47436523
   0.53027344  0.53662109  0.49902344  0.51464844]]
After layer encoder_birnn_reverse_l0_t7_f_output (1, 256) <class 'numpy.float16'> [[ 0.54003906  0.51123047  0.52880859  0.51074219  0.49926758  0.52099609
   0.54980469  0.47363281  0.59765625  0.54541016  0.53173828  0.53759766
   0.53320312  0.49780273  0.53271484  0.53662109  0.52246094  0.49316406
   0.46191406  0.52294922  0.53710938  0.50634766  0.609375    0.51757812
   0.53173828  0.52050781  0.54345703  0.51953125  0.53222656  0.51025391
   0.52392578  0.51074219  0.56201172  0.48608398  0.49804688  0.49389648
   0.4855957   0.53857422  0.50634766  0.52197266  0.47509766  0.52929688
   0.50439453  0.52636719  0.51171875  0.53222656  0.50927734  0.46630859
   0.49633789  0.50341797  0.51904297  0.52636719  0.48657227  0.54003906
   0.515625    0.51220703  0.51416016  0.52734375  0.49731445  0.47216797
   0.52783203  0.51074219  0.52148438  0.50634766  0.49267578  0.54003906
   0.55566406  0.52148438  0.45922852  0.48535156  0.51806641  0.50195312
   0.48486328  0.51074219  0.52929688  0.53955078  0.51806641  0.51953125
   0.52734375  0.52539062  0.55761719  0.55078125  0.50927734  0.50634766
   0.54882812  0.49682617  0.52539062  0.54248047  0.51074219  0.45483398
   0.58642578  0.52001953  0.52050781  0.51855469  0.48266602  0.50195312
   0.49682617  0.50878906  0.4519043   0.45385742  0.47827148  0.49584961
   0.51318359  0.52929688  0.49267578  0.4909668   0.47143555  0.515625
   0.52587891  0.46459961  0.51367188  0.49267578  0.51757812  0.55761719
   0.52539062  0.55224609  0.53369141  0.53515625  0.51171875  0.52929688
   0.55419922  0.54541016  0.51171875  0.50439453  0.48876953  0.49829102
   0.54541016  0.4987793   0.52685547  0.47045898  0.53710938  0.52929688
   0.50439453  0.54882812  0.51269531  0.51025391  0.50683594  0.51708984
   0.53759766  0.55957031  0.48217773  0.50927734  0.52148438  0.50927734
   0.51367188  0.53320312  0.52783203  0.51074219  0.51318359  0.49169922
   0.49316406  0.52246094  0.51367188  0.52832031  0.49365234  0.54736328
   0.52587891  0.48388672  0.51904297  0.54101562  0.55908203  0.52490234
   0.49194336  0.52490234  0.52734375  0.49414062  0.57373047  0.4934082
   0.49853516  0.49682617  0.50537109  0.53564453  0.49682617  0.55517578
   0.48339844  0.53466797  0.54492188  0.4921875   0.50146484  0.53027344
   0.52148438  0.48120117  0.56298828  0.49169922  0.49829102  0.51123047
   0.50830078  0.55419922  0.48608398  0.48046875  0.49047852  0.51416016
   0.54833984  0.54199219  0.46020508  0.50244141  0.5         0.49560547
   0.50830078  0.50683594  0.51757812  0.50976562  0.52050781  0.49487305
   0.53027344  0.46362305  0.48486328  0.54443359  0.4777832   0.52783203
   0.52001953  0.52783203  0.48657227  0.50927734  0.49731445  0.47216797
   0.51660156  0.52636719  0.49194336  0.53320312  0.47460938  0.47509766
   0.56835938  0.50097656  0.52539062  0.49975586  0.5078125   0.51611328
   0.60351562  0.54833984  0.51269531  0.42431641  0.54052734  0.51025391
   0.52050781  0.49853516  0.50146484  0.5234375   0.51708984  0.52441406
   0.51513672  0.51611328  0.4987793   0.55615234  0.45800781  0.49755859
   0.47729492  0.48706055  0.53076172  0.49047852  0.54736328  0.45117188
   0.54101562  0.49975586  0.53515625  0.50048828]]
After layer _mul2086_0 (1, 256) <class 'numpy.float16'> [[ -8.82568359e-02  -7.18383789e-02  -1.43356323e-02   2.59704590e-02
    1.42135620e-02  -3.21044922e-02   1.29547119e-02   3.37524414e-02
    5.18798828e-02  -7.72094727e-02  -4.54711914e-02   9.72290039e-02
    5.45959473e-02  -1.02233887e-02   4.16259766e-02  -1.57714844e-01
    3.99780273e-02   1.31301880e-02   4.29992676e-02   3.06396484e-02
    1.35864258e-01  -3.57666016e-02  -1.03378296e-02   2.52685547e-02
   -7.04345703e-02   1.70745850e-02   2.90222168e-02  -2.85797119e-02
   -8.36791992e-02  -6.26220703e-02   2.47497559e-02  -6.10961914e-02
   -1.19781494e-03   1.59740448e-03   6.48193359e-02  -7.18383789e-02
   -2.84118652e-02   1.33514404e-04  -6.02722168e-02  -5.77392578e-02
    9.85717773e-03  -1.14379883e-01   6.51855469e-02   5.60913086e-02
    5.07812500e-02  -6.75048828e-02   2.87933350e-02  -2.97698975e-02
   -8.57543945e-03  -5.46264648e-02   3.73229980e-02  -7.87963867e-02
   -3.50036621e-02   1.02416992e-01   6.90841675e-03   8.85772705e-03
   -1.14135742e-02   1.15478516e-01   5.79833984e-02  -2.25524902e-02
   -6.51855469e-02  -5.04150391e-02  -1.12838745e-02  -1.50527954e-02
    3.79638672e-02  -2.33764648e-02   2.20947266e-02  -5.96008301e-02
   -4.45556641e-02   5.11169434e-04  -1.55517578e-01   1.39389038e-02
    1.85089111e-02   1.22528076e-02   7.90405273e-02  -1.59606934e-02
   -3.48510742e-02  -1.26342773e-01  -4.55627441e-02  -2.74810791e-02
   -8.33740234e-02   5.58853149e-03  -5.44738770e-02  -9.42382812e-02
   -1.77612305e-01   4.08172607e-03  -5.59387207e-02   9.44519043e-03
   -1.05102539e-01  -4.81262207e-02  -8.57543945e-02  -3.12805176e-02
   -1.58691406e-02   3.46183777e-04  -2.60772705e-02   3.00292969e-02
    4.60815430e-02  -2.53753662e-02  -4.11376953e-02  -4.19921875e-02
    6.89697266e-03   7.73315430e-02  -3.95812988e-02   2.98461914e-02
    3.09753418e-02   8.96606445e-02  -2.09350586e-02  -2.00653076e-02
    9.68017578e-02  -9.17358398e-02   6.11877441e-02  -6.35147095e-03
    5.24902344e-02   7.96508789e-02  -4.97741699e-02   1.94335938e-01
   -9.88769531e-02  -5.56945801e-02   1.68304443e-02  -3.79943848e-02
    1.20422363e-01   3.77502441e-02  -4.53567505e-03  -5.77392578e-02
    4.75463867e-02  -9.72290039e-02  -6.69555664e-02  -4.48303223e-02
   -2.70080566e-02  -9.98687744e-03   7.04345703e-02  -1.35879517e-02
    4.05883789e-02   3.11088562e-03   4.20570374e-04   3.78112793e-02
    4.45556641e-02   1.34155273e-01   2.62498856e-04   4.46166992e-02
   -1.70516968e-03  -2.32849121e-02   8.59375000e-02   1.27944946e-02
   -4.80041504e-02   6.29882812e-02   4.85229492e-02  -5.95092773e-02
   -5.30700684e-02  -7.08007812e-02  -3.76892090e-02  -1.50222778e-02
   -4.37011719e-02  -4.09545898e-02  -2.48908997e-03   5.63049316e-02
   -7.50732422e-02   8.14056396e-03   2.95104980e-02   4.65698242e-02
   -1.69921875e-01  -3.42102051e-02   1.08261108e-02   8.66088867e-02
    2.11334229e-02   4.79736328e-02   7.42721558e-03  -2.00347900e-02
   -1.16821289e-01   5.66482544e-03  -5.83496094e-02   4.10766602e-02
   -1.69219971e-02  -9.89379883e-02  -1.75781250e-02   4.11071777e-02
    1.00585938e-01  -2.71759033e-02  -2.83355713e-02  -1.16348267e-02
    4.19616699e-02   9.82666016e-03   3.21960449e-02  -2.02026367e-02
   -3.93676758e-02   2.13165283e-02   2.79541016e-02  -7.09228516e-02
    4.19006348e-02  -6.22863770e-02   1.07849121e-01  -5.32913208e-03
   -8.82720947e-03   2.20031738e-02  -1.07971191e-01  -1.30534172e-04
   -1.25488281e-01  -4.97436523e-02  -1.74407959e-02   4.81262207e-02
   -9.57641602e-02  -2.80456543e-02   1.07482910e-01  -3.22570801e-02
   -1.06964111e-02  -1.54953003e-02   3.75976562e-02   7.85827637e-03
    6.46362305e-02  -4.35485840e-02  -1.01196289e-01   1.34372711e-03
    1.85089111e-02  -1.07116699e-01  -3.75671387e-02  -4.54711914e-02
    2.13165283e-02  -2.57720947e-02  -2.45361328e-02   7.78198242e-02
   -1.28173828e-02  -3.67431641e-02   6.46362305e-02   1.44348145e-02
    1.06658936e-02  -3.28674316e-02   4.98199463e-03   1.79290771e-02
    1.04675293e-02   6.83593750e-03  -7.83691406e-02   6.28051758e-02
    2.13775635e-02   4.57763672e-02  -3.88183594e-02   1.50451660e-02
   -4.75769043e-02   1.67541504e-02  -1.19567871e-01   6.87866211e-02
    7.74383545e-04  -2.75421143e-03   1.40609741e-02  -3.83605957e-02
   -1.57165527e-02  -2.66571045e-02  -2.97698975e-02  -8.79516602e-02
    1.46942139e-02   1.17736816e-01   1.53442383e-01   4.64477539e-02
    1.98516846e-02  -4.26940918e-02  -3.53393555e-02  -3.55911255e-03]]
After layer encoder_birnn_reverse_l0_t7_i_output (1, 256) <class 'numpy.float16'> [[ 0.49633789  0.49316406  0.48901367  0.49316406  0.49804688  0.49169922
   0.49902344  0.50146484  0.52490234  0.51806641  0.48754883  0.52734375
   0.50146484  0.50439453  0.49975586  0.57763672  0.46655273  0.47705078
   0.50341797  0.49707031  0.52734375  0.5         0.46459961  0.48632812
   0.51464844  0.46728516  0.49169922  0.49829102  0.49951172  0.49462891
   0.49829102  0.49707031  0.48510742  0.48901367  0.52148438  0.45874023
   0.49560547  0.49584961  0.47753906  0.47973633  0.45800781  0.50634766
   0.48779297  0.50146484  0.50732422  0.49511719  0.51855469  0.47802734
   0.48754883  0.50634766  0.50732422  0.52783203  0.45727539  0.52148438
   0.54492188  0.53076172  0.48071289  0.50390625  0.47729492  0.49658203
   0.52246094  0.48339844  0.53955078  0.4934082   0.47119141  0.48925781
   0.52832031  0.49414062  0.47338867  0.4987793   0.52783203  0.49511719
   0.49487305  0.4921875   0.50439453  0.51318359  0.52978516  0.54296875
   0.51123047  0.515625    0.50585938  0.51171875  0.52294922  0.4934082
   0.54199219  0.50830078  0.49365234  0.47753906  0.49584961  0.51318359
   0.52929688  0.50097656  0.47827148  0.51855469  0.51757812  0.50830078
   0.49194336  0.50634766  0.4699707   0.46606445  0.46777344  0.51953125
   0.50488281  0.47143555  0.46630859  0.50195312  0.49243164  0.47216797
   0.51855469  0.49975586  0.47363281  0.49755859  0.50830078  0.56103516
   0.50439453  0.57861328  0.4934082   0.50195312  0.49902344  0.48535156
   0.5546875   0.4675293   0.49731445  0.52587891  0.47924805  0.51855469
   0.46386719  0.52050781  0.49194336  0.50244141  0.55712891  0.51171875
   0.49780273  0.48681641  0.47802734  0.47119141  0.52978516  0.54150391
   0.49389648  0.49682617  0.48925781  0.46582031  0.52490234  0.51367188
   0.49609375  0.50097656  0.50927734  0.51660156  0.49780273  0.51855469
   0.53173828  0.48217773  0.49926758  0.47680664  0.47143555  0.54980469
   0.50683594  0.50292969  0.49389648  0.4921875   0.56005859  0.49975586
   0.48095703  0.50439453  0.50097656  0.47998047  0.49804688  0.4855957
   0.5078125   0.48730469  0.49682617  0.51123047  0.50048828  0.52539062
   0.50488281  0.45507812  0.51074219  0.46606445  0.48388672  0.49511719
   0.51416016  0.48095703  0.49829102  0.50634766  0.52587891  0.49609375
   0.49511719  0.48632812  0.52441406  0.50878906  0.48706055  0.48852539
   0.50830078  0.484375    0.48681641  0.52392578  0.52734375  0.45556641
   0.51074219  0.52392578  0.50292969  0.52441406  0.52050781  0.51855469
   0.50195312  0.48950195  0.49658203  0.48706055  0.47924805  0.50976562
   0.51269531  0.53271484  0.50537109  0.51171875  0.49707031  0.49682617
   0.49829102  0.49462891  0.50976562  0.49902344  0.48266602  0.4699707
   0.52734375  0.47924805  0.49926758  0.51660156  0.49169922  0.47338867
   0.4675293   0.52148438  0.49633789  0.46240234  0.49511719  0.48583984
   0.50683594  0.51513672  0.4987793   0.52099609  0.50878906  0.49291992
   0.46679688  0.46142578  0.5234375   0.55957031  0.48339844  0.50439453
   0.47070312  0.47851562  0.50292969  0.49633789  0.54296875  0.49560547
   0.46826172  0.51367188  0.51367188  0.49975586]]
After layer encoder_birnn_reverse_l0_t7_c_output (1, 256) <class 'numpy.float16'> [[ -1.65649414e-01  -1.50878906e-01  -4.47082520e-02   6.61010742e-02
    9.26208496e-03  -6.29882812e-02  -3.05175781e-04   5.95397949e-02
    1.03393555e-01  -1.70166016e-01  -9.08203125e-02   2.13623047e-01
    1.12548828e-01  -6.17218018e-03   8.95996094e-02  -2.83691406e-01
    9.60083008e-02   3.26232910e-02   1.16333008e-01   6.66503906e-02
    2.77587891e-01  -8.56323242e-02  -4.09545898e-02   3.32946777e-02
   -1.40380859e-01   3.37219238e-02   4.82788086e-02  -5.81054688e-02
   -1.65893555e-01  -1.43066406e-01   5.14221191e-02  -1.17736816e-01
    8.78906250e-03  -3.92150879e-03   1.46118164e-01  -1.68945312e-01
   -5.68542480e-02   1.10778809e-02  -1.28051758e-01  -1.27929688e-01
    1.34887695e-02  -2.31079102e-01   1.46362305e-01   1.26586914e-01
    1.07177734e-01  -1.42211914e-01   7.79418945e-02  -7.14111328e-02
   -2.66876221e-02  -1.22802734e-01   7.28759766e-02  -1.63818359e-01
   -6.75048828e-02   2.31445312e-01  -2.47802734e-02   6.60705566e-03
   -6.77490234e-03   2.45605469e-01   1.50756836e-01  -5.27343750e-02
   -1.48681641e-01  -1.03088379e-01  -1.25656128e-02  -4.65393066e-02
    1.00280762e-01  -5.03234863e-02   3.03344727e-02  -1.27563477e-01
   -1.09985352e-01   1.55639648e-02  -3.22998047e-01   4.39147949e-02
    1.96838379e-02   2.42919922e-02   1.63818359e-01  -9.24682617e-03
   -8.33129883e-02  -2.69042969e-01  -1.07543945e-01  -6.61621094e-02
   -1.67968750e-01  -1.77001953e-03  -1.23535156e-01  -2.15454102e-01
   -3.31787109e-01   5.18798828e-04  -7.91625977e-02  -3.81469727e-03
   -2.45361328e-01  -9.52758789e-02  -1.48193359e-01  -5.95092773e-02
   -3.60717773e-02   1.69677734e-02  -5.72509766e-02   7.38525391e-02
    9.40551758e-02  -4.35791016e-02  -1.02355957e-01  -1.29516602e-01
    6.10351562e-03   1.71142578e-01  -8.52661133e-02   7.33642578e-02
    8.02612305e-02   2.22656250e-01  -5.23986816e-02  -3.00292969e-02
    2.04101562e-01  -2.24121094e-01   1.60766602e-01  -3.17993164e-02
    1.31347656e-01   1.58203125e-01  -8.89892578e-02   3.32275391e-01
   -2.16186523e-01  -1.21032715e-01   8.14056396e-03  -7.97119141e-02
    2.22778320e-01   6.03637695e-02   7.52258301e-03  -1.29882812e-01
    9.39331055e-02  -2.11791992e-01  -1.45141602e-01  -1.04431152e-01
   -5.76171875e-02  -1.96838379e-02   1.56860352e-01  -8.45336914e-03
    8.68530273e-02   4.21142578e-03  -6.13403320e-03   7.87353516e-02
    8.25805664e-02   2.75146484e-01   9.74273682e-03   9.02709961e-02
   -5.37109375e-03  -4.69055176e-02   1.78588867e-01   2.35137939e-02
   -1.03881836e-01   1.36962891e-01   1.14562988e-01  -1.14318848e-01
   -1.14501953e-01  -1.63574219e-01  -9.41772461e-02  -3.14941406e-02
   -1.11022949e-01  -7.89184570e-02  -8.48388672e-03   1.14196777e-01
   -1.57836914e-01  -1.08947754e-02   6.20727539e-02   1.01196289e-01
   -3.09326172e-01  -5.74645996e-02   1.56097412e-02   1.68334961e-01
    4.82788086e-02   1.05346680e-01   1.82533264e-03  -3.22265625e-02
   -2.78320312e-01   6.22558594e-03  -1.34643555e-01   1.03820801e-01
   -2.67944336e-02  -1.70898438e-01  -5.58471680e-02   8.24584961e-02
    1.97753906e-01  -7.19604492e-02  -5.45043945e-02  -9.96398926e-03
    8.14819336e-02   3.10516357e-02   7.31201172e-02  -5.11779785e-02
   -9.79614258e-02   2.20947266e-02   6.39648438e-02  -1.45751953e-01
    6.28662109e-02  -1.26464844e-01   2.64404297e-01  -4.24194336e-03
   -2.51464844e-02   5.48095703e-02  -2.81494141e-01   4.33349609e-03
   -2.77587891e-01  -1.30371094e-01  -3.02581787e-02   1.22558594e-01
   -2.14843750e-01  -6.95800781e-02   2.21557617e-01  -7.53784180e-02
   -2.54211426e-02  -4.40368652e-02   9.06372070e-02   1.77154541e-02
    1.62353516e-01  -7.20214844e-02  -2.18017578e-01   2.92968750e-03
    5.22155762e-02  -2.40356445e-01  -9.92431641e-02  -1.15234375e-01
    5.53283691e-02  -5.90209961e-02  -7.06787109e-02   1.70043945e-01
   -2.49633789e-02  -7.91625977e-02   1.34887695e-01   3.98864746e-02
    3.25317383e-02  -7.61718750e-02   1.29013062e-02   4.04663086e-02
   -1.74865723e-02   3.73535156e-02  -1.65039062e-01   1.86035156e-01
    2.74047852e-02   9.47265625e-02  -7.84301758e-02   2.53906250e-02
   -9.63745117e-02   4.48608398e-02  -2.80273438e-01   1.39038086e-01
   -1.79138184e-02   6.84356689e-03   1.93634033e-02  -6.50634766e-02
   -3.81164551e-02  -4.09851074e-02  -8.05053711e-02  -2.19482422e-01
    4.02221680e-02   2.74169922e-01   3.08349609e-01   1.19628906e-01
    2.09045410e-02  -9.62524414e-02  -7.65380859e-02  -8.54492188e-04]]
After layer _mul2087_0 (1, 256) <class 'numpy.float16'> [[ -8.22143555e-02  -7.44018555e-02  -2.18658447e-02   3.25927734e-02
    4.61196899e-03  -3.09753418e-02  -1.52349472e-04   2.98614502e-02
    5.42602539e-02  -8.81347656e-02  -4.42810059e-02   1.12670898e-01
    5.64270020e-02  -3.11279297e-03   4.47692871e-02  -1.63818359e-01
    4.47998047e-02   1.55639648e-02   5.85632324e-02   3.31420898e-02
    1.46362305e-01  -4.28161621e-02  -1.90277100e-02   1.61895752e-02
   -7.22656250e-02   1.57623291e-02   2.37426758e-02  -2.89459229e-02
   -8.28857422e-02  -7.07397461e-02   2.56195068e-02  -5.85327148e-02
    4.26483154e-03  -1.91783905e-03   7.61718750e-02  -7.75146484e-02
   -2.81829834e-02   5.49316406e-03  -6.11572266e-02  -6.13708496e-02
    6.17980957e-03  -1.17004395e-01   7.14111328e-02   6.34765625e-02
    5.43823242e-02  -7.04345703e-02   4.04052734e-02  -3.41491699e-02
   -1.30081177e-02  -6.21948242e-02   3.69567871e-02  -8.64868164e-02
   -3.08685303e-02   1.20666504e-01  -1.35040283e-02   3.50761414e-03
   -3.25584412e-03   1.23779297e-01   7.19604492e-02  -2.61840820e-02
   -7.76977539e-02  -4.98352051e-02  -6.77871704e-03  -2.29644775e-02
    4.72412109e-02  -2.46276855e-02   1.60217285e-02  -6.30493164e-02
   -5.20629883e-02   7.76290894e-03  -1.70532227e-01   2.17437744e-02
    9.74273682e-03   1.19552612e-02   8.26416016e-02  -4.74548340e-03
   -4.41284180e-02  -1.46118164e-01  -5.49926758e-02  -3.41186523e-02
   -8.49609375e-02  -9.05990601e-04  -6.45751953e-02  -1.06323242e-01
   -1.79809570e-01   2.63690948e-04  -3.90930176e-02  -1.82151794e-03
   -1.21643066e-01  -4.88891602e-02  -7.84301758e-02  -2.98156738e-02
   -1.72576904e-02   8.79669189e-03  -2.96325684e-02   3.75366211e-02
    4.62646484e-02  -2.20642090e-02  -4.80957031e-02  -6.03637695e-02
    2.85530090e-03   8.89282227e-02  -4.30603027e-02   3.45764160e-02
    3.74145508e-02   1.11755371e-01  -2.58026123e-02  -1.41754150e-02
    1.05834961e-01  -1.11999512e-01   7.61718750e-02  -1.58233643e-02
    6.67724609e-02   8.87451172e-02  -4.48913574e-02   1.92260742e-01
   -1.06689453e-01  -6.07604980e-02   4.06265259e-03  -3.86962891e-02
    1.23596191e-01   2.82287598e-02   3.74031067e-03  -6.82983398e-02
    4.50134277e-02  -1.09802246e-01  -6.73217773e-02  -5.43518066e-02
   -2.83508301e-02  -9.88769531e-03   8.74023438e-02  -4.32586670e-03
    4.32434082e-02   2.05039978e-03  -2.93159485e-03   3.71093750e-02
    4.37622070e-02   1.49047852e-01   4.81033325e-03   4.48608398e-02
   -2.62832642e-03  -2.18505859e-02   9.37500000e-02   1.20773315e-02
   -5.15441895e-02   6.86035156e-02   5.83496094e-02  -5.90515137e-02
   -5.70068359e-02  -8.48388672e-02  -5.00793457e-02  -1.51824951e-02
   -5.54199219e-02  -3.76281738e-02  -3.99780273e-03   6.28051758e-02
   -8.00170898e-02  -5.47790527e-03   3.06549072e-02   4.98046875e-02
   -1.73217773e-01  -2.87170410e-02   7.50732422e-03   8.48999023e-02
    2.41851807e-02   5.05676270e-02   9.09328461e-04  -1.56555176e-02
   -1.41357422e-01   3.03459167e-03  -6.68945312e-02   5.30700684e-02
   -1.34124756e-02  -8.97827148e-02  -2.81982422e-02   3.75366211e-02
    1.01013184e-01  -3.35388184e-02  -2.63671875e-02  -4.93240356e-03
    4.19006348e-02   1.49307251e-02   3.64379883e-02  -2.59094238e-02
   -5.15136719e-02   1.09634399e-02   3.16772461e-02  -7.08618164e-02
    3.29589844e-02  -6.43310547e-02   1.28784180e-01  -2.07138062e-03
   -1.27792358e-02   2.65502930e-02  -1.37084961e-01   2.26974487e-03
   -1.46362305e-01  -5.93872070e-02  -1.54571533e-02   6.42089844e-02
   -1.08032227e-01  -3.64990234e-02   1.15295410e-01  -3.90930176e-02
   -1.27639771e-02  -2.15606689e-02   4.50134277e-02   8.62884521e-03
    7.78198242e-02  -3.67126465e-02  -1.11755371e-01   1.56021118e-03
    2.63824463e-02  -1.22985840e-01  -4.93164062e-02  -5.72509766e-02
    2.75726318e-02  -2.91900635e-02  -3.60412598e-02   8.48388672e-02
   -1.20468140e-02  -3.72009277e-02   7.11059570e-02   1.91192627e-02
    1.62353516e-02  -3.93371582e-02   6.34384155e-03   1.91497803e-02
   -8.17871094e-03   1.94854736e-02  -8.19091797e-02   8.59985352e-02
    1.35650635e-02   4.60205078e-02  -3.97644043e-02   1.30767822e-02
   -4.80651855e-02   2.33764648e-02  -1.42578125e-01   6.85424805e-02
   -8.36181641e-03   3.15856934e-03   1.01318359e-02  -3.64074707e-02
   -1.84326172e-02  -2.06756592e-02  -3.79028320e-02  -1.05041504e-01
    2.02331543e-02   1.36108398e-01   1.67480469e-01   5.92956543e-02
    9.78851318e-03  -4.94384766e-02  -3.93066406e-02  -4.27007675e-04]]
After layer encoder_birnn_reverse_l0_t7_state_0 (1, 256) <class 'numpy.float16'> [[ -1.70410156e-01  -1.46240234e-01  -3.61938477e-02   5.85632324e-02
    1.88293457e-02  -6.31103516e-02   1.28021240e-02   6.35986328e-02
    1.06140137e-01  -1.65283203e-01  -8.97216797e-02   2.09960938e-01
    1.11022949e-01  -1.33361816e-02   8.64257812e-02  -3.21533203e-01
    8.47778320e-02   2.86865234e-02   1.01562500e-01   6.37817383e-02
    2.82226562e-01  -7.86132812e-02  -2.93579102e-02   4.14428711e-02
   -1.42700195e-01   3.28369141e-02   5.27648926e-02  -5.75256348e-02
   -1.66503906e-01  -1.33300781e-01   5.03540039e-02  -1.19628906e-01
    3.06701660e-03  -3.20434570e-04   1.40991211e-01  -1.49414062e-01
   -5.65795898e-02   5.62667847e-03  -1.21459961e-01  -1.19140625e-01
    1.60369873e-02  -2.31445312e-01   1.36596680e-01   1.19567871e-01
    1.05163574e-01  -1.37939453e-01   6.92138672e-02  -6.39038086e-02
   -2.15759277e-02  -1.16821289e-01   7.42797852e-02  -1.65283203e-01
   -6.58569336e-02   2.23144531e-01  -6.59561157e-03   1.23672485e-02
   -1.46713257e-02   2.39257812e-01   1.29882812e-01  -4.87365723e-02
   -1.42822266e-01  -1.00219727e-01  -1.80664062e-02  -3.80249023e-02
    8.52050781e-02  -4.80041504e-02   3.81164551e-02  -1.22680664e-01
   -9.66186523e-02   8.27026367e-03  -3.26171875e-01   3.56750488e-02
    2.82592773e-02   2.42004395e-02   1.61621094e-01  -2.07061768e-02
   -7.89794922e-02  -2.72460938e-01  -1.00585938e-01  -6.15844727e-02
   -1.68334961e-01   4.68444824e-03  -1.19018555e-01  -2.00561523e-01
   -3.57421875e-01   4.34494019e-03  -9.50317383e-02   7.62176514e-03
   -2.26806641e-01  -9.70458984e-02  -1.64184570e-01  -6.10961914e-02
   -3.31420898e-02   9.14001465e-03  -5.57250977e-02   6.75659180e-02
    9.23461914e-02  -4.74243164e-02  -8.92333984e-02  -1.02355957e-01
    9.75036621e-03   1.66259766e-01  -8.26416016e-02   6.44531250e-02
    6.83593750e-02   2.01416016e-01  -4.67529297e-02  -3.42407227e-02
    2.02636719e-01  -2.03735352e-01   1.37329102e-01  -2.21710205e-02
    1.19262695e-01   1.68457031e-01  -9.46655273e-02   3.86718750e-01
   -2.05566406e-01  -1.16455078e-01   2.08892822e-02  -7.66601562e-02
    2.44018555e-01   6.59790039e-02  -7.95364380e-04  -1.25976562e-01
    9.25292969e-02  -2.07031250e-01  -1.34277344e-01  -9.91821289e-02
   -5.53588867e-02  -1.98669434e-02   1.57836914e-01  -1.79138184e-02
    8.38623047e-02   5.16128540e-03  -2.51007080e-03   7.49511719e-02
    8.83178711e-02   2.83203125e-01   5.07354736e-03   8.94775391e-02
   -4.33349609e-03  -4.51354980e-02   1.79687500e-01   2.48718262e-02
   -9.95483398e-02   1.31591797e-01   1.06872559e-01  -1.18530273e-01
   -1.10107422e-01  -1.55639648e-01  -8.77685547e-02  -3.02124023e-02
   -9.91210938e-02  -7.86132812e-02  -6.48498535e-03   1.19140625e-01
   -1.55029297e-01   2.66265869e-03   6.01806641e-02   9.63745117e-02
   -3.43261719e-01  -6.29272461e-02   1.83410645e-02   1.71508789e-01
    4.53186035e-02   9.85107422e-02   8.33892822e-03  -3.57055664e-02
   -2.58300781e-01   8.69750977e-03  -1.25244141e-01   9.41162109e-02
   -3.03344727e-02  -1.88720703e-01  -4.57763672e-02   7.86132812e-02
    2.01660156e-01  -6.07299805e-02  -5.46875000e-02  -1.65710449e-02
    8.38623047e-02   2.47497559e-02   6.86035156e-02  -4.61120605e-02
   -9.08813477e-02   3.22875977e-02   5.96313477e-02  -1.41845703e-01
    7.48291016e-02  -1.26586914e-01   2.36572266e-01  -7.40051270e-03
   -2.16064453e-02   4.85534668e-02  -2.45117188e-01   2.14004517e-03
   -2.71972656e-01  -1.09130859e-01  -3.28979492e-02   1.12304688e-01
   -2.03857422e-01  -6.45751953e-02   2.22778320e-01  -7.13500977e-02
   -2.34680176e-02  -3.70483398e-02   8.26416016e-02   1.64794922e-02
    1.42456055e-01  -8.02612305e-02  -2.12890625e-01   2.90298462e-03
    4.48913574e-02  -2.30102539e-01  -8.69140625e-02  -1.02722168e-01
    4.88891602e-02  -5.49621582e-02  -6.05773926e-02   1.62597656e-01
   -2.48718262e-02  -7.39746094e-02   1.35742188e-01   3.35693359e-02
    2.69012451e-02  -7.22045898e-02   1.13220215e-02   3.70788574e-02
    2.28881836e-03   2.63214111e-02  -1.60278320e-01   1.48803711e-01
    3.49426270e-02   9.17968750e-02  -7.86132812e-02   2.81219482e-02
   -9.56420898e-02   4.01306152e-02  -2.62207031e-01   1.37329102e-01
   -7.58743286e-03   4.04357910e-04   2.42004395e-02  -7.47680664e-02
   -3.41491699e-02  -4.73327637e-02  -6.76879883e-02  -1.92993164e-01
    3.49121094e-02   2.53906250e-01   3.20800781e-01   1.05712891e-01
    2.96325684e-02  -9.21630859e-02  -7.46459961e-02  -3.98635864e-03]]
After layer activation1043_output (1, 256) <class 'numpy.float16'> [[ -1.68823242e-01  -1.45263672e-01  -3.61633301e-02   5.85021973e-02
    1.88293457e-02  -6.30493164e-02   1.28021240e-02   6.35375977e-02
    1.05712891e-01  -1.63818359e-01  -8.94775391e-02   2.06909180e-01
    1.10595703e-01  -1.33361816e-02   8.61816406e-02  -3.10791016e-01
    8.45947266e-02   2.86712646e-02   1.01196289e-01   6.37207031e-02
    2.74902344e-01  -7.84301758e-02  -2.93426514e-02   4.14123535e-02
   -1.41723633e-01   3.28369141e-02   5.27038574e-02  -5.74645996e-02
   -1.65039062e-01  -1.32568359e-01   5.03234863e-02  -1.19079590e-01
    3.06701660e-03  -3.20434570e-04   1.40014648e-01  -1.48315430e-01
   -5.65185547e-02   5.62667847e-03  -1.20849609e-01  -1.18591309e-01
    1.60369873e-02  -2.27416992e-01   1.35742188e-01   1.19018555e-01
    1.04797363e-01  -1.37084961e-01   6.90917969e-02  -6.38427734e-02
   -2.15759277e-02  -1.16271973e-01   7.41577148e-02  -1.63818359e-01
   -6.57348633e-02   2.19482422e-01  -6.59561157e-03   1.23672485e-02
   -1.46713257e-02   2.34741211e-01   1.29150391e-01  -4.87060547e-02
   -1.41845703e-01  -9.99145508e-02  -1.80664062e-02  -3.79943848e-02
    8.50219727e-02  -4.79736328e-02   3.80859375e-02  -1.22070312e-01
   -9.63134766e-02   8.27026367e-03  -3.15185547e-01   3.56750488e-02
    2.82592773e-02   2.42004395e-02   1.60278320e-01  -2.07061768e-02
   -7.87963867e-02  -2.65869141e-01  -1.00219727e-01  -6.14929199e-02
   -1.66748047e-01   4.68444824e-03  -1.18469238e-01  -1.97875977e-01
   -3.43017578e-01   4.34494019e-03  -9.47265625e-02   7.62176514e-03
   -2.23022461e-01  -9.67407227e-02  -1.62719727e-01  -6.10351562e-02
   -3.31420898e-02   9.14001465e-03  -5.56640625e-02   6.74438477e-02
    9.21020508e-02  -4.73937988e-02  -8.89892578e-02  -1.01989746e-01
    9.75036621e-03   1.64794922e-01  -8.24584961e-02   6.43920898e-02
    6.82373047e-02   1.98730469e-01  -4.67224121e-02  -3.42407227e-02
    1.99951172e-01  -2.00927734e-01   1.36474609e-01  -2.21710205e-02
    1.18713379e-01   1.66870117e-01  -9.43603516e-02   3.68408203e-01
   -2.02758789e-01  -1.15905762e-01   2.08892822e-02  -7.65380859e-02
    2.39257812e-01   6.58569336e-02  -7.95364380e-04  -1.25366211e-01
    9.22851562e-02  -2.04101562e-01  -1.33422852e-01  -9.88769531e-02
   -5.52978516e-02  -1.98669434e-02   1.56494141e-01  -1.79138184e-02
    8.36791992e-02   5.16128540e-03  -2.51007080e-03   7.48291016e-02
    8.80737305e-02   2.75878906e-01   5.07354736e-03   8.92333984e-02
   -4.33349609e-03  -4.51049805e-02   1.77734375e-01   2.48718262e-02
   -9.92431641e-02   1.30859375e-01   1.06445312e-01  -1.17980957e-01
   -1.09680176e-01  -1.54418945e-01  -8.75244141e-02  -3.01971436e-02
   -9.88159180e-02  -7.84301758e-02  -6.48498535e-03   1.18591309e-01
   -1.53808594e-01   2.66265869e-03   6.01196289e-02   9.60693359e-02
   -3.30322266e-01  -6.28662109e-02   1.83410645e-02   1.69799805e-01
    4.52880859e-02   9.82055664e-02   8.33892822e-03  -3.57055664e-02
   -2.52685547e-01   8.69750977e-03  -1.24572754e-01   9.38110352e-02
   -3.03192139e-02  -1.86523438e-01  -4.57458496e-02   7.84301758e-02
    1.98974609e-01  -6.06689453e-02  -5.46264648e-02  -1.65710449e-02
    8.36791992e-02   2.47497559e-02   6.84814453e-02  -4.60815430e-02
   -9.06372070e-02   3.22875977e-02   5.95703125e-02  -1.40869141e-01
    7.47070312e-02  -1.25854492e-01   2.32299805e-01  -7.40051270e-03
   -2.16064453e-02   4.85229492e-02  -2.40356445e-01   2.14004517e-03
   -2.65380859e-01  -1.08703613e-01  -3.28979492e-02   1.11816406e-01
   -2.01049805e-01  -6.45141602e-02   2.19116211e-01  -7.12280273e-02
   -2.34680176e-02  -3.70178223e-02   8.24584961e-02   1.64794922e-02
    1.41479492e-01  -8.00781250e-02  -2.09716797e-01   2.90298462e-03
    4.48608398e-02  -2.26074219e-01  -8.66699219e-02  -1.02355957e-01
    4.88586426e-02  -5.49011230e-02  -6.05163574e-02   1.61132812e-01
   -2.48718262e-02  -7.38525391e-02   1.34887695e-01   3.35693359e-02
    2.69012451e-02  -7.20825195e-02   1.13220215e-02   3.70483398e-02
    2.28881836e-03   2.63214111e-02  -1.58935547e-01   1.47705078e-01
    3.49426270e-02   9.15527344e-02  -7.84301758e-02   2.81219482e-02
   -9.53369141e-02   4.01000977e-02  -2.56347656e-01   1.36474609e-01
   -7.58743286e-03   4.04357910e-04   2.42004395e-02  -7.46459961e-02
   -3.41491699e-02  -4.73022461e-02  -6.75659180e-02  -1.90673828e-01
    3.49121094e-02   2.48535156e-01   3.10302734e-01   1.05346680e-01
    2.96173096e-02  -9.19189453e-02  -7.45239258e-02  -3.98635864e-03]]
After layer encoder_birnn_reverse_l0_t7_out_0 (1, 256) <class 'numpy.float16'> [[ -8.76464844e-02  -7.49511719e-02  -1.79595947e-02   3.03649902e-02
    9.52148438e-03  -3.47595215e-02   6.68334961e-03   3.35693359e-02
    6.45751953e-02  -8.74023438e-02  -4.32434082e-02   1.07482910e-01
    6.00585938e-02  -6.52313232e-03   4.43115234e-02  -1.66137695e-01
    4.09851074e-02   1.36184692e-02   5.17272949e-02   3.17382812e-02
    1.34155273e-01  -3.64074707e-02  -1.68762207e-02   2.18811035e-02
   -7.22656250e-02   1.70898438e-02   2.60467529e-02  -2.84118652e-02
   -7.76977539e-02  -6.66503906e-02   2.66418457e-02  -6.26220703e-02
    1.56497955e-03  -1.63197517e-04   6.94580078e-02  -7.18994141e-02
   -2.98919678e-02   2.79617310e-03  -6.21337891e-02  -5.81970215e-02
    8.23974609e-03  -1.12182617e-01   6.77490234e-02   5.98144531e-02
    5.15136719e-02  -6.99462891e-02   3.51562500e-02  -3.04260254e-02
   -1.09176636e-02  -6.18286133e-02   3.86352539e-02  -8.17871094e-02
   -3.10668945e-02   1.12854004e-01  -3.56101990e-03   5.85937500e-03
   -7.93457031e-03   1.19445801e-01   6.54907227e-02  -2.29034424e-02
   -7.39746094e-02  -5.23071289e-02  -9.15527344e-03  -2.07061768e-02
    4.23889160e-02  -2.33612061e-02   2.11181641e-02  -6.29882812e-02
   -4.76074219e-02   4.25720215e-03  -1.58813477e-01   1.81121826e-02
    1.41067505e-02   1.19857788e-02   8.57543945e-02  -1.13067627e-02
   -4.23889160e-02  -1.35498047e-01  -5.35278320e-02  -3.41796875e-02
   -9.13696289e-02   2.58636475e-03  -6.28051758e-02  -1.04125977e-01
   -1.86767578e-01   2.22969055e-03  -4.84619141e-02   3.95584106e-03
   -1.16394043e-01  -4.92553711e-02  -8.86840820e-02  -2.97546387e-02
   -1.57775879e-02   4.63104248e-03  -2.82897949e-02   3.41796875e-02
    4.72717285e-02  -2.44903564e-02  -4.11376953e-02  -4.76989746e-02
    4.69589233e-03   7.60498047e-02  -3.93066406e-02   3.05938721e-02
    3.34777832e-02   9.96704102e-02  -2.28424072e-02  -1.82800293e-02
    1.03271484e-01  -1.05590820e-01   6.90917969e-02  -1.14135742e-02
    5.65185547e-02   8.98437500e-02  -4.70581055e-02   1.99096680e-01
   -9.77783203e-02  -5.69763184e-02   1.06582642e-02  -3.71704102e-02
    1.21704102e-01   3.45764160e-02  -4.13179398e-04  -6.25000000e-02
    4.44946289e-02  -1.04125977e-01  -6.68334961e-02  -4.96215820e-02
   -2.74505615e-02  -9.33074951e-03   7.91625977e-02  -9.78088379e-03
    4.13513184e-02   2.73132324e-03  -1.28650665e-03   3.57055664e-02
    4.72717285e-02   1.41601562e-01   2.71224976e-03   4.56237793e-02
   -2.19154358e-03  -2.24304199e-02   8.58764648e-02   1.30081177e-02
   -4.92553711e-02   6.65283203e-02   5.81054688e-02  -6.17065430e-02
   -5.56335449e-02  -7.64160156e-02  -4.33044434e-02  -1.48696899e-02
   -5.16662598e-02  -4.20227051e-02  -3.19099426e-03   6.14318848e-02
   -8.14819336e-02   1.38854980e-03   3.06396484e-02   5.16357422e-02
   -1.72363281e-01  -3.21960449e-02   9.20104980e-03   9.07592773e-02
    2.36663818e-02   4.68139648e-02   4.79888916e-03  -1.89361572e-02
   -1.16577148e-01   4.40216064e-03  -5.82885742e-02   5.00183105e-02
   -1.59606934e-02  -1.03942871e-01  -2.29187012e-02   4.29382324e-02
    1.07360840e-01  -2.92358398e-02  -2.81982422e-02  -8.19396973e-03
    3.90319824e-02   1.17874146e-02   3.53088379e-02  -2.18963623e-02
   -4.36706543e-02   1.74713135e-02   2.93121338e-02  -7.47070312e-02
    3.64074707e-02  -5.86853027e-02   1.16821289e-01  -3.97491455e-03
   -1.11312866e-02   2.46429443e-02  -1.17004395e-01   1.10721588e-03
   -1.30249023e-01  -5.54809570e-02  -1.74560547e-02   5.68237305e-02
   -1.05041504e-01  -3.57971191e-02   1.14929199e-01  -3.85437012e-02
   -1.23062134e-02  -1.93939209e-02   3.93066406e-02   8.49151611e-03
    6.64672852e-02  -4.37011719e-02  -1.05163574e-01   1.67846680e-03
    2.33306885e-02  -1.22619629e-01  -4.58374023e-02  -4.93164062e-02
    2.51159668e-02  -3.05328369e-02  -2.97393799e-02   7.81860352e-02
   -1.22375488e-02  -3.37219238e-02   7.33642578e-02   1.70288086e-02
    1.39617920e-02  -3.79028320e-02   5.64575195e-03   1.89819336e-02
    1.35231018e-03   1.42440796e-02  -7.99560547e-02   6.75659180e-02
    1.71966553e-02   4.60510254e-02  -3.88488770e-02   1.43051147e-02
   -4.70581055e-02   2.09655762e-02  -1.36230469e-01   6.99462891e-02
   -3.45802307e-03   2.11477280e-04   1.25350952e-02  -4.33654785e-02
   -1.57012939e-02  -2.43835449e-02  -3.35998535e-02  -8.80737305e-02
    1.78527832e-02   1.22314453e-01   1.64672852e-01   4.99877930e-02
    1.57012939e-02  -4.93164062e-02  -3.72009277e-02  -2.05230713e-03]]
After layer expand_dims1049_0 (1, 1, 256) <class 'numpy.float16'> [[[ -8.76464844e-02  -7.49511719e-02  -1.79595947e-02   3.03649902e-02
     9.52148438e-03  -3.47595215e-02   6.68334961e-03   3.35693359e-02
     6.45751953e-02  -8.74023438e-02  -4.32434082e-02   1.07482910e-01
     6.00585938e-02  -6.52313232e-03   4.43115234e-02  -1.66137695e-01
     4.09851074e-02   1.36184692e-02   5.17272949e-02   3.17382812e-02
     1.34155273e-01  -3.64074707e-02  -1.68762207e-02   2.18811035e-02
    -7.22656250e-02   1.70898438e-02   2.60467529e-02  -2.84118652e-02
    -7.76977539e-02  -6.66503906e-02   2.66418457e-02  -6.26220703e-02
     1.56497955e-03  -1.63197517e-04   6.94580078e-02  -7.18994141e-02
    -2.98919678e-02   2.79617310e-03  -6.21337891e-02  -5.81970215e-02
     8.23974609e-03  -1.12182617e-01   6.77490234e-02   5.98144531e-02
     5.15136719e-02  -6.99462891e-02   3.51562500e-02  -3.04260254e-02
    -1.09176636e-02  -6.18286133e-02   3.86352539e-02  -8.17871094e-02
    -3.10668945e-02   1.12854004e-01  -3.56101990e-03   5.85937500e-03
    -7.93457031e-03   1.19445801e-01   6.54907227e-02  -2.29034424e-02
    -7.39746094e-02  -5.23071289e-02  -9.15527344e-03  -2.07061768e-02
     4.23889160e-02  -2.33612061e-02   2.11181641e-02  -6.29882812e-02
    -4.76074219e-02   4.25720215e-03  -1.58813477e-01   1.81121826e-02
     1.41067505e-02   1.19857788e-02   8.57543945e-02  -1.13067627e-02
    -4.23889160e-02  -1.35498047e-01  -5.35278320e-02  -3.41796875e-02
    -9.13696289e-02   2.58636475e-03  -6.28051758e-02  -1.04125977e-01
    -1.86767578e-01   2.22969055e-03  -4.84619141e-02   3.95584106e-03
    -1.16394043e-01  -4.92553711e-02  -8.86840820e-02  -2.97546387e-02
    -1.57775879e-02   4.63104248e-03  -2.82897949e-02   3.41796875e-02
     4.72717285e-02  -2.44903564e-02  -4.11376953e-02  -4.76989746e-02
     4.69589233e-03   7.60498047e-02  -3.93066406e-02   3.05938721e-02
     3.34777832e-02   9.96704102e-02  -2.28424072e-02  -1.82800293e-02
     1.03271484e-01  -1.05590820e-01   6.90917969e-02  -1.14135742e-02
     5.65185547e-02   8.98437500e-02  -4.70581055e-02   1.99096680e-01
    -9.77783203e-02  -5.69763184e-02   1.06582642e-02  -3.71704102e-02
     1.21704102e-01   3.45764160e-02  -4.13179398e-04  -6.25000000e-02
     4.44946289e-02  -1.04125977e-01  -6.68334961e-02  -4.96215820e-02
    -2.74505615e-02  -9.33074951e-03   7.91625977e-02  -9.78088379e-03
     4.13513184e-02   2.73132324e-03  -1.28650665e-03   3.57055664e-02
     4.72717285e-02   1.41601562e-01   2.71224976e-03   4.56237793e-02
    -2.19154358e-03  -2.24304199e-02   8.58764648e-02   1.30081177e-02
    -4.92553711e-02   6.65283203e-02   5.81054688e-02  -6.17065430e-02
    -5.56335449e-02  -7.64160156e-02  -4.33044434e-02  -1.48696899e-02
    -5.16662598e-02  -4.20227051e-02  -3.19099426e-03   6.14318848e-02
    -8.14819336e-02   1.38854980e-03   3.06396484e-02   5.16357422e-02
    -1.72363281e-01  -3.21960449e-02   9.20104980e-03   9.07592773e-02
     2.36663818e-02   4.68139648e-02   4.79888916e-03  -1.89361572e-02
    -1.16577148e-01   4.40216064e-03  -5.82885742e-02   5.00183105e-02
    -1.59606934e-02  -1.03942871e-01  -2.29187012e-02   4.29382324e-02
     1.07360840e-01  -2.92358398e-02  -2.81982422e-02  -8.19396973e-03
     3.90319824e-02   1.17874146e-02   3.53088379e-02  -2.18963623e-02
    -4.36706543e-02   1.74713135e-02   2.93121338e-02  -7.47070312e-02
     3.64074707e-02  -5.86853027e-02   1.16821289e-01  -3.97491455e-03
    -1.11312866e-02   2.46429443e-02  -1.17004395e-01   1.10721588e-03
    -1.30249023e-01  -5.54809570e-02  -1.74560547e-02   5.68237305e-02
    -1.05041504e-01  -3.57971191e-02   1.14929199e-01  -3.85437012e-02
    -1.23062134e-02  -1.93939209e-02   3.93066406e-02   8.49151611e-03
     6.64672852e-02  -4.37011719e-02  -1.05163574e-01   1.67846680e-03
     2.33306885e-02  -1.22619629e-01  -4.58374023e-02  -4.93164062e-02
     2.51159668e-02  -3.05328369e-02  -2.97393799e-02   7.81860352e-02
    -1.22375488e-02  -3.37219238e-02   7.33642578e-02   1.70288086e-02
     1.39617920e-02  -3.79028320e-02   5.64575195e-03   1.89819336e-02
     1.35231018e-03   1.42440796e-02  -7.99560547e-02   6.75659180e-02
     1.71966553e-02   4.60510254e-02  -3.88488770e-02   1.43051147e-02
    -4.70581055e-02   2.09655762e-02  -1.36230469e-01   6.99462891e-02
    -3.45802307e-03   2.11477280e-04   1.25350952e-02  -4.33654785e-02
    -1.57012939e-02  -2.43835449e-02  -3.35998535e-02  -8.80737305e-02
     1.78527832e-02   1.22314453e-01   1.64672852e-01   4.99877930e-02
     1.57012939e-02  -4.93164062e-02  -3.72009277e-02  -2.05230713e-03]]]
After layer encoder_birnn_reverse_l0_t8_i2h_output (1, 1024) <class 'numpy.float16'> [[-0.0128479  -0.04095459  0.03787231 ...,  0.06970215 -0.04626465
   0.03759766]]
After layer encoder_birnn_reverse_l0_t8_h2h_output (1, 1024) <class 'numpy.float16'> [[-0.00221252  0.01064301 -0.09033203 ...,  0.08190918  0.04467773
   0.0199585 ]]
After layer _plus1044_0 (1, 1024) <class 'numpy.float16'> [[-0.01506042 -0.03030396 -0.05245972 ...,  0.15161133 -0.00158691
   0.05755615]]
After layer encoder_birnn_reverse_l0_t8_slice_output0 (1, 256) <class 'numpy.float16'> [[ -1.50604248e-02  -3.03039551e-02  -5.24597168e-02  -3.07312012e-02
   -2.82592773e-02  -3.72314453e-02  -1.61132812e-02  -3.20434570e-04
    9.64355469e-02   7.71484375e-02  -5.59082031e-02   1.16027832e-01
    1.83105469e-03   1.35040283e-02  -6.71386719e-04   3.30566406e-01
   -1.41967773e-01  -9.95483398e-02   1.31378174e-02  -1.10778809e-02
    1.21093750e-01  -5.18798828e-03  -1.57958984e-01  -6.03637695e-02
    5.14526367e-02  -1.31591797e-01  -3.04565430e-02  -1.29699707e-03
   -9.58251953e-03  -2.15759277e-02  -1.01852417e-02  -1.07727051e-02
   -6.29882812e-02  -4.40063477e-02   9.32617188e-02  -1.76757812e-01
   -1.84020996e-02  -1.95922852e-02  -9.36279297e-02  -8.85620117e-02
   -1.91650391e-01   2.53906250e-02  -4.66613770e-02   9.21630859e-03
    2.78472900e-02  -2.20642090e-02   7.92236328e-02  -9.19799805e-02
   -5.99670410e-02   2.45056152e-02   3.36914062e-02   1.16027832e-01
   -1.95434570e-01   9.20410156e-02   1.86767578e-01   1.31103516e-01
   -8.17260742e-02   1.57318115e-02  -9.96093750e-02  -9.75036621e-03
    9.77172852e-02  -7.43408203e-02   1.60766602e-01  -2.47802734e-02
   -1.14807129e-01  -4.28466797e-02   1.19750977e-01  -2.23846436e-02
   -1.20849609e-01  -1.18408203e-02   1.15722656e-01  -1.83258057e-02
   -2.61840820e-02  -3.69262695e-02   2.12402344e-02   4.68750000e-02
    1.16149902e-01   1.79687500e-01   5.37414551e-02   7.20825195e-02
    2.43530273e-02   4.83398438e-02   9.50927734e-02  -2.91442871e-02
    1.69433594e-01   2.56042480e-02  -2.43682861e-02  -1.03393555e-01
   -1.41296387e-02   4.75463867e-02   1.22131348e-01   1.06811523e-02
   -8.85620117e-02   7.12890625e-02   7.28149414e-02   3.29284668e-02
   -3.30810547e-02   7.75146484e-03  -1.30004883e-01  -1.43066406e-01
   -1.44653320e-01   7.63549805e-02   2.41699219e-02  -1.08642578e-01
   -1.54296875e-01   5.41687012e-03  -3.06854248e-02  -1.11816406e-01
    8.14819336e-02  -1.75781250e-02  -1.00036621e-01  -2.08129883e-02
    3.58276367e-02   2.63183594e-01   2.20947266e-02   3.22753906e-01
   -1.94702148e-02   6.66809082e-03  -6.22558594e-03  -6.60400391e-02
    2.27294922e-01  -1.30859375e-01  -1.97906494e-02   1.07482910e-01
   -9.41772461e-02   8.49609375e-02  -1.50146484e-01   8.72192383e-02
   -3.54919434e-02   1.14746094e-02   2.41333008e-01   3.97949219e-02
   -8.91113281e-03  -5.56640625e-02  -9.41162109e-02  -1.30004883e-01
    1.24877930e-01   1.70166016e-01  -3.15856934e-02  -1.09100342e-02
   -4.24804688e-02  -1.48437500e-01   1.06445312e-01   5.01403809e-02
   -6.68334961e-03   8.02612305e-03   4.02221680e-02   6.72607422e-02
   -5.37109375e-03   8.31909180e-02   1.30615234e-01  -7.58056641e-02
   -3.44848633e-03  -9.25292969e-02  -1.28906250e-01   2.04345703e-01
    2.65808105e-02  -2.25830078e-03  -2.56042480e-02  -3.01666260e-02
    2.56591797e-01  -5.15747070e-03  -8.31909180e-02   1.52282715e-02
    3.66210938e-03  -8.30688477e-02  -1.38854980e-02  -6.12182617e-02
    2.86254883e-02  -5.10864258e-02  -1.89514160e-02   4.73327637e-02
    4.35638428e-03   9.99145508e-02   1.98516846e-02  -1.95556641e-01
    4.73632812e-02  -1.41967773e-01  -6.93969727e-02  -1.52435303e-02
    6.12182617e-02  -7.94677734e-02  -7.35473633e-03   2.63366699e-02
    1.09130859e-01  -1.34429932e-02  -1.96228027e-02  -5.16357422e-02
    9.70458984e-02   3.11279297e-02  -5.90515137e-02  -4.96215820e-02
    2.83050537e-02  -7.06176758e-02  -8.34960938e-02   1.01074219e-01
    1.17492676e-01  -1.81884766e-01   4.34570312e-02   1.05773926e-01
    1.28173828e-02   9.28955078e-02   8.89282227e-02   8.59985352e-02
    1.66320801e-03  -4.95910645e-02  -1.87683105e-02  -5.00183105e-02
   -8.95996094e-02   3.55834961e-02   5.31005859e-02   1.42089844e-01
    2.14538574e-02   4.22973633e-02  -1.81884766e-02  -2.78320312e-02
   -5.49316406e-03  -2.05078125e-02   4.68139648e-02  -5.69152832e-03
   -7.37915039e-02  -1.40747070e-01   1.20056152e-01  -8.75244141e-02
   -1.09329224e-02   6.86035156e-02  -3.52172852e-02  -1.10534668e-01
   -1.48925781e-01   7.08618164e-02  -1.61437988e-02  -1.64550781e-01
   -1.75323486e-02  -5.82580566e-02   2.60925293e-02   5.94482422e-02
   -4.93621826e-03   8.75854492e-02   3.86047363e-02  -1.99890137e-02
   -1.50146484e-01  -1.63574219e-01   9.47265625e-02   2.41455078e-01
   -7.03125000e-02   1.77612305e-02  -1.34765625e-01  -9.39941406e-02
    9.33837891e-03  -2.17437744e-02   1.83715820e-01  -2.18200684e-02
   -1.38916016e-01   5.72509766e-02   5.38330078e-02   4.60815430e-03]]
After layer encoder_birnn_reverse_l0_t8_slice_output1 (1, 256) <class 'numpy.float16'> [[ 0.16503906  0.05307007  0.12481689  0.03942871 -0.01428223  0.08691406
   0.21057129 -0.10845947  0.41088867  0.19750977  0.13146973  0.16467285
   0.14208984 -0.01039124  0.13891602  0.15795898  0.09222412 -0.01904297
  -0.15405273  0.10449219  0.15930176  0.03112793  0.4831543   0.0793457
   0.13110352  0.08990479  0.18798828  0.07556152  0.13586426  0.04238892
   0.10528564  0.05099487  0.26025391 -0.05249023 -0.00500488 -0.02548218
  -0.0581665   0.17504883  0.0262146   0.08508301 -0.11682129  0.12261963
   0.01908875  0.11401367  0.05490112  0.13696289  0.03881836 -0.14367676
  -0.01699829  0.00784302  0.07983398  0.11383057 -0.06799316  0.16955566
   0.06848145  0.04620361  0.06231689  0.11694336 -0.01821899 -0.11987305
   0.12902832  0.04574585  0.09606934  0.02201843 -0.03366089  0.16967773
   0.23352051  0.09759521 -0.17797852 -0.07012939  0.07623291  0.01165771
  -0.06677246  0.04846191  0.12597656  0.1505127   0.07861328  0.09020996
   0.11761475  0.1138916   0.23974609  0.22009277  0.03918457  0.01815796
   0.21057129 -0.01651001  0.11157227  0.16674805  0.04516602 -0.19458008
   0.36865234  0.07800293  0.08398438  0.07568359 -0.07128906  0.00544739
  -0.02142334  0.01391602 -0.20458984 -0.18933105 -0.09545898 -0.0272522
   0.06130981  0.12475586 -0.03955078 -0.03820801 -0.1184082   0.06149292
   0.1116333  -0.15771484  0.06811523 -0.03042603  0.07958984  0.25048828
   0.10522461  0.22009277  0.15148926  0.14550781  0.04504395  0.12023926
   0.23071289  0.19018555  0.04748535  0.0186615  -0.05767822 -0.00579834
   0.1862793  -0.00379944  0.10986328 -0.12573242  0.16235352  0.11480713
   0.02165222  0.21337891  0.04684448  0.03338623  0.0295105   0.07495117
   0.16418457  0.26000977 -0.06677246  0.03015137  0.09509277  0.04333496
   0.06210327  0.13183594  0.12670898  0.04394531  0.05285645 -0.03704834
  -0.0262146   0.10083008  0.0657959   0.12695312 -0.0369873   0.1953125
   0.10943604 -0.08117676  0.08624268  0.1730957   0.24511719  0.10827637
  -0.03033447  0.10662842  0.12457275 -0.027771    0.31103516 -0.02258301
  -0.00354004 -0.00378418  0.01956177  0.15319824 -0.00366211  0.23083496
  -0.06890869  0.15344238  0.18725586 -0.0383606   0.00158691  0.12585449
   0.08764648 -0.07788086  0.26342773 -0.02931213 -0.00869751  0.05810547
   0.03112793  0.22937012 -0.06506348 -0.08422852 -0.04141235  0.06835938
   0.20483398  0.17736816 -0.19384766  0.01443481  0.0057373  -0.01605225
   0.03567505  0.03131104  0.08392334  0.0329895   0.08813477 -0.01367188
   0.12524414 -0.1505127  -0.06939697  0.19238281 -0.09899902  0.11773682
   0.08087158  0.11798096 -0.0557251   0.04129028 -0.00784302 -0.12365723
   0.07049561  0.11273193 -0.03884888  0.14282227 -0.10406494 -0.11340332
   0.29272461 -0.00254822  0.10620117 -0.00097656  0.03948975  0.07409668
   0.44848633  0.18530273  0.06231689 -0.31762695  0.16918945  0.04440308
   0.09216309 -0.00720215  0.00691223  0.09887695  0.08154297  0.10144043
   0.05291748  0.07592773 -0.012146    0.23193359 -0.1784668  -0.00466919
  -0.10058594 -0.05105591  0.13586426 -0.04495239  0.20361328 -0.20458984
   0.17028809  0.00476074  0.14648438  0.00469971]]
After layer encoder_birnn_reverse_l0_t8_slice_output2 (1, 256) <class 'numpy.float16'> [[ -1.69677734e-01  -1.53930664e-01  -5.17578125e-02   7.32421875e-02
   -1.61743164e-03  -6.39648438e-02  -1.09863281e-02   4.88586426e-02
    1.20605469e-01  -1.91650391e-01  -9.20410156e-02   2.39501953e-01
    1.22070312e-01   2.41088867e-03   9.79003906e-02  -3.07373047e-01
    1.00769043e-01   3.33557129e-02   1.22924805e-01   7.24487305e-02
    3.09570312e-01  -9.11865234e-02  -5.42602539e-02   2.71911621e-02
   -1.48193359e-01   3.39965820e-02   4.23583984e-02  -5.60302734e-02
   -1.72607422e-01  -1.52587891e-01   5.28564453e-02  -1.17797852e-01
    1.28784180e-02  -1.06658936e-02   1.56616211e-01  -1.71875000e-01
   -5.57250977e-02   1.45263672e-02  -1.29150391e-01  -1.35498047e-01
    7.99560547e-03  -2.44628906e-01   1.54541016e-01   1.41601562e-01
    1.13281250e-01  -1.55151367e-01   9.44824219e-02  -7.22045898e-02
   -3.32336426e-02  -1.27685547e-01   6.97631836e-02  -1.77001953e-01
   -5.56640625e-02   2.63671875e-01  -4.84008789e-02   1.03759766e-03
    9.15527344e-05   2.67578125e-01   1.62719727e-01  -5.42602539e-02
   -1.65649414e-01  -1.03820801e-01  -9.36126709e-03  -5.59082031e-02
    1.10839844e-01  -5.46264648e-02   2.93731689e-02  -1.30615234e-01
   -1.13159180e-01   2.05078125e-02  -3.57910156e-01   5.05371094e-02
    7.44628906e-03   2.50701904e-02   1.76513672e-01  -2.13623047e-04
   -9.26513672e-02  -2.97119141e-01  -1.21398926e-01  -7.75756836e-02
   -1.85058594e-01  -8.85009766e-03  -1.34155273e-01  -2.31567383e-01
   -3.69873047e-01  -3.47900391e-03  -6.67114258e-02  -1.36108398e-02
   -2.68066406e-01  -8.12377930e-02  -1.61621094e-01  -5.95092773e-02
   -3.81164551e-02   2.50549316e-02  -5.57861328e-02   8.02001953e-02
    9.00878906e-02  -3.61022949e-02  -9.91210938e-02  -1.37573242e-01
    3.41796875e-03   1.82373047e-01  -9.14306641e-02   8.24584961e-02
    8.63037109e-02   2.39379883e-01  -5.65185547e-02  -2.36206055e-02
    2.23144531e-01  -2.29003906e-01   1.78955078e-01  -4.01611328e-02
    1.47460938e-01   1.78833008e-01  -8.64257812e-02   3.65966797e-01
   -2.34375000e-01  -1.28417969e-01  -1.19552612e-02  -8.03222656e-02
    2.47802734e-01   5.81665039e-02   1.73034668e-02  -1.39526367e-01
    8.71582031e-02  -2.26074219e-01  -1.53076172e-01  -1.12731934e-01
   -6.10961914e-02  -1.51672363e-02   1.81396484e-01  -1.70898438e-03
    9.05761719e-02  -3.57055664e-03  -1.06201172e-02   7.77587891e-02
    8.54492188e-02   2.99072266e-01   1.51596069e-02   9.93652344e-02
   -9.94873047e-03  -4.63562012e-02   1.90185547e-01   1.87683105e-02
   -1.12670898e-01   1.50146484e-01   1.29516602e-01  -1.17065430e-01
   -1.20605469e-01  -1.71386719e-01  -1.07543945e-01  -3.31420898e-02
   -1.22375488e-01  -8.17871094e-02  -1.58386230e-02   1.29760742e-01
   -1.67114258e-01  -2.41699219e-02   6.51855469e-02   1.10656738e-01
   -3.48144531e-01  -5.65795898e-02   8.60595703e-03   1.73583984e-01
    5.36193848e-02   1.04736328e-01  -7.33566284e-03  -3.04412842e-02
   -3.03955078e-01  -6.10351562e-05  -1.43432617e-01   1.22009277e-01
   -1.79290771e-02  -1.74072266e-01  -6.84814453e-02   7.98950195e-02
    2.13256836e-01  -7.97729492e-02  -5.30090332e-02  -6.39343262e-03
    8.35571289e-02   3.47290039e-02   8.48999023e-02  -5.83190918e-02
   -1.09130859e-01   8.72802734e-03   6.67724609e-02  -1.61010742e-01
    4.59289551e-02  -1.16882324e-01   2.83691406e-01   1.22070312e-03
   -2.74658203e-02   5.63964844e-02  -2.97607422e-01   7.62939453e-03
   -3.01269531e-01  -1.44409180e-01  -2.56652832e-02   1.37939453e-01
   -2.34130859e-01  -7.59277344e-02   2.39624023e-01  -8.25195312e-02
   -2.88085938e-02  -4.65698242e-02   9.49707031e-02   2.01568604e-02
    1.66992188e-01  -6.98852539e-02  -2.37304688e-01   5.92041016e-03
    6.05773926e-02  -2.58056641e-01  -1.13525391e-01  -1.21032715e-01
    6.27441406e-02  -6.32934570e-02  -8.07495117e-02   1.86889648e-01
   -2.21252441e-02  -7.44018555e-02   1.57470703e-01   4.20532227e-02
    3.76281738e-02  -8.12377930e-02   1.37634277e-02   4.42504883e-02
   -3.58581543e-02   5.24597168e-02  -1.71020508e-01   1.88964844e-01
    2.40173340e-02   9.69848633e-02  -8.36181641e-02   2.66571045e-02
   -9.99755859e-02   5.40771484e-02  -3.14697266e-01   1.46484375e-01
   -2.80456543e-02   1.15280151e-02   8.54492188e-03  -7.33642578e-02
   -3.86657715e-02  -3.35693359e-02  -8.89892578e-02  -2.31811523e-01
    4.61120605e-02   2.98339844e-01   3.50585938e-01   1.23168945e-01
    1.42669678e-02  -1.01196289e-01  -8.23974609e-02   1.40380859e-03]]
After layer encoder_birnn_reverse_l0_t8_slice_output3 (1, 256) <class 'numpy.float16'> [[ 0.08276367  0.07434082 -0.01159668  0.08111572  0.01745605  0.20825195
   0.08227539  0.10827637  0.4765625   0.14453125 -0.07104492  0.08300781
   0.17773438 -0.0463562   0.06256104  0.14916992 -0.06140137 -0.10101318
   0.05133057 -0.00189209 -0.050354   -0.15075684  0.32104492  0.11724854
   0.03015137  0.09368896 -0.0266571  -0.02648926 -0.12597656  0.00869751
   0.11993408  0.10614014  0.04614258  0.04187012 -0.01159668 -0.06817627
   0.1204834  -0.01190186  0.04922485 -0.04638672  0.04391479 -0.02453613
  -0.00252533  0.01522827 -0.03103638  0.04434204  0.04104614 -0.1050415
   0.02468872  0.13085938  0.08520508  0.00531006 -0.12719727  0.05914307
   0.17016602 -0.10266113  0.1706543   0.04077148  0.02732849 -0.11950684
   0.09710693  0.10418701  0.02749634  0.18798828 -0.00796509 -0.04620361
   0.22924805  0.06835938 -0.03503418  0.0491333   0.01457214  0.0308075
  -0.00448608 -0.01882935  0.1541748   0.1751709   0.15405273  0.03823853
   0.14575195  0.23034668  0.20239258  0.21459961  0.1328125   0.10083008
   0.18579102  0.0534668   0.05499268  0.06652832  0.09051514  0.02862549
   0.18969727 -0.05105591 -0.10205078  0.02792358  0.0255127   0.02746582
   0.04980469  0.04974365 -0.15441895 -0.13647461 -0.08288574 -0.15930176
  -0.09924316 -0.1038208  -0.04534912  0.00377655 -0.04776001  0.14038086
   0.07043457  0.08514404  0.0352478   0.06008911 -0.10150146  0.16235352
  -0.00726318  0.16809082 -0.06799316 -0.03759766  0.0401001  -0.05718994
   0.04129028  0.1027832   0.07629395 -0.01145935 -0.0793457   0.0451355
   0.01364136  0.012146   -0.01055908 -0.13024902  0.02871704  0.18127441
  -0.02244568  0.12695312  0.05245972 -0.09753418  0.15759277  0.05001831
   0.14782715  0.05352783  0.0272522  -0.01248169 -0.06280518  0.10119629
  -0.01864624  0.03955078  0.19921875  0.10314941  0.02703857 -0.02377319
  -0.01721191 -0.02914429  0.1038208   0.15063477 -0.04248047  0.07006836
   0.1295166   0.07849121  0.03872681  0.1595459   0.09118652  0.06069946
   0.01373291  0.140625    0.09716797 -0.10107422  0.32373047  0.12670898
  -0.1619873   0.02949524 -0.13903809  0.14428711  0.11810303  0.24487305
  -0.00146484  0.1965332   0.16235352 -0.07696533  0.05853271 -0.02490234
  -0.14245605 -0.10723877  0.07281494 -0.10888672 -0.08148193  0.18029785
  -0.04022217  0.12976074 -0.05950928 -0.14599609  0.01055908  0.15356445
   0.06732178  0.03845215 -0.07861328  0.07714844 -0.04000854  0.04003906
   0.12609863  0.04345703  0.0949707   0.22241211  0.10070801  0.17138672
   0.09979248  0.09710693 -0.10205078  0.06835938 -0.13000488  0.19262695
   0.00939941  0.32666016  0.0892334   0.17871094  0.12536621 -0.08337402
   0.059021    0.24401855 -0.03292847 -0.05963135 -0.02886963 -0.18969727
   0.1887207   0.02928162  0.07769775  0.10601807 -0.00494385  0.0539856
   0.39111328  0.1541748   0.01145935 -0.18237305 -0.03158569  0.01657104
  -0.01605225  0.04180908 -0.02085876  0.10028076  0.13330078  0.06045532
  -0.20043945  0.09631348  0.06719971  0.33300781 -0.17956543  0.06591797
  -0.02423096 -0.16247559  0.04763794 -0.0380249   0.13085938 -0.10821533
   0.12988281  0.15161133 -0.00158691  0.05755615]]
After layer encoder_birnn_reverse_l0_t8_o_output (1, 256) <class 'numpy.float16'> [[ 0.52050781  0.51855469  0.49707031  0.52050781  0.50439453  0.55175781
   0.52050781  0.52685547  0.61669922  0.53613281  0.48217773  0.52050781
   0.54443359  0.48852539  0.515625    0.53710938  0.48461914  0.47485352
   0.51269531  0.49951172  0.48730469  0.46240234  0.57958984  0.52929688
   0.50732422  0.5234375   0.4934082   0.4934082   0.46850586  0.50195312
   0.52978516  0.52636719  0.51171875  0.51025391  0.49707031  0.48291016
   0.53027344  0.49707031  0.51220703  0.48852539  0.51074219  0.49389648
   0.49926758  0.50390625  0.4921875   0.51123047  0.51025391  0.47387695
   0.50634766  0.53271484  0.52148438  0.50146484  0.46826172  0.51464844
   0.54248047  0.47436523  0.54248047  0.51025391  0.50683594  0.47021484
   0.52441406  0.52587891  0.50683594  0.546875    0.49804688  0.48852539
   0.55712891  0.51708984  0.49121094  0.51220703  0.50341797  0.5078125
   0.4987793   0.49536133  0.53857422  0.54345703  0.53857422  0.50976562
   0.53613281  0.55712891  0.55029297  0.55322266  0.53320312  0.52539062
   0.54638672  0.51318359  0.51367188  0.51660156  0.52246094  0.50732422
   0.54736328  0.48730469  0.47460938  0.50683594  0.50634766  0.50683594
   0.51220703  0.51220703  0.46142578  0.46582031  0.47924805  0.46020508
   0.47509766  0.47412109  0.48876953  0.50097656  0.48803711  0.53515625
   0.51757812  0.52148438  0.50878906  0.51513672  0.47460938  0.54052734
   0.49829102  0.54199219  0.48291016  0.49072266  0.51025391  0.4855957
   0.51025391  0.52587891  0.51904297  0.49707031  0.48022461  0.51123047
   0.50341797  0.50292969  0.49731445  0.4675293   0.50732422  0.54541016
   0.49438477  0.53173828  0.51318359  0.47558594  0.53955078  0.51269531
   0.53710938  0.51318359  0.50683594  0.49682617  0.484375    0.52539062
   0.49536133  0.50976562  0.54980469  0.52587891  0.50683594  0.49414062
   0.49560547  0.49267578  0.52587891  0.53759766  0.48950195  0.51757812
   0.53222656  0.51953125  0.50976562  0.54003906  0.52294922  0.51513672
   0.50341797  0.53515625  0.52441406  0.47485352  0.58007812  0.53173828
   0.45947266  0.50732422  0.46533203  0.53613281  0.52929688  0.56103516
   0.49975586  0.54882812  0.54052734  0.48071289  0.51464844  0.49389648
   0.46435547  0.47314453  0.51806641  0.47290039  0.47973633  0.54492188
   0.48999023  0.53222656  0.48510742  0.46362305  0.50244141  0.53808594
   0.51660156  0.50976562  0.48046875  0.51904297  0.48999023  0.50976562
   0.53125     0.51074219  0.52392578  0.55517578  0.52539062  0.54296875
   0.52490234  0.52441406  0.47460938  0.51708984  0.4675293   0.54785156
   0.50244141  0.58105469  0.52246094  0.54443359  0.53125     0.47924805
   0.51464844  0.56054688  0.49169922  0.48510742  0.49267578  0.45263672
   0.546875    0.50732422  0.51953125  0.52636719  0.4987793   0.51367188
   0.59667969  0.53857422  0.50292969  0.45458984  0.4921875   0.50390625
   0.49609375  0.51025391  0.49487305  0.52490234  0.53320312  0.51513672
   0.44995117  0.52392578  0.51660156  0.58251953  0.45532227  0.51660156
   0.49389648  0.45947266  0.51171875  0.49047852  0.53271484  0.47290039
   0.53222656  0.53759766  0.49951172  0.51416016]]
After layer encoder_birnn_reverse_l0_t8_f_output (1, 256) <class 'numpy.float16'> [[ 0.54101562  0.51318359  0.53125     0.50976562  0.49633789  0.52148438
   0.55224609  0.47290039  0.60107422  0.54931641  0.53271484  0.54101562
   0.53564453  0.49731445  0.53466797  0.53955078  0.52294922  0.49536133
   0.46166992  0.52587891  0.53955078  0.5078125   0.61865234  0.52001953
   0.53271484  0.52246094  0.546875    0.51904297  0.53369141  0.51074219
   0.52636719  0.51269531  0.56494141  0.48681641  0.4987793   0.49365234
   0.48535156  0.54345703  0.50634766  0.52148438  0.47094727  0.53076172
   0.50488281  0.52832031  0.51367188  0.53417969  0.50976562  0.46411133
   0.49584961  0.50195312  0.52001953  0.52832031  0.48291016  0.54248047
   0.51708984  0.51171875  0.515625    0.52929688  0.49536133  0.4699707
   0.53222656  0.51123047  0.52392578  0.50537109  0.49169922  0.54248047
   0.55810547  0.52441406  0.45556641  0.48242188  0.51904297  0.50292969
   0.48339844  0.51220703  0.53125     0.53759766  0.51953125  0.52246094
   0.52929688  0.52832031  0.55957031  0.5546875   0.50976562  0.50439453
   0.55224609  0.49584961  0.52783203  0.54150391  0.51123047  0.45141602
   0.59130859  0.51953125  0.52099609  0.51904297  0.48217773  0.50146484
   0.49462891  0.50341797  0.44897461  0.45288086  0.47607422  0.49316406
   0.51513672  0.53125     0.49023438  0.49047852  0.47045898  0.51513672
   0.52783203  0.46069336  0.51708984  0.49243164  0.52001953  0.5625
   0.52636719  0.5546875   0.53759766  0.53613281  0.51123047  0.52978516
   0.55761719  0.54736328  0.51171875  0.50488281  0.4855957   0.49853516
   0.54638672  0.49902344  0.52734375  0.46850586  0.54052734  0.52880859
   0.50537109  0.55322266  0.51171875  0.50830078  0.50732422  0.51855469
   0.54101562  0.56445312  0.48339844  0.50732422  0.52392578  0.51074219
   0.515625    0.53271484  0.53173828  0.51074219  0.51318359  0.49072266
   0.4934082   0.52539062  0.51660156  0.53173828  0.49072266  0.54882812
   0.52734375  0.47973633  0.52148438  0.54296875  0.56103516  0.52685547
   0.49243164  0.52685547  0.53125     0.49316406  0.57714844  0.49438477
   0.49902344  0.49902344  0.50488281  0.53808594  0.49902344  0.55761719
   0.48266602  0.53808594  0.546875    0.49047852  0.50048828  0.53125
   0.52197266  0.48046875  0.56542969  0.49267578  0.49780273  0.51464844
   0.5078125   0.55712891  0.48364258  0.47900391  0.48974609  0.51708984
   0.55126953  0.54443359  0.45166016  0.50341797  0.50146484  0.49609375
   0.50878906  0.5078125   0.52099609  0.50830078  0.52197266  0.49658203
   0.53125     0.46240234  0.48266602  0.54785156  0.4753418   0.52929688
   0.52001953  0.52929688  0.48608398  0.51025391  0.49804688  0.46923828
   0.51757812  0.52832031  0.49023438  0.53564453  0.47412109  0.47167969
   0.57275391  0.49926758  0.52636719  0.49975586  0.50976562  0.51855469
   0.61035156  0.54638672  0.515625    0.42114258  0.54199219  0.51123047
   0.52294922  0.49829102  0.50195312  0.52490234  0.52050781  0.52539062
   0.51318359  0.51904297  0.49707031  0.55761719  0.45556641  0.4987793
   0.47485352  0.48730469  0.53369141  0.48876953  0.55078125  0.44897461
   0.54248047  0.50097656  0.53662109  0.50097656]]
After layer _mul2088_0 (1, 256) <class 'numpy.float16'> [[ -9.22241211e-02  -7.50732422e-02  -1.92260742e-02   2.98461914e-02
    9.34600830e-03  -3.28979492e-02   7.06863403e-03   3.00750732e-02
    6.37817383e-02  -9.08203125e-02  -4.77905273e-02   1.13586426e-01
    5.94787598e-02  -6.63375854e-03   4.62036133e-02  -1.73461914e-01
    4.43420410e-02   1.42135620e-02   4.68750000e-02   3.35388184e-02
    1.52221680e-01  -3.99169922e-02  -1.81579590e-02   2.15454102e-02
   -7.59887695e-02   1.71508789e-02   2.88543701e-02  -2.98614502e-02
   -8.88671875e-02  -6.80541992e-02   2.65045166e-02  -6.13403320e-02
    1.73282623e-03  -1.56044960e-04   7.03125000e-02  -7.37304688e-02
   -2.74658203e-02   3.05747986e-03  -6.14929199e-02  -6.21337891e-02
    7.55310059e-03  -1.22863770e-01   6.89697266e-02   6.31713867e-02
    5.40161133e-02  -7.36694336e-02   3.52783203e-02  -2.96630859e-02
   -1.06964111e-02  -5.86242676e-02   3.86352539e-02  -8.73413086e-02
   -3.17993164e-02   1.21032715e-01  -3.41033936e-03   6.32858276e-03
   -7.56454468e-03   1.26586914e-01   6.43310547e-02  -2.29034424e-02
   -7.59887695e-02  -5.12390137e-02  -9.46807861e-03  -1.92108154e-02
    4.19006348e-02  -2.60467529e-02   2.12707520e-02  -6.43310547e-02
   -4.40063477e-02   3.99017334e-03  -1.69311523e-01   1.79443359e-02
    1.36642456e-02   1.23977661e-02   8.58764648e-02  -1.11312866e-02
   -4.10461426e-02  -1.42333984e-01  -5.32531738e-02  -3.25317383e-02
   -9.41772461e-02   2.59780884e-03  -6.06689453e-02  -1.01135254e-01
   -1.97387695e-01   2.15530396e-03  -5.01708984e-02   4.12750244e-03
   -1.15966797e-01  -4.38232422e-02  -9.71069336e-02  -3.17382812e-02
   -1.72729492e-02   4.74548340e-03  -2.68707275e-02   3.38745117e-02
    4.56848145e-02  -2.38800049e-02  -4.00695801e-02  -4.63562012e-02
    4.64248657e-03   8.19702148e-02  -4.25720215e-02   3.42407227e-02
    3.35083008e-02   9.88159180e-02  -2.19879150e-02  -1.76391602e-02
    1.06933594e-01  -9.38720703e-02   7.09838867e-02  -1.09176636e-02
    6.20117188e-02   9.47265625e-02  -4.98352051e-02   2.14477539e-01
   -1.10534668e-01  -6.24389648e-02   1.06811523e-02  -4.06188965e-02
    1.36108398e-01   3.61022949e-02  -4.06980515e-04  -6.35986328e-02
    4.49218750e-02  -1.03210449e-01  -7.33642578e-02  -4.94995117e-02
   -2.91900635e-02  -9.30786133e-03   8.53271484e-02  -9.47570801e-03
    4.23889160e-02   2.85530090e-03  -1.28459930e-03   3.80859375e-02
    4.47998047e-02   1.46850586e-01   2.74467468e-03   5.05065918e-02
   -2.09426880e-03  -2.29034424e-02   9.41162109e-02   1.27029419e-02
   -5.13305664e-02   7.01293945e-02   5.68237305e-02  -6.05468750e-02
   -5.65185547e-02  -7.63549805e-02  -4.33044434e-02  -1.58691406e-02
   -5.12084961e-02  -4.18090820e-02  -3.18145752e-03   6.53686523e-02
   -8.17260742e-02   1.27696991e-03   3.13720703e-02   5.23376465e-02
   -1.92626953e-01  -3.31420898e-02   9.03320312e-03   9.03320312e-02
    2.40783691e-02   4.85839844e-02   4.81414795e-03  -1.76544189e-02
   -1.28906250e-01   4.34112549e-03  -6.32324219e-02   5.06286621e-02
   -1.51367188e-02  -1.05224609e-01  -2.20947266e-02   4.22973633e-02
    1.10290527e-01  -2.97851562e-02  -2.73742676e-02  -8.80432129e-03
    4.37622070e-02   1.18942261e-02   3.87878418e-02  -2.27203369e-02
   -4.52270508e-02   1.66168213e-02   3.02886963e-02  -7.90405273e-02
    3.61938477e-02  -6.06384277e-02   1.15844727e-01  -3.82614136e-03
   -1.19094849e-02   2.64282227e-02  -1.10717773e-01   1.07765198e-03
   -1.36352539e-01  -5.41381836e-02  -1.67388916e-02   5.70373535e-02
   -1.06201172e-01  -3.28369141e-02   1.16271973e-01  -3.54309082e-02
   -1.24664307e-02  -1.71356201e-02   3.98864746e-02   9.02557373e-03
    6.76879883e-02  -4.24804688e-02  -1.10717773e-01   1.53636932e-03
    2.18200684e-02  -1.17431641e-01  -4.32739258e-02  -4.81872559e-02
    2.52990723e-02  -2.90374756e-02  -2.96936035e-02   8.70971680e-02
   -1.17950439e-02  -3.48815918e-02   7.77587891e-02   1.67541504e-02
    1.41601562e-02  -3.60717773e-02   5.77163696e-03   1.92260742e-02
    1.39713287e-03   1.43814087e-02  -8.26416016e-02   6.26831055e-02
    1.89361572e-02   4.69360352e-02  -4.11071777e-02   1.40151978e-02
   -4.80041504e-02   2.10571289e-02  -1.36474609e-01   7.21435547e-02
   -3.89289856e-03   2.09927559e-04   1.20315552e-02  -4.16870117e-02
   -1.55563354e-02  -2.36053467e-02  -3.21350098e-02  -9.40551758e-02
    1.86309814e-02   1.24084473e-01   1.76635742e-01   4.74548340e-02
    1.60675049e-02  -4.61730957e-02  -4.00695801e-02  -1.99699402e-03]]
After layer encoder_birnn_reverse_l0_t8_i_output (1, 256) <class 'numpy.float16'> [[ 0.49633789  0.49243164  0.48681641  0.49243164  0.49291992  0.49072266
   0.49609375  0.5         0.52392578  0.51904297  0.48608398  0.52880859
   0.50048828  0.50341797  0.49975586  0.58203125  0.46459961  0.47509766
   0.50341797  0.49731445  0.53027344  0.4987793   0.46069336  0.48486328
   0.51269531  0.46704102  0.49243164  0.49975586  0.49755859  0.49462891
   0.49755859  0.49731445  0.484375    0.48901367  0.5234375   0.45581055
   0.49536133  0.49511719  0.4765625   0.4777832   0.45214844  0.50634766
   0.48828125  0.50244141  0.50683594  0.49438477  0.52001953  0.47705078
   0.48510742  0.50634766  0.50830078  0.52880859  0.45141602  0.52294922
   0.54638672  0.53271484  0.47949219  0.50390625  0.47509766  0.49755859
   0.52441406  0.48144531  0.54003906  0.49389648  0.47143555  0.48925781
   0.52978516  0.49438477  0.46972656  0.49707031  0.52880859  0.49536133
   0.4934082   0.49072266  0.50537109  0.51171875  0.52880859  0.54492188
   0.51367188  0.51806641  0.50585938  0.51220703  0.52392578  0.49267578
   0.54248047  0.50634766  0.49389648  0.47412109  0.49658203  0.51171875
   0.53027344  0.50244141  0.4777832   0.51757812  0.51806641  0.50830078
   0.49169922  0.50195312  0.4675293   0.46435547  0.46386719  0.51904297
   0.50585938  0.47290039  0.46142578  0.50146484  0.49243164  0.47216797
   0.52050781  0.49560547  0.47509766  0.49487305  0.50878906  0.56542969
   0.50537109  0.58007812  0.49511719  0.50146484  0.49853516  0.48339844
   0.55664062  0.46728516  0.49511719  0.52685547  0.4765625   0.52099609
   0.46264648  0.52197266  0.49121094  0.50292969  0.56005859  0.50976562
   0.49780273  0.48608398  0.4765625   0.4675293   0.53125     0.54248047
   0.4921875   0.49731445  0.48950195  0.46289062  0.52636719  0.51269531
   0.49829102  0.50195312  0.51025391  0.51660156  0.49853516  0.52099609
   0.53271484  0.48095703  0.49902344  0.47680664  0.46777344  0.55078125
   0.50683594  0.49951172  0.49365234  0.49243164  0.56396484  0.4987793
   0.47924805  0.50390625  0.50097656  0.47924805  0.49658203  0.48461914
   0.50732422  0.48730469  0.49536133  0.51171875  0.50097656  0.52490234
   0.50488281  0.45117188  0.51171875  0.46459961  0.48266602  0.49609375
   0.51513672  0.48022461  0.49804688  0.50634766  0.52734375  0.49658203
   0.49511719  0.48706055  0.52441406  0.5078125   0.48535156  0.48754883
   0.50683594  0.48242188  0.47924805  0.52539062  0.52929688  0.45458984
   0.51074219  0.52636719  0.50341797  0.5234375   0.52246094  0.52148438
   0.50048828  0.48754883  0.49536133  0.48754883  0.47753906  0.50878906
   0.51318359  0.53564453  0.50537109  0.51074219  0.49536133  0.49316406
   0.49853516  0.49487305  0.51171875  0.49853516  0.48144531  0.46484375
   0.52978516  0.47802734  0.49731445  0.51708984  0.49121094  0.47241211
   0.46289062  0.51757812  0.49584961  0.45898438  0.49560547  0.48535156
   0.50634766  0.51464844  0.4987793   0.52197266  0.50976562  0.49511719
   0.46264648  0.45922852  0.5234375   0.56005859  0.48242188  0.50439453
   0.46630859  0.4765625   0.50244141  0.49462891  0.54589844  0.49462891
   0.46533203  0.51416016  0.51367188  0.50097656]]
After layer encoder_birnn_reverse_l0_t8_c_output (1, 256) <class 'numpy.float16'> [[ -1.68090820e-01  -1.52709961e-01  -5.16967773e-02   7.31201172e-02
   -1.61743164e-03  -6.39038086e-02  -1.09863281e-02   4.88281250e-02
    1.19995117e-01  -1.89331055e-01  -9.17968750e-02   2.34985352e-01
    1.21459961e-01   2.41088867e-03   9.75952148e-02  -2.98095703e-01
    1.00402832e-01   3.33557129e-02   1.22314453e-01   7.23266602e-02
    3.00048828e-01  -9.09423828e-02  -5.41992188e-02   2.71911621e-02
   -1.47094727e-01   3.39965820e-02   4.23278809e-02  -5.59692383e-02
   -1.70898438e-01  -1.51367188e-01   5.27954102e-02  -1.17248535e-01
    1.28784180e-02  -1.06658936e-02   1.55395508e-01  -1.70166016e-01
   -5.56640625e-02   1.45263672e-02  -1.28417969e-01  -1.34643555e-01
    7.99560547e-03  -2.39868164e-01   1.53320312e-01   1.40625000e-01
    1.12792969e-01  -1.53930664e-01   9.41772461e-02  -7.20825195e-02
   -3.32336426e-02  -1.26953125e-01   6.96411133e-02  -1.75170898e-01
   -5.56030273e-02   2.57812500e-01  -4.83703613e-02   1.03759766e-03
    9.15527344e-05   2.61474609e-01   1.61254883e-01  -5.41992188e-02
   -1.64184570e-01  -1.03454590e-01  -9.36126709e-03  -5.58471680e-02
    1.10412598e-01  -5.45654297e-02   2.93579102e-02  -1.29882812e-01
   -1.12670898e-01   2.05078125e-02  -3.43261719e-01   5.05065918e-02
    7.44628906e-03   2.50701904e-02   1.74682617e-01  -2.13623047e-04
   -9.24072266e-02  -2.88574219e-01  -1.20788574e-01  -7.73925781e-02
   -1.82983398e-01  -8.85009766e-03  -1.33300781e-01  -2.27539062e-01
   -3.53759766e-01  -3.47900391e-03  -6.65893555e-02  -1.36108398e-02
   -2.61718750e-01  -8.10546875e-02  -1.60278320e-01  -5.94482422e-02
   -3.80859375e-02   2.50549316e-02  -5.57250977e-02   8.00170898e-02
    8.98437500e-02  -3.60717773e-02  -9.88159180e-02  -1.36718750e-01
    3.41796875e-03   1.80419922e-01  -9.11865234e-02   8.22753906e-02
    8.60595703e-02   2.34863281e-01  -5.64575195e-02  -2.36206055e-02
    2.19482422e-01  -2.25097656e-01   1.77124023e-01  -4.01306152e-02
    1.46362305e-01   1.77001953e-01  -8.61816406e-02   3.50341797e-01
   -2.30224609e-01  -1.27685547e-01  -1.19552612e-02  -8.01391602e-02
    2.42797852e-01   5.81054688e-02   1.73034668e-02  -1.38671875e-01
    8.69140625e-02  -2.22290039e-01  -1.51855469e-01  -1.12243652e-01
   -6.10351562e-02  -1.51672363e-02   1.79443359e-01  -1.70898438e-03
    9.03320312e-02  -3.57055664e-03  -1.06201172e-02   7.75756836e-02
    8.52661133e-02   2.90527344e-01   1.51596069e-02   9.90600586e-02
   -9.94873047e-03  -4.63256836e-02   1.87866211e-01   1.87683105e-02
   -1.12182617e-01   1.49047852e-01   1.28784180e-01  -1.16516113e-01
   -1.19995117e-01  -1.69677734e-01  -1.07116699e-01  -3.31420898e-02
   -1.21765137e-01  -8.16040039e-02  -1.58386230e-02   1.29028320e-01
   -1.65527344e-01  -2.41699219e-02   6.50634766e-02   1.10229492e-01
   -3.34716797e-01  -5.65185547e-02   8.60595703e-03   1.71875000e-01
    5.35583496e-02   1.04370117e-01  -7.33566284e-03  -3.04260254e-02
   -2.94921875e-01  -6.10351562e-05  -1.42456055e-01   1.21398926e-01
   -1.79290771e-02  -1.72363281e-01  -6.83593750e-02   7.97119141e-02
    2.10083008e-01  -7.95898438e-02  -5.29479980e-02  -6.39343262e-03
    8.33740234e-02   3.47290039e-02   8.47167969e-02  -5.82580566e-02
   -1.08703613e-01   8.72802734e-03   6.66503906e-02  -1.59667969e-01
    4.58984375e-02  -1.16333008e-01   2.76367188e-01   1.22070312e-03
   -2.74658203e-02   5.63354492e-02  -2.89062500e-01   7.62939453e-03
   -2.92480469e-01  -1.43432617e-01  -2.56652832e-02   1.37084961e-01
   -2.29980469e-01  -7.58056641e-02   2.35107422e-01  -8.23364258e-02
   -2.87933350e-02  -4.65393066e-02   9.46655273e-02   2.01568604e-02
    1.65405273e-01  -6.97631836e-02  -2.32910156e-01   5.92041016e-03
    6.05163574e-02  -2.52441406e-01  -1.13037109e-01  -1.20422363e-01
    6.26831055e-02  -6.32324219e-02  -8.05664062e-02   1.84692383e-01
   -2.21252441e-02  -7.42797852e-02   1.56127930e-01   4.20227051e-02
    3.75976562e-02  -8.10546875e-02   1.37634277e-02   4.42199707e-02
   -3.58276367e-02   5.23986816e-02  -1.69311523e-01   1.86767578e-01
    2.40173340e-02   9.66796875e-02  -8.34350586e-02   2.66571045e-02
   -9.96704102e-02   5.40161133e-02  -3.04687500e-01   1.45385742e-01
   -2.80456543e-02   1.15280151e-02   8.54492188e-03  -7.32421875e-02
   -3.86352539e-02  -3.35693359e-02  -8.87451172e-02  -2.27783203e-01
    4.60815430e-02   2.89794922e-01   3.36914062e-01   1.22558594e-01
    1.42669678e-02  -1.00830078e-01  -8.22143555e-02   1.40380859e-03]]
After layer _mul2089_0 (1, 256) <class 'numpy.float16'> [[ -8.34350586e-02  -7.51953125e-02  -2.51617432e-02   3.60107422e-02
   -7.97271729e-04  -3.13720703e-02  -5.45120239e-03   2.44140625e-02
    6.28662109e-02  -9.82666016e-02  -4.46166992e-02   1.24267578e-01
    6.07910156e-02   1.21402740e-03   4.87670898e-02  -1.73461914e-01
    4.66613770e-02   1.58538818e-02   6.15844727e-02   3.59802246e-02
    1.59057617e-01  -4.53491211e-02  -2.49633789e-02   1.31835938e-02
   -7.54394531e-02   1.58843994e-02   2.08435059e-02  -2.79693604e-02
   -8.50219727e-02  -7.48901367e-02   2.62756348e-02  -5.83190918e-02
    6.23703003e-03  -5.21469116e-03   8.13598633e-02  -7.75756836e-02
   -2.75726318e-02   7.19070435e-03  -6.11877441e-02  -6.43310547e-02
    3.61442566e-03  -1.21459961e-01   7.48901367e-02   7.06787109e-02
    5.71594238e-02  -7.61108398e-02   4.89807129e-02  -3.43933105e-02
   -1.61285400e-02  -6.42700195e-02   3.54003906e-02  -9.26513672e-02
   -2.51007080e-02   1.34765625e-01  -2.64282227e-02   5.52654266e-04
    4.38690186e-05   1.31713867e-01   7.65991211e-02  -2.69622803e-02
   -8.61206055e-02  -4.98046875e-02  -5.05447388e-03  -2.75878906e-02
    5.20629883e-02  -2.67028809e-02   1.55563354e-02  -6.42089844e-02
   -5.29174805e-02   1.01928711e-02  -1.81518555e-01   2.50244141e-02
    3.67355347e-03   1.23062134e-02   8.82568359e-02  -1.09314919e-04
   -4.88586426e-02  -1.57226562e-01  -6.20422363e-02  -4.01000977e-02
   -9.25903320e-02  -4.53186035e-03  -6.98242188e-02  -1.12121582e-01
   -1.91894531e-01  -1.76143646e-03  -3.28979492e-02  -6.45446777e-03
   -1.30004883e-01  -4.14733887e-02  -8.49609375e-02  -2.98767090e-02
   -1.82037354e-02   1.29699707e-02  -2.88696289e-02   4.06799316e-02
    4.41894531e-02  -1.81121826e-02  -4.62036133e-02  -6.34765625e-02
    1.58500671e-03   9.36279297e-02  -4.61425781e-02   3.89099121e-02
    3.97033691e-02   1.17797852e-01  -2.78015137e-02  -1.11541748e-02
    1.14257812e-01  -1.11572266e-01   8.41674805e-02  -1.98669434e-02
    7.44628906e-02   1.00097656e-01  -4.35485840e-02   2.03247070e-01
   -1.14013672e-01  -6.40258789e-02  -5.95855713e-03  -3.87268066e-02
    1.35131836e-01   2.71453857e-02   8.56781006e-03  -7.30590820e-02
    4.14123535e-02  -1.15783691e-01  -7.02514648e-02  -5.85937500e-02
   -2.99835205e-02  -7.62939453e-03   1.00524902e-01  -8.71181488e-04
    4.49523926e-02  -1.73568726e-03  -5.06210327e-03   3.62548828e-02
    4.52880859e-02   1.57592773e-01   7.46154785e-03   4.92553711e-02
   -4.87136841e-03  -2.14385986e-02   9.88769531e-02   9.62066650e-03
   -5.59082031e-02   7.48291016e-02   6.57348633e-02  -6.01806641e-02
   -5.98144531e-02  -8.83789062e-02  -5.70678711e-02  -1.59454346e-02
   -6.07604980e-02  -3.89099121e-02  -7.40814209e-03   7.10449219e-02
   -8.39233398e-02  -1.20697021e-02   3.21044922e-02   5.42907715e-02
   -1.88720703e-01  -2.81829834e-02   4.12368774e-03   8.66088867e-02
    2.68249512e-02   5.00183105e-02  -3.64303589e-03  -1.47476196e-02
   -1.49658203e-01  -2.97427177e-05  -7.05566406e-02   6.21337891e-02
   -8.97979736e-03  -9.04541016e-02  -3.45153809e-02   3.59497070e-02
    1.07482910e-01  -3.69873047e-02  -2.55584717e-02  -3.17192078e-03
    4.29382324e-02   1.66778564e-02   4.22058105e-02  -2.94952393e-02
   -5.73120117e-02   4.33349609e-03   3.29895020e-02  -7.77587891e-02
    2.40631104e-02  -5.90820312e-02   1.34155273e-01   5.95092773e-04
   -1.39236450e-02   2.71759033e-02  -1.38549805e-01   4.00924683e-03
   -1.54785156e-01  -6.51855469e-02  -1.31072998e-02   7.21435547e-02
   -1.15783691e-01  -3.96728516e-02   1.22863770e-01  -4.29382324e-02
   -1.44119263e-02  -2.26898193e-02   4.69055176e-02   9.82666016e-03
    7.89794922e-02  -3.54919434e-02  -1.19506836e-01   3.17192078e-03
    3.05786133e-02  -1.28906250e-01  -5.59997559e-02  -5.93872070e-02
    3.12500000e-02  -3.12805176e-02  -4.12292480e-02   9.21020508e-02
   -1.06506348e-02  -3.45153809e-02   8.27026367e-02   2.00805664e-02
    1.86920166e-02  -4.19006348e-02   6.75964355e-03   2.08892822e-02
   -1.65863037e-02   2.71148682e-02  -8.39233398e-02   8.56933594e-02
    1.19018555e-02   4.69360352e-02  -4.22363281e-02   1.37176514e-02
   -4.97131348e-02   2.81982422e-02  -1.55273438e-01   7.19604492e-02
   -1.29776001e-02   5.29479980e-03   4.47082520e-03  -4.10156250e-02
   -1.86309814e-02  -1.69372559e-02  -4.13818359e-02  -1.08581543e-01
    2.31475830e-02   1.43310547e-01   1.83959961e-01   6.06079102e-02
    6.63757324e-03  -5.18493652e-02  -4.22363281e-02   7.03334808e-04]]
After layer encoder_birnn_reverse_l0_t8_state_0 (1, 256) <class 'numpy.float16'> [[ -1.75659180e-01  -1.50268555e-01  -4.43725586e-02   6.58569336e-02
    8.54492188e-03  -6.42700195e-02   1.61743164e-03   5.45043945e-02
    1.26708984e-01  -1.89086914e-01  -9.24072266e-02   2.37792969e-01
    1.20239258e-01  -5.42068481e-03   9.49707031e-02  -3.46923828e-01
    9.10034180e-02   3.00598145e-02   1.08459473e-01   6.95190430e-02
    3.11279297e-01  -8.52661133e-02  -4.31213379e-02   3.47290039e-02
   -1.51367188e-01   3.30200195e-02   4.96826172e-02  -5.78308105e-02
   -1.73828125e-01  -1.42944336e-01   5.27954102e-02  -1.19628906e-01
    7.97271729e-03  -5.37109375e-03   1.51611328e-01  -1.51367188e-01
   -5.50537109e-02   1.02462769e-02  -1.22680664e-01  -1.26464844e-01
    1.11694336e-02  -2.44384766e-01   1.43798828e-01   1.33789062e-01
    1.11206055e-01  -1.49780273e-01   8.42285156e-02  -6.40869141e-02
   -2.68249512e-02  -1.22924805e-01   7.40356445e-02  -1.79931641e-01
   -5.68847656e-02   2.55859375e-01  -2.98461914e-02   6.88171387e-03
   -7.52258301e-03   2.58300781e-01   1.40869141e-01  -4.98657227e-02
   -1.62109375e-01  -1.01074219e-01  -1.45263672e-02  -4.68139648e-02
    9.39941406e-02  -5.27343750e-02   3.68347168e-02  -1.28540039e-01
   -9.69238281e-02   1.41830444e-02  -3.50830078e-01   4.29687500e-02
    1.73339844e-02   2.47039795e-02   1.74072266e-01  -1.12380981e-02
   -8.99047852e-02  -2.99560547e-01  -1.15295410e-01  -7.26318359e-02
   -1.86767578e-01  -1.93405151e-03  -1.30493164e-01  -2.13256836e-01
   -3.89160156e-01   3.93867493e-04  -8.30688477e-02  -2.32696533e-03
   -2.45971680e-01  -8.53271484e-02  -1.82128906e-01  -6.16149902e-02
   -3.54614258e-02   1.77154541e-02  -5.57250977e-02   7.45849609e-02
    8.98437500e-02  -4.19921875e-02  -8.63037109e-02  -1.09863281e-01
    6.22558594e-03   1.75537109e-01  -8.87451172e-02   7.31201172e-02
    7.32421875e-02   2.16552734e-01  -4.98046875e-02  -2.87933350e-02
    2.21191406e-01  -2.05444336e-01   1.55151367e-01  -3.07922363e-02
    1.36474609e-01   1.94824219e-01  -9.33837891e-02   4.17724609e-01
   -2.24609375e-01  -1.26464844e-01   4.72259521e-03  -7.93457031e-02
    2.71240234e-01   6.32324219e-02   8.16345215e-03  -1.36718750e-01
    8.63037109e-02  -2.18994141e-01  -1.43554688e-01  -1.08093262e-01
   -5.91735840e-02  -1.69372559e-02   1.85791016e-01  -1.03454590e-02
    8.73413086e-02   1.11961365e-03  -6.34765625e-03   7.43408203e-02
    9.00878906e-02   3.04443359e-01   1.02081299e-02   9.97314453e-02
   -6.96563721e-03  -4.43420410e-02   1.92993164e-01   2.23236084e-02
   -1.07238770e-01   1.45019531e-01   1.22558594e-01  -1.20727539e-01
   -1.16333008e-01  -1.64794922e-01  -1.00341797e-01  -3.17993164e-02
   -1.11938477e-01  -8.06884766e-02  -1.05895996e-02   1.36474609e-01
   -1.65649414e-01  -1.07955933e-02   6.34765625e-02   1.06628418e-01
   -3.81347656e-01  -6.13403320e-02   1.31530762e-02   1.77001953e-01
    5.09033203e-02   9.86328125e-02   1.17111206e-03  -3.24096680e-02
   -2.78564453e-01   4.31060791e-03  -1.33789062e-01   1.12792969e-01
   -2.41088867e-02  -1.95678711e-01  -5.66101074e-02   7.82470703e-02
    2.17773438e-01  -6.67724609e-02  -5.29174805e-02  -1.19781494e-02
    8.66699219e-02   2.85644531e-02   8.09936523e-02  -5.22155762e-02
   -1.02539062e-01   2.09503174e-02   6.32934570e-02  -1.56738281e-01
    6.02416992e-02  -1.19750977e-01   2.50000000e-01  -3.23104858e-03
   -2.58331299e-02   5.35888672e-02  -2.49267578e-01   5.08880615e-03
   -2.91015625e-01  -1.19323730e-01  -2.98461914e-02   1.29150391e-01
   -2.21923828e-01  -7.25097656e-02   2.39135742e-01  -7.83691406e-02
   -2.68859863e-02  -3.98254395e-02   8.67919922e-02   1.88598633e-02
    1.46728516e-01  -7.80029297e-02  -2.30224609e-01   4.70733643e-03
    5.23986816e-02  -2.46337891e-01  -9.92431641e-02  -1.07543945e-01
    5.65490723e-02  -6.03027344e-02  -7.09228516e-02   1.79199219e-01
   -2.24456787e-02  -6.93969727e-02   1.60400391e-01   3.68347168e-02
    3.28369141e-02  -7.80029297e-02   1.25274658e-02   4.01000977e-02
   -1.51901245e-02   4.15039062e-02  -1.66503906e-01   1.48437500e-01
    3.08380127e-02   9.38720703e-02  -8.33740234e-02   2.77404785e-02
   -9.77172852e-02   4.92553711e-02  -2.91748047e-01   1.44042969e-01
   -1.68762207e-02   5.50460815e-03   1.65100098e-02  -8.27026367e-02
   -3.41796875e-02  -4.05273438e-02  -7.34863281e-02  -2.02636719e-01
    4.17785645e-02   2.67333984e-01   3.60595703e-01   1.08032227e-01
    2.27050781e-02  -9.80224609e-02  -8.22753906e-02  -1.29318237e-03]]
After layer activation1044_output (1, 256) <class 'numpy.float16'> [[ -1.73828125e-01  -1.49169922e-01  -4.43420410e-02   6.57348633e-02
    8.54492188e-03  -6.42089844e-02   1.61743164e-03   5.44433594e-02
    1.25976562e-01  -1.86889648e-01  -9.21630859e-02   2.33398438e-01
    1.19689941e-01  -5.42068481e-03   9.46655273e-02  -3.33740234e-01
    9.07592773e-02   3.00445557e-02   1.08032227e-01   6.93969727e-02
    3.01513672e-01  -8.50830078e-02  -4.30908203e-02   3.47290039e-02
   -1.50268555e-01   3.30200195e-02   4.96520996e-02  -5.77697754e-02
   -1.72119141e-01  -1.41967773e-01   5.27343750e-02  -1.19079590e-01
    7.97271729e-03  -5.37109375e-03   1.50512695e-01  -1.50268555e-01
   -5.49926758e-02   1.02462769e-02  -1.22070312e-01  -1.25854492e-01
    1.11694336e-02  -2.39624023e-01   1.42822266e-01   1.33056641e-01
    1.10778809e-01  -1.48681641e-01   8.40454102e-02  -6.40258789e-02
   -2.68249512e-02  -1.22314453e-01   7.39135742e-02  -1.77978516e-01
   -5.68237305e-02   2.50488281e-01  -2.98309326e-02   6.88171387e-03
   -7.52258301e-03   2.52685547e-01   1.39892578e-01  -4.98352051e-02
   -1.60644531e-01  -1.00708008e-01  -1.45263672e-02  -4.67834473e-02
    9.36889648e-02  -5.26733398e-02   3.68041992e-02  -1.27807617e-01
   -9.66186523e-02   1.41830444e-02  -3.37158203e-01   4.29382324e-02
    1.73339844e-02   2.47039795e-02   1.72363281e-01  -1.12380981e-02
   -8.96606445e-02  -2.91015625e-01  -1.14807129e-01  -7.25097656e-02
   -1.84570312e-01  -1.93405151e-03  -1.29760742e-01  -2.10083008e-01
   -3.70605469e-01   3.93867493e-04  -8.28857422e-02  -2.32696533e-03
   -2.41088867e-01  -8.51440430e-02  -1.80175781e-01  -6.15234375e-02
   -3.54614258e-02   1.77154541e-02  -5.56640625e-02   7.44628906e-02
    8.95996094e-02  -4.19616699e-02  -8.60595703e-02  -1.09436035e-01
    6.22558594e-03   1.73706055e-01  -8.85009766e-02   7.29980469e-02
    7.31201172e-02   2.13256836e-01  -4.97741699e-02  -2.87780762e-02
    2.17651367e-01  -2.02636719e-01   1.53930664e-01  -3.07769775e-02
    1.35620117e-01   1.92382812e-01  -9.31396484e-02   3.95019531e-01
   -2.20947266e-01  -1.25854492e-01   4.72259521e-03  -7.91625977e-02
    2.64892578e-01   6.31713867e-02   8.16345215e-03  -1.35864258e-01
    8.60595703e-02  -2.15576172e-01  -1.42578125e-01  -1.07666016e-01
   -5.91125488e-02  -1.69372559e-02   1.83715820e-01  -1.03454590e-02
    8.70971680e-02   1.11961365e-03  -6.34765625e-03   7.42187500e-02
    8.98437500e-02   2.95410156e-01   1.02081299e-02   9.94262695e-02
   -6.96563721e-03  -4.43115234e-02   1.90673828e-01   2.23236084e-02
   -1.06811523e-01   1.44042969e-01   1.21948242e-01  -1.20117188e-01
   -1.15783691e-01  -1.63330078e-01  -1.00036621e-01  -3.17993164e-02
   -1.11450195e-01  -8.05053711e-02  -1.05895996e-02   1.35620117e-01
   -1.64184570e-01  -1.07955933e-02   6.34155273e-02   1.06201172e-01
   -3.63769531e-01  -6.12487793e-02   1.31530762e-02   1.75170898e-01
    5.08728027e-02   9.83276367e-02   1.17111206e-03  -3.24096680e-02
   -2.71484375e-01   4.31060791e-03  -1.33056641e-01   1.12304688e-01
   -2.41088867e-02  -1.93237305e-01  -5.65490723e-02   7.80639648e-02
    2.14355469e-01  -6.66503906e-02  -5.28564453e-02  -1.19781494e-02
    8.64257812e-02   2.85491943e-02   8.08105469e-02  -5.21545410e-02
   -1.02172852e-01   2.09503174e-02   6.32324219e-02  -1.55517578e-01
    6.01806641e-02  -1.19201660e-01   2.44873047e-01  -3.23104858e-03
   -2.58331299e-02   5.35278320e-02  -2.44262695e-01   5.08880615e-03
   -2.82958984e-01  -1.18774414e-01  -2.98309326e-02   1.28417969e-01
   -2.18383789e-01  -7.23876953e-02   2.34619141e-01  -7.81860352e-02
   -2.68859863e-02  -3.97949219e-02   8.65478516e-02   1.88598633e-02
    1.45629883e-01  -7.78198242e-02  -2.26196289e-01   4.70733643e-03
    5.23376465e-02  -2.41455078e-01  -9.89379883e-02  -1.07116699e-01
    5.64880371e-02  -6.02416992e-02  -7.08007812e-02   1.77246094e-01
   -2.24456787e-02  -6.92749023e-02   1.59057617e-01   3.68041992e-02
    3.28369141e-02  -7.78198242e-02   1.25274658e-02   4.00695801e-02
   -1.51901245e-02   4.14733887e-02  -1.65039062e-01   1.47338867e-01
    3.08227539e-02   9.35668945e-02  -8.31909180e-02   2.77404785e-02
   -9.74121094e-02   4.92248535e-02  -2.83691406e-01   1.43066406e-01
   -1.68762207e-02   5.50460815e-03   1.65100098e-02  -8.25195312e-02
   -3.41796875e-02  -4.04968262e-02  -7.33642578e-02  -1.99951172e-01
    4.17480469e-02   2.61230469e-01   3.45703125e-01   1.07604980e-01
    2.27050781e-02  -9.77172852e-02  -8.20922852e-02  -1.29318237e-03]]
After layer encoder_birnn_reverse_l0_t8_out_0 (1, 256) <class 'numpy.float16'> [[ -9.04541016e-02  -7.73315430e-02  -2.20336914e-02   3.42102051e-02
    4.31060791e-03  -3.54309082e-02   8.42094421e-04   2.86865234e-02
    7.76977539e-02  -1.00219727e-01  -4.44335938e-02   1.21459961e-01
    6.51855469e-02  -2.64739990e-03   4.87976074e-02  -1.79199219e-01
    4.39758301e-02   1.42669678e-02   5.53894043e-02   3.46679688e-02
    1.46972656e-01  -3.93371582e-02  -2.49786377e-02   1.83868408e-02
   -7.62329102e-02   1.72882080e-02   2.45056152e-02  -2.85034180e-02
   -8.06274414e-02  -7.12890625e-02   2.79388428e-02  -6.26831055e-02
    4.07791138e-03  -2.74085999e-03   7.48291016e-02  -7.25708008e-02
   -2.91595459e-02   5.09262085e-03  -6.25000000e-02  -6.14929199e-02
    5.70297241e-03  -1.18347168e-01   7.12890625e-02   6.70776367e-02
    5.45349121e-02  -7.59887695e-02   4.28771973e-02  -3.03344727e-02
   -1.35803223e-02  -6.51855469e-02   3.85437012e-02  -8.92333984e-02
   -2.66113281e-02   1.28906250e-01  -1.61895752e-02   3.26538086e-03
   -4.08172607e-03   1.28906250e-01   7.09228516e-02  -2.34375000e-02
   -8.42285156e-02  -5.29479980e-02  -7.36236572e-03  -2.55889893e-02
    4.66613770e-02  -2.57263184e-02   2.05078125e-02  -6.61010742e-02
   -4.74548340e-02   7.26318359e-03  -1.69677734e-01   2.18048096e-02
    8.64410400e-03   1.22375488e-02   9.28344727e-02  -6.10733032e-03
   -4.82788086e-02  -1.48315430e-01  -6.15539551e-02  -4.04052734e-02
   -1.01562500e-01  -1.07002258e-03  -6.92138672e-02  -1.10351562e-01
   -2.02514648e-01   2.02178955e-04  -4.25720215e-02  -1.20258331e-03
   -1.25976562e-01  -4.31823730e-02  -9.86328125e-02  -2.99835205e-02
   -1.68304443e-02   8.97979736e-03  -2.81829834e-02   3.77502441e-02
    4.58984375e-02  -2.14996338e-02  -3.97033691e-02  -5.09643555e-02
    2.98309326e-03   7.99560547e-02  -4.20532227e-02   3.46069336e-02
    3.57360840e-02   1.06811523e-01  -2.42919922e-02  -1.54037476e-02
    1.12670898e-01  -1.05651855e-01   7.83081055e-02  -1.58538818e-02
    6.43920898e-02   1.04003906e-01  -4.64172363e-02   2.14111328e-01
   -1.06689453e-01  -6.17675781e-02   2.40898132e-03  -3.84521484e-02
    1.35131836e-01   3.32336426e-02   4.23812866e-03  -6.75048828e-02
    4.13208008e-02  -1.10229492e-01  -7.17773438e-02  -5.41381836e-02
   -2.94036865e-02  -7.91931152e-03   9.32006836e-02  -5.64193726e-03
    4.30603027e-02   5.95569611e-04  -3.25775146e-03   3.53088379e-02
    4.84619141e-02   1.51489258e-01   5.48171997e-03   5.10253906e-02
   -3.53050232e-03  -2.20184326e-02   9.23461914e-02   1.17263794e-02
   -5.29174805e-02   7.34252930e-02   6.70776367e-02  -6.31713867e-02
   -5.86853027e-02  -8.06884766e-02  -4.95910645e-02  -1.56707764e-02
   -5.86242676e-02  -4.32739258e-02  -5.18417358e-03   7.01904297e-02
   -8.74023438e-02  -5.60760498e-03   3.23181152e-02   5.73425293e-02
   -1.90185547e-01  -3.15551758e-02   6.62231445e-03   9.37500000e-02
    2.66723633e-02   4.66918945e-02   6.79492950e-04  -1.72271729e-02
   -1.24755859e-01   2.18772888e-03  -6.19201660e-02   6.02111816e-02
   -1.27639771e-02  -1.08398438e-01  -2.82592773e-02   4.28466797e-02
    1.15844727e-01  -3.20434570e-02  -2.72064209e-02  -5.91659546e-03
    4.01306152e-02   1.35116577e-02   4.18701172e-02  -2.46582031e-02
   -4.90112305e-02   1.14135742e-02   3.09906006e-02  -8.27636719e-02
    2.91900635e-02  -5.52673340e-02   1.23046875e-01  -1.73854828e-03
   -1.33438110e-02   2.72827148e-02  -1.17370605e-01   2.64167786e-03
   -1.38671875e-01  -6.05468750e-02  -1.58538818e-02   6.56127930e-02
   -1.14440918e-01  -4.01916504e-02   1.23291016e-01  -4.24499512e-02
   -1.41143799e-02  -2.08740234e-02   4.10766602e-02   9.75036621e-03
    6.81152344e-02  -4.26330566e-02  -1.13647461e-01   2.73513794e-03
    2.73437500e-02  -1.31469727e-01  -5.25512695e-02  -5.13305664e-02
    2.90679932e-02  -3.37829590e-02  -3.48205566e-02   8.59985352e-02
   -1.10549927e-02  -3.13415527e-02   8.69750977e-02   1.86767578e-02
    1.70593262e-02  -4.09545898e-02   6.24847412e-03   2.05841064e-02
   -9.06372070e-03   2.23388672e-02  -8.30078125e-02   6.69555664e-02
    1.51672363e-02   4.71496582e-02  -4.12597656e-02   1.41525269e-02
   -4.82177734e-02   2.58331299e-02  -1.51245117e-01   7.36694336e-02
   -7.59506226e-03   2.88391113e-03   8.52966309e-03  -4.80651855e-02
   -1.55639648e-02  -2.09197998e-02  -3.62243652e-02  -9.18579102e-02
    2.13623047e-02   1.28173828e-01   1.84204102e-01   5.08728027e-02
    1.20849609e-02  -5.25207520e-02  -4.10156250e-02  -6.64710999e-04]]
After layer expand_dims1050_0 (1, 1, 256) <class 'numpy.float16'> [[[ -9.04541016e-02  -7.73315430e-02  -2.20336914e-02   3.42102051e-02
     4.31060791e-03  -3.54309082e-02   8.42094421e-04   2.86865234e-02
     7.76977539e-02  -1.00219727e-01  -4.44335938e-02   1.21459961e-01
     6.51855469e-02  -2.64739990e-03   4.87976074e-02  -1.79199219e-01
     4.39758301e-02   1.42669678e-02   5.53894043e-02   3.46679688e-02
     1.46972656e-01  -3.93371582e-02  -2.49786377e-02   1.83868408e-02
    -7.62329102e-02   1.72882080e-02   2.45056152e-02  -2.85034180e-02
    -8.06274414e-02  -7.12890625e-02   2.79388428e-02  -6.26831055e-02
     4.07791138e-03  -2.74085999e-03   7.48291016e-02  -7.25708008e-02
    -2.91595459e-02   5.09262085e-03  -6.25000000e-02  -6.14929199e-02
     5.70297241e-03  -1.18347168e-01   7.12890625e-02   6.70776367e-02
     5.45349121e-02  -7.59887695e-02   4.28771973e-02  -3.03344727e-02
    -1.35803223e-02  -6.51855469e-02   3.85437012e-02  -8.92333984e-02
    -2.66113281e-02   1.28906250e-01  -1.61895752e-02   3.26538086e-03
    -4.08172607e-03   1.28906250e-01   7.09228516e-02  -2.34375000e-02
    -8.42285156e-02  -5.29479980e-02  -7.36236572e-03  -2.55889893e-02
     4.66613770e-02  -2.57263184e-02   2.05078125e-02  -6.61010742e-02
    -4.74548340e-02   7.26318359e-03  -1.69677734e-01   2.18048096e-02
     8.64410400e-03   1.22375488e-02   9.28344727e-02  -6.10733032e-03
    -4.82788086e-02  -1.48315430e-01  -6.15539551e-02  -4.04052734e-02
    -1.01562500e-01  -1.07002258e-03  -6.92138672e-02  -1.10351562e-01
    -2.02514648e-01   2.02178955e-04  -4.25720215e-02  -1.20258331e-03
    -1.25976562e-01  -4.31823730e-02  -9.86328125e-02  -2.99835205e-02
    -1.68304443e-02   8.97979736e-03  -2.81829834e-02   3.77502441e-02
     4.58984375e-02  -2.14996338e-02  -3.97033691e-02  -5.09643555e-02
     2.98309326e-03   7.99560547e-02  -4.20532227e-02   3.46069336e-02
     3.57360840e-02   1.06811523e-01  -2.42919922e-02  -1.54037476e-02
     1.12670898e-01  -1.05651855e-01   7.83081055e-02  -1.58538818e-02
     6.43920898e-02   1.04003906e-01  -4.64172363e-02   2.14111328e-01
    -1.06689453e-01  -6.17675781e-02   2.40898132e-03  -3.84521484e-02
     1.35131836e-01   3.32336426e-02   4.23812866e-03  -6.75048828e-02
     4.13208008e-02  -1.10229492e-01  -7.17773438e-02  -5.41381836e-02
    -2.94036865e-02  -7.91931152e-03   9.32006836e-02  -5.64193726e-03
     4.30603027e-02   5.95569611e-04  -3.25775146e-03   3.53088379e-02
     4.84619141e-02   1.51489258e-01   5.48171997e-03   5.10253906e-02
    -3.53050232e-03  -2.20184326e-02   9.23461914e-02   1.17263794e-02
    -5.29174805e-02   7.34252930e-02   6.70776367e-02  -6.31713867e-02
    -5.86853027e-02  -8.06884766e-02  -4.95910645e-02  -1.56707764e-02
    -5.86242676e-02  -4.32739258e-02  -5.18417358e-03   7.01904297e-02
    -8.74023438e-02  -5.60760498e-03   3.23181152e-02   5.73425293e-02
    -1.90185547e-01  -3.15551758e-02   6.62231445e-03   9.37500000e-02
     2.66723633e-02   4.66918945e-02   6.79492950e-04  -1.72271729e-02
    -1.24755859e-01   2.18772888e-03  -6.19201660e-02   6.02111816e-02
    -1.27639771e-02  -1.08398438e-01  -2.82592773e-02   4.28466797e-02
     1.15844727e-01  -3.20434570e-02  -2.72064209e-02  -5.91659546e-03
     4.01306152e-02   1.35116577e-02   4.18701172e-02  -2.46582031e-02
    -4.90112305e-02   1.14135742e-02   3.09906006e-02  -8.27636719e-02
     2.91900635e-02  -5.52673340e-02   1.23046875e-01  -1.73854828e-03
    -1.33438110e-02   2.72827148e-02  -1.17370605e-01   2.64167786e-03
    -1.38671875e-01  -6.05468750e-02  -1.58538818e-02   6.56127930e-02
    -1.14440918e-01  -4.01916504e-02   1.23291016e-01  -4.24499512e-02
    -1.41143799e-02  -2.08740234e-02   4.10766602e-02   9.75036621e-03
     6.81152344e-02  -4.26330566e-02  -1.13647461e-01   2.73513794e-03
     2.73437500e-02  -1.31469727e-01  -5.25512695e-02  -5.13305664e-02
     2.90679932e-02  -3.37829590e-02  -3.48205566e-02   8.59985352e-02
    -1.10549927e-02  -3.13415527e-02   8.69750977e-02   1.86767578e-02
     1.70593262e-02  -4.09545898e-02   6.24847412e-03   2.05841064e-02
    -9.06372070e-03   2.23388672e-02  -8.30078125e-02   6.69555664e-02
     1.51672363e-02   4.71496582e-02  -4.12597656e-02   1.41525269e-02
    -4.82177734e-02   2.58331299e-02  -1.51245117e-01   7.36694336e-02
    -7.59506226e-03   2.88391113e-03   8.52966309e-03  -4.80651855e-02
    -1.55639648e-02  -2.09197998e-02  -3.62243652e-02  -9.18579102e-02
     2.13623047e-02   1.28173828e-01   1.84204102e-01   5.08728027e-02
     1.20849609e-02  -5.25207520e-02  -4.10156250e-02  -6.64710999e-04]]]
After layer encoder_birnn_reverse_l0_t9_i2h_output (1, 1024) <class 'numpy.float16'> [[-0.0128479  -0.04095459  0.03787231 ...,  0.06970215 -0.04626465
   0.03759766]]
After layer encoder_birnn_reverse_l0_t9_h2h_output (1, 1024) <class 'numpy.float16'> [[-0.00114441  0.00850677 -0.09741211 ...,  0.08813477  0.04727173
   0.0206604 ]]
After layer _plus1045_0 (1, 1024) <class 'numpy.float16'> [[-0.01399231 -0.03244019 -0.05953979 ...,  0.15783691  0.00100708
   0.05825806]]
After layer encoder_birnn_reverse_l0_t9_slice_output0 (1, 256) <class 'numpy.float16'> [[ -1.39923096e-02  -3.24401855e-02  -5.95397949e-02  -3.43017578e-02
   -4.94995117e-02  -4.06494141e-02  -2.86254883e-02  -6.57653809e-03
    9.24072266e-02   8.10546875e-02  -6.25000000e-02   1.21582031e-01
   -2.84576416e-03   1.04827881e-02   2.44140625e-04   3.46435547e-01
   -1.47583008e-01  -1.05895996e-01   1.32598877e-02  -1.01928711e-02
    1.32568359e-01  -9.64355469e-03  -1.73217773e-01  -6.52465820e-02
    4.37011719e-02  -1.31835938e-01  -2.70843506e-02   4.97436523e-03
   -1.69372559e-02  -2.16369629e-02  -1.34124756e-02  -1.07116699e-02
   -6.61010742e-02  -4.37927246e-02   1.00219727e-01  -1.87133789e-01
   -1.81579590e-02  -2.17590332e-02  -9.69238281e-02  -9.54589844e-02
   -2.15087891e-01   2.72216797e-02  -4.39758301e-02   1.31835938e-02
    2.70843506e-02  -2.37121582e-02   8.50830078e-02  -9.54589844e-02
   -6.93359375e-02   2.20642090e-02   3.78417969e-02   1.19934082e-01
   -2.16674805e-01   9.90600586e-02   1.96044922e-01   1.39038086e-01
   -8.48999023e-02   1.64642334e-02  -1.07910156e-01  -5.40161133e-03
    1.05041504e-01  -8.28247070e-02   1.62597656e-01  -2.21252441e-02
   -1.13281250e-01  -4.21752930e-02   1.25732422e-01  -2.07366943e-02
   -1.34887695e-01  -1.85546875e-02   1.20849609e-01  -1.68914795e-02
   -3.12805176e-02  -4.16259766e-02   2.40478516e-02   4.10766602e-02
    1.13403320e-01   1.85058594e-01   6.29882812e-02   8.27026367e-02
    2.56347656e-02   4.97436523e-02   9.91210938e-02  -3.14331055e-02
    1.68701172e-01   1.71203613e-02  -2.25524902e-02  -1.16577148e-01
   -1.15661621e-02   4.41284180e-02   1.27319336e-01   1.71508789e-02
   -8.97827148e-02   6.79931641e-02   7.54394531e-02   3.22265625e-02
   -3.30810547e-02  -1.01928711e-02  -1.39282227e-01  -1.49169922e-01
   -1.58325195e-01   7.32421875e-02   2.69165039e-02  -1.03149414e-01
   -1.72363281e-01   2.24304199e-03  -3.08380127e-02  -1.12548828e-01
    8.90502930e-02  -3.43017578e-02  -9.41162109e-02  -3.02124023e-02
    3.75976562e-02   2.80273438e-01   2.68554688e-02   3.28125000e-01
   -1.16577148e-02   5.92041016e-03  -4.63867188e-03  -7.34252930e-02
    2.35229492e-01  -1.31347656e-01  -3.02734375e-02   1.12243652e-01
   -1.06140137e-01   9.58251953e-02  -1.54296875e-01   9.28955078e-02
   -3.76586914e-02   1.35498047e-02   2.52929688e-01   3.17382812e-02
   -8.48388672e-03  -5.79833984e-02  -9.96093750e-02  -1.43310547e-01
    1.30371094e-01   1.72241211e-01  -3.86352539e-02  -9.94873047e-03
   -4.16259766e-02  -1.58813477e-01   1.11816406e-01   4.64172363e-02
    3.54003906e-03   1.36718750e-02   4.19616699e-02   6.78710938e-02
   -1.00708008e-03   9.29565430e-02   1.33789062e-01  -7.92846680e-02
   -3.81469727e-03  -9.18579102e-02  -1.42822266e-01   2.09472656e-01
    2.68554688e-02  -1.53198242e-02  -2.60620117e-02  -2.95410156e-02
    2.71484375e-01  -9.70458984e-03  -8.90502930e-02   1.26342773e-02
    3.57055664e-03  -8.53271484e-02  -1.98974609e-02  -6.37817383e-02
    2.70690918e-02  -5.13916016e-02  -2.37731934e-02   4.87365723e-02
    8.12530518e-03   9.64965820e-02   2.19268799e-02  -2.09716797e-01
    5.32836914e-02  -1.47705078e-01  -7.37915039e-02  -1.06201172e-02
    6.57348633e-02  -8.26416016e-02  -9.03320312e-03   2.93273926e-02
    1.13769531e-01  -1.19934082e-02  -1.95617676e-02  -4.73632812e-02
    9.86938477e-02   2.75878906e-02  -6.53076172e-02  -5.16357422e-02
    2.35290527e-02  -7.74536133e-02  -1.12060547e-01   1.05590820e-01
    1.24755859e-01  -1.83959961e-01   4.43725586e-02   1.15356445e-01
    1.35192871e-02   8.97216797e-02   9.52758789e-02   9.66186523e-02
   -3.49426270e-03  -5.70373535e-02  -2.41241455e-02  -4.72412109e-02
   -9.52148438e-02   3.22875977e-02   5.60302734e-02   1.54296875e-01
    2.21862793e-02   3.68652344e-02  -2.36816406e-02  -4.25415039e-02
   -4.07409668e-03  -1.96228027e-02   5.49316406e-02  -6.71386719e-03
   -7.82470703e-02  -1.61132812e-01   1.31225586e-01  -9.13696289e-02
   -1.93786621e-02   7.20825195e-02  -3.56445312e-02  -1.14135742e-01
   -1.66748047e-01   5.64575195e-02  -1.75628662e-02  -1.77246094e-01
   -1.52893066e-02  -5.88073730e-02   2.59552002e-02   5.95092773e-02
   -4.60815430e-03   9.19189453e-02   4.40063477e-02  -1.05895996e-02
   -1.67236328e-01  -1.71508789e-01   9.81445312e-02   2.42553711e-01
   -7.40966797e-02   1.85852051e-02  -1.50146484e-01  -1.02416992e-01
    7.56835938e-03  -2.85797119e-02   1.93481445e-01  -2.49938965e-02
   -1.49658203e-01   6.09741211e-02   5.26733398e-02   1.07116699e-02]]
After layer encoder_birnn_reverse_l0_t9_slice_output1 (1, 256) <class 'numpy.float16'> [[  1.70654297e-01   6.26220703e-02   1.33789062e-01   3.51257324e-02
   -2.71301270e-02   8.88671875e-02   2.20458984e-01  -1.11511230e-01
    4.25537109e-01   2.12524414e-01   1.36962891e-01   1.77001953e-01
    1.51123047e-01  -1.09405518e-02   1.46850586e-01   1.67968750e-01
    9.52148438e-02  -9.88769531e-03  -1.53320312e-01   1.18286133e-01
    1.69555664e-01   3.57666016e-02   5.19531250e-01   8.95996094e-02
    1.34765625e-01   9.74731445e-02   2.02148438e-01   7.36694336e-02
    1.41723633e-01   4.24499512e-02   1.15295410e-01   5.72814941e-02
    2.71484375e-01  -4.86145020e-02  -2.53295898e-03  -2.45056152e-02
   -5.89599609e-02   1.94580078e-01   2.81982422e-02   8.20312500e-02
   -1.32080078e-01   1.29028320e-01   2.11029053e-02   1.23535156e-01
    6.19201660e-02   1.44287109e-01   4.01306152e-02  -1.51123047e-01
   -1.79748535e-02   2.54821777e-03   8.42895508e-02   1.21582031e-01
   -7.87353516e-02   1.79077148e-01   7.95288086e-02   4.44946289e-02
    6.84814453e-02   1.24145508e-01  -2.59094238e-02  -1.26831055e-01
    1.45996094e-01   4.84924316e-02   1.06201172e-01   1.89666748e-02
   -3.77502441e-02   1.79565430e-01   2.43286133e-01   1.11022949e-01
   -1.91650391e-01  -8.11157227e-02   7.92846680e-02   1.59912109e-02
   -7.17163086e-02   5.38330078e-02   1.34765625e-01   1.42578125e-01
    8.32519531e-02   1.00830078e-01   1.25732422e-01   1.27197266e-01
    2.47070312e-01   2.34985352e-01   4.09240723e-02   1.02081299e-02
    2.24243164e-01  -1.96228027e-02   1.21337891e-01   1.63085938e-01
    4.82788086e-02  -2.05078125e-01   3.86230469e-01   7.50732422e-02
    8.58764648e-02   7.78808594e-02  -7.12890625e-02   4.10461426e-03
   -2.89306641e-02  -6.22558594e-03  -2.14355469e-01  -1.90551758e-01
   -1.01440430e-01  -3.89099121e-02   6.92138672e-02   1.32202148e-01
   -5.01708984e-02  -4.01916504e-02  -1.22436523e-01   6.17065430e-02
    1.19079590e-01  -1.72363281e-01   8.12988281e-02  -3.14941406e-02
    8.80126953e-02   2.68798828e-01   1.10290527e-01   2.29003906e-01
    1.69555664e-01   1.48681641e-01   4.79736328e-02   1.22192383e-01
    2.44384766e-01   1.98242188e-01   4.72412109e-02   1.90124512e-02
   -7.03735352e-02  -5.06591797e-03   1.89086914e-01  -1.67846680e-03
    1.13647461e-01  -1.32690430e-01   1.74926758e-01   1.12915039e-01
    2.63061523e-02   2.30957031e-01   4.24194336e-02   2.57568359e-02
    3.28369141e-02   8.09326172e-02   1.78466797e-01   2.80273438e-01
   -6.15234375e-02   2.53906250e-02   1.04431152e-01   5.12084961e-02
    6.93359375e-02   1.30493164e-01   1.42333984e-01   4.38842773e-02
    5.26123047e-02  -4.09240723e-02  -2.50244141e-02   1.13525391e-01
    7.58666992e-02   1.41967773e-01  -4.69970703e-02   1.99462891e-01
    1.17126465e-01  -9.75341797e-02   9.64965820e-02   1.81884766e-01
    2.53662109e-01   1.18041992e-01  -2.78320312e-02   1.12365723e-01
    1.39892578e-01  -3.15856934e-02   3.24707031e-01  -1.87377930e-02
    2.44140625e-04   5.52368164e-03   1.78222656e-02   1.63696289e-01
    5.61523438e-03   2.39624023e-01  -6.84204102e-02   1.67846680e-01
    1.93847656e-01  -4.45251465e-02  -2.50244141e-03   1.31225586e-01
    8.96606445e-02  -8.05053711e-02   2.73193359e-01  -2.55126953e-02
   -9.76562500e-03   7.21435547e-02   2.97851562e-02   2.41699219e-01
   -6.84814453e-02  -8.78906250e-02  -4.46472168e-02   8.16650391e-02
    2.15209961e-01   1.87011719e-01  -2.24365234e-01   1.95617676e-02
    1.02844238e-02  -1.26953125e-02   3.66210938e-02   3.62548828e-02
    9.78393555e-02   2.81982422e-02   9.41162109e-02  -5.98144531e-03
    1.29150391e-01  -1.54174805e-01  -7.70263672e-02   2.06298828e-01
   -1.08154297e-01   1.23596191e-01   8.05053711e-02   1.27685547e-01
   -5.74645996e-02   4.56848145e-02  -3.96728516e-03  -1.35131836e-01
    7.51953125e-02   1.20544434e-01  -4.47387695e-02   1.53808594e-01
   -1.05773926e-01  -1.25244141e-01   3.09326172e-01  -8.62121582e-03
    1.11083984e-01  -5.49316406e-04   4.92248535e-02   8.31298828e-02
    4.77050781e-01   1.78222656e-01   7.53173828e-02  -3.27880859e-01
    1.75292969e-01   4.90112305e-02   1.01623535e-01  -7.62939453e-03
    9.32312012e-03   1.05773926e-01   9.47265625e-02   1.05163574e-01
    4.42199707e-02   8.63037109e-02  -1.64184570e-02   2.39746094e-01
   -1.87744141e-01   7.01904297e-04  -1.07421875e-01  -5.03540039e-02
    1.48315430e-01  -5.17883301e-02   2.16186523e-01  -2.10327148e-01
    1.77734375e-01   1.03759766e-02   1.51611328e-01   7.11059570e-03]]
After layer encoder_birnn_reverse_l0_t9_slice_output2 (1, 256) <class 'numpy.float16'> [[-0.171875   -0.15551758 -0.0581665   0.0793457  -0.01263428 -0.06555176
  -0.02078247  0.03689575  0.13891602 -0.2109375  -0.09228516  0.26123047
   0.13085938  0.0118103   0.10583496 -0.32177734  0.10473633  0.03430176
   0.12768555  0.07849121  0.33447266 -0.09570312 -0.06768799  0.02200317
  -0.15454102  0.03500366  0.03527832 -0.05300903 -0.17687988 -0.16088867
   0.05395508 -0.11773682  0.01623535 -0.01829529  0.16577148 -0.17224121
  -0.05493164  0.01730347 -0.1295166  -0.14208984  0.00128174 -0.25341797
   0.16186523  0.15673828  0.1192627  -0.16784668  0.11206055 -0.07324219
  -0.04077148 -0.13122559  0.06567383 -0.1887207  -0.04129028  0.29150391
  -0.07421875 -0.00453186  0.00665283  0.28393555  0.17199707 -0.05535889
  -0.1817627  -0.10430908 -0.00604248 -0.06549072  0.12060547 -0.05865479
   0.0279541  -0.13183594 -0.11676025  0.02514648 -0.38208008  0.05645752
  -0.00549316  0.02624512  0.18811035  0.00939941 -0.10131836 -0.31762695
  -0.13476562 -0.09051514 -0.20117188 -0.01586914 -0.14404297 -0.2442627
  -0.39428711 -0.00799561 -0.0546875  -0.02331543 -0.28588867 -0.0645752
  -0.17504883 -0.06030273 -0.04003906  0.03335571 -0.05322266  0.08630371
   0.08392334 -0.02610779 -0.09472656 -0.1427002   0.00152588  0.19213867
  -0.09777832  0.0916748   0.09216309  0.25097656 -0.06115723 -0.01716614
   0.23974609 -0.22729492  0.1953125  -0.04812622  0.16223145  0.1986084
  -0.08312988  0.38574219 -0.24865723 -0.13391113 -0.03530884 -0.07983398
   0.27026367  0.05609131  0.02783203 -0.1484375   0.07922363 -0.23828125
  -0.15966797 -0.12078857 -0.06433105 -0.00942993  0.20483398  0.00473022
   0.09429932 -0.01312256 -0.01544189  0.07568359  0.08911133  0.31567383
   0.02087402  0.10839844 -0.015625   -0.04528809  0.19909668  0.01215363
  -0.12207031  0.16320801  0.14453125 -0.11968994 -0.12658691 -0.17724609
  -0.12097168 -0.03475952 -0.13256836 -0.08526611 -0.02560425  0.14550781
  -0.17346191 -0.03646851  0.06811523  0.11962891 -0.3762207  -0.05654907
   0.00039673  0.17749023  0.05975342  0.10266113 -0.01831055 -0.02975464
  -0.31958008 -0.00714111 -0.15087891  0.140625   -0.00772095 -0.1730957
  -0.08251953  0.07580566  0.22570801 -0.08789062 -0.05123901 -0.00364685
   0.08526611  0.03833008  0.097229   -0.06665039 -0.1206665  -0.00488281
   0.06903076 -0.17529297  0.02635193 -0.1038208   0.29467773  0.00720215
  -0.02874756  0.05581665 -0.30200195  0.01123047 -0.31738281 -0.15917969
  -0.02067566  0.15209961 -0.25048828 -0.08081055  0.25415039 -0.09002686
  -0.03262329 -0.0489502   0.09912109  0.02342224  0.16784668 -0.06762695
  -0.25292969  0.01000977  0.06896973 -0.26977539 -0.12841797 -0.12524414
   0.07019043 -0.06646729 -0.09112549  0.20227051 -0.01931763 -0.06878662
   0.18017578  0.04327393  0.04190063 -0.08630371  0.01455688  0.04864502
  -0.05545044  0.0682373  -0.17504883  0.18908691  0.02120972  0.09960938
  -0.0892334   0.02897644 -0.10449219  0.06408691 -0.34130859  0.15380859
  -0.03799438  0.01577759 -0.00471497 -0.08203125 -0.03955078 -0.0255127
  -0.09802246 -0.23937988  0.05175781  0.31616211  0.38232422  0.12658691
   0.00810242 -0.10552979 -0.08728027  0.0036087 ]]
After layer encoder_birnn_reverse_l0_t9_slice_output3 (1, 256) <class 'numpy.float16'> [[ 0.09033203  0.08312988 -0.00856018  0.08496094  0.01095581  0.21240234
   0.07714844  0.10144043  0.50244141  0.15563965 -0.07427979  0.08764648
   0.18334961 -0.04736328  0.06793213  0.15820312 -0.05950928 -0.10064697
   0.05822754  0.00521851 -0.0512085  -0.15771484  0.33886719  0.12237549
   0.0222168   0.10626221 -0.02766418 -0.02940369 -0.13427734  0.0063324
   0.12402344  0.11004639  0.05230713  0.04724121 -0.00756836 -0.07537842
   0.12487793 -0.01071167  0.04122925 -0.05603027  0.0329895  -0.02160645
  -0.00091553  0.02053833 -0.027771    0.04733276  0.04776001 -0.11688232
   0.02609253  0.13293457  0.08605957  0.01312256 -0.14160156  0.06082153
   0.18383789 -0.09936523  0.17700195  0.04724121  0.02505493 -0.11981201
   0.10894775  0.11395264  0.02856445  0.19506836 -0.01075745 -0.04040527
   0.23901367  0.07275391 -0.04675293  0.04083252  0.01411438  0.03201294
  -0.00479126 -0.01895142  0.16674805  0.1652832   0.15307617  0.03704834
   0.15368652  0.23779297  0.21386719  0.21899414  0.14575195  0.09619141
   0.19360352  0.0541687   0.06335449  0.05770874  0.09344482  0.02227783
   0.20043945 -0.05178833 -0.1072998   0.02931213  0.01843262  0.02778625
   0.04718018  0.03302002 -0.15698242 -0.14196777 -0.09020996 -0.16308594
  -0.10430908 -0.10662842 -0.05352783  0.00250244 -0.05020142  0.14550781
   0.07373047  0.07037354  0.04693604  0.0619812  -0.10693359  0.16845703
  -0.00845337  0.17260742 -0.06408691 -0.04089355  0.04302979 -0.0581665
   0.04733276  0.10656738  0.07531738 -0.01838684 -0.08679199  0.04946899
   0.02371216  0.01672363 -0.00671387 -0.13708496  0.03414917  0.17883301
  -0.02006531  0.13806152  0.052948   -0.1036377   0.16796875  0.04678345
   0.15649414  0.06427002  0.03198242 -0.01315308 -0.05895996  0.11169434
  -0.02157593  0.04650879  0.21411133  0.11474609  0.02500916 -0.02722168
  -0.01382446 -0.02792358  0.11639404  0.15869141 -0.0526123   0.0690918
   0.13989258  0.07128906  0.03881836  0.16882324  0.09460449  0.07476807
   0.02142334  0.14208984  0.10583496 -0.10900879  0.34204102  0.13305664
  -0.16760254  0.03436279 -0.1496582   0.15649414  0.13208008  0.25952148
  -0.0043335   0.20385742  0.16674805 -0.0802002   0.05328369 -0.02780151
  -0.1505127  -0.11956787  0.08294678 -0.11682129 -0.0881958   0.19458008
  -0.04943848  0.13793945 -0.06463623 -0.15576172  0.0112915   0.15771484
   0.07421875  0.04589844 -0.10205078  0.08435059 -0.0423584   0.03887939
   0.12805176  0.05285645  0.1005249   0.22766113  0.10437012  0.17797852
   0.10137939  0.09899902 -0.11181641  0.0758667  -0.13867188  0.20068359
   0.01239014  0.34008789  0.09790039  0.18554688  0.13549805 -0.0947876
   0.06158447  0.26196289 -0.03143311 -0.06030273 -0.02508545 -0.20532227
   0.203125    0.02806091  0.07952881  0.10839844 -0.00363159  0.0585022
   0.41455078  0.14465332  0.01104736 -0.19238281 -0.03198242  0.02249146
  -0.01217651  0.04998779 -0.01599121  0.1104126   0.14245605  0.06982422
  -0.22241211  0.1003418   0.06549072  0.33886719 -0.19775391  0.06890869
  -0.03460693 -0.171875    0.05075073 -0.04449463  0.13891602 -0.11236572
   0.13928223  0.15783691  0.00100708  0.05825806]]
After layer encoder_birnn_reverse_l0_t9_o_output (1, 256) <class 'numpy.float16'> [[ 0.52246094  0.52099609  0.49780273  0.52099609  0.50292969  0.55273438
   0.51904297  0.52539062  0.62304688  0.5390625   0.48144531  0.52197266
   0.54589844  0.48828125  0.51708984  0.53955078  0.48510742  0.47485352
   0.51464844  0.50146484  0.48730469  0.46069336  0.58398438  0.53076172
   0.50537109  0.52636719  0.49316406  0.49267578  0.46655273  0.50146484
   0.53076172  0.52734375  0.51318359  0.51171875  0.49804688  0.48120117
   0.53125     0.49731445  0.51025391  0.48608398  0.50830078  0.49462891
   0.49975586  0.50537109  0.49316406  0.51171875  0.51171875  0.47070312
   0.50634766  0.53320312  0.52148438  0.50341797  0.46459961  0.51513672
   0.54589844  0.47509766  0.54394531  0.51171875  0.50634766  0.4699707
   0.52734375  0.52832031  0.50732422  0.54882812  0.49731445  0.48999023
   0.55957031  0.51806641  0.48828125  0.51025391  0.50341797  0.5078125
   0.4987793   0.49536133  0.54150391  0.54101562  0.53808594  0.50927734
   0.53857422  0.55908203  0.55322266  0.5546875   0.53613281  0.52392578
   0.54833984  0.51367188  0.515625    0.51464844  0.5234375   0.50537109
   0.54980469  0.48706055  0.47314453  0.50732422  0.50439453  0.50683594
   0.51171875  0.50830078  0.4609375   0.46459961  0.47753906  0.45922852
   0.47387695  0.47338867  0.48657227  0.50048828  0.48754883  0.53613281
   0.51855469  0.51757812  0.51171875  0.515625    0.47338867  0.54199219
   0.49780273  0.54296875  0.48388672  0.48974609  0.51074219  0.48535156
   0.51171875  0.52685547  0.51904297  0.49536133  0.47827148  0.51220703
   0.50585938  0.50439453  0.49829102  0.46582031  0.50830078  0.54443359
   0.49487305  0.53466797  0.51318359  0.47412109  0.54199219  0.51171875
   0.5390625   0.51611328  0.5078125   0.49682617  0.48535156  0.52783203
   0.49462891  0.51171875  0.55322266  0.52880859  0.50634766  0.49316406
   0.49658203  0.49291992  0.52929688  0.53955078  0.48681641  0.51708984
   0.53515625  0.51757812  0.50976562  0.54199219  0.5234375   0.51855469
   0.50537109  0.53564453  0.52636719  0.47265625  0.58447266  0.53320312
   0.45825195  0.50878906  0.46264648  0.5390625   0.53320312  0.56445312
   0.49902344  0.55078125  0.54150391  0.47998047  0.51318359  0.49316406
   0.46240234  0.47021484  0.52050781  0.47094727  0.47802734  0.54833984
   0.48754883  0.53466797  0.48388672  0.46118164  0.50292969  0.53955078
   0.51855469  0.51123047  0.47460938  0.52099609  0.48950195  0.50976562
   0.53173828  0.51318359  0.52490234  0.55664062  0.52587891  0.54443359
   0.52539062  0.52490234  0.47216797  0.51904297  0.46533203  0.54980469
   0.50292969  0.58398438  0.52441406  0.54638672  0.53369141  0.47631836
   0.515625    0.56494141  0.4921875   0.48486328  0.49365234  0.44873047
   0.55078125  0.50683594  0.52001953  0.52685547  0.49902344  0.51464844
   0.60205078  0.53613281  0.50292969  0.45214844  0.49194336  0.50585938
   0.49707031  0.51269531  0.49609375  0.52734375  0.53564453  0.51757812
   0.44458008  0.52490234  0.51660156  0.58398438  0.45068359  0.51708984
   0.49145508  0.45703125  0.51269531  0.48876953  0.53466797  0.47192383
   0.53466797  0.53955078  0.50048828  0.51464844]]
After layer encoder_birnn_reverse_l0_t9_f_output (1, 256) <class 'numpy.float16'> [[ 0.54248047  0.515625    0.53320312  0.50878906  0.49316406  0.52197266
   0.5546875   0.47216797  0.60498047  0.55273438  0.53417969  0.54394531
   0.53759766  0.49731445  0.53662109  0.54199219  0.52392578  0.49755859
   0.46166992  0.52929688  0.54248047  0.50878906  0.62695312  0.52246094
   0.53369141  0.52441406  0.55029297  0.51855469  0.53515625  0.51074219
   0.52880859  0.51416016  0.56738281  0.48779297  0.49926758  0.49389648
   0.48535156  0.54833984  0.50683594  0.52050781  0.46704102  0.53222656
   0.50537109  0.53076172  0.515625    0.53613281  0.51025391  0.46240234
   0.49560547  0.50048828  0.52099609  0.53027344  0.48022461  0.54443359
   0.52001953  0.51123047  0.51708984  0.53076172  0.4934082   0.46826172
   0.53662109  0.51220703  0.52636719  0.50488281  0.49047852  0.54492188
   0.56054688  0.52783203  0.45214844  0.47973633  0.52001953  0.50390625
   0.48217773  0.51367188  0.53369141  0.53564453  0.52099609  0.52539062
   0.53125     0.53173828  0.56152344  0.55859375  0.51025391  0.50244141
   0.55566406  0.49511719  0.53027344  0.54052734  0.51220703  0.44897461
   0.59521484  0.51855469  0.52148438  0.51953125  0.48217773  0.50097656
   0.49267578  0.49853516  0.4465332   0.45239258  0.47460938  0.49023438
   0.51708984  0.53320312  0.48754883  0.48999023  0.46948242  0.515625
   0.52978516  0.45703125  0.52050781  0.4921875   0.52197266  0.56689453
   0.52734375  0.55712891  0.54248047  0.53710938  0.51220703  0.53027344
   0.56103516  0.54931641  0.51171875  0.50488281  0.48242188  0.4987793
   0.54736328  0.49951172  0.52832031  0.46679688  0.54345703  0.52832031
   0.50634766  0.55761719  0.51074219  0.50634766  0.50830078  0.52001953
   0.54443359  0.56982422  0.48461914  0.50634766  0.52587891  0.51269531
   0.51708984  0.53271484  0.53564453  0.51074219  0.51318359  0.48974609
   0.49365234  0.52832031  0.51904297  0.53564453  0.48828125  0.54980469
   0.52929688  0.47558594  0.52392578  0.54541016  0.56298828  0.52929688
   0.49316406  0.52783203  0.53515625  0.4921875   0.58056641  0.49536133
   0.5         0.50146484  0.50439453  0.54101562  0.50146484  0.55957031
   0.48291016  0.54199219  0.54833984  0.48876953  0.49926758  0.53271484
   0.52246094  0.47998047  0.56787109  0.49365234  0.49755859  0.51806641
   0.50732422  0.56005859  0.48291016  0.47802734  0.48876953  0.52050781
   0.55371094  0.54638672  0.4440918   0.50488281  0.50244141  0.49682617
   0.50927734  0.50927734  0.52441406  0.50683594  0.5234375   0.49853516
   0.53222656  0.46142578  0.48071289  0.55126953  0.47290039  0.53076172
   0.52001953  0.53173828  0.4855957   0.51123047  0.49902344  0.46630859
   0.51855469  0.53027344  0.48876953  0.53857422  0.47363281  0.46875
   0.57666016  0.49780273  0.52783203  0.49975586  0.51220703  0.52099609
   0.6171875   0.54443359  0.51904297  0.41870117  0.54394531  0.51220703
   0.52539062  0.49804688  0.50244141  0.52636719  0.5234375   0.52636719
   0.51123047  0.52148438  0.49584961  0.55957031  0.453125    0.5
   0.47314453  0.48730469  0.53710938  0.48706055  0.55371094  0.44750977
   0.54443359  0.50244141  0.53759766  0.50195312]]
After layer _mul2090_0 (1, 256) <class 'numpy.float16'> [[ -9.52758789e-02  -7.74536133e-02  -2.36663818e-02   3.35083008e-02
    4.21524048e-03  -3.35388184e-02   8.97407532e-04   2.57415771e-02
    7.66601562e-02  -1.04492188e-01  -4.93469238e-02   1.29394531e-01
    6.46362305e-02  -2.69508362e-03   5.09643555e-02  -1.87988281e-01
    4.76684570e-02   1.49536133e-02   5.00793457e-02   3.68041992e-02
    1.68823242e-01  -4.33959961e-02  -2.70385742e-02   1.81427002e-02
   -8.08105469e-02   1.73187256e-02   2.73437500e-02  -2.99835205e-02
   -9.30175781e-02  -7.29980469e-02   2.79235840e-02  -6.15234375e-02
    4.52423096e-03  -2.62069702e-03   7.56835938e-02  -7.47680664e-02
   -2.67181396e-02   5.61904907e-03  -6.21643066e-02  -6.57958984e-02
    5.21469116e-03  -1.30126953e-01   7.26928711e-02   7.09838867e-02
    5.73425293e-02  -8.03222656e-02   4.29687500e-02  -2.96325684e-02
   -1.32980347e-02  -6.15234375e-02   3.85742188e-02  -9.53979492e-02
   -2.73132324e-02   1.39282227e-01  -1.55181885e-02   3.51905823e-03
   -3.88908386e-03   1.37084961e-01   6.95190430e-02  -2.33459473e-02
   -8.69750977e-02  -5.17578125e-02  -7.64465332e-03  -2.36358643e-02
    4.61120605e-02  -2.87322998e-02   2.06451416e-02  -6.78710938e-02
   -4.38232422e-02   6.80541992e-03  -1.82495117e-01   2.16522217e-02
    8.36181641e-03   1.26876831e-02   9.28955078e-02  -6.01959229e-03
   -4.68444824e-02  -1.57348633e-01  -6.12487793e-02  -3.86352539e-02
   -1.04858398e-01  -1.08051300e-03  -6.65893555e-02  -1.07177734e-01
   -2.16186523e-01   1.95026398e-04  -4.40368652e-02  -1.25789642e-03
   -1.25976562e-01  -3.82995605e-02  -1.08398438e-01  -3.19519043e-02
   -1.84936523e-02   9.20104980e-03  -2.68707275e-02   3.73535156e-02
    4.42504883e-02  -2.09350586e-02  -3.85437012e-02  -4.97131348e-02
    2.95448303e-03   8.60595703e-02  -4.58984375e-02   3.90014648e-02
    3.57055664e-02   1.06079102e-01  -2.33764648e-02  -1.48468018e-02
    1.17187500e-01  -9.38720703e-02   8.07495117e-02  -1.51519775e-02
    7.12280273e-02   1.10473633e-01  -4.92553711e-02   2.32666016e-01
   -1.21826172e-01  -6.79321289e-02   2.41851807e-03  -4.20837402e-02
    1.52221680e-01   3.47290039e-02   4.17709351e-03  -6.90307617e-02
    4.16259766e-02  -1.09252930e-01  -7.85522461e-02  -5.39855957e-02
   -3.12500000e-02  -7.90405273e-03   1.00952148e-01  -5.46646118e-03
    4.42199707e-02   6.24179840e-04  -3.24249268e-03   3.76281738e-02
    4.58068848e-02   1.58325195e-01   5.55801392e-03   5.68237305e-02
   -3.37600708e-03  -2.24456787e-02   1.01501465e-01   1.14440918e-02
   -5.54504395e-02   7.72705078e-02   6.56738281e-02  -6.16455078e-02
   -5.96923828e-02  -8.06884766e-02  -4.95300293e-02  -1.67999268e-02
   -5.81054688e-02  -4.32128906e-02  -5.16891479e-03   7.50122070e-02
   -8.77075195e-02  -5.13458252e-03   3.32641602e-02   5.81665039e-02
   -2.14721680e-01  -3.24707031e-02   6.48498535e-03   9.34448242e-02
    2.72369385e-02   4.85534668e-02   6.79969788e-04  -1.60522461e-02
   -1.39282227e-01   2.16102600e-03  -6.75048828e-02   6.10351562e-02
   -1.20925903e-02  -1.09497070e-01  -2.73437500e-02   4.24194336e-02
    1.19384766e-01  -3.26232910e-02  -2.64129639e-02  -6.38198853e-03
    4.52880859e-02   1.37100220e-02   4.59899902e-02  -2.57720947e-02
   -5.10253906e-02   1.08566284e-02   3.21044922e-02  -8.77685547e-02
    2.90985107e-02  -5.72509766e-02   1.22192383e-01  -1.68132782e-03
   -1.43051147e-02   2.92816162e-02  -1.10717773e-01   2.56919861e-03
   -1.46240234e-01  -5.92956543e-02  -1.51977539e-02   6.57958984e-02
   -1.16394043e-01  -3.67431641e-02   1.25122070e-01  -3.90625000e-02
   -1.43127441e-02  -1.83715820e-02   4.17175293e-02   1.03988647e-02
    6.93969727e-02  -4.14123535e-02  -1.19750977e-01   2.50244141e-03
    2.54516602e-02  -1.25976562e-01  -4.95300293e-02  -5.01403809e-02
    2.93273926e-02  -3.19824219e-02  -3.46679688e-02   9.64965820e-02
   -1.06277466e-02  -3.25317383e-02   9.24682617e-02   1.83410645e-02
    1.73339844e-02  -3.89709473e-02   6.41632080e-03   2.08892822e-02
   -9.37652588e-03   2.25982666e-02  -8.64257812e-02   6.21643066e-02
    1.67694092e-02   4.80957031e-02  -4.37927246e-02   1.38168335e-02
   -4.91027832e-02   2.59246826e-02  -1.52709961e-01   7.58056641e-02
   -8.62884521e-03   2.87055969e-03   8.18634033e-03  -4.62646484e-02
   -1.54876709e-02  -2.02636719e-02  -3.47595215e-02  -9.87548828e-02
    2.24456787e-02   1.30249023e-01   1.99707031e-01   4.83398438e-02
    1.23596191e-02  -4.92553711e-02  -4.42199707e-02  -6.48975372e-04]]
After layer encoder_birnn_reverse_l0_t9_i_output (1, 256) <class 'numpy.float16'> [[ 0.49658203  0.49194336  0.48510742  0.49145508  0.48754883  0.48974609
   0.49291992  0.49829102  0.52294922  0.52001953  0.484375    0.53027344
   0.49926758  0.50244141  0.5         0.5859375   0.46313477  0.47363281
   0.50341797  0.49755859  0.53320312  0.49755859  0.45678711  0.48364258
   0.51074219  0.46704102  0.49316406  0.50146484  0.49584961  0.49462891
   0.49658203  0.49731445  0.48339844  0.48901367  0.52490234  0.45336914
   0.49536133  0.49462891  0.47583008  0.47607422  0.4465332   0.50683594
   0.48901367  0.50341797  0.50683594  0.49414062  0.52148438  0.47607422
   0.48266602  0.50537109  0.50927734  0.52978516  0.44604492  0.52490234
   0.54882812  0.53466797  0.47875977  0.50390625  0.47314453  0.49853516
   0.52636719  0.47924805  0.54052734  0.49438477  0.47167969  0.48950195
   0.53125     0.49487305  0.46630859  0.49536133  0.53027344  0.49584961
   0.4921875   0.48950195  0.50585938  0.51025391  0.52832031  0.54589844
   0.515625    0.52050781  0.50634766  0.51220703  0.52490234  0.4921875
   0.54199219  0.50439453  0.49438477  0.47094727  0.49707031  0.51123047
   0.53173828  0.50439453  0.47753906  0.51708984  0.51904297  0.5078125
   0.49169922  0.49755859  0.46533203  0.46289062  0.46044922  0.51806641
   0.50683594  0.47412109  0.45703125  0.50048828  0.4921875   0.47192383
   0.52246094  0.49145508  0.4765625   0.49243164  0.50927734  0.56982422
   0.50683594  0.58154297  0.49707031  0.50146484  0.4987793   0.48168945
   0.55859375  0.46728516  0.49243164  0.52783203  0.47338867  0.52392578
   0.46142578  0.5234375   0.49047852  0.50341797  0.56298828  0.5078125
   0.49780273  0.4855957   0.47509766  0.46435547  0.53271484  0.54296875
   0.49023438  0.49755859  0.48950195  0.46044922  0.52783203  0.51171875
   0.50097656  0.50341797  0.51025391  0.51708984  0.49975586  0.5234375
   0.53320312  0.48022461  0.49902344  0.47705078  0.46435547  0.55224609
   0.50683594  0.49609375  0.4934082   0.49267578  0.56738281  0.49755859
   0.4777832   0.50292969  0.50097656  0.47875977  0.49511719  0.48413086
   0.50683594  0.48706055  0.49414062  0.51220703  0.50195312  0.52392578
   0.50537109  0.44775391  0.51318359  0.46313477  0.48144531  0.49731445
   0.51660156  0.47924805  0.49780273  0.50732422  0.52832031  0.49707031
   0.49511719  0.48828125  0.52441406  0.50683594  0.48364258  0.48706055
   0.50585938  0.48071289  0.47192383  0.52636719  0.53125     0.45410156
   0.51123047  0.52880859  0.50341797  0.52246094  0.52392578  0.52392578
   0.49902344  0.48583984  0.49389648  0.48828125  0.47631836  0.50830078
   0.51416016  0.53857422  0.50537109  0.50927734  0.49414062  0.48925781
   0.49902344  0.49511719  0.51367188  0.49829102  0.48046875  0.4597168
   0.53271484  0.47729492  0.49511719  0.51806641  0.49121094  0.47143555
   0.45849609  0.51416016  0.49560547  0.45581055  0.49609375  0.48535156
   0.50634766  0.51464844  0.4987793   0.52294922  0.51123047  0.49731445
   0.45825195  0.45727539  0.52441406  0.56054688  0.48144531  0.50488281
   0.46264648  0.47436523  0.50195312  0.49291992  0.54833984  0.49365234
   0.46264648  0.51513672  0.51318359  0.50244141]]
After layer encoder_birnn_reverse_l0_t9_c_output (1, 256) <class 'numpy.float16'> [[-0.17016602 -0.15429688 -0.05810547  0.0791626  -0.01263428 -0.06542969
  -0.02078247  0.03686523  0.13806152 -0.20788574 -0.09204102  0.25537109
   0.13012695  0.0118103   0.10546875 -0.31103516  0.10437012  0.03430176
   0.12695312  0.07830811  0.32250977 -0.09539795 -0.06756592  0.02200317
  -0.15332031  0.03500366  0.03527832 -0.052948   -0.17504883 -0.1595459
   0.05389404 -0.1171875   0.01623535 -0.01829529  0.16430664 -0.17053223
  -0.05487061  0.01730347 -0.12878418 -0.14111328  0.00128174 -0.24816895
   0.16052246  0.15551758  0.11871338 -0.16625977  0.11157227 -0.07312012
  -0.04074097 -0.13049316  0.06555176 -0.18652344 -0.04125977  0.28344727
  -0.07409668 -0.00453186  0.00665283  0.27661133  0.17028809 -0.05529785
  -0.17980957 -0.10394287 -0.00604248 -0.06536865  0.11999512 -0.05859375
   0.0279541  -0.13110352 -0.11621094  0.02514648 -0.36450195  0.05639648
  -0.00549316  0.02624512  0.18591309  0.00939941 -0.10095215 -0.30737305
  -0.13391113 -0.090271   -0.19848633 -0.01586914 -0.14306641 -0.23950195
  -0.375      -0.00799561 -0.05462646 -0.02331543 -0.27832031 -0.06451416
  -0.17333984 -0.0602417  -0.04000854  0.03335571 -0.05316162  0.08605957
   0.08374023 -0.02610779 -0.09442139 -0.14172363  0.00152588  0.18981934
  -0.09747314  0.09143066  0.09191895  0.24584961 -0.06109619 -0.01716614
   0.23522949 -0.22351074  0.19287109 -0.0480957   0.1607666   0.19604492
  -0.08294678  0.36767578 -0.24365234 -0.13305664 -0.03530884 -0.07965088
   0.26391602  0.05603027  0.02783203 -0.14733887  0.07904053 -0.23388672
  -0.1583252  -0.12017822 -0.06427002 -0.00942993  0.20202637  0.00473022
   0.09399414 -0.01312256 -0.01544189  0.07556152  0.08886719  0.30566406
   0.02087402  0.10797119 -0.015625   -0.04525757  0.1965332   0.01215363
  -0.12145996  0.16174316  0.14355469 -0.11914062 -0.12585449 -0.17541504
  -0.12036133 -0.03475952 -0.13183594 -0.08508301 -0.02560425  0.14453125
  -0.17175293 -0.03643799  0.06799316  0.11907959 -0.359375   -0.05648804
   0.00039673  0.17565918  0.05969238  0.10229492 -0.01831055 -0.02973938
  -0.30908203 -0.00714111 -0.14978027  0.13964844 -0.00772095 -0.17138672
  -0.08233643  0.07568359  0.22192383 -0.08764648 -0.0512085  -0.00364685
   0.08508301  0.03829956  0.09692383 -0.06652832 -0.12005615 -0.00488281
   0.06890869 -0.17346191  0.02635193 -0.10345459  0.28637695  0.00720215
  -0.0287323   0.05575562 -0.29321289  0.01123047 -0.30712891 -0.15783691
  -0.02067566  0.15087891 -0.24536133 -0.08062744  0.2487793  -0.08978271
  -0.03262329 -0.04891968  0.09881592  0.02342224  0.16625977 -0.06750488
  -0.24768066  0.01000977  0.06884766 -0.26342773 -0.12768555 -0.12457275
   0.07006836 -0.06634521 -0.09088135  0.19958496 -0.01931763 -0.06866455
   0.17822266  0.04324341  0.04187012 -0.08605957  0.01455688  0.0486145
  -0.0553894   0.06811523 -0.17333984  0.18688965  0.02120972  0.0993042
  -0.08898926  0.02896118 -0.10412598  0.06402588 -0.32861328  0.15258789
  -0.03796387  0.01577759 -0.00471497 -0.08184814 -0.03952026 -0.0255127
  -0.09771729 -0.23486328  0.05169678  0.30615234  0.36474609  0.12585449
   0.00810242 -0.10516357 -0.08703613  0.0036087 ]]
After layer _mul2091_0 (1, 256) <class 'numpy.float16'> [[ -8.44726562e-02  -7.59277344e-02  -2.81829834e-02   3.89099121e-02
   -6.16073608e-03  -3.20434570e-02  -1.02462769e-02   1.83715820e-02
    7.22045898e-02  -1.08093262e-01  -4.45861816e-02   1.35375977e-01
    6.49414062e-02   5.93566895e-03   5.27343750e-02  -1.82250977e-01
    4.83398438e-02   1.62506104e-02   6.39038086e-02   3.89709473e-02
    1.71997070e-01  -4.74548340e-02  -3.08685303e-02   1.06430054e-02
   -7.83081055e-02   1.63421631e-02   1.73950195e-02  -2.65502930e-02
   -8.67919922e-02  -7.89184570e-02   2.67639160e-02  -5.82885742e-02
    7.85064697e-03  -8.94927979e-03   8.62426758e-02  -7.73315430e-02
   -2.71759033e-02   8.56018066e-03  -6.12792969e-02  -6.71997070e-02
    5.72204590e-04  -1.25732422e-01   7.84912109e-02   7.83081055e-02
    6.01806641e-02  -8.21533203e-02   5.81970215e-02  -3.48205566e-02
   -1.96685791e-02  -6.59179688e-02   3.33862305e-02  -9.88159180e-02
   -1.84020996e-02   1.48803711e-01  -4.06799316e-02  -2.42233276e-03
    3.18527222e-03   1.39404297e-01   8.05664062e-02  -2.75726318e-02
   -9.46655273e-02  -4.98046875e-02  -3.26538086e-03  -3.23181152e-02
    5.66101074e-02  -2.86865234e-02   1.48468018e-02  -6.48803711e-02
   -5.41992188e-02   1.24588013e-02  -1.93237305e-01   2.79693604e-02
   -2.70462036e-03   1.28479004e-02   9.40551758e-02   4.79507446e-03
   -5.33447266e-02  -1.67846680e-01  -6.90307617e-02  -4.69970703e-02
   -1.00524902e-01  -8.12530518e-03  -7.50732422e-02  -1.17858887e-01
   -2.03247070e-01  -4.03213501e-03  -2.70080566e-02  -1.09786987e-02
   -1.38305664e-01  -3.29895020e-02  -9.21630859e-02  -3.03802490e-02
   -1.91040039e-02   1.72424316e-02  -2.75878906e-02   4.37011719e-02
    4.11682129e-02  -1.29928589e-02  -4.39453125e-02  -6.56127930e-02
    7.02381134e-04   9.83276367e-02  -4.94079590e-02   4.33349609e-02
    4.20227051e-02   1.23046875e-01  -3.00750732e-02  -8.10241699e-03
    1.22924805e-01  -1.09863281e-01   9.19189453e-02  -2.36816406e-02
    8.18481445e-02   1.11694336e-01  -4.20532227e-02   2.13867188e-01
   -1.21093750e-01  -6.67114258e-02  -1.76086426e-02  -3.83605957e-02
    1.47460938e-01   2.61840820e-02   1.37023926e-02  -7.77587891e-02
    3.74145508e-02  -1.22558594e-01  -7.30590820e-02  -6.29272461e-02
   -3.15246582e-02  -4.74548340e-03   1.13708496e-01   2.40135193e-03
    4.67834473e-02  -6.37054443e-03  -7.33566284e-03   3.50952148e-02
    4.73327637e-02   1.66015625e-01   1.02310181e-02   5.37109375e-02
   -7.64846802e-03  -2.08435059e-02   1.03759766e-01   6.21795654e-03
   -6.08520508e-02   8.14208984e-02   7.32421875e-02  -6.16149902e-02
   -6.28662109e-02  -9.17968750e-02  -6.41479492e-02  -1.66931152e-02
   -6.57958984e-02  -4.05883789e-02  -1.18865967e-02   7.98339844e-02
   -8.70361328e-02  -1.80816650e-02   3.35388184e-02   5.86547852e-02
   -2.03857422e-01  -2.81066895e-02   1.89542770e-04   8.83178711e-02
    2.99072266e-02   4.89807129e-02  -9.06372070e-03  -1.43966675e-02
   -1.56616211e-01  -3.47900391e-03  -7.40356445e-02   7.15332031e-02
   -3.87573242e-03  -8.97827148e-02  -4.15954590e-02   3.38745117e-02
    1.13891602e-01  -4.05883789e-02  -2.46582031e-02  -1.81388855e-03
    4.39453125e-02   1.83563232e-02   4.82482910e-02  -3.37524414e-02
   -6.34155273e-02  -2.42614746e-03   3.41186523e-02  -8.47167969e-02
    1.38168335e-02  -5.24291992e-02   1.38549805e-01   3.50761414e-03
   -1.45339966e-02   2.68096924e-02  -1.38427734e-01   5.91278076e-03
   -1.63208008e-01  -7.16552734e-02  -1.05667114e-02   7.97729492e-02
   -1.23535156e-01  -4.21142578e-02   1.30371094e-01  -4.70275879e-02
   -1.62811279e-02  -2.37731934e-02   4.87976074e-02   1.14364624e-02
    7.91625977e-02  -3.43017578e-02  -1.27319336e-01   5.39016724e-03
    3.47900391e-02  -1.34155273e-01  -6.31103516e-02  -6.09436035e-02
    3.49731445e-02  -3.28369141e-02  -4.66918945e-02   9.94262695e-02
   -9.28497314e-03  -3.15551758e-02   9.49707031e-02   2.06451416e-02
    2.07366943e-02  -4.45861816e-02   7.14874268e-03   2.29187012e-02
   -2.53906250e-02   3.50341797e-02  -8.59375000e-02   8.52050781e-02
    1.05209351e-02   4.81872559e-02  -4.50744629e-02   1.49078369e-02
   -5.19409180e-02   3.34777832e-02  -1.67968750e-01   7.58666992e-02
   -1.73950195e-02   7.21359253e-03  -2.47192383e-03  -4.58679199e-02
   -1.90277100e-02  -1.28784180e-02  -4.51965332e-02  -1.11389160e-01
    2.59552002e-02   1.50878906e-01   1.99951172e-01   6.21337891e-02
    3.74794006e-03  -5.41687012e-02  -4.46777344e-02   1.81293488e-03]]
After layer encoder_birnn_reverse_l0_t9_state_0 (1, 256) <class 'numpy.float16'> [[-0.1796875  -0.15332031 -0.05184937  0.0723877  -0.0019455  -0.06555176
  -0.00934601  0.04412842  0.14892578 -0.21264648 -0.09393311  0.26464844
   0.12963867  0.00324059  0.10369873 -0.37011719  0.0960083   0.03120422
   0.11401367  0.07580566  0.34082031 -0.09082031 -0.05792236  0.02877808
  -0.15917969  0.03366089  0.04473877 -0.05651855 -0.17980957 -0.15185547
   0.0546875  -0.11981201  0.01237488 -0.01156616  0.16186523 -0.15209961
  -0.05389404  0.01417542 -0.12341309 -0.13305664  0.0057869  -0.25585938
   0.15112305  0.14929199  0.11755371 -0.16247559  0.10119629 -0.06445312
  -0.03295898 -0.12744141  0.07196045 -0.19421387 -0.04571533  0.28808594
  -0.05621338  0.00109673 -0.00070381  0.27636719  0.15014648 -0.05090332
  -0.18164062 -0.1015625  -0.01091003 -0.05596924  0.10272217 -0.05743408
   0.03549194 -0.1328125  -0.09802246  0.01925659 -0.37573242  0.04962158
   0.0056572   0.02554321  0.18701172 -0.00122452 -0.10021973 -0.32519531
  -0.13024902 -0.08563232 -0.20532227 -0.00920868 -0.14160156 -0.22509766
  -0.41943359 -0.00383759 -0.07104492 -0.01223755 -0.26416016 -0.07128906
  -0.20056152 -0.06231689 -0.03759766  0.02644348 -0.05444336  0.08105469
   0.08544922 -0.03393555 -0.08251953 -0.11535645  0.00365639  0.18432617
  -0.09533691  0.08233643  0.07775879  0.22912598 -0.0534668  -0.02294922
   0.2401123  -0.20373535  0.17260742 -0.03881836  0.15307617  0.22216797
  -0.09130859  0.4465332  -0.24291992 -0.13464355 -0.01519012 -0.08044434
   0.29980469  0.06091309  0.0178833  -0.14672852  0.07904053 -0.23181152
  -0.15161133 -0.11694336 -0.06274414 -0.01264954  0.21459961 -0.00306511
   0.09100342 -0.00574493 -0.01057434  0.07275391  0.09313965  0.32421875
   0.01579285  0.11053467 -0.01102448 -0.04327393  0.20532227  0.01766968
  -0.11633301  0.15869141  0.13891602 -0.12329102 -0.12255859 -0.17248535
  -0.11364746 -0.0335083  -0.12390137 -0.08380127 -0.01705933  0.15478516
  -0.17480469 -0.02322388  0.06677246  0.11682129 -0.41845703 -0.06057739
   0.00667572  0.1817627   0.05712891  0.09753418 -0.0083847  -0.03045654
  -0.29589844 -0.00131798 -0.14160156  0.13256836 -0.01596069 -0.19921875
  -0.06896973  0.07629395  0.23327637 -0.07324219 -0.05108643 -0.00819397
   0.0892334   0.03207397  0.09423828 -0.05950928 -0.11444092  0.00843048
   0.06622314 -0.17248535  0.04290771 -0.10968018  0.26074219  0.00182629
  -0.02883911  0.05609131 -0.24914551  0.00848389 -0.30957031 -0.13098145
  -0.02575684  0.14550781 -0.23999023 -0.07885742  0.25537109 -0.08605957
  -0.03059387 -0.04214478  0.09051514  0.02183533  0.14855957 -0.07568359
  -0.24707031  0.00788879  0.0602417  -0.26025391 -0.1126709  -0.11108398
   0.06433105 -0.06481934 -0.08135986  0.19592285 -0.01991272 -0.06408691
   0.1875      0.03900146  0.03808594 -0.08355713  0.01356506  0.04382324
  -0.03475952  0.05761719 -0.17236328  0.14733887  0.02728271  0.09631348
  -0.08886719  0.02871704 -0.10107422  0.05938721 -0.32080078  0.15161133
  -0.02603149  0.01008606  0.00571442 -0.09216309 -0.03451538 -0.03314209
  -0.07995605 -0.21020508  0.04840088  0.28125     0.3996582   0.11047363
   0.01611328 -0.10339355 -0.08886719  0.00116348]]
After layer activation1045_output (1, 256) <class 'numpy.float16'> [[-0.17773438 -0.15209961 -0.05178833  0.07226562 -0.0019455  -0.06542969
  -0.00934601  0.0440979   0.14782715 -0.20947266 -0.09362793  0.25854492
   0.12890625  0.00324059  0.10333252 -0.35400391  0.09570312  0.03118896
   0.11352539  0.07568359  0.328125   -0.09057617 -0.05786133  0.02876282
  -0.15783691  0.03366089  0.04470825 -0.05645752 -0.17785645 -0.15075684
   0.05462646 -0.1192627   0.01237488 -0.01156616  0.16052246 -0.15087891
  -0.05383301  0.01417542 -0.12280273 -0.13232422  0.0057869  -0.25048828
   0.15002441  0.14819336  0.11700439 -0.16101074  0.10083008 -0.06439209
  -0.03295898 -0.12670898  0.07183838 -0.19177246 -0.04568481  0.28027344
  -0.05615234  0.00109673 -0.00070381  0.26953125  0.14904785 -0.0508728
  -0.1796875  -0.10119629 -0.01091003 -0.0559082   0.10235596 -0.05737305
   0.03549194 -0.13208008 -0.09771729  0.01925659 -0.35888672  0.04959106
   0.0056572   0.02554321  0.18481445 -0.00122452 -0.09991455 -0.31420898
  -0.1295166  -0.08544922 -0.20251465 -0.00920868 -0.140625   -0.22131348
  -0.39648438 -0.00383759 -0.07092285 -0.01223755 -0.25830078 -0.07116699
  -0.19787598 -0.06222534 -0.03756714  0.02644348 -0.05438232  0.08087158
   0.08526611 -0.03393555 -0.08233643 -0.11486816  0.00365639  0.18225098
  -0.09503174  0.08215332  0.07757568  0.22521973 -0.05340576 -0.02294922
   0.2355957  -0.20092773  0.17089844 -0.03878784  0.15185547  0.21862793
  -0.09106445  0.41894531 -0.23828125 -0.13378906 -0.01519012 -0.08026123
   0.29101562  0.06085205  0.0178833  -0.14562988  0.07885742 -0.2277832
  -0.1505127  -0.11639404 -0.06268311 -0.01264954  0.21142578 -0.00306511
   0.09075928 -0.00574493 -0.01057434  0.07263184  0.09289551  0.31323242
   0.01579285  0.11010742 -0.01102448 -0.04324341  0.20251465  0.01766968
  -0.11578369  0.15734863  0.13806152 -0.12268066 -0.12194824 -0.17077637
  -0.11315918 -0.0335083  -0.12329102 -0.08361816 -0.01705933  0.15356445
  -0.1730957  -0.02322388  0.06665039  0.11627197 -0.39550781 -0.06051636
   0.00667572  0.17980957  0.05706787  0.097229   -0.0083847  -0.03044128
  -0.28759766 -0.00131798 -0.140625    0.13183594 -0.01596069 -0.19665527
  -0.06884766  0.07617188  0.22912598 -0.07312012 -0.05105591 -0.00819397
   0.08898926  0.03207397  0.09393311 -0.05944824 -0.11395264  0.00843048
   0.06610107 -0.17077637  0.0428772  -0.10925293  0.25488281  0.00182629
  -0.02882385  0.05603027 -0.24414062  0.00848389 -0.30004883 -0.13024902
  -0.02575684  0.14453125 -0.23547363 -0.07867432  0.25       -0.08587646
  -0.03057861 -0.04211426  0.090271    0.02183533  0.14746094 -0.07556152
  -0.2421875   0.00788879  0.06018066 -0.25463867 -0.11218262 -0.11065674
   0.06427002 -0.0647583  -0.08117676  0.19348145 -0.01991272 -0.06402588
   0.18530273  0.03897095  0.03805542 -0.08337402  0.01356506  0.04379272
  -0.03475952  0.05755615 -0.1706543   0.14624023  0.02728271  0.0960083
  -0.08862305  0.02870178 -0.10070801  0.05932617 -0.31030273  0.1505127
  -0.02603149  0.01008606  0.00571442 -0.09191895 -0.03451538 -0.03314209
  -0.07977295 -0.20715332  0.04837036  0.27416992  0.37963867  0.11004639
   0.01611328 -0.10302734 -0.08862305  0.00116348]]
After layer encoder_birnn_reverse_l0_t9_out_0 (1, 256) <class 'numpy.float16'> [[-0.09283447 -0.07922363 -0.02578735  0.03765869 -0.00097847 -0.03616333
  -0.00485229  0.02316284  0.09210205 -0.11291504 -0.04507446  0.13500977
   0.07037354  0.00158215  0.05343628 -0.19104004  0.04641724  0.01480865
   0.05841064  0.03796387  0.15991211 -0.04171753 -0.03378296  0.01526642
  -0.07977295  0.01771545  0.02204895 -0.02781677 -0.08300781 -0.07562256
   0.0289917  -0.06286621  0.00635147 -0.00592041  0.07995605 -0.07263184
  -0.02859497  0.00704956 -0.06268311 -0.06433105  0.00294113 -0.12390137
   0.07495117  0.07489014  0.05770874 -0.08239746  0.05160522 -0.03030396
  -0.01669312 -0.06756592  0.03747559 -0.09655762 -0.02122498  0.14440918
  -0.03065491  0.00052118 -0.0003829   0.13793945  0.07550049 -0.02391052
  -0.09472656 -0.0534668  -0.00553513 -0.03068542  0.05090332 -0.02810669
   0.01986694 -0.06842041 -0.04769897  0.00982666 -0.18066406  0.025177
   0.00282097  0.01264954  0.10009766 -0.00066233 -0.05377197 -0.16003418
  -0.06976318 -0.04776001 -0.11206055 -0.00510788 -0.07537842 -0.1159668
  -0.21740723 -0.0019722  -0.03656006 -0.00629807 -0.13525391 -0.03598022
  -0.10876465 -0.03030396 -0.01777649  0.01341248 -0.0274353   0.04098511
   0.04364014 -0.01724243 -0.03796387 -0.05337524  0.00174618  0.0836792
  -0.04504395  0.03887939  0.03775024  0.11273193 -0.02603149 -0.01230621
   0.12219238 -0.10400391  0.08746338 -0.02000427  0.07189941  0.11846924
  -0.0453186   0.22741699 -0.11529541 -0.06555176 -0.00775909 -0.03894043
   0.14892578  0.03207397  0.00928497 -0.07214355  0.03771973 -0.11669922
  -0.07611084 -0.05871582 -0.03123474 -0.00589371  0.10748291 -0.00166893
   0.04492188 -0.00307083 -0.00542831  0.03442383  0.050354    0.16027832
   0.0085144   0.05682373 -0.00559998 -0.02148438  0.0982666   0.00932312
  -0.05728149  0.08050537  0.07635498 -0.06488037 -0.06173706 -0.08422852
  -0.05618286 -0.01651001 -0.06524658 -0.04510498 -0.00830841  0.07940674
  -0.09265137 -0.01202393  0.03396606  0.06298828 -0.20703125 -0.03137207
   0.0033741   0.09631348  0.03004456  0.04595947 -0.00490189 -0.01623535
  -0.13183594 -0.00067043 -0.06506348  0.07104492 -0.00850677 -0.11102295
  -0.03436279  0.04196167  0.12408447 -0.03509521 -0.02619934 -0.00403976
   0.0411377   0.01508331  0.04888916 -0.02799988 -0.05447388  0.00462341
   0.03222656 -0.09130859  0.02075195 -0.05038452  0.12817383  0.00098515
  -0.01494598  0.02864075 -0.11584473  0.00442123 -0.14685059 -0.06640625
  -0.01369476  0.07415771 -0.12359619 -0.04379272  0.13146973 -0.04675293
  -0.0160675  -0.02210999  0.04263306  0.01133728  0.06860352 -0.04153442
  -0.12182617  0.00460815  0.03155518 -0.13916016 -0.05987549 -0.05270386
   0.03314209 -0.03659058 -0.03994751  0.09381104 -0.00982666 -0.0287323
   0.10205078  0.01974487  0.01979065 -0.04391479  0.00677109  0.02253723
  -0.0209198   0.03085327 -0.08581543  0.06610107  0.0134201   0.04855347
  -0.04403687  0.0147171  -0.04995728  0.03128052 -0.16625977  0.07788086
  -0.01157379  0.0052948   0.00295258 -0.05368042 -0.01555634 -0.01713562
  -0.03921509 -0.09466553  0.02479553  0.1340332   0.20300293  0.05194092
   0.00861359 -0.05560303 -0.04434204  0.00059891]]
After layer expand_dims1051_0 (1, 1, 256) <class 'numpy.float16'> [[[-0.09283447 -0.07922363 -0.02578735  0.03765869 -0.00097847 -0.03616333
   -0.00485229  0.02316284  0.09210205 -0.11291504 -0.04507446  0.13500977
    0.07037354  0.00158215  0.05343628 -0.19104004  0.04641724  0.01480865
    0.05841064  0.03796387  0.15991211 -0.04171753 -0.03378296  0.01526642
   -0.07977295  0.01771545  0.02204895 -0.02781677 -0.08300781 -0.07562256
    0.0289917  -0.06286621  0.00635147 -0.00592041  0.07995605 -0.07263184
   -0.02859497  0.00704956 -0.06268311 -0.06433105  0.00294113 -0.12390137
    0.07495117  0.07489014  0.05770874 -0.08239746  0.05160522 -0.03030396
   -0.01669312 -0.06756592  0.03747559 -0.09655762 -0.02122498  0.14440918
   -0.03065491  0.00052118 -0.0003829   0.13793945  0.07550049 -0.02391052
   -0.09472656 -0.0534668  -0.00553513 -0.03068542  0.05090332 -0.02810669
    0.01986694 -0.06842041 -0.04769897  0.00982666 -0.18066406  0.025177
    0.00282097  0.01264954  0.10009766 -0.00066233 -0.05377197 -0.16003418
   -0.06976318 -0.04776001 -0.11206055 -0.00510788 -0.07537842 -0.1159668
   -0.21740723 -0.0019722  -0.03656006 -0.00629807 -0.13525391 -0.03598022
   -0.10876465 -0.03030396 -0.01777649  0.01341248 -0.0274353   0.04098511
    0.04364014 -0.01724243 -0.03796387 -0.05337524  0.00174618  0.0836792
   -0.04504395  0.03887939  0.03775024  0.11273193 -0.02603149 -0.01230621
    0.12219238 -0.10400391  0.08746338 -0.02000427  0.07189941  0.11846924
   -0.0453186   0.22741699 -0.11529541 -0.06555176 -0.00775909 -0.03894043
    0.14892578  0.03207397  0.00928497 -0.07214355  0.03771973 -0.11669922
   -0.07611084 -0.05871582 -0.03123474 -0.00589371  0.10748291 -0.00166893
    0.04492188 -0.00307083 -0.00542831  0.03442383  0.050354    0.16027832
    0.0085144   0.05682373 -0.00559998 -0.02148438  0.0982666   0.00932312
   -0.05728149  0.08050537  0.07635498 -0.06488037 -0.06173706 -0.08422852
   -0.05618286 -0.01651001 -0.06524658 -0.04510498 -0.00830841  0.07940674
   -0.09265137 -0.01202393  0.03396606  0.06298828 -0.20703125 -0.03137207
    0.0033741   0.09631348  0.03004456  0.04595947 -0.00490189 -0.01623535
   -0.13183594 -0.00067043 -0.06506348  0.07104492 -0.00850677 -0.11102295
   -0.03436279  0.04196167  0.12408447 -0.03509521 -0.02619934 -0.00403976
    0.0411377   0.01508331  0.04888916 -0.02799988 -0.05447388  0.00462341
    0.03222656 -0.09130859  0.02075195 -0.05038452  0.12817383  0.00098515
   -0.01494598  0.02864075 -0.11584473  0.00442123 -0.14685059 -0.06640625
   -0.01369476  0.07415771 -0.12359619 -0.04379272  0.13146973 -0.04675293
   -0.0160675  -0.02210999  0.04263306  0.01133728  0.06860352 -0.04153442
   -0.12182617  0.00460815  0.03155518 -0.13916016 -0.05987549 -0.05270386
    0.03314209 -0.03659058 -0.03994751  0.09381104 -0.00982666 -0.0287323
    0.10205078  0.01974487  0.01979065 -0.04391479  0.00677109  0.02253723
   -0.0209198   0.03085327 -0.08581543  0.06610107  0.0134201   0.04855347
   -0.04403687  0.0147171  -0.04995728  0.03128052 -0.16625977  0.07788086
   -0.01157379  0.0052948   0.00295258 -0.05368042 -0.01555634 -0.01713562
   -0.03921509 -0.09466553  0.02479553  0.1340332   0.20300293  0.05194092
    0.00861359 -0.05560303 -0.04434204  0.00059891]]]
After layer concat5_output (10, 1, 256) <class 'numpy.float16'> [[[-0.02970886 -0.01194763 -0.01511383 ..., -0.01320648  0.0104599
   -0.01748657]]

 [[-0.02632141 -0.01463318  0.01530457 ..., -0.00766373  0.00930023
   -0.03518677]]

 [[-0.04400635 -0.03665161  0.00863647 ..., -0.02056885 -0.00748062
   -0.020401  ]]

 ...,
 [[-0.08764648 -0.07495117 -0.01795959 ..., -0.04931641 -0.03720093
   -0.00205231]]

 [[-0.0904541  -0.07733154 -0.02203369 ..., -0.05252075 -0.04101562
   -0.00066471]]

 [[-0.09283447 -0.07922363 -0.02578735 ..., -0.05560303 -0.04434204
    0.00059891]]]
After layer sequencereverse5_output (10, 1, 256) <class 'numpy.float16'> [[[-0.02632141 -0.01463318  0.01530457 ..., -0.00766373  0.00930023
   -0.03518677]]

 [[-0.02970886 -0.01194763 -0.01511383 ..., -0.01320648  0.0104599
   -0.01748657]]

 [[-0.04400635 -0.03665161  0.00863647 ..., -0.02056885 -0.00748062
   -0.020401  ]]

 ...,
 [[-0.08764648 -0.07495117 -0.01795959 ..., -0.04931641 -0.03720093
   -0.00205231]]

 [[-0.0904541  -0.07733154 -0.02203369 ..., -0.05252075 -0.04101562
   -0.00066471]]

 [[-0.09283447 -0.07922363 -0.02578735 ..., -0.05560303 -0.04434204
    0.00059891]]]
After layer encoder_birnn__rnn_output (10, 1, 512) <class 'numpy.float16'> [[[  3.44657898e-03   2.28118896e-02  -6.56890869e-03 ...,  -7.66372681e-03
     9.30023193e-03  -3.51867676e-02]]

 [[  2.75878906e-02   5.06896973e-02  -5.15441895e-02 ...,  -1.32064819e-02
     1.04598999e-02  -1.74865723e-02]]

 [[  4.40368652e-02   7.92236328e-02  -1.12670898e-01 ...,  -2.05688477e-02
    -7.48062134e-03  -2.04010010e-02]]

 ...,
 [[  6.63574219e-01   5.45898438e-01  -6.80175781e-01 ...,  -4.93164062e-02
    -3.72009277e-02  -2.05230713e-03]]

 [[  8.23730469e-01   6.33300781e-01  -7.52929688e-01 ...,  -5.25207520e-02
    -4.10156250e-02  -6.64710999e-04]]

 [[  9.11621094e-01   7.02148438e-01  -8.03710938e-01 ...,  -5.56030273e-02
    -4.43420410e-02   5.98907471e-04]]]
After layer swapaxes11_output (1, 10, 512) <class 'numpy.float16'> [[[  3.44657898e-03   2.28118896e-02  -6.56890869e-03 ...,  -7.66372681e-03
     9.30023193e-03  -3.51867676e-02]
  [  2.75878906e-02   5.06896973e-02  -5.15441895e-02 ...,  -1.32064819e-02
     1.04598999e-02  -1.74865723e-02]
  [  4.40368652e-02   7.92236328e-02  -1.12670898e-01 ...,  -2.05688477e-02
    -7.48062134e-03  -2.04010010e-02]
  ...,
  [  6.63574219e-01   5.45898438e-01  -6.80175781e-01 ...,  -4.93164062e-02
    -3.72009277e-02  -2.05230713e-03]
  [  8.23730469e-01   6.33300781e-01  -7.52929688e-01 ...,  -5.25207520e-02
    -4.10156250e-02  -6.64710999e-04]
  [  9.11621094e-01   7.02148438e-01  -8.03710938e-01 ...,  -5.56030273e-02
    -4.43420410e-02   5.98907471e-04]]]
After layer zeros_like5_0 (1,) <class 'numpy.float16'> [ 0.]
After layer expand_dims1053_0 (1, 1) <class 'numpy.float16'> [[ 0.]]
After layer expand_dims1054_0 (1, 1, 1) <class 'numpy.float16'> [[[ 0.]]]
After layer broadcast_to2_0 (1, 10, 1) <class 'numpy.float16'> [[[ 0.]
  [ 0.]
  [ 0.]
  [ 0.]
  [ 0.]
  [ 0.]
  [ 0.]
  [ 0.]
  [ 0.]
  [ 0.]]]
After layer zeros_like4_0 (1,) <class 'numpy.float16'> [ 0.]
After layer expand_dims1052_0 (1, 1) <class 'numpy.float16'> [[ 0.]]
After layer tile2_0 (1, 512) <class 'numpy.float16'> [[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
   0.  0.  0.  0.  0.  0.  0.  0.]]
After layer swapaxes12_output (10, 1, 512) <class 'numpy.float16'> [[[  3.44657898e-03   2.28118896e-02  -6.56890869e-03 ...,  -7.66372681e-03
     9.30023193e-03  -3.51867676e-02]]

 [[  2.75878906e-02   5.06896973e-02  -5.15441895e-02 ...,  -1.32064819e-02
     1.04598999e-02  -1.74865723e-02]]

 [[  4.40368652e-02   7.92236328e-02  -1.12670898e-01 ...,  -2.05688477e-02
    -7.48062134e-03  -2.04010010e-02]]

 ...,
 [[  6.63574219e-01   5.45898438e-01  -6.80175781e-01 ...,  -4.93164062e-02
    -3.72009277e-02  -2.05230713e-03]]

 [[  8.23730469e-01   6.33300781e-01  -7.52929688e-01 ...,  -5.25207520e-02
    -4.10156250e-02  -6.64710999e-04]]

 [[  9.11621094e-01   7.02148438e-01  -8.03710938e-01 ...,  -5.56030273e-02
    -4.43420410e-02   5.98907471e-04]]]
After layer sequencelast2_output (1, 512) <class 'numpy.float16'> [[ 0.02758789  0.0506897  -0.05154419 -0.01663208  0.05926514 -0.03540039
   0.0369873  -0.03317261  0.02275085 -0.0186615   0.01365662  0.03010559
   0.0446167  -0.05508423  0.02688599 -0.03356934  0.01108551  0.04925537
  -0.01513672  0.02366638 -0.04086304 -0.0411377  -0.0725708   0.03561401
   0.00396729 -0.01180267 -0.08532715 -0.0333252  -0.02604675  0.03120422
   0.01792908 -0.05749512  0.06280518 -0.00585175  0.05627441  0.04541016
   0.02993774 -0.05340576 -0.05621338  0.01676941 -0.04263306  0.04016113
  -0.04608154  0.02890015 -0.02552795 -0.0161438   0.02201843  0.04501343
   0.04507446  0.00097084  0.00552368  0.02168274  0.03878784 -0.0224762
   0.06185913  0.04629517 -0.02166748 -0.01678467  0.05560303 -0.03164673
   0.03768921 -0.02363586  0.03744507  0.07489014 -0.04421997  0.019104
   0.01330566  0.06222534  0.02250671 -0.06719971  0.01603699 -0.03475952
  -0.0960083   0.03179932  0.04327393  0.034729    0.05145264 -0.10595703
   0.05670166 -0.05871582  0.05056763 -0.04977417  0.06069946  0.01942444
  -0.02763367 -0.06280518  0.03256226 -0.07122803  0.00629425  0.03762817
   0.02703857  0.03726196 -0.037323   -0.02903748 -0.06384277  0.00440216
  -0.00149155 -0.09643555  0.02793884  0.06130981 -0.02937317 -0.00946045
  -0.01589966  0.05105591 -0.02095032 -0.04064941  0.01716614  0.0579834
   0.03585815  0.06512451 -0.03338623 -0.05612183  0.07159424  0.07543945
  -0.01459503  0.04598999  0.0390625   0.04336548  0.04077148 -0.00387573
   0.00832367 -0.07824707  0.06439209 -0.02934265  0.09429932 -0.01015472
   0.04760742  0.03726196 -0.04647827 -0.10314941 -0.00587845  0.03747559
   0.02435303 -0.0198822   0.06256104  0.05831909 -0.00563431  0.04824829
  -0.07873535 -0.02355957 -0.02284241  0.06048584 -0.06185913 -0.01823425
   0.05801392  0.02685547  0.04467773 -0.02516174  0.05215454 -0.03503418
   0.04016113 -0.04022217  0.05682373  0.090271    0.03549194 -0.06970215
   0.05380249 -0.00997162  0.03347778  0.02215576  0.07928467  0.03527832
   0.05615234  0.04138184 -0.04110718  0.02920532 -0.03790283  0.03363037
  -0.05599976 -0.03570557  0.02938843  0.07775879 -0.03634644  0.04452515
  -0.02462769 -0.0295105   0.04602051  0.04653931 -0.04870605 -0.01000977
   0.06347656  0.0486145   0.03561401  0.03604126 -0.01663208 -0.04702759
  -0.02815247  0.07019043  0.02539062 -0.01502228  0.0198822  -0.04797363
  -0.07348633  0.07336426  0.0218811  -0.05673218 -0.00022924 -0.06286621
   0.04968262  0.01316833  0.04519653 -0.05783081 -0.03182983 -0.01129913
  -0.0484314   0.03613281  0.01194     0.01927185  0.02445984  0.04986572
  -0.02641296  0.06439209  0.04376221  0.00348854  0.06561279 -0.05645752
  -0.03915405 -0.0647583  -0.02156067  0.00758362 -0.03305054  0.02920532
   0.05303955 -0.07818604  0.03817749 -0.10162354 -0.08270264 -0.05377197
   0.01713562 -0.01756287 -0.02946472 -0.05407715 -0.00563812  0.07672119
  -0.02960205 -0.00894928  0.0737915   0.06671143 -0.014328    0.06494141
   0.0322876   0.04251099 -0.08441162 -0.04620361  0.05618286 -0.04138184
   0.00748825 -0.03482056 -0.06280518  0.04467773 -0.04992676 -0.01421356
  -0.04055786 -0.04177856  0.00665665  0.05032349 -0.02970886 -0.01194763
  -0.01511383 -0.02838135  0.0007     -0.05084229  0.01519012  0.00743484
  -0.01263428 -0.0292511  -0.00892639  0.02149963  0.01942444 -0.02441406
   0.02238464 -0.01264191  0.01180267  0.01028442  0.01543427 -0.00818634
   0.01702881 -0.02944946  0.00573349  0.02171326  0.00350571 -0.00063372
  -0.05001831 -0.00417328  0.00456619 -0.01956177  0.01311493 -0.01486206
   0.01568604 -0.00918579  0.01121521 -0.00168228 -0.04040527 -0.00548935
  -0.02720642 -0.00129986  0.00836182  0.00656509  0.02973938  0.00282669
   0.03250122 -0.02288818  0.02363586 -0.01882935 -0.00304222 -0.03842163
  -0.03875732 -0.0131073   0.00892639  0.02011108 -0.00271797  0.01379395
  -0.02578735  0.03094482  0.00950623 -0.03234863 -0.02154541 -0.00498581
  -0.0140686  -0.02342224  0.03289795 -0.02375793  0.0236969  -0.00036716
  -0.03019714 -0.01751709 -0.03948975  0.0123291   0.00642014 -0.01829529
   0.00468063 -0.02523804 -0.01780701 -0.02337646 -0.01007843 -0.01079559
  -0.02659607 -0.00647354 -0.01719666 -0.03111267 -0.02229309  0.01875305
  -0.01251984  0.01481628 -0.0100708  -0.03857422  0.02728271  0.00107765
   0.01277161 -0.01413727  0.01475525 -0.00128365  0.01143646  0.01904297
   0.00614548  0.0079422   0.012146    0.02174377 -0.03643799  0.01468658
  -0.0165863   0.00683594 -0.00529861 -0.03295898  0.0256958  -0.00377464
   0.02749634  0.05664062 -0.00127029  0.01612854 -0.01235962 -0.00540543
  -0.0144043  -0.03134155  0.00041747  0.01966858  0.01081848  0.02047729
  -0.01663208 -0.01065826  0.0308075  -0.02427673 -0.0149231  -0.00465775
   0.02220154  0.03936768  0.02455139  0.02876282  0.00157738  0.02304077
   0.00752258  0.01875305  0.01270294 -0.00427628  0.01747131  0.03393555
  -0.02720642 -0.00717926  0.01522064 -0.02423096 -0.03430176  0.01942444
   0.04260254 -0.02565002  0.0039978  -0.00577545 -0.02064514 -0.00551605
   0.00696564  0.00358391  0.0052681  -0.02737427 -0.03034973  0.01759338
   0.03051758  0.02159119 -0.01197052 -0.01370239  0.01242828  0.00999451
   0.01055908  0.0078125   0.01652527 -0.03192139  0.00061989 -0.02333069
  -0.01067352  0.01901245 -0.01052094 -0.00665283 -0.01657104  0.01316071
   0.06103516 -0.01058197 -0.04373169 -0.0141449  -0.00225067 -0.0042038
  -0.02294922 -0.00239372  0.05526733 -0.02081299  0.0049324  -0.02848816
   0.01670837 -0.01989746  0.00649643  0.0319519  -0.0010128   0.00437927
  -0.01757812  0.01151276 -0.02888489 -0.0271759   0.01145172  0.01248169
  -0.01329041  0.02778625  0.03289795 -0.01377869  0.02510071 -0.00474548
  -0.01776123  0.00962067  0.03497314 -0.01861572 -0.00306702  0.0096817
   0.02575684 -0.02365112  0.01309204 -0.01945496  0.00263214 -0.00123215
  -0.01481628  0.03010559  0.03053284 -0.01325989 -0.01644897 -0.00350952
  -0.01004791 -0.00623703 -0.00696564  0.02159119 -0.00396729  0.00918579
  -0.00107384  0.02076721  0.02133179  0.00662994 -0.01174927  0.02926636
  -0.02088928 -0.00403214 -0.01184845  0.01908875  0.01038361 -0.01324463
   0.01747131  0.01171875 -0.02796936  0.01062012  0.00388718  0.00206566
  -0.03031921  0.0145874   0.01432037  0.01546478  0.03607178 -0.01320648
   0.0104599  -0.01748657]]
After layer decoder_rnn_enc2decinit_0_output (1, 512) <class 'numpy.float16'> [[-0.01641846 -0.07019043  0.16564941  0.12817383 -0.0094986  -0.04650879
  -0.42651367 -0.09735107  0.12805176  0.11437988 -0.21704102 -0.13720703
  -0.16394043  0.19628906  0.11376953 -0.13830566 -0.11791992  0.2166748
   0.47338867 -0.18151855  0.13830566  0.17016602  0.07202148 -0.22888184
  -0.10693359 -0.15893555  0.14501953  0.10705566 -0.12036133 -0.1763916
  -0.27026367  0.1472168   0.30078125  0.0949707   0.11279297  0.22802734
   0.05279541 -0.04315186 -0.54589844 -0.12335205 -0.04788208  0.2512207
  -0.19677734 -0.65625    -0.0994873   0.16357422 -0.18994141 -0.50292969
   0.08404541 -0.09020996  0.0562439  -0.15185547  0.22314453 -0.05584717
   0.17236328 -0.00184631 -0.11132812  0.29223633 -0.078125   -0.23071289
   0.01971436 -0.12463379  0.1328125  -0.35449219 -0.36132812 -0.17565918
  -0.15722656 -0.04800415 -0.19836426  0.07318115 -0.66308594 -0.09967041
   0.23803711 -0.09802246  0.15576172  0.36474609 -0.03662109 -0.08618164
  -0.25292969 -0.0612793  -0.08959961 -0.08825684 -0.23620605  0.4050293
   0.18994141 -0.09863281 -0.08190918 -0.10638428 -0.1739502   0.25048828
  -0.16394043 -0.61132812 -0.31005859  0.08062744 -0.27709961 -0.16369629
   0.13110352 -0.11865234 -0.03396606 -0.16113281 -0.0949707  -0.10717773
   0.29760742 -0.034729    0.13305664 -0.13354492 -0.10681152 -0.12866211
  -0.1907959   0.2286377   0.32055664  0.22119141 -0.58642578  0.00499725
   0.02615356  0.24865723 -0.10626221 -0.42211914 -0.1439209  -0.09820557
  -0.12841797 -0.4765625   0.15991211  0.07012939  0.1550293   0.21826172
   0.24645996  0.35180664 -0.03509521 -0.17102051 -0.12072754 -0.1307373
  -0.24816895  0.1697998   0.14892578  0.12390137 -0.12457275 -0.60986328
  -0.27783203 -0.05484009 -0.1817627   0.12915039  0.24353027  0.04882812
   0.12817383 -0.27246094  0.25439453  0.13916016  0.12902832  0.58740234
   0.36645508 -0.09771729  0.25268555  0.20141602 -0.03320312 -0.06872559
   0.08325195 -0.1505127  -0.01316833 -0.15576172  0.2878418   0.12609863
   0.11584473 -0.13586426 -0.20361328 -0.1270752   0.12548828 -0.07049561
  -0.12927246 -0.07434082  0.12353516  0.10302734 -0.05050659 -0.04437256
  -0.14929199 -0.20654297 -0.15014648 -0.1003418   0.18505859 -0.25268555
   0.12280273  0.1340332  -0.23339844 -0.2043457   0.17749023  0.26147461
  -0.24633789  0.19116211 -0.21374512  0.22729492  0.02832031 -0.14208984
  -0.07965088 -0.04858398  0.12255859 -0.17077637 -0.08105469 -0.21252441
   0.22119141  0.59375     0.16467285 -0.19958496 -0.07696533 -0.15551758
   0.14526367 -0.10693359 -0.10943604 -0.2578125   0.22619629 -0.26196289
   0.09143066  0.17260742 -0.09399414  0.13891602 -0.21582031 -0.23852539
   0.24438477 -0.17321777  0.16259766  0.17089844  0.03497314 -0.19763184
   0.06817627 -0.18566895  0.09979248 -0.25512695 -0.1472168   0.24450684
  -0.08703613 -0.43261719  0.25146484 -0.42822266  0.14038086  0.10571289
   0.17663574 -0.04916382 -0.39453125  0.19628906  0.19116211 -0.12902832
   0.13757324 -0.07183838 -0.21801758 -0.13684082  0.23352051 -0.0579834
  -0.06982422  0.11639404  0.12091064 -0.0949707  -0.13745117  0.25854492
   0.20275879  0.00784302  0.14611816  0.07537842  0.1072998   0.28759766
  -0.13366699  0.25341797  0.09906006  0.20275879  0.19799805  0.10778809
  -0.05157471 -0.03063965  0.26586914  0.17675781  0.16052246  0.32592773
   0.1817627   0.1739502  -0.18786621 -0.16308594  0.1315918  -0.21691895
   0.60888672  0.01916504  0.074646    0.26025391  0.15246582  0.09960938
  -0.24658203 -0.06744385 -0.42871094 -0.02722168  0.05664062 -0.23046875
  -0.15844727  0.28369141  0.14355469  0.13525391  0.20788574 -0.19689941
   0.10552979  0.02450562  0.13476562  0.26245117 -0.01931763 -0.13891602
  -0.31640625  0.03436279 -0.10595703  0.07830811 -0.04797363 -0.17700195
  -0.21655273  0.08331299  0.18725586  0.04632568 -0.21936035 -0.16491699
  -0.16760254 -0.12744141  0.20874023 -0.06005859 -0.06622314 -0.08880615
   0.2956543  -0.18127441  0.2232666   0.27807617  0.14257812  0.01156616
  -0.21557617  0.51806641  0.1385498  -0.09399414 -0.11572266 -0.14025879
   0.13903809 -0.18310547 -0.46337891 -0.18286133 -0.09863281 -0.08050537
  -0.03457642 -0.14587402 -0.1270752  -0.2980957  -0.2088623  -0.18591309
  -0.05661011  0.41333008 -0.03613281 -0.09906006  0.16027832 -0.20166016
   0.20141602  0.59375     0.30932617  0.01020813 -0.15991211 -0.11218262
  -0.32983398  0.10290527  0.15026855 -0.12927246  0.20556641  0.18127441
  -0.14733887 -0.09667969  0.11627197 -0.1439209  -0.13623047 -0.03713989
   0.09881592 -0.00734711 -0.68457031  0.12268066 -0.14807129  0.20068359
   0.52636719  0.09033203 -0.12988281 -0.07714844 -0.16784668 -0.11248779
   0.13830566 -0.08398438  0.27319336  0.22131348 -0.06970215 -0.10314941
  -0.21435547  0.19799805 -0.07171631 -0.31958008 -0.12817383  0.08666992
  -0.64013672 -0.18701172  0.12573242  0.28125     0.12915039 -0.45556641
  -0.2076416   0.02598572 -0.02270508 -0.20788574  0.35498047 -0.02030945
   0.0916748  -0.16796875  0.08166504  0.06170654  0.32104492  0.67529297
   0.11920166 -0.13415527 -0.17919922 -0.13354492  0.19152832 -0.00592041
  -0.18139648 -0.01161957 -0.2253418  -0.12731934  0.18457031  0.15405273
  -0.25463867  0.1027832   0.05404663 -0.16503906  0.24206543 -0.11187744
   0.01573181  0.24780273  0.10058594 -0.3215332   0.23010254 -0.06872559
   0.08251953  0.15197754 -0.0418396   0.09771729  0.27294922  0.10028076
  -0.07312012  0.10809326 -0.27294922 -0.112854   -0.11566162 -0.12158203
  -0.25170898  0.21362305 -0.20507812  0.14379883 -0.05505371  0.06671143
  -0.08001709  0.10418701 -0.18603516  0.02046204 -0.20019531  0.09112549
  -0.2454834  -0.54052734 -0.09570312 -0.17553711  0.19494629  0.23510742
   0.08251953  0.06192017  0.20092773 -0.0894165  -0.22229004  0.12457275
   0.06542969 -0.105896    0.1484375  -0.07849121  0.52685547  0.26953125
   0.13146973  0.12054443  0.00917053  0.17932129 -0.23193359  0.12402344
   0.17822266  0.31640625 -0.11853027  0.33764648  0.24609375 -0.09118652
   0.00712585 -0.13574219 -0.15527344  0.34667969  0.16552734  0.42163086
   0.27587891  0.06341553  0.20227051 -0.1697998   0.17272949 -0.18798828
   0.00684357  0.14501953  0.13525391 -0.28710938 -0.10076904  0.01966858
  -0.03994751  0.24267578  0.29248047 -0.11901855  0.46337891  0.06390381
   0.45483398  0.24328613]]
After layer decoder_rnn_enc2dec_inittanh_0_output (1, 512) <class 'numpy.float16'> [[-0.01641846 -0.07006836  0.16418457  0.12744141 -0.0094986  -0.04647827
  -0.40234375 -0.0970459   0.12731934  0.1138916  -0.21374512 -0.13635254
  -0.16247559  0.19384766  0.11328125 -0.13745117 -0.11737061  0.21337891
   0.44091797 -0.17956543  0.13745117  0.1685791   0.07189941 -0.22497559
  -0.10650635 -0.15759277  0.14404297  0.10662842 -0.11981201 -0.17456055
  -0.26391602  0.14611816  0.29199219  0.09466553  0.11230469  0.22412109
   0.05273438 -0.04312134 -0.49755859 -0.1227417  -0.04785156  0.24609375
  -0.19433594 -0.57568359 -0.09918213  0.16210938 -0.18774414 -0.46435547
   0.0838623  -0.08996582  0.05618286 -0.15075684  0.21948242 -0.05578613
   0.1706543  -0.00184631 -0.11090088  0.28417969 -0.07794189 -0.22668457
   0.01971436 -0.1239624   0.13208008 -0.34033203 -0.34643555 -0.17382812
  -0.15588379 -0.04797363 -0.19580078  0.07305908 -0.58056641 -0.09936523
   0.23364258 -0.09771729  0.15454102  0.34936523 -0.03659058 -0.08599854
  -0.24768066 -0.06118774 -0.08935547 -0.0880127  -0.23193359  0.38427734
   0.18774414 -0.09832764 -0.08172607 -0.10595703 -0.17224121  0.24536133
  -0.16247559 -0.54492188 -0.30053711  0.08044434 -0.27026367 -0.16223145
   0.13037109 -0.11810303 -0.03396606 -0.15979004 -0.09466553 -0.10675049
   0.2890625  -0.034729    0.13232422 -0.1328125  -0.10638428 -0.12792969
  -0.18847656  0.22473145  0.31005859  0.21765137 -0.52734375  0.00499725
   0.02615356  0.24365234 -0.10583496 -0.39868164 -0.14294434 -0.09790039
  -0.12768555 -0.44360352  0.15856934  0.07000732  0.15380859  0.21484375
   0.24157715  0.33789062 -0.03509521 -0.16931152 -0.12011719 -0.13000488
  -0.24316406  0.16821289  0.14782715  0.12329102 -0.1239624  -0.54394531
  -0.27099609 -0.05477905 -0.17980957  0.12841797  0.23876953  0.04879761
   0.12744141 -0.26586914  0.24902344  0.13830566  0.1282959   0.52783203
   0.35083008 -0.09741211  0.24743652  0.19873047 -0.03320312 -0.06860352
   0.08306885 -0.14941406 -0.01316833 -0.15454102  0.2800293   0.12548828
   0.11535645 -0.13500977 -0.20080566 -0.12634277  0.12481689 -0.07037354
  -0.12854004 -0.07421875  0.1229248   0.10266113 -0.05047607 -0.04434204
  -0.14819336 -0.20361328 -0.14904785 -0.10003662  0.1829834  -0.24743652
   0.12219238  0.13317871 -0.22924805 -0.20153809  0.17565918  0.25561523
  -0.24145508  0.18884277 -0.21057129  0.22351074  0.02832031 -0.14111328
  -0.07946777 -0.04855347  0.12194824 -0.16918945 -0.08087158 -0.20935059
   0.21765137  0.53271484  0.16320801 -0.19702148 -0.07684326 -0.15429688
   0.14428711 -0.10650635 -0.10900879 -0.25219727  0.22241211 -0.25610352
   0.09118652  0.17089844 -0.09368896  0.13806152 -0.21252441 -0.23413086
   0.23962402 -0.17150879  0.16113281  0.16931152  0.03497314 -0.19506836
   0.0680542  -0.18359375  0.0994873  -0.24975586 -0.14611816  0.23974609
  -0.08679199 -0.4074707   0.24633789 -0.40380859  0.13952637  0.10534668
   0.17480469 -0.0491333  -0.37524414  0.19384766  0.18884277 -0.1282959
   0.13671875 -0.07171631 -0.21459961 -0.13598633  0.22937012 -0.05792236
  -0.06970215  0.11584473  0.12030029 -0.09466553 -0.13659668  0.25292969
   0.20007324  0.00784302  0.1451416   0.07525635  0.10687256  0.2800293
  -0.13293457  0.24816895  0.09875488  0.20007324  0.19543457  0.10736084
  -0.05154419 -0.03062439  0.25976562  0.17492676  0.15917969  0.31494141
   0.17980957  0.17224121 -0.18566895 -0.16162109  0.13085938 -0.21362305
   0.54345703  0.01916504  0.07452393  0.25463867  0.15124512  0.0993042
  -0.24169922 -0.06732178 -0.40429688 -0.02722168  0.05657959 -0.22644043
  -0.15710449  0.27636719  0.14257812  0.13439941  0.20495605 -0.19433594
   0.10516357  0.02450562  0.13391113  0.2565918  -0.01931763 -0.13806152
  -0.30615234  0.03436279 -0.10559082  0.078125   -0.04794312 -0.1751709
  -0.21325684  0.08312988  0.18505859  0.04629517 -0.21594238 -0.16345215
  -0.16601562 -0.12670898  0.20581055 -0.05999756 -0.06610107 -0.08856201
   0.28735352 -0.17932129  0.21960449  0.27124023  0.14160156  0.01156616
  -0.21228027  0.47631836  0.13769531 -0.09368896 -0.11523438 -0.1394043
   0.13818359 -0.18103027 -0.43286133 -0.1809082  -0.09832764 -0.08032227
  -0.03457642 -0.14489746 -0.12634277 -0.28955078 -0.20593262 -0.18383789
  -0.05654907  0.39135742 -0.03610229 -0.09875488  0.15893555 -0.19897461
   0.19873047  0.53271484  0.29980469  0.01020813 -0.15856934 -0.11169434
  -0.31835938  0.10253906  0.14916992 -0.12854004  0.20275879  0.17932129
  -0.14624023 -0.09637451  0.11572266 -0.14294434 -0.13537598 -0.03710938
   0.09851074 -0.00734711 -0.59472656  0.12207031 -0.14697266  0.19799805
   0.48266602  0.09008789 -0.12915039 -0.07696533 -0.16625977 -0.11199951
   0.13745117 -0.08380127  0.26660156  0.21777344 -0.06958008 -0.1027832
  -0.21118164  0.19543457 -0.07159424 -0.30908203 -0.12744141  0.08642578
  -0.56494141 -0.18481445  0.12512207  0.27416992  0.12841797 -0.42651367
  -0.20471191  0.02598572 -0.02270508 -0.20495605  0.34082031 -0.02030945
   0.09143066 -0.16638184  0.08148193  0.06161499  0.31054688  0.58837891
   0.11865234 -0.13330078 -0.17724609 -0.1328125   0.18920898 -0.00592041
  -0.17944336 -0.01161957 -0.22155762 -0.12658691  0.18249512  0.15283203
  -0.24926758  0.10241699  0.0539856  -0.16357422  0.23742676 -0.11138916
   0.01573181  0.24279785  0.10021973 -0.31079102  0.22607422 -0.06860352
   0.08233643  0.15087891 -0.04180908  0.09741211  0.26635742  0.09997559
  -0.07299805  0.10766602 -0.26635742 -0.11236572 -0.11517334 -0.12097168
  -0.24658203  0.21044922 -0.20227051  0.14282227 -0.05499268  0.06658936
  -0.07983398  0.1038208  -0.18395996  0.02046204 -0.19750977  0.09088135
  -0.24072266 -0.4934082  -0.09539795 -0.17370605  0.19250488  0.23083496
   0.08233643  0.06182861  0.19824219 -0.08917236 -0.21875     0.1239624
   0.06530762 -0.10552979  0.14733887 -0.07830811  0.48291016  0.26318359
   0.1307373   0.11993408  0.00917053  0.17736816 -0.22790527  0.12341309
   0.1763916   0.30615234 -0.11798096  0.32543945  0.24121094 -0.09094238
   0.00712585 -0.1348877  -0.15405273  0.33349609  0.1640625   0.39819336
   0.26904297  0.06335449  0.19958496 -0.16821289  0.17102051 -0.18579102
   0.00684357  0.14404297  0.13439941 -0.27954102 -0.10040283  0.01966858
  -0.03991699  0.23803711  0.28442383 -0.11846924  0.43286133  0.06384277
   0.42578125  0.23864746]]
After layer decoder_rnn_enc2decinit_1_output (1, 512) <class 'numpy.float16'> [[ -7.61718750e-02  -1.46331787e-02   6.90307617e-02  -9.18579102e-02
    3.14941406e-01   7.60498047e-02  -5.56030273e-02   4.84008789e-02
    8.24584961e-02   1.44775391e-01   1.63085938e-01  -4.95300293e-02
   -1.52709961e-01   5.18493652e-02  -9.71069336e-02  -6.45141602e-02
   -1.81274414e-01   2.06909180e-01   5.80566406e-01  -8.39233398e-02
    4.98657227e-02   1.50024414e-01   6.47583008e-02   3.59191895e-02
   -3.98254395e-02  -4.57763672e-02   7.31201172e-02   1.88720703e-01
   -1.02966309e-01  -4.60205078e-02  -4.01000977e-02   9.03930664e-02
    1.96899414e-01  -4.68750000e-02   3.66455078e-01   3.36425781e-01
   -2.01538086e-01  -3.85131836e-02   3.66210938e-01  -3.74267578e-01
    2.37792969e-01   2.28118896e-02  -3.03955078e-01  -7.78808594e-02
   -1.77246094e-01   1.57226562e-01  -2.39990234e-01  -5.46875000e-02
   -3.56445312e-02  -2.11181641e-02   4.19921875e-02  -8.44116211e-02
   -4.38720703e-01  -1.49291992e-01   1.21276855e-01  -9.48486328e-02
   -2.12890625e-01   1.77368164e-01  -8.00781250e-02   2.27050781e-02
   -7.03735352e-02  -2.35176086e-03   7.28759766e-02   1.06811523e-01
    4.49371338e-03   8.72802734e-03  -9.05609131e-03   4.82788086e-02
   -2.41455078e-01   1.44897461e-01  -5.15441895e-02   5.17578125e-02
   -7.91015625e-02  -7.70874023e-02   5.37109375e-02   1.43051147e-02
    2.61718750e-01  -6.21414185e-03  -1.16271973e-01  -9.08813477e-02
   -5.38940430e-02  -8.65478516e-02  -1.25244141e-01  -9.45434570e-02
   -1.75170898e-02   1.14059448e-02  -2.11181641e-01  -2.75878906e-01
   -1.21643066e-01   3.72070312e-01  -1.74926758e-01   1.55761719e-01
    1.19079590e-01   1.60400391e-01   2.09960938e-01  -1.24206543e-01
   -1.38305664e-01  -3.53515625e-01  -5.76782227e-02  -1.64794922e-01
   -2.00561523e-01  -1.35986328e-01  -6.06445312e-01   1.40136719e-01
    1.96289062e-01  -6.31103516e-02  -1.53442383e-01  -2.35107422e-01
   -4.28466797e-02   6.13403320e-02   1.66625977e-01  -3.54492188e-01
    5.82519531e-01   5.81359863e-03   7.61108398e-02   1.71875000e-01
   -1.59301758e-01  -4.59899902e-02  -2.94677734e-01   1.45385742e-01
   -4.05273438e-02  -6.71386719e-02   1.97631836e-01   1.02539062e-01
    1.91772461e-01   5.51757812e-02   5.59997559e-02   1.82373047e-01
   -3.34228516e-01  -1.08032227e-02  -2.50854492e-02  -1.93481445e-02
   -3.99475098e-02   1.17675781e-01   1.36230469e-01   1.65039062e-01
   -1.47949219e-01  -4.32861328e-01  -4.33349609e-02  -3.39660645e-02
   -2.16674805e-01   2.78076172e-01  -3.53027344e-01  -8.52050781e-02
    2.47802734e-01  -1.27197266e-01   1.53198242e-02   1.60766602e-01
    2.49023438e-01   1.25000000e-01   2.36938477e-01  -1.95922852e-01
    1.74560547e-01   6.73828125e-02  -1.95922852e-01   1.11145020e-01
    6.39648438e-02  -2.52929688e-01  -4.03442383e-02  -6.26831055e-02
    9.53979492e-02   2.80517578e-01  -7.69653320e-02  -8.08105469e-02
   -6.40136719e-01   7.81250000e-02   1.29394531e-01  -1.02478027e-01
   -1.18103027e-01  -7.24487305e-02  -2.60986328e-01   1.64306641e-01
    1.03515625e-01   9.39941406e-02  -5.66711426e-02  -1.81121826e-02
   -1.89941406e-01  -9.68017578e-02   1.73583984e-01  -3.13964844e-01
    1.21276855e-01   4.40063477e-02  -1.64672852e-01  -8.12988281e-02
    2.99072266e-01   2.05688477e-01  -1.34765625e-01   1.04431152e-01
   -8.69140625e-02   1.54113770e-02   3.17993164e-02  -1.69067383e-01
    8.72192383e-02  -1.40747070e-01   1.67602539e-01  -2.21923828e-01
   -1.00280762e-01  -2.29736328e-01   7.94067383e-02   7.73925781e-02
    3.83377075e-03  -3.05175781e-01   6.11114502e-03  -1.98486328e-01
    1.59057617e-01  -3.07617188e-01   1.26342773e-01  -2.18750000e-01
    1.48681641e-01  -1.01440430e-01   4.63256836e-02  -8.20922852e-02
   -1.75323486e-02  -4.91638184e-02  -1.16088867e-01  -1.14868164e-01
    2.55371094e-01  -5.04394531e-01   7.87353516e-02   1.56494141e-01
    2.14111328e-01  -9.97314453e-02   1.71142578e-01  -6.71386719e-02
    4.28955078e-01  -3.12255859e-01   2.82135010e-02   1.70776367e-01
   -6.73217773e-02  -2.19604492e-01   1.79443359e-01  -5.92285156e-01
    7.18994141e-02   3.41796875e-01   2.86254883e-02  -6.53076172e-02
    1.73950195e-02   1.25656128e-02   1.02050781e-01  -8.62884521e-03
    2.86376953e-01  -5.07507324e-02  -2.84179688e-01  -2.13012695e-01
    1.04492188e-01   1.62109375e-01  -8.55712891e-02   1.32080078e-01
    6.18896484e-02  -1.40014648e-01  -2.27050781e-01   2.16186523e-01
    7.40966797e-02  -4.52270508e-02  -1.34277344e-01   3.06640625e-01
   -3.66943359e-01  -4.73632812e-02  -4.29687500e-02  -2.70263672e-01
    6.71386719e-02   3.63769531e-01   1.63818359e-01   9.22241211e-02
    4.01306152e-03  -1.28051758e-01   3.49731445e-02   1.77978516e-01
   -5.00183105e-02  -1.45019531e-01   2.35595703e-01   1.28936768e-02
   -2.98339844e-01  -5.42907715e-02  -2.10815430e-01  -9.15527344e-02
    6.41632080e-03  -9.72290039e-02  -7.85827637e-03   2.59765625e-01
    1.93481445e-01  -1.92016602e-01   3.35998535e-02  -2.65136719e-01
   -4.66003418e-02   2.02148438e-01  -1.64184570e-01  -3.91845703e-02
   -1.01928711e-01   3.01269531e-01   1.71875000e-01   3.45703125e-01
   -2.05322266e-01  -6.56738281e-02   1.83227539e-01  -1.59179688e-01
    1.13220215e-01   2.56347656e-02  -5.97839355e-02  -1.53442383e-01
   -2.47314453e-01   7.56225586e-02  -1.58813477e-01  -2.85888672e-01
   -5.98754883e-02  -1.84814453e-01   2.78930664e-02   1.87835693e-02
    3.33251953e-02   8.81347656e-02  -1.14807129e-01   1.17309570e-01
   -1.02294922e-01  -4.83398438e-02   4.55322266e-02   1.34277344e-01
   -6.03332520e-02  -7.76367188e-02   1.04187012e-01  -7.20825195e-02
    1.68579102e-01   2.67333984e-01   1.60400391e-01  -2.97241211e-02
   -1.92993164e-01  -3.86962891e-01   3.11035156e-01   3.18115234e-01
   -2.30712891e-01  -7.08007812e-02   2.20947266e-01  -2.73895264e-02
    2.97546387e-04  -1.53808594e-01  -3.51257324e-02  -1.02783203e-01
   -5.00793457e-02  -1.03515625e-01  -1.06018066e-01  -2.96630859e-01
   -8.85620117e-02  -1.93115234e-01  -3.02886963e-03   3.94042969e-01
   -2.59765625e-01  -6.46972656e-02   9.90600586e-02   4.61730957e-02
    1.39892578e-01   5.87158203e-02  -2.83203125e-01  -7.20825195e-02
   -5.65185547e-02   3.33251953e-02   6.36230469e-01   7.44628906e-02
    7.14111328e-02  -6.06994629e-02   2.38891602e-01   1.53320312e-01
    3.22265625e-01  -7.89184570e-02  -1.78100586e-01  -6.93359375e-02
   -2.09960938e-02  -1.19140625e-01   2.49755859e-01  -9.35668945e-02
    4.69726562e-01   9.81445312e-02  -1.03393555e-01   3.36914062e-02
    6.24389648e-02   2.08374023e-01  -1.08764648e-01  -1.71752930e-01
   -4.27734375e-01  -2.36450195e-01   2.82592773e-02  -9.30175781e-02
    1.23657227e-01   6.12487793e-02  -1.25488281e-01  -2.51220703e-01
   -3.00903320e-02   3.06884766e-01  -3.05175781e-01  -6.28051758e-02
   -1.10290527e-01  -8.16040039e-02  -3.34960938e-01   1.30981445e-01
    1.16882324e-01   5.43823242e-02  -4.01306152e-02  -2.65136719e-01
   -5.81359863e-02   2.15698242e-01  -2.25219727e-01  -1.26953125e-01
    2.73925781e-01  -1.59301758e-01  -2.20642090e-02  -1.35040283e-02
   -1.20178223e-01   1.24084473e-01  -2.01660156e-01  -4.18457031e-01
    4.86450195e-02   1.18713379e-01  -1.09802246e-01  -1.29150391e-01
    1.71386719e-01   9.79003906e-02   1.26953125e-01   1.45751953e-01
   -6.46972656e-02  -2.31567383e-01   1.80053711e-01   7.23876953e-02
   -3.85284424e-04   2.18627930e-01   1.19995117e-01  -8.64868164e-02
    9.24072266e-02   2.52685547e-01   1.92504883e-01   2.87841797e-01
    7.70874023e-02   1.37939453e-01   2.71728516e-01  -1.45385742e-01
   -1.34277344e-01  -1.33514404e-03   2.80761719e-01   2.26287842e-02
    2.15820312e-01   3.77273560e-03  -2.58300781e-01   1.04248047e-01
   -1.55395508e-01  -9.28955078e-02   3.82690430e-02  -1.98852539e-01
   -3.26660156e-01  -4.76074219e-02  -2.03369141e-01   1.93603516e-01
   -9.40551758e-02  -2.20092773e-01  -1.83715820e-01   3.26538086e-02
    2.68249512e-02   9.59777832e-03  -2.12158203e-01   3.49235535e-03
   -1.05041504e-01   8.53271484e-02   1.13708496e-01  -1.13281250e-01
    1.39892578e-01   1.73950195e-01  -1.04980469e-01   1.56494141e-01
    1.20117188e-01  -3.39508057e-03  -5.09033203e-02   5.94482422e-02
    5.79833984e-02  -5.42907715e-02   1.13769531e-01  -2.64404297e-01
    4.39697266e-01   5.35644531e-01   3.49121094e-02  -8.30688477e-02
    7.94677734e-02  -2.10571289e-02  -4.34570312e-02   1.64306641e-01
   -7.73620605e-03   3.56689453e-01   1.44531250e-01   1.15783691e-01
    2.25952148e-01  -5.18188477e-02  -7.34252930e-02  -2.36938477e-01
   -5.13458252e-03  -5.59692383e-02   1.51367188e-01   5.01708984e-02
   -6.26220703e-02   8.41064453e-02   6.01196289e-02  -5.02624512e-02
    1.74072266e-01  -7.06176758e-02  -7.52563477e-02  -2.10571289e-03
    3.06396484e-01   3.15551758e-02  -1.91894531e-01   3.71704102e-02
   -1.00341797e-01   8.63647461e-02   2.66357422e-01  -2.03125000e-01
   -2.52990723e-02   4.86145020e-02   2.35717773e-01   1.27563477e-01]]
After layer decoder_rnn_enc2dec_inittanh_1_output (1, 512) <class 'numpy.float16'> [[ -7.60498047e-02  -1.46331787e-02   6.89086914e-02  -9.16137695e-02
    3.04931641e-01   7.59277344e-02  -5.55419922e-02   4.83703613e-02
    8.22753906e-02   1.43798828e-01   1.61621094e-01  -4.94995117e-02
   -1.51489258e-01   5.17883301e-02  -9.68017578e-02  -6.44531250e-02
   -1.79321289e-01   2.03979492e-01   5.22949219e-01  -8.37402344e-02
    4.98352051e-02   1.48925781e-01   6.46972656e-02   3.58886719e-02
   -3.97949219e-02  -4.57458496e-02   7.29980469e-02   1.86523438e-01
   -1.02600098e-01  -4.59899902e-02  -4.00695801e-02   9.01489258e-02
    1.94335938e-01  -4.68444824e-02   3.50830078e-01   3.24218750e-01
   -1.98852539e-01  -3.84826660e-02   3.50585938e-01  -3.57666016e-01
    2.33398438e-01   2.28118896e-02  -2.94921875e-01  -7.76977539e-02
   -1.75415039e-01   1.55883789e-01  -2.35473633e-01  -5.46264648e-02
   -3.56445312e-02  -2.11181641e-02   4.19616699e-02  -8.42285156e-02
   -4.12597656e-01  -1.48193359e-01   1.20666504e-01  -9.45434570e-02
   -2.09716797e-01   1.75537109e-01  -7.98950195e-02   2.27050781e-02
   -7.02514648e-02  -2.35176086e-03   7.27539062e-02   1.06384277e-01
    4.49371338e-03   8.72802734e-03  -9.05609131e-03   4.82482910e-02
   -2.36816406e-01   1.43920898e-01  -5.15136719e-02   5.16967773e-02
   -7.89184570e-02  -7.69653320e-02   5.36499023e-02   1.43051147e-02
    2.55859375e-01  -6.21414185e-03  -1.15722656e-01  -9.06372070e-02
   -5.38330078e-02  -8.63037109e-02  -1.24572754e-01  -9.42382812e-02
   -1.75170898e-02   1.14059448e-02  -2.08129883e-01  -2.69042969e-01
   -1.21032715e-01   3.55712891e-01  -1.73217773e-01   1.54541016e-01
    1.18530273e-01   1.59057617e-01   2.06909180e-01  -1.23596191e-01
   -1.37451172e-01  -3.39599609e-01  -5.76171875e-02  -1.63330078e-01
   -1.97875977e-01  -1.35131836e-01  -5.41503906e-01   1.39282227e-01
    1.93847656e-01  -6.30493164e-02  -1.52221680e-01  -2.30834961e-01
   -4.28161621e-02   6.12487793e-02   1.65161133e-01  -3.40332031e-01
    5.24414062e-01   5.81359863e-03   7.59887695e-02   1.70166016e-01
   -1.57958984e-01  -4.59594727e-02  -2.86376953e-01   1.44409180e-01
   -4.04968262e-02  -6.70166016e-02   1.95068359e-01   1.02172852e-01
    1.89453125e-01   5.51147461e-02   5.59387207e-02   1.80419922e-01
   -3.22265625e-01  -1.08032227e-02  -2.50854492e-02  -1.93481445e-02
   -3.99169922e-02   1.17126465e-01   1.35375977e-01   1.63574219e-01
   -1.46850586e-01  -4.07714844e-01  -4.33044434e-02  -3.39660645e-02
   -2.13378906e-01   2.71240234e-01  -3.39111328e-01  -8.50219727e-02
    2.42797852e-01  -1.26464844e-01   1.53198242e-02   1.59423828e-01
    2.44018555e-01   1.24328613e-01   2.32543945e-01  -1.93481445e-01
    1.72851562e-01   6.72607422e-02  -1.93481445e-01   1.10717773e-01
    6.39038086e-02  -2.47680664e-01  -4.03137207e-02  -6.26220703e-02
    9.50927734e-02   2.73437500e-01  -7.68432617e-02  -8.06274414e-02
   -5.64941406e-01   7.79418945e-02   1.28662109e-01  -1.02111816e-01
   -1.17553711e-01  -7.23266602e-02  -2.55126953e-01   1.62841797e-01
    1.03149414e-01   9.36889648e-02  -5.66101074e-02  -1.81121826e-02
   -1.87744141e-01  -9.64965820e-02   1.71875000e-01  -3.03955078e-01
    1.20666504e-01   4.39758301e-02  -1.63208008e-01  -8.11157227e-02
    2.90527344e-01   2.02880859e-01  -1.33911133e-01   1.04064941e-01
   -8.66699219e-02   1.54113770e-02   3.17993164e-02  -1.67480469e-01
    8.69750977e-02  -1.39770508e-01   1.66015625e-01  -2.18383789e-01
   -9.99755859e-02  -2.25830078e-01   7.92236328e-02   7.72094727e-02
    3.83377075e-03  -2.96142578e-01   6.11114502e-03  -1.95922852e-01
    1.57714844e-01  -2.98339844e-01   1.25732422e-01  -2.15332031e-01
    1.47583008e-01  -1.01074219e-01   4.62951660e-02  -8.19091797e-02
   -1.75323486e-02  -4.91333008e-02  -1.15600586e-01  -1.14379883e-01
    2.50000000e-01  -4.65576172e-01   7.85522461e-02   1.55273438e-01
    2.10937500e-01  -9.94262695e-02   1.69433594e-01  -6.70166016e-02
    4.04541016e-01  -3.02490234e-01   2.82135010e-02   1.69189453e-01
   -6.71997070e-02  -2.16186523e-01   1.77490234e-01  -5.31738281e-01
    7.17773438e-02   3.29101562e-01   2.86102295e-02  -6.51855469e-02
    1.73950195e-02   1.25656128e-02   1.01684570e-01  -8.62884521e-03
    2.78808594e-01  -5.07202148e-02  -2.76855469e-01  -2.09838867e-01
    1.04125977e-01   1.60644531e-01  -8.53881836e-02   1.31347656e-01
    6.17980957e-02  -1.39160156e-01  -2.23266602e-01   2.12890625e-01
    7.39746094e-02  -4.51965332e-02  -1.33422852e-01   2.97363281e-01
   -3.51318359e-01  -4.73327637e-02  -4.29382324e-02  -2.63916016e-01
    6.70166016e-02   3.48632812e-01   1.62353516e-01   9.19799805e-02
    4.01306152e-03  -1.27319336e-01   3.49731445e-02   1.76147461e-01
   -4.99877930e-02  -1.44042969e-01   2.31323242e-01   1.28936768e-02
   -2.89794922e-01  -5.42297363e-02  -2.07763672e-01  -9.13085938e-02
    6.41632080e-03  -9.69238281e-02  -7.85827637e-03   2.54150391e-01
    1.91162109e-01  -1.89697266e-01   3.35998535e-02  -2.59033203e-01
   -4.65698242e-02   1.99462891e-01  -1.62719727e-01  -3.91540527e-02
   -1.01562500e-01   2.92480469e-01   1.70166016e-01   3.32519531e-01
   -2.02514648e-01  -6.55517578e-02   1.81152344e-01  -1.57836914e-01
    1.12731934e-01   2.56347656e-02  -5.97229004e-02  -1.52221680e-01
   -2.42431641e-01   7.55004883e-02  -1.57470703e-01  -2.78320312e-01
   -5.98144531e-02  -1.82739258e-01   2.78930664e-02   1.87835693e-02
    3.33251953e-02   8.78906250e-02  -1.14318848e-01   1.16760254e-01
   -1.01928711e-01  -4.83093262e-02   4.55017090e-02   1.33422852e-01
   -6.02722168e-02  -7.74536133e-02   1.03820801e-01  -7.19604492e-02
    1.66992188e-01   2.61230469e-01   1.59057617e-01  -2.97088623e-02
   -1.90673828e-01  -3.68652344e-01   3.01269531e-01   3.07861328e-01
   -2.26684570e-01  -7.06787109e-02   2.17407227e-01  -2.73895264e-02
    2.97546387e-04  -1.52587891e-01  -3.51257324e-02  -1.02416992e-01
   -5.00488281e-02  -1.03149414e-01  -1.05651855e-01  -2.88330078e-01
   -8.83178711e-02  -1.90795898e-01  -3.02886963e-03   3.74755859e-01
   -2.54150391e-01  -6.46362305e-02   9.87548828e-02   4.61425781e-02
    1.39038086e-01   5.86547852e-02  -2.75878906e-01  -7.19604492e-02
   -5.64575195e-02   3.33251953e-02   5.62500000e-01   7.43408203e-02
    7.12890625e-02  -6.06384277e-02   2.34497070e-01   1.52099609e-01
    3.11523438e-01  -7.87353516e-02  -1.76269531e-01  -6.92138672e-02
   -2.09960938e-02  -1.18591309e-01   2.44628906e-01  -9.33227539e-02
    4.37988281e-01   9.78393555e-02  -1.03027344e-01   3.36914062e-02
    6.23474121e-02   2.05444336e-01  -1.08337402e-01  -1.70043945e-01
   -4.03320312e-01  -2.32177734e-01   2.82592773e-02  -9.27734375e-02
    1.23046875e-01   6.11572266e-02  -1.24816895e-01  -2.46093750e-01
   -3.00750732e-02   2.97607422e-01  -2.96142578e-01  -6.27441406e-02
   -1.09863281e-01  -8.14208984e-02  -3.22998047e-01   1.30249023e-01
    1.16333008e-01   5.43212891e-02  -4.01000977e-02  -2.59033203e-01
   -5.80749512e-02   2.12402344e-01  -2.21435547e-01  -1.26220703e-01
    2.67333984e-01  -1.57958984e-01  -2.20642090e-02  -1.35040283e-02
   -1.19628906e-01   1.23474121e-01  -1.98974609e-01  -3.95507812e-01
    4.86145020e-02   1.18164062e-01  -1.09375000e-01  -1.28417969e-01
    1.69677734e-01   9.75952148e-02   1.26220703e-01   1.44775391e-01
   -6.46362305e-02  -2.27539062e-01   1.78100586e-01   7.22656250e-02
   -3.85284424e-04   2.15209961e-01   1.19445801e-01  -8.62426758e-02
    9.21630859e-02   2.47436523e-01   1.90185547e-01   2.80029297e-01
    7.69653320e-02   1.37084961e-01   2.65136719e-01  -1.44409180e-01
   -1.33422852e-01  -1.33514404e-03   2.73681641e-01   2.26287842e-02
    2.12524414e-01   3.77273560e-03  -2.52685547e-01   1.03881836e-01
   -1.54174805e-01  -9.26513672e-02   3.82385254e-02  -1.96289062e-01
   -3.15429688e-01  -4.75769043e-02  -2.00561523e-01   1.91162109e-01
   -9.37500000e-02  -2.16552734e-01  -1.81640625e-01   3.26538086e-02
    2.68249512e-02   9.59777832e-03  -2.08984375e-01   3.49235535e-03
   -1.04675293e-01   8.51440430e-02   1.13220215e-01  -1.12792969e-01
    1.39038086e-01   1.72241211e-01  -1.04614258e-01   1.55273438e-01
    1.19567871e-01  -3.39508057e-03  -5.08728027e-02   5.93872070e-02
    5.79223633e-02  -5.42297363e-02   1.13281250e-01  -2.58300781e-01
    4.13330078e-01   4.89746094e-01   3.49121094e-02  -8.28857422e-02
    7.92846680e-02  -2.10571289e-02  -4.34265137e-02   1.62841797e-01
   -7.73620605e-03   3.42285156e-01   1.43554688e-01   1.15295410e-01
    2.22167969e-01  -5.17578125e-02  -7.33032227e-02  -2.32543945e-01
   -5.13458252e-03  -5.59082031e-02   1.50268555e-01   5.01403809e-02
   -6.25610352e-02   8.39233398e-02   6.00585938e-02  -5.02319336e-02
    1.72363281e-01  -7.04956055e-02  -7.51342773e-02  -2.10571289e-03
    2.97119141e-01   3.15551758e-02  -1.89575195e-01   3.71398926e-02
   -1.00036621e-01   8.61206055e-02   2.60253906e-01  -2.00317383e-01
   -2.52990723e-02   4.85839844e-02   2.31445312e-01   1.26831055e-01]]
After layer target_embed_embed_0 (20, 256) <class 'numpy.float16'> [[ 0.0609436  -0.04937744 -0.03683472 ...,  0.06219482 -0.08508301
  -0.07885742]
 [ 0.0609436  -0.04937744 -0.03683472 ...,  0.06219482 -0.08508301
  -0.07885742]
 [ 0.0609436  -0.04937744 -0.03683472 ...,  0.06219482 -0.08508301
  -0.07885742]
 ...,
 [ 0.0609436  -0.04937744 -0.03683472 ...,  0.06219482 -0.08508301
  -0.07885742]
 [ 0.0609436  -0.04937744 -0.03683472 ...,  0.06219482 -0.08508301
  -0.07885742]
 [ 0.0609436  -0.04937744 -0.03683472 ...,  0.06219482 -0.08508301
  -0.07885742]]
After layer decoder_rnn_concat_target_context_t0_output (20, 768) <class 'numpy.float16'> [[ 0.0609436  -0.04937744 -0.03683472 ...,  0.          0.          0.        ]
 [ 0.0609436  -0.04937744 -0.03683472 ...,  0.          0.          0.        ]
 [ 0.0609436  -0.04937744 -0.03683472 ...,  0.          0.          0.        ]
 ...,
 [ 0.0609436  -0.04937744 -0.03683472 ...,  0.          0.          0.        ]
 [ 0.0609436  -0.04937744 -0.03683472 ...,  0.          0.          0.        ]
 [ 0.0609436  -0.04937744 -0.03683472 ...,  0.          0.          0.        ]]
After layer decoder_rnn_l0_t0_i2h_output (20, 2048) <class 'numpy.float16'> [[ 0.92041016 -0.15795898  0.11663818 ...,  0.56445312  0.84423828
   0.27294922]
 [ 0.92041016 -0.15795898  0.11663818 ...,  0.56445312  0.84423828
   0.27294922]
 [ 0.92041016 -0.15795898  0.11663818 ...,  0.56445312  0.84423828
   0.27294922]
 ...,
 [ 0.92041016 -0.15795898  0.11663818 ...,  0.56445312  0.84423828
   0.27294922]
 [ 0.92041016 -0.15795898  0.11663818 ...,  0.56445312  0.84423828
   0.27294922]
 [ 0.92041016 -0.15795898  0.11663818 ...,  0.56445312  0.84423828
   0.27294922]]
After layer decoder_rnn_l0_t0_h2h_output (20, 2048) <class 'numpy.float16'> [[ 0.53710938 -0.54052734  0.07330322 ...,  0.2878418   0.30883789
   0.58642578]
 [ 0.53710938 -0.54052734  0.07330322 ...,  0.2878418   0.30883789
   0.58642578]
 [ 0.53710938 -0.54052734  0.07330322 ...,  0.2878418   0.30883789
   0.58642578]
 ...,
 [ 0.53710938 -0.54052734  0.07330322 ...,  0.2878418   0.30883789
   0.58642578]
 [ 0.53710938 -0.54052734  0.07330322 ...,  0.2878418   0.30883789
   0.58642578]
 [ 0.53710938 -0.54052734  0.07330322 ...,  0.2878418   0.30883789
   0.58642578]]
After layer _plus1046_0 (20, 2048) <class 'numpy.float16'> [[ 1.45703125 -0.69824219  0.18994141 ...,  0.85253906  1.15332031
   0.859375  ]
 [ 1.45703125 -0.69824219  0.18994141 ...,  0.85253906  1.15332031
   0.859375  ]
 [ 1.45703125 -0.69824219  0.18994141 ...,  0.85253906  1.15332031
   0.859375  ]
 ...,
 [ 1.45703125 -0.69824219  0.18994141 ...,  0.85253906  1.15332031
   0.859375  ]
 [ 1.45703125 -0.69824219  0.18994141 ...,  0.85253906  1.15332031
   0.859375  ]
 [ 1.45703125 -0.69824219  0.18994141 ...,  0.85253906  1.15332031
   0.859375  ]]
After layer decoder_rnn_l0_t0_slice_output0 (20, 512) <class 'numpy.float16'> [[ 1.45703125 -0.69824219  0.18994141 ..., -0.0703125   1.54296875
   0.29125977]
 [ 1.45703125 -0.69824219  0.18994141 ..., -0.0703125   1.54296875
   0.29125977]
 [ 1.45703125 -0.69824219  0.18994141 ..., -0.0703125   1.54296875
   0.29125977]
 ...,
 [ 1.45703125 -0.69824219  0.18994141 ..., -0.0703125   1.54296875
   0.29125977]
 [ 1.45703125 -0.69824219  0.18994141 ..., -0.0703125   1.54296875
   0.29125977]
 [ 1.45703125 -0.69824219  0.18994141 ..., -0.0703125   1.54296875
   0.29125977]]
After layer decoder_rnn_l0_t0_slice_output1 (20, 512) <class 'numpy.float16'> [[ 1.55371094 -0.91992188  0.62304688 ...,  1.09765625  0.03173828
   1.09765625]
 [ 1.55371094 -0.91992188  0.62304688 ...,  1.09765625  0.03173828
   1.09765625]
 [ 1.55371094 -0.91992188  0.62304688 ...,  1.09765625  0.03173828
   1.09765625]
 ...,
 [ 1.55371094 -0.91992188  0.62304688 ...,  1.09765625  0.03173828
   1.09765625]
 [ 1.55371094 -0.91992188  0.62304688 ...,  1.09765625  0.03173828
   1.09765625]
 [ 1.55371094 -0.91992188  0.62304688 ...,  1.09765625  0.03173828
   1.09765625]]
After layer decoder_rnn_l0_t0_slice_output2 (20, 512) <class 'numpy.float16'> [[-1.69335938 -0.45288086  0.32275391 ...,  1.50195312  1.33203125
   0.65429688]
 [-1.69335938 -0.45288086  0.32275391 ...,  1.50195312  1.33203125
   0.65429688]
 [-1.69335938 -0.45288086  0.32275391 ...,  1.50195312  1.33203125
   0.65429688]
 ...,
 [-1.69335938 -0.45288086  0.32275391 ...,  1.50195312  1.33203125
   0.65429688]
 [-1.69335938 -0.45288086  0.32275391 ...,  1.50195312  1.33203125
   0.65429688]
 [-1.69335938 -0.45288086  0.32275391 ...,  1.50195312  1.33203125
   0.65429688]]
After layer decoder_rnn_l0_t0_slice_output3 (20, 512) <class 'numpy.float16'> [[ 2.3515625  -1.16992188 -0.07141113 ...,  0.85253906  1.15332031
   0.859375  ]
 [ 2.3515625  -1.16992188 -0.07141113 ...,  0.85253906  1.15332031
   0.859375  ]
 [ 2.3515625  -1.16992188 -0.07141113 ...,  0.85253906  1.15332031
   0.859375  ]
 ...,
 [ 2.3515625  -1.16992188 -0.07141113 ...,  0.85253906  1.15332031
   0.859375  ]
 [ 2.3515625  -1.16992188 -0.07141113 ...,  0.85253906  1.15332031
   0.859375  ]
 [ 2.3515625  -1.16992188 -0.07141113 ...,  0.85253906  1.15332031
   0.859375  ]]
After layer decoder_rnn_l0_t0_o_output (20, 512) <class 'numpy.float16'> [[ 0.91308594  0.23681641  0.48217773 ...,  0.70117188  0.76025391
   0.70263672]
 [ 0.91308594  0.23681641  0.48217773 ...,  0.70117188  0.76025391
   0.70263672]
 [ 0.91308594  0.23681641  0.48217773 ...,  0.70117188  0.76025391
   0.70263672]
 ...,
 [ 0.91308594  0.23681641  0.48217773 ...,  0.70117188  0.76025391
   0.70263672]
 [ 0.91308594  0.23681641  0.48217773 ...,  0.70117188  0.76025391
   0.70263672]
 [ 0.91308594  0.23681641  0.48217773 ...,  0.70117188  0.76025391
   0.70263672]]
After layer decoder_rnn_l0_t0_f_output (20, 512) <class 'numpy.float16'> [[ 0.82568359  0.28491211  0.65087891 ...,  0.75        0.5078125   0.75      ]
 [ 0.82568359  0.28491211  0.65087891 ...,  0.75        0.5078125   0.75      ]
 [ 0.82568359  0.28491211  0.65087891 ...,  0.75        0.5078125   0.75      ]
 ...,
 [ 0.82568359  0.28491211  0.65087891 ...,  0.75        0.5078125   0.75      ]
 [ 0.82568359  0.28491211  0.65087891 ...,  0.75        0.5078125   0.75      ]
 [ 0.82568359  0.28491211  0.65087891 ...,  0.75        0.5078125   0.75      ]]
After layer _mul2092_0 (20, 512) <class 'numpy.float16'> [[-0.06280518 -0.00416946  0.04486084 ...,  0.03643799  0.11755371
   0.09509277]
 [-0.06280518 -0.00416946  0.04486084 ...,  0.03643799  0.11755371
   0.09509277]
 [-0.06280518 -0.00416946  0.04486084 ...,  0.03643799  0.11755371
   0.09509277]
 ...,
 [-0.06280518 -0.00416946  0.04486084 ...,  0.03643799  0.11755371
   0.09509277]
 [-0.06280518 -0.00416946  0.04486084 ...,  0.03643799  0.11755371
   0.09509277]
 [-0.06280518 -0.00416946  0.04486084 ...,  0.03643799  0.11755371
   0.09509277]]
After layer decoder_rnn_l0_t0_i_output (20, 512) <class 'numpy.float16'> [[ 0.81103516  0.33227539  0.54736328 ...,  0.48242188  0.82373047
   0.57226562]
 [ 0.81103516  0.33227539  0.54736328 ...,  0.48242188  0.82373047
   0.57226562]
 [ 0.81103516  0.33227539  0.54736328 ...,  0.48242188  0.82373047
   0.57226562]
 ...,
 [ 0.81103516  0.33227539  0.54736328 ...,  0.48242188  0.82373047
   0.57226562]
 [ 0.81103516  0.33227539  0.54736328 ...,  0.48242188  0.82373047
   0.57226562]
 [ 0.81103516  0.33227539  0.54736328 ...,  0.48242188  0.82373047
   0.57226562]]
After layer decoder_rnn_l0_t0_c_output (20, 512) <class 'numpy.float16'> [[-0.93457031 -0.42431641  0.31201172 ...,  0.90527344  0.86962891
   0.57470703]
 [-0.93457031 -0.42431641  0.31201172 ...,  0.90527344  0.86962891
   0.57470703]
 [-0.93457031 -0.42431641  0.31201172 ...,  0.90527344  0.86962891
   0.57470703]
 ...,
 [-0.93457031 -0.42431641  0.31201172 ...,  0.90527344  0.86962891
   0.57470703]
 [-0.93457031 -0.42431641  0.31201172 ...,  0.90527344  0.86962891
   0.57470703]
 [-0.93457031 -0.42431641  0.31201172 ...,  0.90527344  0.86962891
   0.57470703]]
After layer _mul2093_0 (20, 512) <class 'numpy.float16'> [[-0.7578125  -0.14099121  0.17077637 ...,  0.43676758  0.71630859
   0.32885742]
 [-0.7578125  -0.14099121  0.17077637 ...,  0.43676758  0.71630859
   0.32885742]
 [-0.7578125  -0.14099121  0.17077637 ...,  0.43676758  0.71630859
   0.32885742]
 ...,
 [-0.7578125  -0.14099121  0.17077637 ...,  0.43676758  0.71630859
   0.32885742]
 [-0.7578125  -0.14099121  0.17077637 ...,  0.43676758  0.71630859
   0.32885742]
 [-0.7578125  -0.14099121  0.17077637 ...,  0.43676758  0.71630859
   0.32885742]]
After layer decoder_rnn_l0_t0_state_0 (20, 512) <class 'numpy.float16'> [[-0.82080078 -0.1451416   0.21557617 ...,  0.47314453  0.83398438
   0.42382812]
 [-0.82080078 -0.1451416   0.21557617 ...,  0.47314453  0.83398438
   0.42382812]
 [-0.82080078 -0.1451416   0.21557617 ...,  0.47314453  0.83398438
   0.42382812]
 ...,
 [-0.82080078 -0.1451416   0.21557617 ...,  0.47314453  0.83398438
   0.42382812]
 [-0.82080078 -0.1451416   0.21557617 ...,  0.47314453  0.83398438
   0.42382812]
 [-0.82080078 -0.1451416   0.21557617 ...,  0.47314453  0.83398438
   0.42382812]]
After layer activation1046_output (20, 512) <class 'numpy.float16'> [[-0.67529297 -0.14416504  0.21228027 ...,  0.44067383  0.68261719
   0.40014648]
 [-0.67529297 -0.14416504  0.21228027 ...,  0.44067383  0.68261719
   0.40014648]
 [-0.67529297 -0.14416504  0.21228027 ...,  0.44067383  0.68261719
   0.40014648]
 ...,
 [-0.67529297 -0.14416504  0.21228027 ...,  0.44067383  0.68261719
   0.40014648]
 [-0.67529297 -0.14416504  0.21228027 ...,  0.44067383  0.68261719
   0.40014648]
 [-0.67529297 -0.14416504  0.21228027 ...,  0.44067383  0.68261719
   0.40014648]]
After layer decoder_rnn_l0_t0_out_0 (20, 512) <class 'numpy.float16'> [[-0.61669922 -0.03414917  0.10235596 ...,  0.30908203  0.51904297  0.28125   ]
 [-0.61669922 -0.03414917  0.10235596 ...,  0.30908203  0.51904297  0.28125   ]
 [-0.61669922 -0.03414917  0.10235596 ...,  0.30908203  0.51904297  0.28125   ]
 ...,
 [-0.61669922 -0.03414917  0.10235596 ...,  0.30908203  0.51904297  0.28125   ]
 [-0.61669922 -0.03414917  0.10235596 ...,  0.30908203  0.51904297  0.28125   ]
 [-0.61669922 -0.03414917  0.10235596 ...,  0.30908203  0.51904297  0.28125   ]]
After layer expand_dims1055_0 (20, 512, 1) <class 'numpy.float16'> [[[-0.61669922]
  [-0.03414917]
  [ 0.10235596]
  ...,
  [ 0.30908203]
  [ 0.51904297]
  [ 0.28125   ]]

 [[-0.61669922]
  [-0.03414917]
  [ 0.10235596]
  ...,
  [ 0.30908203]
  [ 0.51904297]
  [ 0.28125   ]]

 [[-0.61669922]
  [-0.03414917]
  [ 0.10235596]
  ...,
  [ 0.30908203]
  [ 0.51904297]
  [ 0.28125   ]]

 ...,
 [[-0.61669922]
  [-0.03414917]
  [ 0.10235596]
  ...,
  [ 0.30908203]
  [ 0.51904297]
  [ 0.28125   ]]

 [[-0.61669922]
  [-0.03414917]
  [ 0.10235596]
  ...,
  [ 0.30908203]
  [ 0.51904297]
  [ 0.28125   ]]

 [[-0.61669922]
  [-0.03414917]
  [ 0.10235596]
  ...,
  [ 0.30908203]
  [ 0.51904297]
  [ 0.28125   ]]]
After layer att_batch_dot_0 (20, 10, 1) <class 'numpy.float16'> [[[  0.234375  ]
  [  0.85693359]
  [  2.15039062]
  [  4.4921875 ]
  [  7.44921875]
  [  9.984375  ]
  [ 11.5703125 ]
  [ 12.40625   ]
  [ 12.8203125 ]
  [ 12.9375    ]]

 [[  0.234375  ]
  [  0.85693359]
  [  2.15039062]
  [  4.4921875 ]
  [  7.44921875]
  [  9.984375  ]
  [ 11.5703125 ]
  [ 12.40625   ]
  [ 12.8203125 ]
  [ 12.9375    ]]

 [[  0.234375  ]
  [  0.85693359]
  [  2.15039062]
  [  4.4921875 ]
  [  7.44921875]
  [  9.984375  ]
  [ 11.5703125 ]
  [ 12.40625   ]
  [ 12.8203125 ]
  [ 12.9375    ]]

 [[  0.234375  ]
  [  0.85693359]
  [  2.15039062]
  [  4.4921875 ]
  [  7.44921875]
  [  9.984375  ]
  [ 11.5703125 ]
  [ 12.40625   ]
  [ 12.8203125 ]
  [ 12.9375    ]]

 [[  0.234375  ]
  [  0.85693359]
  [  2.15039062]
  [  4.4921875 ]
  [  7.44921875]
  [  9.984375  ]
  [ 11.5703125 ]
  [ 12.40625   ]
  [ 12.8203125 ]
  [ 12.9375    ]]

 [[  0.234375  ]
  [  0.85693359]
  [  2.15039062]
  [  4.4921875 ]
  [  7.44921875]
  [  9.984375  ]
  [ 11.5703125 ]
  [ 12.40625   ]
  [ 12.8203125 ]
  [ 12.9375    ]]

 [[  0.234375  ]
  [  0.85693359]
  [  2.15039062]
  [  4.4921875 ]
  [  7.44921875]
  [  9.984375  ]
  [ 11.5703125 ]
  [ 12.40625   ]
  [ 12.8203125 ]
  [ 12.9375    ]]

 [[  0.234375  ]
  [  0.85693359]
  [  2.15039062]
  [  4.4921875 ]
  [  7.44921875]
  [  9.984375  ]
  [ 11.5703125 ]
  [ 12.40625   ]
  [ 12.8203125 ]
  [ 12.9375    ]]

 [[  0.234375  ]
  [  0.85693359]
  [  2.15039062]
  [  4.4921875 ]
  [  7.44921875]
  [  9.984375  ]
  [ 11.5703125 ]
  [ 12.40625   ]
  [ 12.8203125 ]
  [ 12.9375    ]]

 [[  0.234375  ]
  [  0.85693359]
  [  2.15039062]
  [  4.4921875 ]
  [  7.44921875]
  [  9.984375  ]
  [ 11.5703125 ]
  [ 12.40625   ]
  [ 12.8203125 ]
  [ 12.9375    ]]

 [[  0.234375  ]
  [  0.85693359]
  [  2.15039062]
  [  4.4921875 ]
  [  7.44921875]
  [  9.984375  ]
  [ 11.5703125 ]
  [ 12.40625   ]
  [ 12.8203125 ]
  [ 12.9375    ]]

 [[  0.234375  ]
  [  0.85693359]
  [  2.15039062]
  [  4.4921875 ]
  [  7.44921875]
  [  9.984375  ]
  [ 11.5703125 ]
  [ 12.40625   ]
  [ 12.8203125 ]
  [ 12.9375    ]]

 [[  0.234375  ]
  [  0.85693359]
  [  2.15039062]
  [  4.4921875 ]
  [  7.44921875]
  [  9.984375  ]
  [ 11.5703125 ]
  [ 12.40625   ]
  [ 12.8203125 ]
  [ 12.9375    ]]

 [[  0.234375  ]
  [  0.85693359]
  [  2.15039062]
  [  4.4921875 ]
  [  7.44921875]
  [  9.984375  ]
  [ 11.5703125 ]
  [ 12.40625   ]
  [ 12.8203125 ]
  [ 12.9375    ]]

 [[  0.234375  ]
  [  0.85693359]
  [  2.15039062]
  [  4.4921875 ]
  [  7.44921875]
  [  9.984375  ]
  [ 11.5703125 ]
  [ 12.40625   ]
  [ 12.8203125 ]
  [ 12.9375    ]]

 [[  0.234375  ]
  [  0.85693359]
  [  2.15039062]
  [  4.4921875 ]
  [  7.44921875]
  [  9.984375  ]
  [ 11.5703125 ]
  [ 12.40625   ]
  [ 12.8203125 ]
  [ 12.9375    ]]

 [[  0.234375  ]
  [  0.85693359]
  [  2.15039062]
  [  4.4921875 ]
  [  7.44921875]
  [  9.984375  ]
  [ 11.5703125 ]
  [ 12.40625   ]
  [ 12.8203125 ]
  [ 12.9375    ]]

 [[  0.234375  ]
  [  0.85693359]
  [  2.15039062]
  [  4.4921875 ]
  [  7.44921875]
  [  9.984375  ]
  [ 11.5703125 ]
  [ 12.40625   ]
  [ 12.8203125 ]
  [ 12.9375    ]]

 [[  0.234375  ]
  [  0.85693359]
  [  2.15039062]
  [  4.4921875 ]
  [  7.44921875]
  [  9.984375  ]
  [ 11.5703125 ]
  [ 12.40625   ]
  [ 12.8203125 ]
  [ 12.9375    ]]

 [[  0.234375  ]
  [  0.85693359]
  [  2.15039062]
  [  4.4921875 ]
  [  7.44921875]
  [  9.984375  ]
  [ 11.5703125 ]
  [ 12.40625   ]
  [ 12.8203125 ]
  [ 12.9375    ]]]
After layer swapaxes13_output (10, 20, 1) <class 'numpy.float16'> [[[  0.234375  ]
  [  0.234375  ]
  [  0.234375  ]
  [  0.234375  ]
  [  0.234375  ]
  [  0.234375  ]
  [  0.234375  ]
  [  0.234375  ]
  [  0.234375  ]
  [  0.234375  ]
  [  0.234375  ]
  [  0.234375  ]
  [  0.234375  ]
  [  0.234375  ]
  [  0.234375  ]
  [  0.234375  ]
  [  0.234375  ]
  [  0.234375  ]
  [  0.234375  ]
  [  0.234375  ]]

 [[  0.85693359]
  [  0.85693359]
  [  0.85693359]
  [  0.85693359]
  [  0.85693359]
  [  0.85693359]
  [  0.85693359]
  [  0.85693359]
  [  0.85693359]
  [  0.85693359]
  [  0.85693359]
  [  0.85693359]
  [  0.85693359]
  [  0.85693359]
  [  0.85693359]
  [  0.85693359]
  [  0.85693359]
  [  0.85693359]
  [  0.85693359]
  [  0.85693359]]

 [[  2.15039062]
  [  2.15039062]
  [  2.15039062]
  [  2.15039062]
  [  2.15039062]
  [  2.15039062]
  [  2.15039062]
  [  2.15039062]
  [  2.15039062]
  [  2.15039062]
  [  2.15039062]
  [  2.15039062]
  [  2.15039062]
  [  2.15039062]
  [  2.15039062]
  [  2.15039062]
  [  2.15039062]
  [  2.15039062]
  [  2.15039062]
  [  2.15039062]]

 [[  4.4921875 ]
  [  4.4921875 ]
  [  4.4921875 ]
  [  4.4921875 ]
  [  4.4921875 ]
  [  4.4921875 ]
  [  4.4921875 ]
  [  4.4921875 ]
  [  4.4921875 ]
  [  4.4921875 ]
  [  4.4921875 ]
  [  4.4921875 ]
  [  4.4921875 ]
  [  4.4921875 ]
  [  4.4921875 ]
  [  4.4921875 ]
  [  4.4921875 ]
  [  4.4921875 ]
  [  4.4921875 ]
  [  4.4921875 ]]

 [[  7.44921875]
  [  7.44921875]
  [  7.44921875]
  [  7.44921875]
  [  7.44921875]
  [  7.44921875]
  [  7.44921875]
  [  7.44921875]
  [  7.44921875]
  [  7.44921875]
  [  7.44921875]
  [  7.44921875]
  [  7.44921875]
  [  7.44921875]
  [  7.44921875]
  [  7.44921875]
  [  7.44921875]
  [  7.44921875]
  [  7.44921875]
  [  7.44921875]]

 [[  9.984375  ]
  [  9.984375  ]
  [  9.984375  ]
  [  9.984375  ]
  [  9.984375  ]
  [  9.984375  ]
  [  9.984375  ]
  [  9.984375  ]
  [  9.984375  ]
  [  9.984375  ]
  [  9.984375  ]
  [  9.984375  ]
  [  9.984375  ]
  [  9.984375  ]
  [  9.984375  ]
  [  9.984375  ]
  [  9.984375  ]
  [  9.984375  ]
  [  9.984375  ]
  [  9.984375  ]]

 [[ 11.5703125 ]
  [ 11.5703125 ]
  [ 11.5703125 ]
  [ 11.5703125 ]
  [ 11.5703125 ]
  [ 11.5703125 ]
  [ 11.5703125 ]
  [ 11.5703125 ]
  [ 11.5703125 ]
  [ 11.5703125 ]
  [ 11.5703125 ]
  [ 11.5703125 ]
  [ 11.5703125 ]
  [ 11.5703125 ]
  [ 11.5703125 ]
  [ 11.5703125 ]
  [ 11.5703125 ]
  [ 11.5703125 ]
  [ 11.5703125 ]
  [ 11.5703125 ]]

 [[ 12.40625   ]
  [ 12.40625   ]
  [ 12.40625   ]
  [ 12.40625   ]
  [ 12.40625   ]
  [ 12.40625   ]
  [ 12.40625   ]
  [ 12.40625   ]
  [ 12.40625   ]
  [ 12.40625   ]
  [ 12.40625   ]
  [ 12.40625   ]
  [ 12.40625   ]
  [ 12.40625   ]
  [ 12.40625   ]
  [ 12.40625   ]
  [ 12.40625   ]
  [ 12.40625   ]
  [ 12.40625   ]
  [ 12.40625   ]]

 [[ 12.8203125 ]
  [ 12.8203125 ]
  [ 12.8203125 ]
  [ 12.8203125 ]
  [ 12.8203125 ]
  [ 12.8203125 ]
  [ 12.8203125 ]
  [ 12.8203125 ]
  [ 12.8203125 ]
  [ 12.8203125 ]
  [ 12.8203125 ]
  [ 12.8203125 ]
  [ 12.8203125 ]
  [ 12.8203125 ]
  [ 12.8203125 ]
  [ 12.8203125 ]
  [ 12.8203125 ]
  [ 12.8203125 ]
  [ 12.8203125 ]
  [ 12.8203125 ]]

 [[ 12.9375    ]
  [ 12.9375    ]
  [ 12.9375    ]
  [ 12.9375    ]
  [ 12.9375    ]
  [ 12.9375    ]
  [ 12.9375    ]
  [ 12.9375    ]
  [ 12.9375    ]
  [ 12.9375    ]
  [ 12.9375    ]
  [ 12.9375    ]
  [ 12.9375    ]
  [ 12.9375    ]
  [ 12.9375    ]
  [ 12.9375    ]
  [ 12.9375    ]
  [ 12.9375    ]
  [ 12.9375    ]
  [ 12.9375    ]]]
After layer sequencemask2_output (10, 20, 1) <class 'numpy.float16'> [[[  2.34375000e-01]
  [  2.34375000e-01]
  [  2.34375000e-01]
  [  2.34375000e-01]
  [  2.34375000e-01]
  [  2.34375000e-01]
  [  2.34375000e-01]
  [  2.34375000e-01]
  [  2.34375000e-01]
  [  2.34375000e-01]
  [  2.34375000e-01]
  [  2.34375000e-01]
  [  2.34375000e-01]
  [  2.34375000e-01]
  [  2.34375000e-01]
  [  2.34375000e-01]
  [  2.34375000e-01]
  [  2.34375000e-01]
  [  2.34375000e-01]
  [  2.34375000e-01]]

 [[  8.56933594e-01]
  [  8.56933594e-01]
  [  8.56933594e-01]
  [  8.56933594e-01]
  [  8.56933594e-01]
  [  8.56933594e-01]
  [  8.56933594e-01]
  [  8.56933594e-01]
  [  8.56933594e-01]
  [  8.56933594e-01]
  [  8.56933594e-01]
  [  8.56933594e-01]
  [  8.56933594e-01]
  [  8.56933594e-01]
  [  8.56933594e-01]
  [  8.56933594e-01]
  [  8.56933594e-01]
  [  8.56933594e-01]
  [  8.56933594e-01]
  [  8.56933594e-01]]

 [[ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]]
After layer swapaxes14_output (20, 10, 1) <class 'numpy.float16'> [[[  2.34375000e-01]
  [  8.56933594e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  2.34375000e-01]
  [  8.56933594e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  2.34375000e-01]
  [  8.56933594e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  2.34375000e-01]
  [  8.56933594e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  2.34375000e-01]
  [  8.56933594e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  2.34375000e-01]
  [  8.56933594e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  2.34375000e-01]
  [  8.56933594e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  2.34375000e-01]
  [  8.56933594e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  2.34375000e-01]
  [  8.56933594e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  2.34375000e-01]
  [  8.56933594e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  2.34375000e-01]
  [  8.56933594e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  2.34375000e-01]
  [  8.56933594e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  2.34375000e-01]
  [  8.56933594e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  2.34375000e-01]
  [  8.56933594e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  2.34375000e-01]
  [  8.56933594e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  2.34375000e-01]
  [  8.56933594e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  2.34375000e-01]
  [  8.56933594e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  2.34375000e-01]
  [  8.56933594e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  2.34375000e-01]
  [  8.56933594e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  2.34375000e-01]
  [  8.56933594e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]]
After layer attention_softmax_0 (20, 10, 1) <class 'numpy.float16'> [[[ 0.34912109]
  [ 0.65039062]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.34912109]
  [ 0.65039062]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.34912109]
  [ 0.65039062]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.34912109]
  [ 0.65039062]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.34912109]
  [ 0.65039062]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.34912109]
  [ 0.65039062]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.34912109]
  [ 0.65039062]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.34912109]
  [ 0.65039062]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.34912109]
  [ 0.65039062]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.34912109]
  [ 0.65039062]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.34912109]
  [ 0.65039062]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.34912109]
  [ 0.65039062]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.34912109]
  [ 0.65039062]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.34912109]
  [ 0.65039062]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.34912109]
  [ 0.65039062]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.34912109]
  [ 0.65039062]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.34912109]
  [ 0.65039062]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.34912109]
  [ 0.65039062]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.34912109]
  [ 0.65039062]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.34912109]
  [ 0.65039062]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]]
After layer batch_dot2_0 (20, 512, 1) <class 'numpy.float16'> [[[ 0.01914978]
  [ 0.04092407]
  [-0.03582764]
  ...,
  [-0.01126862]
  [ 0.01004791]
  [-0.02365112]]

 [[ 0.01914978]
  [ 0.04092407]
  [-0.03582764]
  ...,
  [-0.01126862]
  [ 0.01004791]
  [-0.02365112]]

 [[ 0.01914978]
  [ 0.04092407]
  [-0.03582764]
  ...,
  [-0.01126862]
  [ 0.01004791]
  [-0.02365112]]

 ...,
 [[ 0.01914978]
  [ 0.04092407]
  [-0.03582764]
  ...,
  [-0.01126862]
  [ 0.01004791]
  [-0.02365112]]

 [[ 0.01914978]
  [ 0.04092407]
  [-0.03582764]
  ...,
  [-0.01126862]
  [ 0.01004791]
  [-0.02365112]]

 [[ 0.01914978]
  [ 0.04092407]
  [-0.03582764]
  ...,
  [-0.01126862]
  [ 0.01004791]
  [-0.02365112]]]
After layer reshape4_0 (20, 512) <class 'numpy.float16'> [[ 0.01914978  0.04092407 -0.03582764 ..., -0.01126862  0.01004791
  -0.02365112]
 [ 0.01914978  0.04092407 -0.03582764 ..., -0.01126862  0.01004791
  -0.02365112]
 [ 0.01914978  0.04092407 -0.03582764 ..., -0.01126862  0.01004791
  -0.02365112]
 ...,
 [ 0.01914978  0.04092407 -0.03582764 ..., -0.01126862  0.01004791
  -0.02365112]
 [ 0.01914978  0.04092407 -0.03582764 ..., -0.01126862  0.01004791
  -0.02365112]
 [ 0.01914978  0.04092407 -0.03582764 ..., -0.01126862  0.01004791
  -0.02365112]]
After layer decoder_rnn_hidden_concat_t0_output (20, 1024) <class 'numpy.float16'> [[-0.61669922 -0.03414917  0.10235596 ..., -0.01126862  0.01004791
  -0.02365112]
 [-0.61669922 -0.03414917  0.10235596 ..., -0.01126862  0.01004791
  -0.02365112]
 [-0.61669922 -0.03414917  0.10235596 ..., -0.01126862  0.01004791
  -0.02365112]
 ...,
 [-0.61669922 -0.03414917  0.10235596 ..., -0.01126862  0.01004791
  -0.02365112]
 [-0.61669922 -0.03414917  0.10235596 ..., -0.01126862  0.01004791
  -0.02365112]
 [-0.61669922 -0.03414917  0.10235596 ..., -0.01126862  0.01004791
  -0.02365112]]
After layer decoder_rnn_hidden_fc_t0_output (20, 512) <class 'numpy.float16'> [[-0.10339355  0.18591309  0.17687988 ..., -0.86230469  1.18847656
  -1.03710938]
 [-0.10339355  0.18591309  0.17687988 ..., -0.86230469  1.18847656
  -1.03710938]
 [-0.10339355  0.18591309  0.17687988 ..., -0.86230469  1.18847656
  -1.03710938]
 ...,
 [-0.10339355  0.18591309  0.17687988 ..., -0.86230469  1.18847656
  -1.03710938]
 [-0.10339355  0.18591309  0.17687988 ..., -0.86230469  1.18847656
  -1.03710938]
 [-0.10339355  0.18591309  0.17687988 ..., -0.86230469  1.18847656
  -1.03710938]]
After layer decoder_rnn_next_hidden_t0_output (20, 512) <class 'numpy.float16'> [[-0.10302734  0.18383789  0.17504883 ..., -0.69726562  0.83007812
  -0.77685547]
 [-0.10302734  0.18383789  0.17504883 ..., -0.69726562  0.83007812
  -0.77685547]
 [-0.10302734  0.18383789  0.17504883 ..., -0.69726562  0.83007812
  -0.77685547]
 ...,
 [-0.10302734  0.18383789  0.17504883 ..., -0.69726562  0.83007812
  -0.77685547]
 [-0.10302734  0.18383789  0.17504883 ..., -0.69726562  0.83007812
  -0.77685547]
 [-0.10302734  0.18383789  0.17504883 ..., -0.69726562  0.83007812
  -0.77685547]]
After layer logits_output (20, 16743) <class 'numpy.float16'> [[-1.97558594 -1.57128906 -2.53125    ..., -2.80273438 -2.45117188
  -2.70898438]
 [-1.97558594 -1.57128906 -2.53125    ..., -2.80273438 -2.45117188
  -2.70898438]
 [-1.97558594 -1.57128906 -2.53125    ..., -2.80273438 -2.45117188
  -2.70898438]
 ...,
 [-1.97558594 -1.57128906 -2.53125    ..., -2.80273438 -2.45117188
  -2.70898438]
 [-1.97558594 -1.57128906 -2.53125    ..., -2.80273438 -2.45117188
  -2.70898438]
 [-1.97558594 -1.57128906 -2.53125    ..., -2.80273438 -2.45117188
  -2.70898438]]
After layer softmax_0 (20, 16743) <class 'numpy.float16'> [[  4.05311584e-06   6.07967377e-06   2.32458115e-06 ...,   1.78813934e-06
    2.50339508e-06   1.96695328e-06]
 [  4.05311584e-06   6.07967377e-06   2.32458115e-06 ...,   1.78813934e-06
    2.50339508e-06   1.96695328e-06]
 [  4.05311584e-06   6.07967377e-06   2.32458115e-06 ...,   1.78813934e-06
    2.50339508e-06   1.96695328e-06]
 ...,
 [  4.05311584e-06   6.07967377e-06   2.32458115e-06 ...,   1.78813934e-06
    2.50339508e-06   1.96695328e-06]
 [  4.05311584e-06   6.07967377e-06   2.32458115e-06 ...,   1.78813934e-06
    2.50339508e-06   1.96695328e-06]
 [  4.05311584e-06   6.07967377e-06   2.32458115e-06 ...,   1.78813934e-06
    2.50339508e-06   1.96695328e-06]]
After layer reshape5_0 (20, 10) <class 'numpy.float16'> [[ 0.34912109  0.65039062  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.34912109  0.65039062  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.34912109  0.65039062  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.34912109  0.65039062  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.34912109  0.65039062  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.34912109  0.65039062  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.34912109  0.65039062  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.34912109  0.65039062  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.34912109  0.65039062  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.34912109  0.65039062  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.34912109  0.65039062  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.34912109  0.65039062  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.34912109  0.65039062  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.34912109  0.65039062  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.34912109  0.65039062  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.34912109  0.65039062  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.34912109  0.65039062  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.34912109  0.65039062  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.34912109  0.65039062  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.34912109  0.65039062  0.          0.          0.          0.          0.
   0.          0.          0.        ]]
After layer target_embed_embed_0 (20, 256) <class 'numpy.float16'> [[ 0.14013672  0.20153809 -0.07067871 ..., -0.01544189 -0.08544922
  -0.18017578]
 [-0.09741211  0.03695679 -0.09680176 ...,  0.04989624 -0.08117676
   0.02781677]
 [-0.03533936 -0.15087891 -0.13806152 ...,  0.14208984 -0.02362061
   0.09649658]
 ...,
 [-0.09918213 -0.03604126 -0.10394287 ..., -0.01651001  0.06848145
  -0.00800323]
 [ 0.1050415   0.08380127 -0.09240723 ...,  0.02670288 -0.09100342
   0.01057434]
 [-0.06762695 -0.01657104  0.0635376  ..., -0.02737427  0.04412842
   0.00128555]]
After layer decoder_rnn_concat_target_context_t0_output (20, 768) <class 'numpy.float16'> [[ 0.14013672  0.20153809 -0.07067871 ..., -0.69726562  0.83007812
  -0.77685547]
 [-0.09741211  0.03695679 -0.09680176 ..., -0.69726562  0.83007812
  -0.77685547]
 [-0.03533936 -0.15087891 -0.13806152 ..., -0.69726562  0.83007812
  -0.77685547]
 ...,
 [-0.09918213 -0.03604126 -0.10394287 ..., -0.69726562  0.83007812
  -0.77685547]
 [ 0.1050415   0.08380127 -0.09240723 ..., -0.69726562  0.83007812
  -0.77685547]
 [-0.06762695 -0.01657104  0.0635376  ..., -0.69726562  0.83007812
  -0.77685547]]
After layer decoder_rnn_l0_t0_i2h_output (20, 2048) <class 'numpy.float16'> [[-2.95507812  2.19921875  2.51757812 ..., -2.8515625   3.65039062
  -0.25683594]
 [-2.74804688  1.97070312  2.5625     ..., -0.43994141  3.90234375
  -0.47363281]
 [-2.69921875  1.82226562  2.55664062 ...,  0.1920166   3.94140625
  -0.80371094]
 ...,
 [-2.69921875  1.99804688  2.5390625  ..., -0.41015625  3.86132812
  -0.74853516]
 [-2.77929688  1.88964844  2.5546875  ..., -0.63232422  3.94726562
  -0.3972168 ]
 [-2.78320312  1.82714844  2.5        ..., -0.01402283  3.859375
  -0.56396484]]
After layer decoder_rnn_l0_t0_h2h_output (20, 2048) <class 'numpy.float16'> [[-0.14819336  0.31567383  1.21191406 ...,  0.20788574  0.5859375
   0.4465332 ]
 [-0.14819336  0.31567383  1.21191406 ...,  0.20788574  0.5859375
   0.4465332 ]
 [-0.14819336  0.31567383  1.21191406 ...,  0.20788574  0.5859375
   0.4465332 ]
 ...,
 [-0.14819336  0.31567383  1.21191406 ...,  0.20788574  0.5859375
   0.4465332 ]
 [-0.14819336  0.31567383  1.21191406 ...,  0.20788574  0.5859375
   0.4465332 ]
 [-0.14819336  0.31567383  1.21191406 ...,  0.20788574  0.5859375
   0.4465332 ]]
After layer _plus1047_0 (20, 2048) <class 'numpy.float16'> [[-3.10351562  2.515625    3.73046875 ..., -2.64453125  4.234375
   0.18969727]
 [-2.89648438  2.28710938  3.7734375  ..., -0.23205566  4.48828125
  -0.02709961]
 [-2.84765625  2.13867188  3.76953125 ...,  0.39990234  4.52734375
  -0.35717773]
 ...,
 [-2.84765625  2.31445312  3.75       ..., -0.20227051  4.4453125
  -0.30200195]
 [-2.92773438  2.20507812  3.765625   ..., -0.42431641  4.53125     0.04931641]
 [-2.93164062  2.14257812  3.7109375  ...,  0.19384766  4.4453125
  -0.11743164]]
After layer decoder_rnn_l0_t0_slice_output0 (20, 512) <class 'numpy.float16'> [[-3.10351562  2.515625    3.73046875 ...,  2.26171875  4.35546875
   1.171875  ]
 [-2.89648438  2.28710938  3.7734375  ...,  2.28320312  4.4296875
   0.99658203]
 [-2.84765625  2.13867188  3.76953125 ...,  2.265625    4.484375
   1.02246094]
 ...,
 [-2.84765625  2.31445312  3.75       ...,  2.25390625  4.47265625
   1.00097656]
 [-2.92773438  2.20507812  3.765625   ...,  2.3125      4.4375      1.09179688]
 [-2.93164062  2.14257812  3.7109375  ...,  2.25195312  4.4453125
   1.05566406]]
After layer decoder_rnn_l0_t0_slice_output1 (20, 512) <class 'numpy.float16'> [[ 0.19140625  0.03613281  2.34375    ...,  1.5078125  -0.60400391
   1.4765625 ]
 [-0.63476562  0.33349609  2.28515625 ...,  1.44628906 -1.19433594
   1.296875  ]
 [-0.59130859  0.171875    2.3515625  ...,  1.47460938 -1.64648438
   1.24804688]
 ...,
 [-0.62792969  0.48095703  2.3125     ...,  1.37890625 -1.40625     1.2109375 ]
 [-0.3984375  -0.03125     2.328125   ...,  1.55078125 -1.03125     1.39257812]
 [-0.63134766  0.18994141  2.29492188 ...,  1.49023438 -1.2734375
   1.34179688]]
After layer decoder_rnn_l0_t0_slice_output2 (20, 512) <class 'numpy.float16'> [[-1.76074219 -2.015625    2.9140625  ...,  2.63671875 -0.7421875
   1.53027344]
 [-1.87011719 -1.91601562  3.01171875 ...,  2.703125   -0.73193359
   1.45507812]
 [-1.88476562 -1.91992188  3.04492188 ...,  2.6875     -0.48291016  1.40625   ]
 ...,
 [-1.82324219 -1.91015625  2.953125   ...,  2.62109375 -0.87792969
   1.44140625]
 [-1.87207031 -1.96289062  3.00585938 ...,  2.73828125 -0.55175781
   1.484375  ]
 [-1.83984375 -1.85351562  2.97851562 ...,  2.6640625  -0.66699219
   1.44726562]]
After layer decoder_rnn_l0_t0_slice_output3 (20, 512) <class 'numpy.float16'> [[ 0.83886719 -2.5        -1.5546875  ..., -2.64453125  4.234375
   0.18969727]
 [ 0.43066406 -1.02148438  0.73046875 ..., -0.23205566  4.48828125
  -0.02709961]
 [ 0.43408203 -0.73681641  1.65527344 ...,  0.39990234  4.52734375
  -0.35717773]
 ...,
 [ 0.31396484 -0.36181641  1.671875   ..., -0.20227051  4.4453125
  -0.30200195]
 [ 0.56201172 -1.52734375 -0.10205078 ..., -0.42431641  4.53125     0.04931641]
 [ 0.40087891 -1.02148438  0.84179688 ...,  0.19384766  4.4453125
  -0.11743164]]
After layer decoder_rnn_l0_t0_o_output (20, 512) <class 'numpy.float16'> [[ 0.69824219  0.0758667   0.17443848 ...,  0.06634521  0.98583984
   0.54736328]
 [ 0.60595703  0.26464844  0.67480469 ...,  0.44213867  0.98876953
   0.49316406]
 [ 0.60693359  0.32373047  0.83984375 ...,  0.59863281  0.98925781
   0.41162109]
 ...,
 [ 0.57763672  0.41040039  0.84179688 ...,  0.44970703  0.98828125
   0.42504883]
 [ 0.63671875  0.17834473  0.47460938 ...,  0.39550781  0.98925781
   0.51220703]
 [ 0.59912109  0.26464844  0.69873047 ...,  0.54833984  0.98828125
   0.47070312]]
After layer decoder_rnn_l0_t0_f_output (20, 512) <class 'numpy.float16'> [[ 0.54785156  0.50878906  0.91259766 ...,  0.81884766  0.35351562
   0.81396484]
 [ 0.34643555  0.58251953  0.90771484 ...,  0.80957031  0.23254395
   0.78515625]
 [ 0.35644531  0.54296875  0.91308594 ...,  0.81396484  0.16162109
   0.77685547]
 ...,
 [ 0.34790039  0.61816406  0.90966797 ...,  0.79882812  0.19677734
   0.77050781]
 [ 0.40161133  0.4921875   0.91113281 ...,  0.82519531  0.26293945
   0.80078125]
 [ 0.34716797  0.54736328  0.90869141 ...,  0.81591797  0.21862793
   0.79296875]]
After layer _mul2094_0 (20, 512) <class 'numpy.float16'> [[-0.44970703 -0.07385254  0.19677734 ...,  0.38745117  0.29492188
   0.3449707 ]
 [-0.28442383 -0.08453369  0.19567871 ...,  0.38305664  0.19396973
   0.33276367]
 [-0.29248047 -0.07879639  0.19689941 ...,  0.38500977  0.13476562
   0.3293457 ]
 ...,
 [-0.28564453 -0.08972168  0.19604492 ...,  0.37792969  0.1640625
   0.32666016]
 [-0.32958984 -0.07141113  0.19641113 ...,  0.39038086  0.21923828
   0.33935547]
 [-0.28491211 -0.07946777  0.19592285 ...,  0.38598633  0.18237305
   0.33618164]]
After layer decoder_rnn_l0_t0_i_output (20, 512) <class 'numpy.float16'> [[ 0.04296875  0.92529297  0.9765625  ...,  0.90576172  0.98730469
   0.76367188]
 [ 0.05233765  0.90771484  0.97753906 ...,  0.90771484  0.98828125
   0.73046875]
 [ 0.05480957  0.89453125  0.97753906 ...,  0.90576172  0.98876953
   0.73535156]
 ...,
 [ 0.05480957  0.91015625  0.97705078 ...,  0.90478516  0.98876953
   0.73144531]
 [ 0.05081177  0.90087891  0.97753906 ...,  0.90966797  0.98828125
   0.74853516]
 [ 0.05059814  0.89501953  0.97607422 ...,  0.90478516  0.98828125
   0.74169922]]
After layer decoder_rnn_l0_t0_c_output (20, 512) <class 'numpy.float16'> [[-0.94238281 -0.96533203  0.99414062 ...,  0.98974609 -0.63037109
   0.91064453]
 [-0.95361328 -0.95751953  0.99511719 ...,  0.99121094 -0.62402344
   0.89648438]
 [-0.95507812 -0.95800781  0.99560547 ...,  0.99072266 -0.44848633
   0.88671875]
 ...,
 [-0.94921875 -0.95703125  0.99462891 ...,  0.98925781 -0.70556641
   0.89404297]
 [-0.95361328 -0.96142578  0.99511719 ...,  0.99169922 -0.50195312
   0.90234375]
 [-0.95068359 -0.95214844  0.99462891 ...,  0.99023438 -0.58300781
   0.89501953]]
After layer _mul2095_0 (20, 512) <class 'numpy.float16'> [[-0.04049683 -0.89306641  0.97070312 ...,  0.89648438 -0.62255859
   0.6953125 ]
 [-0.04989624 -0.86914062  0.97265625 ...,  0.89990234 -0.61669922
   0.65478516]
 [-0.05233765 -0.85693359  0.97314453 ...,  0.89746094 -0.44335938
   0.65185547]
 ...,
 [-0.05203247 -0.87109375  0.97167969 ...,  0.89501953 -0.69775391
   0.65380859]
 [-0.04846191 -0.86621094  0.97265625 ...,  0.90234375 -0.49609375
   0.67529297]
 [-0.0480957  -0.85205078  0.97070312 ...,  0.89599609 -0.57617188
   0.6640625 ]]
After layer decoder_rnn_l0_t0_state_0 (20, 512) <class 'numpy.float16'> [[-0.49023438 -0.96679688  1.16796875 ...,  1.28417969 -0.32763672
   1.04003906]
 [-0.33422852 -0.95361328  1.16796875 ...,  1.28320312 -0.42285156
   0.98730469]
 [-0.34472656 -0.93554688  1.16992188 ...,  1.28222656 -0.30859375
   0.98144531]
 ...,
 [-0.33764648 -0.9609375   1.16796875 ...,  1.2734375  -0.53369141
   0.98046875]
 [-0.37792969 -0.9375      1.16894531 ...,  1.29296875 -0.27685547
   1.01464844]
 [-0.33300781 -0.93164062  1.16699219 ...,  1.28222656 -0.39379883  1.        ]]
After layer activation1047_output (20, 512) <class 'numpy.float16'> [[-0.4543457  -0.74707031  0.82373047 ...,  0.85742188 -0.31640625
   0.77783203]
 [-0.32226562 -0.74121094  0.82373047 ...,  0.85742188 -0.39941406
   0.75634766]
 [-0.33178711 -0.73339844  0.82421875 ...,  0.85693359 -0.29907227
   0.75390625]
 ...,
 [-0.32543945 -0.74462891  0.82373047 ...,  0.85449219 -0.48828125
   0.75341797]
 [-0.36083984 -0.73388672  0.82373047 ...,  0.85986328 -0.27001953
   0.76757812]
 [-0.32128906 -0.73144531  0.82324219 ...,  0.85693359 -0.37451172
   0.76171875]]
After layer decoder_rnn_l0_t0_out_0 (20, 512) <class 'numpy.float16'> [[-0.31713867 -0.05667114  0.14367676 ...,  0.05688477 -0.31201172
   0.42578125]
 [-0.1953125  -0.19616699  0.55566406 ...,  0.37915039 -0.39501953
   0.37304688]
 [-0.20141602 -0.23742676  0.69238281 ...,  0.51318359 -0.29589844
   0.31030273]
 ...,
 [-0.18798828 -0.30566406  0.69335938 ...,  0.38427734 -0.48266602
   0.3203125 ]
 [-0.22973633 -0.13085938  0.39086914 ...,  0.34008789 -0.26708984
   0.39306641]
 [-0.19250488 -0.19360352  0.57519531 ...,  0.4699707  -0.37011719
   0.35864258]]
After layer expand_dims1056_0 (20, 512, 1) <class 'numpy.float16'> [[[-0.31713867]
  [-0.05667114]
  [ 0.14367676]
  ...,
  [ 0.05688477]
  [-0.31201172]
  [ 0.42578125]]

 [[-0.1953125 ]
  [-0.19616699]
  [ 0.55566406]
  ...,
  [ 0.37915039]
  [-0.39501953]
  [ 0.37304688]]

 [[-0.20141602]
  [-0.23742676]
  [ 0.69238281]
  ...,
  [ 0.51318359]
  [-0.29589844]
  [ 0.31030273]]

 ...,
 [[-0.18798828]
  [-0.30566406]
  [ 0.69335938]
  ...,
  [ 0.38427734]
  [-0.48266602]
  [ 0.3203125 ]]

 [[-0.22973633]
  [-0.13085938]
  [ 0.39086914]
  ...,
  [ 0.34008789]
  [-0.26708984]
  [ 0.39306641]]

 [[-0.19250488]
  [-0.19360352]
  [ 0.57519531]
  ...,
  [ 0.4699707 ]
  [-0.37011719]
  [ 0.35864258]]]
After layer att_batch_dot_0 (20, 10, 1) <class 'numpy.float16'> [[[  0.60302734]
  [  1.16699219]
  [  2.82226562]
  [  5.390625  ]
  [  8.140625  ]
  [  9.734375  ]
  [ 10.1640625 ]
  [  9.984375  ]
  [  9.5625    ]
  [  8.984375  ]]

 [[  0.26196289]
  [ -0.09436035]
  [ -0.12939453]
  [ -0.63330078]
  [ -2.53710938]
  [ -6.44921875]
  [-10.984375  ]
  [-14.734375  ]
  [-17.390625  ]
  [-19.25      ]]

 [[  0.23364258]
  [ -0.33349609]
  [ -0.75976562]
  [ -1.99511719]
  [ -5.09765625]
  [-10.53125   ]
  [-16.515625  ]
  [-21.359375  ]
  [-24.703125  ]
  [-26.953125  ]]

 [[  0.44799805]
  [  0.67041016]
  [  1.56445312]
  [  2.7421875 ]
  [  3.27539062]
  [  2.1171875 ]
  [  0.05349731]
  [ -1.80859375]
  [ -3.13671875]
  [ -4.078125  ]]

 [[  0.30541992]
  [  0.09411621]
  [  0.34741211]
  [  0.39379883]
  [ -0.58935547]
  [ -3.3125    ]
  [ -6.7265625 ]
  [ -9.65625   ]
  [-11.8125    ]
  [-13.3828125 ]]

 [[  0.36254883]
  [  0.31176758]
  [  0.78271484]
  [  1.2109375 ]
  [  0.68652344]
  [ -1.63671875]
  [ -4.74609375]
  [ -7.4296875 ]
  [ -9.3671875 ]
  [-10.7578125 ]]

 [[  0.30737305]
  [  0.11352539]
  [  0.38574219]
  [  0.50195312]
  [ -0.33422852]
  [ -2.84765625]
  [ -6.05078125]
  [ -8.8203125 ]
  [-10.875     ]
  [-12.390625  ]]

 [[  0.57568359]
  [  1.04394531]
  [  2.53515625]
  [  4.828125  ]
  [  7.25      ]
  [  8.5234375 ]
  [  8.6953125 ]
  [  8.359375  ]
  [  7.82421875]
  [  7.19140625]]

 [[  0.42504883]
  [  0.57470703]
  [  1.38964844]
  [  2.45703125]
  [  2.89648438]
  [  1.703125  ]
  [ -0.36425781]
  [ -2.24804688]
  [ -3.63085938]
  [ -4.6484375 ]]

 [[  0.47729492]
  [  0.79638672]
  [  1.86816406]
  [  3.39648438]
  [  4.49609375]
  [  4.05078125]
  [  2.65625   ]
  [  1.28222656]
  [  0.24462891]
  [ -0.54882812]]

 [[  0.44384766]
  [  0.68261719]
  [  1.60449219]
  [  2.85546875]
  [  3.53125   ]
  [  2.57421875]
  [  0.703125  ]
  [ -1.02636719]
  [ -2.29101562]
  [ -3.21679688]]

 [[  0.48168945]
  [  0.87060547]
  [  2.04882812]
  [  3.77929688]
  [  5.1953125 ]
  [  5.12890625]
  [  4.1015625 ]
  [  3.03125   ]
  [  2.23046875]
  [  1.61816406]]

 [[  0.45532227]
  [  0.69824219]
  [  1.68652344]
  [  3.08984375]
  [  4.09375   ]
  [  3.63867188]
  [  2.25195312]
  [  0.8359375 ]
  [ -0.2956543 ]
  [ -1.20605469]]

 [[  0.31518555]
  [  0.13000488]
  [  0.39697266]
  [  0.48535156]
  [ -0.45117188]
  [ -3.1484375 ]
  [ -6.55078125]
  [ -9.4609375 ]
  [-11.578125  ]
  [-13.109375  ]]

 [[  0.18518066]
  [ -0.48461914]
  [ -1.0390625 ]
  [ -2.49609375]
  [ -5.828125  ]
  [-11.40625   ]
  [-17.453125  ]
  [-22.296875  ]
  [-25.65625   ]
  [-27.9375    ]]

 [[  0.44750977]
  [  0.67724609]
  [  1.60644531]
  [  2.85351562]
  [  3.50390625]
  [  2.48828125]
  [  0.53710938]
  [ -1.2890625 ]
  [ -2.65234375]
  [ -3.66796875]]

 [[  0.25292969]
  [ -0.14538574]
  [ -0.25708008]
  [ -0.89111328]
  [ -2.96875   ]
  [ -7.0546875 ]
  [-11.734375  ]
  [-15.59375   ]
  [-18.328125  ]
  [-20.21875   ]]

 [[  0.13977051]
  [ -0.76708984]
  [ -1.66601562]
  [ -3.74023438]
  [ -7.9765625 ]
  [-14.59375   ]
  [-21.609375  ]
  [-27.265625  ]
  [-31.28125   ]
  [-34.0625    ]]

 [[  0.4206543 ]
  [  0.56542969]
  [  1.38671875]
  [  2.453125  ]
  [  2.91601562]
  [  1.78808594]
  [ -0.21411133]
  [ -2.07226562]
  [ -3.48046875]
  [ -4.5546875 ]]

 [[  0.27050781]
  [ -0.0680542 ]
  [ -0.09613037]
  [ -0.58642578]
  [ -2.49023438]
  [ -6.421875  ]
  [-10.9765625 ]
  [-14.71875   ]
  [-17.328125  ]
  [-19.125     ]]]
After layer swapaxes15_output (10, 20, 1) <class 'numpy.float16'> [[[  0.60302734]
  [  0.26196289]
  [  0.23364258]
  [  0.44799805]
  [  0.30541992]
  [  0.36254883]
  [  0.30737305]
  [  0.57568359]
  [  0.42504883]
  [  0.47729492]
  [  0.44384766]
  [  0.48168945]
  [  0.45532227]
  [  0.31518555]
  [  0.18518066]
  [  0.44750977]
  [  0.25292969]
  [  0.13977051]
  [  0.4206543 ]
  [  0.27050781]]

 [[  1.16699219]
  [ -0.09436035]
  [ -0.33349609]
  [  0.67041016]
  [  0.09411621]
  [  0.31176758]
  [  0.11352539]
  [  1.04394531]
  [  0.57470703]
  [  0.79638672]
  [  0.68261719]
  [  0.87060547]
  [  0.69824219]
  [  0.13000488]
  [ -0.48461914]
  [  0.67724609]
  [ -0.14538574]
  [ -0.76708984]
  [  0.56542969]
  [ -0.0680542 ]]

 [[  2.82226562]
  [ -0.12939453]
  [ -0.75976562]
  [  1.56445312]
  [  0.34741211]
  [  0.78271484]
  [  0.38574219]
  [  2.53515625]
  [  1.38964844]
  [  1.86816406]
  [  1.60449219]
  [  2.04882812]
  [  1.68652344]
  [  0.39697266]
  [ -1.0390625 ]
  [  1.60644531]
  [ -0.25708008]
  [ -1.66601562]
  [  1.38671875]
  [ -0.09613037]]

 [[  5.390625  ]
  [ -0.63330078]
  [ -1.99511719]
  [  2.7421875 ]
  [  0.39379883]
  [  1.2109375 ]
  [  0.50195312]
  [  4.828125  ]
  [  2.45703125]
  [  3.39648438]
  [  2.85546875]
  [  3.77929688]
  [  3.08984375]
  [  0.48535156]
  [ -2.49609375]
  [  2.85351562]
  [ -0.89111328]
  [ -3.74023438]
  [  2.453125  ]
  [ -0.58642578]]

 [[  8.140625  ]
  [ -2.53710938]
  [ -5.09765625]
  [  3.27539062]
  [ -0.58935547]
  [  0.68652344]
  [ -0.33422852]
  [  7.25      ]
  [  2.89648438]
  [  4.49609375]
  [  3.53125   ]
  [  5.1953125 ]
  [  4.09375   ]
  [ -0.45117188]
  [ -5.828125  ]
  [  3.50390625]
  [ -2.96875   ]
  [ -7.9765625 ]
  [  2.91601562]
  [ -2.49023438]]

 [[  9.734375  ]
  [ -6.44921875]
  [-10.53125   ]
  [  2.1171875 ]
  [ -3.3125    ]
  [ -1.63671875]
  [ -2.84765625]
  [  8.5234375 ]
  [  1.703125  ]
  [  4.05078125]
  [  2.57421875]
  [  5.12890625]
  [  3.63867188]
  [ -3.1484375 ]
  [-11.40625   ]
  [  2.48828125]
  [ -7.0546875 ]
  [-14.59375   ]
  [  1.78808594]
  [ -6.421875  ]]

 [[ 10.1640625 ]
  [-10.984375  ]
  [-16.515625  ]
  [  0.05349731]
  [ -6.7265625 ]
  [ -4.74609375]
  [ -6.05078125]
  [  8.6953125 ]
  [ -0.36425781]
  [  2.65625   ]
  [  0.703125  ]
  [  4.1015625 ]
  [  2.25195312]
  [ -6.55078125]
  [-17.453125  ]
  [  0.53710938]
  [-11.734375  ]
  [-21.609375  ]
  [ -0.21411133]
  [-10.9765625 ]]

 [[  9.984375  ]
  [-14.734375  ]
  [-21.359375  ]
  [ -1.80859375]
  [ -9.65625   ]
  [ -7.4296875 ]
  [ -8.8203125 ]
  [  8.359375  ]
  [ -2.24804688]
  [  1.28222656]
  [ -1.02636719]
  [  3.03125   ]
  [  0.8359375 ]
  [ -9.4609375 ]
  [-22.296875  ]
  [ -1.2890625 ]
  [-15.59375   ]
  [-27.265625  ]
  [ -2.07226562]
  [-14.71875   ]]

 [[  9.5625    ]
  [-17.390625  ]
  [-24.703125  ]
  [ -3.13671875]
  [-11.8125    ]
  [ -9.3671875 ]
  [-10.875     ]
  [  7.82421875]
  [ -3.63085938]
  [  0.24462891]
  [ -2.29101562]
  [  2.23046875]
  [ -0.2956543 ]
  [-11.578125  ]
  [-25.65625   ]
  [ -2.65234375]
  [-18.328125  ]
  [-31.28125   ]
  [ -3.48046875]
  [-17.328125  ]]

 [[  8.984375  ]
  [-19.25      ]
  [-26.953125  ]
  [ -4.078125  ]
  [-13.3828125 ]
  [-10.7578125 ]
  [-12.390625  ]
  [  7.19140625]
  [ -4.6484375 ]
  [ -0.54882812]
  [ -3.21679688]
  [  1.61816406]
  [ -1.20605469]
  [-13.109375  ]
  [-27.9375    ]
  [ -3.66796875]
  [-20.21875   ]
  [-34.0625    ]
  [ -4.5546875 ]
  [-19.125     ]]]
After layer sequencemask3_output (10, 20, 1) <class 'numpy.float16'> [[[  6.03027344e-01]
  [  2.61962891e-01]
  [  2.33642578e-01]
  [  4.47998047e-01]
  [  3.05419922e-01]
  [  3.62548828e-01]
  [  3.07373047e-01]
  [  5.75683594e-01]
  [  4.25048828e-01]
  [  4.77294922e-01]
  [  4.43847656e-01]
  [  4.81689453e-01]
  [  4.55322266e-01]
  [  3.15185547e-01]
  [  1.85180664e-01]
  [  4.47509766e-01]
  [  2.52929688e-01]
  [  1.39770508e-01]
  [  4.20654297e-01]
  [  2.70507812e-01]]

 [[  1.16699219e+00]
  [ -9.43603516e-02]
  [ -3.33496094e-01]
  [  6.70410156e-01]
  [  9.41162109e-02]
  [  3.11767578e-01]
  [  1.13525391e-01]
  [  1.04394531e+00]
  [  5.74707031e-01]
  [  7.96386719e-01]
  [  6.82617188e-01]
  [  8.70605469e-01]
  [  6.98242188e-01]
  [  1.30004883e-01]
  [ -4.84619141e-01]
  [  6.77246094e-01]
  [ -1.45385742e-01]
  [ -7.67089844e-01]
  [  5.65429688e-01]
  [ -6.80541992e-02]]

 [[ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]]
After layer swapaxes16_output (20, 10, 1) <class 'numpy.float16'> [[[  6.03027344e-01]
  [  1.16699219e+00]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  2.61962891e-01]
  [ -9.43603516e-02]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  2.33642578e-01]
  [ -3.33496094e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  4.47998047e-01]
  [  6.70410156e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  3.05419922e-01]
  [  9.41162109e-02]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  3.62548828e-01]
  [  3.11767578e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  3.07373047e-01]
  [  1.13525391e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  5.75683594e-01]
  [  1.04394531e+00]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  4.25048828e-01]
  [  5.74707031e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  4.77294922e-01]
  [  7.96386719e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  4.43847656e-01]
  [  6.82617188e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  4.81689453e-01]
  [  8.70605469e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  4.55322266e-01]
  [  6.98242188e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  3.15185547e-01]
  [  1.30004883e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  1.85180664e-01]
  [ -4.84619141e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  4.47509766e-01]
  [  6.77246094e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  2.52929688e-01]
  [ -1.45385742e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  1.39770508e-01]
  [ -7.67089844e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  4.20654297e-01]
  [  5.65429688e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  2.70507812e-01]
  [ -6.80541992e-02]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]]
After layer attention_softmax_0 (20, 10, 1) <class 'numpy.float16'> [[[ 0.36279297]
  [ 0.63769531]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.58837891]
  [ 0.41186523]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.63818359]
  [ 0.36206055]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.44458008]
  [ 0.55517578]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.55273438]
  [ 0.44726562]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.51269531]
  [ 0.48706055]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.54833984]
  [ 0.45166016]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.38500977]
  [ 0.61523438]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.46264648]
  [ 0.53710938]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.42089844]
  [ 0.57910156]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.44067383]
  [ 0.55957031]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40405273]
  [ 0.59619141]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.43969727]
  [ 0.56054688]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.54589844]
  [ 0.45385742]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.66162109]
  [ 0.33862305]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.44287109]
  [ 0.55712891]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.59814453]
  [ 0.40161133]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.71191406]
  [ 0.28759766]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.46386719]
  [ 0.53613281]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.58398438]
  [ 0.41601562]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]]
After layer batch_dot3_0 (20, 512, 1) <class 'numpy.float16'> [[[ 0.0188446 ]
  [ 0.04058838]
  [-0.0352478 ]
  ...,
  [-0.01119995]
  [ 0.01004791]
  [-0.02391052]]

 [[ 0.01338959]
  [ 0.03430176]
  [-0.02510071]
  ...,
  [-0.00994873]
  [ 0.00978088]
  [-0.02790833]]

 [[ 0.01219177]
  [ 0.03289795]
  [-0.02285767]
  ...,
  [-0.00967407]
  [ 0.00971985]
  [-0.02879333]]

 ...,
 [[ 0.01039124]
  [ 0.03082275]
  [-0.01950073]
  ...,
  [-0.00925446]
  [ 0.0096283 ]
  [-0.03007507]]

 [[ 0.01638794]
  [ 0.03775024]
  [-0.03068542]
  ...,
  [-0.01063538]
  [ 0.00991821]
  [-0.0256958 ]]

 [[ 0.01348877]
  [ 0.03442383]
  [-0.02528381]
  ...,
  [-0.00997162]
  [ 0.00978088]
  [-0.02781677]]]
After layer reshape6_0 (20, 512) <class 'numpy.float16'> [[ 0.0188446   0.04058838 -0.0352478  ..., -0.01119995  0.01004791
  -0.02391052]
 [ 0.01338959  0.03430176 -0.02510071 ..., -0.00994873  0.00978088
  -0.02790833]
 [ 0.01219177  0.03289795 -0.02285767 ..., -0.00967407  0.00971985
  -0.02879333]
 ...,
 [ 0.01039124  0.03082275 -0.01950073 ..., -0.00925446  0.0096283
  -0.03007507]
 [ 0.01638794  0.03775024 -0.03068542 ..., -0.01063538  0.00991821
  -0.0256958 ]
 [ 0.01348877  0.03442383 -0.02528381 ..., -0.00997162  0.00978088
  -0.02781677]]
After layer decoder_rnn_hidden_concat_t0_output (20, 1024) <class 'numpy.float16'> [[-0.31713867 -0.05667114  0.14367676 ..., -0.01119995  0.01004791
  -0.02391052]
 [-0.1953125  -0.19616699  0.55566406 ..., -0.00994873  0.00978088
  -0.02790833]
 [-0.20141602 -0.23742676  0.69238281 ..., -0.00967407  0.00971985
  -0.02879333]
 ...,
 [-0.18798828 -0.30566406  0.69335938 ..., -0.00925446  0.0096283
  -0.03007507]
 [-0.22973633 -0.13085938  0.39086914 ..., -0.01063538  0.00991821
  -0.0256958 ]
 [-0.19250488 -0.19360352  0.57519531 ..., -0.00997162  0.00978088
  -0.02781677]]
After layer decoder_rnn_hidden_fc_t0_output (20, 512) <class 'numpy.float16'> [[ 0.53564453 -1.93652344  1.77050781 ..., -0.66650391  1.57128906
   0.74316406]
 [-0.14538574 -1.57714844  1.62402344 ..., -0.35595703  1.90429688
  -1.31542969]
 [-0.42626953 -1.53710938  1.79101562 ..., -0.4309082   2.12304688
  -2.49023438]
 ...,
 [-0.08508301 -1.8359375   2.         ..., -0.55322266  2.08203125
  -1.89355469]
 [ 0.02212524 -1.5703125   1.49804688 ..., -0.3840332   1.78222656
  -0.52441406]
 [-0.28051758 -1.41503906  1.51660156 ..., -0.31835938  1.93066406
  -1.61621094]]
After layer decoder_rnn_next_hidden_t0_output (20, 512) <class 'numpy.float16'> [[ 0.48974609 -0.95947266  0.94384766 ..., -0.58251953  0.91699219
   0.63085938]
 [-0.14440918 -0.91796875  0.92529297 ..., -0.34155273  0.95654297
  -0.86572266]
 [-0.40209961 -0.91162109  0.94580078 ..., -0.40600586  0.97167969
  -0.98632812]
 ...,
 [-0.0848999  -0.95019531  0.96386719 ..., -0.50292969  0.96923828
  -0.95556641]
 [ 0.02212524 -0.91699219  0.90478516 ..., -0.36621094  0.94482422
  -0.48120117]
 [-0.2734375  -0.88867188  0.90820312 ..., -0.30810547  0.95898438
  -0.92431641]]
After layer logits_output (20, 16743) <class 'numpy.float16'> [[-1.93066406 -2.3046875  -1.50976562 ..., -2.546875   -1.86230469
  -1.71289062]
 [-1.77148438 -3.36132812 -3.171875   ..., -3.1171875  -3.13867188
  -3.109375  ]
 [-1.83105469 -3.56054688 -3.82421875 ..., -3.03710938 -3.55273438
  -3.65039062]
 ...,
 [-1.76757812 -3.54882812 -3.56445312 ..., -2.99609375 -3.32617188 -3.34375   ]
 [-1.86230469 -3.04296875 -2.43554688 ..., -3.11132812 -2.75       -2.609375  ]
 [-1.83105469 -3.39648438 -3.40820312 ..., -3.14648438 -3.26367188
  -3.31640625]]
After layer softmax_0 (20, 16743) <class 'numpy.float16'> [[  4.17232513e-06   2.86102295e-06   6.37769699e-06 ...,   2.26497650e-06
    4.47034836e-06   5.18560410e-06]
 [  9.53674316e-07   1.78813934e-07   2.38418579e-07 ...,   2.38418579e-07
    2.38418579e-07   2.38418579e-07]
 [  5.96046448e-08   0.00000000e+00   0.00000000e+00 ...,   0.00000000e+00
    0.00000000e+00   0.00000000e+00]
 ...,
 [  1.78813934e-07   5.96046448e-08   5.96046448e-08 ...,   5.96046448e-08
    5.96046448e-08   5.96046448e-08]
 [  3.45706940e-06   1.07288361e-06   1.96695328e-06 ...,   1.01327896e-06
    1.43051147e-06   1.60932541e-06]
 [  5.36441803e-07   1.19209290e-07   1.19209290e-07 ...,   1.19209290e-07
    1.19209290e-07   1.19209290e-07]]
After layer reshape7_0 (20, 10) <class 'numpy.float16'> [[ 0.36279297  0.63769531  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.58837891  0.41186523  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.63818359  0.36206055  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.44458008  0.55517578  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.55273438  0.44726562  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.51269531  0.48706055  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.54833984  0.45166016  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.38500977  0.61523438  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.46264648  0.53710938  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.42089844  0.57910156  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.44067383  0.55957031  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40405273  0.59619141  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.43969727  0.56054688  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.54589844  0.45385742  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.66162109  0.33862305  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.44287109  0.55712891  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.59814453  0.40161133  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.71191406  0.28759766  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.46386719  0.53613281  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.58398438  0.41601562  0.          0.          0.          0.          0.
   0.          0.          0.        ]]
After layer target_embed_embed_0 (20, 256) <class 'numpy.float16'> [[ 0.08892822  0.08123779 -0.08746338 ...,  0.04257202  0.08666992
   0.03131104]
 [ 0.08892822  0.08123779 -0.08746338 ...,  0.04257202  0.08666992
   0.03131104]
 [ 0.08892822  0.08123779 -0.08746338 ...,  0.04257202  0.08666992
   0.03131104]
 ...,
 [-0.01300049  0.11682129  0.06750488 ..., -0.10992432 -0.05990601
  -0.10571289]
 [-0.00485992  0.01457214  0.0317688  ..., -0.01901245 -0.00218773
   0.05514526]
 [-0.01300049  0.11682129  0.06750488 ..., -0.10992432 -0.05990601
  -0.10571289]]
After layer decoder_rnn_concat_target_context_t0_output (20, 768) <class 'numpy.float16'> [[ 0.08892822  0.08123779 -0.08746338 ..., -0.40600586  0.97167969
  -0.98632812]
 [ 0.08892822  0.08123779 -0.08746338 ..., -0.34155273  0.95654297
  -0.86572266]
 [ 0.08892822  0.08123779 -0.08746338 ..., -0.24255371  0.95019531
  -0.84228516]
 ...,
 [-0.01300049  0.11682129  0.06750488 ..., -0.34155273  0.95654297
  -0.86572266]
 [-0.00485992  0.01457214  0.0317688  ..., -0.58251953  0.91699219
   0.63085938]
 [-0.01300049  0.11682129  0.06750488 ..., -0.24255371  0.95019531
  -0.84228516]]
After layer decoder_rnn_l0_t0_i2h_output (20, 2048) <class 'numpy.float16'> [[-3.2265625   2.67773438  2.53125    ...,  0.05404663  4.11328125
   1.98144531]
 [-3.20898438  2.73046875  2.24609375 ..., -0.33959961  3.91601562
   1.96289062]
 [-3.38085938  2.75        2.54296875 ..., -0.43408203  4.02734375
   1.56152344]
 ...,
 [-3.33203125  2.67773438  2.29492188 ..., -0.15734863  3.9140625
   2.04101562]
 [-2.76171875  2.38867188  1.57714844 ..., -2.08007812  3.4453125   1.109375  ]
 [-3.50390625  2.69726562  2.58984375 ..., -0.25170898  4.02734375
   1.63964844]]
After layer decoder_rnn_l0_t0_h2h_output (20, 2048) <class 'numpy.float16'> [[-0.26977539  0.1307373   1.67285156 ...,  0.26098633  1.04003906
   1.12304688]
 [-0.30761719  0.17602539  1.60351562 ...,  0.04226685  1.02441406
   0.89013672]
 [-0.27905273  0.22070312  1.64355469 ...,  0.01293945  1.05078125
   0.78173828]
 ...,
 [-0.30761719  0.17602539  1.60351562 ...,  0.04226685  1.02441406
   0.89013672]
 [-0.40405273  0.3659668   1.41210938 ..., -0.47338867  1.0390625
   0.56835938]
 [-0.27905273  0.22070312  1.64355469 ...,  0.01293945  1.05078125
   0.78173828]]
After layer _plus1048_0 (20, 2048) <class 'numpy.float16'> [[-3.49609375  2.80859375  4.203125   ...,  0.31494141  5.15234375
   3.10546875]
 [-3.515625    2.90625     3.84960938 ..., -0.29736328  4.94140625
   2.85351562]
 [-3.66015625  2.97070312  4.1875     ..., -0.42114258  5.078125    2.34375   ]
 ...,
 [-3.640625    2.85351562  3.8984375  ..., -0.1151123   4.9375      2.93164062]
 [-3.16601562  2.75390625  2.98828125 ..., -2.55273438  4.484375
   1.67773438]
 [-3.78320312  2.91796875  4.234375   ..., -0.23876953  5.078125    2.421875  ]]
After layer decoder_rnn_l0_t0_slice_output0 (20, 512) <class 'numpy.float16'> [[-3.49609375  2.80859375  4.203125   ...,  2.48828125  5.16796875
   1.89355469]
 [-3.515625    2.90625     3.84960938 ...,  2.29882812  5.0234375
   1.84960938]
 [-3.66015625  2.97070312  4.1875     ...,  2.328125    5.39453125
   1.77148438]
 ...,
 [-3.640625    2.85351562  3.8984375  ...,  2.33984375  4.921875
   1.96289062]
 [-3.16601562  2.75390625  2.98828125 ...,  2.21679688  4.8359375
   1.12890625]
 [-3.78320312  2.91796875  4.234375   ...,  2.36914062  5.29296875
   1.88476562]]
After layer decoder_rnn_l0_t0_slice_output1 (20, 512) <class 'numpy.float16'> [[-2.93554688  2.359375    2.5625     ...,  3.0234375  -1.68164062
   2.0546875 ]
 [-3.08203125  2.29296875  2.34375    ...,  2.50390625 -1.72753906
   1.86914062]
 [-2.90820312  1.98535156  2.41015625 ...,  2.44921875 -1.58105469
   1.890625  ]
 ...,
 [-3.0703125   2.13476562  2.41601562 ...,  2.453125   -1.72949219
   1.91796875]
 [-2.83789062  1.5390625   2.04882812 ...,  1.20898438 -0.95800781
   1.32519531]
 [-2.8984375   1.82519531  2.48242188 ...,  2.3984375  -1.58398438
   1.94140625]]
After layer decoder_rnn_l0_t0_slice_output2 (20, 512) <class 'numpy.float16'> [[-2.93359375 -4.3125      3.89648438 ...,  5.28125     2.44140625
   2.71484375]
 [-2.921875   -3.9375      3.4375     ...,  4.9453125   1.015625    2.5625    ]
 [-2.93359375 -3.75        3.3203125  ...,  4.8828125   0.52832031
   2.49414062]
 ...,
 [-2.88671875 -3.9140625   3.46484375 ...,  4.8828125   1.28808594  2.5625    ]
 [-3.10351562 -2.55859375  2.19921875 ...,  3.625      -2.64648438
   2.33984375]
 [-2.8984375  -3.72851562  3.34765625 ...,  4.828125    0.79980469
   2.4921875 ]]
After layer decoder_rnn_l0_t0_slice_output3 (20, 512) <class 'numpy.float16'> [[-2.63085938  2.12890625 -0.33081055 ...,  0.31494141  5.15234375
   3.10546875]
 [-2.72070312  1.9921875  -0.48828125 ..., -0.29736328  4.94140625
   2.85351562]
 [-2.28125     1.35058594 -0.42602539 ..., -0.42114258  5.078125    2.34375   ]
 ...,
 [-2.80273438  1.52539062 -1.15234375 ..., -0.1151123   4.9375      2.93164062]
 [-1.50390625  0.73876953 -0.18493652 ..., -2.55273438  4.484375
   1.67773438]
 [-2.36328125  0.88476562 -1.08984375 ..., -0.23876953  5.078125    2.421875  ]]
After layer decoder_rnn_l0_t0_o_output (20, 512) <class 'numpy.float16'> [[ 0.06719971  0.89355469  0.41796875 ...,  0.578125    0.99414062
   0.95703125]
 [ 0.06176758  0.87988281  0.38037109 ...,  0.42626953  0.99267578
   0.9453125 ]
 [ 0.0927124   0.79443359  0.39501953 ...,  0.39624023  0.99365234
   0.91259766]
 ...,
 [ 0.05718994  0.82128906  0.2401123  ...,  0.47119141  0.99267578
   0.94921875]
 [ 0.18188477  0.67675781  0.45385742 ...,  0.07226562  0.98876953
   0.84277344]
 [ 0.08599854  0.70800781  0.25170898 ...,  0.44067383  0.99365234
   0.91845703]]
After layer decoder_rnn_l0_t0_f_output (20, 512) <class 'numpy.float16'> [[ 0.05041504  0.91357422  0.92822266 ...,  0.95361328  0.15686035
   0.88623047]
 [ 0.04385376  0.90820312  0.91259766 ...,  0.92431641  0.15087891
   0.86621094]
 [ 0.05175781  0.87939453  0.91748047 ...,  0.92041016  0.1706543
   0.86865234]
 ...,
 [ 0.04434204  0.89404297  0.91796875 ...,  0.92089844  0.15063477
   0.87207031]
 [ 0.05529785  0.82324219  0.88574219 ...,  0.77001953  0.27734375
   0.79003906]
 [ 0.05224609  0.86132812  0.92285156 ...,  0.91650391  0.17028809
   0.87451172]]
After layer _mul2096_0 (20, 512) <class 'numpy.float16'> [[-0.01737976 -0.85449219  1.0859375  ...,  1.22265625 -0.04840088
   0.86962891]
 [-0.01465607 -0.86621094  1.06542969 ...,  1.18652344 -0.06378174
   0.85498047]
 [-0.01994324 -0.81201172  1.07226562 ...,  1.18359375 -0.01985168
   0.87548828]
 ...,
 [-0.01482391 -0.85253906  1.07226562 ...,  1.18164062 -0.0637207
   0.86083984]
 [-0.02711487 -0.79589844  1.03417969 ...,  0.98876953 -0.09088135
   0.82177734]
 [-0.02012634 -0.79541016  1.07910156 ...,  1.17871094 -0.01980591
   0.88134766]]
After layer decoder_rnn_l0_t0_i_output (20, 512) <class 'numpy.float16'> [[ 0.02941895  0.94335938  0.98535156 ...,  0.92333984  0.99414062
   0.86914062]
 [ 0.02886963  0.94824219  0.97900391 ...,  0.90869141  0.99365234
   0.86425781]
 [ 0.02508545  0.95117188  0.98486328 ...,  0.91113281  0.99560547
   0.85449219]
 ...,
 [ 0.02555847  0.9453125   0.97998047 ...,  0.91210938  0.99267578
   0.87695312]
 [ 0.04046631  0.93994141  0.95214844 ...,  0.90185547  0.9921875
   0.75585938]
 [ 0.02224731  0.94873047  0.98583984 ...,  0.91455078  0.99511719
   0.86816406]]
After layer decoder_rnn_l0_t0_c_output (20, 512) <class 'numpy.float16'> [[-0.99414062 -0.99951172  0.99902344 ...,  1.          0.98486328
   0.99121094]
 [-0.99414062 -0.99902344  0.99804688 ...,  1.          0.76806641
   0.98828125]
 [-0.99414062 -0.99902344  0.99755859 ...,  1.          0.48413086
   0.98632812]
 ...,
 [-0.99365234 -0.99902344  0.99804688 ...,  1.          0.85839844
   0.98828125]
 [-0.99609375 -0.98828125  0.97558594 ...,  0.99853516 -0.99023438
   0.98144531]
 [-0.99414062 -0.99902344  0.99755859 ...,  1.          0.6640625
   0.98632812]]
After layer _mul2097_0 (20, 512) <class 'numpy.float16'> [[-0.0292511  -0.94287109  0.984375   ...,  0.92333984  0.97900391
   0.86132812]
 [-0.02870178 -0.94726562  0.97705078 ...,  0.90869141  0.76318359
   0.85400391]
 [-0.02493286 -0.95019531  0.98242188 ...,  0.91113281  0.48193359
   0.84277344]
 ...,
 [-0.02539062 -0.94433594  0.97802734 ...,  0.91210938  0.85205078
   0.86669922]
 [-0.04031372 -0.92871094  0.92871094 ...,  0.90039062 -0.98242188
   0.74169922]
 [-0.02210999 -0.94775391  0.98339844 ...,  0.91455078  0.66064453
   0.85644531]]
After layer decoder_rnn_l0_t0_state_0 (20, 512) <class 'numpy.float16'> [[-0.04663086 -1.796875    2.0703125  ...,  2.14648438  0.93066406
   1.73046875]
 [-0.04336548 -1.81347656  2.04296875 ...,  2.09570312  0.69921875
   1.70898438]
 [-0.04486084 -1.76171875  2.0546875  ...,  2.09375     0.4621582   1.71875   ]
 ...,
 [-0.04022217 -1.796875    2.05078125 ...,  2.09375     0.78808594
   1.72753906]
 [-0.06744385 -1.72460938  1.96289062 ...,  1.88867188 -1.07324219
   1.56347656]
 [-0.04223633 -1.74316406  2.0625     ...,  2.09375     0.640625
   1.73828125]]
After layer activation1048_output (20, 512) <class 'numpy.float16'> [[-0.04660034 -0.94628906  0.96875    ...,  0.97314453  0.73095703
   0.93896484]
 [-0.04333496 -0.94824219  0.96679688 ...,  0.97021484  0.60400391
   0.93652344]
 [-0.04483032 -0.94287109  0.96777344 ...,  0.97021484  0.43188477  0.9375    ]
 ...,
 [-0.04019165 -0.94628906  0.96728516 ...,  0.97021484  0.65722656
   0.93896484]
 [-0.06732178 -0.93847656  0.96142578 ...,  0.95507812 -0.79052734
   0.91601562]
 [-0.04220581 -0.94042969  0.96826172 ...,  0.97021484  0.56542969
   0.93994141]]
After layer decoder_rnn_l0_t0_out_0 (20, 512) <class 'numpy.float16'> [[-0.00313187 -0.84570312  0.40478516 ...,  0.5625      0.7265625
   0.8984375 ]
 [-0.00267601 -0.83447266  0.36767578 ...,  0.41357422  0.59960938
   0.88525391]
 [-0.00415802 -0.74902344  0.38232422 ...,  0.38452148  0.42919922
   0.85546875]
 ...,
 [-0.00229836 -0.77734375  0.2322998  ...,  0.45727539  0.65234375
   0.89111328]
 [-0.01224518 -0.63525391  0.4362793  ...,  0.06903076 -0.78173828
   0.77197266]
 [-0.00362968 -0.66601562  0.24377441 ...,  0.42749023  0.56201172
   0.86328125]]
After layer expand_dims1057_0 (20, 512, 1) <class 'numpy.float16'> [[[-0.00313187]
  [-0.84570312]
  [ 0.40478516]
  ...,
  [ 0.5625    ]
  [ 0.7265625 ]
  [ 0.8984375 ]]

 [[-0.00267601]
  [-0.83447266]
  [ 0.36767578]
  ...,
  [ 0.41357422]
  [ 0.59960938]
  [ 0.88525391]]

 [[-0.00415802]
  [-0.74902344]
  [ 0.38232422]
  ...,
  [ 0.38452148]
  [ 0.42919922]
  [ 0.85546875]]

 ...,
 [[-0.00229836]
  [-0.77734375]
  [ 0.2322998 ]
  ...,
  [ 0.45727539]
  [ 0.65234375]
  [ 0.89111328]]

 [[-0.01224518]
  [-0.63525391]
  [ 0.4362793 ]
  ...,
  [ 0.06903076]
  [-0.78173828]
  [ 0.77197266]]

 [[-0.00362968]
  [-0.66601562]
  [ 0.24377441]
  ...,
  [ 0.42749023]
  [ 0.56201172]
  [ 0.86328125]]]
After layer att_batch_dot_0 (20, 10, 1) <class 'numpy.float16'> [[[  0.53955078]
  [  0.78222656]
  [  1.41699219]
  [  2.171875  ]
  [  2.00390625]
  [ -0.05740356]
  [ -2.97265625]
  [ -5.46484375]
  [ -7.2890625 ]
  [ -8.6640625 ]]

 [[  0.53759766]
  [  0.71923828]
  [  1.36230469]
  [  2.08789062]
  [  1.89453125]
  [ -0.14978027]
  [ -3.00585938]
  [ -5.421875  ]
  [ -7.16796875]
  [ -8.4609375 ]]

 [[  0.51513672]
  [  0.69677734]
  [  1.41796875]
  [  2.24023438]
  [  2.13085938]
  [  0.10888672]
  [ -2.76757812]
  [ -5.2109375 ]
  [ -6.9765625 ]
  [ -8.28125   ]]

 [[  0.52246094]
  [  0.79931641]
  [  1.47851562]
  [  2.31640625]
  [  2.26171875]
  [  0.3293457 ]
  [ -2.46875   ]
  [ -4.8671875 ]
  [ -6.62109375]
  [ -7.93359375]]

 [[  0.55273438]
  [  0.75927734]
  [  1.35546875]
  [  2.04296875]
  [  1.82226562]
  [ -0.2286377 ]
  [ -3.08984375]
  [ -5.51953125]
  [ -7.2890625 ]
  [ -8.6171875 ]]

 [[  0.53857422]
  [  0.73144531]
  [  1.38574219]
  [  2.13671875]
  [  1.97851562]
  [ -0.03089905]
  [ -2.86328125]
  [ -5.26953125]
  [ -7.01171875]
  [ -8.3046875 ]]

 [[  0.53076172]
  [  0.74267578]
  [  1.41601562]
  [  2.203125  ]
  [  2.08007812]
  [  0.08520508]
  [ -2.75195312]
  [ -5.1640625 ]
  [ -6.9140625 ]
  [ -8.21875   ]]

 [[  0.53076172]
  [  0.68359375]
  [  1.36621094]
  [  2.12304688]
  [  1.95117188]
  [ -0.08935547]
  [ -2.95117188]
  [ -5.3671875 ]
  [ -7.1015625 ]
  [ -8.3828125 ]]

 [[  0.44384766]
  [  0.11224365]
  [  0.20544434]
  [ -0.29760742]
  [ -2.38085938]
  [ -6.59375   ]
  [-11.3359375 ]
  [-15.078125  ]
  [-17.59375   ]
  [-19.28125   ]]

 [[  0.51367188]
  [  0.66455078]
  [  1.37597656]
  [  2.16015625]
  [  2.        ]
  [ -0.05862427]
  [ -2.95117188]
  [ -5.3984375 ]
  [ -7.15625   ]
  [ -8.4453125 ]]

 [[  0.53027344]
  [  0.64111328]
  [  1.30761719]
  [  2.00976562]
  [  1.7578125 ]
  [ -0.37182617]
  [ -3.30664062]
  [ -5.7734375 ]
  [ -7.5390625 ]
  [ -8.8359375 ]]

 [[  0.93115234]
  [  2.41796875]
  [  5.2890625 ]
  [ 10.0390625 ]
  [ 15.8203125 ]
  [ 20.71875   ]
  [ 24.21875   ]
  [ 26.671875  ]
  [ 28.28125   ]
  [ 29.21875   ]]

 [[  0.5234375 ]
  [  0.70019531]
  [  1.42871094]
  [  2.25976562]
  [  2.19335938]
  [  0.2722168 ]
  [ -2.484375  ]
  [ -4.828125  ]
  [ -6.51171875]
  [ -7.75390625]]

 [[  0.51318359]
  [  0.64746094]
  [  1.36621094]
  [  2.1484375 ]
  [  1.99511719]
  [ -0.03930664]
  [ -2.89453125]
  [ -5.30078125]
  [ -7.015625  ]
  [ -8.2734375 ]]

 [[  0.53076172]
  [  0.65625   ]
  [  1.34863281]
  [  2.09179688]
  [  1.9140625 ]
  [ -0.09942627]
  [ -2.9140625 ]
  [ -5.2890625 ]
  [ -6.98828125]
  [ -8.234375  ]]

 [[  0.64208984]
  [  0.99755859]
  [  2.44726562]
  [  4.41015625]
  [  6.26171875]
  [  6.90625   ]
  [  6.6328125 ]
  [  6.12890625]
  [  5.58984375]
  [  5.00390625]]

 [[  0.50634766]
  [  0.63085938]
  [  1.34863281]
  [  2.11523438]
  [  1.93164062]
  [ -0.14477539]
  [ -3.04296875]
  [ -5.484375  ]
  [ -7.23046875]
  [ -8.515625  ]]

 [[  0.69335938]
  [  1.40527344]
  [  2.96289062]
  [  5.3359375 ]
  [  7.609375  ]
  [  8.4375    ]
  [  8.1953125 ]
  [  7.73046875]
  [  7.296875  ]
  [  6.84375   ]]

 [[  0.26196289]
  [ -0.54296875]
  [ -1.11328125]
  [ -2.765625  ]
  [ -6.40625   ]
  [-12.265625  ]
  [-18.46875   ]
  [-23.4375    ]
  [-26.96875   ]
  [-29.484375  ]]

 [[  0.67333984]
  [  1.39453125]
  [  3.03125   ]
  [  5.5078125 ]
  [  7.8828125 ]
  [  8.765625  ]
  [  8.5390625 ]
  [  8.09375   ]
  [  7.671875  ]
  [  7.23046875]]]
After layer swapaxes17_output (10, 20, 1) <class 'numpy.float16'> [[[  0.53955078]
  [  0.53759766]
  [  0.51513672]
  [  0.52246094]
  [  0.55273438]
  [  0.53857422]
  [  0.53076172]
  [  0.53076172]
  [  0.44384766]
  [  0.51367188]
  [  0.53027344]
  [  0.93115234]
  [  0.5234375 ]
  [  0.51318359]
  [  0.53076172]
  [  0.64208984]
  [  0.50634766]
  [  0.69335938]
  [  0.26196289]
  [  0.67333984]]

 [[  0.78222656]
  [  0.71923828]
  [  0.69677734]
  [  0.79931641]
  [  0.75927734]
  [  0.73144531]
  [  0.74267578]
  [  0.68359375]
  [  0.11224365]
  [  0.66455078]
  [  0.64111328]
  [  2.41796875]
  [  0.70019531]
  [  0.64746094]
  [  0.65625   ]
  [  0.99755859]
  [  0.63085938]
  [  1.40527344]
  [ -0.54296875]
  [  1.39453125]]

 [[  1.41699219]
  [  1.36230469]
  [  1.41796875]
  [  1.47851562]
  [  1.35546875]
  [  1.38574219]
  [  1.41601562]
  [  1.36621094]
  [  0.20544434]
  [  1.37597656]
  [  1.30761719]
  [  5.2890625 ]
  [  1.42871094]
  [  1.36621094]
  [  1.34863281]
  [  2.44726562]
  [  1.34863281]
  [  2.96289062]
  [ -1.11328125]
  [  3.03125   ]]

 [[  2.171875  ]
  [  2.08789062]
  [  2.24023438]
  [  2.31640625]
  [  2.04296875]
  [  2.13671875]
  [  2.203125  ]
  [  2.12304688]
  [ -0.29760742]
  [  2.16015625]
  [  2.00976562]
  [ 10.0390625 ]
  [  2.25976562]
  [  2.1484375 ]
  [  2.09179688]
  [  4.41015625]
  [  2.11523438]
  [  5.3359375 ]
  [ -2.765625  ]
  [  5.5078125 ]]

 [[  2.00390625]
  [  1.89453125]
  [  2.13085938]
  [  2.26171875]
  [  1.82226562]
  [  1.97851562]
  [  2.08007812]
  [  1.95117188]
  [ -2.38085938]
  [  2.        ]
  [  1.7578125 ]
  [ 15.8203125 ]
  [  2.19335938]
  [  1.99511719]
  [  1.9140625 ]
  [  6.26171875]
  [  1.93164062]
  [  7.609375  ]
  [ -6.40625   ]
  [  7.8828125 ]]

 [[ -0.05740356]
  [ -0.14978027]
  [  0.10888672]
  [  0.3293457 ]
  [ -0.2286377 ]
  [ -0.03089905]
  [  0.08520508]
  [ -0.08935547]
  [ -6.59375   ]
  [ -0.05862427]
  [ -0.37182617]
  [ 20.71875   ]
  [  0.2722168 ]
  [ -0.03930664]
  [ -0.09942627]
  [  6.90625   ]
  [ -0.14477539]
  [  8.4375    ]
  [-12.265625  ]
  [  8.765625  ]]

 [[ -2.97265625]
  [ -3.00585938]
  [ -2.76757812]
  [ -2.46875   ]
  [ -3.08984375]
  [ -2.86328125]
  [ -2.75195312]
  [ -2.95117188]
  [-11.3359375 ]
  [ -2.95117188]
  [ -3.30664062]
  [ 24.21875   ]
  [ -2.484375  ]
  [ -2.89453125]
  [ -2.9140625 ]
  [  6.6328125 ]
  [ -3.04296875]
  [  8.1953125 ]
  [-18.46875   ]
  [  8.5390625 ]]

 [[ -5.46484375]
  [ -5.421875  ]
  [ -5.2109375 ]
  [ -4.8671875 ]
  [ -5.51953125]
  [ -5.26953125]
  [ -5.1640625 ]
  [ -5.3671875 ]
  [-15.078125  ]
  [ -5.3984375 ]
  [ -5.7734375 ]
  [ 26.671875  ]
  [ -4.828125  ]
  [ -5.30078125]
  [ -5.2890625 ]
  [  6.12890625]
  [ -5.484375  ]
  [  7.73046875]
  [-23.4375    ]
  [  8.09375   ]]

 [[ -7.2890625 ]
  [ -7.16796875]
  [ -6.9765625 ]
  [ -6.62109375]
  [ -7.2890625 ]
  [ -7.01171875]
  [ -6.9140625 ]
  [ -7.1015625 ]
  [-17.59375   ]
  [ -7.15625   ]
  [ -7.5390625 ]
  [ 28.28125   ]
  [ -6.51171875]
  [ -7.015625  ]
  [ -6.98828125]
  [  5.58984375]
  [ -7.23046875]
  [  7.296875  ]
  [-26.96875   ]
  [  7.671875  ]]

 [[ -8.6640625 ]
  [ -8.4609375 ]
  [ -8.28125   ]
  [ -7.93359375]
  [ -8.6171875 ]
  [ -8.3046875 ]
  [ -8.21875   ]
  [ -8.3828125 ]
  [-19.28125   ]
  [ -8.4453125 ]
  [ -8.8359375 ]
  [ 29.21875   ]
  [ -7.75390625]
  [ -8.2734375 ]
  [ -8.234375  ]
  [  5.00390625]
  [ -8.515625  ]
  [  6.84375   ]
  [-29.484375  ]
  [  7.23046875]]]
After layer sequencemask4_output (10, 20, 1) <class 'numpy.float16'> [[[  5.39550781e-01]
  [  5.37597656e-01]
  [  5.15136719e-01]
  [  5.22460938e-01]
  [  5.52734375e-01]
  [  5.38574219e-01]
  [  5.30761719e-01]
  [  5.30761719e-01]
  [  4.43847656e-01]
  [  5.13671875e-01]
  [  5.30273438e-01]
  [  9.31152344e-01]
  [  5.23437500e-01]
  [  5.13183594e-01]
  [  5.30761719e-01]
  [  6.42089844e-01]
  [  5.06347656e-01]
  [  6.93359375e-01]
  [  2.61962891e-01]
  [  6.73339844e-01]]

 [[  7.82226562e-01]
  [  7.19238281e-01]
  [  6.96777344e-01]
  [  7.99316406e-01]
  [  7.59277344e-01]
  [  7.31445312e-01]
  [  7.42675781e-01]
  [  6.83593750e-01]
  [  1.12243652e-01]
  [  6.64550781e-01]
  [  6.41113281e-01]
  [  2.41796875e+00]
  [  7.00195312e-01]
  [  6.47460938e-01]
  [  6.56250000e-01]
  [  9.97558594e-01]
  [  6.30859375e-01]
  [  1.40527344e+00]
  [ -5.42968750e-01]
  [  1.39453125e+00]]

 [[ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]]
After layer swapaxes18_output (20, 10, 1) <class 'numpy.float16'> [[[  5.39550781e-01]
  [  7.82226562e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  5.37597656e-01]
  [  7.19238281e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  5.15136719e-01]
  [  6.96777344e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  5.22460938e-01]
  [  7.99316406e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  5.52734375e-01]
  [  7.59277344e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  5.38574219e-01]
  [  7.31445312e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  5.30761719e-01]
  [  7.42675781e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  5.30761719e-01]
  [  6.83593750e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  4.43847656e-01]
  [  1.12243652e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  5.13671875e-01]
  [  6.64550781e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  5.30273438e-01]
  [  6.41113281e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  9.31152344e-01]
  [  2.41796875e+00]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  5.23437500e-01]
  [  7.00195312e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  5.13183594e-01]
  [  6.47460938e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  5.30761719e-01]
  [  6.56250000e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  6.42089844e-01]
  [  9.97558594e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  5.06347656e-01]
  [  6.30859375e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  6.93359375e-01]
  [  1.40527344e+00]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  2.61962891e-01]
  [ -5.42968750e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  6.73339844e-01]
  [  1.39453125e+00]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]]
After layer attention_softmax_0 (20, 10, 1) <class 'numpy.float16'> [[[ 0.43945312]
  [ 0.56005859]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.45458984]
  [ 0.54541016]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.45458984]
  [ 0.54541016]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.43139648]
  [ 0.56884766]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.44848633]
  [ 0.55126953]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.4519043 ]
  [ 0.54833984]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.44726562]
  [ 0.55273438]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.46191406]
  [ 0.53808594]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.58203125]
  [ 0.41796875]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.46240234]
  [ 0.53759766]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.47241211]
  [ 0.52783203]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.18444824]
  [ 0.81542969]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.45605469]
  [ 0.54394531]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.46630859]
  [ 0.53320312]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.46875   ]
  [ 0.53125   ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.41186523]
  [ 0.58789062]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.46899414]
  [ 0.53125   ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.3293457 ]
  [ 0.67089844]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.69091797]
  [ 0.30908203]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.32714844]
  [ 0.67285156]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]]
After layer batch_dot4_0 (20, 512, 1) <class 'numpy.float16'> [[[ 0.01696777]
  [ 0.03842163]
  [-0.0317688 ]
  ...,
  [-0.01076508]
  [ 0.00994873]
  [-0.0252533 ]]

 [[ 0.01661682]
  [ 0.0380249 ]
  [-0.03109741]
  ...,
  [-0.01068878]
  [ 0.00993347]
  [-0.02552795]]

 [[ 0.01661682]
  [ 0.0380249 ]
  [-0.03109741]
  ...,
  [-0.01068878]
  [ 0.00993347]
  [-0.02552795]]

 ...,
 [[ 0.01963806]
  [ 0.04153442]
  [-0.03674316]
  ...,
  [-0.01138306]
  [ 0.01007843]
  [-0.02331543]]

 [[ 0.01091003]
  [ 0.03143311]
  [-0.02047729]
  ...,
  [-0.00937653]
  [ 0.00965881]
  [-0.02970886]]

 [[ 0.01968384]
  [ 0.04156494]
  [-0.03683472]
  ...,
  [-0.01139069]
  [ 0.01007843]
  [-0.02326965]]]
After layer reshape8_0 (20, 512) <class 'numpy.float16'> [[ 0.01696777  0.03842163 -0.0317688  ..., -0.01076508  0.00994873
  -0.0252533 ]
 [ 0.01661682  0.0380249  -0.03109741 ..., -0.01068878  0.00993347
  -0.02552795]
 [ 0.01661682  0.0380249  -0.03109741 ..., -0.01068878  0.00993347
  -0.02552795]
 ...,
 [ 0.01963806  0.04153442 -0.03674316 ..., -0.01138306  0.01007843
  -0.02331543]
 [ 0.01091003  0.03143311 -0.02047729 ..., -0.00937653  0.00965881
  -0.02970886]
 [ 0.01968384  0.04156494 -0.03683472 ..., -0.01139069  0.01007843
  -0.02326965]]
After layer decoder_rnn_hidden_concat_t0_output (20, 1024) <class 'numpy.float16'> [[-0.00313187 -0.84570312  0.40478516 ..., -0.01076508  0.00994873
  -0.0252533 ]
 [-0.00267601 -0.83447266  0.36767578 ..., -0.01068878  0.00993347
  -0.02552795]
 [-0.00415802 -0.74902344  0.38232422 ..., -0.01068878  0.00993347
  -0.02552795]
 ...,
 [-0.00229836 -0.77734375  0.2322998  ..., -0.01138306  0.01007843
  -0.02331543]
 [-0.01224518 -0.63525391  0.4362793  ..., -0.00937653  0.00965881
  -0.02970886]
 [-0.00362968 -0.66601562  0.24377441 ..., -0.01139069  0.01007843
  -0.02326965]]
After layer decoder_rnn_hidden_fc_t0_output (20, 512) <class 'numpy.float16'> [[-0.89648438 -0.55908203  0.19702148 ...,  0.73535156  2.0703125
  -1.63378906]
 [-0.85839844 -0.49267578  0.12805176 ...,  0.79785156  1.9140625
  -1.33105469]
 [-0.84667969 -0.73730469  0.3034668  ...,  0.81494141  1.91308594
  -1.17382812]
 ...,
 [-1.02734375  0.03668213 -0.46777344 ...,  1.03320312  1.70898438
  -0.95605469]
 [ 0.18273926 -1.98339844  1.84179688 ..., -0.44580078  1.95800781
  -0.63671875]
 [-1.01757812 -0.18920898 -0.30981445 ...,  1.0390625   1.71191406
  -0.81103516]]
After layer decoder_rnn_next_hidden_t0_output (20, 512) <class 'numpy.float16'> [[-0.71435547 -0.50732422  0.19445801 ...,  0.62646484  0.96875    -0.92675781]
 [-0.6953125  -0.45629883  0.12731934 ...,  0.66259766  0.95751953
  -0.86962891]
 [-0.68945312 -0.62744141  0.29443359 ...,  0.67236328  0.95751953
  -0.82568359]
 ...,
 [-0.77294922  0.03665161 -0.4362793  ...,  0.77539062  0.93652344
  -0.74267578]
 [ 0.18078613 -0.96289062  0.95117188 ..., -0.41845703  0.9609375  -0.5625    ]
 [-0.76904297 -0.18701172 -0.30029297 ...,  0.77734375  0.93701172
  -0.66992188]]
After layer logits_output (20, 16743) <class 'numpy.float16'> [[-1.81152344 -3.19140625 -2.875      ..., -2.44726562 -3.5234375
  -3.06445312]
 [-1.71289062 -3.05859375 -2.6171875  ..., -2.33398438 -3.36132812
  -2.89257812]
 [-1.63183594 -3.12890625 -2.50976562 ..., -2.35546875 -3.24804688
  -2.88476562]
 ...,
 [-1.87695312 -2.77148438 -2.16796875 ..., -2.078125   -3.33789062
  -2.57226562]
 [-1.45800781 -3.23046875 -2.40625    ..., -2.50976562 -2.79882812
  -2.66210938]
 [-1.81933594 -2.84375    -2.06054688 ..., -2.13476562 -3.24414062
  -2.56835938]]
After layer softmax_0 (20, 16743) <class 'numpy.float16'> [[  1.01327896e-06   2.38418579e-07   3.57627869e-07 ...,   5.36441803e-07
    1.78813934e-07   2.98023224e-07]
 [  1.54972076e-06   4.17232513e-07   5.96046448e-07 ...,   8.34465027e-07
    2.98023224e-07   4.76837158e-07]
 [  1.90734863e-06   4.17232513e-07   7.74860382e-07 ...,   8.94069672e-07
    3.57627869e-07   5.36441803e-07]
 ...,
 [  3.75509262e-06   1.54972076e-06   2.86102295e-06 ...,   3.09944153e-06
    8.94069672e-07   1.90734863e-06]
 [  2.08616257e-06   3.57627869e-07   8.34465027e-07 ...,   7.15255737e-07
    5.36441803e-07   6.55651093e-07]
 [  4.11272049e-06   1.49011612e-06   3.21865082e-06 ...,   2.98023224e-06
    1.01327896e-06   1.96695328e-06]]
After layer reshape9_0 (20, 10) <class 'numpy.float16'> [[ 0.43945312  0.56005859  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.45458984  0.54541016  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.45458984  0.54541016  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.43139648  0.56884766  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.44848633  0.55126953  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.4519043   0.54833984  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.44726562  0.55273438  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.46191406  0.53808594  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.58203125  0.41796875  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.46240234  0.53759766  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.47241211  0.52783203  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.18444824  0.81542969  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.45605469  0.54394531  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.46630859  0.53320312  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.46875     0.53125     0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.41186523  0.58789062  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.46899414  0.53125     0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.3293457   0.67089844  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.69091797  0.30908203  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.32714844  0.67285156  0.          0.          0.          0.          0.
   0.          0.          0.        ]]
After layer target_embed_embed_0 (20, 256) <class 'numpy.float16'> [[-0.05505371 -0.0300293  -0.03598022 ...,  0.08459473 -0.05288696
  -0.01667786]
 [-0.05505371 -0.0300293  -0.03598022 ...,  0.08459473 -0.05288696
  -0.01667786]
 [ 0.08892822  0.08123779 -0.08746338 ...,  0.04257202  0.08666992
   0.03131104]
 ...,
 [-0.05505371 -0.0300293  -0.03598022 ...,  0.08459473 -0.05288696
  -0.01667786]
 [-0.05505371 -0.0300293  -0.03598022 ...,  0.08459473 -0.05288696
  -0.01667786]
 [ 0.20776367  0.12670898  0.05969238 ..., -0.14892578 -0.13439941
  -0.15319824]]
After layer decoder_rnn_concat_target_context_t0_output (20, 768) <class 'numpy.float16'> [[-0.05505371 -0.0300293  -0.03598022 ...,  0.62646484  0.96875    -0.92675781]
 [-0.05505371 -0.0300293  -0.03598022 ...,  0.66259766  0.95751953
  -0.86962891]
 [ 0.08892822  0.08123779 -0.08746338 ..., -0.31518555  0.96679688
  -0.92578125]
 ...,
 [-0.05505371 -0.0300293  -0.03598022 ...,  0.64990234  0.95068359
  -0.78759766]
 [-0.05505371 -0.0300293  -0.03598022 ...,  0.66210938  0.94726562
  -0.81201172]
 [ 0.20776367  0.12670898  0.05969238 ..., -0.31518555  0.96679688
  -0.92578125]]
After layer decoder_rnn_l0_t0_i2h_output (20, 2048) <class 'numpy.float16'> [[-3.43359375  2.07617188  2.44335938 ..., -0.25292969  4.0546875
   1.18554688]
 [-3.31445312  1.98730469  2.296875   ..., -0.26855469  3.91992188
   1.20703125]
 [-3.18164062  2.36132812  2.140625   ..., -0.19702148  3.91992188
   2.08984375]
 ...,
 [-3.26757812  2.0546875   2.19921875 ..., -0.34155273  3.8203125
   1.34960938]
 [-3.2109375   1.94238281  2.18554688 ..., -0.25610352  3.80078125
   1.27539062]
 [-3.37695312  2.1015625   2.15039062 ...,  0.45678711  3.9921875
   2.5234375 ]]
After layer decoder_rnn_l0_t0_h2h_output (20, 2048) <class 'numpy.float16'> [[-0.4543457   0.27783203  1.70898438 ...,  0.43481445  1.13671875
   0.83496094]
 [-0.47192383  0.28051758  1.62988281 ...,  0.29736328  1.09375     0.75      ]
 [-0.57324219  0.20483398  1.70605469 ...,  0.0559082   1.15917969
   1.1640625 ]
 ...,
 [-0.50439453  0.32006836  1.63867188 ...,  0.13830566  1.09472656
   0.6640625 ]
 [-0.50927734  0.31787109  1.60058594 ...,  0.18115234  1.0703125
   0.66699219]
 [-0.57324219  0.20483398  1.70605469 ...,  0.0559082   1.15917969
   1.1640625 ]]
After layer _plus1049_0 (20, 2048) <class 'numpy.float16'> [[-3.88867188  2.35351562  4.15234375 ...,  0.18188477  5.19140625
   2.01953125]
 [-3.78710938  2.26757812  3.92578125 ...,  0.02880859  5.015625
   1.95703125]
 [-3.75390625  2.56640625  3.84765625 ..., -0.14111328  5.078125
   3.25390625]
 ...,
 [-3.77148438  2.375       3.83789062 ..., -0.20324707  4.9140625
   2.01367188]
 [-3.72070312  2.25976562  3.78515625 ..., -0.07495117  4.87109375
   1.94238281]
 [-3.94921875  2.30664062  3.85546875 ...,  0.51269531  5.15234375  3.6875    ]]
After layer decoder_rnn_l0_t0_slice_output0 (20, 512) <class 'numpy.float16'> [[-3.88867188  2.35351562  4.15234375 ...,  2.13085938  5.05078125
   2.51757812]
 [-3.78710938  2.26757812  3.92578125 ...,  1.9296875   4.84375     2.48046875]
 [-3.75390625  2.56640625  3.84765625 ...,  2.19335938  4.7734375   2.        ]
 ...,
 [-3.77148438  2.375       3.83789062 ...,  1.87792969  4.7578125
   2.37109375]
 [-3.72070312  2.25976562  3.78515625 ...,  1.82714844  4.6640625
   2.38671875]
 [-3.94921875  2.30664062  3.85546875 ...,  2.27539062  4.65234375
   2.16015625]]
After layer decoder_rnn_l0_t0_slice_output1 (20, 512) <class 'numpy.float16'> [[-2.38085938  2.32617188  2.63085938 ...,  2.8515625  -1.390625
   2.15039062]
 [-2.484375    2.3671875   2.4453125  ...,  2.66796875 -1.37304688
   1.93261719]
 [-2.796875    2.61523438  2.53515625 ...,  2.609375   -1.90039062
   1.57617188]
 ...,
 [-2.78320312  2.453125    2.32421875 ...,  2.53515625 -1.31640625
   1.74609375]
 [-2.65429688  2.40820312  2.296875   ...,  2.51757812 -1.33789062
   1.66796875]
 [-2.75976562  1.82226562  2.59375    ...,  2.73828125 -1.56835938
   1.76171875]]
After layer decoder_rnn_l0_t0_slice_output2 (20, 512) <class 'numpy.float16'> [[-2.8671875  -3.30078125  3.0546875  ...,  4.52734375  0.48828125
   2.13085938]
 [-2.70507812 -3.10546875  2.79101562 ...,  4.41796875  0.18701172
   2.04492188]
 [-2.83203125 -3.7578125   3.50976562 ...,  5.0546875   1.4453125
   2.20898438]
 ...,
 [-2.71484375 -3.04296875  2.69921875 ...,  4.4921875  -0.1184082
   2.07421875]
 [-2.58789062 -3.          2.6640625  ...,  4.3359375  -0.05566406
   2.00390625]
 [-2.84960938 -3.68945312  3.51171875 ...,  5.109375    2.38671875
   2.34765625]]
After layer decoder_rnn_l0_t0_slice_output3 (20, 512) <class 'numpy.float16'> [[-3.44921875  2.12890625 -1.27539062 ...,  0.18188477  5.19140625
   2.01953125]
 [-3.41210938  2.22460938 -1.32226562 ...,  0.02880859  5.015625
   1.95703125]
 [-3.30664062  2.37304688 -0.68652344 ..., -0.14111328  5.078125
   3.25390625]
 ...,
 [-3.4609375   2.26953125 -1.21386719 ..., -0.20324707  4.9140625
   2.01367188]
 [-3.42578125  2.34765625 -1.26855469 ..., -0.07495117  4.87109375
   1.94238281]
 [-3.34960938  0.92773438 -2.8671875  ...,  0.51269531  5.15234375  3.6875    ]]
After layer decoder_rnn_l0_t0_o_output (20, 512) <class 'numpy.float16'> [[ 0.03079224  0.89355469  0.21838379 ...,  0.54541016  0.99462891
   0.8828125 ]
 [ 0.03192139  0.90234375  0.21044922 ...,  0.50732422  0.99365234
   0.87597656]
 [ 0.03533936  0.91455078  0.3347168  ...,  0.46484375  0.99365234
   0.96289062]
 ...,
 [ 0.03044128  0.90625     0.22900391 ...,  0.44946289  0.99267578
   0.88232422]
 [ 0.03149414  0.91259766  0.21948242 ...,  0.48120117  0.9921875
   0.87451172]
 [ 0.03390503  0.71679688  0.05380249 ...,  0.62548828  0.99414062
   0.97558594]]
After layer decoder_rnn_l0_t0_f_output (20, 512) <class 'numpy.float16'> [[ 0.08465576  0.91113281  0.93261719 ...,  0.9453125   0.19934082
   0.89550781]
 [ 0.07696533  0.9140625   0.92041016 ...,  0.93505859  0.20214844
   0.87353516]
 [ 0.05749512  0.93164062  0.92675781 ...,  0.93164062  0.13000488
   0.82861328]
 ...,
 [ 0.05822754  0.92089844  0.91064453 ...,  0.92675781  0.21142578
   0.8515625 ]
 [ 0.06573486  0.91748047  0.90869141 ...,  0.92529297  0.20788574
   0.84130859]
 [ 0.05953979  0.86083984  0.93066406 ...,  0.93945312  0.17248535
   0.85351562]]
After layer _mul2098_0 (20, 512) <class 'numpy.float16'> [[-0.00394821 -1.63671875  1.93066406 ...,  2.02929688  0.18554688
   1.54980469]
 [-0.00333786 -1.65722656  1.87988281 ...,  1.95996094  0.14135742
   1.49316406]
 [-0.0043602  -1.51757812  1.82226562 ...,  1.7734375  -0.13562012
   1.30371094]
 ...,
 [-0.00279999 -1.62695312  1.86230469 ...,  1.91308594 -0.02388     1.45019531]
 [-0.00315475 -1.63769531  1.83203125 ...,  1.8828125  -0.03988647
   1.42578125]
 [-0.00451279 -1.40234375  1.83007812 ...,  1.78808594 -0.17993164
   1.34277344]]
After layer decoder_rnn_l0_t0_i_output (20, 512) <class 'numpy.float16'> [[ 0.02006531  0.91308594  0.984375   ...,  0.89404297  0.99365234
   0.92529297]
 [ 0.02215576  0.90625     0.98046875 ...,  0.87304688  0.9921875
   0.92285156]
 [ 0.02288818  0.92871094  0.97900391 ...,  0.89941406  0.99169922
   0.88085938]
 ...,
 [ 0.02250671  0.91503906  0.97900391 ...,  0.8671875   0.99169922
   0.91455078]
 [ 0.02365112  0.90527344  0.97802734 ...,  0.86132812  0.99072266
   0.91601562]
 [ 0.01890564  0.90966797  0.97949219 ...,  0.90673828  0.99072266
   0.89648438]]
After layer decoder_rnn_l0_t0_c_output (20, 512) <class 'numpy.float16'> [[-0.99365234 -0.99707031  0.99560547 ...,  1.          0.45288086
   0.97216797]
 [-0.99121094 -0.99609375  0.99267578 ...,  0.99951172  0.18481445
   0.96728516]
 [-0.99316406 -0.99902344  0.99804688 ...,  1.          0.89453125
   0.97607422]
 ...,
 [-0.99121094 -0.99560547  0.99121094 ...,  0.99951172 -0.11785889  0.96875   ]
 [-0.98876953 -0.99511719  0.99023438 ...,  0.99951172 -0.05560303
   0.96435547]
 [-0.99316406 -0.99853516  0.99804688 ...,  1.          0.98339844
   0.98193359]]
After layer _mul2099_0 (20, 512) <class 'numpy.float16'> [[-0.01994324 -0.91064453  0.97998047 ...,  0.89404297  0.44995117
   0.89941406]
 [-0.0219574  -0.90283203  0.97314453 ...,  0.87255859  0.18334961
   0.89257812]
 [-0.0227356  -0.92773438  0.97705078 ...,  0.89941406  0.88720703
   0.85986328]
 ...,
 [-0.02230835 -0.91113281  0.97021484 ...,  0.86669922 -0.11688232
   0.88574219]
 [-0.02339172 -0.90087891  0.96826172 ...,  0.86083984 -0.05508423
   0.88330078]
 [-0.01878357 -0.90820312  0.97753906 ...,  0.90673828  0.97412109
   0.88037109]]
After layer decoder_rnn_l0_t0_state_0 (20, 512) <class 'numpy.float16'> [[-0.02389526 -2.546875    2.91015625 ...,  2.92382812  0.63574219
   2.44921875]
 [-0.02529907 -2.56054688  2.85351562 ...,  2.83203125  0.32470703
   2.38671875]
 [-0.02709961 -2.4453125   2.79882812 ...,  2.671875    0.75146484
   2.1640625 ]
 ...,
 [-0.02511597 -2.5390625   2.83203125 ...,  2.77929688 -0.14074707
   2.3359375 ]
 [-0.02655029 -2.5390625   2.80078125 ...,  2.74414062 -0.0949707
   2.30859375]
 [-0.02330017 -2.31054688  2.80859375 ...,  2.6953125   0.79394531
   2.22265625]]
After layer activation1049_output (20, 512) <class 'numpy.float16'> [[-0.02389526 -0.98779297  0.99414062 ...,  0.99414062  0.56201172
   0.98535156]
 [-0.02529907 -0.98828125  0.99316406 ...,  0.99316406  0.3137207
   0.98339844]
 [-0.02709961 -0.98486328  0.99267578 ...,  0.99072266  0.63623047
   0.97412109]
 ...,
 [-0.02511597 -0.98779297  0.99316406 ...,  0.9921875  -0.13977051
   0.98144531]
 [-0.02655029 -0.98779297  0.99267578 ...,  0.99169922 -0.09466553
   0.98046875]
 [-0.02330017 -0.98046875  0.99267578 ...,  0.99072266  0.66064453
   0.9765625 ]]
After layer decoder_rnn_l0_t0_out_0 (20, 512) <class 'numpy.float16'> [[ -7.35759735e-04  -8.82812500e-01   2.17163086e-01 ...,   5.41992188e-01
    5.59082031e-01   8.70117188e-01]
 [ -8.07762146e-04  -8.91601562e-01   2.08984375e-01 ...,   5.03906250e-01
    3.11767578e-01   8.61328125e-01]
 [ -9.57489014e-04  -9.00878906e-01   3.32275391e-01 ...,   4.60449219e-01
    6.32324219e-01   9.37988281e-01]
 ...,
 [ -7.64369965e-04  -8.95019531e-01   2.27416992e-01 ...,   4.46044922e-01
   -1.38793945e-01   8.65722656e-01]
 [ -8.36372375e-04  -9.01367188e-01   2.17895508e-01 ...,   4.77294922e-01
   -9.39331055e-02   8.57421875e-01]
 [ -7.90119171e-04  -7.02636719e-01   5.34057617e-02 ...,   6.19628906e-01
    6.56738281e-01   9.52636719e-01]]
After layer expand_dims1058_0 (20, 512, 1) <class 'numpy.float16'> [[[ -7.35759735e-04]
  [ -8.82812500e-01]
  [  2.17163086e-01]
  ...,
  [  5.41992188e-01]
  [  5.59082031e-01]
  [  8.70117188e-01]]

 [[ -8.07762146e-04]
  [ -8.91601562e-01]
  [  2.08984375e-01]
  ...,
  [  5.03906250e-01]
  [  3.11767578e-01]
  [  8.61328125e-01]]

 [[ -9.57489014e-04]
  [ -9.00878906e-01]
  [  3.32275391e-01]
  ...,
  [  4.60449219e-01]
  [  6.32324219e-01]
  [  9.37988281e-01]]

 ...,
 [[ -7.64369965e-04]
  [ -8.95019531e-01]
  [  2.27416992e-01]
  ...,
  [  4.46044922e-01]
  [ -1.38793945e-01]
  [  8.65722656e-01]]

 [[ -8.36372375e-04]
  [ -9.01367188e-01]
  [  2.17895508e-01]
  ...,
  [  4.77294922e-01]
  [ -9.39331055e-02]
  [  8.57421875e-01]]

 [[ -7.90119171e-04]
  [ -7.02636719e-01]
  [  5.34057617e-02]
  ...,
  [  6.19628906e-01]
  [  6.56738281e-01]
  [  9.52636719e-01]]]
After layer att_batch_dot_0 (20, 10, 1) <class 'numpy.float16'> [[[  0.45068359]
  [  0.72607422]
  [  1.25878906]
  [  1.89648438]
  [  1.45507812]
  [ -1.04980469]
  [ -4.44140625]
  [ -7.34765625]
  [ -9.4921875 ]
  [-11.0859375 ]]

 [[  0.45629883]
  [  0.70654297]
  [  1.23242188]
  [  1.84570312]
  [  1.35644531]
  [ -1.21582031]
  [ -4.66796875]
  [ -7.61328125]
  [ -9.7734375 ]
  [-11.359375  ]]

 [[  0.53955078]
  [  0.71435547]
  [  1.28808594]
  [  1.88476562]
  [  1.41992188]
  [ -1.01953125]
  [ -4.26953125]
  [ -7.00390625]
  [ -8.9921875 ]
  [-10.46875   ]]

 [[  0.47729492]
  [  0.72070312]
  [  1.29980469]
  [  1.97167969]
  [  1.55761719]
  [ -0.9296875 ]
  [ -4.296875  ]
  [ -7.1640625 ]
  [ -9.25      ]
  [-10.7734375 ]]

 [[  0.44360352]
  [  0.72802734]
  [  1.26269531]
  [  1.91113281]
  [  1.47070312]
  [ -1.0546875 ]
  [ -4.48046875]
  [ -7.42578125]
  [ -9.6015625 ]
  [-11.203125  ]]

 [[  0.44238281]
  [  0.70019531]
  [  1.19335938]
  [  1.77148438]
  [  1.2421875 ]
  [ -1.3671875 ]
  [ -4.85546875]
  [ -7.83984375]
  [-10.046875  ]
  [-11.671875  ]]

 [[  0.58496094]
  [  0.70800781]
  [  1.27539062]
  [  1.84472656]
  [  1.41015625]
  [ -0.90332031]
  [ -3.9921875 ]
  [ -6.6015625 ]
  [ -8.5       ]
  [ -9.9140625 ]]

 [[  0.45410156]
  [  0.70800781]
  [  1.23632812]
  [  1.85644531]
  [  1.37695312]
  [ -1.18554688]
  [ -4.6328125 ]
  [ -7.578125  ]
  [ -9.7421875 ]
  [-11.3359375 ]]

 [[  0.45581055]
  [  0.71826172]
  [  1.26269531]
  [  1.91015625]
  [  1.46679688]
  [ -1.05859375]
  [ -4.47265625]
  [ -7.39453125]
  [ -9.5390625 ]
  [-11.125     ]]

 [[  0.46826172]
  [  0.70019531]
  [  1.24707031]
  [  1.87207031]
  [  1.39257812]
  [ -1.16796875]
  [ -4.60546875]
  [ -7.5234375 ]
  [ -9.6484375 ]
  [-11.2109375 ]]

 [[  0.98193359]
  [  2.44140625]
  [  5.30859375]
  [ 10.        ]
  [ 15.6640625 ]
  [ 20.40625   ]
  [ 23.75      ]
  [ 26.0625    ]
  [ 27.546875  ]
  [ 28.390625  ]]

 [[  0.47119141]
  [  0.83154297]
  [  1.66113281]
  [  2.7265625 ]
  [  2.81640625]
  [  0.81835938]
  [ -2.1796875 ]
  [ -4.828125  ]
  [ -6.8203125 ]
  [ -8.3125    ]]

 [[  0.48608398]
  [  0.84082031]
  [  1.7109375 ]
  [  2.8203125 ]
  [  2.96875   ]
  [  1.04296875]
  [ -1.875     ]
  [ -4.4453125 ]
  [ -6.359375  ]
  [ -7.79296875]]

 [[  0.47802734]
  [  0.70263672]
  [  1.26953125]
  [  1.90917969]
  [  1.44628906]
  [ -1.09375   ]
  [ -4.50390625]
  [ -7.39453125]
  [ -9.4921875 ]
  [-11.015625  ]]

 [[  0.48242188]
  [  0.68896484]
  [  1.23925781]
  [  1.84472656]
  [  1.34863281]
  [ -1.20898438]
  [ -4.62109375]
  [ -7.50390625]
  [ -9.59375   ]
  [-11.109375  ]]

 [[  0.68701172]
  [  1.6796875 ]
  [  3.99609375]
  [  7.51953125]
  [ 11.296875  ]
  [ 13.671875  ]
  [ 14.640625  ]
  [ 14.8515625 ]
  [ 14.578125  ]
  [ 13.9765625 ]]

 [[  0.45922852]
  [  0.69482422]
  [  1.2421875 ]
  [  1.86816406]
  [  1.37402344]
  [ -1.22265625]
  [ -4.70703125]
  [ -7.67578125]
  [ -9.84375   ]
  [-11.421875  ]]

 [[  0.47558594]
  [  0.68652344]
  [  1.24609375]
  [  1.86425781]
  [  1.36816406]
  [ -1.20800781]
  [ -4.6484375 ]
  [ -7.5625    ]
  [ -9.671875  ]
  [-11.203125  ]]

 [[  0.4621582 ]
  [  0.67382812]
  [  1.20019531]
  [  1.77636719]
  [  1.21875   ]
  [ -1.43652344]
  [ -4.9609375 ]
  [ -7.9453125 ]
  [-10.1171875 ]
  [-11.703125  ]]

 [[  0.94091797]
  [  2.45507812]
  [  5.32421875]
  [ 10.0546875 ]
  [ 15.7421875 ]
  [ 20.453125  ]
  [ 23.75      ]
  [ 26.015625  ]
  [ 27.484375  ]
  [ 28.296875  ]]]
After layer swapaxes19_output (10, 20, 1) <class 'numpy.float16'> [[[  0.45068359]
  [  0.45629883]
  [  0.53955078]
  [  0.47729492]
  [  0.44360352]
  [  0.44238281]
  [  0.58496094]
  [  0.45410156]
  [  0.45581055]
  [  0.46826172]
  [  0.98193359]
  [  0.47119141]
  [  0.48608398]
  [  0.47802734]
  [  0.48242188]
  [  0.68701172]
  [  0.45922852]
  [  0.47558594]
  [  0.4621582 ]
  [  0.94091797]]

 [[  0.72607422]
  [  0.70654297]
  [  0.71435547]
  [  0.72070312]
  [  0.72802734]
  [  0.70019531]
  [  0.70800781]
  [  0.70800781]
  [  0.71826172]
  [  0.70019531]
  [  2.44140625]
  [  0.83154297]
  [  0.84082031]
  [  0.70263672]
  [  0.68896484]
  [  1.6796875 ]
  [  0.69482422]
  [  0.68652344]
  [  0.67382812]
  [  2.45507812]]

 [[  1.25878906]
  [  1.23242188]
  [  1.28808594]
  [  1.29980469]
  [  1.26269531]
  [  1.19335938]
  [  1.27539062]
  [  1.23632812]
  [  1.26269531]
  [  1.24707031]
  [  5.30859375]
  [  1.66113281]
  [  1.7109375 ]
  [  1.26953125]
  [  1.23925781]
  [  3.99609375]
  [  1.2421875 ]
  [  1.24609375]
  [  1.20019531]
  [  5.32421875]]

 [[  1.89648438]
  [  1.84570312]
  [  1.88476562]
  [  1.97167969]
  [  1.91113281]
  [  1.77148438]
  [  1.84472656]
  [  1.85644531]
  [  1.91015625]
  [  1.87207031]
  [ 10.        ]
  [  2.7265625 ]
  [  2.8203125 ]
  [  1.90917969]
  [  1.84472656]
  [  7.51953125]
  [  1.86816406]
  [  1.86425781]
  [  1.77636719]
  [ 10.0546875 ]]

 [[  1.45507812]
  [  1.35644531]
  [  1.41992188]
  [  1.55761719]
  [  1.47070312]
  [  1.2421875 ]
  [  1.41015625]
  [  1.37695312]
  [  1.46679688]
  [  1.39257812]
  [ 15.6640625 ]
  [  2.81640625]
  [  2.96875   ]
  [  1.44628906]
  [  1.34863281]
  [ 11.296875  ]
  [  1.37402344]
  [  1.36816406]
  [  1.21875   ]
  [ 15.7421875 ]]

 [[ -1.04980469]
  [ -1.21582031]
  [ -1.01953125]
  [ -0.9296875 ]
  [ -1.0546875 ]
  [ -1.3671875 ]
  [ -0.90332031]
  [ -1.18554688]
  [ -1.05859375]
  [ -1.16796875]
  [ 20.40625   ]
  [  0.81835938]
  [  1.04296875]
  [ -1.09375   ]
  [ -1.20898438]
  [ 13.671875  ]
  [ -1.22265625]
  [ -1.20800781]
  [ -1.43652344]
  [ 20.453125  ]]

 [[ -4.44140625]
  [ -4.66796875]
  [ -4.26953125]
  [ -4.296875  ]
  [ -4.48046875]
  [ -4.85546875]
  [ -3.9921875 ]
  [ -4.6328125 ]
  [ -4.47265625]
  [ -4.60546875]
  [ 23.75      ]
  [ -2.1796875 ]
  [ -1.875     ]
  [ -4.50390625]
  [ -4.62109375]
  [ 14.640625  ]
  [ -4.70703125]
  [ -4.6484375 ]
  [ -4.9609375 ]
  [ 23.75      ]]

 [[ -7.34765625]
  [ -7.61328125]
  [ -7.00390625]
  [ -7.1640625 ]
  [ -7.42578125]
  [ -7.83984375]
  [ -6.6015625 ]
  [ -7.578125  ]
  [ -7.39453125]
  [ -7.5234375 ]
  [ 26.0625    ]
  [ -4.828125  ]
  [ -4.4453125 ]
  [ -7.39453125]
  [ -7.50390625]
  [ 14.8515625 ]
  [ -7.67578125]
  [ -7.5625    ]
  [ -7.9453125 ]
  [ 26.015625  ]]

 [[ -9.4921875 ]
  [ -9.7734375 ]
  [ -8.9921875 ]
  [ -9.25      ]
  [ -9.6015625 ]
  [-10.046875  ]
  [ -8.5       ]
  [ -9.7421875 ]
  [ -9.5390625 ]
  [ -9.6484375 ]
  [ 27.546875  ]
  [ -6.8203125 ]
  [ -6.359375  ]
  [ -9.4921875 ]
  [ -9.59375   ]
  [ 14.578125  ]
  [ -9.84375   ]
  [ -9.671875  ]
  [-10.1171875 ]
  [ 27.484375  ]]

 [[-11.0859375 ]
  [-11.359375  ]
  [-10.46875   ]
  [-10.7734375 ]
  [-11.203125  ]
  [-11.671875  ]
  [ -9.9140625 ]
  [-11.3359375 ]
  [-11.125     ]
  [-11.2109375 ]
  [ 28.390625  ]
  [ -8.3125    ]
  [ -7.79296875]
  [-11.015625  ]
  [-11.109375  ]
  [ 13.9765625 ]
  [-11.421875  ]
  [-11.203125  ]
  [-11.703125  ]
  [ 28.296875  ]]]
After layer sequencemask5_output (10, 20, 1) <class 'numpy.float16'> [[[  4.50683594e-01]
  [  4.56298828e-01]
  [  5.39550781e-01]
  [  4.77294922e-01]
  [  4.43603516e-01]
  [  4.42382812e-01]
  [  5.84960938e-01]
  [  4.54101562e-01]
  [  4.55810547e-01]
  [  4.68261719e-01]
  [  9.81933594e-01]
  [  4.71191406e-01]
  [  4.86083984e-01]
  [  4.78027344e-01]
  [  4.82421875e-01]
  [  6.87011719e-01]
  [  4.59228516e-01]
  [  4.75585938e-01]
  [  4.62158203e-01]
  [  9.40917969e-01]]

 [[  7.26074219e-01]
  [  7.06542969e-01]
  [  7.14355469e-01]
  [  7.20703125e-01]
  [  7.28027344e-01]
  [  7.00195312e-01]
  [  7.08007812e-01]
  [  7.08007812e-01]
  [  7.18261719e-01]
  [  7.00195312e-01]
  [  2.44140625e+00]
  [  8.31542969e-01]
  [  8.40820312e-01]
  [  7.02636719e-01]
  [  6.88964844e-01]
  [  1.67968750e+00]
  [  6.94824219e-01]
  [  6.86523438e-01]
  [  6.73828125e-01]
  [  2.45507812e+00]]

 [[ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]]
After layer swapaxes20_output (20, 10, 1) <class 'numpy.float16'> [[[  4.50683594e-01]
  [  7.26074219e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  4.56298828e-01]
  [  7.06542969e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  5.39550781e-01]
  [  7.14355469e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  4.77294922e-01]
  [  7.20703125e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  4.43603516e-01]
  [  7.28027344e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  4.42382812e-01]
  [  7.00195312e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  5.84960938e-01]
  [  7.08007812e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  4.54101562e-01]
  [  7.08007812e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  4.55810547e-01]
  [  7.18261719e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  4.68261719e-01]
  [  7.00195312e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  9.81933594e-01]
  [  2.44140625e+00]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  4.71191406e-01]
  [  8.31542969e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  4.86083984e-01]
  [  8.40820312e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  4.78027344e-01]
  [  7.02636719e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  4.82421875e-01]
  [  6.88964844e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  6.87011719e-01]
  [  1.67968750e+00]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  4.59228516e-01]
  [  6.94824219e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  4.75585938e-01]
  [  6.86523438e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  4.62158203e-01]
  [  6.73828125e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  9.40917969e-01]
  [  2.45507812e+00]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]]
After layer attention_softmax_0 (20, 10, 1) <class 'numpy.float16'> [[[ 0.43139648]
  [ 0.56835938]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.4375    ]
  [ 0.56201172]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.45629883]
  [ 0.54345703]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.43945312]
  [ 0.56054688]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.42944336]
  [ 0.57080078]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.43579102]
  [ 0.56396484]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.46923828]
  [ 0.53076172]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.43701172]
  [ 0.56347656]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.43457031]
  [ 0.56494141]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.44238281]
  [ 0.55761719]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.18859863]
  [ 0.81152344]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.41088867]
  [ 0.58935547]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.41235352]
  [ 0.58789062]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.4440918 ]
  [ 0.55615234]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.44848633]
  [ 0.55126953]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.27026367]
  [ 0.72949219]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.44140625]
  [ 0.55859375]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.44726562]
  [ 0.55224609]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.44750977]
  [ 0.55273438]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.18041992]
  [ 0.81982422]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]]
After layer batch_dot5_0 (20, 512, 1) <class 'numpy.float16'> [[[ 0.01716614]
  [ 0.03866577]
  [-0.03213501]
  ...,
  [-0.01081085]
  [ 0.00995636]
  [-0.02511597]]

 [[ 0.01701355]
  [ 0.03848267]
  [-0.03182983]
  ...,
  [-0.01077271]
  [ 0.00994873]
  [-0.02522278]]

 [[ 0.01657104]
  [ 0.03796387]
  [-0.03100586]
  ...,
  [-0.01067352]
  [ 0.00992584]
  [-0.02555847]]

 ...,
 [[ 0.01676941]
  [ 0.03820801]
  [-0.03140259]
  ...,
  [-0.0107193 ]
  [ 0.00993347]
  [-0.02539062]]

 [[ 0.01678467]
  [ 0.03823853]
  [-0.03143311]
  ...,
  [-0.01072693]
  [ 0.0099411 ]
  [-0.02540588]]

 [[ 0.02323914]
  [ 0.04568481]
  [-0.04345703]
  ...,
  [-0.01220703]
  [ 0.01025391]
  [-0.02069092]]]
After layer reshape10_0 (20, 512) <class 'numpy.float16'> [[ 0.01716614  0.03866577 -0.03213501 ..., -0.01081085  0.00995636
  -0.02511597]
 [ 0.01701355  0.03848267 -0.03182983 ..., -0.01077271  0.00994873
  -0.02522278]
 [ 0.01657104  0.03796387 -0.03100586 ..., -0.01067352  0.00992584
  -0.02555847]
 ...,
 [ 0.01676941  0.03820801 -0.03140259 ..., -0.0107193   0.00993347
  -0.02539062]
 [ 0.01678467  0.03823853 -0.03143311 ..., -0.01072693  0.0099411
  -0.02540588]
 [ 0.02323914  0.04568481 -0.04345703 ..., -0.01220703  0.01025391
  -0.02069092]]
After layer decoder_rnn_hidden_concat_t0_output (20, 1024) <class 'numpy.float16'> [[ -7.35759735e-04  -8.82812500e-01   2.17163086e-01 ...,  -1.08108521e-02
    9.95635986e-03  -2.51159668e-02]
 [ -8.07762146e-04  -8.91601562e-01   2.08984375e-01 ...,  -1.07727051e-02
    9.94873047e-03  -2.52227783e-02]
 [ -9.57489014e-04  -9.00878906e-01   3.32275391e-01 ...,  -1.06735229e-02
    9.92584229e-03  -2.55584717e-02]
 ...,
 [ -7.64369965e-04  -8.95019531e-01   2.27416992e-01 ...,  -1.07192993e-02
    9.93347168e-03  -2.53906250e-02]
 [ -8.36372375e-04  -9.01367188e-01   2.17895508e-01 ...,  -1.07269287e-02
    9.94110107e-03  -2.54058838e-02]
 [ -7.90119171e-04  -7.02636719e-01   5.34057617e-02 ...,  -1.22070312e-02
    1.02539062e-02  -2.06909180e-02]]
After layer decoder_rnn_hidden_fc_t0_output (20, 512) <class 'numpy.float16'> [[-1.33984375 -0.09661865 -0.38330078 ...,  1.48828125  1.96972656
  -1.33886719]
 [-1.37792969 -0.02212524 -0.46582031 ...,  1.51269531  1.92382812
  -1.32324219]
 [-0.93310547 -0.47290039  0.04742432 ...,  0.86083984  2.0078125
  -1.46386719]
 ...,
 [-1.36328125 -0.06988525 -0.42553711 ...,  1.47167969  1.87304688
  -1.29003906]
 [-1.40039062 -0.00624466 -0.49414062 ...,  1.50390625  1.88671875
  -1.32519531]
 [-1.35644531  0.78808594 -1.38476562 ...,  1.25976562  1.55761719
  -0.54785156]]
After layer decoder_rnn_next_hidden_t0_output (20, 512) <class 'numpy.float16'> [[-0.87158203 -0.09631348 -0.36547852 ...,  0.90283203  0.96191406
  -0.87158203]
 [-0.88037109 -0.02212524 -0.43481445 ...,  0.90722656  0.95800781
  -0.86767578]
 [-0.73193359 -0.44042969  0.0473938  ...,  0.69677734  0.96435547
  -0.8984375 ]
 ...,
 [-0.87695312 -0.06976318 -0.40161133 ...,  0.89990234  0.95410156
  -0.859375  ]
 [-0.88525391 -0.00624466 -0.45751953 ...,  0.90576172  0.95507812
  -0.86816406]
 [-0.87548828  0.65722656 -0.88183594 ...,  0.85107422  0.91503906
  -0.49902344]]
After layer logits_output (20, 16743) <class 'numpy.float16'> [[-1.76855469 -2.91601562 -2.36523438 ..., -2.10351562 -3.36132812 -2.53125   ]
 [-1.77832031 -2.85351562 -2.33984375 ..., -2.08203125 -3.3359375  -2.5       ]
 [-1.7578125  -3.078125   -2.66601562 ..., -2.32421875 -3.41796875
  -2.8828125 ]
 ...,
 [-1.74414062 -2.8359375  -2.29492188 ..., -2.07421875 -3.2734375
  -2.51171875]
 [-1.77636719 -2.81640625 -2.32617188 ..., -2.08007812 -3.29882812
  -2.4921875 ]
 [-2.00195312 -2.33203125 -1.79394531 ..., -1.88671875 -3.13671875 -2.21875   ]]
After layer softmax_0 (20, 16743) <class 'numpy.float16'> [[  1.60932541e-06   4.76837158e-07   8.94069672e-07 ...,   1.13248825e-06
    2.98023224e-07   7.15255737e-07]
 [  1.60932541e-06   5.36441803e-07   8.94069672e-07 ...,   1.19209290e-06
    3.57627869e-07   7.74860382e-07]
 [  1.19209290e-06   2.98023224e-07   4.76837158e-07 ...,   6.55651093e-07
    2.38418579e-07   3.57627869e-07]
 ...,
 [  1.72853470e-06   5.96046448e-07   9.53674316e-07 ...,   1.19209290e-06
    3.57627869e-07   7.74860382e-07]
 [  1.60932541e-06   5.96046448e-07   8.94069672e-07 ...,   1.19209290e-06
    3.57627869e-07   7.74860382e-07]
 [  4.35113907e-06   3.09944153e-06   5.36441803e-06 ...,   4.94718552e-06
    1.43051147e-06   3.51667404e-06]]
After layer reshape11_0 (20, 10) <class 'numpy.float16'> [[ 0.43139648  0.56835938  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.4375      0.56201172  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.45629883  0.54345703  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.43945312  0.56054688  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.42944336  0.57080078  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.43579102  0.56396484  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.46923828  0.53076172  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.43701172  0.56347656  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.43457031  0.56494141  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.44238281  0.55761719  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.18859863  0.81152344  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.41088867  0.58935547  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.41235352  0.58789062  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.4440918   0.55615234  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.44848633  0.55126953  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.27026367  0.72949219  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.44140625  0.55859375  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.44726562  0.55224609  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.44750977  0.55273438  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.18041992  0.81982422  0.          0.          0.          0.          0.
   0.          0.          0.        ]]
After layer target_embed_embed_0 (20, 256) <class 'numpy.float16'> [[-0.05505371 -0.0300293  -0.03598022 ...,  0.08459473 -0.05288696
  -0.01667786]
 [-0.05505371 -0.0300293  -0.03598022 ...,  0.08459473 -0.05288696
  -0.01667786]
 [-0.05505371 -0.0300293  -0.03598022 ...,  0.08459473 -0.05288696
  -0.01667786]
 ...,
 [ 0.14013672  0.20153809 -0.07067871 ..., -0.01544189 -0.08544922
  -0.18017578]
 [ 0.13598633  0.02095032  0.05236816 ..., -0.01808167 -0.03991699
  -0.14160156]
 [ 0.01077271  0.03018188  0.03326416 ..., -0.03665161 -0.09197998
  -0.04290771]]
After layer decoder_rnn_concat_target_context_t0_output (20, 768) <class 'numpy.float16'> [[-0.05505371 -0.0300293  -0.03598022 ...,  0.90283203  0.96191406
  -0.87158203]
 [-0.05505371 -0.0300293  -0.03598022 ...,  0.90722656  0.95800781
  -0.86767578]
 [-0.05505371 -0.0300293  -0.03598022 ...,  0.69677734  0.96435547
  -0.8984375 ]
 ...,
 [ 0.14013672  0.20153809 -0.07067871 ...,  0.85107422  0.91503906
  -0.49902344]
 [ 0.13598633  0.02095032  0.05236816 ...,  0.71630859  0.92919922
   0.78759766]
 [ 0.01077271  0.03018188  0.03326416 ...,  0.82470703  0.90429688
  -0.45532227]]
After layer decoder_rnn_l0_t0_i2h_output (20, 2048) <class 'numpy.float16'> [[-3.16015625  1.70800781  2.30273438 ..., -0.19934082  3.84765625
   0.80712891]
 [-3.109375    1.6640625   2.28515625 ..., -0.16870117  3.80078125
   0.78222656]
 [-3.28710938  1.91992188  2.31054688 ..., -0.23461914  3.94921875
   1.20410156]
 ...,
 [-3.2734375   1.69238281  2.64648438 ..., -3.15234375  3.52148438
  -0.25537109]
 [-2.93554688  1.98242188  1.71484375 ..., -2.1875      3.28710938
   1.52832031]
 [-3.19921875  1.35351562  2.578125   ..., -1.69824219  3.51367188
  -0.15002441]]
After layer decoder_rnn_l0_t0_h2h_output (20, 2048) <class 'numpy.float16'> [[-0.41723633  0.37109375  1.72265625 ...,  0.49731445  1.26757812
   0.31665039]
 [-0.43334961  0.38989258  1.68652344 ...,  0.50732422  1.23632812
   0.29370117]
 [-0.56494141  0.32226562  1.6953125  ...,  0.38842773  1.16210938
   0.76611328]
 ...,
 [-0.59521484  0.52197266  1.72558594 ...,  0.22570801  1.1484375
   0.01496887]
 [-0.51464844  0.58935547  1.59082031 ..., -0.32202148  1.328125
   0.03909302]
 [-0.57763672  0.51660156  1.64941406 ...,  0.21875     1.11132812
   0.01763916]]
After layer _plus1050_0 (20, 2048) <class 'numpy.float16'> [[-3.578125    2.078125    4.0234375  ...,  0.29785156  5.1171875
   1.12402344]
 [-3.54296875  2.0546875   3.97265625 ...,  0.33862305  5.0390625
   1.07617188]
 [-3.8515625   2.2421875   4.0078125  ...,  0.15380859  5.109375
   1.97070312]
 ...,
 [-3.86914062  2.21484375  4.37109375 ..., -2.92578125  4.671875
  -0.24035645]
 [-3.44921875  2.57226562  3.3046875  ..., -2.50976562  4.6171875
   1.56738281]
 [-3.77734375  1.87011719  4.2265625  ..., -1.47949219  4.625      -0.13232422]]
After layer decoder_rnn_l0_t0_slice_output0 (20, 512) <class 'numpy.float16'> [[-3.578125    2.078125    4.0234375  ...,  1.86621094  4.609375
   2.64648438]
 [-3.54296875  2.0546875   3.97265625 ...,  1.79882812  4.5390625
   2.61328125]
 [-3.8515625   2.2421875   4.0078125  ...,  2.04296875  4.8125      2.4921875 ]
 ...,
 [-3.86914062  2.21484375  4.37109375 ...,  1.79296875  5.1015625
   2.51953125]
 [-3.44921875  2.57226562  3.3046875  ...,  2.01367188  4.31640625
   1.69140625]
 [-3.77734375  1.87011719  4.2265625  ...,  1.65039062  5.0078125   2.359375  ]]
After layer decoder_rnn_l0_t0_slice_output1 (20, 512) <class 'numpy.float16'> [[-2.15234375  2.35546875  2.26953125 ...,  2.97070312 -1.04589844
   2.02539062]
 [-2.15429688  2.33203125  2.25390625 ...,  2.9296875  -1.04101562
   1.92578125]
 [-2.39453125  2.41015625  2.62890625 ...,  2.7890625  -1.45800781
   1.98535156]
 ...,
 [-0.74023438  1.52636719  2.41015625 ...,  2.33984375 -0.23474121
   1.97363281]
 [-2.53125     1.70214844  1.75195312 ...,  1.97753906  0.31298828
   1.328125  ]
 [-1.30859375  1.65429688  2.20703125 ...,  2.14453125 -0.48095703
   1.7109375 ]]
After layer decoder_rnn_l0_t0_slice_output2 (20, 512) <class 'numpy.float16'> [[-2.79101562 -3.02148438  2.72851562 ...,  4.265625   -0.18579102
   2.12695312]
 [-2.70898438 -2.97851562  2.68359375 ...,  4.1796875  -0.234375
   2.08984375]
 [-2.72851562 -3.18164062  2.91796875 ...,  4.3984375   0.22814941
   2.03710938]
 ...,
 [-2.5234375  -2.2734375   1.85253906 ...,  3.57617188 -2.47851562
   1.453125  ]
 [-3.08984375 -2.1796875   1.54589844 ...,  3.72265625 -2.85546875
   2.10546875]
 [-2.40625    -2.05859375  1.76953125 ...,  3.44140625 -2.5703125
   1.40917969]]
After layer decoder_rnn_l0_t0_slice_output3 (20, 512) <class 'numpy.float16'> [[-3.41796875  2.47265625 -1.46679688 ...,  0.29785156  5.1171875
   1.12402344]
 [-3.36914062  2.5078125  -1.48828125 ...,  0.33862305  5.0390625
   1.07617188]
 [-3.51757812  2.37304688 -1.42773438 ...,  0.15380859  5.109375
   1.97070312]
 ...,
 [-1.71484375 -0.75683594 -3.11523438 ..., -2.92578125  4.671875
  -0.24035645]
 [-2.79882812  0.33496094 -2.71484375 ..., -2.50976562  4.6171875
   1.56738281]
 [-2.01171875 -0.07958984 -3.09375    ..., -1.47949219  4.625      -0.13232422]]
After layer decoder_rnn_l0_t0_o_output (20, 512) <class 'numpy.float16'> [[ 0.03173828  0.92236328  0.18737793 ...,  0.57373047  0.99414062
   0.75488281]
 [ 0.03326416  0.92480469  0.1842041  ...,  0.58398438  0.99365234
   0.74560547]
 [ 0.02880859  0.91455078  0.19348145 ...,  0.53857422  0.99414062
   0.87792969]
 ...,
 [ 0.15258789  0.31933594  0.04248047 ...,  0.05090332  0.99072266
   0.44018555]
 [ 0.05737305  0.58300781  0.06210327 ...,  0.07519531  0.99023438
   0.82763672]
 [ 0.11798096  0.48022461  0.04336548 ...,  0.18554688  0.99023438
   0.46704102]]
After layer decoder_rnn_l0_t0_f_output (20, 512) <class 'numpy.float16'> [[ 0.10412598  0.91357422  0.90625    ...,  0.95117188  0.26000977
   0.88330078]
 [ 0.10394287  0.91162109  0.90478516 ...,  0.94921875  0.26098633
   0.87255859]
 [ 0.08361816  0.91748047  0.93261719 ...,  0.94189453  0.1887207
   0.87939453]
 ...,
 [ 0.32299805  0.82128906  0.91748047 ...,  0.91210938  0.44165039
   0.87792969]
 [ 0.07366943  0.84570312  0.85205078 ...,  0.87841797  0.57763672
   0.79052734]
 [ 0.21276855  0.83935547  0.90087891 ...,  0.89501953  0.38208008
   0.84716797]]
After layer _mul2100_0 (20, 512) <class 'numpy.float16'> [[ -2.48718262e-03  -2.32617188e+00   2.63671875e+00 ...,   2.78125000e+00
    1.65283203e-01   2.16406250e+00]
 [ -2.63023376e-03  -2.33398438e+00   2.58203125e+00 ...,   2.68750000e+00
    8.47167969e-02   2.08203125e+00]
 [ -2.26593018e-03  -2.24414062e+00   2.60937500e+00 ...,   2.51757812e+00
    1.41845703e-01   1.90332031e+00]
 ...,
 [ -7.52639771e-03  -1.89746094e+00   2.57617188e+00 ...,   2.45898438e+00
    3.50585938e-01   1.95117188e+00]
 [ -2.49099731e-03  -1.90820312e+00   2.38281250e+00 ...,   2.41992188e+00
   -3.31054688e-01   1.87304688e+00]
 [ -6.79016113e-03  -1.97363281e+00   2.46289062e+00 ...,   2.33593750e+00
    2.79785156e-01   1.83203125e+00]]
After layer decoder_rnn_l0_t0_i_output (20, 512) <class 'numpy.float16'> [[ 0.0271759   0.88867188  0.98242188 ...,  0.86621094  0.99023438
   0.93359375]
 [ 0.02810669  0.88623047  0.98144531 ...,  0.85791016  0.98925781
   0.93164062]
 [ 0.02079773  0.90380859  0.98193359 ...,  0.88525391  0.99169922
   0.92382812]
 ...,
 [ 0.02044678  0.90136719  0.98730469 ...,  0.85742188  0.99414062
   0.92529297]
 [ 0.03079224  0.92919922  0.96435547 ...,  0.88232422  0.98681641
   0.84423828]
 [ 0.02236938  0.86669922  0.98583984 ...,  0.83886719  0.99316406
   0.91357422]]
After layer decoder_rnn_l0_t0_c_output (20, 512) <class 'numpy.float16'> [[-0.99267578 -0.99511719  0.99169922 ...,  0.99951172 -0.18371582
   0.97216797]
 [-0.99121094 -0.99462891  0.99072266 ...,  0.99951172 -0.23022461
   0.96972656]
 [-0.99169922 -0.99658203  0.99414062 ...,  0.99951172  0.22424316
   0.96679688]
 ...,
 [-0.98730469 -0.97900391  0.95214844 ...,  0.99853516 -0.98583984
   0.89648438]
 [-0.99609375 -0.97460938  0.91308594 ...,  0.99902344 -0.99316406
   0.97070312]
 [-0.98388672 -0.96777344  0.94335938 ...,  0.99804688 -0.98828125
   0.88720703]]
After layer _mul2101_0 (20, 512) <class 'numpy.float16'> [[-0.02697754 -0.88427734  0.97412109 ...,  0.86572266 -0.18188477
   0.90771484]
 [-0.02786255 -0.88134766  0.97216797 ...,  0.85742188 -0.2277832
   0.90332031]
 [-0.02062988 -0.90087891  0.97607422 ...,  0.88476562  0.22241211
   0.89306641]
 ...,
 [-0.02018738 -0.88232422  0.93994141 ...,  0.85595703 -0.97998047
   0.82958984]
 [-0.03067017 -0.90576172  0.88037109 ...,  0.88134766 -0.97998047
   0.81933594]
 [-0.02200317 -0.83886719  0.93017578 ...,  0.83740234 -0.98144531
   0.81054688]]
After layer decoder_rnn_l0_t0_state_0 (20, 512) <class 'numpy.float16'> [[-0.02946472 -3.2109375   3.61132812 ...,  3.64648438 -0.01660156
   3.07226562]
 [-0.03048706 -3.21484375  3.5546875  ...,  3.54492188 -0.14306641
   2.984375  ]
 [-0.02288818 -3.14453125  3.5859375  ...,  3.40234375  0.36425781
   2.796875  ]
 ...,
 [-0.02770996 -2.77929688  3.515625   ...,  3.31445312 -0.62939453  2.78125   ]
 [-0.03317261 -2.81445312  3.26367188 ...,  3.30078125 -1.31054688
   2.69140625]
 [-0.02879333 -2.8125      3.39257812 ...,  3.17382812 -0.70166016
   2.64257812]]
After layer activation1050_output (20, 512) <class 'numpy.float16'> [[-0.02944946 -0.99658203  0.99853516 ...,  0.99853516 -0.01660156
   0.99560547]
 [-0.0304718  -0.99658203  0.99853516 ...,  0.99853516 -0.14208984
   0.99511719]
 [-0.02288818 -0.99609375  0.99853516 ...,  0.99755859  0.34887695
   0.99267578]
 ...,
 [-0.02770996 -0.9921875   0.99804688 ...,  0.99755859 -0.55761719
   0.9921875 ]
 [-0.03317261 -0.99267578  0.99707031 ...,  0.99707031 -0.86425781
   0.99072266]
 [-0.02877808 -0.99267578  0.99755859 ...,  0.99658203 -0.60546875
   0.98974609]]
After layer decoder_rnn_l0_t0_out_0 (20, 512) <class 'numpy.float16'> [[ -9.34600830e-04  -9.19433594e-01   1.87133789e-01 ...,   5.72753906e-01
   -1.65100098e-02   7.51464844e-01]
 [ -1.01375580e-03  -9.21875000e-01   1.83959961e-01 ...,   5.83007812e-01
   -1.41235352e-01   7.42187500e-01]
 [ -6.59465790e-04  -9.11132812e-01   1.93237305e-01 ...,   5.37109375e-01
    3.46923828e-01   8.71582031e-01]
 ...,
 [ -4.22668457e-03  -3.16894531e-01   4.23889160e-02 ...,   5.07812500e-02
   -5.52246094e-01   4.36767578e-01]
 [ -1.90353394e-03  -5.78613281e-01   6.19201660e-02 ...,   7.49511719e-02
   -8.55957031e-01   8.19824219e-01]
 [ -3.39508057e-03  -4.76806641e-01   4.32739258e-02 ...,   1.84936523e-01
   -5.99609375e-01   4.62158203e-01]]
After layer expand_dims1059_0 (20, 512, 1) <class 'numpy.float16'> [[[ -9.34600830e-04]
  [ -9.19433594e-01]
  [  1.87133789e-01]
  ...,
  [  5.72753906e-01]
  [ -1.65100098e-02]
  [  7.51464844e-01]]

 [[ -1.01375580e-03]
  [ -9.21875000e-01]
  [  1.83959961e-01]
  ...,
  [  5.83007812e-01]
  [ -1.41235352e-01]
  [  7.42187500e-01]]

 [[ -6.59465790e-04]
  [ -9.11132812e-01]
  [  1.93237305e-01]
  ...,
  [  5.37109375e-01]
  [  3.46923828e-01]
  [  8.71582031e-01]]

 ...,
 [[ -4.22668457e-03]
  [ -3.16894531e-01]
  [  4.23889160e-02]
  ...,
  [  5.07812500e-02]
  [ -5.52246094e-01]
  [  4.36767578e-01]]

 [[ -1.90353394e-03]
  [ -5.78613281e-01]
  [  6.19201660e-02]
  ...,
  [  7.49511719e-02]
  [ -8.55957031e-01]
  [  8.19824219e-01]]

 [[ -3.39508057e-03]
  [ -4.76806641e-01]
  [  4.32739258e-02]
  ...,
  [  1.84936523e-01]
  [ -5.99609375e-01]
  [  4.62158203e-01]]]
After layer att_batch_dot_0 (20, 10, 1) <class 'numpy.float16'> [[[  0.48144531]
  [  0.83886719]
  [  1.43945312]
  [  2.23046875]
  [  1.97363281]
  [ -0.36303711]
  [ -3.62304688]
  [ -6.453125  ]
  [ -8.5546875 ]
  [-10.109375  ]]

 [[  0.48266602]
  [  0.82714844]
  [  1.42871094]
  [  2.21484375]
  [  1.93457031]
  [ -0.44458008]
  [ -3.75195312]
  [ -6.6171875 ]
  [ -8.7421875 ]
  [-10.3046875 ]]

 [[  0.453125  ]
  [  0.71435547]
  [  1.21582031]
  [  1.79882812]
  [  1.24414062]
  [ -1.42285156]
  [ -4.96484375]
  [ -7.98046875]
  [-10.1953125 ]
  [-11.8203125 ]]

 [[  0.48876953]
  [  0.82666016]
  [  1.44921875]
  [  2.2578125 ]
  [  1.99511719]
  [ -0.38525391]
  [ -3.70507812]
  [ -6.578125  ]
  [ -8.703125  ]
  [-10.265625  ]]

 [[  0.48339844]
  [  0.84423828]
  [  1.453125  ]
  [  2.25585938]
  [  2.01171875]
  [ -0.31591797]
  [ -3.57421875]
  [ -6.40234375]
  [ -8.5078125 ]
  [-10.0625    ]]

 [[  0.47802734]
  [  0.82958984]
  [  1.41503906]
  [  2.18164062]
  [  1.89160156]
  [ -0.47973633]
  [ -3.76757812]
  [ -6.62109375]
  [ -8.734375  ]
  [-10.296875  ]]

 [[  0.44995117]
  [  0.67626953]
  [  1.12109375]
  [  1.60742188]
  [  0.91601562]
  [ -1.90234375]
  [ -5.57421875]
  [ -8.6875    ]
  [-10.96875   ]
  [-12.6328125 ]]

 [[  0.48266602]
  [  0.82910156]
  [  1.43261719]
  [  2.22265625]
  [  1.95019531]
  [ -0.41870117]
  [ -3.71679688]
  [ -6.57421875]
  [ -8.6953125 ]
  [-10.2578125 ]]

 [[  0.48510742]
  [  0.83398438]
  [  1.44628906]
  [  2.24804688]
  [  1.99121094]
  [ -0.36376953]
  [ -3.65234375]
  [ -6.50390625]
  [ -8.6171875 ]
  [-10.1796875 ]]

 [[  0.48486328]
  [  0.81982422]
  [  1.4296875 ]
  [  2.21875   ]
  [  1.93261719]
  [ -0.46606445]
  [ -3.796875  ]
  [ -6.6796875 ]
  [ -8.8125    ]
  [-10.375     ]]

 [[  0.69287109]
  [  1.68066406]
  [  3.97851562]
  [  7.47265625]
  [ 11.1875    ]
  [ 13.46875   ]
  [ 14.3359375 ]
  [ 14.453125  ]
  [ 14.1015625 ]
  [ 13.4375    ]]

 [[  0.50683594]
  [  0.82714844]
  [  1.47167969]
  [  2.27148438]
  [  2.        ]
  [ -0.36547852]
  [ -3.6484375 ]
  [ -6.48046875]
  [ -8.5625    ]
  [-10.1015625 ]]

 [[  0.51074219]
  [  0.82324219]
  [  1.48242188]
  [  2.29296875]
  [  2.02734375]
  [ -0.34521484]
  [ -3.640625  ]
  [ -6.4765625 ]
  [ -8.5625    ]
  [-10.09375   ]]

 [[  0.4465332 ]
  [  0.66455078]
  [  1.36035156]
  [  2.02539062]
  [  1.25390625]
  [ -2.03710938]
  [ -6.33984375]
  [ -9.984375  ]
  [-12.578125  ]
  [-14.3671875 ]]

 [[  0.48681641]
  [  0.81640625]
  [  1.4296875 ]
  [  2.22070312]
  [  1.92871094]
  [ -0.48583984]
  [ -3.8359375 ]
  [ -6.73046875]
  [ -8.8671875 ]
  [-10.4375    ]]

 [[  0.51464844]
  [  0.89013672]
  [  2.22265625]
  [  4.0078125 ]
  [  5.29296875]
  [  4.84375   ]
  [  3.296875  ]
  [  1.66992188]
  [  0.2442627 ]
  [ -0.99462891]]

 [[  0.48364258]
  [  0.80761719]
  [  1.40917969]
  [  2.1796875 ]
  [  1.8671875 ]
  [ -0.56347656]
  [ -3.921875  ]
  [ -6.8203125 ]
  [ -8.953125  ]
  [-10.5234375 ]]

 [[  0.69091797]
  [  1.703125  ]
  [  4.02734375]
  [  7.55859375]
  [ 11.328125  ]
  [ 13.671875  ]
  [ 14.609375  ]
  [ 14.7890625 ]
  [ 14.484375  ]
  [ 13.8515625 ]]

 [[  0.70556641]
  [  1.3515625 ]
  [  3.14648438]
  [  5.67578125]
  [  8.1640625 ]
  [  9.3203125 ]
  [  9.3984375 ]
  [  9.109375  ]
  [  8.65625   ]
  [  8.0625    ]]

 [[  0.64794922]
  [  1.44238281]
  [  3.421875  ]
  [  6.37890625]
  [  9.3828125 ]
  [ 10.90625   ]
  [ 11.125     ]
  [ 10.796875  ]
  [ 10.203125  ]
  [  9.4453125 ]]]
After layer swapaxes21_output (10, 20, 1) <class 'numpy.float16'> [[[  0.48144531]
  [  0.48266602]
  [  0.453125  ]
  [  0.48876953]
  [  0.48339844]
  [  0.47802734]
  [  0.44995117]
  [  0.48266602]
  [  0.48510742]
  [  0.48486328]
  [  0.69287109]
  [  0.50683594]
  [  0.51074219]
  [  0.4465332 ]
  [  0.48681641]
  [  0.51464844]
  [  0.48364258]
  [  0.69091797]
  [  0.70556641]
  [  0.64794922]]

 [[  0.83886719]
  [  0.82714844]
  [  0.71435547]
  [  0.82666016]
  [  0.84423828]
  [  0.82958984]
  [  0.67626953]
  [  0.82910156]
  [  0.83398438]
  [  0.81982422]
  [  1.68066406]
  [  0.82714844]
  [  0.82324219]
  [  0.66455078]
  [  0.81640625]
  [  0.89013672]
  [  0.80761719]
  [  1.703125  ]
  [  1.3515625 ]
  [  1.44238281]]

 [[  1.43945312]
  [  1.42871094]
  [  1.21582031]
  [  1.44921875]
  [  1.453125  ]
  [  1.41503906]
  [  1.12109375]
  [  1.43261719]
  [  1.44628906]
  [  1.4296875 ]
  [  3.97851562]
  [  1.47167969]
  [  1.48242188]
  [  1.36035156]
  [  1.4296875 ]
  [  2.22265625]
  [  1.40917969]
  [  4.02734375]
  [  3.14648438]
  [  3.421875  ]]

 [[  2.23046875]
  [  2.21484375]
  [  1.79882812]
  [  2.2578125 ]
  [  2.25585938]
  [  2.18164062]
  [  1.60742188]
  [  2.22265625]
  [  2.24804688]
  [  2.21875   ]
  [  7.47265625]
  [  2.27148438]
  [  2.29296875]
  [  2.02539062]
  [  2.22070312]
  [  4.0078125 ]
  [  2.1796875 ]
  [  7.55859375]
  [  5.67578125]
  [  6.37890625]]

 [[  1.97363281]
  [  1.93457031]
  [  1.24414062]
  [  1.99511719]
  [  2.01171875]
  [  1.89160156]
  [  0.91601562]
  [  1.95019531]
  [  1.99121094]
  [  1.93261719]
  [ 11.1875    ]
  [  2.        ]
  [  2.02734375]
  [  1.25390625]
  [  1.92871094]
  [  5.29296875]
  [  1.8671875 ]
  [ 11.328125  ]
  [  8.1640625 ]
  [  9.3828125 ]]

 [[ -0.36303711]
  [ -0.44458008]
  [ -1.42285156]
  [ -0.38525391]
  [ -0.31591797]
  [ -0.47973633]
  [ -1.90234375]
  [ -0.41870117]
  [ -0.36376953]
  [ -0.46606445]
  [ 13.46875   ]
  [ -0.36547852]
  [ -0.34521484]
  [ -2.03710938]
  [ -0.48583984]
  [  4.84375   ]
  [ -0.56347656]
  [ 13.671875  ]
  [  9.3203125 ]
  [ 10.90625   ]]

 [[ -3.62304688]
  [ -3.75195312]
  [ -4.96484375]
  [ -3.70507812]
  [ -3.57421875]
  [ -3.76757812]
  [ -5.57421875]
  [ -3.71679688]
  [ -3.65234375]
  [ -3.796875  ]
  [ 14.3359375 ]
  [ -3.6484375 ]
  [ -3.640625  ]
  [ -6.33984375]
  [ -3.8359375 ]
  [  3.296875  ]
  [ -3.921875  ]
  [ 14.609375  ]
  [  9.3984375 ]
  [ 11.125     ]]

 [[ -6.453125  ]
  [ -6.6171875 ]
  [ -7.98046875]
  [ -6.578125  ]
  [ -6.40234375]
  [ -6.62109375]
  [ -8.6875    ]
  [ -6.57421875]
  [ -6.50390625]
  [ -6.6796875 ]
  [ 14.453125  ]
  [ -6.48046875]
  [ -6.4765625 ]
  [ -9.984375  ]
  [ -6.73046875]
  [  1.66992188]
  [ -6.8203125 ]
  [ 14.7890625 ]
  [  9.109375  ]
  [ 10.796875  ]]

 [[ -8.5546875 ]
  [ -8.7421875 ]
  [-10.1953125 ]
  [ -8.703125  ]
  [ -8.5078125 ]
  [ -8.734375  ]
  [-10.96875   ]
  [ -8.6953125 ]
  [ -8.6171875 ]
  [ -8.8125    ]
  [ 14.1015625 ]
  [ -8.5625    ]
  [ -8.5625    ]
  [-12.578125  ]
  [ -8.8671875 ]
  [  0.2442627 ]
  [ -8.953125  ]
  [ 14.484375  ]
  [  8.65625   ]
  [ 10.203125  ]]

 [[-10.109375  ]
  [-10.3046875 ]
  [-11.8203125 ]
  [-10.265625  ]
  [-10.0625    ]
  [-10.296875  ]
  [-12.6328125 ]
  [-10.2578125 ]
  [-10.1796875 ]
  [-10.375     ]
  [ 13.4375    ]
  [-10.1015625 ]
  [-10.09375   ]
  [-14.3671875 ]
  [-10.4375    ]
  [ -0.99462891]
  [-10.5234375 ]
  [ 13.8515625 ]
  [  8.0625    ]
  [  9.4453125 ]]]
After layer sequencemask6_output (10, 20, 1) <class 'numpy.float16'> [[[  4.81445312e-01]
  [  4.82666016e-01]
  [  4.53125000e-01]
  [  4.88769531e-01]
  [  4.83398438e-01]
  [  4.78027344e-01]
  [  4.49951172e-01]
  [  4.82666016e-01]
  [  4.85107422e-01]
  [  4.84863281e-01]
  [  6.92871094e-01]
  [  5.06835938e-01]
  [  5.10742188e-01]
  [  4.46533203e-01]
  [  4.86816406e-01]
  [  5.14648438e-01]
  [  4.83642578e-01]
  [  6.90917969e-01]
  [  7.05566406e-01]
  [  6.47949219e-01]]

 [[  8.38867188e-01]
  [  8.27148438e-01]
  [  7.14355469e-01]
  [  8.26660156e-01]
  [  8.44238281e-01]
  [  8.29589844e-01]
  [  6.76269531e-01]
  [  8.29101562e-01]
  [  8.33984375e-01]
  [  8.19824219e-01]
  [  1.68066406e+00]
  [  8.27148438e-01]
  [  8.23242188e-01]
  [  6.64550781e-01]
  [  8.16406250e-01]
  [  8.90136719e-01]
  [  8.07617188e-01]
  [  1.70312500e+00]
  [  1.35156250e+00]
  [  1.44238281e+00]]

 [[ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]]
After layer swapaxes22_output (20, 10, 1) <class 'numpy.float16'> [[[  4.81445312e-01]
  [  8.38867188e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  4.82666016e-01]
  [  8.27148438e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  4.53125000e-01]
  [  7.14355469e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  4.88769531e-01]
  [  8.26660156e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  4.83398438e-01]
  [  8.44238281e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  4.78027344e-01]
  [  8.29589844e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  4.49951172e-01]
  [  6.76269531e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  4.82666016e-01]
  [  8.29101562e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  4.85107422e-01]
  [  8.33984375e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  4.84863281e-01]
  [  8.19824219e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  6.92871094e-01]
  [  1.68066406e+00]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  5.06835938e-01]
  [  8.27148438e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  5.10742188e-01]
  [  8.23242188e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  4.46533203e-01]
  [  6.64550781e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  4.86816406e-01]
  [  8.16406250e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  5.14648438e-01]
  [  8.90136719e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  4.83642578e-01]
  [  8.07617188e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  6.90917969e-01]
  [  1.70312500e+00]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  7.05566406e-01]
  [  1.35156250e+00]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  6.47949219e-01]
  [  1.44238281e+00]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]]
After layer attention_softmax_0 (20, 10, 1) <class 'numpy.float16'> [[[ 0.41162109]
  [ 0.58837891]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.41455078]
  [ 0.58496094]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.43530273]
  [ 0.56494141]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.41650391]
  [ 0.58398438]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.41064453]
  [ 0.58935547]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.41308594]
  [ 0.58691406]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.44384766]
  [ 0.55664062]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.41430664]
  [ 0.5859375 ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.41381836]
  [ 0.58642578]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.41723633]
  [ 0.58300781]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.27148438]
  [ 0.72900391]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.42041016]
  [ 0.57910156]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.42260742]
  [ 0.57763672]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.44555664]
  [ 0.55419922]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.41845703]
  [ 0.58203125]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40698242]
  [ 0.59277344]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.41992188]
  [ 0.58056641]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.26660156]
  [ 0.73339844]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.34399414]
  [ 0.65625   ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.31103516]
  [ 0.68847656]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]]
After layer batch_dot6_0 (20, 512, 1) <class 'numpy.float16'> [[[ 0.01765442]
  [ 0.03921509]
  [-0.03302002]
  ...,
  [-0.01092529]
  [ 0.00997925]
  [-0.02476501]]

 [[ 0.01756287]
  [ 0.03909302]
  [-0.03286743]
  ...,
  [-0.0109024 ]
  [ 0.00997162]
  [-0.02481079]]

 [[ 0.01708984]
  [ 0.03857422]
  [-0.03198242]
  ...,
  [-0.01079559]
  [ 0.00995636]
  [-0.02519226]]

 ...,
 [[ 0.02114868]
  [ 0.04324341]
  [-0.03955078]
  ...,
  [-0.01172638]
  [ 0.01014709]
  [-0.02220154]]

 [[ 0.01928711]
  [ 0.04110718]
  [-0.03607178]
  ...,
  [-0.01130676]
  [ 0.01006317]
  [-0.02357483]]

 [[ 0.02006531]
  [ 0.04199219]
  [-0.03753662]
  ...,
  [-0.01147461]
  [ 0.01009369]
  [-0.02297974]]]
After layer reshape12_0 (20, 512) <class 'numpy.float16'> [[ 0.01765442  0.03921509 -0.03302002 ..., -0.01092529  0.00997925
  -0.02476501]
 [ 0.01756287  0.03909302 -0.03286743 ..., -0.0109024   0.00997162
  -0.02481079]
 [ 0.01708984  0.03857422 -0.03198242 ..., -0.01079559  0.00995636
  -0.02519226]
 ...,
 [ 0.02114868  0.04324341 -0.03955078 ..., -0.01172638  0.01014709
  -0.02220154]
 [ 0.01928711  0.04110718 -0.03607178 ..., -0.01130676  0.01006317
  -0.02357483]
 [ 0.02006531  0.04199219 -0.03753662 ..., -0.01147461  0.01009369
  -0.02297974]]
After layer decoder_rnn_hidden_concat_t0_output (20, 1024) <class 'numpy.float16'> [[ -9.34600830e-04  -9.19433594e-01   1.87133789e-01 ...,  -1.09252930e-02
    9.97924805e-03  -2.47650146e-02]
 [ -1.01375580e-03  -9.21875000e-01   1.83959961e-01 ...,  -1.09024048e-02
    9.97161865e-03  -2.48107910e-02]
 [ -6.59465790e-04  -9.11132812e-01   1.93237305e-01 ...,  -1.07955933e-02
    9.95635986e-03  -2.51922607e-02]
 ...,
 [ -4.22668457e-03  -3.16894531e-01   4.23889160e-02 ...,  -1.17263794e-02
    1.01470947e-02  -2.22015381e-02]
 [ -1.90353394e-03  -5.78613281e-01   6.19201660e-02 ...,  -1.13067627e-02
    1.00631714e-02  -2.35748291e-02]
 [ -3.39508057e-03  -4.76806641e-01   4.32739258e-02 ...,  -1.14746094e-02
    1.00936890e-02  -2.29797363e-02]]
After layer decoder_rnn_hidden_fc_t0_output (20, 512) <class 'numpy.float16'> [[-1.72167969  0.18273926 -0.7109375  ...,  1.79101562  1.97167969
  -1.47363281]
 [-1.74804688  0.20092773 -0.74169922 ...,  1.80078125  1.97167969
  -1.47851562]
 [-1.42285156  0.0120697  -0.51416016 ...,  1.53417969  1.98046875
  -1.4140625 ]
 ...,
 [-0.62451172 -1.67382812  1.16503906 ...,  0.98388672  1.68066406
   1.04980469]
 [-0.73632812 -1.01367188  0.32421875 ...,  1.07324219  1.68554688
   0.74462891]
 [-0.90966797 -0.51855469 -0.07745361 ...,  1.49902344  1.57226562
   0.7578125 ]]
After layer decoder_rnn_next_hidden_t0_output (20, 512) <class 'numpy.float16'> [[-0.93798828  0.18078613 -0.61132812 ...,  0.94580078  0.96191406
  -0.90039062]
 [-0.94091797  0.19824219 -0.63037109 ...,  0.94677734  0.96191406
  -0.90136719]
 [-0.89013672  0.0120697  -0.47314453 ...,  0.91113281  0.96240234
  -0.88818359]
 ...,
 [-0.55419922 -0.93212891  0.82275391 ...,  0.75488281  0.93310547
   0.78173828]
 [-0.62695312 -0.76708984  0.31323242 ...,  0.79052734  0.93359375
   0.63183594]
 [-0.72119141 -0.4765625  -0.07727051 ...,  0.90478516  0.91748047
   0.63964844]]
After layer logits_output (20, 16743) <class 'numpy.float16'> [[-1.8984375  -2.79882812 -2.35742188 ..., -2.07226562 -3.44335938 -2.5       ]
 [-1.90722656 -2.78320312 -2.36132812 ..., -2.07226562 -3.4375     -2.49414062]
 [-1.81054688 -2.86328125 -2.3828125  ..., -2.10351562 -3.375      -2.51757812]
 ...,
 [-1.47167969 -2.96679688 -0.92529297 ..., -2.0078125  -2.44726562
  -1.57421875]
 [-1.49414062 -2.81445312 -0.92822266 ..., -1.74707031 -2.58789062
  -1.68066406]
 [-1.52441406 -2.67773438 -0.85693359 ..., -1.63378906 -2.44921875
  -1.453125  ]]
After layer softmax_0 (20, 16743) <class 'numpy.float16'> [[  1.13248825e-06   4.76837158e-07   7.15255737e-07 ...,   9.53674316e-07
    2.38418579e-07   5.96046448e-07]
 [  1.13248825e-06   4.76837158e-07   7.15255737e-07 ...,   9.53674316e-07
    2.38418579e-07   5.96046448e-07]
 [  1.37090683e-06   4.76837158e-07   7.74860382e-07 ...,   1.01327896e-06
    2.98023224e-07   6.55651093e-07]
 ...,
 [  7.39097595e-06   1.66893005e-06   1.27553940e-05 ...,   4.29153442e-06
    2.80141830e-06   6.67572021e-06]
 [  7.21216202e-06   1.90734863e-06   1.26957893e-05 ...,   5.60283661e-06
    2.44379044e-06   6.02006912e-06]
 [  7.51018524e-06   2.38418579e-06   1.47223473e-05 ...,   6.73532486e-06
    2.98023224e-06   8.10623169e-06]]
After layer reshape13_0 (20, 10) <class 'numpy.float16'> [[ 0.41162109  0.58837891  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.41455078  0.58496094  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.43530273  0.56494141  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.41650391  0.58398438  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.41064453  0.58935547  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.41308594  0.58691406  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.44384766  0.55664062  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.41430664  0.5859375   0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.41381836  0.58642578  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.41723633  0.58300781  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.27148438  0.72900391  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.42041016  0.57910156  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.42260742  0.57763672  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.44555664  0.55419922  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.41845703  0.58203125  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40698242  0.59277344  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.41992188  0.58056641  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.26660156  0.73339844  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.34399414  0.65625     0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.31103516  0.68847656  0.          0.          0.          0.          0.
   0.          0.          0.        ]]
After layer target_embed_embed_0 (20, 256) <class 'numpy.float16'> [[-0.05505371 -0.0300293  -0.03598022 ...,  0.08459473 -0.05288696
  -0.01667786]
 [-0.05505371 -0.0300293  -0.03598022 ...,  0.08459473 -0.05288696
  -0.01667786]
 [-0.05505371 -0.0300293  -0.03598022 ...,  0.08459473 -0.05288696
  -0.01667786]
 ...,
 [-0.05505371 -0.0300293  -0.03598022 ...,  0.08459473 -0.05288696
  -0.01667786]
 [ 0.09375     0.03564453  0.10772705 ..., -0.10864258 -0.07653809
  -0.06854248]
 [-0.01300049  0.11682129  0.06750488 ..., -0.10992432 -0.05990601
  -0.10571289]]
After layer decoder_rnn_concat_target_context_t0_output (20, 768) <class 'numpy.float16'> [[-0.05505371 -0.0300293  -0.03598022 ...,  0.94580078  0.96191406
  -0.90039062]
 [-0.05505371 -0.0300293  -0.03598022 ...,  0.94677734  0.96191406
  -0.90136719]
 [-0.05505371 -0.0300293  -0.03598022 ...,  0.91113281  0.96240234
  -0.88818359]
 ...,
 [-0.05505371 -0.0300293  -0.03598022 ...,  0.94384766  0.96044922
  -0.89550781]
 [ 0.09375     0.03564453  0.10772705 ...,  0.95068359  0.90039062
   0.29882812]
 [-0.01300049  0.11682129  0.06750488 ...,  0.74853516  0.93066406
   0.78613281]]
After layer decoder_rnn_l0_t0_i2h_output (20, 2048) <class 'numpy.float16'> [[-3.12304688  1.59960938  2.36523438 ..., -0.09533691  3.83203125
   0.63037109]
 [-3.109375    1.59179688  2.36523438 ..., -0.08630371  3.81835938
   0.62158203]
 [-3.11328125  1.65332031  2.30273438 ..., -0.13830566  3.828125
   0.78271484]
 ...,
 [-3.09179688  1.58496094  2.34960938 ..., -0.09674072  3.79492188
   0.64013672]
 [-2.92578125  1.51269531  1.83886719 ..., -0.98730469  2.95117188
   0.60009766]
 [-2.72460938  1.79101562  1.72753906 ..., -1.17871094  3.37109375
   1.37890625]]
After layer decoder_rnn_l0_t0_h2h_output (20, 2048) <class 'numpy.float16'> [[ -3.65234375e-01   4.48486328e-01   1.74511719e+00 ...,   6.22558594e-01
    1.26074219e+00   1.79809570e-01]
 [ -3.72802734e-01   4.61669922e-01   1.73730469e+00 ...,   6.29394531e-01
    1.25390625e+00   1.68334961e-01]
 [ -4.53125000e-01   4.15771484e-01   1.75000000e+00 ...,   5.04882812e-01
    1.26562500e+00   3.16406250e-01]
 ...,
 [ -4.02587891e-01   4.72900391e-01   1.73046875e+00 ...,   6.05957031e-01
    1.24609375e+00   1.77001953e-01]
 [ -4.23583984e-01   5.12695312e-01   1.66308594e+00 ...,   1.18835449e-01
    1.23730469e+00  -5.28320312e-01]
 [ -5.29785156e-01   5.90332031e-01   1.59082031e+00 ...,  -3.07128906e-01
    1.35839844e+00  -1.49154663e-03]]
After layer _plus1051_0 (20, 2048) <class 'numpy.float16'> [[-3.48828125  2.04882812  4.109375   ...,  0.52734375  5.09375     0.81005859]
 [-3.48242188  2.05273438  4.1015625  ...,  0.54296875  5.0703125
   0.79003906]
 [-3.56640625  2.06835938  4.0546875  ...,  0.36669922  5.09375     1.09960938]
 ...,
 [-3.49414062  2.05859375  4.078125   ...,  0.50927734  5.0390625
   0.81738281]
 [-3.34960938  2.02539062  3.50195312 ..., -0.86865234  4.1875      0.07177734]
 [-3.25390625  2.38085938  3.31835938 ..., -1.48632812  4.73046875
   1.37695312]]
After layer decoder_rnn_l0_t0_slice_output0 (20, 512) <class 'numpy.float16'> [[-3.48828125  2.04882812  4.109375   ...,  1.74414062  4.4921875
   2.69921875]
 [-3.48242188  2.05273438  4.1015625  ...,  1.73535156  4.484375    2.6875    ]
 [-3.56640625  2.06835938  4.0546875  ...,  1.84863281  4.5390625
   2.65039062]
 ...,
 [-3.49414062  2.05859375  4.078125   ...,  1.72460938  4.47265625
   2.66796875]
 [-3.34960938  2.02539062  3.50195312 ...,  1.49804688  3.69921875
   2.27148438]
 [-3.25390625  2.38085938  3.31835938 ...,  2.078125    4.3359375
   1.76367188]]
After layer decoder_rnn_l0_t0_slice_output1 (20, 512) <class 'numpy.float16'> [[ -1.95410156e+00   2.28125000e+00   2.28515625e+00 ...,   3.07031250e+00
   -8.75488281e-01   1.89843750e+00]
 [ -1.95703125e+00   2.27148438e+00   2.29296875e+00 ...,   3.05468750e+00
   -8.67187500e-01   1.87500000e+00]
 [ -2.10156250e+00   2.33789062e+00   2.34179688e+00 ...,   2.95703125e+00
   -1.08203125e+00   1.97070312e+00]
 ...,
 [ -1.99414062e+00   2.28320312e+00   2.28515625e+00 ...,   3.01953125e+00
   -8.79882812e-01   1.84960938e+00]
 [ -2.39843750e+00   2.59570312e+00   1.52148438e+00 ...,   2.08203125e+00
    1.43310547e-01   1.23144531e+00]
 [ -2.53125000e+00   1.56640625e+00   1.91015625e+00 ...,   2.09375000e+00
   -2.38037109e-03   1.28417969e+00]]
After layer decoder_rnn_l0_t0_slice_output2 (20, 512) <class 'numpy.float16'> [[-2.72460938 -2.96875     2.76171875 ...,  4.171875   -0.16113281
   2.109375  ]
 [-2.70703125 -2.97265625  2.76171875 ...,  4.140625   -0.17041016
   2.09960938]
 [-2.74609375 -3.0078125   2.765625   ...,  4.1953125  -0.1862793
   2.09765625]
 ...,
 [-2.66796875 -2.95703125  2.73828125 ...,  4.1171875  -0.2109375
   2.08203125]
 [-2.66601562 -1.95898438  1.4140625  ...,  3.328125   -3.41210938
   2.04296875]
 [-3.10351562 -2.12109375  1.70703125 ...,  3.68359375 -2.45507812
   2.07421875]]
After layer decoder_rnn_l0_t0_slice_output3 (20, 512) <class 'numpy.float16'> [[-3.3046875   2.50390625 -1.44726562 ...,  0.52734375  5.09375     0.81005859]
 [-3.29101562  2.5234375  -1.45703125 ...,  0.54296875  5.0703125
   0.79003906]
 [-3.38671875  2.57226562 -1.51269531 ...,  0.36669922  5.09375     1.09960938]
 ...,
 [-3.30078125  2.53710938 -1.47558594 ...,  0.50927734  5.0390625
   0.81738281]
 [-3.07226562  2.01171875 -2.88671875 ..., -0.86865234  4.1875      0.07177734]
 [-2.7734375   0.31005859 -2.13085938 ..., -1.48632812  4.73046875
   1.37695312]]
After layer decoder_rnn_l0_t0_o_output (20, 512) <class 'numpy.float16'> [[ 0.03540039  0.92431641  0.19042969 ...,  0.62890625  0.99414062
   0.69189453]
 [ 0.03588867  0.92578125  0.18896484 ...,  0.63232422  0.99365234
   0.68798828]
 [ 0.03271484  0.92919922  0.18054199 ...,  0.59082031  0.99414062  0.75      ]
 ...,
 [ 0.03555298  0.92675781  0.18603516 ...,  0.62451172  0.99365234
   0.69384766]
 [ 0.04428101  0.88183594  0.05282593 ...,  0.2956543   0.98486328
   0.51806641]
 [ 0.05877686  0.57666016  0.10614014 ...,  0.18444824  0.99121094
   0.79833984]]
After layer decoder_rnn_l0_t0_f_output (20, 512) <class 'numpy.float16'> [[ 0.12408447  0.90722656  0.90771484 ...,  0.95556641  0.29418945
   0.86962891]
 [ 0.1237793   0.90625     0.90820312 ...,  0.95507812  0.29589844
   0.8671875 ]
 [ 0.10894775  0.91210938  0.91210938 ...,  0.95068359  0.25317383
   0.87792969]
 ...,
 [ 0.11981201  0.90771484  0.90771484 ...,  0.95361328  0.29321289
   0.86425781]
 [ 0.08331299  0.93066406  0.82080078 ...,  0.88916016  0.53564453
   0.77392578]
 [ 0.07366943  0.82714844  0.87109375 ...,  0.89013672  0.49951172
   0.78320312]]
After layer _mul2102_0 (20, 512) <class 'numpy.float16'> [[ -3.65638733e-03  -2.91210938e+00   3.27734375e+00 ...,   3.48437500e+00
   -4.88281250e-03   2.67187500e+00]
 [ -3.77273560e-03  -2.91406250e+00   3.22851562e+00 ...,   3.38476562e+00
   -4.23278809e-02   2.58789062e+00]
 [ -2.49290466e-03  -2.86718750e+00   3.27148438e+00 ...,   3.23437500e+00
    9.22241211e-02   2.45507812e+00]
 ...,
 [ -3.48854065e-03  -2.90429688e+00   3.23046875e+00 ...,   3.34375000e+00
   -6.21337891e-02   2.54296875e+00]
 [ -2.08282471e-03  -2.69531250e+00   2.79296875e+00 ...,   2.78710938e+00
   -3.52539062e-01   2.02539062e+00]
 [ -2.38800049e-03  -2.30078125e+00   2.97070312e+00 ...,   2.83789062e+00
   -3.31787109e-01   2.08007812e+00]]
After layer decoder_rnn_l0_t0_i_output (20, 512) <class 'numpy.float16'> [[ 0.02964783  0.88574219  0.98388672 ...,  0.85107422  0.98876953
   0.93701172]
 [ 0.02981567  0.88623047  0.98388672 ...,  0.85009766  0.98876953
   0.93652344]
 [ 0.02748108  0.88769531  0.98291016 ...,  0.86376953  0.98925781
   0.93408203]
 ...,
 [ 0.02947998  0.88671875  0.98339844 ...,  0.84863281  0.98876953
   0.93505859]
 [ 0.03390503  0.88330078  0.97070312 ...,  0.81738281  0.97607422  0.90625   ]
 [ 0.03720093  0.91552734  0.96484375 ...,  0.88867188  0.98730469
   0.85351562]]
After layer decoder_rnn_l0_t0_c_output (20, 512) <class 'numpy.float16'> [[-0.99121094 -0.99462891  0.9921875  ...,  0.99951172 -0.15979004
   0.97119141]
 [-0.99121094 -0.99462891  0.9921875  ...,  0.99951172 -0.16882324
   0.97021484]
 [-0.99169922 -0.99511719  0.9921875  ...,  0.99951172 -0.1842041
   0.97021484]
 ...,
 [-0.99023438 -0.99462891  0.99169922 ...,  0.99951172 -0.20788574
   0.96923828]
 [-0.99023438 -0.9609375   0.88818359 ...,  0.99755859 -0.99804688
   0.96679688]
 [-0.99609375 -0.97167969  0.93652344 ...,  0.99853516 -0.98535156  0.96875   ]]
After layer _mul2103_0 (20, 512) <class 'numpy.float16'> [[-0.02938843 -0.88085938  0.97607422 ...,  0.85058594 -0.15795898
   0.91015625]
 [-0.02955627 -0.88134766  0.97607422 ...,  0.84960938 -0.16687012
   0.90869141]
 [-0.0272522  -0.88330078  0.97509766 ...,  0.86328125 -0.18225098  0.90625   ]
 ...,
 [-0.02919006 -0.88183594  0.97509766 ...,  0.84814453 -0.20556641  0.90625   ]
 [-0.03356934 -0.84863281  0.86230469 ...,  0.81542969 -0.97412109
   0.87597656]
 [-0.03704834 -0.88964844  0.90380859 ...,  0.88720703 -0.97265625
   0.82666016]]
After layer decoder_rnn_l0_t0_state_0 (20, 512) <class 'numpy.float16'> [[-0.03305054 -3.79296875  4.25390625 ...,  4.3359375  -0.1628418
   3.58203125]
 [-0.0333252  -3.79492188  4.203125   ...,  4.234375   -0.20922852
   3.49609375]
 [-0.02973938 -3.75        4.24609375 ...,  4.09765625 -0.09002686
   3.36132812]
 ...,
 [-0.03268433 -3.78515625  4.20703125 ...,  4.19140625 -0.26757812
   3.44921875]
 [-0.03564453 -3.54296875  3.65625    ...,  3.6015625  -1.32617188
   2.90234375]
 [-0.03942871 -3.19140625  3.875      ...,  3.72460938 -1.3046875   2.90625   ]]
After layer activation1051_output (20, 512) <class 'numpy.float16'> [[-0.03305054 -0.99902344  0.99951172 ...,  0.99951172 -0.16137695
   0.99853516]
 [-0.0333252  -0.99902344  0.99951172 ...,  0.99951172 -0.20617676
   0.99804688]
 [-0.02972412 -0.99902344  0.99951172 ...,  0.99951172 -0.08978271
   0.99755859]
 ...,
 [-0.03268433 -0.99902344  0.99951172 ...,  0.99951172 -0.26147461
   0.99804688]
 [-0.03564453 -0.99853516  0.99853516 ...,  0.99853516 -0.86816406
   0.99414062]
 [-0.03939819 -0.99658203  0.99902344 ...,  0.99902344 -0.86279297
   0.99414062]]
After layer decoder_rnn_l0_t0_out_0 (20, 512) <class 'numpy.float16'> [[-0.00117016 -0.92333984  0.19030762 ...,  0.62841797 -0.16040039
   0.69091797]
 [-0.00119591 -0.92480469  0.18884277 ...,  0.63183594 -0.20483398
   0.68652344]
 [-0.00097227 -0.92822266  0.18041992 ...,  0.59033203 -0.0892334
   0.74804688]
 ...,
 [-0.00116158 -0.92578125  0.18591309 ...,  0.62402344 -0.25976562
   0.69238281]
 [-0.00157833 -0.88037109  0.05273438 ...,  0.29516602 -0.85498047
   0.51513672]
 [-0.00231552 -0.57470703  0.10601807 ...,  0.18432617 -0.85498047
   0.79345703]]
After layer expand_dims1060_0 (20, 512, 1) <class 'numpy.float16'> [[[-0.00117016]
  [-0.92333984]
  [ 0.19030762]
  ...,
  [ 0.62841797]
  [-0.16040039]
  [ 0.69091797]]

 [[-0.00119591]
  [-0.92480469]
  [ 0.18884277]
  ...,
  [ 0.63183594]
  [-0.20483398]
  [ 0.68652344]]

 [[-0.00097227]
  [-0.92822266]
  [ 0.18041992]
  ...,
  [ 0.59033203]
  [-0.0892334 ]
  [ 0.74804688]]

 ...,
 [[-0.00116158]
  [-0.92578125]
  [ 0.18591309]
  ...,
  [ 0.62402344]
  [-0.25976562]
  [ 0.69238281]]

 [[-0.00157833]
  [-0.88037109]
  [ 0.05273438]
  ...,
  [ 0.29516602]
  [-0.85498047]
  [ 0.51513672]]

 [[-0.00231552]
  [-0.57470703]
  [ 0.10601807]
  ...,
  [ 0.18432617]
  [-0.85498047]
  [ 0.79345703]]]
After layer att_batch_dot_0 (20, 10, 1) <class 'numpy.float16'> [[[  0.50097656]
  [  0.87744141]
  [  1.5078125 ]
  [  2.35742188]
  [  2.15039062]
  [ -0.16882324]
  [ -3.4375    ]
  [ -6.29296875]
  [ -8.421875  ]
  [-10.0078125 ]]

 [[  0.50244141]
  [  0.87304688]
  [  1.50878906]
  [  2.36328125]
  [  2.15625   ]
  [ -0.17541504]
  [ -3.45898438]
  [ -6.32421875]
  [ -8.4609375 ]
  [-10.046875  ]]

 [[  0.47998047]
  [  0.82275391]
  [  1.40332031]
  [  2.15429688]
  [  1.81445312]
  [ -0.64794922]
  [ -4.03515625]
  [ -6.9609375 ]
  [ -9.125     ]
  [-10.7265625 ]]

 [[  0.50683594]
  [  0.87792969]
  [  1.53222656]
  [  2.41015625]
  [  2.22851562]
  [ -0.09558105]
  [ -3.3828125 ]
  [ -6.25390625]
  [ -8.390625  ]
  [ -9.9765625 ]]

 [[  0.50195312]
  [  0.87939453]
  [  1.51367188]
  [  2.36914062]
  [  2.16992188]
  [ -0.14599609]
  [ -3.4140625 ]
  [ -6.26953125]
  [ -8.3984375 ]
  [ -9.984375  ]]

 [[  0.60107422]
  [  1.01464844]
  [  1.81738281]
  [  2.88476562]
  [  2.99023438]
  [  1.03320312]
  [ -1.88574219]
  [ -4.44140625]
  [ -6.359375  ]
  [ -7.828125  ]]

 [[  0.49853516]
  [  0.87060547]
  [  1.48925781]
  [  2.3203125 ]
  [  2.09179688]
  [ -0.24816895]
  [ -3.53125   ]
  [ -6.390625  ]
  [ -8.53125   ]
  [-10.1171875 ]]

 [[  0.47583008]
  [  0.80566406]
  [  1.36035156]
  [  2.06835938]
  [  1.671875  ]
  [ -0.84765625]
  [ -4.2734375 ]
  [ -7.22265625]
  [ -9.40625   ]
  [-11.0078125 ]]

 [[  0.50244141]
  [  0.87402344]
  [  1.50976562]
  [  2.36328125]
  [  2.15820312]
  [ -0.17077637]
  [ -3.45117188]
  [ -6.31640625]
  [ -8.453125  ]
  [-10.03125   ]]

 [[  0.50390625]
  [  0.87744141]
  [  1.51855469]
  [  2.38085938]
  [  2.18554688]
  [ -0.13439941]
  [ -3.41015625]
  [ -6.26953125]
  [ -8.40625   ]
  [ -9.984375  ]]

 [[  0.50439453]
  [  0.87255859]
  [  1.51660156]
  [  2.37890625]
  [  2.17773438]
  [ -0.16003418]
  [ -3.45507812]
  [ -6.328125  ]
  [ -8.46875   ]
  [-10.0546875 ]]

 [[  0.51220703]
  [  0.87304688]
  [  1.52734375]
  [  2.39257812]
  [  2.19335938]
  [ -0.14599609]
  [ -3.44335938]
  [ -6.31640625]
  [ -8.453125  ]
  [-10.046875  ]]

 [[  0.52197266]
  [  0.76953125]
  [  1.46191406]
  [  2.1875    ]
  [  1.609375  ]
  [ -1.31347656]
  [ -5.20703125]
  [ -8.53125   ]
  [-10.90625   ]
  [-12.5703125 ]]

 [[  0.51416016]
  [  0.87402344]
  [  1.53808594]
  [  2.41796875]
  [  2.22460938]
  [ -0.11553955]
  [ -3.421875  ]
  [ -6.30078125]
  [ -8.4453125 ]
  [-10.03125   ]]

 [[  0.70068359]
  [  1.34472656]
  [  3.12109375]
  [  5.625     ]
  [  8.0859375 ]
  [  9.1953125 ]
  [  9.234375  ]
  [  8.8984375 ]
  [  8.3984375 ]
  [  7.76171875]]

 [[  0.50537109]
  [  0.87304688]
  [  1.52246094]
  [  2.39257812]
  [  2.1953125 ]
  [ -0.14587402]
  [ -3.44726562]
  [ -6.328125  ]
  [ -8.46875   ]
  [-10.0625    ]]

 [[  0.44628906]
  [  0.18286133]
  [  0.19128418]
  [ -0.42138672]
  [ -2.8515625 ]
  [ -7.73828125]
  [-13.2734375 ]
  [-17.734375  ]
  [-20.84375   ]
  [-23.015625  ]]

 [[  0.50292969]
  [  0.8671875 ]
  [  1.50878906]
  [  2.36523438]
  [  2.15234375]
  [ -0.19897461]
  [ -3.5078125 ]
  [ -6.390625  ]
  [ -8.53125   ]
  [-10.125     ]]

 [[  0.53759766]
  [  0.95556641]
  [  2.30273438]
  [  4.13671875]
  [  5.5546875 ]
  [  5.34765625]
  [  4.0859375 ]
  [  2.68359375]
  [  1.40820312]
  [  0.27734375]]

 [[  0.734375  ]
  [  1.53320312]
  [  3.37304688]
  [  6.03515625]
  [  8.59375   ]
  [  9.6796875 ]
  [  9.671875  ]
  [  9.3984375 ]
  [  9.0859375 ]
  [  8.6953125 ]]]
After layer swapaxes23_output (10, 20, 1) <class 'numpy.float16'> [[[  0.50097656]
  [  0.50244141]
  [  0.47998047]
  [  0.50683594]
  [  0.50195312]
  [  0.60107422]
  [  0.49853516]
  [  0.47583008]
  [  0.50244141]
  [  0.50390625]
  [  0.50439453]
  [  0.51220703]
  [  0.52197266]
  [  0.51416016]
  [  0.70068359]
  [  0.50537109]
  [  0.44628906]
  [  0.50292969]
  [  0.53759766]
  [  0.734375  ]]

 [[  0.87744141]
  [  0.87304688]
  [  0.82275391]
  [  0.87792969]
  [  0.87939453]
  [  1.01464844]
  [  0.87060547]
  [  0.80566406]
  [  0.87402344]
  [  0.87744141]
  [  0.87255859]
  [  0.87304688]
  [  0.76953125]
  [  0.87402344]
  [  1.34472656]
  [  0.87304688]
  [  0.18286133]
  [  0.8671875 ]
  [  0.95556641]
  [  1.53320312]]

 [[  1.5078125 ]
  [  1.50878906]
  [  1.40332031]
  [  1.53222656]
  [  1.51367188]
  [  1.81738281]
  [  1.48925781]
  [  1.36035156]
  [  1.50976562]
  [  1.51855469]
  [  1.51660156]
  [  1.52734375]
  [  1.46191406]
  [  1.53808594]
  [  3.12109375]
  [  1.52246094]
  [  0.19128418]
  [  1.50878906]
  [  2.30273438]
  [  3.37304688]]

 [[  2.35742188]
  [  2.36328125]
  [  2.15429688]
  [  2.41015625]
  [  2.36914062]
  [  2.88476562]
  [  2.3203125 ]
  [  2.06835938]
  [  2.36328125]
  [  2.38085938]
  [  2.37890625]
  [  2.39257812]
  [  2.1875    ]
  [  2.41796875]
  [  5.625     ]
  [  2.39257812]
  [ -0.42138672]
  [  2.36523438]
  [  4.13671875]
  [  6.03515625]]

 [[  2.15039062]
  [  2.15625   ]
  [  1.81445312]
  [  2.22851562]
  [  2.16992188]
  [  2.99023438]
  [  2.09179688]
  [  1.671875  ]
  [  2.15820312]
  [  2.18554688]
  [  2.17773438]
  [  2.19335938]
  [  1.609375  ]
  [  2.22460938]
  [  8.0859375 ]
  [  2.1953125 ]
  [ -2.8515625 ]
  [  2.15234375]
  [  5.5546875 ]
  [  8.59375   ]]

 [[ -0.16882324]
  [ -0.17541504]
  [ -0.64794922]
  [ -0.09558105]
  [ -0.14599609]
  [  1.03320312]
  [ -0.24816895]
  [ -0.84765625]
  [ -0.17077637]
  [ -0.13439941]
  [ -0.16003418]
  [ -0.14599609]
  [ -1.31347656]
  [ -0.11553955]
  [  9.1953125 ]
  [ -0.14587402]
  [ -7.73828125]
  [ -0.19897461]
  [  5.34765625]
  [  9.6796875 ]]

 [[ -3.4375    ]
  [ -3.45898438]
  [ -4.03515625]
  [ -3.3828125 ]
  [ -3.4140625 ]
  [ -1.88574219]
  [ -3.53125   ]
  [ -4.2734375 ]
  [ -3.45117188]
  [ -3.41015625]
  [ -3.45507812]
  [ -3.44335938]
  [ -5.20703125]
  [ -3.421875  ]
  [  9.234375  ]
  [ -3.44726562]
  [-13.2734375 ]
  [ -3.5078125 ]
  [  4.0859375 ]
  [  9.671875  ]]

 [[ -6.29296875]
  [ -6.32421875]
  [ -6.9609375 ]
  [ -6.25390625]
  [ -6.26953125]
  [ -4.44140625]
  [ -6.390625  ]
  [ -7.22265625]
  [ -6.31640625]
  [ -6.26953125]
  [ -6.328125  ]
  [ -6.31640625]
  [ -8.53125   ]
  [ -6.30078125]
  [  8.8984375 ]
  [ -6.328125  ]
  [-17.734375  ]
  [ -6.390625  ]
  [  2.68359375]
  [  9.3984375 ]]

 [[ -8.421875  ]
  [ -8.4609375 ]
  [ -9.125     ]
  [ -8.390625  ]
  [ -8.3984375 ]
  [ -6.359375  ]
  [ -8.53125   ]
  [ -9.40625   ]
  [ -8.453125  ]
  [ -8.40625   ]
  [ -8.46875   ]
  [ -8.453125  ]
  [-10.90625   ]
  [ -8.4453125 ]
  [  8.3984375 ]
  [ -8.46875   ]
  [-20.84375   ]
  [ -8.53125   ]
  [  1.40820312]
  [  9.0859375 ]]

 [[-10.0078125 ]
  [-10.046875  ]
  [-10.7265625 ]
  [ -9.9765625 ]
  [ -9.984375  ]
  [ -7.828125  ]
  [-10.1171875 ]
  [-11.0078125 ]
  [-10.03125   ]
  [ -9.984375  ]
  [-10.0546875 ]
  [-10.046875  ]
  [-12.5703125 ]
  [-10.03125   ]
  [  7.76171875]
  [-10.0625    ]
  [-23.015625  ]
  [-10.125     ]
  [  0.27734375]
  [  8.6953125 ]]]
After layer sequencemask7_output (10, 20, 1) <class 'numpy.float16'> [[[  5.00976562e-01]
  [  5.02441406e-01]
  [  4.79980469e-01]
  [  5.06835938e-01]
  [  5.01953125e-01]
  [  6.01074219e-01]
  [  4.98535156e-01]
  [  4.75830078e-01]
  [  5.02441406e-01]
  [  5.03906250e-01]
  [  5.04394531e-01]
  [  5.12207031e-01]
  [  5.21972656e-01]
  [  5.14160156e-01]
  [  7.00683594e-01]
  [  5.05371094e-01]
  [  4.46289062e-01]
  [  5.02929688e-01]
  [  5.37597656e-01]
  [  7.34375000e-01]]

 [[  8.77441406e-01]
  [  8.73046875e-01]
  [  8.22753906e-01]
  [  8.77929688e-01]
  [  8.79394531e-01]
  [  1.01464844e+00]
  [  8.70605469e-01]
  [  8.05664062e-01]
  [  8.74023438e-01]
  [  8.77441406e-01]
  [  8.72558594e-01]
  [  8.73046875e-01]
  [  7.69531250e-01]
  [  8.74023438e-01]
  [  1.34472656e+00]
  [  8.73046875e-01]
  [  1.82861328e-01]
  [  8.67187500e-01]
  [  9.55566406e-01]
  [  1.53320312e+00]]

 [[ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]]
After layer swapaxes24_output (20, 10, 1) <class 'numpy.float16'> [[[  5.00976562e-01]
  [  8.77441406e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  5.02441406e-01]
  [  8.73046875e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  4.79980469e-01]
  [  8.22753906e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  5.06835938e-01]
  [  8.77929688e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  5.01953125e-01]
  [  8.79394531e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  6.01074219e-01]
  [  1.01464844e+00]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  4.98535156e-01]
  [  8.70605469e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  4.75830078e-01]
  [  8.05664062e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  5.02441406e-01]
  [  8.74023438e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  5.03906250e-01]
  [  8.77441406e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  5.04394531e-01]
  [  8.72558594e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  5.12207031e-01]
  [  8.73046875e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  5.21972656e-01]
  [  7.69531250e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  5.14160156e-01]
  [  8.74023438e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  7.00683594e-01]
  [  1.34472656e+00]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  5.05371094e-01]
  [  8.73046875e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  4.46289062e-01]
  [  1.82861328e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  5.02929688e-01]
  [  8.67187500e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  5.37597656e-01]
  [  9.55566406e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  7.34375000e-01]
  [  1.53320312e+00]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]]
After layer attention_softmax_0 (20, 10, 1) <class 'numpy.float16'> [[[ 0.40698242]
  [ 0.59277344]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40844727]
  [ 0.59179688]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.41503906]
  [ 0.58496094]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40844727]
  [ 0.59179688]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40673828]
  [ 0.59326172]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.39819336]
  [ 0.60205078]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40795898]
  [ 0.59179688]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.41845703]
  [ 0.58203125]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40820312]
  [ 0.59179688]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40771484]
  [ 0.59228516]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40917969]
  [ 0.59130859]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.41064453]
  [ 0.58935547]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.43823242]
  [ 0.56152344]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.41113281]
  [ 0.58935547]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.34423828]
  [ 0.65576172]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40917969]
  [ 0.59082031]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.56542969]
  [ 0.43457031]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40966797]
  [ 0.58984375]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.39697266]
  [ 0.60302734]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.31030273]
  [ 0.68945312]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]]
After layer batch_dot7_0 (20, 512, 1) <class 'numpy.float16'> [[[ 0.01776123]
  [ 0.03933716]
  [-0.03323364]
  ...,
  [-0.01094818]
  [ 0.00998688]
  [-0.02468872]]

 [[ 0.01773071]
  [ 0.03930664]
  [-0.03317261]
  ...,
  [-0.01094818]
  [ 0.00998688]
  [-0.02471924]]

 [[ 0.01756287]
  [ 0.03912354]
  [-0.03286743]
  ...,
  [-0.0109024 ]
  [ 0.00997925]
  [-0.02482605]]

 ...,
 [[ 0.01768494]
  [ 0.03924561]
  [-0.03308105]
  ...,
  [-0.01093292]
  [ 0.00997925]
  [-0.0247345 ]]

 [[ 0.01800537]
  [ 0.03961182]
  [-0.03369141]
  ...,
  [-0.01100922]
  [ 0.01000214]
  [-0.02450562]]

 [[ 0.02009583]
  [ 0.04202271]
  [-0.03756714]
  ...,
  [-0.01148224]
  [ 0.01009369]
  [-0.02297974]]]
After layer reshape14_0 (20, 512) <class 'numpy.float16'> [[ 0.01776123  0.03933716 -0.03323364 ..., -0.01094818  0.00998688
  -0.02468872]
 [ 0.01773071  0.03930664 -0.03317261 ..., -0.01094818  0.00998688
  -0.02471924]
 [ 0.01756287  0.03912354 -0.03286743 ..., -0.0109024   0.00997925
  -0.02482605]
 ...,
 [ 0.01768494  0.03924561 -0.03308105 ..., -0.01093292  0.00997925
  -0.0247345 ]
 [ 0.01800537  0.03961182 -0.03369141 ..., -0.01100922  0.01000214
  -0.02450562]
 [ 0.02009583  0.04202271 -0.03756714 ..., -0.01148224  0.01009369
  -0.02297974]]
After layer decoder_rnn_hidden_concat_t0_output (20, 1024) <class 'numpy.float16'> [[-0.00117016 -0.92333984  0.19030762 ..., -0.01094818  0.00998688
  -0.02468872]
 [-0.00119591 -0.92480469  0.18884277 ..., -0.01094818  0.00998688
  -0.02471924]
 [-0.00097227 -0.92822266  0.18041992 ..., -0.0109024   0.00997925
  -0.02482605]
 ...,
 [-0.00116158 -0.92578125  0.18591309 ..., -0.01093292  0.00997925
  -0.0247345 ]
 [-0.00157833 -0.88037109  0.05273438 ..., -0.01100922  0.01000214
  -0.02450562]
 [-0.00231552 -0.57470703  0.10601807 ..., -0.01148224  0.01009369
  -0.02297974]]
After layer decoder_rnn_hidden_fc_t0_output (20, 512) <class 'numpy.float16'> [[-1.86914062  0.20568848 -0.78564453 ...,  1.88867188  2.03710938
  -1.54785156]
 [-1.87988281  0.2088623  -0.79589844 ...,  1.89355469  2.04101562
  -1.54785156]
 [-1.7578125   0.21032715 -0.75390625 ...,  1.80761719  2.00390625
  -1.52050781]
 ...,
 [-1.86816406  0.21740723 -0.79833984 ...,  1.88769531  2.02734375
  -1.53515625]
 [-1.40429688  0.59667969 -1.36816406 ...,  1.98339844  1.41308594
   0.14416504]
 [-1.25       -0.66894531  0.03811646 ...,  1.22753906  1.84375    -0.35058594]]
After layer decoder_rnn_next_hidden_t0_output (20, 512) <class 'numpy.float16'> [[-0.95361328  0.20288086 -0.65576172 ...,  0.95507812  0.96679688
  -0.91357422]
 [-0.95458984  0.20593262 -0.66162109 ...,  0.95556641  0.96679688
  -0.91357422]
 [-0.94238281  0.20727539 -0.63769531 ...,  0.94775391  0.96435547
  -0.90869141]
 ...,
 [-0.95361328  0.21398926 -0.66308594 ...,  0.95507812  0.96582031
  -0.91113281]
 [-0.88623047  0.53466797 -0.87841797 ...,  0.96289062  0.88818359
   0.14318848]
 [-0.84814453 -0.58447266  0.03808594 ...,  0.84179688  0.95117188
  -0.33691406]]
After layer logits_output (20, 16743) <class 'numpy.float16'> [[-1.95996094 -2.80859375 -2.39453125 ..., -2.09570312 -3.47851562
  -2.53515625]
 [-1.96386719 -2.80273438 -2.39648438 ..., -2.09570312 -3.47460938
  -2.53515625]
 [-1.91796875 -2.79882812 -2.38476562 ..., -2.0859375  -3.45117188
  -2.51367188]
 ...,
 [-1.95410156 -2.79296875 -2.3828125  ..., -2.08789062 -3.45898438
  -2.52539062]
 [-1.35253906 -2.29492188 -1.21582031 ..., -1.31933594 -2.45117188
  -1.46777344]
 [-1.59277344 -2.83007812 -1.54199219 ..., -2.06445312 -3.03125    -2.35546875]]
After layer softmax_0 (20, 16743) <class 'numpy.float16'> [[  8.94069672e-07   4.17232513e-07   5.96046448e-07 ...,   7.74860382e-07
    1.78813934e-07   5.36441803e-07]
 [  8.94069672e-07   4.17232513e-07   5.96046448e-07 ...,   8.34465027e-07
    1.78813934e-07   5.36441803e-07]
 [  1.07288361e-06   4.17232513e-07   6.55651093e-07 ...,   8.94069672e-07
    2.38418579e-07   5.96046448e-07]
 ...,
 [  9.53674316e-07   4.17232513e-07   6.55651093e-07 ...,   8.34465027e-07
    2.38418579e-07   5.36441803e-07]
 [  7.68899918e-06   2.98023224e-06   8.82148743e-06 ...,   7.92741776e-06
    2.56299973e-06   6.85453415e-06]
 [  3.93390656e-06   1.13248825e-06   4.17232513e-06 ...,   2.50339508e-06
    9.53674316e-07   1.84774399e-06]]
After layer reshape15_0 (20, 10) <class 'numpy.float16'> [[ 0.40698242  0.59277344  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40844727  0.59179688  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.41503906  0.58496094  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40844727  0.59179688  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40673828  0.59326172  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.39819336  0.60205078  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40795898  0.59179688  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.41845703  0.58203125  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40820312  0.59179688  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40771484  0.59228516  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40917969  0.59130859  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.41064453  0.58935547  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.43823242  0.56152344  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.41113281  0.58935547  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.34423828  0.65576172  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40917969  0.59082031  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.56542969  0.43457031  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40966797  0.58984375  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.39697266  0.60302734  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.31030273  0.68945312  0.          0.          0.          0.          0.
   0.          0.          0.        ]]
After layer target_embed_embed_0 (20, 256) <class 'numpy.float16'> [[-0.05505371 -0.0300293  -0.03598022 ...,  0.08459473 -0.05288696
  -0.01667786]
 [-0.05505371 -0.0300293  -0.03598022 ...,  0.08459473 -0.05288696
  -0.01667786]
 [-0.05505371 -0.0300293  -0.03598022 ...,  0.08459473 -0.05288696
  -0.01667786]
 ...,
 [ 0.02738953 -0.07226562 -0.00852966 ...,  0.02572632  0.00955963
  -0.04855347]
 [-0.05505371 -0.0300293  -0.03598022 ...,  0.08459473 -0.05288696
  -0.01667786]
 [ 0.13598633  0.02095032  0.05236816 ..., -0.01808167 -0.03991699
  -0.14160156]]
After layer decoder_rnn_concat_target_context_t0_output (20, 768) <class 'numpy.float16'> [[-0.05505371 -0.0300293  -0.03598022 ...,  0.95507812  0.96679688
  -0.91357422]
 [-0.05505371 -0.0300293  -0.03598022 ...,  0.95556641  0.96679688
  -0.91357422]
 [-0.05505371 -0.0300293  -0.03598022 ...,  0.94775391  0.96435547
  -0.90869141]
 ...,
 [ 0.02738953 -0.07226562 -0.00852966 ...,  0.79980469  0.93505859  0.625     ]
 [-0.05505371 -0.0300293  -0.03598022 ...,  0.95556641  0.96630859
  -0.91210938]
 [ 0.13598633  0.02095032  0.05236816 ...,  0.79980469  0.93505859  0.625     ]]
After layer decoder_rnn_l0_t0_i2h_output (20, 2048) <class 'numpy.float16'> [[-3.15234375  1.60644531  2.40429688 ..., -0.07354736  3.85351562
   0.60302734]
 [-3.1484375   1.60449219  2.40429688 ..., -0.07196045  3.84570312
   0.60107422]
 [-3.11914062  1.59667969  2.37109375 ..., -0.07580566  3.83398438
   0.63525391]
 ...,
 [-2.60742188  1.59082031  1.59570312 ..., -0.72265625  3.2734375
   1.20605469]
 [-3.13867188  1.59863281  2.40234375 ..., -0.07427979  3.83398438
   0.60205078]
 [-2.90039062  1.66015625  1.58007812 ..., -1.67480469  3.10742188
   1.66601562]]
After layer decoder_rnn_l0_t0_h2h_output (20, 2048) <class 'numpy.float16'> [[-0.3371582   0.46533203  1.77832031 ...,  0.68408203  1.28417969
   0.1583252 ]
 [-0.34033203  0.47241211  1.77539062 ...,  0.68164062  1.28027344
   0.15356445]
 [-0.37817383  0.46777344  1.76757812 ...,  0.62695312  1.28027344
   0.18554688]
 ...,
 [-0.55322266  0.53271484  1.51757812 ..., -0.12548828  1.26660156
   0.24963379]
 [-0.35424805  0.49047852  1.77441406 ...,  0.66796875  1.28320312
   0.14367676]
 [-0.55322266  0.53271484  1.51757812 ..., -0.12548828  1.26660156
   0.24963379]]
After layer _plus1052_0 (20, 2048) <class 'numpy.float16'> [[-3.49023438  2.07226562  4.18359375 ...,  0.61035156  5.13671875
   0.76123047]
 [-3.48828125  2.07617188  4.1796875  ...,  0.60986328  5.125       0.75488281]
 [-3.49804688  2.06445312  4.140625   ...,  0.55126953  5.11328125
   0.82080078]
 ...,
 [-3.16015625  2.12304688  3.11328125 ..., -0.84814453  4.5390625
   1.45605469]
 [-3.4921875   2.08984375  4.17578125 ...,  0.59375     5.1171875
   0.74560547]
 [-3.453125    2.19335938  3.09765625 ..., -1.80078125  4.375       1.91601562]]
After layer decoder_rnn_l0_t0_slice_output0 (20, 512) <class 'numpy.float16'> [[-3.49023438  2.07226562  4.18359375 ...,  1.75195312  4.5234375
   2.73632812]
 [-3.48828125  2.07617188  4.1796875  ...,  1.74804688  4.52734375
   2.73046875]
 [-3.49804688  2.06445312  4.140625   ...,  1.76171875  4.48828125
   2.70898438]
 ...,
 [-3.16015625  2.12304688  3.11328125 ...,  1.76757812  3.88867188
   2.0546875 ]
 [-3.4921875   2.08984375  4.17578125 ...,  1.73632812  4.5234375
   2.72265625]
 [-3.453125    2.19335938  3.09765625 ...,  1.77539062  3.70703125
   2.078125  ]]
After layer decoder_rnn_l0_t0_slice_output1 (20, 512) <class 'numpy.float16'> [[-1.90625     2.27929688  2.3515625  ...,  3.12890625 -0.80908203
   1.91796875]
 [-1.91015625  2.27539062  2.35546875 ...,  3.11914062 -0.79833984
   1.91015625]
 [-1.94140625  2.27929688  2.33984375 ...,  3.06835938 -0.88769531
   1.90917969]
 ...,
 [-2.28125     1.88671875  1.75097656 ...,  1.90234375 -0.62988281
   1.02148438]
 [-1.92480469  2.28125     2.3515625  ...,  3.1015625  -0.79003906
   1.89648438]
 [-2.22851562  1.93359375  1.66210938 ...,  1.8984375  -0.08953857
   1.046875  ]]
After layer decoder_rnn_l0_t0_slice_output2 (20, 512) <class 'numpy.float16'> [[-2.76367188 -3.03320312  2.82421875 ...,  4.2109375  -0.09570312
   2.13671875]
 [-2.7578125  -3.03515625  2.82617188 ...,  4.1953125  -0.10229492
   2.13476562]
 [-2.74414062 -3.00195312  2.80664062 ...,  4.16015625 -0.14916992
   2.12109375]
 ...,
 [-2.87109375 -2.046875    1.71484375 ...,  3.63671875 -2.36328125  1.78125   ]
 [-2.73828125 -3.02929688  2.81835938 ...,  4.17578125 -0.12890625  2.125     ]
 [-2.796875   -2.0546875   1.62109375 ...,  3.55664062 -2.55859375
   1.81640625]]
After layer decoder_rnn_l0_t0_slice_output3 (20, 512) <class 'numpy.float16'> [[-3.2734375   2.4921875  -1.42285156 ...,  0.61035156  5.13671875
   0.76123047]
 [-3.27539062  2.49804688 -1.42871094 ...,  0.60986328  5.125       0.75488281]
 [-3.30273438  2.55078125 -1.46972656 ...,  0.55126953  5.11328125
   0.82080078]
 ...,
 [-2.99414062  1.375      -0.80810547 ..., -0.84814453  4.5390625
   1.45605469]
 [-3.27734375  2.5078125  -1.44140625 ...,  0.59375     5.1171875
   0.74560547]
 [-3.09179688  1.01660156 -2.79296875 ..., -1.80078125  4.375       1.91601562]]
After layer decoder_rnn_l0_t0_o_output (20, 512) <class 'numpy.float16'> [[ 0.03649902  0.92382812  0.19421387 ...,  0.64794922  0.99414062
   0.68164062]
 [ 0.03643799  0.92382812  0.19335938 ...,  0.64794922  0.99414062
   0.68017578]
 [ 0.03549194  0.92773438  0.18701172 ...,  0.63427734  0.99414062
   0.69433594]
 ...,
 [ 0.04769897  0.79833984  0.30834961 ...,  0.29980469  0.98925781
   0.81103516]
 [ 0.03634644  0.92480469  0.19128418 ...,  0.64404297  0.99414062
   0.67822266]
 [ 0.04345703  0.734375    0.05770874 ...,  0.14172363  0.98779297
   0.87158203]]
After layer decoder_rnn_l0_t0_f_output (20, 512) <class 'numpy.float16'> [[ 0.12939453  0.90722656  0.91308594 ...,  0.95800781  0.30810547
   0.87207031]
 [ 0.12890625  0.90673828  0.91357422 ...,  0.95751953  0.31030273
   0.87109375]
 [ 0.12548828  0.90722656  0.91210938 ...,  0.95556641  0.29150391
   0.87109375]
 ...,
 [ 0.0927124   0.86816406  0.85205078 ...,  0.87011719  0.34765625
   0.73535156]
 [ 0.12731934  0.90722656  0.91308594 ...,  0.95703125  0.31225586
   0.86962891]
 [ 0.097229    0.87353516  0.84033203 ...,  0.86962891  0.47753906
   0.74023438]]
After layer _mul2104_0 (20, 512) <class 'numpy.float16'> [[ -4.27627563e-03  -3.44140625e+00   3.88476562e+00 ...,   4.15234375e+00
   -5.01708984e-02   3.12304688e+00]
 [ -4.29534912e-03  -3.44140625e+00   3.83984375e+00 ...,   4.05468750e+00
   -6.49414062e-02   3.04492188e+00]
 [ -3.73268127e-03  -3.40234375e+00   3.87304688e+00 ...,   3.91601562e+00
   -2.62451172e-02   2.92773438e+00]
 ...,
 [ -3.09181213e-03  -2.83398438e+00   3.23828125e+00 ...,   3.20898438e+00
   -4.73632812e-01   2.13085938e+00]
 [ -4.17327881e-03  -3.43945312e+00   3.82617188e+00 ...,   4.00390625e+00
   -8.76464844e-02   2.99218750e+00]
 [ -3.24249268e-03  -2.85156250e+00   3.19335938e+00 ...,   3.20703125e+00
   -6.50390625e-01   2.14648438e+00]]
After layer decoder_rnn_l0_t0_i_output (20, 512) <class 'numpy.float16'> [[ 0.02958679  0.88818359  0.98486328 ...,  0.85205078  0.98925781
   0.93896484]
 [ 0.02964783  0.88867188  0.98486328 ...,  0.8515625   0.98925781
   0.93896484]
 [ 0.02937317  0.88720703  0.984375   ...,  0.85351562  0.98876953  0.9375    ]
 ...,
 [ 0.04067993  0.89306641  0.95751953 ...,  0.85400391  0.97998047
   0.88623047]
 [ 0.02954102  0.89013672  0.98486328 ...,  0.85009766  0.98925781
   0.93847656]
 [ 0.03067017  0.89941406  0.95703125 ...,  0.85498047  0.97607422
   0.88867188]]
After layer decoder_rnn_l0_t0_c_output (20, 512) <class 'numpy.float16'> [[-0.9921875  -0.99560547  0.99316406 ...,  0.99951172 -0.09539795
   0.97265625]
 [-0.9921875  -0.99560547  0.99316406 ...,  0.99951172 -0.10192871
   0.97216797]
 [-0.99169922 -0.99511719  0.99267578 ...,  0.99951172 -0.14807129
   0.97167969]
 ...,
 [-0.99365234 -0.96728516  0.93701172 ...,  0.99853516 -0.98242188
   0.94482422]
 [-0.99169922 -0.99511719  0.99267578 ...,  0.99951172 -0.12817383
   0.97167969]
 [-0.99267578 -0.96777344  0.92480469 ...,  0.99853516 -0.98828125
   0.94824219]]
After layer _mul2105_0 (20, 512) <class 'numpy.float16'> [[-0.02935791 -0.88427734  0.97802734 ...,  0.8515625  -0.09436035
   0.91308594]
 [-0.02941895 -0.88476562  0.97802734 ...,  0.85107422 -0.10083008
   0.91259766]
 [-0.02912903 -0.8828125   0.97705078 ...,  0.85302734 -0.1463623
   0.91113281]
 ...,
 [-0.04043579 -0.86376953  0.89697266 ...,  0.85253906 -0.96289062
   0.83740234]
 [-0.02929688 -0.88574219  0.97753906 ...,  0.84960938 -0.12683105
   0.91210938]
 [-0.03044128 -0.87060547  0.88525391 ...,  0.85351562 -0.96484375
   0.84277344]]
After layer decoder_rnn_l0_t0_state_0 (20, 512) <class 'numpy.float16'> [[-0.03363037 -4.32421875  4.86328125 ...,  5.00390625 -0.14453125
   4.03515625]
 [-0.03372192 -4.328125    4.81640625 ...,  4.90625    -0.16577148
   3.95703125]
 [-0.03286743 -4.28515625  4.8515625  ...,  4.76953125 -0.17260742
   3.83984375]
 ...,
 [-0.04351807 -3.69726562  4.13671875 ...,  4.0625     -1.43652344  2.96875   ]
 [-0.03347778 -4.32421875  4.8046875  ...,  4.8515625  -0.21447754
   3.90429688]
 [-0.03369141 -3.72265625  4.078125   ...,  4.0625     -1.61523438
   2.98828125]]
After layer activation1052_output (20, 512) <class 'numpy.float16'> [[-0.03363037 -0.99951172  1.         ...,  1.         -0.14355469
   0.99951172]
 [-0.03372192 -0.99951172  1.         ...,  1.         -0.16430664
   0.99951172]
 [-0.03286743 -0.99951172  1.         ...,  1.         -0.17089844
   0.99902344]
 ...,
 [-0.04348755 -0.99853516  0.99951172 ...,  0.99951172 -0.89306641
   0.99462891]
 [-0.03347778 -0.99951172  1.         ...,  1.         -0.21130371
   0.99902344]
 [-0.03369141 -0.99902344  0.99951172 ...,  0.99951172 -0.92382812
   0.99511719]]
After layer decoder_rnn_l0_t0_out_0 (20, 512) <class 'numpy.float16'> [[-0.00122738 -0.92333984  0.19421387 ...,  0.64794922 -0.1427002
   0.68115234]
 [-0.00122833 -0.92333984  0.19335938 ...,  0.64794922 -0.16333008
   0.6796875 ]
 [-0.00116634 -0.92724609  0.18701172 ...,  0.63427734 -0.16992188
   0.69384766]
 ...,
 [-0.0020752  -0.79736328  0.30810547 ...,  0.29956055 -0.88330078
   0.80664062]
 [-0.00121689 -0.92431641  0.19128418 ...,  0.64404297 -0.21008301
   0.67773438]
 [-0.00146389 -0.73388672  0.05767822 ...,  0.14160156 -0.91259766
   0.8671875 ]]
After layer expand_dims1061_0 (20, 512, 1) <class 'numpy.float16'> [[[-0.00122738]
  [-0.92333984]
  [ 0.19421387]
  ...,
  [ 0.64794922]
  [-0.1427002 ]
  [ 0.68115234]]

 [[-0.00122833]
  [-0.92333984]
  [ 0.19335938]
  ...,
  [ 0.64794922]
  [-0.16333008]
  [ 0.6796875 ]]

 [[-0.00116634]
  [-0.92724609]
  [ 0.18701172]
  ...,
  [ 0.63427734]
  [-0.16992188]
  [ 0.69384766]]

 ...,
 [[-0.0020752 ]
  [-0.79736328]
  [ 0.30810547]
  ...,
  [ 0.29956055]
  [-0.88330078]
  [ 0.80664062]]

 [[-0.00121689]
  [-0.92431641]
  [ 0.19128418]
  ...,
  [ 0.64404297]
  [-0.21008301]
  [ 0.67773438]]

 [[-0.00146389]
  [-0.73388672]
  [ 0.05767822]
  ...,
  [ 0.14160156]
  [-0.91259766]
  [ 0.8671875 ]]]
After layer att_batch_dot_0 (20, 10, 1) <class 'numpy.float16'> [[[  5.15136719e-01]
  [  9.03320312e-01]
  [  1.56347656e+00]
  [  2.46484375e+00]
  [  2.31835938e+00]
  [  4.36401367e-02]
  [ -3.19531250e+00]
  [ -6.03125000e+00]
  [ -8.15625000e+00]
  [ -9.74218750e+00]]

 [[  5.16601562e-01]
  [  9.01367188e-01]
  [  1.56640625e+00]
  [  2.47265625e+00]
  [  2.32812500e+00]
  [  5.02319336e-02]
  [ -3.19531250e+00]
  [ -6.03515625e+00]
  [ -8.15625000e+00]
  [ -9.74218750e+00]]

 [[  5.01953125e-01]
  [  8.70117188e-01]
  [  1.49218750e+00]
  [  2.32226562e+00]
  [  2.07617188e+00]
  [ -3.12255859e-01]
  [ -3.64843750e+00]
  [ -6.55468750e+00]
  [ -8.71875000e+00]
  [ -1.03281250e+01]]

 [[  5.19531250e-01]
  [  9.05761719e-01]
  [  1.58300781e+00]
  [  2.50585938e+00]
  [  2.37695312e+00]
  [  1.03149414e-01]
  [ -3.14648438e+00]
  [ -5.99609375e+00]
  [ -8.12500000e+00]
  [ -9.71093750e+00]]

 [[  5.95214844e-01]
  [  1.00488281e+00]
  [  1.78320312e+00]
  [  2.84765625e+00]
  [  2.91210938e+00]
  [  8.41308594e-01]
  [ -2.23046875e+00]
  [ -4.94531250e+00]
  [ -7.00781250e+00]
  [ -8.58593750e+00]]

 [[  5.19531250e-01]
  [  8.75000000e-01]
  [  1.50585938e+00]
  [  2.33398438e+00]
  [  2.07617188e+00]
  [ -3.36425781e-01]
  [ -3.69531250e+00]
  [ -6.60156250e+00]
  [ -8.76562500e+00]
  [ -1.03671875e+01]]

 [[  5.15625000e-01]
  [  9.04296875e-01]
  [  1.56738281e+00]
  [  2.47265625e+00]
  [  2.33007812e+00]
  [  5.82275391e-02]
  [ -3.17968750e+00]
  [ -6.01953125e+00]
  [ -8.14062500e+00]
  [ -9.72656250e+00]]

 [[  5.14160156e-01]
  [  8.98925781e-01]
  [  1.55273438e+00]
  [  2.44140625e+00]
  [  2.28320312e+00]
  [ -1.10054016e-03]
  [ -3.24414062e+00]
  [ -6.08203125e+00]
  [ -8.21093750e+00]
  [ -9.78906250e+00]]

 [[  6.05957031e-01]
  [  9.41406250e-01]
  [  1.64355469e+00]
  [  2.53320312e+00]
  [  2.41406250e+00]
  [  2.41699219e-01]
  [ -2.83789062e+00]
  [ -5.49218750e+00]
  [ -7.47656250e+00]
  [ -8.99218750e+00]]

 [[  4.97802734e-01]
  [  8.57421875e-01]
  [  1.46093750e+00]
  [  2.25976562e+00]
  [  1.97363281e+00]
  [ -4.46777344e-01]
  [ -3.80273438e+00]
  [ -6.71875000e+00]
  [ -8.89062500e+00]
  [ -1.04921875e+01]]

 [[  5.16601562e-01]
  [  9.01855469e-01]
  [  1.56738281e+00]
  [  2.47265625e+00]
  [  2.33007812e+00]
  [  5.40466309e-02]
  [ -3.18945312e+00]
  [ -6.02734375e+00]
  [ -8.15625000e+00]
  [ -9.73437500e+00]]

 [[  5.17578125e-01]
  [  9.04296875e-01]
  [  1.57226562e+00]
  [  2.48437500e+00]
  [  2.34765625e+00]
  [  7.45849609e-02]
  [ -3.16601562e+00]
  [ -6.00781250e+00]
  [ -8.13281250e+00]
  [ -9.71093750e+00]]

 [[  5.18066406e-01]
  [  9.02343750e-01]
  [  1.57324219e+00]
  [  2.48632812e+00]
  [  2.34765625e+00]
  [  6.70166016e-02]
  [ -3.18554688e+00]
  [ -6.03125000e+00]
  [ -8.16406250e+00]
  [ -9.75000000e+00]]

 [[  5.20019531e-01]
  [  9.02832031e-01]
  [  1.58105469e+00]
  [  2.50195312e+00]
  [  2.36523438e+00]
  [  8.03833008e-02]
  [ -3.17968750e+00]
  [ -6.03515625e+00]
  [ -8.17187500e+00]
  [ -9.76562500e+00]]

 [[  5.54199219e-01]
  [  8.65722656e-01]
  [  1.72363281e+00]
  [  2.74218750e+00]
  [  2.73828125e+00]
  [  6.38183594e-01]
  [ -2.41796875e+00]
  [ -5.08203125e+00]
  [ -7.07031250e+00]
  [ -8.56250000e+00]]

 [[  5.16113281e-01]
  [  7.61230469e-01]
  [  1.41992188e+00]
  [  2.14453125e+00]
  [  1.55371094e+00]
  [ -1.42382812e+00]
  [ -5.41796875e+00]
  [ -8.87500000e+00]
  [ -1.14140625e+01]
  [ -1.32265625e+01]]

 [[  5.20996094e-01]
  [  9.03808594e-01]
  [  1.58886719e+00]
  [  2.51757812e+00]
  [  2.38867188e+00]
  [  9.83886719e-02]
  [ -3.17187500e+00]
  [ -6.03515625e+00]
  [ -8.17968750e+00]
  [ -9.77343750e+00]]

 [[  5.48339844e-01]
  [  6.78222656e-01]
  [  1.23925781e+00]
  [  1.69628906e+00]
  [  7.78808594e-01]
  [ -2.47460938e+00]
  [ -6.62500000e+00]
  [ -1.01171875e+01]
  [ -1.26093750e+01]
  [ -1.43750000e+01]]

 [[  5.19042969e-01]
  [  9.02832031e-01]
  [  1.57714844e+00]
  [  2.49414062e+00]
  [  2.35742188e+00]
  [  7.28149414e-02]
  [ -3.18554688e+00]
  [ -6.03906250e+00]
  [ -8.17187500e+00]
  [ -9.76562500e+00]]

 [[  6.82128906e-01]
  [  1.36914062e+00]
  [  3.15234375e+00]
  [  5.74218750e+00]
  [  8.28906250e+00]
  [  9.42187500e+00]
  [  9.39062500e+00]
  [  8.93750000e+00]
  [  8.29687500e+00]
  [  7.54296875e+00]]]
After layer swapaxes25_output (10, 20, 1) <class 'numpy.float16'> [[[  5.15136719e-01]
  [  5.16601562e-01]
  [  5.01953125e-01]
  [  5.19531250e-01]
  [  5.95214844e-01]
  [  5.19531250e-01]
  [  5.15625000e-01]
  [  5.14160156e-01]
  [  6.05957031e-01]
  [  4.97802734e-01]
  [  5.16601562e-01]
  [  5.17578125e-01]
  [  5.18066406e-01]
  [  5.20019531e-01]
  [  5.54199219e-01]
  [  5.16113281e-01]
  [  5.20996094e-01]
  [  5.48339844e-01]
  [  5.19042969e-01]
  [  6.82128906e-01]]

 [[  9.03320312e-01]
  [  9.01367188e-01]
  [  8.70117188e-01]
  [  9.05761719e-01]
  [  1.00488281e+00]
  [  8.75000000e-01]
  [  9.04296875e-01]
  [  8.98925781e-01]
  [  9.41406250e-01]
  [  8.57421875e-01]
  [  9.01855469e-01]
  [  9.04296875e-01]
  [  9.02343750e-01]
  [  9.02832031e-01]
  [  8.65722656e-01]
  [  7.61230469e-01]
  [  9.03808594e-01]
  [  6.78222656e-01]
  [  9.02832031e-01]
  [  1.36914062e+00]]

 [[  1.56347656e+00]
  [  1.56640625e+00]
  [  1.49218750e+00]
  [  1.58300781e+00]
  [  1.78320312e+00]
  [  1.50585938e+00]
  [  1.56738281e+00]
  [  1.55273438e+00]
  [  1.64355469e+00]
  [  1.46093750e+00]
  [  1.56738281e+00]
  [  1.57226562e+00]
  [  1.57324219e+00]
  [  1.58105469e+00]
  [  1.72363281e+00]
  [  1.41992188e+00]
  [  1.58886719e+00]
  [  1.23925781e+00]
  [  1.57714844e+00]
  [  3.15234375e+00]]

 [[  2.46484375e+00]
  [  2.47265625e+00]
  [  2.32226562e+00]
  [  2.50585938e+00]
  [  2.84765625e+00]
  [  2.33398438e+00]
  [  2.47265625e+00]
  [  2.44140625e+00]
  [  2.53320312e+00]
  [  2.25976562e+00]
  [  2.47265625e+00]
  [  2.48437500e+00]
  [  2.48632812e+00]
  [  2.50195312e+00]
  [  2.74218750e+00]
  [  2.14453125e+00]
  [  2.51757812e+00]
  [  1.69628906e+00]
  [  2.49414062e+00]
  [  5.74218750e+00]]

 [[  2.31835938e+00]
  [  2.32812500e+00]
  [  2.07617188e+00]
  [  2.37695312e+00]
  [  2.91210938e+00]
  [  2.07617188e+00]
  [  2.33007812e+00]
  [  2.28320312e+00]
  [  2.41406250e+00]
  [  1.97363281e+00]
  [  2.33007812e+00]
  [  2.34765625e+00]
  [  2.34765625e+00]
  [  2.36523438e+00]
  [  2.73828125e+00]
  [  1.55371094e+00]
  [  2.38867188e+00]
  [  7.78808594e-01]
  [  2.35742188e+00]
  [  8.28906250e+00]]

 [[  4.36401367e-02]
  [  5.02319336e-02]
  [ -3.12255859e-01]
  [  1.03149414e-01]
  [  8.41308594e-01]
  [ -3.36425781e-01]
  [  5.82275391e-02]
  [ -1.10054016e-03]
  [  2.41699219e-01]
  [ -4.46777344e-01]
  [  5.40466309e-02]
  [  7.45849609e-02]
  [  6.70166016e-02]
  [  8.03833008e-02]
  [  6.38183594e-01]
  [ -1.42382812e+00]
  [  9.83886719e-02]
  [ -2.47460938e+00]
  [  7.28149414e-02]
  [  9.42187500e+00]]

 [[ -3.19531250e+00]
  [ -3.19531250e+00]
  [ -3.64843750e+00]
  [ -3.14648438e+00]
  [ -2.23046875e+00]
  [ -3.69531250e+00]
  [ -3.17968750e+00]
  [ -3.24414062e+00]
  [ -2.83789062e+00]
  [ -3.80273438e+00]
  [ -3.18945312e+00]
  [ -3.16601562e+00]
  [ -3.18554688e+00]
  [ -3.17968750e+00]
  [ -2.41796875e+00]
  [ -5.41796875e+00]
  [ -3.17187500e+00]
  [ -6.62500000e+00]
  [ -3.18554688e+00]
  [  9.39062500e+00]]

 [[ -6.03125000e+00]
  [ -6.03515625e+00]
  [ -6.55468750e+00]
  [ -5.99609375e+00]
  [ -4.94531250e+00]
  [ -6.60156250e+00]
  [ -6.01953125e+00]
  [ -6.08203125e+00]
  [ -5.49218750e+00]
  [ -6.71875000e+00]
  [ -6.02734375e+00]
  [ -6.00781250e+00]
  [ -6.03125000e+00]
  [ -6.03515625e+00]
  [ -5.08203125e+00]
  [ -8.87500000e+00]
  [ -6.03515625e+00]
  [ -1.01171875e+01]
  [ -6.03906250e+00]
  [  8.93750000e+00]]

 [[ -8.15625000e+00]
  [ -8.15625000e+00]
  [ -8.71875000e+00]
  [ -8.12500000e+00]
  [ -7.00781250e+00]
  [ -8.76562500e+00]
  [ -8.14062500e+00]
  [ -8.21093750e+00]
  [ -7.47656250e+00]
  [ -8.89062500e+00]
  [ -8.15625000e+00]
  [ -8.13281250e+00]
  [ -8.16406250e+00]
  [ -8.17187500e+00]
  [ -7.07031250e+00]
  [ -1.14140625e+01]
  [ -8.17968750e+00]
  [ -1.26093750e+01]
  [ -8.17187500e+00]
  [  8.29687500e+00]]

 [[ -9.74218750e+00]
  [ -9.74218750e+00]
  [ -1.03281250e+01]
  [ -9.71093750e+00]
  [ -8.58593750e+00]
  [ -1.03671875e+01]
  [ -9.72656250e+00]
  [ -9.78906250e+00]
  [ -8.99218750e+00]
  [ -1.04921875e+01]
  [ -9.73437500e+00]
  [ -9.71093750e+00]
  [ -9.75000000e+00]
  [ -9.76562500e+00]
  [ -8.56250000e+00]
  [ -1.32265625e+01]
  [ -9.77343750e+00]
  [ -1.43750000e+01]
  [ -9.76562500e+00]
  [  7.54296875e+00]]]
After layer sequencemask8_output (10, 20, 1) <class 'numpy.float16'> [[[  5.15136719e-01]
  [  5.16601562e-01]
  [  5.01953125e-01]
  [  5.19531250e-01]
  [  5.95214844e-01]
  [  5.19531250e-01]
  [  5.15625000e-01]
  [  5.14160156e-01]
  [  6.05957031e-01]
  [  4.97802734e-01]
  [  5.16601562e-01]
  [  5.17578125e-01]
  [  5.18066406e-01]
  [  5.20019531e-01]
  [  5.54199219e-01]
  [  5.16113281e-01]
  [  5.20996094e-01]
  [  5.48339844e-01]
  [  5.19042969e-01]
  [  6.82128906e-01]]

 [[  9.03320312e-01]
  [  9.01367188e-01]
  [  8.70117188e-01]
  [  9.05761719e-01]
  [  1.00488281e+00]
  [  8.75000000e-01]
  [  9.04296875e-01]
  [  8.98925781e-01]
  [  9.41406250e-01]
  [  8.57421875e-01]
  [  9.01855469e-01]
  [  9.04296875e-01]
  [  9.02343750e-01]
  [  9.02832031e-01]
  [  8.65722656e-01]
  [  7.61230469e-01]
  [  9.03808594e-01]
  [  6.78222656e-01]
  [  9.02832031e-01]
  [  1.36914062e+00]]

 [[ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]]
After layer swapaxes26_output (20, 10, 1) <class 'numpy.float16'> [[[  5.15136719e-01]
  [  9.03320312e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  5.16601562e-01]
  [  9.01367188e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  5.01953125e-01]
  [  8.70117188e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  5.19531250e-01]
  [  9.05761719e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  5.95214844e-01]
  [  1.00488281e+00]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  5.19531250e-01]
  [  8.75000000e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  5.15625000e-01]
  [  9.04296875e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  5.14160156e-01]
  [  8.98925781e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  6.05957031e-01]
  [  9.41406250e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  4.97802734e-01]
  [  8.57421875e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  5.16601562e-01]
  [  9.01855469e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  5.17578125e-01]
  [  9.04296875e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  5.18066406e-01]
  [  9.02343750e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  5.20019531e-01]
  [  9.02832031e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  5.54199219e-01]
  [  8.65722656e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  5.16113281e-01]
  [  7.61230469e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  5.20996094e-01]
  [  9.03808594e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  5.48339844e-01]
  [  6.78222656e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  5.19042969e-01]
  [  9.02832031e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  6.82128906e-01]
  [  1.36914062e+00]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]]
After layer attention_softmax_0 (20, 10, 1) <class 'numpy.float16'> [[[ 0.40429688]
  [ 0.59619141]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.4050293 ]
  [ 0.59521484]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40917969]
  [ 0.59130859]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40454102]
  [ 0.59521484]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.39892578]
  [ 0.60107422]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.41186523]
  [ 0.58789062]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40405273]
  [ 0.59619141]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.4050293 ]
  [ 0.59521484]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.41699219]
  [ 0.58300781]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.41113281]
  [ 0.58935547]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.4050293 ]
  [ 0.59521484]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40429688]
  [ 0.59521484]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.4050293 ]
  [ 0.59472656]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40551758]
  [ 0.59472656]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.42260742]
  [ 0.57714844]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.43896484]
  [ 0.56054688]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40551758]
  [ 0.59472656]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.46728516]
  [ 0.53222656]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.4050293 ]
  [ 0.59472656]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.3347168 ]
  [ 0.66552734]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]]
After layer batch_dot8_0 (20, 512, 1) <class 'numpy.float16'> [[[ 0.01783752]
  [ 0.03942871]
  [-0.03338623]
  ...,
  [-0.01097107]
  [ 0.00999451]
  [-0.0246582 ]]

 [[ 0.01782227]
  [ 0.03939819]
  [-0.03335571]
  ...,
  [-0.01096344]
  [ 0.00999451]
  [-0.0246582 ]]

 [[ 0.01773071]
  [ 0.03930664]
  [-0.03317261]
  ...,
  [-0.01094818]
  [ 0.00998688]
  [-0.0247345 ]]

 ...,
 [[ 0.01629639]
  [ 0.03762817]
  [-0.03050232]
  ...,
  [-0.01061249]
  [ 0.00991058]
  [-0.02574158]]

 [[ 0.01780701]
  [ 0.03939819]
  [-0.0333252 ]
  ...,
  [-0.01095581]
  [ 0.00998688]
  [-0.0246582 ]]

 [[ 0.01951599]
  [ 0.04138184]
  [-0.03649902]
  ...,
  [-0.01135254]
  [ 0.0100708 ]
  [-0.02342224]]]
After layer reshape16_0 (20, 512) <class 'numpy.float16'> [[ 0.01783752  0.03942871 -0.03338623 ..., -0.01097107  0.00999451
  -0.0246582 ]
 [ 0.01782227  0.03939819 -0.03335571 ..., -0.01096344  0.00999451
  -0.0246582 ]
 [ 0.01773071  0.03930664 -0.03317261 ..., -0.01094818  0.00998688
  -0.0247345 ]
 ...,
 [ 0.01629639  0.03762817 -0.03050232 ..., -0.01061249  0.00991058
  -0.02574158]
 [ 0.01780701  0.03939819 -0.0333252  ..., -0.01095581  0.00998688
  -0.0246582 ]
 [ 0.01951599  0.04138184 -0.03649902 ..., -0.01135254  0.0100708
  -0.02342224]]
After layer decoder_rnn_hidden_concat_t0_output (20, 1024) <class 'numpy.float16'> [[-0.00122738 -0.92333984  0.19421387 ..., -0.01097107  0.00999451
  -0.0246582 ]
 [-0.00122833 -0.92333984  0.19335938 ..., -0.01096344  0.00999451
  -0.0246582 ]
 [-0.00116634 -0.92724609  0.18701172 ..., -0.01094818  0.00998688
  -0.0247345 ]
 ...,
 [-0.0020752  -0.79736328  0.30810547 ..., -0.01061249  0.00991058
  -0.02574158]
 [-0.00121689 -0.92431641  0.19128418 ..., -0.01095581  0.00998688
  -0.0246582 ]
 [-0.00146389 -0.73388672  0.05767822 ..., -0.01135254  0.0100708
  -0.02342224]]
After layer decoder_rnn_hidden_fc_t0_output (20, 512) <class 'numpy.float16'> [[-1.91699219  0.20227051 -0.80175781 ...,  1.92382812  2.07226562
  -1.57714844]
 [-1.921875    0.20239258 -0.80517578 ...,  1.92675781  2.07617188
  -1.57421875]
 [-1.87890625  0.21716309 -0.80322266 ...,  1.89355469  2.0546875
  -1.5703125 ]
 ...,
 [-1.54492188 -0.96582031  0.51416016 ...,  1.20605469  2.31640625
  -1.89941406]
 [-1.92382812  0.2076416  -0.81201172 ...,  1.92871094  2.0703125
  -1.5703125 ]
 [-0.97314453 -0.49462891 -0.23193359 ...,  1.40917969  1.67285156
   0.58642578]]
After layer decoder_rnn_next_hidden_t0_output (20, 512) <class 'numpy.float16'> [[-0.95751953  0.19958496 -0.66503906 ...,  0.95800781  0.96875    -0.91796875]
 [-0.95800781  0.19970703 -0.66699219 ...,  0.95849609  0.96923828
  -0.91748047]
 [-0.95458984  0.21386719 -0.66601562 ...,  0.95556641  0.96777344
  -0.91699219]
 ...,
 [-0.91308594 -0.74707031  0.47314453 ...,  0.83544922  0.98095703
  -0.95605469]
 [-0.95800781  0.20471191 -0.67089844 ...,  0.95849609  0.96875    -0.91699219]
 [-0.75       -0.45776367 -0.22790527 ...,  0.88720703  0.93212891
   0.52734375]]
After layer logits_output (20, 16743) <class 'numpy.float16'> [[-1.984375   -2.81835938 -2.40820312 ..., -2.1015625  -3.4921875
  -2.55859375]
 [-1.98535156 -2.81445312 -2.40625    ..., -2.09960938 -3.48828125
  -2.55859375]
 [-1.96582031 -2.81054688 -2.40625    ..., -2.1015625  -3.47851562
  -2.54492188]
 ...,
 [-1.68164062 -3.22460938 -2.7890625  ..., -2.32226562 -3.375      -3.17578125]
 [-1.98242188 -2.80859375 -2.40039062 ..., -2.09765625 -3.48046875
  -2.55664062]
 [-1.5390625  -2.6953125  -0.92626953 ..., -1.54589844 -2.60546875
  -1.61035156]]
After layer softmax_0 (20, 16743) <class 'numpy.float16'> [[  8.34465027e-07   3.57627869e-07   5.36441803e-07 ...,   7.74860382e-07
    1.78813934e-07   4.76837158e-07]
 [  8.34465027e-07   3.57627869e-07   5.96046448e-07 ...,   7.74860382e-07
    1.78813934e-07   4.76837158e-07]
 [  8.94069672e-07   4.17232513e-07   5.96046448e-07 ...,   7.74860382e-07
    1.78813934e-07   5.36441803e-07]
 ...,
 [  5.96046448e-08   0.00000000e+00   0.00000000e+00 ...,   5.96046448e-08
    0.00000000e+00   0.00000000e+00]
 [  8.94069672e-07   4.17232513e-07   5.96046448e-07 ...,   7.74860382e-07
    1.78813934e-07   4.76837158e-07]
 [  6.97374344e-06   2.20537186e-06   1.29342079e-05 ...,   6.97374344e-06
    2.44379044e-06   6.49690628e-06]]
After layer reshape17_0 (20, 10) <class 'numpy.float16'> [[ 0.40429688  0.59619141  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.4050293   0.59521484  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40917969  0.59130859  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40454102  0.59521484  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.39892578  0.60107422  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.41186523  0.58789062  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40405273  0.59619141  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.4050293   0.59521484  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.41699219  0.58300781  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.41113281  0.58935547  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.4050293   0.59521484  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40429688  0.59521484  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.4050293   0.59472656  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40551758  0.59472656  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.42260742  0.57714844  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.43896484  0.56054688  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40551758  0.59472656  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.46728516  0.53222656  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.4050293   0.59472656  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.3347168   0.66552734  0.          0.          0.          0.          0.
   0.          0.          0.        ]]
After layer target_embed_embed_0 (20, 256) <class 'numpy.float16'> [[-0.05505371 -0.0300293  -0.03598022 ...,  0.08459473 -0.05288696
  -0.01667786]
 [-0.05505371 -0.0300293  -0.03598022 ...,  0.08459473 -0.05288696
  -0.01667786]
 [-0.05505371 -0.0300293  -0.03598022 ...,  0.08459473 -0.05288696
  -0.01667786]
 ...,
 [-0.05505371 -0.0300293  -0.03598022 ...,  0.08459473 -0.05288696
  -0.01667786]
 [ 0.02738953 -0.07226562 -0.00852966 ...,  0.02572632  0.00955963
  -0.04855347]
 [-0.05505371 -0.0300293  -0.03598022 ...,  0.08459473 -0.05288696
  -0.01667786]]
After layer decoder_rnn_concat_target_context_t0_output (20, 768) <class 'numpy.float16'> [[-0.05505371 -0.0300293  -0.03598022 ...,  0.95800781  0.96875    -0.91796875]
 [-0.05505371 -0.0300293  -0.03598022 ...,  0.95849609  0.96923828
  -0.91748047]
 [-0.05505371 -0.0300293  -0.03598022 ...,  0.95556641  0.96777344
  -0.91699219]
 ...,
 [-0.05505371 -0.0300293  -0.03598022 ...,  0.95898438  0.96875    -0.91699219]
 [ 0.02738953 -0.07226562 -0.00852966 ...,  0.88720703  0.93212891
   0.52734375]
 [-0.05505371 -0.0300293  -0.03598022 ...,  0.95849609  0.96875    -0.91699219]]
After layer decoder_rnn_l0_t0_i2h_output (20, 2048) <class 'numpy.float16'> [[-3.17382812  1.61230469  2.42382812 ..., -0.07354736  3.86523438
   0.60058594]
 [-3.171875    1.61132812  2.421875   ..., -0.07330322  3.859375
   0.60058594]
 [-3.15429688  1.60644531  2.40625    ..., -0.06799316  3.85546875
   0.61132812]
 ...,
 [-3.16210938  1.60351562  2.421875   ..., -0.07452393  3.84570312
   0.60302734]
 [-2.59765625  1.37304688  1.65722656 ..., -0.57324219  3.25        0.87011719]
 [-3.16601562  1.60644531  2.421875   ..., -0.07409668  3.8515625
   0.60058594]]
After layer decoder_rnn_l0_t0_h2h_output (20, 2048) <class 'numpy.float16'> [[-0.32641602  0.47119141  1.80175781 ...,  0.69628906  1.29296875
   0.16491699]
 [-0.328125    0.47485352  1.80078125 ...,  0.69335938  1.29003906
   0.16247559]
 [-0.34594727  0.47924805  1.79101562 ...,  0.67773438  1.29882812
   0.16210938]
 ...,
 [-0.34350586  0.49755859  1.80273438 ...,  0.68212891  1.296875
   0.15185547]
 [-0.53515625  0.55322266  1.47265625 ...,  0.04074097  1.24804688
   0.10223389]
 [-0.33642578  0.48779297  1.79980469 ...,  0.68408203  1.29394531
   0.15332031]]
After layer _plus1053_0 (20, 2048) <class 'numpy.float16'> [[-3.5         2.08398438  4.2265625  ...,  0.62255859  5.15625     0.765625  ]
 [-3.5         2.0859375   4.22265625 ...,  0.62011719  5.1484375
   0.76318359]
 [-3.5         2.0859375   4.1953125  ...,  0.60986328  5.15625     0.7734375 ]
 ...,
 [-3.50585938  2.1015625   4.2265625  ...,  0.60742188  5.140625
   0.75488281]
 [-3.1328125   1.92578125  3.12890625 ..., -0.53271484  4.5         0.97216797]
 [-3.50195312  2.09375     4.22265625 ...,  0.60986328  5.14453125
   0.75390625]]
After layer decoder_rnn_l0_t0_slice_output0 (20, 512) <class 'numpy.float16'> [[-3.5         2.08398438  4.2265625  ...,  1.75683594  4.5625      2.76171875]
 [-3.5         2.0859375   4.22265625 ...,  1.75292969  4.56640625
   2.7578125 ]
 [-3.5         2.0859375   4.1953125  ...,  1.76171875  4.52734375
   2.74609375]
 ...,
 [-3.50585938  2.1015625   4.2265625  ...,  1.73828125  4.5625      2.75390625]
 [-3.1328125   1.92578125  3.12890625 ...,  1.68164062  3.74609375
   2.13085938]
 [-3.50195312  2.09375     4.22265625 ...,  1.74414062  4.5625      2.75390625]]
After layer decoder_rnn_l0_t0_slice_output1 (20, 512) <class 'numpy.float16'> [[-1.88378906  2.2890625   2.390625   ...,  3.1484375  -0.76660156
   1.9453125 ]
 [-1.88671875  2.2890625   2.39257812 ...,  3.14257812 -0.7578125
   1.94140625]
 [-1.90429688  2.28320312  2.38476562 ...,  3.12304688 -0.80810547
   1.9296875 ]
 ...,
 [-1.8984375   2.296875    2.39257812 ...,  3.12695312 -0.74023438
   1.92773438]
 [-2.00195312  1.83789062  1.72070312 ...,  2.015625   -0.45092773
   1.00390625]
 [-1.89453125  2.29101562  2.38867188 ...,  3.13085938 -0.75097656
   1.93261719]]
After layer decoder_rnn_l0_t0_slice_output2 (20, 512) <class 'numpy.float16'> [[-2.79101562 -3.06054688  2.84570312 ...,  4.2421875  -0.07202148
   2.15234375]
 [-2.78710938 -3.05859375  2.84375    ...,  4.234375   -0.078125
   2.15039062]
 [-2.78125    -3.0546875   2.8515625  ...,  4.203125   -0.09667969
   2.14648438]
 ...,
 [-2.76953125 -3.05859375  2.83984375 ...,  4.21484375 -0.1081543   2.140625  ]
 [-2.640625   -1.90820312  1.59375    ...,  3.41210938 -2.50195312
   1.69140625]
 [-2.77734375 -3.05664062  2.84179688 ...,  4.21875    -0.09619141
   2.14648438]]
After layer decoder_rnn_l0_t0_slice_output3 (20, 512) <class 'numpy.float16'> [[-3.26953125  2.47070312 -1.41308594 ...,  0.62255859  5.15625     0.765625  ]
 [-3.27148438  2.47460938 -1.41601562 ...,  0.62011719  5.1484375
   0.76318359]
 [-3.27734375  2.51757812 -1.43945312 ...,  0.60986328  5.15625     0.7734375 ]
 ...,
 [-3.2734375   2.48046875 -1.43066406 ...,  0.60742188  5.140625
   0.75488281]
 [-2.87695312  1.4921875  -0.93994141 ..., -0.53271484  4.5         0.97216797]
 [-3.2734375   2.48242188 -1.42382812 ...,  0.60986328  5.14453125
   0.75390625]]
After layer decoder_rnn_l0_t0_o_output (20, 512) <class 'numpy.float16'> [[ 0.03662109  0.921875    0.19580078 ...,  0.65087891  0.99414062
   0.68261719]
 [ 0.03656006  0.92236328  0.1953125  ...,  0.65039062  0.99414062
   0.68212891]
 [ 0.03634644  0.92529297  0.19165039 ...,  0.64794922  0.99414062
   0.68408203]
 ...,
 [ 0.03649902  0.92285156  0.19299316 ...,  0.64746094  0.99414062
   0.68017578]
 [ 0.05331421  0.81640625  0.28100586 ...,  0.36987305  0.98876953
   0.72558594]
 [ 0.03649902  0.92285156  0.1940918  ...,  0.64794922  0.99414062
   0.68017578]]
After layer decoder_rnn_l0_t0_f_output (20, 512) <class 'numpy.float16'> [[ 0.13195801  0.90820312  0.91601562 ...,  0.95898438  0.31713867  0.875     ]
 [ 0.1315918   0.90820312  0.91601562 ...,  0.95849609  0.3190918
   0.87451172]
 [ 0.12963867  0.90771484  0.91552734 ...,  0.95800781  0.30834961
   0.87304688]
 ...,
 [ 0.13024902  0.90869141  0.91601562 ...,  0.95800781  0.32299805
   0.87304688]
 [ 0.11901855  0.86279297  0.84814453 ...,  0.88232422  0.38916016
   0.73193359]
 [ 0.1307373   0.90820312  0.91601562 ...,  0.95800781  0.32055664
   0.87353516]]
After layer _mul2106_0 (20, 512) <class 'numpy.float16'> [[ -4.43649292e-03  -3.92773438e+00   4.45312500e+00 ...,   4.79687500e+00
   -4.58374023e-02   3.53125000e+00]
 [ -4.43649292e-03  -3.93164062e+00   4.41015625e+00 ...,   4.70312500e+00
   -5.28869629e-02   3.46093750e+00]
 [ -4.26101685e-03  -3.89062500e+00   4.44140625e+00 ...,   4.57031250e+00
   -5.32226562e-02   3.35156250e+00]
 ...,
 [ -4.31060791e-03  -3.91796875e+00   4.37109375e+00 ...,   4.65234375e+00
   -8.24584961e-02   3.36328125e+00]
 [ -4.00924683e-03  -3.21093750e+00   3.45898438e+00 ...,   3.58398438e+00
   -6.28417969e-01   2.18750000e+00]
 [ -4.37545776e-03  -3.92773438e+00   4.40234375e+00 ...,   4.64843750e+00
   -6.87255859e-02   3.41015625e+00]]
After layer decoder_rnn_l0_t0_i_output (20, 512) <class 'numpy.float16'> [[ 0.02931213  0.88916016  0.98583984 ...,  0.85302734  0.98974609
   0.94042969]
 [ 0.02931213  0.88964844  0.98535156 ...,  0.85253906  0.98974609
   0.94042969]
 [ 0.02931213  0.88964844  0.98535156 ...,  0.85351562  0.98925781
   0.93945312]
 ...,
 [ 0.02914429  0.89111328  0.98583984 ...,  0.85058594  0.98974609
   0.93994141]
 [ 0.04177856  0.87255859  0.95800781 ...,  0.84326172  0.97705078
   0.89404297]
 [ 0.0292511   0.89013672  0.98535156 ...,  0.85107422  0.98974609
   0.93994141]]
After layer decoder_rnn_l0_t0_c_output (20, 512) <class 'numpy.float16'> [[-0.99267578 -0.99560547  0.99316406 ...,  0.99951172 -0.07189941
   0.97314453]
 [-0.99267578 -0.99560547  0.99316406 ...,  0.99951172 -0.07794189
   0.97314453]
 [-0.9921875  -0.99560547  0.99316406 ...,  0.99951172 -0.09637451
   0.97314453]
 ...,
 [-0.9921875  -0.99560547  0.99316406 ...,  0.99951172 -0.10772705
   0.97265625]
 [-0.98974609 -0.95703125  0.92089844 ...,  0.99804688 -0.98681641
   0.93408203]
 [-0.9921875  -0.99560547  0.99316406 ...,  0.99951172 -0.09588623
   0.97314453]]
After layer _mul2107_0 (20, 512) <class 'numpy.float16'> [[-0.02909851 -0.88525391  0.97900391 ...,  0.85253906 -0.07116699
   0.91503906]
 [-0.02909851 -0.88574219  0.97851562 ...,  0.85205078 -0.07714844
   0.91503906]
 [-0.02908325 -0.88574219  0.97851562 ...,  0.85302734 -0.09533691
   0.9140625 ]
 ...,
 [-0.02891541 -0.88720703  0.97900391 ...,  0.85009766 -0.10662842
   0.9140625 ]
 [-0.04135132 -0.83496094  0.88232422 ...,  0.84179688 -0.96435547
   0.83496094]
 [-0.02902222 -0.88623047  0.97851562 ...,  0.85058594 -0.09490967
   0.91455078]]
After layer decoder_rnn_l0_t0_state_0 (20, 512) <class 'numpy.float16'> [[-0.03353882 -4.8125      5.43359375 ...,  5.6484375  -0.11700439
   4.4453125 ]
 [-0.03353882 -4.81640625  5.390625   ...,  5.5546875  -0.13000488  4.375     ]
 [-0.03335571 -4.77734375  5.421875   ...,  5.421875   -0.14855957
   4.265625  ]
 ...,
 [-0.03323364 -4.8046875   5.3515625  ...,  5.50390625 -0.18908691
   4.27734375]
 [-0.04534912 -4.046875    4.33984375 ...,  4.42578125 -1.59277344
   3.0234375 ]
 [-0.03338623 -4.8125      5.3828125  ...,  5.5        -0.16357422
   4.32421875]]
After layer activation1053_output (20, 512) <class 'numpy.float16'> [[-0.03353882 -1.          1.         ...,  1.         -0.11645508
   0.99951172]
 [-0.03353882 -1.          1.         ...,  1.         -0.12927246
   0.99951172]
 [-0.03335571 -1.          1.         ...,  1.         -0.14746094
   0.99951172]
 ...,
 [-0.03323364 -1.          1.         ...,  1.         -0.18688965
   0.99951172]
 [-0.0453186  -0.99951172  0.99951172 ...,  0.99951172 -0.92041016
   0.99511719]
 [-0.03338623 -1.          1.         ...,  1.         -0.16210938
   0.99951172]]
After layer decoder_rnn_l0_t0_out_0 (20, 512) <class 'numpy.float16'> [[-0.00122833 -0.921875    0.19580078 ...,  0.65087891 -0.11578369
   0.68212891]
 [-0.00122643 -0.92236328  0.1953125  ...,  0.65039062 -0.12854004
   0.68164062]
 [-0.00121212 -0.92529297  0.19165039 ...,  0.64794922 -0.14660645
   0.68359375]
 ...,
 [-0.00121307 -0.92285156  0.19299316 ...,  0.64746094 -0.18579102
   0.6796875 ]
 [-0.00241661 -0.81591797  0.28076172 ...,  0.36962891 -0.91015625
   0.72216797]
 [-0.0012188  -0.92285156  0.1940918  ...,  0.64794922 -0.16113281
   0.6796875 ]]
After layer expand_dims1062_0 (20, 512, 1) <class 'numpy.float16'> [[[-0.00122833]
  [-0.921875  ]
  [ 0.19580078]
  ...,
  [ 0.65087891]
  [-0.11578369]
  [ 0.68212891]]

 [[-0.00122643]
  [-0.92236328]
  [ 0.1953125 ]
  ...,
  [ 0.65039062]
  [-0.12854004]
  [ 0.68164062]]

 [[-0.00121212]
  [-0.92529297]
  [ 0.19165039]
  ...,
  [ 0.64794922]
  [-0.14660645]
  [ 0.68359375]]

 ...,
 [[-0.00121307]
  [-0.92285156]
  [ 0.19299316]
  ...,
  [ 0.64746094]
  [-0.18579102]
  [ 0.6796875 ]]

 [[-0.00241661]
  [-0.81591797]
  [ 0.28076172]
  ...,
  [ 0.36962891]
  [-0.91015625]
  [ 0.72216797]]

 [[-0.0012188 ]
  [-0.92285156]
  [ 0.1940918 ]
  ...,
  [ 0.64794922]
  [-0.16113281]
  [ 0.6796875 ]]]
After layer att_batch_dot_0 (20, 10, 1) <class 'numpy.float16'> [[[  0.52246094]
  [  0.9140625 ]
  [  1.59179688]
  [  2.51953125]
  [  2.40429688]
  [  0.14819336]
  [ -3.08203125]
  [ -5.9140625 ]
  [ -8.0390625 ]
  [ -9.625     ]]

 [[  0.5234375 ]
  [  0.91259766]
  [  1.59375   ]
  [  2.52539062]
  [  2.41210938]
  [  0.15441895]
  [ -3.078125  ]
  [ -5.9140625 ]
  [ -8.0390625 ]
  [ -9.625     ]]

 [[  0.515625  ]
  [  0.89746094]
  [  1.55175781]
  [  2.4375    ]
  [  2.25976562]
  [ -0.06524658]
  [ -3.35351562]
  [ -6.23046875]
  [ -8.3828125 ]
  [ -9.984375  ]]

 [[  0.52539062]
  [  0.91650391]
  [  1.60546875]
  [  2.55078125]
  [  2.44726562]
  [  0.19287109]
  [ -3.04296875]
  [ -5.8828125 ]
  [ -8.0078125 ]
  [ -9.6015625 ]]

 [[  0.52636719]
  [  0.89794922]
  [  1.5625    ]
  [  2.45117188]
  [  2.26757812]
  [ -0.08190918]
  [ -3.39453125]
  [ -6.27734375]
  [ -8.421875  ]
  [-10.0234375 ]]

 [[  0.52246094]
  [  0.90673828]
  [  1.57714844]
  [  2.48632812]
  [  2.33203125]
  [  0.02227783]
  [ -3.25976562]
  [ -6.12890625]
  [ -8.2734375 ]
  [ -9.875     ]]

 [[  0.52246094]
  [  0.9140625 ]
  [  1.59375   ]
  [  2.5234375 ]
  [  2.41015625]
  [  0.15515137]
  [ -3.07617188]
  [ -5.91015625]
  [ -8.03125   ]
  [ -9.625     ]]

 [[  0.52148438]
  [  0.91113281]
  [  1.58496094]
  [  2.50585938]
  [  2.3828125 ]
  [  0.12127686]
  [ -3.109375  ]
  [ -5.94140625]
  [ -8.0625    ]
  [ -9.6484375 ]]

 [[  0.60839844]
  [  1.0390625 ]
  [  1.86425781]
  [  3.015625  ]
  [  3.19921875]
  [  1.2578125 ]
  [ -1.70214844]
  [ -4.33984375]
  [ -6.3515625 ]
  [ -7.89453125]]

 [[  0.49145508]
  [  0.81884766]
  [  1.390625  ]
  [  2.12304688]
  [  1.72167969]
  [ -0.85742188]
  [ -4.36328125]
  [ -7.37890625]
  [ -9.6171875 ]
  [-11.2734375 ]]

 [[  0.51367188]
  [  0.89013672]
  [  1.53320312]
  [  2.40039062]
  [  2.20117188]
  [ -0.13867188]
  [ -3.43359375]
  [ -6.30859375]
  [ -8.453125  ]
  [-10.0546875 ]]

 [[  0.59863281]
  [  0.95166016]
  [  1.67871094]
  [  2.62109375]
  [  2.54296875]
  [  0.36547852]
  [ -2.75390625]
  [ -5.46875   ]
  [ -7.51171875]
  [ -9.0703125 ]]

 [[  0.5234375 ]
  [  0.91308594]
  [  1.59375   ]
  [  2.52539062]
  [  2.41210938]
  [  0.15551758]
  [ -3.07617188]
  [ -5.91015625]
  [ -8.03125   ]
  [ -9.625     ]]

 [[  0.52392578]
  [  0.91503906]
  [  1.59863281]
  [  2.53320312]
  [  2.42578125]
  [  0.17285156]
  [ -3.05664062]
  [ -5.890625  ]
  [ -8.015625  ]
  [ -9.6015625 ]]

 [[  0.52441406]
  [  0.9140625 ]
  [  1.59960938]
  [  2.53710938]
  [  2.42773438]
  [  0.16906738]
  [ -3.06835938]
  [ -5.90625   ]
  [ -8.03125   ]
  [ -9.625     ]]

 [[  0.52539062]
  [  0.91503906]
  [  1.60449219]
  [  2.54882812]
  [  2.44140625]
  [  0.1809082 ]
  [ -3.0625    ]
  [ -5.90625   ]
  [ -8.0390625 ]
  [ -9.6328125 ]]

 [[  0.52490234]
  [  0.82275391]
  [  1.46289062]
  [  2.234375  ]
  [  1.88476562]
  [ -0.62109375]
  [ -4.046875  ]
  [ -6.9921875 ]
  [ -9.1640625 ]
  [-10.765625  ]]

 [[  0.52587891]
  [  0.91650391]
  [  1.61132812]
  [  2.56054688]
  [  2.45703125]
  [  0.19360352]
  [ -3.05664062]
  [ -5.91015625]
  [ -8.046875  ]
  [ -9.640625  ]]

 [[  0.53662109]
  [  0.69824219]
  [  1.27050781]
  [  1.79296875]
  [  0.95654297]
  [ -2.23046875]
  [ -6.3515625 ]
  [ -9.8671875 ]
  [-12.421875  ]
  [-14.2421875 ]]

 [[  0.52490234]
  [  0.91455078]
  [  1.60253906]
  [  2.54296875]
  [  2.43554688]
  [  0.1739502 ]
  [ -3.06835938]
  [ -5.91015625]
  [ -8.0390625 ]
  [ -9.6328125 ]]]
After layer swapaxes27_output (10, 20, 1) <class 'numpy.float16'> [[[  0.52246094]
  [  0.5234375 ]
  [  0.515625  ]
  [  0.52539062]
  [  0.52636719]
  [  0.52246094]
  [  0.52246094]
  [  0.52148438]
  [  0.60839844]
  [  0.49145508]
  [  0.51367188]
  [  0.59863281]
  [  0.5234375 ]
  [  0.52392578]
  [  0.52441406]
  [  0.52539062]
  [  0.52490234]
  [  0.52587891]
  [  0.53662109]
  [  0.52490234]]

 [[  0.9140625 ]
  [  0.91259766]
  [  0.89746094]
  [  0.91650391]
  [  0.89794922]
  [  0.90673828]
  [  0.9140625 ]
  [  0.91113281]
  [  1.0390625 ]
  [  0.81884766]
  [  0.89013672]
  [  0.95166016]
  [  0.91308594]
  [  0.91503906]
  [  0.9140625 ]
  [  0.91503906]
  [  0.82275391]
  [  0.91650391]
  [  0.69824219]
  [  0.91455078]]

 [[  1.59179688]
  [  1.59375   ]
  [  1.55175781]
  [  1.60546875]
  [  1.5625    ]
  [  1.57714844]
  [  1.59375   ]
  [  1.58496094]
  [  1.86425781]
  [  1.390625  ]
  [  1.53320312]
  [  1.67871094]
  [  1.59375   ]
  [  1.59863281]
  [  1.59960938]
  [  1.60449219]
  [  1.46289062]
  [  1.61132812]
  [  1.27050781]
  [  1.60253906]]

 [[  2.51953125]
  [  2.52539062]
  [  2.4375    ]
  [  2.55078125]
  [  2.45117188]
  [  2.48632812]
  [  2.5234375 ]
  [  2.50585938]
  [  3.015625  ]
  [  2.12304688]
  [  2.40039062]
  [  2.62109375]
  [  2.52539062]
  [  2.53320312]
  [  2.53710938]
  [  2.54882812]
  [  2.234375  ]
  [  2.56054688]
  [  1.79296875]
  [  2.54296875]]

 [[  2.40429688]
  [  2.41210938]
  [  2.25976562]
  [  2.44726562]
  [  2.26757812]
  [  2.33203125]
  [  2.41015625]
  [  2.3828125 ]
  [  3.19921875]
  [  1.72167969]
  [  2.20117188]
  [  2.54296875]
  [  2.41210938]
  [  2.42578125]
  [  2.42773438]
  [  2.44140625]
  [  1.88476562]
  [  2.45703125]
  [  0.95654297]
  [  2.43554688]]

 [[  0.14819336]
  [  0.15441895]
  [ -0.06524658]
  [  0.19287109]
  [ -0.08190918]
  [  0.02227783]
  [  0.15515137]
  [  0.12127686]
  [  1.2578125 ]
  [ -0.85742188]
  [ -0.13867188]
  [  0.36547852]
  [  0.15551758]
  [  0.17285156]
  [  0.16906738]
  [  0.1809082 ]
  [ -0.62109375]
  [  0.19360352]
  [ -2.23046875]
  [  0.1739502 ]]

 [[ -3.08203125]
  [ -3.078125  ]
  [ -3.35351562]
  [ -3.04296875]
  [ -3.39453125]
  [ -3.25976562]
  [ -3.07617188]
  [ -3.109375  ]
  [ -1.70214844]
  [ -4.36328125]
  [ -3.43359375]
  [ -2.75390625]
  [ -3.07617188]
  [ -3.05664062]
  [ -3.06835938]
  [ -3.0625    ]
  [ -4.046875  ]
  [ -3.05664062]
  [ -6.3515625 ]
  [ -3.06835938]]

 [[ -5.9140625 ]
  [ -5.9140625 ]
  [ -6.23046875]
  [ -5.8828125 ]
  [ -6.27734375]
  [ -6.12890625]
  [ -5.91015625]
  [ -5.94140625]
  [ -4.33984375]
  [ -7.37890625]
  [ -6.30859375]
  [ -5.46875   ]
  [ -5.91015625]
  [ -5.890625  ]
  [ -5.90625   ]
  [ -5.90625   ]
  [ -6.9921875 ]
  [ -5.91015625]
  [ -9.8671875 ]
  [ -5.91015625]]

 [[ -8.0390625 ]
  [ -8.0390625 ]
  [ -8.3828125 ]
  [ -8.0078125 ]
  [ -8.421875  ]
  [ -8.2734375 ]
  [ -8.03125   ]
  [ -8.0625    ]
  [ -6.3515625 ]
  [ -9.6171875 ]
  [ -8.453125  ]
  [ -7.51171875]
  [ -8.03125   ]
  [ -8.015625  ]
  [ -8.03125   ]
  [ -8.0390625 ]
  [ -9.1640625 ]
  [ -8.046875  ]
  [-12.421875  ]
  [ -8.0390625 ]]

 [[ -9.625     ]
  [ -9.625     ]
  [ -9.984375  ]
  [ -9.6015625 ]
  [-10.0234375 ]
  [ -9.875     ]
  [ -9.625     ]
  [ -9.6484375 ]
  [ -7.89453125]
  [-11.2734375 ]
  [-10.0546875 ]
  [ -9.0703125 ]
  [ -9.625     ]
  [ -9.6015625 ]
  [ -9.625     ]
  [ -9.6328125 ]
  [-10.765625  ]
  [ -9.640625  ]
  [-14.2421875 ]
  [ -9.6328125 ]]]
After layer sequencemask9_output (10, 20, 1) <class 'numpy.float16'> [[[  5.22460938e-01]
  [  5.23437500e-01]
  [  5.15625000e-01]
  [  5.25390625e-01]
  [  5.26367188e-01]
  [  5.22460938e-01]
  [  5.22460938e-01]
  [  5.21484375e-01]
  [  6.08398438e-01]
  [  4.91455078e-01]
  [  5.13671875e-01]
  [  5.98632812e-01]
  [  5.23437500e-01]
  [  5.23925781e-01]
  [  5.24414062e-01]
  [  5.25390625e-01]
  [  5.24902344e-01]
  [  5.25878906e-01]
  [  5.36621094e-01]
  [  5.24902344e-01]]

 [[  9.14062500e-01]
  [  9.12597656e-01]
  [  8.97460938e-01]
  [  9.16503906e-01]
  [  8.97949219e-01]
  [  9.06738281e-01]
  [  9.14062500e-01]
  [  9.11132812e-01]
  [  1.03906250e+00]
  [  8.18847656e-01]
  [  8.90136719e-01]
  [  9.51660156e-01]
  [  9.13085938e-01]
  [  9.15039062e-01]
  [  9.14062500e-01]
  [  9.15039062e-01]
  [  8.22753906e-01]
  [  9.16503906e-01]
  [  6.98242188e-01]
  [  9.14550781e-01]]

 [[ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]]
After layer swapaxes28_output (20, 10, 1) <class 'numpy.float16'> [[[  5.22460938e-01]
  [  9.14062500e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  5.23437500e-01]
  [  9.12597656e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  5.15625000e-01]
  [  8.97460938e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  5.25390625e-01]
  [  9.16503906e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  5.26367188e-01]
  [  8.97949219e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  5.22460938e-01]
  [  9.06738281e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  5.22460938e-01]
  [  9.14062500e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  5.21484375e-01]
  [  9.11132812e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  6.08398438e-01]
  [  1.03906250e+00]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  4.91455078e-01]
  [  8.18847656e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  5.13671875e-01]
  [  8.90136719e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  5.98632812e-01]
  [  9.51660156e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  5.23437500e-01]
  [  9.13085938e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  5.23925781e-01]
  [  9.15039062e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  5.24414062e-01]
  [  9.14062500e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  5.25390625e-01]
  [  9.15039062e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  5.24902344e-01]
  [  8.22753906e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  5.25878906e-01]
  [  9.16503906e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  5.36621094e-01]
  [  6.98242188e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  5.24902344e-01]
  [  9.14550781e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]]
After layer attention_softmax_0 (20, 10, 1) <class 'numpy.float16'> [[[ 0.40332031]
  [ 0.59667969]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40380859]
  [ 0.59619141]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40576172]
  [ 0.59423828]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40356445]
  [ 0.59667969]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40820312]
  [ 0.59179688]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.4050293 ]
  [ 0.59472656]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40332031]
  [ 0.59667969]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40380859]
  [ 0.59619141]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.39379883]
  [ 0.60595703]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.41894531]
  [ 0.58105469]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40698242]
  [ 0.59277344]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.41259766]
  [ 0.58691406]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40380859]
  [ 0.59619141]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40356445]
  [ 0.59667969]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40380859]
  [ 0.59619141]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40380859]
  [ 0.59619141]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.42602539]
  [ 0.57421875]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40356445]
  [ 0.59619141]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.4597168 ]
  [ 0.54052734]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40380859]
  [ 0.59619141]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]]
After layer batch_dot9_0 (20, 512, 1) <class 'numpy.float16'> [[[ 0.01785278]
  [ 0.03945923]
  [-0.03341675]
  ...,
  [-0.01097107]
  [ 0.00999451]
  [-0.02462769]]

 [[ 0.01783752]
  [ 0.03942871]
  [-0.03338623]
  ...,
  [-0.01097107]
  [ 0.00999451]
  [-0.02462769]]

 [[ 0.01779175]
  [ 0.03936768]
  [-0.03329468]
  ...,
  [-0.01095581]
  [ 0.00998688]
  [-0.02467346]]

 ...,
 [[ 0.01783752]
  [ 0.03942871]
  [-0.03338623]
  ...,
  [-0.01096344]
  [ 0.00998688]
  [-0.02462769]]

 [[ 0.01649475]
  [ 0.03787231]
  [-0.03088379]
  ...,
  [-0.01065826]
  [ 0.00992584]
  [-0.02563477]]

 [[ 0.01783752]
  [ 0.03942871]
  [-0.03338623]
  ...,
  [-0.01097107]
  [ 0.00999451]
  [-0.02462769]]]
After layer reshape18_0 (20, 512) <class 'numpy.float16'> [[ 0.01785278  0.03945923 -0.03341675 ..., -0.01097107  0.00999451
  -0.02462769]
 [ 0.01783752  0.03942871 -0.03338623 ..., -0.01097107  0.00999451
  -0.02462769]
 [ 0.01779175  0.03936768 -0.03329468 ..., -0.01095581  0.00998688
  -0.02467346]
 ...,
 [ 0.01783752  0.03942871 -0.03338623 ..., -0.01096344  0.00998688
  -0.02462769]
 [ 0.01649475  0.03787231 -0.03088379 ..., -0.01065826  0.00992584
  -0.02563477]
 [ 0.01783752  0.03942871 -0.03338623 ..., -0.01097107  0.00999451
  -0.02462769]]
After layer decoder_rnn_hidden_concat_t0_output (20, 1024) <class 'numpy.float16'> [[-0.00122833 -0.921875    0.19580078 ..., -0.01097107  0.00999451
  -0.02462769]
 [-0.00122643 -0.92236328  0.1953125  ..., -0.01097107  0.00999451
  -0.02462769]
 [-0.00121212 -0.92529297  0.19165039 ..., -0.01095581  0.00998688
  -0.02467346]
 ...,
 [-0.00121307 -0.92285156  0.19299316 ..., -0.01096344  0.00998688
  -0.02462769]
 [-0.00241661 -0.81591797  0.28076172 ..., -0.01065826  0.00992584
  -0.02563477]
 [-0.0012188  -0.92285156  0.1940918  ..., -0.01097107  0.00999451
  -0.02462769]]
After layer decoder_rnn_hidden_fc_t0_output (20, 512) <class 'numpy.float16'> [[-1.93554688  0.19995117 -0.80371094 ...,  1.94335938  2.08984375
  -1.5859375 ]
 [-1.93847656  0.19970703 -0.80566406 ...,  1.94433594  2.09179688
  -1.58398438]
 [-1.91992188  0.21130371 -0.81298828 ...,  1.92578125  2.08203125
  -1.58789062]
 ...,
 [-1.94628906  0.20874023 -0.81640625 ...,  1.95019531  2.0859375
  -1.58105469]
 [-1.71484375 -0.79199219  0.2980957  ...,  1.359375    2.32421875
  -1.93359375]
 [-1.94042969  0.20361328 -0.81201172 ...,  1.94628906  2.08789062
  -1.58105469]]
After layer decoder_rnn_next_hidden_t0_output (20, 512) <class 'numpy.float16'> [[-0.95898438  0.1973877  -0.66601562 ...,  0.95996094  0.96972656
  -0.91943359]
 [-0.95947266  0.19714355 -0.66699219 ...,  0.95996094  0.96972656
  -0.91943359]
 [-0.95800781  0.20825195 -0.67138672 ...,  0.95849609  0.96923828
  -0.91992188]
 ...,
 [-0.95996094  0.20581055 -0.67333984 ...,  0.96044922  0.96972656
  -0.91894531]
 [-0.93701172 -0.65966797  0.28955078 ...,  0.87646484  0.98095703
  -0.95898438]
 [-0.95947266  0.20080566 -0.67089844 ...,  0.95996094  0.96972656
  -0.91894531]]
After layer logits_output (20, 16743) <class 'numpy.float16'> [[-1.99414062 -2.82226562 -2.41015625 ..., -2.09960938 -3.49804688
  -2.5703125 ]
 [-1.99511719 -2.8203125  -2.40820312 ..., -2.09960938 -3.49414062
  -2.56835938]
 [-1.98535156 -2.81835938 -2.41015625 ..., -2.10351562 -3.4921875
  -2.56445312]
 ...,
 [-1.99121094 -2.8125     -2.40039062 ..., -2.09570312 -3.48632812
  -2.56835938]
 [-1.73535156 -3.19921875 -2.78515625 ..., -2.30664062 -3.36914062
  -3.12109375]
 [-1.9921875  -2.81640625 -2.40429688 ..., -2.09765625 -3.48828125
  -2.56835938]]
After layer softmax_0 (20, 16743) <class 'numpy.float16'> [[  8.34465027e-07   3.57627869e-07   5.36441803e-07 ...,   7.74860382e-07
    1.78813934e-07   4.76837158e-07]
 [  8.34465027e-07   3.57627869e-07   5.36441803e-07 ...,   7.74860382e-07
    1.78813934e-07   4.76837158e-07]
 [  8.94069672e-07   3.57627869e-07   5.96046448e-07 ...,   7.74860382e-07
    1.78813934e-07   4.76837158e-07]
 ...,
 [  8.94069672e-07   3.57627869e-07   5.96046448e-07 ...,   7.74860382e-07
    1.78813934e-07   4.76837158e-07]
 [  5.96046448e-08   0.00000000e+00   0.00000000e+00 ...,   5.96046448e-08
    0.00000000e+00   0.00000000e+00]
 [  8.94069672e-07   3.57627869e-07   5.96046448e-07 ...,   7.74860382e-07
    1.78813934e-07   4.76837158e-07]]
After layer reshape19_0 (20, 10) <class 'numpy.float16'> [[ 0.40332031  0.59667969  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40380859  0.59619141  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40576172  0.59423828  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40356445  0.59667969  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40820312  0.59179688  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.4050293   0.59472656  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40332031  0.59667969  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40380859  0.59619141  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.39379883  0.60595703  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.41894531  0.58105469  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40698242  0.59277344  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.41259766  0.58691406  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40380859  0.59619141  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40356445  0.59667969  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40380859  0.59619141  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40380859  0.59619141  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.42602539  0.57421875  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40356445  0.59619141  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.4597168   0.54052734  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40380859  0.59619141  0.          0.          0.          0.          0.
   0.          0.          0.        ]]
After layer target_embed_embed_0 (20, 256) <class 'numpy.float16'> [[-0.05505371 -0.0300293  -0.03598022 ...,  0.08459473 -0.05288696
  -0.01667786]
 [-0.05505371 -0.0300293  -0.03598022 ...,  0.08459473 -0.05288696
  -0.01667786]
 [-0.05505371 -0.0300293  -0.03598022 ...,  0.08459473 -0.05288696
  -0.01667786]
 ...,
 [-0.05505371 -0.0300293  -0.03598022 ...,  0.08459473 -0.05288696
  -0.01667786]
 [-0.05505371 -0.0300293  -0.03598022 ...,  0.08459473 -0.05288696
  -0.01667786]
 [-0.05505371 -0.0300293  -0.03598022 ...,  0.08459473 -0.05288696
  -0.01667786]]
After layer decoder_rnn_concat_target_context_t0_output (20, 768) <class 'numpy.float16'> [[-0.05505371 -0.0300293  -0.03598022 ...,  0.95996094  0.96972656
  -0.91943359]
 [-0.05505371 -0.0300293  -0.03598022 ...,  0.95996094  0.96972656
  -0.91943359]
 [-0.05505371 -0.0300293  -0.03598022 ...,  0.95849609  0.96923828
  -0.91992188]
 ...,
 [-0.05505371 -0.0300293  -0.03598022 ...,  0.94726562  0.96630859
  -0.90283203]
 [-0.05505371 -0.0300293  -0.03598022 ...,  0.96044922  0.96972656
  -0.91894531]
 [-0.05505371 -0.0300293  -0.03598022 ...,  0.95996094  0.96972656
  -0.91894531]]
After layer decoder_rnn_l0_t0_i2h_output (20, 2048) <class 'numpy.float16'> [[-3.18359375  1.61328125  2.4296875  ..., -0.07592773  3.8671875
   0.60107422]
 [-3.18164062  1.61230469  2.42773438 ..., -0.0760498   3.86328125
   0.60107422]
 [-3.17382812  1.61132812  2.421875   ..., -0.0715332   3.86523438
   0.60693359]
 ...,
 [-3.12304688  1.59960938  2.32226562 ..., -0.07531738  3.79492188
   0.78027344]
 [-3.17578125  1.60742188  2.4296875  ..., -0.07543945  3.85351562
   0.60058594]
 [-3.17773438  1.61035156  2.4296875  ..., -0.07623291  3.859375
   0.60107422]]
After layer decoder_rnn_l0_t0_h2h_output (20, 2048) <class 'numpy.float16'> [[-0.32299805  0.47216797  1.81835938 ...,  0.69970703  1.29589844
   0.17077637]
 [-0.32446289  0.47387695  1.81738281 ...,  0.69726562  1.29394531
   0.16894531]
 [-0.33374023  0.48193359  1.80859375 ...,  0.69042969  1.3046875
   0.16479492]
 ...,
 [-0.44262695  0.52148438  1.78417969 ...,  0.61572266  1.26855469
   0.26953125]
 [-0.33276367  0.49072266  1.81933594 ...,  0.68896484  1.30078125
   0.15661621]
 [-0.32958984  0.48364258  1.81640625 ...,  0.69091797  1.29785156
   0.16162109]]
After layer _plus1054_0 (20, 2048) <class 'numpy.float16'> [[-3.50585938  2.0859375   4.25       ...,  0.62402344  5.1640625
   0.77197266]
 [-3.50585938  2.0859375   4.24609375 ...,  0.62109375  5.15625     0.77001953]
 [-3.5078125   2.09375     4.23046875 ...,  0.61914062  5.171875
   0.77148438]
 ...,
 [-3.56640625  2.12109375  4.10546875 ...,  0.54052734  5.0625      1.04980469]
 [-3.5078125   2.09765625  4.25       ...,  0.61328125  5.15625     0.75732422]
 [-3.5078125   2.09375     4.24609375 ...,  0.61474609  5.15625     0.76269531]]
After layer decoder_rnn_l0_t0_slice_output0 (20, 512) <class 'numpy.float16'> [[-3.50585938  2.0859375   4.25       ...,  1.75488281  4.58203125
   2.7734375 ]
 [-3.50585938  2.0859375   4.24609375 ...,  1.75195312  4.5859375
   2.77148438]
 [-3.5078125   2.09375     4.23046875 ...,  1.75976562  4.55859375
   2.765625  ]
 ...,
 [-3.56640625  2.12109375  4.10546875 ...,  1.72949219  4.5234375
   2.75390625]
 [-3.5078125   2.09765625  4.25       ...,  1.74023438  4.578125    2.765625  ]
 [-3.5078125   2.09375     4.24609375 ...,  1.74609375  4.58203125
   2.76757812]]
After layer decoder_rnn_l0_t0_slice_output1 (20, 512) <class 'numpy.float16'> [[-1.87304688  2.29882812  2.40820312 ...,  3.15820312 -0.73974609
   1.96191406]
 [-1.87207031  2.29882812  2.40820312 ...,  3.15429688 -0.734375
   1.95898438]
 [-1.88476562  2.29101562  2.41015625 ...,  3.14453125 -0.76318359
   1.95117188]
 ...,
 [-2.01757812  2.3515625   2.38671875 ...,  3.04882812 -0.77392578
   1.82226562]
 [-1.88378906  2.3046875   2.40820312 ...,  3.14257812 -0.72216797
   1.95019531]
 [-1.87988281  2.30078125  2.40625    ...,  3.14648438 -0.72949219
   1.953125  ]]
After layer decoder_rnn_l0_t0_slice_output2 (20, 512) <class 'numpy.float16'> [[-2.80664062 -3.0703125   2.84765625 ...,  4.2578125  -0.07080078
   2.16015625]
 [-2.80273438 -3.0703125   2.84765625 ...,  4.25       -0.07543945  2.15625   ]
 [-2.8046875  -3.0703125   2.86328125 ...,  4.234375   -0.07861328  2.15625   ]
 ...,
 [-2.703125   -3.06640625  2.8515625  ...,  4.2109375  -0.13916016
   2.1015625 ]
 [-2.79101562 -3.0703125   2.84765625 ...,  4.234375   -0.09863281
   2.15234375]
 [-2.796875   -3.06835938  2.84570312 ...,  4.2421875  -0.08691406  2.15625   ]]
After layer decoder_rnn_l0_t0_slice_output3 (20, 512) <class 'numpy.float16'> [[-3.26953125  2.45703125 -1.40917969 ...,  0.62402344  5.1640625
   0.77197266]
 [-3.27148438  2.4609375  -1.41015625 ...,  0.62109375  5.15625     0.77001953]
 [-3.27148438  2.48828125 -1.42578125 ...,  0.61914062  5.171875
   0.77148438]
 ...,
 [-3.37109375  2.6015625  -1.39257812 ...,  0.54052734  5.0625      1.04980469]
 [-3.27539062  2.46484375 -1.421875   ...,  0.61328125  5.15625     0.75732422]
 [-3.2734375   2.46484375 -1.41699219 ...,  0.61474609  5.15625     0.76269531]]
After layer decoder_rnn_l0_t0_o_output (20, 512) <class 'numpy.float16'> [[ 0.03662109  0.92089844  0.19641113 ...,  0.65136719  0.99414062
   0.68408203]
 [ 0.03656006  0.92138672  0.19616699 ...,  0.65039062  0.99414062
   0.68359375]
 [ 0.03656006  0.92333984  0.19372559 ...,  0.64990234  0.99414062
   0.68408203]
 ...,
 [ 0.03320312  0.93115234  0.19897461 ...,  0.63183594  0.99365234
   0.74072266]
 [ 0.03643799  0.921875    0.19433594 ...,  0.64892578  0.99414062
   0.68066406]
 [ 0.03649902  0.921875    0.19519043 ...,  0.64892578  0.99414062
   0.68212891]]
After layer decoder_rnn_l0_t0_f_output (20, 512) <class 'numpy.float16'> [[ 0.13317871  0.90869141  0.91748047 ...,  0.95947266  0.32299805
   0.87695312]
 [ 0.13330078  0.90869141  0.91748047 ...,  0.95898438  0.32421875
   0.87646484]
 [ 0.13183594  0.90820312  0.91748047 ...,  0.95849609  0.31787109
   0.87548828]
 ...,
 [ 0.11737061  0.91308594  0.91601562 ...,  0.95458984  0.31567383
   0.86083984]
 [ 0.13195801  0.90917969  0.91748047 ...,  0.95849609  0.3269043
   0.87548828]
 [ 0.13244629  0.90917969  0.91748047 ...,  0.95898438  0.32519531
   0.87597656]]
After layer _mul2108_0 (20, 512) <class 'numpy.float16'> [[ -4.46701050e-03  -4.37500000e+00   4.98437500e+00 ...,   5.41796875e+00
   -3.77807617e-02   3.89843750e+00]
 [ -4.47082520e-03  -4.37500000e+00   4.94531250e+00 ...,   5.32812500e+00
   -4.21447754e-02   3.83398438e+00]
 [ -4.39834595e-03  -4.33984375e+00   4.97265625e+00 ...,   5.19531250e+00
   -4.72106934e-02   3.73437500e+00]
 ...,
 [ -3.41796875e-03  -4.01171875e+00   4.58593750e+00 ...,   4.75000000e+00
   -2.38281250e-01   2.95703125e+00]
 [ -4.38690186e-03  -4.36718750e+00   4.91015625e+00 ...,   5.27734375e+00
   -6.17980957e-02   3.74414062e+00]
 [ -4.42123413e-03  -4.37500000e+00   4.93750000e+00 ...,   5.27343750e+00
   -5.31921387e-02   3.78710938e+00]]
After layer decoder_rnn_l0_t0_i_output (20, 512) <class 'numpy.float16'> [[ 0.02914429  0.88964844  0.98583984 ...,  0.85253906  0.98974609
   0.94140625]
 [ 0.02914429  0.88964844  0.98583984 ...,  0.85205078  0.98974609
   0.94091797]
 [ 0.02908325  0.89013672  0.98583984 ...,  0.85302734  0.98974609
   0.94091797]
 ...,
 [ 0.02748108  0.89306641  0.98388672 ...,  0.84912109  0.98925781
   0.93994141]
 [ 0.02908325  0.890625    0.98583984 ...,  0.85058594  0.98974609
   0.94091797]
 [ 0.02908325  0.89013672  0.98583984 ...,  0.8515625   0.98974609
   0.94091797]]
After layer decoder_rnn_l0_t0_c_output (20, 512) <class 'numpy.float16'> [[-0.99267578 -0.99560547  0.99316406 ...,  0.99951172 -0.07067871
   0.97363281]
 [-0.99267578 -0.99560547  0.99316406 ...,  0.99951172 -0.07531738
   0.97363281]
 [-0.99267578 -0.99560547  0.99365234 ...,  0.99951172 -0.07843018
   0.97363281]
 ...,
 [-0.99121094 -0.99560547  0.99316406 ...,  0.99951172 -0.13830566
   0.97070312]
 [-0.99267578 -0.99560547  0.99316406 ...,  0.99951172 -0.09832764
   0.97314453]
 [-0.99267578 -0.99560547  0.99316406 ...,  0.99951172 -0.08666992
   0.97363281]]
After layer _mul2109_0 (20, 512) <class 'numpy.float16'> [[-0.02893066 -0.88574219  0.97900391 ...,  0.85205078 -0.06994629
   0.91650391]
 [-0.02893066 -0.88574219  0.97900391 ...,  0.8515625  -0.07452393
   0.91601562]
 [-0.02886963 -0.88623047  0.97949219 ...,  0.85253906 -0.07763672
   0.91601562]
 ...,
 [-0.02723694 -0.88916016  0.97705078 ...,  0.84863281 -0.13684082
   0.91259766]
 [-0.02886963 -0.88671875  0.97900391 ...,  0.85009766 -0.09729004
   0.91552734]
 [-0.02886963 -0.88623047  0.97900391 ...,  0.85107422 -0.08575439
   0.91601562]]
After layer decoder_rnn_l0_t0_state_0 (20, 512) <class 'numpy.float16'> [[-0.03338623 -5.26171875  5.96484375 ...,  6.26953125 -0.10772705
   4.81640625]
 [-0.03338623 -5.26171875  5.92578125 ...,  6.1796875  -0.11669922  4.75      ]
 [-0.03326416 -5.2265625   5.953125   ...,  6.046875   -0.12487793
   4.6484375 ]
 ...,
 [-0.03065491 -4.90234375  5.5625     ...,  5.59765625 -0.375       3.86914062]
 [-0.03326416 -5.25390625  5.890625   ...,  6.12890625 -0.15905762
   4.66015625]
 [-0.03329468 -5.26171875  5.91796875 ...,  6.125      -0.13891602
   4.703125  ]]
After layer activation1054_output (20, 512) <class 'numpy.float16'> [[-0.03338623 -1.          1.         ...,  1.         -0.1072998   1.        ]
 [-0.03338623 -1.          1.         ...,  1.         -0.1161499   1.        ]
 [-0.03326416 -1.          1.         ...,  1.         -0.12420654  1.        ]
 ...,
 [-0.03063965 -1.          1.         ...,  1.         -0.35839844
   0.99902344]
 [-0.03326416 -1.          1.         ...,  1.         -0.15771484  1.        ]
 [-0.03329468 -1.          1.         ...,  1.         -0.13806152  1.        ]]
After layer decoder_rnn_l0_t0_out_0 (20, 512) <class 'numpy.float16'> [[-0.00122261 -0.92089844  0.19641113 ...,  0.65136719 -0.10668945
   0.68408203]
 [-0.0012207  -0.92138672  0.19616699 ...,  0.65039062 -0.11547852
   0.68359375]
 [-0.00121593 -0.92333984  0.19372559 ...,  0.64990234 -0.12347412
   0.68408203]
 ...,
 [-0.00101757 -0.93115234  0.19897461 ...,  0.63183594 -0.35620117
   0.74023438]
 [-0.00121212 -0.921875    0.19433594 ...,  0.64892578 -0.15673828
   0.68066406]
 [-0.00121498 -0.921875    0.19519043 ...,  0.64892578 -0.13720703
   0.68212891]]
After layer expand_dims1063_0 (20, 512, 1) <class 'numpy.float16'> [[[-0.00122261]
  [-0.92089844]
  [ 0.19641113]
  ...,
  [ 0.65136719]
  [-0.10668945]
  [ 0.68408203]]

 [[-0.0012207 ]
  [-0.92138672]
  [ 0.19616699]
  ...,
  [ 0.65039062]
  [-0.11547852]
  [ 0.68359375]]

 [[-0.00121593]
  [-0.92333984]
  [ 0.19372559]
  ...,
  [ 0.64990234]
  [-0.12347412]
  [ 0.68408203]]

 ...,
 [[-0.00101757]
  [-0.93115234]
  [ 0.19897461]
  ...,
  [ 0.63183594]
  [-0.35620117]
  [ 0.74023438]]

 [[-0.00121212]
  [-0.921875  ]
  [ 0.19433594]
  ...,
  [ 0.64892578]
  [-0.15673828]
  [ 0.68066406]]

 [[-0.00121498]
  [-0.921875  ]
  [ 0.19519043]
  ...,
  [ 0.64892578]
  [-0.13720703]
  [ 0.68212891]]]
After layer att_batch_dot_0 (20, 10, 1) <class 'numpy.float16'> [[[  0.52636719]
  [  0.91943359]
  [  1.60839844]
  [  2.55273438]
  [  2.45507812]
  [  0.2088623 ]
  [ -3.01757812]
  [ -5.84765625]
  [ -7.97265625]
  [ -9.5625    ]]

 [[  0.52685547]
  [  0.91845703]
  [  1.61035156]
  [  2.55664062]
  [  2.4609375 ]
  [  0.21472168]
  [ -3.01171875]
  [ -5.84375   ]
  [ -7.96875   ]
  [ -9.5625    ]]

 [[  0.52246094]
  [  0.90966797]
  [  1.58300781]
  [  2.5       ]
  [  2.35742188]
  [  0.0637207 ]
  [ -3.20507812]
  [ -6.0703125 ]
  [ -8.21875   ]
  [ -9.8203125 ]]

 [[  0.52832031]
  [  0.92089844]
  [  1.6171875 ]
  [  2.57226562]
  [  2.48242188]
  [  0.23632812]
  [ -2.99414062]
  [ -5.83203125]
  [ -7.9609375 ]
  [ -9.5546875 ]]

 [[  0.52490234]
  [  0.90966797]
  [  1.59277344]
  [  2.52148438]
  [  2.38867188]
  [  0.09173584]
  [ -3.1875    ]
  [ -6.05859375]
  [ -8.2109375 ]
  [ -9.8125    ]]

 [[  0.52587891]
  [  0.91894531]
  [  1.609375  ]
  [  2.55664062]
  [  2.45898438]
  [  0.21154785]
  [ -3.015625  ]
  [ -5.8515625 ]
  [ -7.9765625 ]
  [ -9.5703125 ]]

 [[  0.5234375 ]
  [  0.91308594]
  [  1.59375   ]
  [  2.52148438]
  [  2.3828125 ]
  [  0.07446289]
  [ -3.21875   ]
  [ -6.10546875]
  [ -8.2734375 ]
  [ -9.890625  ]]

 [[  0.52587891]
  [  0.91748047]
  [  1.60351562]
  [  2.54492188]
  [  2.44140625]
  [  0.1920166 ]
  [ -3.03320312]
  [ -5.8671875 ]
  [ -7.98828125]
  [ -9.578125  ]]

 [[  0.53027344]
  [  0.90332031]
  [  1.58300781]
  [  2.49609375]
  [  2.34179688]
  [  0.01882935]
  [ -3.27539062]
  [ -6.14453125]
  [ -8.2890625 ]
  [ -9.890625  ]]

 [[  0.50683594]
  [  0.87744141]
  [  1.51660156]
  [  2.37304688]
  [  2.140625  ]
  [ -0.2590332 ]
  [ -3.61914062]
  [ -6.546875  ]
  [ -8.734375  ]
  [-10.359375  ]]

 [[  0.52099609]
  [  0.90478516]
  [  1.57128906]
  [  2.4765625 ]
  [  2.32226562]
  [  0.0209198 ]
  [ -3.24804688]
  [ -6.109375  ]
  [ -8.25      ]
  [ -9.8515625 ]]

 [[  0.50537109]
  [  0.84912109]
  [  1.47167969]
  [  2.28125   ]
  [  1.98144531]
  [ -0.49853516]
  [ -3.92382812]
  [ -6.8828125 ]
  [ -9.0859375 ]
  [-10.71875   ]]

 [[  0.60888672]
  [  0.98388672]
  [  1.74707031]
  [  2.75976562]
  [  2.77539062]
  [  0.69140625]
  [ -2.35742188]
  [ -5.03125   ]
  [ -7.0546875 ]
  [ -8.609375  ]]

 [[  0.52685547]
  [  0.91894531]
  [  1.61035156]
  [  2.55859375]
  [  2.4609375 ]
  [  0.21643066]
  [ -3.00976562]
  [ -5.84375   ]
  [ -7.96875   ]
  [ -9.5546875 ]]

 [[  0.52734375]
  [  0.91992188]
  [  1.61328125]
  [  2.5625    ]
  [  2.46875   ]
  [  0.22412109]
  [ -3.00195312]
  [ -5.8359375 ]
  [ -7.9609375 ]
  [ -9.5546875 ]]

 [[  0.52783203]
  [  0.91943359]
  [  1.61425781]
  [  2.56445312]
  [  2.47070312]
  [  0.22338867]
  [ -3.0078125 ]
  [ -5.84375   ]
  [ -7.97265625]
  [ -9.5625    ]]

 [[  0.52783203]
  [  0.91992188]
  [  1.61621094]
  [  2.5703125 ]
  [  2.4765625 ]
  [  0.22546387]
  [ -3.01171875]
  [ -5.85546875]
  [ -7.984375  ]
  [ -9.5859375 ]]

 [[  0.51269531]
  [  0.86523438]
  [  1.5234375 ]
  [  2.38476562]
  [  2.140625  ]
  [ -0.29418945]
  [ -3.69726562]
  [ -6.65625   ]
  [ -8.859375  ]
  [-10.4921875 ]]

 [[  0.52832031]
  [  0.92089844]
  [  1.62011719]
  [  2.578125  ]
  [  2.48632812]
  [  0.23181152]
  [ -3.01171875]
  [ -5.859375  ]
  [ -8.        ]
  [ -9.59375   ]]

 [[  0.52783203]
  [  0.91992188]
  [  1.61523438]
  [  2.56835938]
  [  2.47265625]
  [  0.22302246]
  [ -3.01171875]
  [ -5.8515625 ]
  [ -7.984375  ]
  [ -9.578125  ]]]
After layer swapaxes29_output (10, 20, 1) <class 'numpy.float16'> [[[  0.52636719]
  [  0.52685547]
  [  0.52246094]
  [  0.52832031]
  [  0.52490234]
  [  0.52587891]
  [  0.5234375 ]
  [  0.52587891]
  [  0.53027344]
  [  0.50683594]
  [  0.52099609]
  [  0.50537109]
  [  0.60888672]
  [  0.52685547]
  [  0.52734375]
  [  0.52783203]
  [  0.52783203]
  [  0.51269531]
  [  0.52832031]
  [  0.52783203]]

 [[  0.91943359]
  [  0.91845703]
  [  0.90966797]
  [  0.92089844]
  [  0.90966797]
  [  0.91894531]
  [  0.91308594]
  [  0.91748047]
  [  0.90332031]
  [  0.87744141]
  [  0.90478516]
  [  0.84912109]
  [  0.98388672]
  [  0.91894531]
  [  0.91992188]
  [  0.91943359]
  [  0.91992188]
  [  0.86523438]
  [  0.92089844]
  [  0.91992188]]

 [[  1.60839844]
  [  1.61035156]
  [  1.58300781]
  [  1.6171875 ]
  [  1.59277344]
  [  1.609375  ]
  [  1.59375   ]
  [  1.60351562]
  [  1.58300781]
  [  1.51660156]
  [  1.57128906]
  [  1.47167969]
  [  1.74707031]
  [  1.61035156]
  [  1.61328125]
  [  1.61425781]
  [  1.61621094]
  [  1.5234375 ]
  [  1.62011719]
  [  1.61523438]]

 [[  2.55273438]
  [  2.55664062]
  [  2.5       ]
  [  2.57226562]
  [  2.52148438]
  [  2.55664062]
  [  2.52148438]
  [  2.54492188]
  [  2.49609375]
  [  2.37304688]
  [  2.4765625 ]
  [  2.28125   ]
  [  2.75976562]
  [  2.55859375]
  [  2.5625    ]
  [  2.56445312]
  [  2.5703125 ]
  [  2.38476562]
  [  2.578125  ]
  [  2.56835938]]

 [[  2.45507812]
  [  2.4609375 ]
  [  2.35742188]
  [  2.48242188]
  [  2.38867188]
  [  2.45898438]
  [  2.3828125 ]
  [  2.44140625]
  [  2.34179688]
  [  2.140625  ]
  [  2.32226562]
  [  1.98144531]
  [  2.77539062]
  [  2.4609375 ]
  [  2.46875   ]
  [  2.47070312]
  [  2.4765625 ]
  [  2.140625  ]
  [  2.48632812]
  [  2.47265625]]

 [[  0.2088623 ]
  [  0.21472168]
  [  0.0637207 ]
  [  0.23632812]
  [  0.09173584]
  [  0.21154785]
  [  0.07446289]
  [  0.1920166 ]
  [  0.01882935]
  [ -0.2590332 ]
  [  0.0209198 ]
  [ -0.49853516]
  [  0.69140625]
  [  0.21643066]
  [  0.22412109]
  [  0.22338867]
  [  0.22546387]
  [ -0.29418945]
  [  0.23181152]
  [  0.22302246]]

 [[ -3.01757812]
  [ -3.01171875]
  [ -3.20507812]
  [ -2.99414062]
  [ -3.1875    ]
  [ -3.015625  ]
  [ -3.21875   ]
  [ -3.03320312]
  [ -3.27539062]
  [ -3.61914062]
  [ -3.24804688]
  [ -3.92382812]
  [ -2.35742188]
  [ -3.00976562]
  [ -3.00195312]
  [ -3.0078125 ]
  [ -3.01171875]
  [ -3.69726562]
  [ -3.01171875]
  [ -3.01171875]]

 [[ -5.84765625]
  [ -5.84375   ]
  [ -6.0703125 ]
  [ -5.83203125]
  [ -6.05859375]
  [ -5.8515625 ]
  [ -6.10546875]
  [ -5.8671875 ]
  [ -6.14453125]
  [ -6.546875  ]
  [ -6.109375  ]
  [ -6.8828125 ]
  [ -5.03125   ]
  [ -5.84375   ]
  [ -5.8359375 ]
  [ -5.84375   ]
  [ -5.85546875]
  [ -6.65625   ]
  [ -5.859375  ]
  [ -5.8515625 ]]

 [[ -7.97265625]
  [ -7.96875   ]
  [ -8.21875   ]
  [ -7.9609375 ]
  [ -8.2109375 ]
  [ -7.9765625 ]
  [ -8.2734375 ]
  [ -7.98828125]
  [ -8.2890625 ]
  [ -8.734375  ]
  [ -8.25      ]
  [ -9.0859375 ]
  [ -7.0546875 ]
  [ -7.96875   ]
  [ -7.9609375 ]
  [ -7.97265625]
  [ -7.984375  ]
  [ -8.859375  ]
  [ -8.        ]
  [ -7.984375  ]]

 [[ -9.5625    ]
  [ -9.5625    ]
  [ -9.8203125 ]
  [ -9.5546875 ]
  [ -9.8125    ]
  [ -9.5703125 ]
  [ -9.890625  ]
  [ -9.578125  ]
  [ -9.890625  ]
  [-10.359375  ]
  [ -9.8515625 ]
  [-10.71875   ]
  [ -8.609375  ]
  [ -9.5546875 ]
  [ -9.5546875 ]
  [ -9.5625    ]
  [ -9.5859375 ]
  [-10.4921875 ]
  [ -9.59375   ]
  [ -9.578125  ]]]
After layer sequencemask10_output (10, 20, 1) <class 'numpy.float16'> [[[  5.26367188e-01]
  [  5.26855469e-01]
  [  5.22460938e-01]
  [  5.28320312e-01]
  [  5.24902344e-01]
  [  5.25878906e-01]
  [  5.23437500e-01]
  [  5.25878906e-01]
  [  5.30273438e-01]
  [  5.06835938e-01]
  [  5.20996094e-01]
  [  5.05371094e-01]
  [  6.08886719e-01]
  [  5.26855469e-01]
  [  5.27343750e-01]
  [  5.27832031e-01]
  [  5.27832031e-01]
  [  5.12695312e-01]
  [  5.28320312e-01]
  [  5.27832031e-01]]

 [[  9.19433594e-01]
  [  9.18457031e-01]
  [  9.09667969e-01]
  [  9.20898438e-01]
  [  9.09667969e-01]
  [  9.18945312e-01]
  [  9.13085938e-01]
  [  9.17480469e-01]
  [  9.03320312e-01]
  [  8.77441406e-01]
  [  9.04785156e-01]
  [  8.49121094e-01]
  [  9.83886719e-01]
  [  9.18945312e-01]
  [  9.19921875e-01]
  [  9.19433594e-01]
  [  9.19921875e-01]
  [  8.65234375e-01]
  [  9.20898438e-01]
  [  9.19921875e-01]]

 [[ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]]
After layer swapaxes30_output (20, 10, 1) <class 'numpy.float16'> [[[  5.26367188e-01]
  [  9.19433594e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  5.26855469e-01]
  [  9.18457031e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  5.22460938e-01]
  [  9.09667969e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  5.28320312e-01]
  [  9.20898438e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  5.24902344e-01]
  [  9.09667969e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  5.25878906e-01]
  [  9.18945312e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  5.23437500e-01]
  [  9.13085938e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  5.25878906e-01]
  [  9.17480469e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  5.30273438e-01]
  [  9.03320312e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  5.06835938e-01]
  [  8.77441406e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  5.20996094e-01]
  [  9.04785156e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  5.05371094e-01]
  [  8.49121094e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  6.08886719e-01]
  [  9.83886719e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  5.26855469e-01]
  [  9.18945312e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  5.27343750e-01]
  [  9.19921875e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  5.27832031e-01]
  [  9.19433594e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  5.27832031e-01]
  [  9.19921875e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  5.12695312e-01]
  [  8.65234375e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  5.28320312e-01]
  [  9.20898438e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  5.27832031e-01]
  [  9.19921875e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]]
After layer attention_softmax_0 (20, 10, 1) <class 'numpy.float16'> [[[ 0.40307617]
  [ 0.59716797]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40332031]
  [ 0.59667969]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40454102]
  [ 0.59570312]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40307617]
  [ 0.59667969]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.4050293 ]
  [ 0.59521484]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40307617]
  [ 0.59716797]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40380859]
  [ 0.59619141]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40332031]
  [ 0.59667969]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40795898]
  [ 0.59228516]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40844727]
  [ 0.59179688]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.4050293 ]
  [ 0.59472656]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.41503906]
  [ 0.58496094]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40722656]
  [ 0.59277344]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40307617]
  [ 0.59667969]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40307617]
  [ 0.59667969]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40332031]
  [ 0.59667969]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40307617]
  [ 0.59667969]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.41259766]
  [ 0.58691406]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40307617]
  [ 0.59667969]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40307617]
  [ 0.59667969]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]]
After layer batch_dot10_0 (20, 512, 1) <class 'numpy.float16'> [[[ 0.01786804]
  [ 0.03945923]
  [-0.03341675]
  ...,
  [-0.0109787 ]
  [ 0.00999451]
  [-0.02462769]]

 [[ 0.01785278]
  [ 0.03945923]
  [-0.03341675]
  ...,
  [-0.01097107]
  [ 0.00999451]
  [-0.02462769]]

 [[ 0.01782227]
  [ 0.03942871]
  [-0.03335571]
  ...,
  [-0.01097107]
  [ 0.00999451]
  [-0.0246582 ]]

 ...,
 [[ 0.01760864]
  [ 0.03915405]
  [-0.03295898]
  ...,
  [-0.01091003]
  [ 0.00997925]
  [-0.02478027]]

 [[ 0.01785278]
  [ 0.03942871]
  [-0.03341675]
  ...,
  [-0.01097107]
  [ 0.00998688]
  [-0.02461243]]

 [[ 0.01785278]
  [ 0.03942871]
  [-0.03341675]
  ...,
  [-0.01097107]
  [ 0.00998688]
  [-0.02461243]]]
After layer reshape20_0 (20, 512) <class 'numpy.float16'> [[ 0.01786804  0.03945923 -0.03341675 ..., -0.0109787   0.00999451
  -0.02462769]
 [ 0.01785278  0.03945923 -0.03341675 ..., -0.01097107  0.00999451
  -0.02462769]
 [ 0.01782227  0.03942871 -0.03335571 ..., -0.01097107  0.00999451
  -0.0246582 ]
 ...,
 [ 0.01760864  0.03915405 -0.03295898 ..., -0.01091003  0.00997925
  -0.02478027]
 [ 0.01785278  0.03942871 -0.03341675 ..., -0.01097107  0.00998688
  -0.02461243]
 [ 0.01785278  0.03942871 -0.03341675 ..., -0.01097107  0.00998688
  -0.02461243]]
After layer decoder_rnn_hidden_concat_t0_output (20, 1024) <class 'numpy.float16'> [[-0.00122261 -0.92089844  0.19641113 ..., -0.0109787   0.00999451
  -0.02462769]
 [-0.0012207  -0.92138672  0.19616699 ..., -0.01097107  0.00999451
  -0.02462769]
 [-0.00121593 -0.92333984  0.19372559 ..., -0.01097107  0.00999451
  -0.0246582 ]
 ...,
 [-0.00101757 -0.93115234  0.19897461 ..., -0.01091003  0.00997925
  -0.02478027]
 [-0.00121212 -0.921875    0.19433594 ..., -0.01097107  0.00998688
  -0.02461243]
 [-0.00121498 -0.921875    0.19519043 ..., -0.01097107  0.00998688
  -0.02461243]]
After layer decoder_rnn_hidden_fc_t0_output (20, 512) <class 'numpy.float16'> [[-1.94726562  0.20141602 -0.80517578 ...,  1.95605469  2.09765625
  -1.58886719]
 [-1.94824219  0.20080566 -0.80664062 ...,  1.95703125  2.09960938
  -1.58789062]
 [-1.9375      0.20825195 -0.81396484 ...,  1.94433594  2.09375    -1.59375   ]
 ...,
 [-1.91308594  0.22460938 -0.81005859 ...,  1.9140625   2.0703125
  -1.57324219]
 [-1.95507812  0.20874023 -0.81640625 ...,  1.9609375   2.09570312
  -1.58691406]
 [-1.95019531  0.20385742 -0.81152344 ...,  1.95703125  2.09765625
  -1.58691406]]
After layer decoder_rnn_next_hidden_t0_output (20, 512) <class 'numpy.float16'> [[-0.95996094  0.19873047 -0.66699219 ...,  0.9609375   0.97021484
  -0.91992188]
 [-0.95996094  0.19812012 -0.66796875 ...,  0.9609375   0.97021484
  -0.91992188]
 [-0.95947266  0.20532227 -0.671875   ...,  0.95996094  0.97021484
  -0.92089844]
 ...,
 [-0.95751953  0.22094727 -0.66943359 ...,  0.95751953  0.96875    -0.91748047]
 [-0.9609375   0.20581055 -0.67333984 ...,  0.9609375   0.97021484
  -0.91943359]
 [-0.96044922  0.2010498  -0.67041016 ...,  0.9609375   0.97021484
  -0.91943359]]
After layer logits_output (20, 16743) <class 'numpy.float16'> [[-1.99902344 -2.82421875 -2.40820312 ..., -2.09765625 -3.5        -2.57421875]
 [-2.         -2.82226562 -2.40820312 ..., -2.09570312 -3.49804688
  -2.57421875]
 [-1.99414062 -2.82226562 -2.41015625 ..., -2.1015625  -3.49609375
  -2.57421875]
 ...,
 [-1.98046875 -2.79296875 -2.3828125  ..., -2.08398438 -3.46289062
  -2.5546875 ]
 [-1.99804688 -2.81835938 -2.40234375 ..., -2.09375    -3.49023438
  -2.57617188]
 [-1.99804688 -2.8203125  -2.40625    ..., -2.09570312 -3.49414062
  -2.57421875]]
After layer softmax_0 (20, 16743) <class 'numpy.float16'> [[  8.34465027e-07   3.57627869e-07   5.36441803e-07 ...,   7.74860382e-07
    1.78813934e-07   4.76837158e-07]
 [  8.34465027e-07   3.57627869e-07   5.36441803e-07 ...,   7.74860382e-07
    1.78813934e-07   4.76837158e-07]
 [  8.34465027e-07   3.57627869e-07   5.96046448e-07 ...,   7.74860382e-07
    1.78813934e-07   4.76837158e-07]
 ...,
 [  9.53674316e-07   4.17232513e-07   5.96046448e-07 ...,   8.34465027e-07
    2.38418579e-07   5.36441803e-07]
 [  8.34465027e-07   3.57627869e-07   5.96046448e-07 ...,   7.74860382e-07
    1.78813934e-07   4.76837158e-07]
 [  8.34465027e-07   3.57627869e-07   5.96046448e-07 ...,   7.74860382e-07
    1.78813934e-07   4.76837158e-07]]
After layer reshape21_0 (20, 10) <class 'numpy.float16'> [[ 0.40307617  0.59716797  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40332031  0.59667969  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40454102  0.59570312  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40307617  0.59667969  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.4050293   0.59521484  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40307617  0.59716797  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40380859  0.59619141  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40332031  0.59667969  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40795898  0.59228516  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40844727  0.59179688  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.4050293   0.59472656  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.41503906  0.58496094  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40722656  0.59277344  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40307617  0.59667969  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40307617  0.59667969  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40332031  0.59667969  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40307617  0.59667969  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.41259766  0.58691406  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40307617  0.59667969  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40307617  0.59667969  0.          0.          0.          0.          0.
   0.          0.          0.        ]]
After layer target_embed_embed_0 (20, 256) <class 'numpy.float16'> [[-0.05505371 -0.0300293  -0.03598022 ...,  0.08459473 -0.05288696
  -0.01667786]
 [-0.05505371 -0.0300293  -0.03598022 ...,  0.08459473 -0.05288696
  -0.01667786]
 [-0.05505371 -0.0300293  -0.03598022 ...,  0.08459473 -0.05288696
  -0.01667786]
 ...,
 [-0.05505371 -0.0300293  -0.03598022 ...,  0.08459473 -0.05288696
  -0.01667786]
 [-0.05505371 -0.0300293  -0.03598022 ...,  0.08459473 -0.05288696
  -0.01667786]
 [-0.05505371 -0.0300293  -0.03598022 ...,  0.08459473 -0.05288696
  -0.01667786]]
After layer decoder_rnn_concat_target_context_t0_output (20, 768) <class 'numpy.float16'> [[-0.05505371 -0.0300293  -0.03598022 ...,  0.9609375   0.97021484
  -0.91992188]
 [-0.05505371 -0.0300293  -0.03598022 ...,  0.9609375   0.97021484
  -0.91992188]
 [-0.05505371 -0.0300293  -0.03598022 ...,  0.95996094  0.97021484
  -0.92089844]
 ...,
 [-0.05505371 -0.0300293  -0.03598022 ...,  0.95751953  0.96875    -0.91748047]
 [-0.05505371 -0.0300293  -0.03598022 ...,  0.9609375   0.97021484
  -0.91943359]
 [-0.05505371 -0.0300293  -0.03598022 ...,  0.9609375   0.97021484
  -0.91943359]]
After layer decoder_rnn_l0_t0_i2h_output (20, 2048) <class 'numpy.float16'> [[-3.1875      1.61230469  2.43359375 ..., -0.07720947  3.8671875
   0.60058594]
 [-3.1875      1.61132812  2.43164062 ..., -0.07739258  3.86523438
   0.60058594]
 [-3.18359375  1.61230469  2.4296875  ..., -0.07495117  3.8671875
   0.60546875]
 ...,
 [-3.14257812  1.59082031  2.40039062 ..., -0.06604004  3.83007812
   0.63671875]
 [-3.18164062  1.60742188  2.43359375 ..., -0.07647705  3.85742188
   0.60009766]
 [-3.18359375  1.609375    2.43164062 ..., -0.07727051  3.86132812
   0.60107422]]
After layer decoder_rnn_l0_t0_h2h_output (20, 2048) <class 'numpy.float16'> [[-0.32177734  0.47265625  1.83007812 ...,  0.70166016  1.296875
   0.17370605]
 [-0.32275391  0.47338867  1.82910156 ...,  0.69970703  1.29492188
   0.17224121]
 [-0.32885742  0.48144531  1.82128906 ...,  0.69628906  1.30566406
   0.16784668]
 ...,
 [-0.38452148  0.51123047  1.81738281 ...,  0.67724609  1.28515625
   0.17614746]
 [-0.328125    0.48583984  1.82910156 ...,  0.69433594  1.30078125
   0.16259766]
 [-0.32641602  0.48046875  1.828125   ...,  0.6953125   1.29785156
   0.16687012]]
After layer _plus1055_0 (20, 2048) <class 'numpy.float16'> [[-3.50976562  2.0859375   4.265625   ...,  0.62451172  5.1640625
   0.77441406]
 [-3.50976562  2.08398438  4.26171875 ...,  0.62207031  5.16015625
   0.77294922]
 [-3.51171875  2.09375     4.25       ...,  0.62109375  5.171875    0.7734375 ]
 ...,
 [-3.52734375  2.1015625   4.21875    ...,  0.61132812  5.1171875
   0.81298828]
 [-3.50976562  2.09375     4.26171875 ...,  0.61767578  5.15625     0.76269531]
 [-3.50976562  2.08984375  4.2578125  ...,  0.61816406  5.16015625
   0.76806641]]
After layer decoder_rnn_l0_t0_slice_output0 (20, 512) <class 'numpy.float16'> [[-3.50976562  2.0859375   4.265625   ...,  1.75        4.59375     2.77929688]
 [-3.50976562  2.08398438  4.26171875 ...,  1.74902344  4.59765625
   2.77734375]
 [-3.51171875  2.09375     4.25       ...,  1.75683594  4.578125
   2.77539062]
 ...,
 [-3.52734375  2.1015625   4.21875    ...,  1.73730469  4.54296875
   2.76953125]
 [-3.50976562  2.09375     4.26171875 ...,  1.74023438  4.58984375
   2.7734375 ]
 [-3.50976562  2.08984375  4.2578125  ...,  1.74414062  4.59375     2.7734375 ]]
After layer decoder_rnn_l0_t0_slice_output1 (20, 512) <class 'numpy.float16'> [[-1.86621094  2.30859375  2.41796875 ...,  3.16210938 -0.72167969
   1.97070312]
 [-1.86523438  2.30859375  2.41796875 ...,  3.16015625 -0.71875     1.96875   ]
 [-1.875       2.30078125  2.42382812 ...,  3.15234375 -0.73632812
   1.96484375]
 ...,
 [-1.90625     2.29492188  2.421875   ...,  3.10546875 -0.74511719
   1.90917969]
 [-1.87304688  2.31054688  2.41796875 ...,  3.1484375  -0.71191406
   1.96289062]
 [-1.87109375  2.30859375  2.41796875 ...,  3.15234375 -0.71582031
   1.96484375]]
After layer decoder_rnn_l0_t0_slice_output2 (20, 512) <class 'numpy.float16'> [[-2.8125     -3.07617188  2.84765625 ...,  4.26171875 -0.07470703
   2.16210938]
 [-2.80859375 -3.07421875  2.84570312 ...,  4.2578125  -0.07763672
   2.16015625]
 [-2.8125     -3.078125    2.86328125 ...,  4.25       -0.078125
   2.16210938]
 ...,
 [-2.75976562 -3.07226562  2.87109375 ...,  4.17578125 -0.13330078
   2.12109375]
 [-2.8046875  -3.07617188  2.84765625 ...,  4.24609375 -0.09350586  2.15625   ]
 [-2.8046875  -3.07421875  2.84765625 ...,  4.25       -0.08520508
   2.15820312]]
After layer decoder_rnn_l0_t0_slice_output3 (20, 512) <class 'numpy.float16'> [[-3.26953125  2.44921875 -1.40625    ...,  0.62451172  5.1640625
   0.77441406]
 [-3.27148438  2.44921875 -1.40625    ...,  0.62207031  5.16015625
   0.77294922]
 [-3.26953125  2.46875    -1.41894531 ...,  0.62109375  5.171875    0.7734375 ]
 ...,
 [-3.28125     2.53125    -1.453125   ...,  0.61132812  5.1171875
   0.81298828]
 [-3.2734375   2.453125   -1.41601562 ...,  0.61767578  5.15625     0.76269531]
 [-3.2734375   2.453125   -1.41210938 ...,  0.61816406  5.16015625
   0.76806641]]
After layer decoder_rnn_l0_t0_o_output (20, 512) <class 'numpy.float16'> [[ 0.03662109  0.92041016  0.19677734 ...,  0.65136719  0.99414062
   0.68457031]
 [ 0.03656006  0.92041016  0.19677734 ...,  0.65087891  0.99414062
   0.68408203]
 [ 0.03662109  0.921875    0.19482422 ...,  0.65039062  0.99414062
   0.68408203]
 ...,
 [ 0.03622437  0.92626953  0.1895752  ...,  0.6484375   0.99414062
   0.69287109]
 [ 0.03649902  0.92089844  0.1953125  ...,  0.64990234  0.99414062
   0.68212891]
 [ 0.03649902  0.92089844  0.19592285 ...,  0.64990234  0.99414062
   0.68310547]]
After layer decoder_rnn_l0_t0_f_output (20, 512) <class 'numpy.float16'> [[ 0.1340332   0.90966797  0.91796875 ...,  0.95947266  0.3269043
   0.87792969]
 [ 0.1340332   0.90966797  0.91796875 ...,  0.95947266  0.32763672
   0.87744141]
 [ 0.13293457  0.90917969  0.91845703 ...,  0.95898438  0.32373047
   0.87695312]
 ...,
 [ 0.12939453  0.90869141  0.91845703 ...,  0.95703125  0.32177734
   0.87109375]
 [ 0.13317871  0.90966797  0.91796875 ...,  0.95898438  0.32910156
   0.87695312]
 [ 0.13342285  0.90966797  0.91796875 ...,  0.95898438  0.32836914
   0.87695312]]
After layer _mul2110_0 (20, 512) <class 'numpy.float16'> [[ -4.47463989e-03  -4.78515625e+00   5.47656250e+00 ...,   6.01562500e+00
   -3.52172852e-02   4.22656250e+00]
 [ -4.47463989e-03  -4.78515625e+00   5.44140625e+00 ...,   5.92968750e+00
   -3.82385254e-02   4.16796875e+00]
 [ -4.42123413e-03  -4.75000000e+00   5.46875000e+00 ...,   5.80078125e+00
   -4.04357910e-02   4.07812500e+00]
 ...,
 [ -3.96728516e-03  -4.45312500e+00   5.10937500e+00 ...,   5.35546875e+00
   -1.20666504e-01   3.37109375e+00]
 [ -4.42886353e-03  -4.78125000e+00   5.40625000e+00 ...,   5.87890625e+00
   -5.23376465e-02   4.08593750e+00]
 [ -4.44412231e-03  -4.78515625e+00   5.43359375e+00 ...,   5.87500000e+00
   -4.56237793e-02   4.12500000e+00]]
After layer decoder_rnn_l0_t0_i_output (20, 512) <class 'numpy.float16'> [[ 0.02903748  0.88964844  0.98632812 ...,  0.85205078  0.98974609
   0.94140625]
 [ 0.02903748  0.88916016  0.98632812 ...,  0.85205078  0.99023438
   0.94140625]
 [ 0.02897644  0.89013672  0.98583984 ...,  0.85302734  0.98974609
   0.94140625]
 ...,
 [ 0.02854919  0.89111328  0.98535156 ...,  0.85058594  0.98925781
   0.94091797]
 [ 0.02903748  0.89013672  0.98632812 ...,  0.85058594  0.98974609
   0.94140625]
 [ 0.02903748  0.89013672  0.98583984 ...,  0.85107422  0.98974609
   0.94140625]]
After layer decoder_rnn_l0_t0_c_output (20, 512) <class 'numpy.float16'> [[-0.99267578 -0.99560547  0.99316406 ...,  0.99951172 -0.07458496
   0.97363281]
 [-0.99267578 -0.99560547  0.99316406 ...,  0.99951172 -0.07745361
   0.97363281]
 [-0.99267578 -0.99560547  0.99365234 ...,  0.99951172 -0.07794189
   0.97363281]
 ...,
 [-0.9921875  -0.99560547  0.99365234 ...,  0.99951172 -0.13256836
   0.97167969]
 [-0.99267578 -0.99560547  0.99316406 ...,  0.99951172 -0.09326172
   0.97363281]
 [-0.99267578 -0.99560547  0.99316406 ...,  0.99951172 -0.08502197
   0.97363281]]
After layer _mul2111_0 (20, 512) <class 'numpy.float16'> [[-0.02882385 -0.88574219  0.97949219 ...,  0.8515625  -0.0737915
   0.91650391]
 [-0.02882385 -0.88525391  0.97949219 ...,  0.8515625  -0.07672119
   0.91650391]
 [-0.02876282 -0.88623047  0.97949219 ...,  0.85253906 -0.07714844
   0.91650391]
 ...,
 [-0.02832031 -0.88720703  0.97900391 ...,  0.85009766 -0.13110352
   0.9140625 ]
 [-0.02882385 -0.88623047  0.97949219 ...,  0.85009766 -0.09228516
   0.91650391]
 [-0.02882385 -0.88623047  0.97900391 ...,  0.85058594 -0.08416748
   0.91650391]]
After layer decoder_rnn_l0_t0_state_0 (20, 512) <class 'numpy.float16'> [[-0.03329468 -5.671875    6.45703125 ...,  6.8671875  -0.10900879
   5.14453125]
 [-0.03329468 -5.671875    6.421875   ...,  6.78125    -0.11499023
   5.0859375 ]
 [-0.03317261 -5.63671875  6.44921875 ...,  6.65234375 -0.11755371
   4.99609375]
 ...,
 [-0.0322876  -5.33984375  6.08984375 ...,  6.20703125 -0.25170898
   4.28515625]
 [-0.03326416 -5.66796875  6.38671875 ...,  6.73046875 -0.14465332
   5.00390625]
 [-0.03326416 -5.671875    6.4140625  ...,  6.7265625  -0.12976074
   5.04296875]]
After layer activation1055_output (20, 512) <class 'numpy.float16'> [[-0.03329468 -1.          1.         ...,  1.         -0.10858154  1.        ]
 [-0.03329468 -1.          1.         ...,  1.         -0.11450195  1.        ]
 [-0.03317261 -1.          1.         ...,  1.         -0.11700439  1.        ]
 ...,
 [-0.0322876  -1.          1.         ...,  1.         -0.24658203
   0.99951172]
 [-0.03326416 -1.          1.         ...,  1.         -0.14367676  1.        ]
 [-0.03326416 -1.          1.         ...,  1.         -0.12902832  1.        ]]
After layer decoder_rnn_l0_t0_out_0 (20, 512) <class 'numpy.float16'> [[-0.00121975 -0.92041016  0.19677734 ...,  0.65136719 -0.10797119
   0.68457031]
 [-0.00121689 -0.92041016  0.19677734 ...,  0.65087891 -0.11383057
   0.68408203]
 [-0.00121498 -0.921875    0.19482422 ...,  0.65039062 -0.11633301
   0.68408203]
 ...,
 [-0.0011692  -0.92626953  0.1895752  ...,  0.6484375  -0.24511719
   0.69238281]
 [-0.00121403 -0.92089844  0.1953125  ...,  0.64990234 -0.14282227
   0.68212891]
 [-0.00121403 -0.92089844  0.19592285 ...,  0.64990234 -0.1282959
   0.68310547]]
After layer expand_dims1064_0 (20, 512, 1) <class 'numpy.float16'> [[[-0.00121975]
  [-0.92041016]
  [ 0.19677734]
  ...,
  [ 0.65136719]
  [-0.10797119]
  [ 0.68457031]]

 [[-0.00121689]
  [-0.92041016]
  [ 0.19677734]
  ...,
  [ 0.65087891]
  [-0.11383057]
  [ 0.68408203]]

 [[-0.00121498]
  [-0.921875  ]
  [ 0.19482422]
  ...,
  [ 0.65039062]
  [-0.11633301]
  [ 0.68408203]]

 ...,
 [[-0.0011692 ]
  [-0.92626953]
  [ 0.1895752 ]
  ...,
  [ 0.6484375 ]
  [-0.24511719]
  [ 0.69238281]]

 [[-0.00121403]
  [-0.92089844]
  [ 0.1953125 ]
  ...,
  [ 0.64990234]
  [-0.14282227]
  [ 0.68212891]]

 [[-0.00121403]
  [-0.92089844]
  [ 0.19592285]
  ...,
  [ 0.64990234]
  [-0.1282959 ]
  [ 0.68310547]]]
After layer att_batch_dot_0 (20, 10, 1) <class 'numpy.float16'> [[[  0.52832031]
  [  0.92089844]
  [  1.6171875 ]
  [  2.5703125 ]
  [  2.48046875]
  [  0.23693848]
  [ -2.99023438]
  [ -5.82421875]
  [ -7.953125  ]
  [ -9.546875  ]]

 [[  0.52880859]
  [  0.92041016]
  [  1.61914062]
  [  2.57421875]
  [  2.48632812]
  [  0.24353027]
  [ -2.98242188]
  [ -5.81640625]
  [ -7.9453125 ]
  [ -9.5390625 ]]

 [[  0.52587891]
  [  0.91552734]
  [  1.60058594]
  [  2.53515625]
  [  2.4140625 ]
  [  0.13537598]
  [ -3.125     ]
  [ -5.984375  ]
  [ -8.1328125 ]
  [ -9.734375  ]]

 [[  0.52929688]
  [  0.92236328]
  [  1.62402344]
  [  2.58398438]
  [  2.5       ]
  [  0.25610352]
  [ -2.97460938]
  [ -5.8125    ]
  [ -7.9453125 ]
  [ -9.5390625 ]]

 [[  0.52587891]
  [  0.9140625 ]
  [  1.60546875]
  [  2.54492188]
  [  2.421875  ]
  [  0.12463379]
  [ -3.16210938]
  [ -6.046875  ]
  [ -8.2109375 ]
  [ -9.828125  ]]

 [[  0.52636719]
  [  0.91845703]
  [  1.609375  ]
  [  2.55078125]
  [  2.43164062]
  [  0.13977051]
  [ -3.140625  ]
  [ -6.01953125]
  [ -8.1796875 ]
  [ -9.796875  ]]

 [[  0.52783203]
  [  0.92089844]
  [  1.61816406]
  [  2.57421875]
  [  2.48242188]
  [  0.23913574]
  [ -2.99023438]
  [ -5.82421875]
  [ -7.95703125]
  [ -9.5546875 ]]

 [[  0.52783203]
  [  0.91992188]
  [  1.61523438]
  [  2.56640625]
  [  2.47460938]
  [  0.23144531]
  [ -2.99414062]
  [ -5.828125  ]
  [ -7.953125  ]
  [ -9.546875  ]]

 [[  0.52978516]
  [  0.9140625 ]
  [  1.609375  ]
  [  2.5546875 ]
  [  2.44921875]
  [  0.18054199]
  [ -3.07226562]
  [ -5.921875  ]
  [ -8.0625    ]
  [ -9.65625   ]]

 [[  0.515625  ]
  [  0.89599609]
  [  1.55859375]
  [  2.453125  ]
  [  2.26757812]
  [ -0.09387207]
  [ -3.4296875 ]
  [ -6.34765625]
  [ -8.5390625 ]
  [-10.1640625 ]]

 [[  0.52490234]
  [  0.91259766]
  [  1.59375   ]
  [  2.52148438]
  [  2.39453125]
  [  0.11462402]
  [ -3.14257812]
  [ -5.99609375]
  [ -8.140625  ]
  [ -9.7421875 ]]

 [[  0.51318359]
  [  0.88623047]
  [  1.54882812]
  [  2.4375    ]
  [  2.2421875 ]
  [ -0.13293457]
  [ -3.48242188]
  [ -6.41015625]
  [ -8.59375   ]
  [-10.2265625 ]]

 [[  0.52880859]
  [  0.92089844]
  [  1.61914062]
  [  2.57617188]
  [  2.48632812]
  [  0.24475098]
  [ -2.98242188]
  [ -5.81640625]
  [ -7.94140625]
  [ -9.5390625 ]]

 [[  0.51220703]
  [  0.86181641]
  [  1.50292969]
  [  2.34375   ]
  [  2.08203125]
  [ -0.36279297]
  [ -3.76367188]
  [ -6.7109375 ]
  [ -8.90625   ]
  [-10.5390625 ]]

 [[  0.52880859]
  [  0.92138672]
  [  1.62109375]
  [  2.578125  ]
  [  2.49023438]
  [  0.24926758]
  [ -2.97851562]
  [ -5.8125    ]
  [ -7.94140625]
  [ -9.5390625 ]]

 [[  0.52929688]
  [  0.92138672]
  [  1.62109375]
  [  2.58007812]
  [  2.4921875 ]
  [  0.24829102]
  [ -2.98242188]
  [ -5.8203125 ]
  [ -7.94921875]
  [ -9.546875  ]]

 [[  0.52929688]
  [  0.92138672]
  [  1.62304688]
  [  2.58203125]
  [  2.49414062]
  [  0.24609375]
  [ -2.99023438]
  [ -5.83203125]
  [ -7.96484375]
  [ -9.5625    ]]

 [[  0.51904297]
  [  0.89453125]
  [  1.57324219]
  [  2.484375  ]
  [  2.30859375]
  [ -0.05804443]
  [ -3.40820312]
  [ -6.33984375]
  [ -8.53125   ]
  [-10.1640625 ]]

 [[  0.52929688]
  [  0.92236328]
  [  1.625     ]
  [  2.5859375 ]
  [  2.49804688]
  [  0.24682617]
  [ -2.99609375]
  [ -5.84375   ]
  [ -7.984375  ]
  [ -9.5859375 ]]

 [[  0.52929688]
  [  0.921875  ]
  [  1.62207031]
  [  2.58203125]
  [  2.49414062]
  [  0.24743652]
  [ -2.98632812]
  [ -5.828125  ]
  [ -7.9609375 ]
  [ -9.5546875 ]]]
After layer swapaxes31_output (10, 20, 1) <class 'numpy.float16'> [[[  0.52832031]
  [  0.52880859]
  [  0.52587891]
  [  0.52929688]
  [  0.52587891]
  [  0.52636719]
  [  0.52783203]
  [  0.52783203]
  [  0.52978516]
  [  0.515625  ]
  [  0.52490234]
  [  0.51318359]
  [  0.52880859]
  [  0.51220703]
  [  0.52880859]
  [  0.52929688]
  [  0.52929688]
  [  0.51904297]
  [  0.52929688]
  [  0.52929688]]

 [[  0.92089844]
  [  0.92041016]
  [  0.91552734]
  [  0.92236328]
  [  0.9140625 ]
  [  0.91845703]
  [  0.92089844]
  [  0.91992188]
  [  0.9140625 ]
  [  0.89599609]
  [  0.91259766]
  [  0.88623047]
  [  0.92089844]
  [  0.86181641]
  [  0.92138672]
  [  0.92138672]
  [  0.92138672]
  [  0.89453125]
  [  0.92236328]
  [  0.921875  ]]

 [[  1.6171875 ]
  [  1.61914062]
  [  1.60058594]
  [  1.62402344]
  [  1.60546875]
  [  1.609375  ]
  [  1.61816406]
  [  1.61523438]
  [  1.609375  ]
  [  1.55859375]
  [  1.59375   ]
  [  1.54882812]
  [  1.61914062]
  [  1.50292969]
  [  1.62109375]
  [  1.62109375]
  [  1.62304688]
  [  1.57324219]
  [  1.625     ]
  [  1.62207031]]

 [[  2.5703125 ]
  [  2.57421875]
  [  2.53515625]
  [  2.58398438]
  [  2.54492188]
  [  2.55078125]
  [  2.57421875]
  [  2.56640625]
  [  2.5546875 ]
  [  2.453125  ]
  [  2.52148438]
  [  2.4375    ]
  [  2.57617188]
  [  2.34375   ]
  [  2.578125  ]
  [  2.58007812]
  [  2.58203125]
  [  2.484375  ]
  [  2.5859375 ]
  [  2.58203125]]

 [[  2.48046875]
  [  2.48632812]
  [  2.4140625 ]
  [  2.5       ]
  [  2.421875  ]
  [  2.43164062]
  [  2.48242188]
  [  2.47460938]
  [  2.44921875]
  [  2.26757812]
  [  2.39453125]
  [  2.2421875 ]
  [  2.48632812]
  [  2.08203125]
  [  2.49023438]
  [  2.4921875 ]
  [  2.49414062]
  [  2.30859375]
  [  2.49804688]
  [  2.49414062]]

 [[  0.23693848]
  [  0.24353027]
  [  0.13537598]
  [  0.25610352]
  [  0.12463379]
  [  0.13977051]
  [  0.23913574]
  [  0.23144531]
  [  0.18054199]
  [ -0.09387207]
  [  0.11462402]
  [ -0.13293457]
  [  0.24475098]
  [ -0.36279297]
  [  0.24926758]
  [  0.24829102]
  [  0.24609375]
  [ -0.05804443]
  [  0.24682617]
  [  0.24743652]]

 [[ -2.99023438]
  [ -2.98242188]
  [ -3.125     ]
  [ -2.97460938]
  [ -3.16210938]
  [ -3.140625  ]
  [ -2.99023438]
  [ -2.99414062]
  [ -3.07226562]
  [ -3.4296875 ]
  [ -3.14257812]
  [ -3.48242188]
  [ -2.98242188]
  [ -3.76367188]
  [ -2.97851562]
  [ -2.98242188]
  [ -2.99023438]
  [ -3.40820312]
  [ -2.99609375]
  [ -2.98632812]]

 [[ -5.82421875]
  [ -5.81640625]
  [ -5.984375  ]
  [ -5.8125    ]
  [ -6.046875  ]
  [ -6.01953125]
  [ -5.82421875]
  [ -5.828125  ]
  [ -5.921875  ]
  [ -6.34765625]
  [ -5.99609375]
  [ -6.41015625]
  [ -5.81640625]
  [ -6.7109375 ]
  [ -5.8125    ]
  [ -5.8203125 ]
  [ -5.83203125]
  [ -6.33984375]
  [ -5.84375   ]
  [ -5.828125  ]]

 [[ -7.953125  ]
  [ -7.9453125 ]
  [ -8.1328125 ]
  [ -7.9453125 ]
  [ -8.2109375 ]
  [ -8.1796875 ]
  [ -7.95703125]
  [ -7.953125  ]
  [ -8.0625    ]
  [ -8.5390625 ]
  [ -8.140625  ]
  [ -8.59375   ]
  [ -7.94140625]
  [ -8.90625   ]
  [ -7.94140625]
  [ -7.94921875]
  [ -7.96484375]
  [ -8.53125   ]
  [ -7.984375  ]
  [ -7.9609375 ]]

 [[ -9.546875  ]
  [ -9.5390625 ]
  [ -9.734375  ]
  [ -9.5390625 ]
  [ -9.828125  ]
  [ -9.796875  ]
  [ -9.5546875 ]
  [ -9.546875  ]
  [ -9.65625   ]
  [-10.1640625 ]
  [ -9.7421875 ]
  [-10.2265625 ]
  [ -9.5390625 ]
  [-10.5390625 ]
  [ -9.5390625 ]
  [ -9.546875  ]
  [ -9.5625    ]
  [-10.1640625 ]
  [ -9.5859375 ]
  [ -9.5546875 ]]]
After layer sequencemask11_output (10, 20, 1) <class 'numpy.float16'> [[[  5.28320312e-01]
  [  5.28808594e-01]
  [  5.25878906e-01]
  [  5.29296875e-01]
  [  5.25878906e-01]
  [  5.26367188e-01]
  [  5.27832031e-01]
  [  5.27832031e-01]
  [  5.29785156e-01]
  [  5.15625000e-01]
  [  5.24902344e-01]
  [  5.13183594e-01]
  [  5.28808594e-01]
  [  5.12207031e-01]
  [  5.28808594e-01]
  [  5.29296875e-01]
  [  5.29296875e-01]
  [  5.19042969e-01]
  [  5.29296875e-01]
  [  5.29296875e-01]]

 [[  9.20898438e-01]
  [  9.20410156e-01]
  [  9.15527344e-01]
  [  9.22363281e-01]
  [  9.14062500e-01]
  [  9.18457031e-01]
  [  9.20898438e-01]
  [  9.19921875e-01]
  [  9.14062500e-01]
  [  8.95996094e-01]
  [  9.12597656e-01]
  [  8.86230469e-01]
  [  9.20898438e-01]
  [  8.61816406e-01]
  [  9.21386719e-01]
  [  9.21386719e-01]
  [  9.21386719e-01]
  [  8.94531250e-01]
  [  9.22363281e-01]
  [  9.21875000e-01]]

 [[ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]]
After layer swapaxes32_output (20, 10, 1) <class 'numpy.float16'> [[[  5.28320312e-01]
  [  9.20898438e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  5.28808594e-01]
  [  9.20410156e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  5.25878906e-01]
  [  9.15527344e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  5.29296875e-01]
  [  9.22363281e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  5.25878906e-01]
  [  9.14062500e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  5.26367188e-01]
  [  9.18457031e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  5.27832031e-01]
  [  9.20898438e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  5.27832031e-01]
  [  9.19921875e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  5.29785156e-01]
  [  9.14062500e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  5.15625000e-01]
  [  8.95996094e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  5.24902344e-01]
  [  9.12597656e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  5.13183594e-01]
  [  8.86230469e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  5.28808594e-01]
  [  9.20898438e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  5.12207031e-01]
  [  8.61816406e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  5.28808594e-01]
  [  9.21386719e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  5.29296875e-01]
  [  9.21386719e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  5.29296875e-01]
  [  9.21386719e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  5.19042969e-01]
  [  8.94531250e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  5.29296875e-01]
  [  9.22363281e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  5.29296875e-01]
  [  9.21875000e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]]
After layer attention_softmax_0 (20, 10, 1) <class 'numpy.float16'> [[[ 0.40307617]
  [ 0.59667969]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40332031]
  [ 0.59667969]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40380859]
  [ 0.59619141]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40307617]
  [ 0.59716797]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40429688]
  [ 0.59619141]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40307617]
  [ 0.59667969]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40307617]
  [ 0.59716797]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40307617]
  [ 0.59667969]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.4050293 ]
  [ 0.59472656]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40600586]
  [ 0.59375   ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40429688]
  [ 0.59570312]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40795898]
  [ 0.59228516]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40307617]
  [ 0.59667969]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.41333008]
  [ 0.58642578]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40307617]
  [ 0.59667969]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40307617]
  [ 0.59667969]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40307617]
  [ 0.59667969]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40698242]
  [ 0.59277344]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40307617]
  [ 0.59716797]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40307617]
  [ 0.59667969]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]]
After layer batch_dot11_0 (20, 512, 1) <class 'numpy.float16'> [[[ 0.01785278]
  [ 0.03942871]
  [-0.03341675]
  ...,
  [-0.01097107]
  [ 0.00998688]
  [-0.02461243]]

 [[ 0.01785278]
  [ 0.03945923]
  [-0.03341675]
  ...,
  [-0.01097107]
  [ 0.00999451]
  [-0.02462769]]

 [[ 0.01783752]
  [ 0.03942871]
  [-0.03338623]
  ...,
  [-0.01097107]
  [ 0.00999451]
  [-0.02462769]]

 ...,
 [[ 0.01776123]
  [ 0.03933716]
  [-0.03323364]
  ...,
  [-0.01094818]
  [ 0.00998688]
  [-0.02468872]]

 [[ 0.01786804]
  [ 0.03945923]
  [-0.03341675]
  ...,
  [-0.0109787 ]
  [ 0.00999451]
  [-0.02462769]]

 [[ 0.01785278]
  [ 0.03942871]
  [-0.03341675]
  ...,
  [-0.01097107]
  [ 0.00998688]
  [-0.02461243]]]
After layer reshape22_0 (20, 512) <class 'numpy.float16'> [[ 0.01785278  0.03942871 -0.03341675 ..., -0.01097107  0.00998688
  -0.02461243]
 [ 0.01785278  0.03945923 -0.03341675 ..., -0.01097107  0.00999451
  -0.02462769]
 [ 0.01783752  0.03942871 -0.03338623 ..., -0.01097107  0.00999451
  -0.02462769]
 ...,
 [ 0.01776123  0.03933716 -0.03323364 ..., -0.01094818  0.00998688
  -0.02468872]
 [ 0.01786804  0.03945923 -0.03341675 ..., -0.0109787   0.00999451
  -0.02462769]
 [ 0.01785278  0.03942871 -0.03341675 ..., -0.01097107  0.00998688
  -0.02461243]]
After layer decoder_rnn_hidden_concat_t0_output (20, 1024) <class 'numpy.float16'> [[-0.00121975 -0.92041016  0.19677734 ..., -0.01097107  0.00998688
  -0.02461243]
 [-0.00121689 -0.92041016  0.19677734 ..., -0.01097107  0.00999451
  -0.02462769]
 [-0.00121498 -0.921875    0.19482422 ..., -0.01097107  0.00999451
  -0.02462769]
 ...,
 [-0.0011692  -0.92626953  0.1895752  ..., -0.01094818  0.00998688
  -0.02468872]
 [-0.00121403 -0.92089844  0.1953125  ..., -0.0109787   0.00999451
  -0.02462769]
 [-0.00121403 -0.92089844  0.19592285 ..., -0.01097107  0.00998688
  -0.02461243]]
After layer decoder_rnn_hidden_fc_t0_output (20, 512) <class 'numpy.float16'> [[-1.95410156  0.20361328 -0.80761719 ...,  1.96484375  2.10351562
  -1.59179688]
 [-1.95605469  0.20300293 -0.80810547 ...,  1.96582031  2.10546875
  -1.59082031]
 [-1.94726562  0.20825195 -0.81445312 ...,  1.95605469  2.1015625
  -1.59570312]
 ...,
 [-1.9453125   0.23242188 -0.83203125 ...,  1.95117188  2.09179688
  -1.59277344]
 [-1.9609375   0.20996094 -0.81689453 ...,  1.96777344  2.1015625
  -1.59179688]
 [-1.95703125  0.20568848 -0.81201172 ...,  1.96582031  2.10351562
  -1.58984375]]
After layer decoder_rnn_next_hidden_t0_output (20, 512) <class 'numpy.float16'> [[-0.96044922  0.20080566 -0.66845703 ...,  0.96142578  0.97070312
  -0.92041016]
 [-0.9609375   0.20031738 -0.66845703 ...,  0.96142578  0.97070312
  -0.92041016]
 [-0.95996094  0.20532227 -0.671875   ...,  0.9609375   0.97070312
  -0.92089844]
 ...,
 [-0.95996094  0.22827148 -0.68164062 ...,  0.96044922  0.96972656
  -0.92041016]
 [-0.9609375   0.20690918 -0.67333984 ...,  0.96191406  0.97070312
  -0.92041016]
 [-0.9609375   0.20288086 -0.67089844 ...,  0.96142578  0.97070312
  -0.91992188]]
After layer logits_output (20, 16743) <class 'numpy.float16'> [[-2.00195312 -2.82421875 -2.40820312 ..., -2.09570312 -3.5        -2.578125  ]
 [-2.00195312 -2.82226562 -2.40625    ..., -2.09570312 -3.5        -2.578125  ]
 [-1.99902344 -2.82421875 -2.40820312 ..., -2.09960938 -3.49804688
  -2.578125  ]
 ...,
 [-1.99414062 -2.80859375 -2.39453125 ..., -2.09179688 -3.48046875
  -2.56640625]
 [-2.00195312 -2.8203125  -2.40429688 ..., -2.09375    -3.49414062
  -2.58007812]
 [-2.00195312 -2.82226562 -2.40625    ..., -2.09375    -3.49609375
  -2.578125  ]]
After layer softmax_0 (20, 16743) <class 'numpy.float16'> [[  8.34465027e-07   3.57627869e-07   5.36441803e-07 ...,   7.74860382e-07
    1.78813934e-07   4.76837158e-07]
 [  8.34465027e-07   3.57627869e-07   5.36441803e-07 ...,   7.74860382e-07
    1.78813934e-07   4.76837158e-07]
 [  8.34465027e-07   3.57627869e-07   5.96046448e-07 ...,   7.74860382e-07
    1.78813934e-07   4.76837158e-07]
 ...,
 [  8.94069672e-07   4.17232513e-07   5.96046448e-07 ...,   8.34465027e-07
    1.78813934e-07   4.76837158e-07]
 [  8.34465027e-07   3.57627869e-07   5.96046448e-07 ...,   7.74860382e-07
    1.78813934e-07   4.76837158e-07]
 [  8.34465027e-07   3.57627869e-07   5.96046448e-07 ...,   7.74860382e-07
    1.78813934e-07   4.76837158e-07]]
After layer reshape23_0 (20, 10) <class 'numpy.float16'> [[ 0.40307617  0.59667969  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40332031  0.59667969  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40380859  0.59619141  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40307617  0.59716797  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40429688  0.59619141  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40307617  0.59667969  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40307617  0.59716797  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40307617  0.59667969  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.4050293   0.59472656  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40600586  0.59375     0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40429688  0.59570312  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40795898  0.59228516  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40307617  0.59667969  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.41333008  0.58642578  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40307617  0.59667969  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40307617  0.59667969  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40307617  0.59667969  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40698242  0.59277344  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40307617  0.59716797  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40307617  0.59667969  0.          0.          0.          0.          0.
   0.          0.          0.        ]]
After layer target_embed_embed_0 (20, 256) <class 'numpy.float16'> [[-0.05505371 -0.0300293  -0.03598022 ...,  0.08459473 -0.05288696
  -0.01667786]
 [-0.05505371 -0.0300293  -0.03598022 ...,  0.08459473 -0.05288696
  -0.01667786]
 [-0.05505371 -0.0300293  -0.03598022 ...,  0.08459473 -0.05288696
  -0.01667786]
 ...,
 [-0.05505371 -0.0300293  -0.03598022 ...,  0.08459473 -0.05288696
  -0.01667786]
 [-0.05505371 -0.0300293  -0.03598022 ...,  0.08459473 -0.05288696
  -0.01667786]
 [-0.05505371 -0.0300293  -0.03598022 ...,  0.08459473 -0.05288696
  -0.01667786]]
After layer decoder_rnn_concat_target_context_t0_output (20, 768) <class 'numpy.float16'> [[-0.05505371 -0.0300293  -0.03598022 ...,  0.96142578  0.97070312
  -0.92041016]
 [-0.05505371 -0.0300293  -0.03598022 ...,  0.96142578  0.97070312
  -0.92041016]
 [-0.05505371 -0.0300293  -0.03598022 ...,  0.9609375   0.97070312
  -0.92089844]
 ...,
 [-0.05505371 -0.0300293  -0.03598022 ...,  0.96044922  0.96972656
  -0.92041016]
 [-0.05505371 -0.0300293  -0.03598022 ...,  0.96191406  0.97070312
  -0.92041016]
 [-0.05505371 -0.0300293  -0.03598022 ...,  0.96142578  0.97070312
  -0.91992188]]
After layer decoder_rnn_l0_t0_i2h_output (20, 2048) <class 'numpy.float16'> [[-3.18945312  1.61132812  2.43359375 ..., -0.07781982  3.86523438
   0.59960938]
 [-3.18945312  1.61035156  2.43359375 ..., -0.07788086  3.86523438
   0.59960938]
 [-3.1875      1.61132812  2.43359375 ..., -0.07666016  3.8671875
   0.60400391]
 ...,
 [-3.16601562  1.59960938  2.42578125 ..., -0.07086182  3.84765625
   0.60986328]
 [-3.18554688  1.60742188  2.43554688 ..., -0.07684326  3.86132812
   0.59960938]
 [-3.1875      1.609375    2.43359375 ..., -0.07751465  3.86132812
   0.60009766]]
After layer decoder_rnn_l0_t0_h2h_output (20, 2048) <class 'numpy.float16'> [[-0.32177734  0.47265625  1.83789062 ...,  0.70361328  1.296875
   0.17504883]
 [-0.32226562  0.47290039  1.83789062 ...,  0.70214844  1.29589844
   0.17419434]
 [-0.32666016  0.48071289  1.83105469 ...,  0.69921875  1.30566406
   0.1697998 ]
 ...,
 [-0.35375977  0.50341797  1.83300781 ...,  0.68945312  1.30273438
   0.15258789]
 [-0.32592773  0.48266602  1.83691406 ...,  0.69873047  1.30175781
   0.16625977]
 [-0.32495117  0.47851562  1.83691406 ...,  0.69921875  1.29882812
   0.1697998 ]]
After layer _plus1056_0 (20, 2048) <class 'numpy.float16'> [[-3.51171875  2.08398438  4.2734375  ...,  0.62597656  5.1640625
   0.77441406]
 [-3.51171875  2.08398438  4.2734375  ...,  0.62402344  5.16015625
   0.77392578]
 [-3.51367188  2.09179688  4.265625   ...,  0.62255859  5.171875
   0.77392578]
 ...,
 [-3.51953125  2.10351562  4.2578125  ...,  0.61865234  5.1484375
   0.76269531]
 [-3.51171875  2.08984375  4.2734375  ...,  0.62207031  5.1640625   0.765625  ]
 [-3.51171875  2.08789062  4.26953125 ...,  0.62158203  5.16015625
   0.77001953]]
After layer decoder_rnn_l0_t0_slice_output0 (20, 512) <class 'numpy.float16'> [[-3.51171875  2.08398438  4.2734375  ...,  1.74609375  4.6015625   2.78125   ]
 [-3.51171875  2.08398438  4.2734375  ...,  1.74511719  4.6015625   2.78125   ]
 [-3.51367188  2.09179688  4.265625   ...,  1.75195312  4.58984375  2.78125   ]
 ...,
 [-3.51953125  2.10351562  4.2578125  ...,  1.74414062  4.56640625
   2.7734375 ]
 [-3.51171875  2.08984375  4.2734375  ...,  1.73925781  4.59765625
   2.77734375]
 [-3.51171875  2.08789062  4.26953125 ...,  1.7421875   4.6015625
   2.77734375]]
After layer decoder_rnn_l0_t0_slice_output1 (20, 512) <class 'numpy.float16'> [[-1.86132812  2.3125      2.421875   ...,  3.1640625  -0.71142578
   1.97558594]
 [-1.86132812  2.3125      2.421875   ...,  3.16210938 -0.70800781
   1.97460938]
 [-1.86914062  2.30664062  2.4296875  ...,  3.16015625 -0.72070312
   1.97070312]
 ...,
 [-1.890625    2.296875    2.4296875  ...,  3.13085938 -0.71875     1.9453125 ]
 [-1.86621094  2.31445312  2.42578125 ...,  3.15429688 -0.70458984
   1.97070312]
 [-1.86425781  2.31445312  2.421875   ...,  3.15820312 -0.70703125
   1.97167969]]
After layer decoder_rnn_l0_t0_slice_output2 (20, 512) <class 'numpy.float16'> [[-2.81445312 -3.078125    2.84765625 ...,  4.265625   -0.078125    2.1640625 ]
 [-2.8125     -3.078125    2.84570312 ...,  4.26171875 -0.08007812
   2.16015625]
 [-2.81640625 -3.08203125  2.86328125 ...,  4.25390625 -0.08129883
   2.16210938]
 ...,
 [-2.79296875 -3.08007812  2.87890625 ...,  4.20703125 -0.12182617
   2.14453125]
 [-2.80859375 -3.08203125  2.84960938 ...,  4.25       -0.09106445
   2.16015625]
 [-2.81054688 -3.08203125  2.84765625 ...,  4.2578125  -0.08569336
   2.16015625]]
After layer decoder_rnn_l0_t0_slice_output3 (20, 512) <class 'numpy.float16'> [[-3.2734375   2.44140625 -1.40429688 ...,  0.62597656  5.1640625
   0.77441406]
 [-3.2734375   2.44140625 -1.40429688 ...,  0.62402344  5.16015625
   0.77392578]
 [-3.26953125  2.45703125 -1.41503906 ...,  0.62255859  5.171875
   0.77392578]
 ...,
 [-3.26757812  2.49414062 -1.44335938 ...,  0.61865234  5.1484375
   0.76269531]
 [-3.27539062  2.4453125  -1.41210938 ...,  0.62207031  5.1640625   0.765625  ]
 [-3.2734375   2.4453125  -1.40820312 ...,  0.62158203  5.16015625
   0.77001953]]
After layer decoder_rnn_l0_t0_o_output (20, 512) <class 'numpy.float16'> [[ 0.03649902  0.91992188  0.19714355 ...,  0.65136719  0.99414062
   0.68457031]
 [ 0.03649902  0.91992188  0.19714355 ...,  0.65136719  0.99414062
   0.68457031]
 [ 0.03662109  0.92089844  0.19543457 ...,  0.65087891  0.99414062
   0.68457031]
 ...,
 [ 0.03671265  0.92382812  0.19104004 ...,  0.64990234  0.99414062
   0.68212891]
 [ 0.03643799  0.92041016  0.19592285 ...,  0.65087891  0.99414062
   0.68261719]
 [ 0.03649902  0.92041016  0.1965332  ...,  0.65039062  0.99414062
   0.68359375]]
After layer decoder_rnn_l0_t0_f_output (20, 512) <class 'numpy.float16'> [[ 0.13452148  0.90966797  0.91845703 ...,  0.95947266  0.3293457
   0.87841797]
 [ 0.13452148  0.90966797  0.91845703 ...,  0.95947266  0.33007812
   0.87792969]
 [ 0.13366699  0.90966797  0.91894531 ...,  0.95947266  0.32714844
   0.87792969]
 ...,
 [ 0.13122559  0.90869141  0.91894531 ...,  0.95800781  0.32763672  0.875     ]
 [ 0.1340332   0.91015625  0.91894531 ...,  0.95898438  0.33081055
   0.87792969]
 [ 0.13415527  0.91015625  0.91845703 ...,  0.95947266  0.33032227
   0.87792969]]
After layer _mul2112_0 (20, 512) <class 'numpy.float16'> [[ -4.47845459e-03  -5.16015625e+00   5.92968750e+00 ...,   6.58984375e+00
   -3.58886719e-02   4.51953125e+00]
 [ -4.47845459e-03  -5.16015625e+00   5.89843750e+00 ...,   6.50781250e+00
   -3.79638672e-02   4.46484375e+00]
 [ -4.43267822e-03  -5.12890625e+00   5.92578125e+00 ...,   6.38281250e+00
   -3.84521484e-02   4.38671875e+00]
 ...,
 [ -4.23812866e-03  -4.85156250e+00   5.59765625e+00 ...,   5.94531250e+00
   -8.24584961e-02   3.75000000e+00]
 [ -4.45938110e-03  -5.16015625e+00   5.86718750e+00 ...,   6.45312500e+00
   -4.78515625e-02   4.39453125e+00]
 [ -4.46319580e-03  -5.16406250e+00   5.89062500e+00 ...,   6.45312500e+00
   -4.28771973e-02   4.42578125e+00]]
After layer decoder_rnn_l0_t0_i_output (20, 512) <class 'numpy.float16'> [[ 0.02897644  0.88916016  0.98632812 ...,  0.8515625   0.99023438
   0.94189453]
 [ 0.02897644  0.88916016  0.98632812 ...,  0.8515625   0.99023438
   0.94189453]
 [ 0.02893066  0.89013672  0.98632812 ...,  0.85205078  0.98974609
   0.94189453]
 ...,
 [ 0.02876282  0.89111328  0.98583984 ...,  0.85107422  0.98974609
   0.94140625]
 [ 0.02897644  0.89013672  0.98632812 ...,  0.85058594  0.99023438
   0.94140625]
 [ 0.02897644  0.88964844  0.98632812 ...,  0.85107422  0.99023438
   0.94140625]]
After layer decoder_rnn_l0_t0_c_output (20, 512) <class 'numpy.float16'> [[-0.99267578 -0.99560547  0.99316406 ...,  0.99951172 -0.07794189
   0.97412109]
 [-0.99267578 -0.99560547  0.99316406 ...,  0.99951172 -0.07989502
   0.97363281]
 [-0.99267578 -0.99560547  0.99365234 ...,  0.99951172 -0.08111572
   0.97363281]
 ...,
 [-0.99267578 -0.99560547  0.99365234 ...,  0.99951172 -0.12121582
   0.97314453]
 [-0.99267578 -0.99560547  0.99316406 ...,  0.99951172 -0.09082031
   0.97363281]
 [-0.99267578 -0.99560547  0.99316406 ...,  0.99951172 -0.08551025
   0.97363281]]
After layer _mul2113_0 (20, 512) <class 'numpy.float16'> [[-0.02876282 -0.88525391  0.97949219 ...,  0.85107422 -0.07720947
   0.91748047]
 [-0.02876282 -0.88525391  0.97949219 ...,  0.85107422 -0.07910156
   0.91699219]
 [-0.02871704 -0.88623047  0.97998047 ...,  0.8515625  -0.08026123
   0.91699219]
 ...,
 [-0.02854919 -0.88720703  0.97949219 ...,  0.85058594 -0.11999512
   0.91601562]
 [-0.02876282 -0.88623047  0.97949219 ...,  0.85009766 -0.08990479
   0.91650391]
 [-0.02876282 -0.88574219  0.97949219 ...,  0.85058594 -0.08465576
   0.91650391]]
After layer decoder_rnn_l0_t0_state_0 (20, 512) <class 'numpy.float16'> [[-0.03323364 -6.046875    6.91015625 ...,  7.44140625 -0.11309814  5.4375    ]
 [-0.03323364 -6.046875    6.87890625 ...,  7.359375   -0.11706543
   5.3828125 ]
 [-0.03314209 -6.015625    6.90625    ...,  7.234375   -0.11871338
   5.3046875 ]
 ...,
 [-0.03277588 -5.73828125  6.578125   ...,  6.796875   -0.20239258
   4.6640625 ]
 [-0.03323364 -6.046875    6.84765625 ...,  7.3046875  -0.13769531  5.3125    ]
 [-0.03323364 -6.05078125  6.87109375 ...,  7.3046875  -0.12756348  5.34375   ]]
After layer activation1056_output (20, 512) <class 'numpy.float16'> [[-0.03323364 -1.          1.         ...,  1.         -0.11260986  1.        ]
 [-0.03323364 -1.          1.         ...,  1.         -0.11651611  1.        ]
 [-0.03314209 -1.          1.         ...,  1.         -0.11816406  1.        ]
 ...,
 [-0.03277588 -1.          1.         ...,  1.         -0.19970703  1.        ]
 [-0.03323364 -1.          1.         ...,  1.         -0.13684082  1.        ]
 [-0.03323364 -1.          1.         ...,  1.         -0.12683105  1.        ]]
After layer decoder_rnn_l0_t0_out_0 (20, 512) <class 'numpy.float16'> [[-0.00121307 -0.91992188  0.19714355 ...,  0.65136719 -0.11193848
   0.68457031]
 [-0.00121307 -0.91992188  0.19714355 ...,  0.65136719 -0.11584473
   0.68457031]
 [-0.00121403 -0.92089844  0.19543457 ...,  0.65087891 -0.11749268
   0.68457031]
 ...,
 [-0.00120354 -0.92382812  0.19104004 ...,  0.64990234 -0.19848633
   0.68212891]
 [-0.00121117 -0.92041016  0.19592285 ...,  0.65087891 -0.13598633
   0.68261719]
 [-0.00121307 -0.92041016  0.1965332  ...,  0.65039062 -0.12609863
   0.68359375]]
After layer expand_dims1065_0 (20, 512, 1) <class 'numpy.float16'> [[[-0.00121307]
  [-0.91992188]
  [ 0.19714355]
  ...,
  [ 0.65136719]
  [-0.11193848]
  [ 0.68457031]]

 [[-0.00121307]
  [-0.91992188]
  [ 0.19714355]
  ...,
  [ 0.65136719]
  [-0.11584473]
  [ 0.68457031]]

 [[-0.00121403]
  [-0.92089844]
  [ 0.19543457]
  ...,
  [ 0.65087891]
  [-0.11749268]
  [ 0.68457031]]

 ...,
 [[-0.00120354]
  [-0.92382812]
  [ 0.19104004]
  ...,
  [ 0.64990234]
  [-0.19848633]
  [ 0.68212891]]

 [[-0.00121117]
  [-0.92041016]
  [ 0.19592285]
  ...,
  [ 0.65087891]
  [-0.13598633]
  [ 0.68261719]]

 [[-0.00121307]
  [-0.92041016]
  [ 0.1965332 ]
  ...,
  [ 0.65039062]
  [-0.12609863]
  [ 0.68359375]]]
After layer att_batch_dot_0 (20, 10, 1) <class 'numpy.float16'> [[[  5.29296875e-01]
  [  9.22363281e-01]
  [  1.62402344e+00]
  [  2.58398438e+00]
  [  2.49804688e+00]
  [  2.54882812e-01]
  [ -2.97460938e+00]
  [ -5.81250000e+00]
  [ -7.94140625e+00]
  [ -9.53906250e+00]]

 [[  5.29785156e-01]
  [  9.21386719e-01]
  [  1.62402344e+00]
  [  2.58593750e+00]
  [  2.50000000e+00]
  [  2.57568359e-01]
  [ -2.97070312e+00]
  [ -5.80859375e+00]
  [ -7.93750000e+00]
  [ -9.53125000e+00]]

 [[  5.27343750e-01]
  [  9.17968750e-01]
  [  1.61035156e+00]
  [  2.55468750e+00]
  [  2.44531250e+00]
  [  1.73706055e-01]
  [ -3.08203125e+00]
  [ -5.94140625e+00]
  [ -8.08593750e+00]
  [ -9.69531250e+00]]

 [[  5.29785156e-01]
  [  9.22851562e-01]
  [  1.62695312e+00]
  [  2.59179688e+00]
  [  2.50781250e+00]
  [  2.63183594e-01]
  [ -2.97070312e+00]
  [ -5.81250000e+00]
  [ -7.94531250e+00]
  [ -9.54687500e+00]]

 [[  5.28320312e-01]
  [  9.18457031e-01]
  [  1.61621094e+00]
  [  2.56640625e+00]
  [  2.45703125e+00]
  [  1.70898438e-01]
  [ -3.10546875e+00]
  [ -5.98437500e+00]
  [ -8.14062500e+00]
  [ -9.75781250e+00]]

 [[  5.28808594e-01]
  [  9.21875000e-01]
  [  1.62402344e+00]
  [  2.58398438e+00]
  [  2.49804688e+00]
  [  2.53173828e-01]
  [ -2.97851562e+00]
  [ -5.81640625e+00]
  [ -7.94921875e+00]
  [ -9.54687500e+00]]

 [[  5.27343750e-01]
  [  9.19433594e-01]
  [  1.61425781e+00]
  [  2.56250000e+00]
  [  2.44921875e+00]
  [  1.62475586e-01]
  [ -3.11328125e+00]
  [ -5.99218750e+00]
  [ -8.14843750e+00]
  [ -9.76562500e+00]]

 [[  5.29296875e-01]
  [  9.21386719e-01]
  [  1.62207031e+00]
  [  2.58007812e+00]
  [  2.49414062e+00]
  [  2.52441406e-01]
  [ -2.97460938e+00]
  [ -5.80859375e+00]
  [ -7.93750000e+00]
  [ -9.53125000e+00]]

 [[  5.29785156e-01]
  [  9.16015625e-01]
  [  1.61523438e+00]
  [  2.56835938e+00]
  [  2.46093750e+00]
  [  1.84692383e-01]
  [ -3.08203125e+00]
  [ -5.95312500e+00]
  [ -8.10156250e+00]
  [ -9.71875000e+00]]

 [[  5.21972656e-01]
  [  9.07714844e-01]
  [  1.58691406e+00]
  [  2.50585938e+00]
  [  2.35546875e+00]
  [  2.96325684e-02]
  [ -3.27734375e+00]
  [ -6.17578125e+00]
  [ -8.35156250e+00]
  [ -9.97656250e+00]]

 [[  5.27343750e-01]
  [  9.16503906e-01]
  [  1.60742188e+00]
  [  2.54882812e+00]
  [  2.43750000e+00]
  [  1.67724609e-01]
  [ -3.08398438e+00]
  [ -5.93750000e+00]
  [ -8.07812500e+00]
  [ -9.67968750e+00]]

 [[  5.20019531e-01]
  [  9.01855469e-01]
  [  1.58007812e+00]
  [  2.49804688e+00]
  [  2.33593750e+00]
  [ -6.64520264e-03]
  [ -3.33398438e+00]
  [ -6.25000000e+00]
  [ -8.43750000e+00]
  [ -1.00703125e+01]]

 [[  5.18066406e-01]
  [  8.92578125e-01]
  [  1.56640625e+00]
  [  2.47460938e+00]
  [  2.30273438e+00]
  [ -4.97436523e-02]
  [ -3.38085938e+00]
  [ -6.29296875e+00]
  [ -8.47656250e+00]
  [ -1.01015625e+01]]

 [[  5.29785156e-01]
  [  9.21875000e-01]
  [  1.62500000e+00]
  [  2.58593750e+00]
  [  2.50000000e+00]
  [  2.58544922e-01]
  [ -2.97070312e+00]
  [ -5.80859375e+00]
  [ -7.93750000e+00]
  [ -9.53125000e+00]]

 [[  5.29785156e-01]
  [  9.22363281e-01]
  [  1.62500000e+00]
  [  2.58789062e+00]
  [  2.50390625e+00]
  [  2.60742188e-01]
  [ -2.96875000e+00]
  [ -5.80859375e+00]
  [ -7.93750000e+00]
  [ -9.53125000e+00]]

 [[  5.29785156e-01]
  [  9.21875000e-01]
  [  1.62597656e+00]
  [  2.58789062e+00]
  [  2.50390625e+00]
  [  2.58789062e-01]
  [ -2.97265625e+00]
  [ -5.81250000e+00]
  [ -7.94531250e+00]
  [ -9.54687500e+00]]

 [[  5.29785156e-01]
  [  9.21875000e-01]
  [  1.62695312e+00]
  [  2.58984375e+00]
  [  2.50390625e+00]
  [  2.55371094e-01]
  [ -2.98242188e+00]
  [ -5.82421875e+00]
  [ -7.96093750e+00]
  [ -9.56250000e+00]]

 [[  5.24414062e-01]
  [  9.08203125e-01]
  [  1.59765625e+00]
  [  2.53125000e+00]
  [  2.38867188e+00]
  [  6.17065430e-02]
  [ -3.25390625e+00]
  [ -6.16015625e+00]
  [ -8.33593750e+00]
  [ -9.96093750e+00]]

 [[  5.29785156e-01]
  [  9.22851562e-01]
  [  1.62792969e+00]
  [  2.59179688e+00]
  [  2.50585938e+00]
  [  2.52929688e-01]
  [ -2.99023438e+00]
  [ -5.83984375e+00]
  [ -7.98046875e+00]
  [ -9.58593750e+00]]

 [[  5.29785156e-01]
  [  9.21875000e-01]
  [  1.62597656e+00]
  [  2.58789062e+00]
  [  2.50195312e+00]
  [  2.55126953e-01]
  [ -2.98046875e+00]
  [ -5.82421875e+00]
  [ -7.95703125e+00]
  [ -9.56250000e+00]]]
After layer swapaxes33_output (10, 20, 1) <class 'numpy.float16'> [[[  5.29296875e-01]
  [  5.29785156e-01]
  [  5.27343750e-01]
  [  5.29785156e-01]
  [  5.28320312e-01]
  [  5.28808594e-01]
  [  5.27343750e-01]
  [  5.29296875e-01]
  [  5.29785156e-01]
  [  5.21972656e-01]
  [  5.27343750e-01]
  [  5.20019531e-01]
  [  5.18066406e-01]
  [  5.29785156e-01]
  [  5.29785156e-01]
  [  5.29785156e-01]
  [  5.29785156e-01]
  [  5.24414062e-01]
  [  5.29785156e-01]
  [  5.29785156e-01]]

 [[  9.22363281e-01]
  [  9.21386719e-01]
  [  9.17968750e-01]
  [  9.22851562e-01]
  [  9.18457031e-01]
  [  9.21875000e-01]
  [  9.19433594e-01]
  [  9.21386719e-01]
  [  9.16015625e-01]
  [  9.07714844e-01]
  [  9.16503906e-01]
  [  9.01855469e-01]
  [  8.92578125e-01]
  [  9.21875000e-01]
  [  9.22363281e-01]
  [  9.21875000e-01]
  [  9.21875000e-01]
  [  9.08203125e-01]
  [  9.22851562e-01]
  [  9.21875000e-01]]

 [[  1.62402344e+00]
  [  1.62402344e+00]
  [  1.61035156e+00]
  [  1.62695312e+00]
  [  1.61621094e+00]
  [  1.62402344e+00]
  [  1.61425781e+00]
  [  1.62207031e+00]
  [  1.61523438e+00]
  [  1.58691406e+00]
  [  1.60742188e+00]
  [  1.58007812e+00]
  [  1.56640625e+00]
  [  1.62500000e+00]
  [  1.62500000e+00]
  [  1.62597656e+00]
  [  1.62695312e+00]
  [  1.59765625e+00]
  [  1.62792969e+00]
  [  1.62597656e+00]]

 [[  2.58398438e+00]
  [  2.58593750e+00]
  [  2.55468750e+00]
  [  2.59179688e+00]
  [  2.56640625e+00]
  [  2.58398438e+00]
  [  2.56250000e+00]
  [  2.58007812e+00]
  [  2.56835938e+00]
  [  2.50585938e+00]
  [  2.54882812e+00]
  [  2.49804688e+00]
  [  2.47460938e+00]
  [  2.58593750e+00]
  [  2.58789062e+00]
  [  2.58789062e+00]
  [  2.58984375e+00]
  [  2.53125000e+00]
  [  2.59179688e+00]
  [  2.58789062e+00]]

 [[  2.49804688e+00]
  [  2.50000000e+00]
  [  2.44531250e+00]
  [  2.50781250e+00]
  [  2.45703125e+00]
  [  2.49804688e+00]
  [  2.44921875e+00]
  [  2.49414062e+00]
  [  2.46093750e+00]
  [  2.35546875e+00]
  [  2.43750000e+00]
  [  2.33593750e+00]
  [  2.30273438e+00]
  [  2.50000000e+00]
  [  2.50390625e+00]
  [  2.50390625e+00]
  [  2.50390625e+00]
  [  2.38867188e+00]
  [  2.50585938e+00]
  [  2.50195312e+00]]

 [[  2.54882812e-01]
  [  2.57568359e-01]
  [  1.73706055e-01]
  [  2.63183594e-01]
  [  1.70898438e-01]
  [  2.53173828e-01]
  [  1.62475586e-01]
  [  2.52441406e-01]
  [  1.84692383e-01]
  [  2.96325684e-02]
  [  1.67724609e-01]
  [ -6.64520264e-03]
  [ -4.97436523e-02]
  [  2.58544922e-01]
  [  2.60742188e-01]
  [  2.58789062e-01]
  [  2.55371094e-01]
  [  6.17065430e-02]
  [  2.52929688e-01]
  [  2.55126953e-01]]

 [[ -2.97460938e+00]
  [ -2.97070312e+00]
  [ -3.08203125e+00]
  [ -2.97070312e+00]
  [ -3.10546875e+00]
  [ -2.97851562e+00]
  [ -3.11328125e+00]
  [ -2.97460938e+00]
  [ -3.08203125e+00]
  [ -3.27734375e+00]
  [ -3.08398438e+00]
  [ -3.33398438e+00]
  [ -3.38085938e+00]
  [ -2.97070312e+00]
  [ -2.96875000e+00]
  [ -2.97265625e+00]
  [ -2.98242188e+00]
  [ -3.25390625e+00]
  [ -2.99023438e+00]
  [ -2.98046875e+00]]

 [[ -5.81250000e+00]
  [ -5.80859375e+00]
  [ -5.94140625e+00]
  [ -5.81250000e+00]
  [ -5.98437500e+00]
  [ -5.81640625e+00]
  [ -5.99218750e+00]
  [ -5.80859375e+00]
  [ -5.95312500e+00]
  [ -6.17578125e+00]
  [ -5.93750000e+00]
  [ -6.25000000e+00]
  [ -6.29296875e+00]
  [ -5.80859375e+00]
  [ -5.80859375e+00]
  [ -5.81250000e+00]
  [ -5.82421875e+00]
  [ -6.16015625e+00]
  [ -5.83984375e+00]
  [ -5.82421875e+00]]

 [[ -7.94140625e+00]
  [ -7.93750000e+00]
  [ -8.08593750e+00]
  [ -7.94531250e+00]
  [ -8.14062500e+00]
  [ -7.94921875e+00]
  [ -8.14843750e+00]
  [ -7.93750000e+00]
  [ -8.10156250e+00]
  [ -8.35156250e+00]
  [ -8.07812500e+00]
  [ -8.43750000e+00]
  [ -8.47656250e+00]
  [ -7.93750000e+00]
  [ -7.93750000e+00]
  [ -7.94531250e+00]
  [ -7.96093750e+00]
  [ -8.33593750e+00]
  [ -7.98046875e+00]
  [ -7.95703125e+00]]

 [[ -9.53906250e+00]
  [ -9.53125000e+00]
  [ -9.69531250e+00]
  [ -9.54687500e+00]
  [ -9.75781250e+00]
  [ -9.54687500e+00]
  [ -9.76562500e+00]
  [ -9.53125000e+00]
  [ -9.71875000e+00]
  [ -9.97656250e+00]
  [ -9.67968750e+00]
  [ -1.00703125e+01]
  [ -1.01015625e+01]
  [ -9.53125000e+00]
  [ -9.53125000e+00]
  [ -9.54687500e+00]
  [ -9.56250000e+00]
  [ -9.96093750e+00]
  [ -9.58593750e+00]
  [ -9.56250000e+00]]]
After layer sequencemask12_output (10, 20, 1) <class 'numpy.float16'> [[[  5.29296875e-01]
  [  5.29785156e-01]
  [  5.27343750e-01]
  [  5.29785156e-01]
  [  5.28320312e-01]
  [  5.28808594e-01]
  [  5.27343750e-01]
  [  5.29296875e-01]
  [  5.29785156e-01]
  [  5.21972656e-01]
  [  5.27343750e-01]
  [  5.20019531e-01]
  [  5.18066406e-01]
  [  5.29785156e-01]
  [  5.29785156e-01]
  [  5.29785156e-01]
  [  5.29785156e-01]
  [  5.24414062e-01]
  [  5.29785156e-01]
  [  5.29785156e-01]]

 [[  9.22363281e-01]
  [  9.21386719e-01]
  [  9.17968750e-01]
  [  9.22851562e-01]
  [  9.18457031e-01]
  [  9.21875000e-01]
  [  9.19433594e-01]
  [  9.21386719e-01]
  [  9.16015625e-01]
  [  9.07714844e-01]
  [  9.16503906e-01]
  [  9.01855469e-01]
  [  8.92578125e-01]
  [  9.21875000e-01]
  [  9.22363281e-01]
  [  9.21875000e-01]
  [  9.21875000e-01]
  [  9.08203125e-01]
  [  9.22851562e-01]
  [  9.21875000e-01]]

 [[ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]]
After layer swapaxes34_output (20, 10, 1) <class 'numpy.float16'> [[[  5.29296875e-01]
  [  9.22363281e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  5.29785156e-01]
  [  9.21386719e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  5.27343750e-01]
  [  9.17968750e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  5.29785156e-01]
  [  9.22851562e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  5.28320312e-01]
  [  9.18457031e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  5.28808594e-01]
  [  9.21875000e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  5.27343750e-01]
  [  9.19433594e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  5.29296875e-01]
  [  9.21386719e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  5.29785156e-01]
  [  9.16015625e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  5.21972656e-01]
  [  9.07714844e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  5.27343750e-01]
  [  9.16503906e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  5.20019531e-01]
  [  9.01855469e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  5.18066406e-01]
  [  8.92578125e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  5.29785156e-01]
  [  9.21875000e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  5.29785156e-01]
  [  9.22363281e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  5.29785156e-01]
  [  9.21875000e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  5.29785156e-01]
  [  9.21875000e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  5.24414062e-01]
  [  9.08203125e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  5.29785156e-01]
  [  9.22851562e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  5.29785156e-01]
  [  9.21875000e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]]
After layer attention_softmax_0 (20, 10, 1) <class 'numpy.float16'> [[[ 0.40307617]
  [ 0.59716797]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40332031]
  [ 0.59667969]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40356445]
  [ 0.59619141]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40307617]
  [ 0.59716797]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40380859]
  [ 0.59619141]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40307617]
  [ 0.59716797]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40307617]
  [ 0.59667969]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40307617]
  [ 0.59667969]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40454102]
  [ 0.59521484]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40478516]
  [ 0.59521484]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40380859]
  [ 0.59619141]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40576172]
  [ 0.59423828]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.4074707 ]
  [ 0.59277344]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40307617]
  [ 0.59667969]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40307617]
  [ 0.59667969]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40307617]
  [ 0.59667969]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40307617]
  [ 0.59667969]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.4050293 ]
  [ 0.59472656]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40307617]
  [ 0.59716797]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40307617]
  [ 0.59667969]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]]
After layer batch_dot12_0 (20, 512, 1) <class 'numpy.float16'> [[[ 0.01786804]
  [ 0.03945923]
  [-0.03341675]
  ...,
  [-0.0109787 ]
  [ 0.00999451]
  [-0.02462769]]

 [[ 0.01785278]
  [ 0.03945923]
  [-0.03341675]
  ...,
  [-0.01097107]
  [ 0.00999451]
  [-0.02462769]]

 [[ 0.01783752]
  [ 0.03942871]
  [-0.03338623]
  ...,
  [-0.01096344]
  [ 0.00998688]
  [-0.02462769]]

 ...,
 [[ 0.01780701]
  [ 0.03939819]
  [-0.0333252 ]
  ...,
  [-0.01095581]
  [ 0.00998688]
  [-0.0246582 ]]

 [[ 0.01786804]
  [ 0.03945923]
  [-0.03341675]
  ...,
  [-0.0109787 ]
  [ 0.00999451]
  [-0.02462769]]

 [[ 0.01785278]
  [ 0.03942871]
  [-0.03341675]
  ...,
  [-0.01097107]
  [ 0.00998688]
  [-0.02461243]]]
After layer reshape24_0 (20, 512) <class 'numpy.float16'> [[ 0.01786804  0.03945923 -0.03341675 ..., -0.0109787   0.00999451
  -0.02462769]
 [ 0.01785278  0.03945923 -0.03341675 ..., -0.01097107  0.00999451
  -0.02462769]
 [ 0.01783752  0.03942871 -0.03338623 ..., -0.01096344  0.00998688
  -0.02462769]
 ...,
 [ 0.01780701  0.03939819 -0.0333252  ..., -0.01095581  0.00998688
  -0.0246582 ]
 [ 0.01786804  0.03945923 -0.03341675 ..., -0.0109787   0.00999451
  -0.02462769]
 [ 0.01785278  0.03942871 -0.03341675 ..., -0.01097107  0.00998688
  -0.02461243]]
After layer decoder_rnn_hidden_concat_t0_output (20, 1024) <class 'numpy.float16'> [[-0.00121307 -0.91992188  0.19714355 ..., -0.0109787   0.00999451
  -0.02462769]
 [-0.00121307 -0.91992188  0.19714355 ..., -0.01097107  0.00999451
  -0.02462769]
 [-0.00121403 -0.92089844  0.19543457 ..., -0.01096344  0.00998688
  -0.02462769]
 ...,
 [-0.00120354 -0.92382812  0.19104004 ..., -0.01095581  0.00998688
  -0.0246582 ]
 [-0.00121117 -0.92041016  0.19592285 ..., -0.0109787   0.00999451
  -0.02462769]
 [-0.00121307 -0.92041016  0.1965332  ..., -0.01097107  0.00998688
  -0.02461243]]
After layer decoder_rnn_hidden_fc_t0_output (20, 512) <class 'numpy.float16'> [[-1.9609375   0.20605469 -0.81005859 ...,  1.97167969  2.10742188 -1.59375   ]
 [-1.96191406  0.20507812 -0.81005859 ...,  1.97167969  2.109375   -1.59375   ]
 [-1.95507812  0.20947266 -0.81542969 ...,  1.96484375  2.10546875
  -1.59765625]
 ...,
 [-1.95507812  0.2244873  -0.83203125 ...,  1.96289062  2.1015625
  -1.60058594]
 [-1.96582031  0.21130371 -0.81738281 ...,  1.97363281  2.10546875
  -1.59472656]
 [-1.96191406  0.2076416  -0.81347656 ...,  1.97167969  2.10742188 -1.59375   ]]
After layer decoder_rnn_next_hidden_t0_output (20, 512) <class 'numpy.float16'> [[-0.9609375   0.20324707 -0.66943359 ...,  0.96191406  0.97070312
  -0.92089844]
 [-0.96142578  0.20227051 -0.66943359 ...,  0.96191406  0.97119141
  -0.92089844]
 [-0.9609375   0.2064209  -0.67236328 ...,  0.96142578  0.97070312
  -0.92138672]
 ...,
 [-0.9609375   0.2208252  -0.68164062 ...,  0.96142578  0.97070312
  -0.921875  ]
 [-0.96142578  0.20825195 -0.67382812 ...,  0.96191406  0.97070312
  -0.92089844]
 [-0.96142578  0.20471191 -0.67138672 ...,  0.96191406  0.97070312
  -0.92089844]]
After layer logits_output (20, 16743) <class 'numpy.float16'> [[-2.00390625 -2.82421875 -2.40625    ..., -2.09375    -3.50195312
  -2.58007812]
 [-2.00585938 -2.82421875 -2.40625    ..., -2.09375    -3.5        -2.58007812]
 [-2.00195312 -2.82421875 -2.40625    ..., -2.09765625 -3.5        -2.58007812]
 ...,
 [-2.         -2.81835938 -2.3984375  ..., -2.09570312 -3.48828125
  -2.57617188]
 [-2.00390625 -2.82226562 -2.40429688 ..., -2.09375    -3.49609375
  -2.58203125]
 [-2.00390625 -2.82226562 -2.40625    ..., -2.09375    -3.49804688
  -2.58007812]]
After layer softmax_0 (20, 16743) <class 'numpy.float16'> [[  8.34465027e-07   3.57627869e-07   5.36441803e-07 ...,   7.74860382e-07
    1.78813934e-07   4.76837158e-07]
 [  8.34465027e-07   3.57627869e-07   5.36441803e-07 ...,   7.74860382e-07
    1.78813934e-07   4.76837158e-07]
 [  8.34465027e-07   3.57627869e-07   5.96046448e-07 ...,   7.74860382e-07
    1.78813934e-07   4.76837158e-07]
 ...,
 [  8.94069672e-07   3.57627869e-07   5.96046448e-07 ...,   7.74860382e-07
    1.78813934e-07   4.76837158e-07]
 [  8.34465027e-07   3.57627869e-07   5.96046448e-07 ...,   7.74860382e-07
    1.78813934e-07   4.76837158e-07]
 [  8.34465027e-07   3.57627869e-07   5.96046448e-07 ...,   7.74860382e-07
    1.78813934e-07   4.76837158e-07]]
After layer reshape25_0 (20, 10) <class 'numpy.float16'> [[ 0.40307617  0.59716797  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40332031  0.59667969  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40356445  0.59619141  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40307617  0.59716797  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40380859  0.59619141  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40307617  0.59716797  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40307617  0.59667969  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40307617  0.59667969  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40454102  0.59521484  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40478516  0.59521484  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40380859  0.59619141  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40576172  0.59423828  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.4074707   0.59277344  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40307617  0.59667969  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40307617  0.59667969  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40307617  0.59667969  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40307617  0.59667969  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.4050293   0.59472656  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40307617  0.59716797  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40307617  0.59667969  0.          0.          0.          0.          0.
   0.          0.          0.        ]]
After layer target_embed_embed_0 (20, 256) <class 'numpy.float16'> [[-0.05505371 -0.0300293  -0.03598022 ...,  0.08459473 -0.05288696
  -0.01667786]
 [-0.05505371 -0.0300293  -0.03598022 ...,  0.08459473 -0.05288696
  -0.01667786]
 [-0.05505371 -0.0300293  -0.03598022 ...,  0.08459473 -0.05288696
  -0.01667786]
 ...,
 [-0.05505371 -0.0300293  -0.03598022 ...,  0.08459473 -0.05288696
  -0.01667786]
 [-0.05505371 -0.0300293  -0.03598022 ...,  0.08459473 -0.05288696
  -0.01667786]
 [-0.05505371 -0.0300293  -0.03598022 ...,  0.08459473 -0.05288696
  -0.01667786]]
After layer decoder_rnn_concat_target_context_t0_output (20, 768) <class 'numpy.float16'> [[-0.05505371 -0.0300293  -0.03598022 ...,  0.96191406  0.97070312
  -0.92089844]
 [-0.05505371 -0.0300293  -0.03598022 ...,  0.96191406  0.97119141
  -0.92089844]
 [-0.05505371 -0.0300293  -0.03598022 ...,  0.96142578  0.97070312
  -0.92138672]
 ...,
 [-0.05505371 -0.0300293  -0.03598022 ...,  0.96142578  0.97070312
  -0.921875  ]
 [-0.05505371 -0.0300293  -0.03598022 ...,  0.96191406  0.97070312
  -0.92089844]
 [-0.05505371 -0.0300293  -0.03598022 ...,  0.96191406  0.97070312
  -0.92089844]]
After layer decoder_rnn_l0_t0_i2h_output (20, 2048) <class 'numpy.float16'> [[-3.19140625  1.609375    2.43554688 ..., -0.07781982  3.86523438
   0.59863281]
 [-3.19140625  1.609375    2.43554688 ..., -0.07788086  3.86523438
   0.59912109]
 [-3.18945312  1.61035156  2.43554688 ..., -0.07696533  3.8671875
   0.60253906]
 ...,
 [-3.17773438  1.60351562  2.43359375 ..., -0.07409668  3.85546875
   0.60693359]
 [-3.18945312  1.60742188  2.4375     ..., -0.0769043   3.86132812
   0.59863281]
 [-3.18945312  1.60839844  2.43554688 ..., -0.07751465  3.86328125
   0.59912109]]
After layer decoder_rnn_l0_t0_h2h_output (20, 2048) <class 'numpy.float16'> [[-0.32177734  0.47241211  1.84375    ...,  0.70556641  1.296875
   0.17565918]
 [-0.32226562  0.47265625  1.84375    ...,  0.70458984  1.29589844
   0.17504883]
 [-0.32568359  0.47998047  1.83886719 ...,  0.70263672  1.3046875
   0.17077637]
 ...,
 [-0.34130859  0.49682617  1.83886719 ...,  0.6953125   1.30664062
   0.15563965]
 [-0.32470703  0.48046875  1.84277344 ...,  0.70214844  1.30078125
   0.16845703]
 [-0.32397461  0.4765625   1.84277344 ...,  0.70263672  1.29882812
   0.17150879]]
After layer _plus1057_0 (20, 2048) <class 'numpy.float16'> [[-3.51367188  2.08203125  4.28125    ...,  0.62792969  5.1640625
   0.77441406]
 [-3.51367188  2.08203125  4.28125    ...,  0.62695312  5.16015625
   0.77441406]
 [-3.515625    2.08984375  4.2734375  ...,  0.62548828  5.171875    0.7734375 ]
 ...,
 [-3.51953125  2.09960938  4.2734375  ...,  0.62109375  5.1640625
   0.76269531]
 [-3.51367188  2.08789062  4.28125    ...,  0.625       5.1640625
   0.76708984]
 [-3.51367188  2.0859375   4.27734375 ...,  0.625       5.1640625
   0.77050781]]
After layer decoder_rnn_l0_t0_slice_output0 (20, 512) <class 'numpy.float16'> [[-3.51367188  2.08203125  4.28125    ...,  1.7421875   4.60546875
   2.78320312]
 [-3.51367188  2.08203125  4.28125    ...,  1.7421875   4.60546875  2.78125   ]
 [-3.515625    2.08984375  4.2734375  ...,  1.74804688  4.59765625  2.78125   ]
 ...,
 [-3.51953125  2.09960938  4.2734375  ...,  1.74414062  4.58203125
   2.77734375]
 [-3.51367188  2.08789062  4.28125    ...,  1.73925781  4.6015625
   2.77734375]
 [-3.51367188  2.0859375   4.27734375 ...,  1.74023438  4.60546875
   2.77929688]]
After layer decoder_rnn_l0_t0_slice_output1 (20, 512) <class 'numpy.float16'> [[-1.859375    2.31640625  2.42773438 ...,  3.1640625  -0.703125
   1.97851562]
 [-1.859375    2.31640625  2.42773438 ...,  3.1640625  -0.70117188
   1.97851562]
 [-1.86621094  2.31054688  2.43359375 ...,  3.16015625 -0.70996094
   1.97460938]
 ...,
 [-1.88183594  2.3046875   2.4375     ...,  3.14453125 -0.70605469
   1.96289062]
 [-1.86328125  2.31835938  2.4296875  ...,  3.15820312 -0.69921875
   1.9765625 ]
 [-1.86132812  2.31640625  2.42773438 ...,  3.16015625 -0.70068359
   1.9765625 ]]
After layer decoder_rnn_l0_t0_slice_output2 (20, 512) <class 'numpy.float16'> [[-2.81640625 -3.08203125  2.84765625 ...,  4.265625   -0.08032227
   2.1640625 ]
 [-2.81445312 -3.08203125  2.84765625 ...,  4.265625   -0.08154297
   2.16015625]
 [-2.8203125  -3.0859375   2.859375   ...,  4.2578125  -0.08349609
   2.16210938]
 ...,
 [-2.80664062 -3.08789062  2.88085938 ...,  4.2265625  -0.1081543
   2.15429688]
 [-2.8125     -3.08789062  2.8515625  ...,  4.25390625 -0.08984375
   2.16015625]
 [-2.81445312 -3.08203125  2.84765625 ...,  4.2578125  -0.08544922
   2.16015625]]
After layer decoder_rnn_l0_t0_slice_output3 (20, 512) <class 'numpy.float16'> [[-3.2734375   2.4375     -1.40332031 ...,  0.62792969  5.1640625
   0.77441406]
 [-3.2734375   2.4375     -1.40234375 ...,  0.62695312  5.16015625
   0.77441406]
 [-3.26953125  2.44921875 -1.41113281 ...,  0.62548828  5.171875    0.7734375 ]
 ...,
 [-3.265625    2.47265625 -1.4296875  ...,  0.62109375  5.1640625
   0.76269531]
 [-3.27539062  2.4375     -1.40917969 ...,  0.625       5.1640625
   0.76708984]
 [-3.27539062  2.43945312 -1.40625    ...,  0.625       5.1640625
   0.77050781]]
After layer decoder_rnn_l0_t0_o_output (20, 512) <class 'numpy.float16'> [[ 0.03649902  0.91943359  0.19726562 ...,  0.65185547  0.99414062
   0.68457031]
 [ 0.03649902  0.91943359  0.1973877  ...,  0.65185547  0.99414062
   0.68457031]
 [ 0.03662109  0.92041016  0.19604492 ...,  0.65136719  0.99414062
   0.68408203]
 ...,
 [ 0.03677368  0.92236328  0.19311523 ...,  0.65039062  0.99414062
   0.68212891]
 [ 0.03643799  0.91943359  0.19641113 ...,  0.65136719  0.99414062
   0.68310547]
 [ 0.03643799  0.91992188  0.19677734 ...,  0.65136719  0.99414062
   0.68359375]]
After layer decoder_rnn_l0_t0_f_output (20, 512) <class 'numpy.float16'> [[ 0.13476562  0.91015625  0.91894531 ...,  0.95947266  0.33105469
   0.87841797]
 [ 0.13476562  0.91015625  0.91894531 ...,  0.95947266  0.33154297
   0.87841797]
 [ 0.1340332   0.90966797  0.91943359 ...,  0.95947266  0.32958984
   0.87792969]
 ...,
 [ 0.13220215  0.90917969  0.91943359 ...,  0.95849609  0.33056641
   0.87695312]
 [ 0.13427734  0.91015625  0.91894531 ...,  0.95947266  0.33203125
   0.87841797]
 [ 0.13452148  0.91015625  0.91894531 ...,  0.95947266  0.33154297
   0.87841797]]
After layer _mul2114_0 (20, 512) <class 'numpy.float16'> [[ -4.47845459e-03  -5.50390625e+00   6.35156250e+00 ...,   7.14062500e+00
   -3.74450684e-02   4.77734375e+00]
 [ -4.47845459e-03  -5.50390625e+00   6.32031250e+00 ...,   7.06250000e+00
   -3.88183594e-02   4.72656250e+00]
 [ -4.44030762e-03  -5.47265625e+00   6.35156250e+00 ...,   6.94140625e+00
   -3.91235352e-02   4.65625000e+00]
 ...,
 [ -4.33349609e-03  -5.21875000e+00   6.04687500e+00 ...,   6.51562500e+00
   -6.68945312e-02   4.08984375e+00]
 [ -4.46319580e-03  -5.50390625e+00   6.29296875e+00 ...,   7.00781250e+00
   -4.57153320e-02   4.66796875e+00]
 [ -4.47082520e-03  -5.50781250e+00   6.31250000e+00 ...,   7.00781250e+00
   -4.22973633e-02   4.69531250e+00]]
After layer decoder_rnn_l0_t0_i_output (20, 512) <class 'numpy.float16'> [[ 0.02893066  0.88916016  0.98632812 ...,  0.85107422  0.99023438
   0.94189453]
 [ 0.02893066  0.88916016  0.98632812 ...,  0.85107422  0.99023438
   0.94189453]
 [ 0.02886963  0.89013672  0.98632812 ...,  0.8515625   0.99023438
   0.94189453]
 ...,
 [ 0.02876282  0.890625    0.98632812 ...,  0.85107422  0.98974609
   0.94140625]
 [ 0.02893066  0.88964844  0.98632812 ...,  0.85058594  0.99023438
   0.94140625]
 [ 0.02893066  0.88964844  0.98632812 ...,  0.85058594  0.99023438
   0.94140625]]
After layer decoder_rnn_l0_t0_c_output (20, 512) <class 'numpy.float16'> [[-0.99267578 -0.99560547  0.99316406 ...,  0.99951172 -0.08013916
   0.97412109]
 [-0.99267578 -0.99560547  0.99316406 ...,  0.99951172 -0.08135986
   0.97363281]
 [-0.99316406 -0.99560547  0.99365234 ...,  0.99951172 -0.08331299
   0.97363281]
 ...,
 [-0.99267578 -0.99609375  0.99365234 ...,  0.99951172 -0.10772705
   0.97363281]
 [-0.99267578 -0.99609375  0.99316406 ...,  0.99951172 -0.08959961
   0.97363281]
 [-0.99267578 -0.99560547  0.99316406 ...,  0.99951172 -0.08526611
   0.97363281]]
After layer _mul2115_0 (20, 512) <class 'numpy.float16'> [[-0.02871704 -0.88525391  0.97949219 ...,  0.85058594 -0.0793457
   0.91748047]
 [-0.02871704 -0.88525391  0.97949219 ...,  0.85058594 -0.08056641
   0.91699219]
 [-0.02867126 -0.88623047  0.97998047 ...,  0.85107422 -0.08251953
   0.91699219]
 ...,
 [-0.02854919 -0.88720703  0.97998047 ...,  0.85058594 -0.10662842
   0.91650391]
 [-0.02871704 -0.88623047  0.97949219 ...,  0.85009766 -0.08874512
   0.91650391]
 [-0.02871704 -0.88574219  0.97949219 ...,  0.85009766 -0.08441162
   0.91650391]]
After layer decoder_rnn_l0_t0_state_0 (20, 512) <class 'numpy.float16'> [[-0.03320312 -6.390625    7.33203125 ...,  7.9921875  -0.11682129
   5.6953125 ]
 [-0.03320312 -6.390625    7.30078125 ...,  7.9140625  -0.11938477
   5.64453125]
 [-0.03311157 -6.359375    7.33203125 ...,  7.79296875 -0.12164307
   5.57421875]
 ...,
 [-0.03289795 -6.10546875  7.02734375 ...,  7.3671875  -0.17358398
   5.0078125 ]
 [-0.03317261 -6.390625    7.2734375  ...,  7.859375   -0.13452148
   5.5859375 ]
 [-0.03320312 -6.39453125  7.29296875 ...,  7.859375   -0.12670898
   5.61328125]]
After layer activation1057_output (20, 512) <class 'numpy.float16'> [[-0.03320312 -1.          1.         ...,  1.         -0.11627197  1.        ]
 [-0.03320312 -1.          1.         ...,  1.         -0.11883545  1.        ]
 [-0.03311157 -1.          1.         ...,  1.         -0.12103271  1.        ]
 ...,
 [-0.03289795 -1.          1.         ...,  1.         -0.171875    1.        ]
 [-0.03317261 -1.          1.         ...,  1.         -0.13366699  1.        ]
 [-0.03320312 -1.          1.         ...,  1.         -0.12597656  1.        ]]
After layer decoder_rnn_l0_t0_out_0 (20, 512) <class 'numpy.float16'> [[-0.00121212 -0.91943359  0.19726562 ...,  0.65185547 -0.11560059
   0.68457031]
 [-0.00121212 -0.91943359  0.1973877  ...,  0.65185547 -0.11816406
   0.68457031]
 [-0.00121212 -0.92041016  0.19604492 ...,  0.65136719 -0.12030029
   0.68408203]
 ...,
 [-0.00121021 -0.92236328  0.19311523 ...,  0.65039062 -0.17089844
   0.68212891]
 [-0.00120831 -0.91943359  0.19641113 ...,  0.65136719 -0.13293457
   0.68310547]
 [-0.00121021 -0.91992188  0.19677734 ...,  0.65136719 -0.12524414
   0.68359375]]
After layer expand_dims1066_0 (20, 512, 1) <class 'numpy.float16'> [[[-0.00121212]
  [-0.91943359]
  [ 0.19726562]
  ...,
  [ 0.65185547]
  [-0.11560059]
  [ 0.68457031]]

 [[-0.00121212]
  [-0.91943359]
  [ 0.1973877 ]
  ...,
  [ 0.65185547]
  [-0.11816406]
  [ 0.68457031]]

 [[-0.00121212]
  [-0.92041016]
  [ 0.19604492]
  ...,
  [ 0.65136719]
  [-0.12030029]
  [ 0.68408203]]

 ...,
 [[-0.00121021]
  [-0.92236328]
  [ 0.19311523]
  ...,
  [ 0.65039062]
  [-0.17089844]
  [ 0.68212891]]

 [[-0.00120831]
  [-0.91943359]
  [ 0.19641113]
  ...,
  [ 0.65136719]
  [-0.13293457]
  [ 0.68310547]]

 [[-0.00121021]
  [-0.91992188]
  [ 0.19677734]
  ...,
  [ 0.65136719]
  [-0.12524414]
  [ 0.68359375]]]
After layer att_batch_dot_0 (20, 10, 1) <class 'numpy.float16'> [[[  0.52978516]
  [  0.92236328]
  [  1.62792969]
  [  2.58984375]
  [  2.5078125 ]
  [  0.26293945]
  [ -2.96875   ]
  [ -5.80859375]
  [ -7.94140625]
  [ -9.5390625 ]]

 [[  0.53027344]
  [  0.921875  ]
  [  1.62792969]
  [  2.59179688]
  [  2.50976562]
  [  0.26635742]
  [ -2.96484375]
  [ -5.8046875 ]
  [ -7.9375    ]
  [ -9.5390625 ]]

 [[  0.52832031]
  [  0.91943359]
  [  1.6171875 ]
  [  2.56835938]
  [  2.46679688]
  [  0.19921875]
  [ -3.0546875 ]
  [ -5.9140625 ]
  [ -8.0625    ]
  [ -9.671875  ]]

 [[  0.53027344]
  [  0.92285156]
  [  1.62988281]
  [  2.59570312]
  [  2.51367188]
  [  0.26782227]
  [ -2.96875   ]
  [ -5.8125    ]
  [ -7.94921875]
  [ -9.546875  ]]

 [[  0.52880859]
  [  0.91992188]
  [  1.62011719]
  [  2.57421875]
  [  2.46875   ]
  [  0.18664551]
  [ -3.0859375 ]
  [ -5.9609375 ]
  [ -8.125     ]
  [ -9.7421875 ]]

 [[  0.52783203]
  [  0.91992188]
  [  1.61816406]
  [  2.5703125 ]
  [  2.4609375 ]
  [  0.17919922]
  [ -3.09375   ]
  [ -5.96875   ]
  [ -8.1328125 ]
  [ -9.75      ]]

 [[  0.52978516]
  [  0.92236328]
  [  1.62792969]
  [  2.59179688]
  [  2.5078125 ]
  [  0.26171875]
  [ -2.97265625]
  [ -5.8125    ]
  [ -7.94921875]
  [ -9.546875  ]]

 [[  0.52978516]
  [  0.921875  ]
  [  1.62695312]
  [  2.58984375]
  [  2.50585938]
  [  0.26269531]
  [ -2.96679688]
  [ -5.8046875 ]
  [ -7.9375    ]
  [ -9.53125   ]]

 [[  0.53125   ]
  [  0.91943359]
  [  1.62402344]
  [  2.58398438]
  [  2.48632812]
  [  0.21838379]
  [ -3.04101562]
  [ -5.90625   ]
  [ -8.0546875 ]
  [ -9.6640625 ]]

 [[  0.52490234]
  [  0.91308594]
  [  1.59960938]
  [  2.53320312]
  [  2.39648438]
  [  0.08666992]
  [ -3.20898438]
  [ -6.1015625 ]
  [ -8.2734375 ]
  [ -9.8984375 ]]

 [[  0.52880859]
  [  0.91845703]
  [  1.61523438]
  [  2.56640625]
  [  2.46289062]
  [  0.19958496]
  [ -3.04882812]
  [ -5.90234375]
  [ -8.046875  ]
  [ -9.6484375 ]]

 [[  0.52490234]
  [  0.91064453]
  [  1.59960938]
  [  2.53320312]
  [  2.39648438]
  [  0.07989502]
  [ -3.22460938]
  [ -6.125     ]
  [ -8.296875  ]
  [ -9.9296875 ]]

 [[  0.53027344]
  [  0.92236328]
  [  1.62792969]
  [  2.59179688]
  [  2.50976562]
  [  0.26635742]
  [ -2.96484375]
  [ -5.8046875 ]
  [ -7.9375    ]
  [ -9.5390625 ]]

 [[  0.52294922]
  [  0.90429688]
  [  1.59082031]
  [  2.51953125]
  [  2.37304688]
  [  0.04174805]
  [ -3.27539062]
  [ -6.1875    ]
  [ -8.3671875 ]
  [-10.        ]]

 [[  0.53027344]
  [  0.92285156]
  [  1.62890625]
  [  2.59375   ]
  [  2.51171875]
  [  0.26831055]
  [ -2.96289062]
  [ -5.8046875 ]
  [ -7.9375    ]
  [ -9.5390625 ]]

 [[  0.53027344]
  [  0.92285156]
  [  1.62890625]
  [  2.59375   ]
  [  2.51171875]
  [  0.26635742]
  [ -2.96679688]
  [ -5.80859375]
  [ -7.9453125 ]
  [ -9.546875  ]]

 [[  0.53027344]
  [  0.92236328]
  [  1.62890625]
  [  2.59375   ]
  [  2.50976562]
  [  0.26049805]
  [ -2.97851562]
  [ -5.82421875]
  [ -7.9609375 ]
  [ -9.5625    ]]

 [[  0.52685547]
  [  0.91357422]
  [  1.60839844]
  [  2.55078125]
  [  2.42382812]
  [  0.11486816]
  [ -3.18359375]
  [ -6.078125  ]
  [ -8.25      ]
  [ -9.875     ]]

 [[  0.52978516]
  [  0.92285156]
  [  1.62988281]
  [  2.59570312]
  [  2.50976562]
  [  0.2565918 ]
  [ -2.98828125]
  [ -5.83984375]
  [ -7.98046875]
  [ -9.5859375 ]]

 [[  0.53027344]
  [  0.92236328]
  [  1.62890625]
  [  2.59375   ]
  [  2.50976562]
  [  0.26123047]
  [ -2.9765625 ]
  [ -5.8203125 ]
  [ -7.95703125]
  [ -9.5625    ]]]
After layer swapaxes35_output (10, 20, 1) <class 'numpy.float16'> [[[  0.52978516]
  [  0.53027344]
  [  0.52832031]
  [  0.53027344]
  [  0.52880859]
  [  0.52783203]
  [  0.52978516]
  [  0.52978516]
  [  0.53125   ]
  [  0.52490234]
  [  0.52880859]
  [  0.52490234]
  [  0.53027344]
  [  0.52294922]
  [  0.53027344]
  [  0.53027344]
  [  0.53027344]
  [  0.52685547]
  [  0.52978516]
  [  0.53027344]]

 [[  0.92236328]
  [  0.921875  ]
  [  0.91943359]
  [  0.92285156]
  [  0.91992188]
  [  0.91992188]
  [  0.92236328]
  [  0.921875  ]
  [  0.91943359]
  [  0.91308594]
  [  0.91845703]
  [  0.91064453]
  [  0.92236328]
  [  0.90429688]
  [  0.92285156]
  [  0.92285156]
  [  0.92236328]
  [  0.91357422]
  [  0.92285156]
  [  0.92236328]]

 [[  1.62792969]
  [  1.62792969]
  [  1.6171875 ]
  [  1.62988281]
  [  1.62011719]
  [  1.61816406]
  [  1.62792969]
  [  1.62695312]
  [  1.62402344]
  [  1.59960938]
  [  1.61523438]
  [  1.59960938]
  [  1.62792969]
  [  1.59082031]
  [  1.62890625]
  [  1.62890625]
  [  1.62890625]
  [  1.60839844]
  [  1.62988281]
  [  1.62890625]]

 [[  2.58984375]
  [  2.59179688]
  [  2.56835938]
  [  2.59570312]
  [  2.57421875]
  [  2.5703125 ]
  [  2.59179688]
  [  2.58984375]
  [  2.58398438]
  [  2.53320312]
  [  2.56640625]
  [  2.53320312]
  [  2.59179688]
  [  2.51953125]
  [  2.59375   ]
  [  2.59375   ]
  [  2.59375   ]
  [  2.55078125]
  [  2.59570312]
  [  2.59375   ]]

 [[  2.5078125 ]
  [  2.50976562]
  [  2.46679688]
  [  2.51367188]
  [  2.46875   ]
  [  2.4609375 ]
  [  2.5078125 ]
  [  2.50585938]
  [  2.48632812]
  [  2.39648438]
  [  2.46289062]
  [  2.39648438]
  [  2.50976562]
  [  2.37304688]
  [  2.51171875]
  [  2.51171875]
  [  2.50976562]
  [  2.42382812]
  [  2.50976562]
  [  2.50976562]]

 [[  0.26293945]
  [  0.26635742]
  [  0.19921875]
  [  0.26782227]
  [  0.18664551]
  [  0.17919922]
  [  0.26171875]
  [  0.26269531]
  [  0.21838379]
  [  0.08666992]
  [  0.19958496]
  [  0.07989502]
  [  0.26635742]
  [  0.04174805]
  [  0.26831055]
  [  0.26635742]
  [  0.26049805]
  [  0.11486816]
  [  0.2565918 ]
  [  0.26123047]]

 [[ -2.96875   ]
  [ -2.96484375]
  [ -3.0546875 ]
  [ -2.96875   ]
  [ -3.0859375 ]
  [ -3.09375   ]
  [ -2.97265625]
  [ -2.96679688]
  [ -3.04101562]
  [ -3.20898438]
  [ -3.04882812]
  [ -3.22460938]
  [ -2.96484375]
  [ -3.27539062]
  [ -2.96289062]
  [ -2.96679688]
  [ -2.97851562]
  [ -3.18359375]
  [ -2.98828125]
  [ -2.9765625 ]]

 [[ -5.80859375]
  [ -5.8046875 ]
  [ -5.9140625 ]
  [ -5.8125    ]
  [ -5.9609375 ]
  [ -5.96875   ]
  [ -5.8125    ]
  [ -5.8046875 ]
  [ -5.90625   ]
  [ -6.1015625 ]
  [ -5.90234375]
  [ -6.125     ]
  [ -5.8046875 ]
  [ -6.1875    ]
  [ -5.8046875 ]
  [ -5.80859375]
  [ -5.82421875]
  [ -6.078125  ]
  [ -5.83984375]
  [ -5.8203125 ]]

 [[ -7.94140625]
  [ -7.9375    ]
  [ -8.0625    ]
  [ -7.94921875]
  [ -8.125     ]
  [ -8.1328125 ]
  [ -7.94921875]
  [ -7.9375    ]
  [ -8.0546875 ]
  [ -8.2734375 ]
  [ -8.046875  ]
  [ -8.296875  ]
  [ -7.9375    ]
  [ -8.3671875 ]
  [ -7.9375    ]
  [ -7.9453125 ]
  [ -7.9609375 ]
  [ -8.25      ]
  [ -7.98046875]
  [ -7.95703125]]

 [[ -9.5390625 ]
  [ -9.5390625 ]
  [ -9.671875  ]
  [ -9.546875  ]
  [ -9.7421875 ]
  [ -9.75      ]
  [ -9.546875  ]
  [ -9.53125   ]
  [ -9.6640625 ]
  [ -9.8984375 ]
  [ -9.6484375 ]
  [ -9.9296875 ]
  [ -9.5390625 ]
  [-10.        ]
  [ -9.5390625 ]
  [ -9.546875  ]
  [ -9.5625    ]
  [ -9.875     ]
  [ -9.5859375 ]
  [ -9.5625    ]]]
After layer sequencemask13_output (10, 20, 1) <class 'numpy.float16'> [[[  5.29785156e-01]
  [  5.30273438e-01]
  [  5.28320312e-01]
  [  5.30273438e-01]
  [  5.28808594e-01]
  [  5.27832031e-01]
  [  5.29785156e-01]
  [  5.29785156e-01]
  [  5.31250000e-01]
  [  5.24902344e-01]
  [  5.28808594e-01]
  [  5.24902344e-01]
  [  5.30273438e-01]
  [  5.22949219e-01]
  [  5.30273438e-01]
  [  5.30273438e-01]
  [  5.30273438e-01]
  [  5.26855469e-01]
  [  5.29785156e-01]
  [  5.30273438e-01]]

 [[  9.22363281e-01]
  [  9.21875000e-01]
  [  9.19433594e-01]
  [  9.22851562e-01]
  [  9.19921875e-01]
  [  9.19921875e-01]
  [  9.22363281e-01]
  [  9.21875000e-01]
  [  9.19433594e-01]
  [  9.13085938e-01]
  [  9.18457031e-01]
  [  9.10644531e-01]
  [  9.22363281e-01]
  [  9.04296875e-01]
  [  9.22851562e-01]
  [  9.22851562e-01]
  [  9.22363281e-01]
  [  9.13574219e-01]
  [  9.22851562e-01]
  [  9.22363281e-01]]

 [[ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]]
After layer swapaxes36_output (20, 10, 1) <class 'numpy.float16'> [[[  5.29785156e-01]
  [  9.22363281e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  5.30273438e-01]
  [  9.21875000e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  5.28320312e-01]
  [  9.19433594e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  5.30273438e-01]
  [  9.22851562e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  5.28808594e-01]
  [  9.19921875e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  5.27832031e-01]
  [  9.19921875e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  5.29785156e-01]
  [  9.22363281e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  5.29785156e-01]
  [  9.21875000e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  5.31250000e-01]
  [  9.19433594e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  5.24902344e-01]
  [  9.13085938e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  5.28808594e-01]
  [  9.18457031e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  5.24902344e-01]
  [  9.10644531e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  5.30273438e-01]
  [  9.22363281e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  5.22949219e-01]
  [  9.04296875e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  5.30273438e-01]
  [  9.22851562e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  5.30273438e-01]
  [  9.22851562e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  5.30273438e-01]
  [  9.22363281e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  5.26855469e-01]
  [  9.13574219e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  5.29785156e-01]
  [  9.22851562e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  5.30273438e-01]
  [  9.22363281e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]]
After layer attention_softmax_0 (20, 10, 1) <class 'numpy.float16'> [[[ 0.40307617]
  [ 0.59667969]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40332031]
  [ 0.59667969]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40356445]
  [ 0.59667969]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40307617]
  [ 0.59667969]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40356445]
  [ 0.59667969]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40307617]
  [ 0.59667969]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40307617]
  [ 0.59667969]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40307617]
  [ 0.59667969]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40429688]
  [ 0.59619141]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40429688]
  [ 0.59619141]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40380859]
  [ 0.59619141]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40478516]
  [ 0.59521484]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40307617]
  [ 0.59667969]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40576172]
  [ 0.59375   ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40307617]
  [ 0.59667969]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40307617]
  [ 0.59667969]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40307617]
  [ 0.59667969]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40429688]
  [ 0.59521484]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40307617]
  [ 0.59716797]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40307617]
  [ 0.59667969]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]]
After layer batch_dot13_0 (20, 512, 1) <class 'numpy.float16'> [[[ 0.01785278]
  [ 0.03942871]
  [-0.03341675]
  ...,
  [-0.01097107]
  [ 0.00998688]
  [-0.02461243]]

 [[ 0.01785278]
  [ 0.03945923]
  [-0.03341675]
  ...,
  [-0.01097107]
  [ 0.00999451]
  [-0.02462769]]

 [[ 0.01785278]
  [ 0.03945923]
  [-0.03341675]
  ...,
  [-0.01097107]
  [ 0.00999451]
  [-0.02462769]]

 ...,
 [[ 0.01780701]
  [ 0.03939819]
  [-0.0333252 ]
  ...,
  [-0.01095581]
  [ 0.00998688]
  [-0.02462769]]

 [[ 0.01786804]
  [ 0.03945923]
  [-0.03341675]
  ...,
  [-0.0109787 ]
  [ 0.00999451]
  [-0.02462769]]

 [[ 0.01785278]
  [ 0.03942871]
  [-0.03341675]
  ...,
  [-0.01097107]
  [ 0.00998688]
  [-0.02461243]]]
After layer reshape26_0 (20, 512) <class 'numpy.float16'> [[ 0.01785278  0.03942871 -0.03341675 ..., -0.01097107  0.00998688
  -0.02461243]
 [ 0.01785278  0.03945923 -0.03341675 ..., -0.01097107  0.00999451
  -0.02462769]
 [ 0.01785278  0.03945923 -0.03341675 ..., -0.01097107  0.00999451
  -0.02462769]
 ...,
 [ 0.01780701  0.03939819 -0.0333252  ..., -0.01095581  0.00998688
  -0.02462769]
 [ 0.01786804  0.03945923 -0.03341675 ..., -0.0109787   0.00999451
  -0.02462769]
 [ 0.01785278  0.03942871 -0.03341675 ..., -0.01097107  0.00998688
  -0.02461243]]
After layer decoder_rnn_hidden_concat_t0_output (20, 1024) <class 'numpy.float16'> [[-0.00121212 -0.91943359  0.19726562 ..., -0.01097107  0.00998688
  -0.02461243]
 [-0.00121212 -0.91943359  0.1973877  ..., -0.01097107  0.00999451
  -0.02462769]
 [-0.00121212 -0.92041016  0.19604492 ..., -0.01097107  0.00999451
  -0.02462769]
 ...,
 [-0.00121021 -0.92236328  0.19311523 ..., -0.01095581  0.00998688
  -0.02462769]
 [-0.00120831 -0.91943359  0.19641113 ..., -0.0109787   0.00999451
  -0.02462769]
 [-0.00121021 -0.91992188  0.19677734 ..., -0.01097107  0.00998688
  -0.02461243]]
After layer decoder_rnn_hidden_fc_t0_output (20, 512) <class 'numpy.float16'> [[-1.96484375  0.20825195 -0.81201172 ...,  1.9765625   2.11132812
  -1.59570312]
 [-1.96582031  0.20727539 -0.81201172 ...,  1.9765625   2.11132812
  -1.59570312]
 [-1.9609375   0.21105957 -0.81689453 ...,  1.97070312  2.10742188
  -1.59960938]
 ...,
 [-1.95996094  0.22009277 -0.82958984 ...,  1.96679688  2.10546875
  -1.60449219]
 [-1.96875     0.21252441 -0.81835938 ...,  1.97753906  2.109375
  -1.59667969]
 [-1.96679688  0.20947266 -0.81494141 ...,  1.9765625   2.109375
  -1.59570312]]
After layer decoder_rnn_next_hidden_t0_output (20, 512) <class 'numpy.float16'> [[-0.96142578  0.20532227 -0.67089844 ...,  0.96240234  0.97119141
  -0.92089844]
 [-0.96142578  0.2043457  -0.67089844 ...,  0.96240234  0.97119141
  -0.92089844]
 [-0.9609375   0.20800781 -0.67333984 ...,  0.96191406  0.97070312
  -0.92138672]
 ...,
 [-0.9609375   0.21655273 -0.68017578 ...,  0.96142578  0.97070312
  -0.92236328]
 [-0.96191406  0.20935059 -0.67431641 ...,  0.96240234  0.97119141
  -0.92138672]
 [-0.96142578  0.2064209  -0.67236328 ...,  0.96240234  0.97119141
  -0.92089844]]
After layer logits_output (20, 16743) <class 'numpy.float16'> [[-2.0078125  -2.82421875 -2.40625    ..., -2.09375    -3.50195312
  -2.58203125]
 [-2.0078125  -2.82421875 -2.40625    ..., -2.09375    -3.50195312
  -2.58203125]
 [-2.00390625 -2.82421875 -2.40625    ..., -2.09570312 -3.5        -2.58398438]
 ...,
 [-2.00390625 -2.82226562 -2.40234375 ..., -2.09570312 -3.4921875
  -2.58203125]
 [-2.00585938 -2.82226562 -2.40429688 ..., -2.09375    -3.49804688
  -2.58398438]
 [-2.0078125  -2.82226562 -2.40625    ..., -2.09375    -3.5        -2.58203125]]
After layer softmax_0 (20, 16743) <class 'numpy.float16'> [[  8.34465027e-07   3.57627869e-07   5.96046448e-07 ...,   7.74860382e-07
    1.78813934e-07   4.76837158e-07]
 [  8.34465027e-07   3.57627869e-07   5.96046448e-07 ...,   7.74860382e-07
    1.78813934e-07   4.76837158e-07]
 [  8.34465027e-07   3.57627869e-07   5.96046448e-07 ...,   7.74860382e-07
    1.78813934e-07   4.76837158e-07]
 ...,
 [  8.94069672e-07   3.57627869e-07   5.96046448e-07 ...,   7.74860382e-07
    1.78813934e-07   4.76837158e-07]
 [  8.34465027e-07   3.57627869e-07   5.96046448e-07 ...,   7.74860382e-07
    1.78813934e-07   4.76837158e-07]
 [  8.34465027e-07   3.57627869e-07   5.96046448e-07 ...,   7.74860382e-07
    1.78813934e-07   4.76837158e-07]]
After layer reshape27_0 (20, 10) <class 'numpy.float16'> [[ 0.40307617  0.59667969  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40332031  0.59667969  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40356445  0.59667969  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40307617  0.59667969  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40356445  0.59667969  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40307617  0.59667969  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40307617  0.59667969  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40307617  0.59667969  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40429688  0.59619141  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40429688  0.59619141  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40380859  0.59619141  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40478516  0.59521484  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40307617  0.59667969  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40576172  0.59375     0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40307617  0.59667969  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40307617  0.59667969  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40307617  0.59667969  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40429688  0.59521484  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40307617  0.59716797  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40307617  0.59667969  0.          0.          0.          0.          0.
   0.          0.          0.        ]]
After layer target_embed_embed_0 (20, 256) <class 'numpy.float16'> [[-0.05505371 -0.0300293  -0.03598022 ...,  0.08459473 -0.05288696
  -0.01667786]
 [-0.05505371 -0.0300293  -0.03598022 ...,  0.08459473 -0.05288696
  -0.01667786]
 [-0.05505371 -0.0300293  -0.03598022 ...,  0.08459473 -0.05288696
  -0.01667786]
 ...,
 [-0.05505371 -0.0300293  -0.03598022 ...,  0.08459473 -0.05288696
  -0.01667786]
 [-0.05505371 -0.0300293  -0.03598022 ...,  0.08459473 -0.05288696
  -0.01667786]
 [-0.05505371 -0.0300293  -0.03598022 ...,  0.08459473 -0.05288696
  -0.01667786]]
After layer decoder_rnn_concat_target_context_t0_output (20, 768) <class 'numpy.float16'> [[-0.05505371 -0.0300293  -0.03598022 ...,  0.96240234  0.97119141
  -0.92089844]
 [-0.05505371 -0.0300293  -0.03598022 ...,  0.96240234  0.97119141
  -0.92089844]
 [-0.05505371 -0.0300293  -0.03598022 ...,  0.96191406  0.97070312
  -0.92138672]
 ...,
 [-0.05505371 -0.0300293  -0.03598022 ...,  0.96142578  0.97070312
  -0.92236328]
 [-0.05505371 -0.0300293  -0.03598022 ...,  0.96240234  0.97119141
  -0.92138672]
 [-0.05505371 -0.0300293  -0.03598022 ...,  0.96240234  0.97119141
  -0.92089844]]
After layer decoder_rnn_l0_t0_i2h_output (20, 2048) <class 'numpy.float16'> [[-3.19335938  1.60839844  2.4375     ..., -0.07763672  3.86523438
   0.59765625]
 [-3.19335938  1.60839844  2.4375     ..., -0.07763672  3.86523438
   0.59814453]
 [-3.19140625  1.60839844  2.4375     ..., -0.07720947  3.86523438
   0.6015625 ]
 ...,
 [-3.18359375  1.60546875  2.4375     ..., -0.07598877  3.86132812
   0.60644531]
 [-3.19140625  1.60644531  2.43945312 ..., -0.07672119  3.86328125
   0.59814453]
 [-3.19140625  1.60742188  2.4375     ..., -0.07739258  3.86328125
   0.59814453]]
After layer decoder_rnn_l0_t0_h2h_output (20, 2048) <class 'numpy.float16'> [[-0.32177734  0.47241211  1.84765625 ...,  0.70751953  1.296875
   0.17602539]
 [-0.32202148  0.47241211  1.84765625 ...,  0.70703125  1.29589844
   0.17578125]
 [-0.32519531  0.47900391  1.84375    ...,  0.70507812  1.30371094
   0.17163086]
 ...,
 [-0.3359375   0.49243164  1.84375    ...,  0.70068359  1.30664062
   0.16015625]
 [-0.32373047  0.47875977  1.84667969 ...,  0.70507812  1.29980469
   0.17016602]
 [-0.32324219  0.47558594  1.84667969 ...,  0.70556641  1.29785156
   0.17260742]]
After layer _plus1058_0 (20, 2048) <class 'numpy.float16'> [[-3.515625    2.08007812  4.28515625 ...,  0.62988281  5.1640625
   0.7734375 ]
 [-3.515625    2.08007812  4.28515625 ...,  0.62939453  5.16015625
   0.77392578]
 [-3.515625    2.08789062  4.28125    ...,  0.62792969  5.16796875
   0.7734375 ]
 ...,
 [-3.51953125  2.09765625  4.28125    ...,  0.62451172  5.16796875
   0.76660156]
 [-3.515625    2.0859375   4.28515625 ...,  0.62841797  5.1640625
   0.76855469]
 [-3.515625    2.08203125  4.28515625 ...,  0.62792969  5.16015625
   0.77050781]]
After layer decoder_rnn_l0_t0_slice_output0 (20, 512) <class 'numpy.float16'> [[-3.515625    2.08007812  4.28515625 ...,  1.74023438  4.609375    2.78125   ]
 [-3.515625    2.08007812  4.28515625 ...,  1.73925781  4.609375    2.78125   ]
 [-3.515625    2.08789062  4.28125    ...,  1.74609375  4.6015625   2.78125   ]
 ...,
 [-3.51953125  2.09765625  4.28125    ...,  1.74511719  4.59375     2.77734375]
 [-3.515625    2.0859375   4.28515625 ...,  1.73730469  4.609375
   2.77734375]
 [-3.515625    2.08203125  4.28515625 ...,  1.73925781  4.609375    2.78125   ]]
After layer decoder_rnn_l0_t0_slice_output1 (20, 512) <class 'numpy.float16'> [[-1.85742188  2.3203125   2.4296875  ...,  3.16601562 -0.69824219
   1.98242188]
 [-1.85742188  2.31835938  2.4296875  ...,  3.1640625  -0.69628906
   1.98242188]
 [-1.86425781  2.31445312  2.4375     ...,  3.16210938 -0.70214844
   1.97851562]
 ...,
 [-1.87695312  2.31054688  2.4453125  ...,  3.15234375 -0.69970703
   1.97070312]
 [-1.86035156  2.31835938  2.43359375 ...,  3.16015625 -0.6953125
   1.97851562]
 [-1.85839844  2.3203125   2.43359375 ...,  3.1640625  -0.69628906
   1.97949219]]
After layer decoder_rnn_l0_t0_slice_output2 (20, 512) <class 'numpy.float16'> [[-2.81640625 -3.0859375   2.84765625 ...,  4.26171875 -0.08154297
   2.16210938]
 [-2.81640625 -3.0859375   2.84765625 ...,  4.26171875 -0.08203125
   2.16015625]
 [-2.8203125  -3.08789062  2.859375   ...,  4.2578125  -0.08520508
   2.16210938]
 ...,
 [-2.81445312 -3.09375     2.88085938 ...,  4.2421875  -0.10058594  2.15625   ]
 [-2.81640625 -3.08984375  2.8515625  ...,  4.2578125  -0.08837891
   2.16015625]
 [-2.81445312 -3.0859375   2.84765625 ...,  4.2578125  -0.08544922
   2.16015625]]
After layer decoder_rnn_l0_t0_slice_output3 (20, 512) <class 'numpy.float16'> [[-3.27539062  2.43359375 -1.40234375 ...,  0.62988281  5.1640625
   0.7734375 ]
 [-3.27539062  2.43359375 -1.40234375 ...,  0.62939453  5.16015625
   0.77392578]
 [-3.27148438  2.44140625 -1.40917969 ...,  0.62792969  5.16796875
   0.7734375 ]
 ...,
 [-3.26757812  2.45898438 -1.421875   ...,  0.62451172  5.16796875
   0.76660156]
 [-3.27539062  2.43359375 -1.40722656 ...,  0.62841797  5.1640625
   0.76855469]
 [-3.27539062  2.43554688 -1.40429688 ...,  0.62792969  5.16015625
   0.77050781]]
After layer decoder_rnn_l0_t0_o_output (20, 512) <class 'numpy.float16'> [[ 0.03643799  0.91943359  0.1973877  ...,  0.65234375  0.99414062
   0.68408203]
 [ 0.03643799  0.91943359  0.1973877  ...,  0.65234375  0.99414062
   0.68457031]
 [ 0.03656006  0.91992188  0.19641113 ...,  0.65185547  0.99414062
   0.68408203]
 ...,
 [ 0.03671265  0.92138672  0.19433594 ...,  0.65136719  0.99414062
   0.68261719]
 [ 0.03643799  0.91943359  0.19665527 ...,  0.65234375  0.99414062
   0.68310547]
 [ 0.03643799  0.91943359  0.19714355 ...,  0.65185547  0.99414062
   0.68359375]]
After layer decoder_rnn_l0_t0_f_output (20, 512) <class 'numpy.float16'> [[ 0.13500977  0.91064453  0.91894531 ...,  0.95947266  0.33227539
   0.87890625]
 [ 0.13500977  0.91015625  0.91894531 ...,  0.95947266  0.33251953
   0.87890625]
 [ 0.13415527  0.91015625  0.91943359 ...,  0.95947266  0.33129883
   0.87841797]
 ...,
 [ 0.13269043  0.90966797  0.92041016 ...,  0.95898438  0.33178711
   0.87792969]
 [ 0.13464355  0.91015625  0.91943359 ...,  0.95947266  0.33276367
   0.87841797]
 [ 0.1348877   0.91064453  0.91943359 ...,  0.95947266  0.33251953
   0.87841797]]
After layer _mul2116_0 (20, 512) <class 'numpy.float16'> [[ -4.48226929e-03  -5.82031250e+00   6.73828125e+00 ...,   7.66796875e+00
   -3.88183594e-02   5.00390625e+00]
 [ -4.48226929e-03  -5.81640625e+00   6.71093750e+00 ...,   7.59375000e+00
   -3.97033691e-02   4.96093750e+00]
 [ -4.44030762e-03  -5.78906250e+00   6.74218750e+00 ...,   7.47656250e+00
   -4.03137207e-02   4.89843750e+00]
 ...,
 [ -4.36401367e-03  -5.55468750e+00   6.46875000e+00 ...,   7.06640625e+00
   -5.75866699e-02   4.39843750e+00]
 [ -4.46701050e-03  -5.81640625e+00   6.68750000e+00 ...,   7.53906250e+00
   -4.47692871e-02   4.90625000e+00]
 [ -4.47845459e-03  -5.82421875e+00   6.70703125e+00 ...,   7.53906250e+00
   -4.21447754e-02   4.92968750e+00]]
After layer decoder_rnn_l0_t0_i_output (20, 512) <class 'numpy.float16'> [[ 0.02886963  0.88916016  0.98632812 ...,  0.85058594  0.99023438
   0.94189453]
 [ 0.02886963  0.88916016  0.98632812 ...,  0.85058594  0.99023438
   0.94189453]
 [ 0.02886963  0.88964844  0.98632812 ...,  0.8515625   0.99023438
   0.94189453]
 ...,
 [ 0.02876282  0.890625    0.98632812 ...,  0.8515625   0.98974609
   0.94140625]
 [ 0.02886963  0.88964844  0.98632812 ...,  0.85058594  0.99023438
   0.94140625]
 [ 0.02886963  0.88916016  0.98632812 ...,  0.85058594  0.99023438
   0.94189453]]
After layer decoder_rnn_l0_t0_c_output (20, 512) <class 'numpy.float16'> [[-0.99267578 -0.99560547  0.99316406 ...,  0.99951172 -0.08135986
   0.97363281]
 [-0.99267578 -0.99560547  0.99316406 ...,  0.99951172 -0.08184814
   0.97363281]
 [-0.99316406 -0.99609375  0.99365234 ...,  0.99951172 -0.08502197
   0.97363281]
 ...,
 [-0.99267578 -0.99609375  0.99365234 ...,  0.99951172 -0.10021973
   0.97363281]
 [-0.99267578 -0.99609375  0.99316406 ...,  0.99951172 -0.08813477
   0.97363281]
 [-0.99267578 -0.99560547  0.99316406 ...,  0.99951172 -0.08526611
   0.97363281]]
After layer _mul2117_0 (20, 512) <class 'numpy.float16'> [[-0.02865601 -0.88525391  0.97949219 ...,  0.85009766 -0.08056641
   0.91699219]
 [-0.02865601 -0.88525391  0.97949219 ...,  0.85009766 -0.08105469
   0.91699219]
 [-0.02867126 -0.88623047  0.97998047 ...,  0.85107422 -0.08416748
   0.91699219]
 ...,
 [-0.02854919 -0.88720703  0.97998047 ...,  0.85107422 -0.09918213
   0.91650391]
 [-0.02865601 -0.88623047  0.97949219 ...,  0.85009766 -0.08728027
   0.91650391]
 [-0.02865601 -0.88525391  0.97949219 ...,  0.85009766 -0.08441162
   0.91699219]]
After layer decoder_rnn_l0_t0_state_0 (20, 512) <class 'numpy.float16'> [[-0.03314209 -6.70703125  7.71875    ...,  8.515625   -0.11938477
   5.921875  ]
 [-0.03314209 -6.703125    7.69140625 ...,  8.4453125  -0.12072754
   5.87890625]
 [-0.03311157 -6.67578125  7.72265625 ...,  8.328125   -0.12451172
   5.81640625]
 ...,
 [-0.03289795 -6.44140625  7.44921875 ...,  7.91796875 -0.15673828
   5.31640625]
 [-0.03311157 -6.703125    7.66796875 ...,  8.390625   -0.13208008
   5.82421875]
 [-0.03314209 -6.7109375   7.6875     ...,  8.390625   -0.12658691
   5.84765625]]
After layer activation1058_output (20, 512) <class 'numpy.float16'> [[-0.03314209 -1.          1.         ...,  1.         -0.11883545  1.        ]
 [-0.03314209 -1.          1.         ...,  1.         -0.12011719  1.        ]
 [-0.03311157 -1.          1.         ...,  1.         -0.12390137  1.        ]
 ...,
 [-0.03289795 -1.          1.         ...,  1.         -0.15551758  1.        ]
 [-0.03311157 -1.          1.         ...,  1.         -0.13134766  1.        ]
 [-0.03314209 -1.          1.         ...,  1.         -0.12585449  1.        ]]
After layer decoder_rnn_l0_t0_out_0 (20, 512) <class 'numpy.float16'> [[-0.00120735 -0.91943359  0.1973877  ...,  0.65234375 -0.11816406
   0.68408203]
 [-0.00120735 -0.91943359  0.1973877  ...,  0.65234375 -0.11938477
   0.68457031]
 [-0.00121021 -0.91992188  0.19641113 ...,  0.65185547 -0.12316895
   0.68408203]
 ...,
 [-0.00120735 -0.92138672  0.19433594 ...,  0.65136719 -0.15466309
   0.68261719]
 [-0.0012064  -0.91943359  0.19665527 ...,  0.65234375 -0.13061523
   0.68310547]
 [-0.00120735 -0.91943359  0.19714355 ...,  0.65185547 -0.12512207
   0.68359375]]
After layer expand_dims1067_0 (20, 512, 1) <class 'numpy.float16'> [[[-0.00120735]
  [-0.91943359]
  [ 0.1973877 ]
  ...,
  [ 0.65234375]
  [-0.11816406]
  [ 0.68408203]]

 [[-0.00120735]
  [-0.91943359]
  [ 0.1973877 ]
  ...,
  [ 0.65234375]
  [-0.11938477]
  [ 0.68457031]]

 [[-0.00121021]
  [-0.91992188]
  [ 0.19641113]
  ...,
  [ 0.65185547]
  [-0.12316895]
  [ 0.68408203]]

 ...,
 [[-0.00120735]
  [-0.92138672]
  [ 0.19433594]
  ...,
  [ 0.65136719]
  [-0.15466309]
  [ 0.68261719]]

 [[-0.0012064 ]
  [-0.91943359]
  [ 0.19665527]
  ...,
  [ 0.65234375]
  [-0.13061523]
  [ 0.68310547]]

 [[-0.00120735]
  [-0.91943359]
  [ 0.19714355]
  ...,
  [ 0.65185547]
  [-0.12512207]
  [ 0.68359375]]]
After layer att_batch_dot_0 (20, 10, 1) <class 'numpy.float16'> [[[ 0.53027344]
  [ 0.92285156]
  [ 1.63085938]
  [ 2.59570312]
  [ 2.51367188]
  [ 0.26879883]
  [-2.96484375]
  [-5.80859375]
  [-7.94140625]
  [-9.546875  ]]

 [[ 0.53076172]
  [ 0.92236328]
  [ 1.63085938]
  [ 2.59765625]
  [ 2.515625  ]
  [ 0.27075195]
  [-2.96289062]
  [-5.8046875 ]
  [-7.9375    ]
  [-9.5390625 ]]

 [[ 0.52880859]
  [ 0.92041016]
  [ 1.62109375]
  [ 2.578125  ]
  [ 2.48046875]
  [ 0.21484375]
  [-3.0390625 ]
  [-5.8984375 ]
  [-8.046875  ]
  [-9.65625   ]]

 [[ 0.53027344]
  [ 0.92333984]
  [ 1.63183594]
  [ 2.59960938]
  [ 2.51757812]
  [ 0.27124023]
  [-2.96679688]
  [-5.8125    ]
  [-7.94921875]
  [-9.5546875 ]]

 [[ 0.52929688]
  [ 0.92041016]
  [ 1.62304688]
  [ 2.578125  ]
  [ 2.47460938]
  [ 0.19567871]
  [-3.07617188]
  [-5.94921875]
  [-8.109375  ]
  [-9.7265625 ]]

 [[ 0.53027344]
  [ 0.92285156]
  [ 1.63085938]
  [ 2.59570312]
  [ 2.51367188]
  [ 0.2668457 ]
  [-2.96875   ]
  [-5.8125    ]
  [-7.94921875]
  [-9.5546875 ]]

 [[ 0.52832031]
  [ 0.92089844]
  [ 1.62109375]
  [ 2.57617188]
  [ 2.47070312]
  [ 0.19067383]
  [-3.08203125]
  [-5.95703125]
  [-8.1171875 ]
  [-9.734375  ]]

 [[ 0.53027344]
  [ 0.92236328]
  [ 1.62988281]
  [ 2.59570312]
  [ 2.51367188]
  [ 0.27001953]
  [-2.96289062]
  [-5.80078125]
  [-7.93359375]
  [-9.5390625 ]]

 [[ 0.53222656]
  [ 0.92089844]
  [ 1.62792969]
  [ 2.58984375]
  [ 2.49609375]
  [ 0.22961426]
  [-3.02929688]
  [-5.890625  ]
  [-8.0390625 ]
  [-9.6484375 ]]

 [[ 0.52685547]
  [ 0.91601562]
  [ 1.60839844]
  [ 2.55078125]
  [ 2.42578125]
  [ 0.12487793]
  [-3.1640625 ]
  [-6.05078125]
  [-8.21875   ]
  [-9.84375   ]]

 [[ 0.52978516]
  [ 0.91992188]
  [ 1.62207031]
  [ 2.578125  ]
  [ 2.48242188]
  [ 0.22106934]
  [-3.02734375]
  [-5.87890625]
  [-8.0234375 ]
  [-9.625     ]]

 [[ 0.52685547]
  [ 0.91503906]
  [ 1.609375  ]
  [ 2.55273438]
  [ 2.42773438]
  [ 0.12261963]
  [-3.171875  ]
  [-6.0625    ]
  [-8.234375  ]
  [-9.859375  ]]

 [[ 0.52685547]
  [ 0.91210938]
  [ 1.60742188]
  [ 2.54882812]
  [ 2.421875  ]
  [ 0.11450195]
  [-3.18359375]
  [-6.078125  ]
  [-8.25      ]
  [-9.875     ]]

 [[ 0.53076172]
  [ 0.92285156]
  [ 1.63085938]
  [ 2.59765625]
  [ 2.515625  ]
  [ 0.27148438]
  [-2.96289062]
  [-5.8046875 ]
  [-7.9375    ]
  [-9.5390625 ]]

 [[ 0.53076172]
  [ 0.92285156]
  [ 1.63183594]
  [ 2.59765625]
  [ 2.51757812]
  [ 0.27294922]
  [-2.9609375 ]
  [-5.8046875 ]
  [-7.9375    ]
  [-9.5390625 ]]

 [[ 0.53076172]
  [ 0.92285156]
  [ 1.63085938]
  [ 2.59765625]
  [ 2.515625  ]
  [ 0.27001953]
  [-2.96679688]
  [-5.80859375]
  [-7.9453125 ]
  [-9.546875  ]]

 [[ 0.53027344]
  [ 0.92236328]
  [ 1.63085938]
  [ 2.59765625]
  [ 2.51367188]
  [ 0.26318359]
  [-2.9765625 ]
  [-5.82421875]
  [-7.96484375]
  [-9.5703125 ]]

 [[ 0.52832031]
  [ 0.91699219]
  [ 1.61523438]
  [ 2.56445312]
  [ 2.4453125 ]
  [ 0.14746094]
  [-3.14257812]
  [-6.03125   ]
  [-8.203125  ]
  [-9.828125  ]]

 [[ 0.52978516]
  [ 0.92285156]
  [ 1.63085938]
  [ 2.59765625]
  [ 2.51171875]
  [ 0.25732422]
  [-2.98828125]
  [-5.83984375]
  [-7.984375  ]
  [-9.59375   ]]

 [[ 0.53027344]
  [ 0.92285156]
  [ 1.63085938]
  [ 2.59765625]
  [ 2.515625  ]
  [ 0.26635742]
  [-2.97265625]
  [-5.8203125 ]
  [-7.95703125]
  [-9.5625    ]]]
After layer swapaxes37_output (10, 20, 1) <class 'numpy.float16'> [[[ 0.53027344]
  [ 0.53076172]
  [ 0.52880859]
  [ 0.53027344]
  [ 0.52929688]
  [ 0.53027344]
  [ 0.52832031]
  [ 0.53027344]
  [ 0.53222656]
  [ 0.52685547]
  [ 0.52978516]
  [ 0.52685547]
  [ 0.52685547]
  [ 0.53076172]
  [ 0.53076172]
  [ 0.53076172]
  [ 0.53027344]
  [ 0.52832031]
  [ 0.52978516]
  [ 0.53027344]]

 [[ 0.92285156]
  [ 0.92236328]
  [ 0.92041016]
  [ 0.92333984]
  [ 0.92041016]
  [ 0.92285156]
  [ 0.92089844]
  [ 0.92236328]
  [ 0.92089844]
  [ 0.91601562]
  [ 0.91992188]
  [ 0.91503906]
  [ 0.91210938]
  [ 0.92285156]
  [ 0.92285156]
  [ 0.92285156]
  [ 0.92236328]
  [ 0.91699219]
  [ 0.92285156]
  [ 0.92285156]]

 [[ 1.63085938]
  [ 1.63085938]
  [ 1.62109375]
  [ 1.63183594]
  [ 1.62304688]
  [ 1.63085938]
  [ 1.62109375]
  [ 1.62988281]
  [ 1.62792969]
  [ 1.60839844]
  [ 1.62207031]
  [ 1.609375  ]
  [ 1.60742188]
  [ 1.63085938]
  [ 1.63183594]
  [ 1.63085938]
  [ 1.63085938]
  [ 1.61523438]
  [ 1.63085938]
  [ 1.63085938]]

 [[ 2.59570312]
  [ 2.59765625]
  [ 2.578125  ]
  [ 2.59960938]
  [ 2.578125  ]
  [ 2.59570312]
  [ 2.57617188]
  [ 2.59570312]
  [ 2.58984375]
  [ 2.55078125]
  [ 2.578125  ]
  [ 2.55273438]
  [ 2.54882812]
  [ 2.59765625]
  [ 2.59765625]
  [ 2.59765625]
  [ 2.59765625]
  [ 2.56445312]
  [ 2.59765625]
  [ 2.59765625]]

 [[ 2.51367188]
  [ 2.515625  ]
  [ 2.48046875]
  [ 2.51757812]
  [ 2.47460938]
  [ 2.51367188]
  [ 2.47070312]
  [ 2.51367188]
  [ 2.49609375]
  [ 2.42578125]
  [ 2.48242188]
  [ 2.42773438]
  [ 2.421875  ]
  [ 2.515625  ]
  [ 2.51757812]
  [ 2.515625  ]
  [ 2.51367188]
  [ 2.4453125 ]
  [ 2.51171875]
  [ 2.515625  ]]

 [[ 0.26879883]
  [ 0.27075195]
  [ 0.21484375]
  [ 0.27124023]
  [ 0.19567871]
  [ 0.2668457 ]
  [ 0.19067383]
  [ 0.27001953]
  [ 0.22961426]
  [ 0.12487793]
  [ 0.22106934]
  [ 0.12261963]
  [ 0.11450195]
  [ 0.27148438]
  [ 0.27294922]
  [ 0.27001953]
  [ 0.26318359]
  [ 0.14746094]
  [ 0.25732422]
  [ 0.26635742]]

 [[-2.96484375]
  [-2.96289062]
  [-3.0390625 ]
  [-2.96679688]
  [-3.07617188]
  [-2.96875   ]
  [-3.08203125]
  [-2.96289062]
  [-3.02929688]
  [-3.1640625 ]
  [-3.02734375]
  [-3.171875  ]
  [-3.18359375]
  [-2.96289062]
  [-2.9609375 ]
  [-2.96679688]
  [-2.9765625 ]
  [-3.14257812]
  [-2.98828125]
  [-2.97265625]]

 [[-5.80859375]
  [-5.8046875 ]
  [-5.8984375 ]
  [-5.8125    ]
  [-5.94921875]
  [-5.8125    ]
  [-5.95703125]
  [-5.80078125]
  [-5.890625  ]
  [-6.05078125]
  [-5.87890625]
  [-6.0625    ]
  [-6.078125  ]
  [-5.8046875 ]
  [-5.8046875 ]
  [-5.80859375]
  [-5.82421875]
  [-6.03125   ]
  [-5.83984375]
  [-5.8203125 ]]

 [[-7.94140625]
  [-7.9375    ]
  [-8.046875  ]
  [-7.94921875]
  [-8.109375  ]
  [-7.94921875]
  [-8.1171875 ]
  [-7.93359375]
  [-8.0390625 ]
  [-8.21875   ]
  [-8.0234375 ]
  [-8.234375  ]
  [-8.25      ]
  [-7.9375    ]
  [-7.9375    ]
  [-7.9453125 ]
  [-7.96484375]
  [-8.203125  ]
  [-7.984375  ]
  [-7.95703125]]

 [[-9.546875  ]
  [-9.5390625 ]
  [-9.65625   ]
  [-9.5546875 ]
  [-9.7265625 ]
  [-9.5546875 ]
  [-9.734375  ]
  [-9.5390625 ]
  [-9.6484375 ]
  [-9.84375   ]
  [-9.625     ]
  [-9.859375  ]
  [-9.875     ]
  [-9.5390625 ]
  [-9.5390625 ]
  [-9.546875  ]
  [-9.5703125 ]
  [-9.828125  ]
  [-9.59375   ]
  [-9.5625    ]]]
After layer sequencemask14_output (10, 20, 1) <class 'numpy.float16'> [[[  5.30273438e-01]
  [  5.30761719e-01]
  [  5.28808594e-01]
  [  5.30273438e-01]
  [  5.29296875e-01]
  [  5.30273438e-01]
  [  5.28320312e-01]
  [  5.30273438e-01]
  [  5.32226562e-01]
  [  5.26855469e-01]
  [  5.29785156e-01]
  [  5.26855469e-01]
  [  5.26855469e-01]
  [  5.30761719e-01]
  [  5.30761719e-01]
  [  5.30761719e-01]
  [  5.30273438e-01]
  [  5.28320312e-01]
  [  5.29785156e-01]
  [  5.30273438e-01]]

 [[  9.22851562e-01]
  [  9.22363281e-01]
  [  9.20410156e-01]
  [  9.23339844e-01]
  [  9.20410156e-01]
  [  9.22851562e-01]
  [  9.20898438e-01]
  [  9.22363281e-01]
  [  9.20898438e-01]
  [  9.16015625e-01]
  [  9.19921875e-01]
  [  9.15039062e-01]
  [  9.12109375e-01]
  [  9.22851562e-01]
  [  9.22851562e-01]
  [  9.22851562e-01]
  [  9.22363281e-01]
  [  9.16992188e-01]
  [  9.22851562e-01]
  [  9.22851562e-01]]

 [[ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]]
After layer swapaxes38_output (20, 10, 1) <class 'numpy.float16'> [[[  5.30273438e-01]
  [  9.22851562e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  5.30761719e-01]
  [  9.22363281e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  5.28808594e-01]
  [  9.20410156e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  5.30273438e-01]
  [  9.23339844e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  5.29296875e-01]
  [  9.20410156e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  5.30273438e-01]
  [  9.22851562e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  5.28320312e-01]
  [  9.20898438e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  5.30273438e-01]
  [  9.22363281e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  5.32226562e-01]
  [  9.20898438e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  5.26855469e-01]
  [  9.16015625e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  5.29785156e-01]
  [  9.19921875e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  5.26855469e-01]
  [  9.15039062e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  5.26855469e-01]
  [  9.12109375e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  5.30761719e-01]
  [  9.22851562e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  5.30761719e-01]
  [  9.22851562e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  5.30761719e-01]
  [  9.22851562e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  5.30273438e-01]
  [  9.22363281e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  5.28320312e-01]
  [  9.16992188e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  5.29785156e-01]
  [  9.22851562e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  5.30273438e-01]
  [  9.22851562e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]]
After layer attention_softmax_0 (20, 10, 1) <class 'numpy.float16'> [[[ 0.40307617]
  [ 0.59667969]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40332031]
  [ 0.59667969]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40332031]
  [ 0.59667969]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40307617]
  [ 0.59716797]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40356445]
  [ 0.59667969]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40307617]
  [ 0.59667969]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40307617]
  [ 0.59667969]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40307617]
  [ 0.59667969]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40405273]
  [ 0.59619141]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40380859]
  [ 0.59619141]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40380859]
  [ 0.59619141]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40429688]
  [ 0.59619141]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.4050293 ]
  [ 0.59521484]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40307617]
  [ 0.59667969]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40307617]
  [ 0.59667969]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40307617]
  [ 0.59667969]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40307617]
  [ 0.59667969]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40405273]
  [ 0.59619141]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40307617]
  [ 0.59716797]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40307617]
  [ 0.59667969]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]]
After layer batch_dot14_0 (20, 512, 1) <class 'numpy.float16'> [[[ 0.01785278]
  [ 0.03942871]
  [-0.03341675]
  ...,
  [-0.01097107]
  [ 0.00998688]
  [-0.02461243]]

 [[ 0.01785278]
  [ 0.03945923]
  [-0.03341675]
  ...,
  [-0.01097107]
  [ 0.00999451]
  [-0.02462769]]

 [[ 0.01785278]
  [ 0.03945923]
  [-0.03341675]
  ...,
  [-0.01097107]
  [ 0.00999451]
  [-0.02462769]]

 ...,
 [[ 0.01783752]
  [ 0.03942871]
  [-0.03338623]
  ...,
  [-0.01097107]
  [ 0.00999451]
  [-0.02464294]]

 [[ 0.01786804]
  [ 0.03945923]
  [-0.03341675]
  ...,
  [-0.0109787 ]
  [ 0.00999451]
  [-0.02462769]]

 [[ 0.01785278]
  [ 0.03942871]
  [-0.03341675]
  ...,
  [-0.01097107]
  [ 0.00998688]
  [-0.02461243]]]
After layer reshape28_0 (20, 512) <class 'numpy.float16'> [[ 0.01785278  0.03942871 -0.03341675 ..., -0.01097107  0.00998688
  -0.02461243]
 [ 0.01785278  0.03945923 -0.03341675 ..., -0.01097107  0.00999451
  -0.02462769]
 [ 0.01785278  0.03945923 -0.03341675 ..., -0.01097107  0.00999451
  -0.02462769]
 ...,
 [ 0.01783752  0.03942871 -0.03338623 ..., -0.01097107  0.00999451
  -0.02464294]
 [ 0.01786804  0.03945923 -0.03341675 ..., -0.0109787   0.00999451
  -0.02462769]
 [ 0.01785278  0.03942871 -0.03341675 ..., -0.01097107  0.00998688
  -0.02461243]]
After layer decoder_rnn_hidden_concat_t0_output (20, 1024) <class 'numpy.float16'> [[-0.00120735 -0.91943359  0.1973877  ..., -0.01097107  0.00998688
  -0.02461243]
 [-0.00120735 -0.91943359  0.1973877  ..., -0.01097107  0.00999451
  -0.02462769]
 [-0.00121021 -0.91992188  0.19641113 ..., -0.01097107  0.00999451
  -0.02462769]
 ...,
 [-0.00120735 -0.92138672  0.19433594 ..., -0.01097107  0.00999451
  -0.02464294]
 [-0.0012064  -0.91943359  0.19665527 ..., -0.0109787   0.00999451
  -0.02462769]
 [-0.00120735 -0.91943359  0.19714355 ..., -0.01097107  0.00998688
  -0.02461243]]
After layer decoder_rnn_hidden_fc_t0_output (20, 512) <class 'numpy.float16'> [[-1.96875     0.20983887 -0.81347656 ...,  1.97949219  2.11328125
  -1.59765625]
 [-1.96875     0.2088623  -0.81347656 ...,  1.97949219  2.11328125
  -1.59765625]
 [-1.96484375  0.21228027 -0.81835938 ...,  1.97460938  2.109375
  -1.60058594]
 ...,
 [-1.96289062  0.21887207 -0.82861328 ...,  1.97070312  2.109375
  -1.60742188]
 [-1.97167969  0.21374512 -0.81884766 ...,  1.97949219  2.11132812
  -1.59960938]
 [-1.96972656  0.21105957 -0.81591797 ...,  1.97949219  2.11328125
  -1.59765625]]
After layer decoder_rnn_next_hidden_t0_output (20, 512) <class 'numpy.float16'> [[-0.96191406  0.20678711 -0.67138672 ...,  0.96240234  0.97119141
  -0.92138672]
 [-0.96191406  0.20593262 -0.67138672 ...,  0.96240234  0.97119141
  -0.92138672]
 [-0.96142578  0.20910645 -0.67431641 ...,  0.96240234  0.97119141
  -0.921875  ]
 ...,
 [-0.96142578  0.2154541  -0.6796875  ...,  0.96191406  0.97119141
  -0.92285156]
 [-0.96191406  0.21057129 -0.67431641 ...,  0.96240234  0.97119141
  -0.92138672]
 [-0.96191406  0.20800781 -0.67285156 ...,  0.96240234  0.97119141
  -0.92138672]]
After layer logits_output (20, 16743) <class 'numpy.float16'> [[-2.00976562 -2.82421875 -2.40625    ..., -2.09375    -3.50195312
  -2.58398438]
 [-2.00976562 -2.82421875 -2.40625    ..., -2.09375    -3.50195312
  -2.58398438]
 [-2.00585938 -2.82421875 -2.40625    ..., -2.09570312 -3.5        -2.58398438]
 ...,
 [-2.00585938 -2.82421875 -2.40429688 ..., -2.09570312 -3.49609375
  -2.5859375 ]
 [-2.0078125  -2.82226562 -2.40625    ..., -2.09375    -3.5        -2.58398438]
 [-2.0078125  -2.82421875 -2.40625    ..., -2.09179688 -3.5        -2.58398438]]
After layer softmax_0 (20, 16743) <class 'numpy.float16'> [[  8.34465027e-07   3.57627869e-07   5.36441803e-07 ...,   7.74860382e-07
    1.78813934e-07   4.76837158e-07]
 [  8.34465027e-07   3.57627869e-07   5.36441803e-07 ...,   7.74860382e-07
    1.78813934e-07   4.76837158e-07]
 [  8.34465027e-07   3.57627869e-07   5.96046448e-07 ...,   7.74860382e-07
    1.78813934e-07   4.76837158e-07]
 ...,
 [  8.34465027e-07   3.57627869e-07   5.96046448e-07 ...,   7.74860382e-07
    1.78813934e-07   4.76837158e-07]
 [  8.34465027e-07   3.57627869e-07   5.96046448e-07 ...,   7.74860382e-07
    1.78813934e-07   4.76837158e-07]
 [  8.34465027e-07   3.57627869e-07   5.96046448e-07 ...,   7.74860382e-07
    1.78813934e-07   4.76837158e-07]]
After layer reshape29_0 (20, 10) <class 'numpy.float16'> [[ 0.40307617  0.59667969  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40332031  0.59667969  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40332031  0.59667969  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40307617  0.59716797  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40356445  0.59667969  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40307617  0.59667969  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40307617  0.59667969  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40307617  0.59667969  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40405273  0.59619141  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40380859  0.59619141  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40380859  0.59619141  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40429688  0.59619141  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.4050293   0.59521484  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40307617  0.59667969  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40307617  0.59667969  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40307617  0.59667969  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40307617  0.59667969  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40405273  0.59619141  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40307617  0.59716797  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40307617  0.59667969  0.          0.          0.          0.          0.
   0.          0.          0.        ]]
After layer target_embed_embed_0 (20, 256) <class 'numpy.float16'> [[-0.05505371 -0.0300293  -0.03598022 ...,  0.08459473 -0.05288696
  -0.01667786]
 [-0.05505371 -0.0300293  -0.03598022 ...,  0.08459473 -0.05288696
  -0.01667786]
 [-0.05505371 -0.0300293  -0.03598022 ...,  0.08459473 -0.05288696
  -0.01667786]
 ...,
 [-0.05505371 -0.0300293  -0.03598022 ...,  0.08459473 -0.05288696
  -0.01667786]
 [-0.05505371 -0.0300293  -0.03598022 ...,  0.08459473 -0.05288696
  -0.01667786]
 [-0.05505371 -0.0300293  -0.03598022 ...,  0.08459473 -0.05288696
  -0.01667786]]
After layer decoder_rnn_concat_target_context_t0_output (20, 768) <class 'numpy.float16'> [[-0.05505371 -0.0300293  -0.03598022 ...,  0.96240234  0.97119141
  -0.92138672]
 [-0.05505371 -0.0300293  -0.03598022 ...,  0.96240234  0.97119141
  -0.92138672]
 [-0.05505371 -0.0300293  -0.03598022 ...,  0.96240234  0.97119141
  -0.921875  ]
 ...,
 [-0.05505371 -0.0300293  -0.03598022 ...,  0.96191406  0.97119141
  -0.92285156]
 [-0.05505371 -0.0300293  -0.03598022 ...,  0.96240234  0.97119141
  -0.92138672]
 [-0.05505371 -0.0300293  -0.03598022 ...,  0.96240234  0.97119141
  -0.92138672]]
After layer decoder_rnn_l0_t0_i2h_output (20, 2048) <class 'numpy.float16'> [[-3.19335938  1.60839844  2.43945312 ..., -0.07775879  3.86523438
   0.59716797]
 [-3.19335938  1.60839844  2.43945312 ..., -0.07775879  3.86523438
   0.59765625]
 [-3.19335938  1.60742188  2.4375     ..., -0.07720947  3.86523438
   0.60058594]
 ...,
 [-3.1875      1.60546875  2.43945312 ..., -0.07635498  3.86328125
   0.60546875]
 [-3.19140625  1.60644531  2.43945312 ..., -0.07666016  3.86328125
   0.59765625]
 [-3.19335938  1.60742188  2.43945312 ..., -0.07727051  3.86328125
   0.59765625]]
After layer decoder_rnn_l0_t0_h2h_output (20, 2048) <class 'numpy.float16'> [[-0.32202148  0.47216797  1.8515625  ...,  0.70898438  1.29589844
   0.17651367]
 [-0.32202148  0.47192383  1.8515625  ...,  0.70898438  1.29492188
   0.17614746]
 [-0.32446289  0.47851562  1.84765625 ...,  0.70751953  1.30175781
   0.17199707]
 ...,
 [-0.33300781  0.48974609  1.84765625 ...,  0.70410156  1.30664062
   0.16259766]
 [-0.32348633  0.47753906  1.85058594 ...,  0.70751953  1.29980469
   0.17150879]
 [-0.32324219  0.47485352  1.85058594 ...,  0.70751953  1.29785156
   0.17358398]]
After layer _plus1059_0 (20, 2048) <class 'numpy.float16'> [[-3.515625    2.08007812  4.2890625  ...,  0.63134766  5.16015625
   0.7734375 ]
 [-3.515625    2.08007812  4.2890625  ...,  0.63134766  5.16015625
   0.77392578]
 [-3.51757812  2.0859375   4.28515625 ...,  0.63037109  5.16796875
   0.77246094]
 ...,
 [-3.51953125  2.09570312  4.2890625  ...,  0.62792969  5.171875
   0.76806641]
 [-3.515625    2.08398438  4.2890625  ...,  0.63085938  5.1640625
   0.76904297]
 [-3.515625    2.08203125  4.2890625  ...,  0.63037109  5.16015625
   0.77148438]]
After layer decoder_rnn_l0_t0_slice_output0 (20, 512) <class 'numpy.float16'> [[-3.515625    2.08007812  4.2890625  ...,  1.74023438  4.61328125  2.78125   ]
 [-3.515625    2.08007812  4.2890625  ...,  1.73925781  4.61328125  2.78125   ]
 [-3.51757812  2.0859375   4.28515625 ...,  1.74414062  4.60546875  2.78125   ]
 ...,
 [-3.51953125  2.09570312  4.2890625  ...,  1.74511719  4.6015625
   2.77929688]
 [-3.515625    2.08398438  4.2890625  ...,  1.73730469  4.609375
   2.77929688]
 [-3.515625    2.08203125  4.2890625  ...,  1.73925781  4.609375    2.78125   ]]
After layer decoder_rnn_l0_t0_slice_output1 (20, 512) <class 'numpy.float16'> [[-1.85546875  2.3203125   2.43359375 ...,  3.16796875 -0.69433594
   1.98339844]
 [-1.85546875  2.3203125   2.43359375 ...,  3.16601562 -0.69335938
   1.98339844]
 [-1.86230469  2.31835938  2.4375     ...,  3.1640625  -0.69726562
   1.98144531]
 ...,
 [-1.87304688  2.3125      2.44726562 ...,  3.15625    -0.69580078
   1.9765625 ]
 [-1.859375    2.3203125   2.4375     ...,  3.16210938 -0.69238281
   1.98242188]
 [-1.85644531  2.32226562  2.43554688 ...,  3.1640625  -0.69335938
   1.98242188]]
After layer decoder_rnn_l0_t0_slice_output2 (20, 512) <class 'numpy.float16'> [[-2.81640625 -3.08789062  2.84960938 ...,  4.26171875 -0.08203125
   2.16210938]
 [-2.81640625 -3.08789062  2.84960938 ...,  4.26171875 -0.08251953
   2.16015625]
 [-2.8203125  -3.08984375  2.859375   ...,  4.2578125  -0.0859375
   2.16015625]
 ...,
 [-2.81835938 -3.09765625  2.88085938 ...,  4.24609375 -0.09594727  2.15625   ]
 [-2.81640625 -3.09375     2.85351562 ...,  4.2578125  -0.08813477
   2.16015625]
 [-2.81640625 -3.08984375  2.8515625  ...,  4.2578125  -0.08569336
   2.16015625]]
After layer decoder_rnn_l0_t0_slice_output3 (20, 512) <class 'numpy.float16'> [[-3.27734375  2.4296875  -1.40234375 ...,  0.63134766  5.16015625
   0.7734375 ]
 [-3.27734375  2.4296875  -1.40039062 ...,  0.63134766  5.16015625
   0.77392578]
 [-3.2734375   2.4375     -1.40722656 ...,  0.63037109  5.16796875
   0.77246094]
 ...,
 [-3.265625    2.45117188 -1.41601562 ...,  0.62792969  5.171875
   0.76806641]
 [-3.27734375  2.4296875  -1.40625    ...,  0.63085938  5.1640625
   0.76904297]
 [-3.27734375  2.43164062 -1.40332031 ...,  0.63037109  5.16015625
   0.77148438]]
After layer decoder_rnn_l0_t0_o_output (20, 512) <class 'numpy.float16'> [[ 0.03634644  0.91894531  0.1973877  ...,  0.65283203  0.99414062
   0.68408203]
 [ 0.03634644  0.91894531  0.19775391 ...,  0.65283203  0.99414062
   0.68457031]
 [ 0.03649902  0.91943359  0.19665527 ...,  0.65234375  0.99414062
   0.68408203]
 ...,
 [ 0.03677368  0.92041016  0.1953125  ...,  0.65185547  0.99414062
   0.68310547]
 [ 0.03634644  0.91894531  0.19677734 ...,  0.65283203  0.99414062
   0.68310547]
 [ 0.03634644  0.91943359  0.19726562 ...,  0.65234375  0.99414062
   0.68408203]]
After layer decoder_rnn_l0_t0_f_output (20, 512) <class 'numpy.float16'> [[ 0.13525391  0.91064453  0.91943359 ...,  0.95947266  0.33300781
   0.87890625]
 [ 0.13525391  0.91064453  0.91943359 ...,  0.95947266  0.33325195
   0.87890625]
 [ 0.13439941  0.91015625  0.91943359 ...,  0.95947266  0.33251953
   0.87890625]
 ...,
 [ 0.13317871  0.90966797  0.92041016 ...,  0.95898438  0.33276367
   0.87841797]
 [ 0.13476562  0.91064453  0.91943359 ...,  0.95947266  0.33349609
   0.87890625]
 [ 0.13513184  0.91064453  0.91943359 ...,  0.95947266  0.33325195
   0.87890625]]
After layer _mul2118_0 (20, 512) <class 'numpy.float16'> [[ -4.48226929e-03  -6.10937500e+00   7.09765625e+00 ...,   8.17187500e+00
   -3.97644043e-02   5.20312500e+00]
 [ -4.48226929e-03  -6.10546875e+00   7.07031250e+00 ...,   8.10156250e+00
   -4.02221680e-02   5.16796875e+00]
 [ -4.45175171e-03  -6.07421875e+00   7.10156250e+00 ...,   7.99218750e+00
   -4.14123535e-02   5.11328125e+00]
 ...,
 [ -4.38308716e-03  -5.85937500e+00   6.85546875e+00 ...,   7.59375000e+00
   -5.21545410e-02   4.67187500e+00]
 [ -4.46319580e-03  -6.10546875e+00   7.05078125e+00 ...,   8.04687500e+00
   -4.40368652e-02   5.11718750e+00]
 [ -4.47845459e-03  -6.10937500e+00   7.06640625e+00 ...,   8.04687500e+00
   -4.21752930e-02   5.14062500e+00]]
After layer decoder_rnn_l0_t0_i_output (20, 512) <class 'numpy.float16'> [[ 0.02886963  0.88916016  0.98632812 ...,  0.85058594  0.99023438
   0.94189453]
 [ 0.02886963  0.88916016  0.98632812 ...,  0.85058594  0.99023438
   0.94189453]
 [ 0.02880859  0.88964844  0.98632812 ...,  0.85107422  0.99023438
   0.94189453]
 ...,
 [ 0.02876282  0.890625    0.98632812 ...,  0.8515625   0.99023438
   0.94140625]
 [ 0.02886963  0.88916016  0.98632812 ...,  0.85058594  0.99023438
   0.94140625]
 [ 0.02886963  0.88916016  0.98632812 ...,  0.85058594  0.99023438
   0.94189453]]
After layer decoder_rnn_l0_t0_c_output (20, 512) <class 'numpy.float16'> [[-0.99267578 -0.99609375  0.99316406 ...,  0.99951172 -0.08184814
   0.97363281]
 [-0.99267578 -0.99609375  0.99316406 ...,  0.99951172 -0.08233643
   0.97363281]
 [-0.99316406 -0.99609375  0.99365234 ...,  0.99951172 -0.08575439
   0.97363281]
 ...,
 [-0.99267578 -0.99609375  0.99365234 ...,  0.99951172 -0.09564209
   0.97363281]
 [-0.99267578 -0.99609375  0.99316406 ...,  0.99951172 -0.08789062
   0.97363281]
 [-0.99267578 -0.99609375  0.99316406 ...,  0.99951172 -0.08551025
   0.97363281]]
After layer _mul2119_0 (20, 512) <class 'numpy.float16'> [[-0.02865601 -0.88574219  0.97949219 ...,  0.85009766 -0.08105469
   0.91699219]
 [-0.02865601 -0.88574219  0.97949219 ...,  0.85009766 -0.08154297
   0.91699219]
 [-0.02861023 -0.88623047  0.97998047 ...,  0.85058594 -0.0848999
   0.91699219]
 ...,
 [-0.02854919 -0.88720703  0.97998047 ...,  0.85107422 -0.09472656
   0.91650391]
 [-0.02865601 -0.88574219  0.97949219 ...,  0.85009766 -0.08703613
   0.91650391]
 [-0.02865601 -0.88574219  0.97949219 ...,  0.85009766 -0.08465576
   0.91699219]]
After layer decoder_rnn_l0_t0_state_0 (20, 512) <class 'numpy.float16'> [[-0.03314209 -6.99609375  8.078125   ...,  9.0234375  -0.12084961
   6.12109375]
 [-0.03314209 -6.9921875   8.046875   ...,  8.953125   -0.12176514
   6.0859375 ]
 [-0.03305054 -6.9609375   8.078125   ...,  8.84375    -0.12634277  6.03125   ]
 ...,
 [-0.03292847 -6.74609375  7.8359375  ...,  8.4453125  -0.14685059
   5.58984375]
 [-0.03311157 -6.9921875   8.03125    ...,  8.8984375  -0.13110352
   6.03515625]
 [-0.03314209 -6.99609375  8.046875   ...,  8.8984375  -0.12683105
   6.05859375]]
After layer activation1059_output (20, 512) <class 'numpy.float16'> [[-0.03314209 -1.          1.         ...,  1.         -0.12023926  1.        ]
 [-0.03314209 -1.          1.         ...,  1.         -0.12115479  1.        ]
 [-0.03305054 -1.          1.         ...,  1.         -0.12573242  1.        ]
 ...,
 [-0.03292847 -1.          1.         ...,  1.         -0.14575195  1.        ]
 [-0.03311157 -1.          1.         ...,  1.         -0.13037109  1.        ]
 [-0.03314209 -1.          1.         ...,  1.         -0.12609863  1.        ]]
After layer decoder_rnn_l0_t0_out_0 (20, 512) <class 'numpy.float16'> [[-0.00120449 -0.91894531  0.1973877  ...,  0.65283203 -0.11950684
   0.68408203]
 [-0.00120449 -0.91894531  0.19775391 ...,  0.65283203 -0.12042236
   0.68457031]
 [-0.0012064  -0.91943359  0.19665527 ...,  0.65234375 -0.125       0.68408203]
 ...,
 [-0.00121117 -0.92041016  0.1953125  ...,  0.65185547 -0.14489746
   0.68310547]
 [-0.00120354 -0.91894531  0.19677734 ...,  0.65283203 -0.12963867
   0.68310547]
 [-0.00120449 -0.91943359  0.19726562 ...,  0.65234375 -0.12536621
   0.68408203]]
After layer expand_dims1068_0 (20, 512, 1) <class 'numpy.float16'> [[[-0.00120449]
  [-0.91894531]
  [ 0.1973877 ]
  ...,
  [ 0.65283203]
  [-0.11950684]
  [ 0.68408203]]

 [[-0.00120449]
  [-0.91894531]
  [ 0.19775391]
  ...,
  [ 0.65283203]
  [-0.12042236]
  [ 0.68457031]]

 [[-0.0012064 ]
  [-0.91943359]
  [ 0.19665527]
  ...,
  [ 0.65234375]
  [-0.125     ]
  [ 0.68408203]]

 ...,
 [[-0.00121117]
  [-0.92041016]
  [ 0.1953125 ]
  ...,
  [ 0.65185547]
  [-0.14489746]
  [ 0.68310547]]

 [[-0.00120354]
  [-0.91894531]
  [ 0.19677734]
  ...,
  [ 0.65283203]
  [-0.12963867]
  [ 0.68310547]]

 [[-0.00120449]
  [-0.91943359]
  [ 0.19726562]
  ...,
  [ 0.65234375]
  [-0.12536621]
  [ 0.68408203]]]
After layer att_batch_dot_0 (20, 10, 1) <class 'numpy.float16'> [[[ 0.53076172]
  [ 0.92285156]
  [ 1.6328125 ]
  [ 2.59960938]
  [ 2.51757812]
  [ 0.2722168 ]
  [-2.96289062]
  [-5.80859375]
  [-7.9453125 ]
  [-9.546875  ]]

 [[ 0.53076172]
  [ 0.92285156]
  [ 1.6328125 ]
  [ 2.6015625 ]
  [ 2.51953125]
  [ 0.27441406]
  [-2.9609375 ]
  [-5.8046875 ]
  [-7.94140625]
  [-9.546875  ]]

 [[ 0.52929688]
  [ 0.92089844]
  [ 1.625     ]
  [ 2.58398438]
  [ 2.49023438]
  [ 0.2253418 ]
  [-3.02929688]
  [-5.88671875]
  [-8.03125   ]
  [-9.6484375 ]]

 [[ 0.53076172]
  [ 0.92333984]
  [ 1.6328125 ]
  [ 2.6015625 ]
  [ 2.51953125]
  [ 0.27026367]
  [-2.96875   ]
  [-5.81640625]
  [-7.95703125]
  [-9.5625    ]]

 [[ 0.52978516]
  [ 0.92089844]
  [ 1.625     ]
  [ 2.58398438]
  [ 2.48242188]
  [ 0.20544434]
  [-3.06445312]
  [-5.9375    ]
  [-8.09375   ]
  [-9.71875   ]]

 [[ 0.52832031]
  [ 0.92089844]
  [ 1.62402344]
  [ 2.58007812]
  [ 2.47851562]
  [ 0.19909668]
  [-3.07226562]
  [-5.9453125 ]
  [-8.109375  ]
  [-9.7265625 ]]

 [[ 0.53027344]
  [ 0.92333984]
  [ 1.6328125 ]
  [ 2.6015625 ]
  [ 2.51953125]
  [ 0.27319336]
  [-2.96484375]
  [-5.80859375]
  [-7.9453125 ]
  [-9.5546875 ]]

 [[ 0.53076172]
  [ 0.92285156]
  [ 1.6328125 ]
  [ 2.59960938]
  [ 2.51953125]
  [ 0.27490234]
  [-2.95898438]
  [-5.80078125]
  [-7.9375    ]
  [-9.5390625 ]]

 [[ 0.53222656]
  [ 0.921875  ]
  [ 1.63085938]
  [ 2.59375   ]
  [ 2.50195312]
  [ 0.23852539]
  [-3.01757812]
  [-5.87890625]
  [-8.03125   ]
  [-9.640625  ]]

 [[ 0.52783203]
  [ 0.91748047]
  [ 1.61425781]
  [ 2.56054688]
  [ 2.44335938]
  [ 0.15014648]
  [-3.1328125 ]
  [-6.015625  ]
  [-8.1875    ]
  [-9.8046875 ]]

 [[ 0.52978516]
  [ 0.92089844]
  [ 1.625     ]
  [ 2.58398438]
  [ 2.4921875 ]
  [ 0.23144531]
  [-3.01757812]
  [-5.87109375]
  [-8.015625  ]
  [-9.625     ]]

 [[ 0.52832031]
  [ 0.91699219]
  [ 1.61523438]
  [ 2.5625    ]
  [ 2.4453125 ]
  [ 0.14733887]
  [-3.140625  ]
  [-6.02734375]
  [-8.1953125 ]
  [-9.8203125 ]]

 [[ 0.53076172]
  [ 0.92285156]
  [ 1.6328125 ]
  [ 2.6015625 ]
  [ 2.51953125]
  [ 0.27514648]
  [-2.9609375 ]
  [-5.8046875 ]
  [-7.94140625]
  [-9.5390625 ]]

 [[ 0.52880859]
  [ 0.91601562]
  [ 1.61523438]
  [ 2.5625    ]
  [ 2.4453125 ]
  [ 0.14746094]
  [-3.140625  ]
  [-6.03125   ]
  [-8.1953125 ]
  [-9.8203125 ]]

 [[ 0.53076172]
  [ 0.92333984]
  [ 1.63378906]
  [ 2.6015625 ]
  [ 2.52148438]
  [ 0.27514648]
  [-2.9609375 ]
  [-5.8046875 ]
  [-7.94140625]
  [-9.546875  ]]

 [[ 0.53076172]
  [ 0.92333984]
  [ 1.63378906]
  [ 2.6015625 ]
  [ 2.52148438]
  [ 0.27416992]
  [-2.96289062]
  [-5.80859375]
  [-7.9453125 ]
  [-9.546875  ]]

 [[ 0.53027344]
  [ 0.92285156]
  [ 1.6328125 ]
  [ 2.59960938]
  [ 2.515625  ]
  [ 0.265625  ]
  [-2.9765625 ]
  [-5.82421875]
  [-7.96484375]
  [-9.5703125 ]]

 [[ 0.52880859]
  [ 0.91845703]
  [ 1.61914062]
  [ 2.57226562]
  [ 2.45898438]
  [ 0.16516113]
  [-3.12109375]
  [-6.0078125 ]
  [-8.1796875 ]
  [-9.8046875 ]]

 [[ 0.53027344]
  [ 0.92285156]
  [ 1.6328125 ]
  [ 2.59960938]
  [ 2.51367188]
  [ 0.25927734]
  [-2.98828125]
  [-5.83984375]
  [-7.984375  ]
  [-9.59375   ]]

 [[ 0.53076172]
  [ 0.92285156]
  [ 1.6328125 ]
  [ 2.59960938]
  [ 2.51757812]
  [ 0.26806641]
  [-2.97265625]
  [-5.8203125 ]
  [-7.9609375 ]
  [-9.5625    ]]]
After layer swapaxes39_output (10, 20, 1) <class 'numpy.float16'> [[[ 0.53076172]
  [ 0.53076172]
  [ 0.52929688]
  [ 0.53076172]
  [ 0.52978516]
  [ 0.52832031]
  [ 0.53027344]
  [ 0.53076172]
  [ 0.53222656]
  [ 0.52783203]
  [ 0.52978516]
  [ 0.52832031]
  [ 0.53076172]
  [ 0.52880859]
  [ 0.53076172]
  [ 0.53076172]
  [ 0.53027344]
  [ 0.52880859]
  [ 0.53027344]
  [ 0.53076172]]

 [[ 0.92285156]
  [ 0.92285156]
  [ 0.92089844]
  [ 0.92333984]
  [ 0.92089844]
  [ 0.92089844]
  [ 0.92333984]
  [ 0.92285156]
  [ 0.921875  ]
  [ 0.91748047]
  [ 0.92089844]
  [ 0.91699219]
  [ 0.92285156]
  [ 0.91601562]
  [ 0.92333984]
  [ 0.92333984]
  [ 0.92285156]
  [ 0.91845703]
  [ 0.92285156]
  [ 0.92285156]]

 [[ 1.6328125 ]
  [ 1.6328125 ]
  [ 1.625     ]
  [ 1.6328125 ]
  [ 1.625     ]
  [ 1.62402344]
  [ 1.6328125 ]
  [ 1.6328125 ]
  [ 1.63085938]
  [ 1.61425781]
  [ 1.625     ]
  [ 1.61523438]
  [ 1.6328125 ]
  [ 1.61523438]
  [ 1.63378906]
  [ 1.63378906]
  [ 1.6328125 ]
  [ 1.61914062]
  [ 1.6328125 ]
  [ 1.6328125 ]]

 [[ 2.59960938]
  [ 2.6015625 ]
  [ 2.58398438]
  [ 2.6015625 ]
  [ 2.58398438]
  [ 2.58007812]
  [ 2.6015625 ]
  [ 2.59960938]
  [ 2.59375   ]
  [ 2.56054688]
  [ 2.58398438]
  [ 2.5625    ]
  [ 2.6015625 ]
  [ 2.5625    ]
  [ 2.6015625 ]
  [ 2.6015625 ]
  [ 2.59960938]
  [ 2.57226562]
  [ 2.59960938]
  [ 2.59960938]]

 [[ 2.51757812]
  [ 2.51953125]
  [ 2.49023438]
  [ 2.51953125]
  [ 2.48242188]
  [ 2.47851562]
  [ 2.51953125]
  [ 2.51953125]
  [ 2.50195312]
  [ 2.44335938]
  [ 2.4921875 ]
  [ 2.4453125 ]
  [ 2.51953125]
  [ 2.4453125 ]
  [ 2.52148438]
  [ 2.52148438]
  [ 2.515625  ]
  [ 2.45898438]
  [ 2.51367188]
  [ 2.51757812]]

 [[ 0.2722168 ]
  [ 0.27441406]
  [ 0.2253418 ]
  [ 0.27026367]
  [ 0.20544434]
  [ 0.19909668]
  [ 0.27319336]
  [ 0.27490234]
  [ 0.23852539]
  [ 0.15014648]
  [ 0.23144531]
  [ 0.14733887]
  [ 0.27514648]
  [ 0.14746094]
  [ 0.27514648]
  [ 0.27416992]
  [ 0.265625  ]
  [ 0.16516113]
  [ 0.25927734]
  [ 0.26806641]]

 [[-2.96289062]
  [-2.9609375 ]
  [-3.02929688]
  [-2.96875   ]
  [-3.06445312]
  [-3.07226562]
  [-2.96484375]
  [-2.95898438]
  [-3.01757812]
  [-3.1328125 ]
  [-3.01757812]
  [-3.140625  ]
  [-2.9609375 ]
  [-3.140625  ]
  [-2.9609375 ]
  [-2.96289062]
  [-2.9765625 ]
  [-3.12109375]
  [-2.98828125]
  [-2.97265625]]

 [[-5.80859375]
  [-5.8046875 ]
  [-5.88671875]
  [-5.81640625]
  [-5.9375    ]
  [-5.9453125 ]
  [-5.80859375]
  [-5.80078125]
  [-5.87890625]
  [-6.015625  ]
  [-5.87109375]
  [-6.02734375]
  [-5.8046875 ]
  [-6.03125   ]
  [-5.8046875 ]
  [-5.80859375]
  [-5.82421875]
  [-6.0078125 ]
  [-5.83984375]
  [-5.8203125 ]]

 [[-7.9453125 ]
  [-7.94140625]
  [-8.03125   ]
  [-7.95703125]
  [-8.09375   ]
  [-8.109375  ]
  [-7.9453125 ]
  [-7.9375    ]
  [-8.03125   ]
  [-8.1875    ]
  [-8.015625  ]
  [-8.1953125 ]
  [-7.94140625]
  [-8.1953125 ]
  [-7.94140625]
  [-7.9453125 ]
  [-7.96484375]
  [-8.1796875 ]
  [-7.984375  ]
  [-7.9609375 ]]

 [[-9.546875  ]
  [-9.546875  ]
  [-9.6484375 ]
  [-9.5625    ]
  [-9.71875   ]
  [-9.7265625 ]
  [-9.5546875 ]
  [-9.5390625 ]
  [-9.640625  ]
  [-9.8046875 ]
  [-9.625     ]
  [-9.8203125 ]
  [-9.5390625 ]
  [-9.8203125 ]
  [-9.546875  ]
  [-9.546875  ]
  [-9.5703125 ]
  [-9.8046875 ]
  [-9.59375   ]
  [-9.5625    ]]]
After layer sequencemask15_output (10, 20, 1) <class 'numpy.float16'> [[[  5.30761719e-01]
  [  5.30761719e-01]
  [  5.29296875e-01]
  [  5.30761719e-01]
  [  5.29785156e-01]
  [  5.28320312e-01]
  [  5.30273438e-01]
  [  5.30761719e-01]
  [  5.32226562e-01]
  [  5.27832031e-01]
  [  5.29785156e-01]
  [  5.28320312e-01]
  [  5.30761719e-01]
  [  5.28808594e-01]
  [  5.30761719e-01]
  [  5.30761719e-01]
  [  5.30273438e-01]
  [  5.28808594e-01]
  [  5.30273438e-01]
  [  5.30761719e-01]]

 [[  9.22851562e-01]
  [  9.22851562e-01]
  [  9.20898438e-01]
  [  9.23339844e-01]
  [  9.20898438e-01]
  [  9.20898438e-01]
  [  9.23339844e-01]
  [  9.22851562e-01]
  [  9.21875000e-01]
  [  9.17480469e-01]
  [  9.20898438e-01]
  [  9.16992188e-01]
  [  9.22851562e-01]
  [  9.16015625e-01]
  [  9.23339844e-01]
  [  9.23339844e-01]
  [  9.22851562e-01]
  [  9.18457031e-01]
  [  9.22851562e-01]
  [  9.22851562e-01]]

 [[ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]]
After layer swapaxes40_output (20, 10, 1) <class 'numpy.float16'> [[[  5.30761719e-01]
  [  9.22851562e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  5.30761719e-01]
  [  9.22851562e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  5.29296875e-01]
  [  9.20898438e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  5.30761719e-01]
  [  9.23339844e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  5.29785156e-01]
  [  9.20898438e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  5.28320312e-01]
  [  9.20898438e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  5.30273438e-01]
  [  9.23339844e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  5.30761719e-01]
  [  9.22851562e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  5.32226562e-01]
  [  9.21875000e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  5.27832031e-01]
  [  9.17480469e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  5.29785156e-01]
  [  9.20898438e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  5.28320312e-01]
  [  9.16992188e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  5.30761719e-01]
  [  9.22851562e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  5.28808594e-01]
  [  9.16015625e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  5.30761719e-01]
  [  9.23339844e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  5.30761719e-01]
  [  9.23339844e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  5.30273438e-01]
  [  9.22851562e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  5.28808594e-01]
  [  9.18457031e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  5.30273438e-01]
  [  9.22851562e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  5.30761719e-01]
  [  9.22851562e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]]
After layer attention_softmax_0 (20, 10, 1) <class 'numpy.float16'> [[[ 0.40307617]
  [ 0.59667969]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40307617]
  [ 0.59667969]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40332031]
  [ 0.59667969]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40307617]
  [ 0.59667969]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40356445]
  [ 0.59667969]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40307617]
  [ 0.59667969]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40307617]
  [ 0.59716797]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40307617]
  [ 0.59667969]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40380859]
  [ 0.59619141]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40380859]
  [ 0.59619141]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40356445]
  [ 0.59667969]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40405273]
  [ 0.59619141]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40307617]
  [ 0.59667969]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40454102]
  [ 0.59570312]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40307617]
  [ 0.59667969]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40307617]
  [ 0.59667969]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40307617]
  [ 0.59667969]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40380859]
  [ 0.59619141]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40307617]
  [ 0.59667969]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40307617]
  [ 0.59667969]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]]
After layer batch_dot15_0 (20, 512, 1) <class 'numpy.float16'> [[[ 0.01785278]
  [ 0.03942871]
  [-0.03341675]
  ...,
  [-0.01097107]
  [ 0.00998688]
  [-0.02461243]]

 [[ 0.01785278]
  [ 0.03942871]
  [-0.03341675]
  ...,
  [-0.01097107]
  [ 0.00998688]
  [-0.02461243]]

 [[ 0.01785278]
  [ 0.03945923]
  [-0.03341675]
  ...,
  [-0.01097107]
  [ 0.00999451]
  [-0.02462769]]

 ...,
 [[ 0.01783752]
  [ 0.03942871]
  [-0.03338623]
  ...,
  [-0.01097107]
  [ 0.00999451]
  [-0.02462769]]

 [[ 0.01785278]
  [ 0.03942871]
  [-0.03341675]
  ...,
  [-0.01097107]
  [ 0.00998688]
  [-0.02461243]]

 [[ 0.01785278]
  [ 0.03942871]
  [-0.03341675]
  ...,
  [-0.01097107]
  [ 0.00998688]
  [-0.02461243]]]
After layer reshape30_0 (20, 512) <class 'numpy.float16'> [[ 0.01785278  0.03942871 -0.03341675 ..., -0.01097107  0.00998688
  -0.02461243]
 [ 0.01785278  0.03942871 -0.03341675 ..., -0.01097107  0.00998688
  -0.02461243]
 [ 0.01785278  0.03945923 -0.03341675 ..., -0.01097107  0.00999451
  -0.02462769]
 ...,
 [ 0.01783752  0.03942871 -0.03338623 ..., -0.01097107  0.00999451
  -0.02462769]
 [ 0.01785278  0.03942871 -0.03341675 ..., -0.01097107  0.00998688
  -0.02461243]
 [ 0.01785278  0.03942871 -0.03341675 ..., -0.01097107  0.00998688
  -0.02461243]]
After layer decoder_rnn_hidden_concat_t0_output (20, 1024) <class 'numpy.float16'> [[-0.00120449 -0.91894531  0.1973877  ..., -0.01097107  0.00998688
  -0.02461243]
 [-0.00120449 -0.91894531  0.19775391 ..., -0.01097107  0.00998688
  -0.02461243]
 [-0.0012064  -0.91943359  0.19665527 ..., -0.01097107  0.00999451
  -0.02462769]
 ...,
 [-0.00121117 -0.92041016  0.1953125  ..., -0.01097107  0.00999451
  -0.02462769]
 [-0.00120354 -0.91894531  0.19677734 ..., -0.01097107  0.00998688
  -0.02461243]
 [-0.00120449 -0.91943359  0.19726562 ..., -0.01097107  0.00998688
  -0.02461243]]
After layer decoder_rnn_hidden_fc_t0_output (20, 512) <class 'numpy.float16'> [[-1.97070312  0.2109375  -0.81494141 ...,  1.98144531  2.11523438
  -1.59960938]
 [-1.97070312  0.21020508 -0.81494141 ...,  1.98144531  2.11523438
  -1.59960938]
 [-1.96777344  0.21337891 -0.81933594 ...,  1.97753906  2.11328125
  -1.60253906]
 ...,
 [-1.96582031  0.21850586 -0.828125   ...,  1.97265625  2.11132812
  -1.609375  ]
 [-1.97363281  0.21496582 -0.81982422 ...,  1.98144531  2.11328125
  -1.6015625 ]
 [-1.97167969  0.2121582  -0.81689453 ...,  1.98144531  2.11523438
  -1.60058594]]
After layer decoder_rnn_next_hidden_t0_output (20, 512) <class 'numpy.float16'> [[-0.96191406  0.20788574 -0.67236328 ...,  0.96289062  0.97119141
  -0.92138672]
 [-0.96191406  0.20715332 -0.67236328 ...,  0.96289062  0.97119141
  -0.92138672]
 [-0.96191406  0.21020508 -0.67480469 ...,  0.96240234  0.97119141
  -0.921875  ]
 ...,
 [-0.96142578  0.21508789 -0.6796875  ...,  0.96191406  0.97119141
  -0.92285156]
 [-0.96191406  0.21166992 -0.67480469 ...,  0.96289062  0.97119141
  -0.921875  ]
 [-0.96191406  0.20898438 -0.67333984 ...,  0.96289062  0.97119141
  -0.921875  ]]
After layer logits_output (20, 16743) <class 'numpy.float16'> [[-2.00976562 -2.82421875 -2.40625    ..., -2.09179688 -3.50195312
  -2.58398438]
 [-2.01171875 -2.82421875 -2.40625    ..., -2.09179688 -3.50195312
  -2.58398438]
 [-2.0078125  -2.82421875 -2.40625    ..., -2.09375    -3.5        -2.5859375 ]
 ...,
 [-2.0078125  -2.82617188 -2.40429688 ..., -2.09570312 -3.49804688
  -2.58789062]
 [-2.00976562 -2.82421875 -2.40625    ..., -2.09375    -3.5        -2.5859375 ]
 [-2.00976562 -2.82421875 -2.40625    ..., -2.09375    -3.50195312
  -2.5859375 ]]
After layer softmax_0 (20, 16743) <class 'numpy.float16'> [[  8.34465027e-07   3.57627869e-07   5.36441803e-07 ...,   7.74860382e-07
    1.78813934e-07   4.76837158e-07]
 [  8.34465027e-07   3.57627869e-07   5.36441803e-07 ...,   7.74860382e-07
    1.78813934e-07   4.76837158e-07]
 [  8.34465027e-07   3.57627869e-07   5.96046448e-07 ...,   7.74860382e-07
    1.78813934e-07   4.76837158e-07]
 ...,
 [  8.34465027e-07   3.57627869e-07   5.96046448e-07 ...,   7.74860382e-07
    1.78813934e-07   4.76837158e-07]
 [  8.34465027e-07   3.57627869e-07   5.96046448e-07 ...,   7.74860382e-07
    1.78813934e-07   4.76837158e-07]
 [  8.34465027e-07   3.57627869e-07   5.96046448e-07 ...,   7.74860382e-07
    1.78813934e-07   4.76837158e-07]]
After layer reshape31_0 (20, 10) <class 'numpy.float16'> [[ 0.40307617  0.59667969  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40307617  0.59667969  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40332031  0.59667969  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40307617  0.59667969  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40356445  0.59667969  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40307617  0.59667969  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40307617  0.59716797  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40307617  0.59667969  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40380859  0.59619141  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40380859  0.59619141  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40356445  0.59667969  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40405273  0.59619141  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40307617  0.59667969  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40454102  0.59570312  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40307617  0.59667969  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40307617  0.59667969  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40307617  0.59667969  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40380859  0.59619141  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40307617  0.59667969  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40307617  0.59667969  0.          0.          0.          0.          0.
   0.          0.          0.        ]]
After layer target_embed_embed_0 (20, 256) <class 'numpy.float16'> [[-0.05505371 -0.0300293  -0.03598022 ...,  0.08459473 -0.05288696
  -0.01667786]
 [-0.05505371 -0.0300293  -0.03598022 ...,  0.08459473 -0.05288696
  -0.01667786]
 [-0.05505371 -0.0300293  -0.03598022 ...,  0.08459473 -0.05288696
  -0.01667786]
 ...,
 [-0.05505371 -0.0300293  -0.03598022 ...,  0.08459473 -0.05288696
  -0.01667786]
 [-0.05505371 -0.0300293  -0.03598022 ...,  0.08459473 -0.05288696
  -0.01667786]
 [-0.05505371 -0.0300293  -0.03598022 ...,  0.08459473 -0.05288696
  -0.01667786]]
After layer decoder_rnn_concat_target_context_t0_output (20, 768) <class 'numpy.float16'> [[-0.05505371 -0.0300293  -0.03598022 ...,  0.96289062  0.97119141
  -0.92138672]
 [-0.05505371 -0.0300293  -0.03598022 ...,  0.96289062  0.97119141
  -0.92138672]
 [-0.05505371 -0.0300293  -0.03598022 ...,  0.96240234  0.97119141
  -0.921875  ]
 ...,
 [-0.05505371 -0.0300293  -0.03598022 ...,  0.96191406  0.97119141
  -0.92285156]
 [-0.05505371 -0.0300293  -0.03598022 ...,  0.96289062  0.97119141
  -0.921875  ]
 [-0.05505371 -0.0300293  -0.03598022 ...,  0.96289062  0.97119141
  -0.921875  ]]
After layer decoder_rnn_l0_t0_i2h_output (20, 2048) <class 'numpy.float16'> [[-3.1953125   1.60742188  2.43945312 ..., -0.07751465  3.86523438
   0.59667969]
 [-3.1953125   1.60742188  2.43945312 ..., -0.07739258  3.86523438
   0.59716797]
 [-3.19335938  1.60742188  2.43945312 ..., -0.0770874   3.86523438
   0.60009766]
 ...,
 [-3.19140625  1.60644531  2.44140625 ..., -0.07647705  3.86523438
   0.60449219]
 [-3.19335938  1.60644531  2.44140625 ..., -0.07666016  3.86328125
   0.59716797]
 [-3.19335938  1.60644531  2.43945312 ..., -0.0770874   3.86328125
   0.59716797]]
After layer decoder_rnn_l0_t0_h2h_output (20, 2048) <class 'numpy.float16'> [[-0.32202148  0.47192383  1.85351562 ...,  0.71044922  1.29589844
   0.17663574]
 [-0.32226562  0.47192383  1.85449219 ...,  0.71044922  1.29492188
   0.1763916 ]
 [-0.32446289  0.4777832   1.8515625  ...,  0.70947266  1.30175781
   0.17248535]
 ...,
 [-0.33129883  0.48779297  1.85058594 ...,  0.70703125  1.30566406
   0.16430664]
 [-0.32324219  0.47705078  1.85351562 ...,  0.70898438  1.29882812
   0.17211914]
 [-0.32299805  0.47436523  1.85351562 ...,  0.70947266  1.296875
   0.17431641]]
After layer _plus1060_0 (20, 2048) <class 'numpy.float16'> [[-3.51757812  2.08007812  4.29296875 ...,  0.6328125   5.16015625
   0.7734375 ]
 [-3.51757812  2.08007812  4.29296875 ...,  0.6328125   5.16015625
   0.7734375 ]
 [-3.51757812  2.0859375   4.2890625  ...,  0.63232422  5.16796875
   0.77246094]
 ...,
 [-3.5234375   2.09375     4.29296875 ...,  0.63037109  5.171875
   0.76855469]
 [-3.515625    2.08398438  4.296875   ...,  0.63232422  5.1640625
   0.76953125]
 [-3.515625    2.08007812  4.29296875 ...,  0.63232422  5.16015625
   0.77148438]]
After layer decoder_rnn_l0_t0_slice_output0 (20, 512) <class 'numpy.float16'> [[-3.51757812  2.08007812  4.29296875 ...,  1.73828125  4.61328125  2.78125   ]
 [-3.51757812  2.08007812  4.29296875 ...,  1.73828125  4.6171875   2.78125   ]
 [-3.51757812  2.0859375   4.2890625  ...,  1.7421875   4.609375    2.78125   ]
 ...,
 [-3.5234375   2.09375     4.29296875 ...,  1.74609375  4.6015625
   2.77929688]
 [-3.515625    2.08398438  4.296875   ...,  1.73828125  4.609375
   2.77929688]
 [-3.515625    2.08007812  4.29296875 ...,  1.73828125  4.61328125  2.78125   ]]
After layer decoder_rnn_l0_t0_slice_output1 (20, 512) <class 'numpy.float16'> [[-1.85546875  2.3203125   2.4375     ...,  3.16796875 -0.69091797
   1.98535156]
 [-1.85546875  2.3203125   2.4375     ...,  3.16796875 -0.69042969
   1.98535156]
 [-1.86035156  2.31835938  2.44140625 ...,  3.1640625  -0.69384766
   1.98242188]
 ...,
 [-1.86914062  2.31445312  2.44921875 ...,  3.15820312 -0.69335938
   1.98242188]
 [-1.85742188  2.32226562  2.43945312 ...,  3.1640625  -0.69042969
   1.984375  ]
 [-1.85644531  2.3203125   2.4375     ...,  3.1640625  -0.69091797
   1.984375  ]]
After layer decoder_rnn_l0_t0_slice_output2 (20, 512) <class 'numpy.float16'> [[-2.81640625 -3.08984375  2.8515625  ...,  4.265625   -0.08227539
   2.16015625]
 [-2.81640625 -3.08984375  2.8515625  ...,  4.265625   -0.08251953
   2.16015625]
 [-2.8203125  -3.09375     2.859375   ...,  4.2578125  -0.08569336
   2.16015625]
 ...,
 [-2.82226562 -3.1015625   2.87890625 ...,  4.25       -0.09350586  2.15625   ]
 [-2.81835938 -3.09570312  2.85546875 ...,  4.2578125  -0.0871582
   2.16015625]
 [-2.81640625 -3.09375     2.8515625  ...,  4.26171875 -0.0847168
   2.16015625]]
After layer decoder_rnn_l0_t0_slice_output3 (20, 512) <class 'numpy.float16'> [[-3.27539062  2.42773438 -1.40136719 ...,  0.6328125   5.16015625
   0.7734375 ]
 [-3.27539062  2.42773438 -1.40039062 ...,  0.6328125   5.16015625
   0.7734375 ]
 [-3.2734375   2.43554688 -1.40625    ...,  0.63232422  5.16796875
   0.77246094]
 ...,
 [-3.26757812  2.44335938 -1.41308594 ...,  0.63037109  5.171875
   0.76855469]
 [-3.27734375  2.42773438 -1.40527344 ...,  0.63232422  5.1640625
   0.76953125]
 [-3.27539062  2.4296875  -1.40234375 ...,  0.63232422  5.16015625
   0.77148438]]
After layer decoder_rnn_l0_t0_o_output (20, 512) <class 'numpy.float16'> [[ 0.03643799  0.91894531  0.19763184 ...,  0.65332031  0.99414062
   0.68408203]
 [ 0.03643799  0.91894531  0.19775391 ...,  0.65332031  0.99414062
   0.68408203]
 [ 0.03649902  0.91943359  0.19677734 ...,  0.65283203  0.99414062
   0.68408203]
 ...,
 [ 0.03671265  0.91992188  0.19580078 ...,  0.65234375  0.99414062
   0.68310547]
 [ 0.03634644  0.91894531  0.19702148 ...,  0.65283203  0.99414062
   0.68359375]
 [ 0.03643799  0.91894531  0.1973877  ...,  0.65283203  0.99414062
   0.68408203]]
After layer decoder_rnn_l0_t0_f_output (20, 512) <class 'numpy.float16'> [[ 0.13525391  0.91064453  0.91943359 ...,  0.95947266  0.33374023
   0.87939453]
 [ 0.13525391  0.91064453  0.91943359 ...,  0.95947266  0.33398438
   0.87939453]
 [ 0.13464355  0.91015625  0.91992188 ...,  0.95947266  0.33325195
   0.87890625]
 ...,
 [ 0.13366699  0.91015625  0.92041016 ...,  0.95947266  0.33325195
   0.87890625]
 [ 0.13500977  0.91064453  0.91992188 ...,  0.95947266  0.33398438
   0.87890625]
 [ 0.13513184  0.91064453  0.91943359 ...,  0.95947266  0.33374023
   0.87890625]]
After layer _mul2120_0 (20, 512) <class 'numpy.float16'> [[ -4.48226929e-03  -6.37109375e+00   7.42578125e+00 ...,   8.65625000e+00
   -4.03442383e-02   5.38281250e+00]
 [ -4.48226929e-03  -6.36718750e+00   7.39843750e+00 ...,   8.59375000e+00
   -4.06799316e-02   5.35156250e+00]
 [ -4.45175171e-03  -6.33593750e+00   7.42968750e+00 ...,   8.48437500e+00
   -4.21142578e-02   5.30078125e+00]
 ...,
 [ -4.40216064e-03  -6.14062500e+00   7.21093750e+00 ...,   8.10156250e+00
   -4.89501953e-02   4.91406250e+00]
 [ -4.47082520e-03  -6.36718750e+00   7.38671875e+00 ...,   8.53906250e+00
   -4.37927246e-02   5.30468750e+00]
 [ -4.47845459e-03  -6.37109375e+00   7.39843750e+00 ...,   8.53906250e+00
   -4.23278809e-02   5.32421875e+00]]
After layer decoder_rnn_l0_t0_i_output (20, 512) <class 'numpy.float16'> [[ 0.02880859  0.88916016  0.98632812 ...,  0.85058594  0.99023438
   0.94189453]
 [ 0.02880859  0.88916016  0.98632812 ...,  0.85058594  0.99023438
   0.94189453]
 [ 0.02880859  0.88964844  0.98632812 ...,  0.85107422  0.99023438
   0.94189453]
 ...,
 [ 0.02865601  0.89013672  0.98632812 ...,  0.8515625   0.99023438
   0.94140625]
 [ 0.02886963  0.88916016  0.98632812 ...,  0.85058594  0.99023438
   0.94140625]
 [ 0.02886963  0.88916016  0.98632812 ...,  0.85058594  0.99023438
   0.94189453]]
After layer decoder_rnn_l0_t0_c_output (20, 512) <class 'numpy.float16'> [[-0.99267578 -0.99609375  0.99316406 ...,  0.99951172 -0.08209229
   0.97363281]
 [-0.99267578 -0.99609375  0.99316406 ...,  0.99951172 -0.08233643
   0.97363281]
 [-0.99316406 -0.99609375  0.99365234 ...,  0.99951172 -0.08551025
   0.97363281]
 ...,
 [-0.99316406 -0.99609375  0.99365234 ...,  0.99951172 -0.09326172
   0.97363281]
 [-0.99267578 -0.99609375  0.99316406 ...,  0.99951172 -0.08691406
   0.97363281]
 [-0.99267578 -0.99609375  0.99316406 ...,  0.99951172 -0.08453369
   0.97363281]]
After layer _mul2121_0 (20, 512) <class 'numpy.float16'> [[-0.02859497 -0.88574219  0.97949219 ...,  0.85009766 -0.08129883
   0.91699219]
 [-0.02859497 -0.88574219  0.97949219 ...,  0.85009766 -0.08154297
   0.91699219]
 [-0.02861023 -0.88623047  0.97998047 ...,  0.85058594 -0.08465576
   0.91699219]
 ...,
 [-0.02845764 -0.88671875  0.97998047 ...,  0.85107422 -0.09234619
   0.91650391]
 [-0.02865601 -0.88574219  0.97949219 ...,  0.85009766 -0.08605957
   0.91650391]
 [-0.02865601 -0.88574219  0.97949219 ...,  0.85009766 -0.0836792
   0.91699219]]
After layer decoder_rnn_l0_t0_state_0 (20, 512) <class 'numpy.float16'> [[-0.03308105 -7.2578125   8.40625    ...,  9.5078125  -0.12164307
   6.30078125]
 [-0.03308105 -7.25390625  8.375      ...,  9.4453125  -0.12219238
   6.26953125]
 [-0.03305054 -7.22265625  8.40625    ...,  9.3359375  -0.12670898  6.21875   ]
 ...,
 [-0.03286743 -7.02734375  8.1875     ...,  8.953125   -0.14135742
   5.83203125]
 [-0.03314209 -7.25390625  8.3671875  ...,  9.390625   -0.12988281
   6.22265625]
 [-0.03314209 -7.2578125   8.375      ...,  9.390625   -0.12597656
   6.2421875 ]]
After layer activation1060_output (20, 512) <class 'numpy.float16'> [[-0.03308105 -1.          1.         ...,  1.         -0.12103271  1.        ]
 [-0.03308105 -1.          1.         ...,  1.         -0.12158203  1.        ]
 [-0.03305054 -1.          1.         ...,  1.         -0.12597656  1.        ]
 ...,
 [-0.03286743 -1.          1.         ...,  1.         -0.14038086  1.        ]
 [-0.03314209 -1.          1.         ...,  1.         -0.12915039  1.        ]
 [-0.03314209 -1.          1.         ...,  1.         -0.12536621  1.        ]]
After layer decoder_rnn_l0_t0_out_0 (20, 512) <class 'numpy.float16'> [[-0.00120544 -0.91894531  0.19763184 ...,  0.65332031 -0.12030029
   0.68408203]
 [-0.00120544 -0.91894531  0.19775391 ...,  0.65332031 -0.12084961
   0.68408203]
 [-0.0012064  -0.91943359  0.19677734 ...,  0.65283203 -0.12524414
   0.68408203]
 ...,
 [-0.0012064  -0.91992188  0.19580078 ...,  0.65234375 -0.13952637
   0.68310547]
 [-0.00120449 -0.91894531  0.19702148 ...,  0.65283203 -0.12841797
   0.68359375]
 [-0.00120735 -0.91894531  0.1973877  ...,  0.65283203 -0.12463379
   0.68408203]]
After layer expand_dims1069_0 (20, 512, 1) <class 'numpy.float16'> [[[-0.00120544]
  [-0.91894531]
  [ 0.19763184]
  ...,
  [ 0.65332031]
  [-0.12030029]
  [ 0.68408203]]

 [[-0.00120544]
  [-0.91894531]
  [ 0.19775391]
  ...,
  [ 0.65332031]
  [-0.12084961]
  [ 0.68408203]]

 [[-0.0012064 ]
  [-0.91943359]
  [ 0.19677734]
  ...,
  [ 0.65283203]
  [-0.12524414]
  [ 0.68408203]]

 ...,
 [[-0.0012064 ]
  [-0.91992188]
  [ 0.19580078]
  ...,
  [ 0.65234375]
  [-0.13952637]
  [ 0.68310547]]

 [[-0.00120449]
  [-0.91894531]
  [ 0.19702148]
  ...,
  [ 0.65283203]
  [-0.12841797]
  [ 0.68359375]]

 [[-0.00120735]
  [-0.91894531]
  [ 0.1973877 ]
  ...,
  [ 0.65283203]
  [-0.12463379]
  [ 0.68408203]]]
After layer att_batch_dot_0 (20, 10, 1) <class 'numpy.float16'> [[[ 0.53076172]
  [ 0.92333984]
  [ 1.63476562]
  [ 2.60351562]
  [ 2.52148438]
  [ 0.27490234]
  [-2.96289062]
  [-5.80859375]
  [-7.9453125 ]
  [-9.5546875 ]]

 [[ 0.53125   ]
  [ 0.92333984]
  [ 1.63476562]
  [ 2.60351562]
  [ 2.5234375 ]
  [ 0.27636719]
  [-2.9609375 ]
  [-5.8046875 ]
  [-7.9453125 ]
  [-9.546875  ]]

 [[ 0.52978516]
  [ 0.92138672]
  [ 1.62792969]
  [ 2.58984375]
  [ 2.49609375]
  [ 0.23400879]
  [-3.01953125]
  [-5.87890625]
  [-8.03125   ]
  [-9.640625  ]]

 [[ 0.53076172]
  [ 0.92382812]
  [ 1.63476562]
  [ 2.60351562]
  [ 2.5234375 ]
  [ 0.27416992]
  [-2.96679688]
  [-5.81640625]
  [-7.95703125]
  [-9.5625    ]]

 [[ 0.53027344]
  [ 0.921875  ]
  [ 1.62792969]
  [ 2.58789062]
  [ 2.48828125]
  [ 0.2130127 ]
  [-3.05664062]
  [-5.9296875 ]
  [-8.0859375 ]
  [-9.7109375 ]]

 [[ 0.53076172]
  [ 0.92333984]
  [ 1.63476562]
  [ 2.60351562]
  [ 2.52148438]
  [ 0.27392578]
  [-2.96484375]
  [-5.8125    ]
  [-7.953125  ]
  [-9.5546875 ]]

 [[ 0.52880859]
  [ 0.92138672]
  [ 1.62597656]
  [ 2.58398438]
  [ 2.484375  ]
  [ 0.20654297]
  [-3.0625    ]
  [-5.9375    ]
  [-8.09375   ]
  [-9.71875   ]]

 [[ 0.53125   ]
  [ 0.92333984]
  [ 1.63476562]
  [ 2.60351562]
  [ 2.5234375 ]
  [ 0.27856445]
  [-2.95703125]
  [-5.80078125]
  [-7.9375    ]
  [-9.5390625 ]]

 [[ 0.53271484]
  [ 0.92285156]
  [ 1.6328125 ]
  [ 2.59765625]
  [ 2.5078125 ]
  [ 0.2434082 ]
  [-3.01367188]
  [-5.875     ]
  [-8.0234375 ]
  [-9.6328125 ]]

 [[ 0.52832031]
  [ 0.91894531]
  [ 1.61914062]
  [ 2.5703125 ]
  [ 2.45898438]
  [ 0.16882324]
  [-3.11132812]
  [-5.9921875 ]
  [-8.15625   ]
  [-9.78125   ]]

 [[ 0.53076172]
  [ 0.92138672]
  [ 1.62890625]
  [ 2.59179688]
  [ 2.5       ]
  [ 0.24157715]
  [-3.0078125 ]
  [-5.86328125]
  [-8.0078125 ]
  [-9.6171875 ]]

 [[ 0.52929688]
  [ 0.91894531]
  [ 1.61914062]
  [ 2.5703125 ]
  [ 2.45898438]
  [ 0.16601562]
  [-3.1171875 ]
  [-6.00390625]
  [-8.171875  ]
  [-9.796875  ]]

 [[ 0.52978516]
  [ 0.91796875]
  [ 1.61914062]
  [ 2.57226562]
  [ 2.45898438]
  [ 0.16809082]
  [-3.11523438]
  [-6.        ]
  [-8.1640625 ]
  [-9.7890625 ]]

 [[ 0.53076172]
  [ 0.92333984]
  [ 1.63476562]
  [ 2.60351562]
  [ 2.5234375 ]
  [ 0.27685547]
  [-2.9609375 ]
  [-5.8046875 ]
  [-7.9453125 ]
  [-9.546875  ]]

 [[ 0.53125   ]
  [ 0.92333984]
  [ 1.63476562]
  [ 2.60351562]
  [ 2.5234375 ]
  [ 0.27563477]
  [-2.96289062]
  [-5.80859375]
  [-7.9453125 ]
  [-9.5546875 ]]

 [[ 0.53076172]
  [ 0.92333984]
  [ 1.63476562]
  [ 2.60351562]
  [ 2.52148438]
  [ 0.27368164]
  [-2.96679688]
  [-5.8125    ]
  [-7.953125  ]
  [-9.5546875 ]]

 [[ 0.53076172]
  [ 0.92333984]
  [ 1.63476562]
  [ 2.60351562]
  [ 2.51953125]
  [ 0.26928711]
  [-2.97460938]
  [-5.82421875]
  [-7.96484375]
  [-9.5703125 ]]

 [[ 0.52929688]
  [ 0.91992188]
  [ 1.62304688]
  [ 2.578125  ]
  [ 2.46875   ]
  [ 0.18017578]
  [-3.1015625 ]
  [-5.984375  ]
  [-8.15625   ]
  [-9.78125   ]]

 [[ 0.53027344]
  [ 0.92333984]
  [ 1.63378906]
  [ 2.6015625 ]
  [ 2.51757812]
  [ 0.26245117]
  [-2.984375  ]
  [-5.83984375]
  [-7.984375  ]
  [-9.59375   ]]

 [[ 0.53076172]
  [ 0.92333984]
  [ 1.63476562]
  [ 2.60351562]
  [ 2.52148438]
  [ 0.27026367]
  [-2.97070312]
  [-5.8203125 ]
  [-7.9609375 ]
  [-9.5703125 ]]]
After layer swapaxes41_output (10, 20, 1) <class 'numpy.float16'> [[[ 0.53076172]
  [ 0.53125   ]
  [ 0.52978516]
  [ 0.53076172]
  [ 0.53027344]
  [ 0.53076172]
  [ 0.52880859]
  [ 0.53125   ]
  [ 0.53271484]
  [ 0.52832031]
  [ 0.53076172]
  [ 0.52929688]
  [ 0.52978516]
  [ 0.53076172]
  [ 0.53125   ]
  [ 0.53076172]
  [ 0.53076172]
  [ 0.52929688]
  [ 0.53027344]
  [ 0.53076172]]

 [[ 0.92333984]
  [ 0.92333984]
  [ 0.92138672]
  [ 0.92382812]
  [ 0.921875  ]
  [ 0.92333984]
  [ 0.92138672]
  [ 0.92333984]
  [ 0.92285156]
  [ 0.91894531]
  [ 0.92138672]
  [ 0.91894531]
  [ 0.91796875]
  [ 0.92333984]
  [ 0.92333984]
  [ 0.92333984]
  [ 0.92333984]
  [ 0.91992188]
  [ 0.92333984]
  [ 0.92333984]]

 [[ 1.63476562]
  [ 1.63476562]
  [ 1.62792969]
  [ 1.63476562]
  [ 1.62792969]
  [ 1.63476562]
  [ 1.62597656]
  [ 1.63476562]
  [ 1.6328125 ]
  [ 1.61914062]
  [ 1.62890625]
  [ 1.61914062]
  [ 1.61914062]
  [ 1.63476562]
  [ 1.63476562]
  [ 1.63476562]
  [ 1.63476562]
  [ 1.62304688]
  [ 1.63378906]
  [ 1.63476562]]

 [[ 2.60351562]
  [ 2.60351562]
  [ 2.58984375]
  [ 2.60351562]
  [ 2.58789062]
  [ 2.60351562]
  [ 2.58398438]
  [ 2.60351562]
  [ 2.59765625]
  [ 2.5703125 ]
  [ 2.59179688]
  [ 2.5703125 ]
  [ 2.57226562]
  [ 2.60351562]
  [ 2.60351562]
  [ 2.60351562]
  [ 2.60351562]
  [ 2.578125  ]
  [ 2.6015625 ]
  [ 2.60351562]]

 [[ 2.52148438]
  [ 2.5234375 ]
  [ 2.49609375]
  [ 2.5234375 ]
  [ 2.48828125]
  [ 2.52148438]
  [ 2.484375  ]
  [ 2.5234375 ]
  [ 2.5078125 ]
  [ 2.45898438]
  [ 2.5       ]
  [ 2.45898438]
  [ 2.45898438]
  [ 2.5234375 ]
  [ 2.5234375 ]
  [ 2.52148438]
  [ 2.51953125]
  [ 2.46875   ]
  [ 2.51757812]
  [ 2.52148438]]

 [[ 0.27490234]
  [ 0.27636719]
  [ 0.23400879]
  [ 0.27416992]
  [ 0.2130127 ]
  [ 0.27392578]
  [ 0.20654297]
  [ 0.27856445]
  [ 0.2434082 ]
  [ 0.16882324]
  [ 0.24157715]
  [ 0.16601562]
  [ 0.16809082]
  [ 0.27685547]
  [ 0.27563477]
  [ 0.27368164]
  [ 0.26928711]
  [ 0.18017578]
  [ 0.26245117]
  [ 0.27026367]]

 [[-2.96289062]
  [-2.9609375 ]
  [-3.01953125]
  [-2.96679688]
  [-3.05664062]
  [-2.96484375]
  [-3.0625    ]
  [-2.95703125]
  [-3.01367188]
  [-3.11132812]
  [-3.0078125 ]
  [-3.1171875 ]
  [-3.11523438]
  [-2.9609375 ]
  [-2.96289062]
  [-2.96679688]
  [-2.97460938]
  [-3.1015625 ]
  [-2.984375  ]
  [-2.97070312]]

 [[-5.80859375]
  [-5.8046875 ]
  [-5.87890625]
  [-5.81640625]
  [-5.9296875 ]
  [-5.8125    ]
  [-5.9375    ]
  [-5.80078125]
  [-5.875     ]
  [-5.9921875 ]
  [-5.86328125]
  [-6.00390625]
  [-6.        ]
  [-5.8046875 ]
  [-5.80859375]
  [-5.8125    ]
  [-5.82421875]
  [-5.984375  ]
  [-5.83984375]
  [-5.8203125 ]]

 [[-7.9453125 ]
  [-7.9453125 ]
  [-8.03125   ]
  [-7.95703125]
  [-8.0859375 ]
  [-7.953125  ]
  [-8.09375   ]
  [-7.9375    ]
  [-8.0234375 ]
  [-8.15625   ]
  [-8.0078125 ]
  [-8.171875  ]
  [-8.1640625 ]
  [-7.9453125 ]
  [-7.9453125 ]
  [-7.953125  ]
  [-7.96484375]
  [-8.15625   ]
  [-7.984375  ]
  [-7.9609375 ]]

 [[-9.5546875 ]
  [-9.546875  ]
  [-9.640625  ]
  [-9.5625    ]
  [-9.7109375 ]
  [-9.5546875 ]
  [-9.71875   ]
  [-9.5390625 ]
  [-9.6328125 ]
  [-9.78125   ]
  [-9.6171875 ]
  [-9.796875  ]
  [-9.7890625 ]
  [-9.546875  ]
  [-9.5546875 ]
  [-9.5546875 ]
  [-9.5703125 ]
  [-9.78125   ]
  [-9.59375   ]
  [-9.5703125 ]]]
After layer sequencemask16_output (10, 20, 1) <class 'numpy.float16'> [[[  5.30761719e-01]
  [  5.31250000e-01]
  [  5.29785156e-01]
  [  5.30761719e-01]
  [  5.30273438e-01]
  [  5.30761719e-01]
  [  5.28808594e-01]
  [  5.31250000e-01]
  [  5.32714844e-01]
  [  5.28320312e-01]
  [  5.30761719e-01]
  [  5.29296875e-01]
  [  5.29785156e-01]
  [  5.30761719e-01]
  [  5.31250000e-01]
  [  5.30761719e-01]
  [  5.30761719e-01]
  [  5.29296875e-01]
  [  5.30273438e-01]
  [  5.30761719e-01]]

 [[  9.23339844e-01]
  [  9.23339844e-01]
  [  9.21386719e-01]
  [  9.23828125e-01]
  [  9.21875000e-01]
  [  9.23339844e-01]
  [  9.21386719e-01]
  [  9.23339844e-01]
  [  9.22851562e-01]
  [  9.18945312e-01]
  [  9.21386719e-01]
  [  9.18945312e-01]
  [  9.17968750e-01]
  [  9.23339844e-01]
  [  9.23339844e-01]
  [  9.23339844e-01]
  [  9.23339844e-01]
  [  9.19921875e-01]
  [  9.23339844e-01]
  [  9.23339844e-01]]

 [[ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]]
After layer swapaxes42_output (20, 10, 1) <class 'numpy.float16'> [[[  5.30761719e-01]
  [  9.23339844e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  5.31250000e-01]
  [  9.23339844e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  5.29785156e-01]
  [  9.21386719e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  5.30761719e-01]
  [  9.23828125e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  5.30273438e-01]
  [  9.21875000e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  5.30761719e-01]
  [  9.23339844e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  5.28808594e-01]
  [  9.21386719e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  5.31250000e-01]
  [  9.23339844e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  5.32714844e-01]
  [  9.22851562e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  5.28320312e-01]
  [  9.18945312e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  5.30761719e-01]
  [  9.21386719e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  5.29296875e-01]
  [  9.18945312e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  5.29785156e-01]
  [  9.17968750e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  5.30761719e-01]
  [  9.23339844e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  5.31250000e-01]
  [  9.23339844e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  5.30761719e-01]
  [  9.23339844e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  5.30761719e-01]
  [  9.23339844e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  5.29296875e-01]
  [  9.19921875e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  5.30273438e-01]
  [  9.23339844e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  5.30761719e-01]
  [  9.23339844e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]]
After layer attention_softmax_0 (20, 10, 1) <class 'numpy.float16'> [[[ 0.40307617]
  [ 0.59667969]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40307617]
  [ 0.59667969]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40332031]
  [ 0.59667969]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40307617]
  [ 0.59716797]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40332031]
  [ 0.59667969]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40307617]
  [ 0.59667969]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40307617]
  [ 0.59667969]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40307617]
  [ 0.59667969]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40380859]
  [ 0.59619141]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40356445]
  [ 0.59619141]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40356445]
  [ 0.59619141]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40380859]
  [ 0.59619141]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40429688]
  [ 0.59619141]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40307617]
  [ 0.59667969]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40307617]
  [ 0.59667969]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40307617]
  [ 0.59667969]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40307617]
  [ 0.59667969]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40356445]
  [ 0.59619141]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40307617]
  [ 0.59716797]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40307617]
  [ 0.59667969]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]]
After layer batch_dot16_0 (20, 512, 1) <class 'numpy.float16'> [[[ 0.01785278]
  [ 0.03942871]
  [-0.03341675]
  ...,
  [-0.01097107]
  [ 0.00998688]
  [-0.02461243]]

 [[ 0.01785278]
  [ 0.03942871]
  [-0.03341675]
  ...,
  [-0.01097107]
  [ 0.00998688]
  [-0.02461243]]

 [[ 0.01785278]
  [ 0.03945923]
  [-0.03341675]
  ...,
  [-0.01097107]
  [ 0.00999451]
  [-0.02462769]]

 ...,
 [[ 0.01783752]
  [ 0.03942871]
  [-0.03338623]
  ...,
  [-0.01096344]
  [ 0.00998688]
  [-0.02462769]]

 [[ 0.01786804]
  [ 0.03945923]
  [-0.03341675]
  ...,
  [-0.0109787 ]
  [ 0.00999451]
  [-0.02462769]]

 [[ 0.01785278]
  [ 0.03942871]
  [-0.03341675]
  ...,
  [-0.01097107]
  [ 0.00998688]
  [-0.02461243]]]
After layer reshape32_0 (20, 512) <class 'numpy.float16'> [[ 0.01785278  0.03942871 -0.03341675 ..., -0.01097107  0.00998688
  -0.02461243]
 [ 0.01785278  0.03942871 -0.03341675 ..., -0.01097107  0.00998688
  -0.02461243]
 [ 0.01785278  0.03945923 -0.03341675 ..., -0.01097107  0.00999451
  -0.02462769]
 ...,
 [ 0.01783752  0.03942871 -0.03338623 ..., -0.01096344  0.00998688
  -0.02462769]
 [ 0.01786804  0.03945923 -0.03341675 ..., -0.0109787   0.00999451
  -0.02462769]
 [ 0.01785278  0.03942871 -0.03341675 ..., -0.01097107  0.00998688
  -0.02461243]]
After layer decoder_rnn_hidden_concat_t0_output (20, 1024) <class 'numpy.float16'> [[-0.00120544 -0.91894531  0.19763184 ..., -0.01097107  0.00998688
  -0.02461243]
 [-0.00120544 -0.91894531  0.19775391 ..., -0.01097107  0.00998688
  -0.02461243]
 [-0.0012064  -0.91943359  0.19677734 ..., -0.01097107  0.00999451
  -0.02462769]
 ...,
 [-0.0012064  -0.91992188  0.19580078 ..., -0.01096344  0.00998688
  -0.02462769]
 [-0.00120449 -0.91894531  0.19702148 ..., -0.0109787   0.00999451
  -0.02462769]
 [-0.00120735 -0.91894531  0.1973877  ..., -0.01097107  0.00998688
  -0.02461243]]
After layer decoder_rnn_hidden_fc_t0_output (20, 512) <class 'numpy.float16'> [[-1.97265625  0.2121582  -0.81640625 ...,  1.98242188  2.1171875
  -1.6015625 ]
 [-1.97265625  0.21154785 -0.81640625 ...,  1.98242188  2.1171875
  -1.6015625 ]
 [-1.97070312  0.21472168 -0.8203125  ...,  1.97949219  2.11523438
  -1.60351562]
 ...,
 [-1.96875     0.21911621 -0.828125   ...,  1.97558594  2.11328125
  -1.61035156]
 [-1.97460938  0.21582031 -0.82080078 ...,  1.98242188  2.11523438
  -1.60253906]
 [-1.97363281  0.21337891 -0.81787109 ...,  1.98242188  2.1171875
  -1.6015625 ]]
After layer decoder_rnn_next_hidden_t0_output (20, 512) <class 'numpy.float16'> [[-0.96191406  0.20898438 -0.67333984 ...,  0.96289062  0.97167969
  -0.921875  ]
 [-0.96191406  0.20849609 -0.67333984 ...,  0.96289062  0.97167969
  -0.921875  ]
 [-0.96191406  0.21142578 -0.67529297 ...,  0.96240234  0.97119141
  -0.92236328]
 ...,
 [-0.96191406  0.21569824 -0.6796875  ...,  0.96240234  0.97119141
  -0.92333984]
 [-0.96240234  0.21252441 -0.67529297 ...,  0.96289062  0.97119141
  -0.921875  ]
 [-0.96191406  0.21020508 -0.67382812 ...,  0.96289062  0.97167969
  -0.921875  ]]
After layer logits_output (20, 16743) <class 'numpy.float16'> [[-2.01171875 -2.82421875 -2.40625    ..., -2.09375    -3.50195312
  -2.5859375 ]
 [-2.01171875 -2.82421875 -2.40625    ..., -2.09179688 -3.50195312
  -2.5859375 ]
 [-2.00976562 -2.82421875 -2.40625    ..., -2.09375    -3.50195312
  -2.58789062]
 ...,
 [-2.00976562 -2.82617188 -2.40429688 ..., -2.09570312 -3.49804688
  -2.58984375]
 [-2.01171875 -2.82421875 -2.40625    ..., -2.09375    -3.5        -2.58789062]
 [-2.01171875 -2.82421875 -2.40625    ..., -2.09375    -3.50195312
  -2.5859375 ]]
After layer softmax_0 (20, 16743) <class 'numpy.float16'> [[  8.34465027e-07   3.57627869e-07   5.36441803e-07 ...,   7.74860382e-07
    1.78813934e-07   4.76837158e-07]
 [  8.34465027e-07   3.57627869e-07   5.36441803e-07 ...,   7.74860382e-07
    1.78813934e-07   4.76837158e-07]
 [  8.34465027e-07   3.57627869e-07   5.96046448e-07 ...,   7.74860382e-07
    1.78813934e-07   4.76837158e-07]
 ...,
 [  8.34465027e-07   3.57627869e-07   5.96046448e-07 ...,   7.74860382e-07
    1.78813934e-07   4.76837158e-07]
 [  8.34465027e-07   3.57627869e-07   5.96046448e-07 ...,   7.74860382e-07
    1.78813934e-07   4.76837158e-07]
 [  8.34465027e-07   3.57627869e-07   5.96046448e-07 ...,   7.74860382e-07
    1.78813934e-07   4.76837158e-07]]
After layer reshape33_0 (20, 10) <class 'numpy.float16'> [[ 0.40307617  0.59667969  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40307617  0.59667969  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40332031  0.59667969  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40307617  0.59716797  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40332031  0.59667969  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40307617  0.59667969  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40307617  0.59667969  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40307617  0.59667969  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40380859  0.59619141  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40356445  0.59619141  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40356445  0.59619141  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40380859  0.59619141  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40429688  0.59619141  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40307617  0.59667969  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40307617  0.59667969  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40307617  0.59667969  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40307617  0.59667969  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40356445  0.59619141  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40307617  0.59716797  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40307617  0.59667969  0.          0.          0.          0.          0.
   0.          0.          0.        ]]
After layer target_embed_embed_0 (20, 256) <class 'numpy.float16'> [[-0.05505371 -0.0300293  -0.03598022 ...,  0.08459473 -0.05288696
  -0.01667786]
 [-0.05505371 -0.0300293  -0.03598022 ...,  0.08459473 -0.05288696
  -0.01667786]
 [-0.05505371 -0.0300293  -0.03598022 ...,  0.08459473 -0.05288696
  -0.01667786]
 ...,
 [-0.05505371 -0.0300293  -0.03598022 ...,  0.08459473 -0.05288696
  -0.01667786]
 [-0.05505371 -0.0300293  -0.03598022 ...,  0.08459473 -0.05288696
  -0.01667786]
 [-0.05505371 -0.0300293  -0.03598022 ...,  0.08459473 -0.05288696
  -0.01667786]]
After layer decoder_rnn_concat_target_context_t0_output (20, 768) <class 'numpy.float16'> [[-0.05505371 -0.0300293  -0.03598022 ...,  0.96289062  0.97167969
  -0.921875  ]
 [-0.05505371 -0.0300293  -0.03598022 ...,  0.96289062  0.97167969
  -0.921875  ]
 [-0.05505371 -0.0300293  -0.03598022 ...,  0.96240234  0.97119141
  -0.92236328]
 ...,
 [-0.05505371 -0.0300293  -0.03598022 ...,  0.96240234  0.97119141
  -0.92333984]
 [-0.05505371 -0.0300293  -0.03598022 ...,  0.96289062  0.97119141
  -0.921875  ]
 [-0.05505371 -0.0300293  -0.03598022 ...,  0.96289062  0.97167969
  -0.921875  ]]
After layer decoder_rnn_l0_t0_i2h_output (20, 2048) <class 'numpy.float16'> [[-3.1953125   1.60742188  2.44140625 ..., -0.07739258  3.86523438
   0.59619141]
 [-3.1953125   1.60742188  2.44140625 ..., -0.07727051  3.86523438
   0.59667969]
 [-3.19335938  1.60644531  2.44140625 ..., -0.07678223  3.86523438
   0.59912109]
 ...,
 [-3.19140625  1.60546875  2.44335938 ..., -0.07641602  3.86523438
   0.60351562]
 [-3.19335938  1.60644531  2.44140625 ..., -0.07647705  3.86523438
   0.59667969]
 [-3.1953125   1.60644531  2.44140625 ..., -0.07702637  3.86523438
   0.59716797]]
After layer decoder_rnn_l0_t0_h2h_output (20, 2048) <class 'numpy.float16'> [[-0.32226562  0.47192383  1.85644531 ...,  0.71142578  1.29589844
   0.17663574]
 [-0.32275391  0.47192383  1.85644531 ...,  0.71142578  1.29492188
   0.17651367]
 [-0.32421875  0.47705078  1.85351562 ...,  0.7109375   1.30078125
   0.17260742]
 ...,
 [-0.33032227  0.48632812  1.85351562 ...,  0.70947266  1.30566406
   0.16540527]
 [-0.32324219  0.47631836  1.85449219 ...,  0.7109375   1.29882812
   0.17285156]
 [-0.32299805  0.47387695  1.85546875 ...,  0.7109375   1.296875
   0.17492676]]
After layer _plus1061_0 (20, 2048) <class 'numpy.float16'> [[-3.51757812  2.08007812  4.296875   ...,  0.63378906  5.16015625
   0.77294922]
 [-3.51757812  2.08007812  4.296875   ...,  0.63427734  5.16015625
   0.7734375 ]
 [-3.51757812  2.08398438  4.296875   ...,  0.63427734  5.1640625
   0.77148438]
 ...,
 [-3.52148438  2.09179688  4.296875   ...,  0.6328125   5.171875
   0.76904297]
 [-3.515625    2.08203125  4.296875   ...,  0.63427734  5.1640625
   0.76953125]
 [-3.51757812  2.08007812  4.296875   ...,  0.63378906  5.1640625
   0.77197266]]
After layer decoder_rnn_l0_t0_slice_output0 (20, 512) <class 'numpy.float16'> [[-3.51757812  2.08007812  4.296875   ...,  1.73828125  4.6171875   2.78125   ]
 [-3.51757812  2.08007812  4.296875   ...,  1.73828125  4.6171875   2.78125   ]
 [-3.51757812  2.08398438  4.296875   ...,  1.7421875   4.609375    2.78125   ]
 ...,
 [-3.52148438  2.09179688  4.296875   ...,  1.74609375  4.609375
   2.77929688]
 [-3.515625    2.08203125  4.296875   ...,  1.73828125  4.61328125
   2.77929688]
 [-3.51757812  2.08007812  4.296875   ...,  1.73828125  4.6171875   2.78125   ]]
After layer decoder_rnn_l0_t0_slice_output1 (20, 512) <class 'numpy.float16'> [[-1.85351562  2.32226562  2.43945312 ...,  3.16796875 -0.68994141
   1.98828125]
 [-1.85351562  2.32226562  2.43945312 ...,  3.16796875 -0.68847656
   1.98828125]
 [-1.85839844  2.3203125   2.44140625 ...,  3.1640625  -0.69140625
   1.984375  ]
 ...,
 [-1.86621094  2.31445312  2.453125   ...,  3.16015625 -0.69091797
   1.984375  ]
 [-1.85742188  2.32226562  2.44140625 ...,  3.1640625  -0.68896484
   1.98632812]
 [-1.85449219  2.3203125   2.44140625 ...,  3.16796875 -0.68945312
   1.98730469]]
After layer decoder_rnn_l0_t0_slice_output2 (20, 512) <class 'numpy.float16'> [[-2.81640625 -3.09375     2.8515625  ...,  4.265625   -0.08251953
   2.16015625]
 [-2.81640625 -3.09375     2.8515625  ...,  4.265625   -0.08276367
   2.16015625]
 [-2.8203125  -3.09375     2.859375   ...,  4.2578125  -0.08544922
   2.16015625]
 ...,
 [-2.8203125  -3.10351562  2.87890625 ...,  4.25       -0.09155273  2.15625   ]
 [-2.81640625 -3.09765625  2.85546875 ...,  4.2578125  -0.08618164
   2.16015625]
 [-2.81640625 -3.09570312  2.85351562 ...,  4.26171875 -0.08422852
   2.16015625]]
After layer decoder_rnn_l0_t0_slice_output3 (20, 512) <class 'numpy.float16'> [[-3.27734375  2.42578125 -1.40136719 ...,  0.63378906  5.16015625
   0.77294922]
 [-3.27734375  2.42578125 -1.40039062 ...,  0.63427734  5.16015625
   0.7734375 ]
 [-3.2734375   2.4296875  -1.40527344 ...,  0.63427734  5.1640625
   0.77148438]
 ...,
 [-3.26757812  2.43945312 -1.41113281 ...,  0.6328125   5.171875
   0.76904297]
 [-3.27734375  2.42578125 -1.40429688 ...,  0.63427734  5.1640625
   0.76953125]
 [-3.27734375  2.42773438 -1.40234375 ...,  0.63378906  5.1640625
   0.77197266]]
After layer decoder_rnn_l0_t0_o_output (20, 512) <class 'numpy.float16'> [[ 0.03634644  0.91894531  0.19763184 ...,  0.65332031  0.99414062
   0.68408203]
 [ 0.03634644  0.91894531  0.19775391 ...,  0.65332031  0.99414062
   0.68408203]
 [ 0.03649902  0.91894531  0.19702148 ...,  0.65332031  0.99414062
   0.68408203]
 ...,
 [ 0.03671265  0.91992188  0.19604492 ...,  0.65332031  0.99414062
   0.68310547]
 [ 0.03634644  0.91894531  0.19714355 ...,  0.65332031  0.99414062
   0.68359375]
 [ 0.03634644  0.91894531  0.1973877  ...,  0.65332031  0.99414062
   0.68408203]]
After layer decoder_rnn_l0_t0_f_output (20, 512) <class 'numpy.float16'> [[ 0.13549805  0.91064453  0.91992188 ...,  0.95947266  0.33398438
   0.87939453]
 [ 0.13549805  0.91064453  0.91992188 ...,  0.95947266  0.33447266
   0.87939453]
 [ 0.1348877   0.91064453  0.91992188 ...,  0.95947266  0.33374023
   0.87890625]
 ...,
 [ 0.1340332   0.91015625  0.92089844 ...,  0.95947266  0.33374023
   0.87890625]
 [ 0.13500977  0.91064453  0.91992188 ...,  0.95947266  0.33422852
   0.87939453]
 [ 0.13537598  0.91064453  0.91992188 ...,  0.95947266  0.33422852
   0.87939453]]
After layer _mul2122_0 (20, 512) <class 'numpy.float16'> [[ -4.48226929e-03  -6.60937500e+00   7.73437500e+00 ...,   9.12500000e+00
   -4.06188965e-02   5.53906250e+00]
 [ -4.48226929e-03  -6.60546875e+00   7.70312500e+00 ...,   9.06250000e+00
   -4.08630371e-02   5.51171875e+00]
 [ -4.45938110e-03  -6.57812500e+00   7.73437500e+00 ...,   8.96093750e+00
   -4.22973633e-02   5.46484375e+00]
 ...,
 [ -4.40597534e-03  -6.39453125e+00   7.53906250e+00 ...,   8.59375000e+00
   -4.71801758e-02   5.12500000e+00]
 [ -4.47463989e-03  -6.60546875e+00   7.69531250e+00 ...,   9.00781250e+00
   -4.33959961e-02   5.47265625e+00]
 [ -4.48608398e-03  -6.60937500e+00   7.70312500e+00 ...,   9.00781250e+00
   -4.21142578e-02   5.48828125e+00]]
After layer decoder_rnn_l0_t0_i_output (20, 512) <class 'numpy.float16'> [[ 0.02880859  0.88916016  0.98632812 ...,  0.85058594  0.99023438
   0.94189453]
 [ 0.02880859  0.88916016  0.98632812 ...,  0.85058594  0.99023438
   0.94189453]
 [ 0.02880859  0.88916016  0.98632812 ...,  0.85107422  0.99023438
   0.94189453]
 ...,
 [ 0.02870178  0.89013672  0.98632812 ...,  0.8515625   0.99023438
   0.94140625]
 [ 0.02886963  0.88916016  0.98632812 ...,  0.85058594  0.99023438
   0.94140625]
 [ 0.02880859  0.88916016  0.98632812 ...,  0.85058594  0.99023438
   0.94189453]]
After layer decoder_rnn_l0_t0_c_output (20, 512) <class 'numpy.float16'> [[-0.99267578 -0.99609375  0.99316406 ...,  0.99951172 -0.08233643
   0.97363281]
 [-0.99267578 -0.99609375  0.99316406 ...,  0.99951172 -0.08258057
   0.97363281]
 [-0.99316406 -0.99609375  0.99365234 ...,  0.99951172 -0.08526611
   0.97363281]
 ...,
 [-0.99316406 -0.99609375  0.99365234 ...,  0.99951172 -0.09130859
   0.97363281]
 [-0.99267578 -0.99609375  0.99316406 ...,  0.99951172 -0.08599854
   0.97363281]
 [-0.99267578 -0.99609375  0.99316406 ...,  0.99951172 -0.08404541
   0.97363281]]
After layer _mul2123_0 (20, 512) <class 'numpy.float16'> [[-0.02859497 -0.88574219  0.97949219 ...,  0.85009766 -0.08154297
   0.91699219]
 [-0.02859497 -0.88574219  0.97949219 ...,  0.85009766 -0.08178711
   0.91699219]
 [-0.02861023 -0.88574219  0.97998047 ...,  0.85058594 -0.08441162
   0.91699219]
 ...,
 [-0.02850342 -0.88671875  0.97998047 ...,  0.85107422 -0.09039307
   0.91650391]
 [-0.02865601 -0.88574219  0.97949219 ...,  0.85009766 -0.08514404
   0.91650391]
 [-0.02859497 -0.88574219  0.97949219 ...,  0.85009766 -0.08325195
   0.91699219]]
After layer decoder_rnn_l0_t0_state_0 (20, 512) <class 'numpy.float16'> [[-0.03308105 -7.49609375  8.7109375  ...,  9.9765625  -0.12219238
   6.45703125]
 [-0.03308105 -7.4921875   8.6796875  ...,  9.9140625  -0.12268066
   6.4296875 ]
 [-0.03308105 -7.46484375  8.7109375  ...,  9.8125     -0.12670898
   6.3828125 ]
 ...,
 [-0.03289795 -7.28125     8.515625   ...,  9.4453125  -0.13757324
   6.04296875]
 [-0.03314209 -7.4921875   8.671875   ...,  9.859375   -0.12854004
   6.390625  ]
 [-0.03308105 -7.49609375  8.6796875  ...,  9.859375   -0.12536621  6.40625   ]]
After layer activation1061_output (20, 512) <class 'numpy.float16'> [[-0.03308105 -1.          1.         ...,  1.         -0.12158203  1.        ]
 [-0.03308105 -1.          1.         ...,  1.         -0.12207031  1.        ]
 [-0.03308105 -1.          1.         ...,  1.         -0.12597656  1.        ]
 ...,
 [-0.03289795 -1.          1.         ...,  1.         -0.13671875  1.        ]
 [-0.03314209 -1.          1.         ...,  1.         -0.12780762  1.        ]
 [-0.03308105 -1.          1.         ...,  1.         -0.12469482  1.        ]]
After layer decoder_rnn_l0_t0_out_0 (20, 512) <class 'numpy.float16'> [[-0.00120258 -0.91894531  0.19763184 ...,  0.65332031 -0.12084961
   0.68408203]
 [-0.00120258 -0.91894531  0.19775391 ...,  0.65332031 -0.12133789
   0.68408203]
 [-0.00120735 -0.91894531  0.19702148 ...,  0.65332031 -0.12524414
   0.68408203]
 ...,
 [-0.00120735 -0.91992188  0.19604492 ...,  0.65332031 -0.13586426
   0.68310547]
 [-0.00120449 -0.91894531  0.19714355 ...,  0.65332031 -0.1270752
   0.68359375]
 [-0.00120258 -0.91894531  0.1973877  ...,  0.65332031 -0.1239624
   0.68408203]]
After layer expand_dims1070_0 (20, 512, 1) <class 'numpy.float16'> [[[-0.00120258]
  [-0.91894531]
  [ 0.19763184]
  ...,
  [ 0.65332031]
  [-0.12084961]
  [ 0.68408203]]

 [[-0.00120258]
  [-0.91894531]
  [ 0.19775391]
  ...,
  [ 0.65332031]
  [-0.12133789]
  [ 0.68408203]]

 [[-0.00120735]
  [-0.91894531]
  [ 0.19702148]
  ...,
  [ 0.65332031]
  [-0.12524414]
  [ 0.68408203]]

 ...,
 [[-0.00120735]
  [-0.91992188]
  [ 0.19604492]
  ...,
  [ 0.65332031]
  [-0.13586426]
  [ 0.68310547]]

 [[-0.00120449]
  [-0.91894531]
  [ 0.19714355]
  ...,
  [ 0.65332031]
  [-0.1270752 ]
  [ 0.68359375]]

 [[-0.00120258]
  [-0.91894531]
  [ 0.1973877 ]
  ...,
  [ 0.65332031]
  [-0.1239624 ]
  [ 0.68408203]]]
After layer att_batch_dot_0 (20, 10, 1) <class 'numpy.float16'> [[[ 0.53125   ]
  [ 0.92382812]
  [ 1.63574219]
  [ 2.60546875]
  [ 2.52539062]
  [ 0.27636719]
  [-2.96289062]
  [-5.80859375]
  [-7.94921875]
  [-9.5546875 ]]

 [[ 0.53125   ]
  [ 0.92333984]
  [ 1.63574219]
  [ 2.60546875]
  [ 2.52539062]
  [ 0.27758789]
  [-2.9609375 ]
  [-5.80859375]
  [-7.9453125 ]
  [-9.5546875 ]]

 [[ 0.53027344]
  [ 0.92236328]
  [ 1.62988281]
  [ 2.59375   ]
  [ 2.50390625]
  [ 0.24072266]
  [-3.01367188]
  [-5.875     ]
  [-8.0234375 ]
  [-9.6328125 ]]

 [[ 0.53076172]
  [ 0.92382812]
  [ 1.63574219]
  [ 2.60546875]
  [ 2.5234375 ]
  [ 0.2734375 ]
  [-2.96875   ]
  [-5.8203125 ]
  [-7.9609375 ]
  [-9.5703125 ]]

 [[ 0.53027344]
  [ 0.92236328]
  [ 1.62988281]
  [ 2.59179688]
  [ 2.49414062]
  [ 0.21887207]
  [-3.04882812]
  [-5.921875  ]
  [-8.078125  ]
  [-9.6953125 ]]

 [[ 0.52929688]
  [ 0.921875  ]
  [ 1.62792969]
  [ 2.58789062]
  [ 2.49023438]
  [ 0.21398926]
  [-3.0546875 ]
  [-5.9296875 ]
  [-8.0859375 ]
  [-9.7109375 ]]

 [[ 0.53076172]
  [ 0.92382812]
  [ 1.63574219]
  [ 2.60546875]
  [ 2.52539062]
  [ 0.27563477]
  [-2.96484375]
  [-5.8125    ]
  [-7.953125  ]
  [-9.5625    ]]

 [[ 0.53125   ]
  [ 0.92333984]
  [ 1.63574219]
  [ 2.60546875]
  [ 2.52539062]
  [ 0.27905273]
  [-2.95898438]
  [-5.8046875 ]
  [-7.94140625]
  [-9.546875  ]]

 [[ 0.53271484]
  [ 0.92382812]
  [ 1.63476562]
  [ 2.6015625 ]
  [ 2.51171875]
  [ 0.24987793]
  [-3.00585938]
  [-5.8671875 ]
  [-8.015625  ]
  [-9.625     ]]

 [[ 0.52880859]
  [ 0.91992188]
  [ 1.62207031]
  [ 2.57617188]
  [ 2.46679688]
  [ 0.18005371]
  [-3.09960938]
  [-5.98046875]
  [-8.1484375 ]
  [-9.765625  ]]

 [[ 0.53076172]
  [ 0.92236328]
  [ 1.63085938]
  [ 2.59570312]
  [ 2.5078125 ]
  [ 0.24890137]
  [-3.        ]
  [-5.85546875]
  [-8.        ]
  [-9.609375  ]]

 [[ 0.52978516]
  [ 0.91992188]
  [ 1.62207031]
  [ 2.57617188]
  [ 2.46679688]
  [ 0.17834473]
  [-3.10351562]
  [-5.98828125]
  [-8.15625   ]
  [-9.78125   ]]

 [[ 0.53125   ]
  [ 0.92333984]
  [ 1.63574219]
  [ 2.60546875]
  [ 2.52539062]
  [ 0.27685547]
  [-2.96289062]
  [-5.80859375]
  [-7.94921875]
  [-9.5546875 ]]

 [[ 0.53076172]
  [ 0.91992188]
  [ 1.62304688]
  [ 2.578125  ]
  [ 2.47070312]
  [ 0.18322754]
  [-3.09765625]
  [-5.98046875]
  [-8.140625  ]
  [-9.765625  ]]

 [[ 0.53125   ]
  [ 0.92382812]
  [ 1.63574219]
  [ 2.60546875]
  [ 2.52539062]
  [ 0.27758789]
  [-2.96289062]
  [-5.80859375]
  [-7.94921875]
  [-9.5546875 ]]

 [[ 0.53125   ]
  [ 0.92382812]
  [ 1.63671875]
  [ 2.60546875]
  [ 2.52539062]
  [ 0.27661133]
  [-2.96484375]
  [-5.8125    ]
  [-7.953125  ]
  [-9.5625    ]]

 [[ 0.53076172]
  [ 0.92333984]
  [ 1.63574219]
  [ 2.60351562]
  [ 2.52148438]
  [ 0.26879883]
  [-2.9765625 ]
  [-5.828125  ]
  [-7.96875   ]
  [-9.578125  ]]

 [[ 0.52978516]
  [ 0.92089844]
  [ 1.625     ]
  [ 2.58203125]
  [ 2.4765625 ]
  [ 0.19030762]
  [-3.08984375]
  [-5.97265625]
  [-8.140625  ]
  [-9.765625  ]]

 [[ 0.53027344]
  [ 0.92333984]
  [ 1.63476562]
  [ 2.60351562]
  [ 2.51757812]
  [ 0.26147461]
  [-2.98828125]
  [-5.84375   ]
  [-7.98828125]
  [-9.6015625 ]]

 [[ 0.53125   ]
  [ 0.92382812]
  [ 1.63574219]
  [ 2.60546875]
  [ 2.5234375 ]
  [ 0.27148438]
  [-2.97265625]
  [-5.82421875]
  [-7.96484375]
  [-9.5703125 ]]]
After layer swapaxes43_output (10, 20, 1) <class 'numpy.float16'> [[[ 0.53125   ]
  [ 0.53125   ]
  [ 0.53027344]
  [ 0.53076172]
  [ 0.53027344]
  [ 0.52929688]
  [ 0.53076172]
  [ 0.53125   ]
  [ 0.53271484]
  [ 0.52880859]
  [ 0.53076172]
  [ 0.52978516]
  [ 0.53125   ]
  [ 0.53076172]
  [ 0.53125   ]
  [ 0.53125   ]
  [ 0.53076172]
  [ 0.52978516]
  [ 0.53027344]
  [ 0.53125   ]]

 [[ 0.92382812]
  [ 0.92333984]
  [ 0.92236328]
  [ 0.92382812]
  [ 0.92236328]
  [ 0.921875  ]
  [ 0.92382812]
  [ 0.92333984]
  [ 0.92382812]
  [ 0.91992188]
  [ 0.92236328]
  [ 0.91992188]
  [ 0.92333984]
  [ 0.91992188]
  [ 0.92382812]
  [ 0.92382812]
  [ 0.92333984]
  [ 0.92089844]
  [ 0.92333984]
  [ 0.92382812]]

 [[ 1.63574219]
  [ 1.63574219]
  [ 1.62988281]
  [ 1.63574219]
  [ 1.62988281]
  [ 1.62792969]
  [ 1.63574219]
  [ 1.63574219]
  [ 1.63476562]
  [ 1.62207031]
  [ 1.63085938]
  [ 1.62207031]
  [ 1.63574219]
  [ 1.62304688]
  [ 1.63574219]
  [ 1.63671875]
  [ 1.63574219]
  [ 1.625     ]
  [ 1.63476562]
  [ 1.63574219]]

 [[ 2.60546875]
  [ 2.60546875]
  [ 2.59375   ]
  [ 2.60546875]
  [ 2.59179688]
  [ 2.58789062]
  [ 2.60546875]
  [ 2.60546875]
  [ 2.6015625 ]
  [ 2.57617188]
  [ 2.59570312]
  [ 2.57617188]
  [ 2.60546875]
  [ 2.578125  ]
  [ 2.60546875]
  [ 2.60546875]
  [ 2.60351562]
  [ 2.58203125]
  [ 2.60351562]
  [ 2.60546875]]

 [[ 2.52539062]
  [ 2.52539062]
  [ 2.50390625]
  [ 2.5234375 ]
  [ 2.49414062]
  [ 2.49023438]
  [ 2.52539062]
  [ 2.52539062]
  [ 2.51171875]
  [ 2.46679688]
  [ 2.5078125 ]
  [ 2.46679688]
  [ 2.52539062]
  [ 2.47070312]
  [ 2.52539062]
  [ 2.52539062]
  [ 2.52148438]
  [ 2.4765625 ]
  [ 2.51757812]
  [ 2.5234375 ]]

 [[ 0.27636719]
  [ 0.27758789]
  [ 0.24072266]
  [ 0.2734375 ]
  [ 0.21887207]
  [ 0.21398926]
  [ 0.27563477]
  [ 0.27905273]
  [ 0.24987793]
  [ 0.18005371]
  [ 0.24890137]
  [ 0.17834473]
  [ 0.27685547]
  [ 0.18322754]
  [ 0.27758789]
  [ 0.27661133]
  [ 0.26879883]
  [ 0.19030762]
  [ 0.26147461]
  [ 0.27148438]]

 [[-2.96289062]
  [-2.9609375 ]
  [-3.01367188]
  [-2.96875   ]
  [-3.04882812]
  [-3.0546875 ]
  [-2.96484375]
  [-2.95898438]
  [-3.00585938]
  [-3.09960938]
  [-3.        ]
  [-3.10351562]
  [-2.96289062]
  [-3.09765625]
  [-2.96289062]
  [-2.96484375]
  [-2.9765625 ]
  [-3.08984375]
  [-2.98828125]
  [-2.97265625]]

 [[-5.80859375]
  [-5.80859375]
  [-5.875     ]
  [-5.8203125 ]
  [-5.921875  ]
  [-5.9296875 ]
  [-5.8125    ]
  [-5.8046875 ]
  [-5.8671875 ]
  [-5.98046875]
  [-5.85546875]
  [-5.98828125]
  [-5.80859375]
  [-5.98046875]
  [-5.80859375]
  [-5.8125    ]
  [-5.828125  ]
  [-5.97265625]
  [-5.84375   ]
  [-5.82421875]]

 [[-7.94921875]
  [-7.9453125 ]
  [-8.0234375 ]
  [-7.9609375 ]
  [-8.078125  ]
  [-8.0859375 ]
  [-7.953125  ]
  [-7.94140625]
  [-8.015625  ]
  [-8.1484375 ]
  [-8.        ]
  [-8.15625   ]
  [-7.94921875]
  [-8.140625  ]
  [-7.94921875]
  [-7.953125  ]
  [-7.96875   ]
  [-8.140625  ]
  [-7.98828125]
  [-7.96484375]]

 [[-9.5546875 ]
  [-9.5546875 ]
  [-9.6328125 ]
  [-9.5703125 ]
  [-9.6953125 ]
  [-9.7109375 ]
  [-9.5625    ]
  [-9.546875  ]
  [-9.625     ]
  [-9.765625  ]
  [-9.609375  ]
  [-9.78125   ]
  [-9.5546875 ]
  [-9.765625  ]
  [-9.5546875 ]
  [-9.5625    ]
  [-9.578125  ]
  [-9.765625  ]
  [-9.6015625 ]
  [-9.5703125 ]]]
After layer sequencemask17_output (10, 20, 1) <class 'numpy.float16'> [[[  5.31250000e-01]
  [  5.31250000e-01]
  [  5.30273438e-01]
  [  5.30761719e-01]
  [  5.30273438e-01]
  [  5.29296875e-01]
  [  5.30761719e-01]
  [  5.31250000e-01]
  [  5.32714844e-01]
  [  5.28808594e-01]
  [  5.30761719e-01]
  [  5.29785156e-01]
  [  5.31250000e-01]
  [  5.30761719e-01]
  [  5.31250000e-01]
  [  5.31250000e-01]
  [  5.30761719e-01]
  [  5.29785156e-01]
  [  5.30273438e-01]
  [  5.31250000e-01]]

 [[  9.23828125e-01]
  [  9.23339844e-01]
  [  9.22363281e-01]
  [  9.23828125e-01]
  [  9.22363281e-01]
  [  9.21875000e-01]
  [  9.23828125e-01]
  [  9.23339844e-01]
  [  9.23828125e-01]
  [  9.19921875e-01]
  [  9.22363281e-01]
  [  9.19921875e-01]
  [  9.23339844e-01]
  [  9.19921875e-01]
  [  9.23828125e-01]
  [  9.23828125e-01]
  [  9.23339844e-01]
  [  9.20898438e-01]
  [  9.23339844e-01]
  [  9.23828125e-01]]

 [[ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]]
After layer swapaxes44_output (20, 10, 1) <class 'numpy.float16'> [[[  5.31250000e-01]
  [  9.23828125e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  5.31250000e-01]
  [  9.23339844e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  5.30273438e-01]
  [  9.22363281e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  5.30761719e-01]
  [  9.23828125e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  5.30273438e-01]
  [  9.22363281e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  5.29296875e-01]
  [  9.21875000e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  5.30761719e-01]
  [  9.23828125e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  5.31250000e-01]
  [  9.23339844e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  5.32714844e-01]
  [  9.23828125e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  5.28808594e-01]
  [  9.19921875e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  5.30761719e-01]
  [  9.22363281e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  5.29785156e-01]
  [  9.19921875e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  5.31250000e-01]
  [  9.23339844e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  5.30761719e-01]
  [  9.19921875e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  5.31250000e-01]
  [  9.23828125e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  5.31250000e-01]
  [  9.23828125e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  5.30761719e-01]
  [  9.23339844e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  5.29785156e-01]
  [  9.20898438e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  5.30273438e-01]
  [  9.23339844e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  5.31250000e-01]
  [  9.23828125e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]]
After layer attention_softmax_0 (20, 10, 1) <class 'numpy.float16'> [[[ 0.40307617]
  [ 0.59667969]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40307617]
  [ 0.59667969]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40307617]
  [ 0.59667969]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40307617]
  [ 0.59716797]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40307617]
  [ 0.59667969]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40307617]
  [ 0.59667969]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40307617]
  [ 0.59716797]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40307617]
  [ 0.59667969]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40356445]
  [ 0.59667969]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40356445]
  [ 0.59667969]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40332031]
  [ 0.59667969]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40380859]
  [ 0.59619141]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40307617]
  [ 0.59667969]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40380859]
  [ 0.59619141]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40307617]
  [ 0.59667969]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40307617]
  [ 0.59667969]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40307617]
  [ 0.59667969]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40356445]
  [ 0.59667969]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40307617]
  [ 0.59716797]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40307617]
  [ 0.59667969]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]]
After layer batch_dot17_0 (20, 512, 1) <class 'numpy.float16'> [[[ 0.01785278]
  [ 0.03942871]
  [-0.03341675]
  ...,
  [-0.01097107]
  [ 0.00998688]
  [-0.02461243]]

 [[ 0.01785278]
  [ 0.03942871]
  [-0.03341675]
  ...,
  [-0.01097107]
  [ 0.00998688]
  [-0.02461243]]

 [[ 0.01785278]
  [ 0.03942871]
  [-0.03341675]
  ...,
  [-0.01097107]
  [ 0.00998688]
  [-0.02461243]]

 ...,
 [[ 0.01785278]
  [ 0.03945923]
  [-0.03341675]
  ...,
  [-0.01097107]
  [ 0.00999451]
  [-0.02462769]]

 [[ 0.01786804]
  [ 0.03945923]
  [-0.03341675]
  ...,
  [-0.0109787 ]
  [ 0.00999451]
  [-0.02462769]]

 [[ 0.01785278]
  [ 0.03942871]
  [-0.03341675]
  ...,
  [-0.01097107]
  [ 0.00998688]
  [-0.02461243]]]
After layer reshape34_0 (20, 512) <class 'numpy.float16'> [[ 0.01785278  0.03942871 -0.03341675 ..., -0.01097107  0.00998688
  -0.02461243]
 [ 0.01785278  0.03942871 -0.03341675 ..., -0.01097107  0.00998688
  -0.02461243]
 [ 0.01785278  0.03942871 -0.03341675 ..., -0.01097107  0.00998688
  -0.02461243]
 ...,
 [ 0.01785278  0.03945923 -0.03341675 ..., -0.01097107  0.00999451
  -0.02462769]
 [ 0.01786804  0.03945923 -0.03341675 ..., -0.0109787   0.00999451
  -0.02462769]
 [ 0.01785278  0.03942871 -0.03341675 ..., -0.01097107  0.00998688
  -0.02461243]]
After layer decoder_rnn_hidden_concat_t0_output (20, 1024) <class 'numpy.float16'> [[-0.00120258 -0.91894531  0.19763184 ..., -0.01097107  0.00998688
  -0.02461243]
 [-0.00120258 -0.91894531  0.19775391 ..., -0.01097107  0.00998688
  -0.02461243]
 [-0.00120735 -0.91894531  0.19702148 ..., -0.01097107  0.00998688
  -0.02461243]
 ...,
 [-0.00120735 -0.91992188  0.19604492 ..., -0.01097107  0.00999451
  -0.02462769]
 [-0.00120449 -0.91894531  0.19714355 ..., -0.0109787   0.00999451
  -0.02462769]
 [-0.00120258 -0.91894531  0.1973877  ..., -0.01097107  0.00998688
  -0.02461243]]
After layer decoder_rnn_hidden_fc_t0_output (20, 512) <class 'numpy.float16'> [[-1.97363281  0.21350098 -0.81787109 ...,  1.984375    2.11914062
  -1.60351562]
 [-1.97363281  0.21276855 -0.81738281 ...,  1.98339844  2.11914062
  -1.60351562]
 [-1.97265625  0.2154541  -0.82128906 ...,  1.98144531  2.1171875
  -1.60449219]
 ...,
 [-1.97070312  0.21960449 -0.82861328 ...,  1.9765625   2.11523438
  -1.61132812]
 [-1.97558594  0.2166748  -0.82177734 ...,  1.98339844  2.1171875
  -1.60449219]
 [-1.97460938  0.21435547 -0.81933594 ...,  1.98339844  2.1171875
  -1.60351562]]
After layer decoder_rnn_next_hidden_t0_output (20, 512) <class 'numpy.float16'> [[-0.96191406  0.21032715 -0.67382812 ...,  0.96289062  0.97167969
  -0.92236328]
 [-0.96191406  0.20959473 -0.67382812 ...,  0.96289062  0.97167969
  -0.92236328]
 [-0.96191406  0.2121582  -0.67578125 ...,  0.96289062  0.97167969
  -0.92236328]
 ...,
 [-0.96191406  0.21618652 -0.6796875  ...,  0.96240234  0.97119141
  -0.92333984]
 [-0.96240234  0.21337891 -0.67626953 ...,  0.96289062  0.97167969
  -0.92236328]
 [-0.96240234  0.21118164 -0.67480469 ...,  0.96289062  0.97167969
  -0.92236328]]
After layer logits_output (20, 16743) <class 'numpy.float16'> [[-2.01171875 -2.82421875 -2.40625    ..., -2.09375    -3.50195312
  -2.58789062]
 [-2.01367188 -2.82421875 -2.40625    ..., -2.09179688 -3.50195312
  -2.58789062]
 [-2.01171875 -2.82617188 -2.40625    ..., -2.09375    -3.50195312
  -2.58789062]
 ...,
 [-2.01171875 -2.82617188 -2.40625    ..., -2.09570312 -3.5        -2.59179688]
 [-2.01367188 -2.82421875 -2.40625    ..., -2.09375    -3.50195312
  -2.58789062]
 [-2.01367188 -2.82421875 -2.40625    ..., -2.09375    -3.50195312
  -2.58789062]]
After layer softmax_0 (20, 16743) <class 'numpy.float16'> [[  8.34465027e-07   3.57627869e-07   5.36441803e-07 ...,   7.74860382e-07
    1.78813934e-07   4.76837158e-07]
 [  8.34465027e-07   3.57627869e-07   5.36441803e-07 ...,   7.74860382e-07
    1.78813934e-07   4.76837158e-07]
 [  8.34465027e-07   3.57627869e-07   5.96046448e-07 ...,   7.74860382e-07
    1.78813934e-07   4.76837158e-07]
 ...,
 [  8.34465027e-07   3.57627869e-07   5.96046448e-07 ...,   7.74860382e-07
    1.78813934e-07   4.76837158e-07]
 [  8.34465027e-07   3.57627869e-07   5.96046448e-07 ...,   7.74860382e-07
    1.78813934e-07   4.76837158e-07]
 [  8.34465027e-07   3.57627869e-07   5.96046448e-07 ...,   7.74860382e-07
    1.78813934e-07   4.76837158e-07]]
After layer reshape35_0 (20, 10) <class 'numpy.float16'> [[ 0.40307617  0.59667969  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40307617  0.59667969  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40307617  0.59667969  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40307617  0.59716797  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40307617  0.59667969  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40307617  0.59667969  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40307617  0.59716797  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40307617  0.59667969  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40356445  0.59667969  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40356445  0.59667969  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40332031  0.59667969  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40380859  0.59619141  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40307617  0.59667969  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40380859  0.59619141  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40307617  0.59667969  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40307617  0.59667969  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40307617  0.59667969  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40356445  0.59667969  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40307617  0.59716797  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40307617  0.59667969  0.          0.          0.          0.          0.
   0.          0.          0.        ]]
After layer target_embed_embed_0 (20, 256) <class 'numpy.float16'> [[-0.05505371 -0.0300293  -0.03598022 ...,  0.08459473 -0.05288696
  -0.01667786]
 [-0.05505371 -0.0300293  -0.03598022 ...,  0.08459473 -0.05288696
  -0.01667786]
 [-0.05505371 -0.0300293  -0.03598022 ...,  0.08459473 -0.05288696
  -0.01667786]
 ...,
 [-0.05505371 -0.0300293  -0.03598022 ...,  0.08459473 -0.05288696
  -0.01667786]
 [-0.05505371 -0.0300293  -0.03598022 ...,  0.08459473 -0.05288696
  -0.01667786]
 [-0.05505371 -0.0300293  -0.03598022 ...,  0.08459473 -0.05288696
  -0.01667786]]
After layer decoder_rnn_concat_target_context_t0_output (20, 768) <class 'numpy.float16'> [[-0.05505371 -0.0300293  -0.03598022 ...,  0.96289062  0.97167969
  -0.92236328]
 [-0.05505371 -0.0300293  -0.03598022 ...,  0.96289062  0.97167969
  -0.92236328]
 [-0.05505371 -0.0300293  -0.03598022 ...,  0.96289062  0.97167969
  -0.92236328]
 ...,
 [-0.05505371 -0.0300293  -0.03598022 ...,  0.96240234  0.97119141
  -0.92333984]
 [-0.05505371 -0.0300293  -0.03598022 ...,  0.96289062  0.97167969
  -0.92236328]
 [-0.05505371 -0.0300293  -0.03598022 ...,  0.96289062  0.97167969
  -0.92236328]]
After layer decoder_rnn_l0_t0_i2h_output (20, 2048) <class 'numpy.float16'> [[-3.1953125   1.60742188  2.44140625 ..., -0.07714844  3.86523438
   0.59619141]
 [-3.1953125   1.60742188  2.44140625 ..., -0.07720947  3.86523438
   0.59619141]
 [-3.1953125   1.60644531  2.44140625 ..., -0.07678223  3.86523438
   0.59863281]
 ...,
 [-3.19335938  1.60546875  2.44335938 ..., -0.07635498  3.8671875
   0.60253906]
 [-3.1953125   1.60644531  2.44140625 ..., -0.07672119  3.86523438
   0.59619141]
 [-3.1953125   1.60644531  2.44140625 ..., -0.07696533  3.86523438
   0.59667969]]
After layer decoder_rnn_l0_t0_h2h_output (20, 2048) <class 'numpy.float16'> [[-0.32275391  0.47216797  1.85742188 ...,  0.71240234  1.29492188
   0.17675781]
 [-0.32275391  0.47192383  1.85742188 ...,  0.71240234  1.29492188
   0.17663574]
 [-0.32421875  0.47680664  1.85546875 ...,  0.71240234  1.29980469
   0.17297363]
 ...,
 [-0.32958984  0.48486328  1.85546875 ...,  0.7109375   1.3046875
   0.16638184]
 [-0.32324219  0.47558594  1.85644531 ...,  0.71191406  1.29785156
   0.17346191]
 [-0.32324219  0.47387695  1.85742188 ...,  0.71191406  1.29589844
   0.1751709 ]]
After layer _plus1062_0 (20, 2048) <class 'numpy.float16'> [[-3.51757812  2.08007812  4.296875   ...,  0.63525391  5.16015625
   0.77294922]
 [-3.51757812  2.08007812  4.296875   ...,  0.63525391  5.16015625
   0.77294922]
 [-3.51953125  2.08398438  4.296875   ...,  0.63574219  5.1640625
   0.77148438]
 ...,
 [-3.5234375   2.08984375  4.296875   ...,  0.63476562  5.171875
   0.76904297]
 [-3.51953125  2.08203125  4.296875   ...,  0.63525391  5.1640625
   0.76953125]
 [-3.51953125  2.08007812  4.296875   ...,  0.63476562  5.16015625
   0.77197266]]
After layer decoder_rnn_l0_t0_slice_output0 (20, 512) <class 'numpy.float16'> [[-3.51757812  2.08007812  4.296875   ...,  1.73925781  4.62109375  2.78125   ]
 [-3.51757812  2.08007812  4.296875   ...,  1.73828125  4.62109375  2.78125   ]
 [-3.51953125  2.08398438  4.296875   ...,  1.74121094  4.61328125  2.78125   ]
 ...,
 [-3.5234375   2.08984375  4.296875   ...,  1.74511719  4.609375
   2.77929688]
 [-3.51953125  2.08203125  4.296875   ...,  1.73828125  4.6171875
   2.77929688]
 [-3.51953125  2.08007812  4.296875   ...,  1.73828125  4.6171875
   2.77929688]]
After layer decoder_rnn_l0_t0_slice_output1 (20, 512) <class 'numpy.float16'> [[-1.85351562  2.32226562  2.44140625 ...,  3.16796875 -0.6875      1.98925781]
 [-1.85351562  2.32226562  2.44140625 ...,  3.16796875 -0.6875      1.98925781]
 [-1.85839844  2.3203125   2.4453125  ...,  3.16601562 -0.68945312
   1.98730469]
 ...,
 [-1.86523438  2.31640625  2.453125   ...,  3.16210938 -0.68945312
   1.98632812]
 [-1.85546875  2.3203125   2.44335938 ...,  3.16601562 -0.68798828
   1.98925781]
 [-1.85449219  2.32226562  2.44140625 ...,  3.16796875 -0.68798828
   1.98828125]]
After layer decoder_rnn_l0_t0_slice_output2 (20, 512) <class 'numpy.float16'> [[-2.81640625 -3.09570312  2.85351562 ...,  4.265625   -0.08227539
   2.16015625]
 [-2.81640625 -3.09570312  2.85351562 ...,  4.265625   -0.08227539
   2.16015625]
 [-2.81835938 -3.09765625  2.86328125 ...,  4.2578125  -0.08496094
   2.16015625]
 ...,
 [-2.82226562 -3.10546875  2.87890625 ...,  4.25       -0.08959961  2.15625   ]
 [-2.81835938 -3.09960938  2.85742188 ...,  4.2578125  -0.08520508
   2.15820312]
 [-2.81640625 -3.09765625  2.85546875 ...,  4.26171875 -0.08398438
   2.16015625]]
After layer decoder_rnn_l0_t0_slice_output3 (20, 512) <class 'numpy.float16'> [[-3.27734375  2.42382812 -1.40136719 ...,  0.63525391  5.16015625
   0.77294922]
 [-3.27734375  2.42382812 -1.40039062 ...,  0.63525391  5.16015625
   0.77294922]
 [-3.2734375   2.42773438 -1.40429688 ...,  0.63574219  5.1640625
   0.77148438]
 ...,
 [-3.26953125  2.43359375 -1.40917969 ...,  0.63476562  5.171875
   0.76904297]
 [-3.27734375  2.42578125 -1.40429688 ...,  0.63525391  5.1640625
   0.76953125]
 [-3.27734375  2.42578125 -1.40234375 ...,  0.63476562  5.16015625
   0.77197266]]
After layer decoder_rnn_l0_t0_o_output (20, 512) <class 'numpy.float16'> [[ 0.03634644  0.91845703  0.19763184 ...,  0.65380859  0.99414062
   0.68408203]
 [ 0.03634644  0.91845703  0.19775391 ...,  0.65380859  0.99414062
   0.68408203]
 [ 0.03649902  0.91894531  0.19714355 ...,  0.65380859  0.99414062
   0.68408203]
 ...,
 [ 0.03662109  0.91943359  0.19641113 ...,  0.65380859  0.99414062
   0.68310547]
 [ 0.03634644  0.91894531  0.19714355 ...,  0.65380859  0.99414062
   0.68359375]
 [ 0.03634644  0.91894531  0.1973877  ...,  0.65380859  0.99414062
   0.68408203]]
After layer decoder_rnn_l0_t0_f_output (20, 512) <class 'numpy.float16'> [[ 0.13549805  0.91064453  0.91992188 ...,  0.95947266  0.33447266
   0.87988281]
 [ 0.13549805  0.91064453  0.91992188 ...,  0.95947266  0.33447266
   0.87988281]
 [ 0.1348877   0.91064453  0.92041016 ...,  0.95947266  0.33422852
   0.87939453]
 ...,
 [ 0.1340332   0.91015625  0.92089844 ...,  0.95947266  0.33422852
   0.87939453]
 [ 0.13525391  0.91064453  0.91992188 ...,  0.95947266  0.33447266
   0.87988281]
 [ 0.13537598  0.91064453  0.91992188 ...,  0.95947266  0.33447266
   0.87939453]]
After layer _mul2124_0 (20, 512) <class 'numpy.float16'> [[ -4.48226929e-03  -6.82812500e+00   8.01562500e+00 ...,   9.57031250e+00
   -4.08630371e-02   5.67968750e+00]
 [ -4.48226929e-03  -6.82421875e+00   7.98437500e+00 ...,   9.51562500e+00
   -4.10461426e-02   5.65625000e+00]
 [ -4.46319580e-03  -6.79687500e+00   8.01562500e+00 ...,   9.41406250e+00
   -4.23583984e-02   5.61328125e+00]
 ...,
 [ -4.40979004e-03  -6.62890625e+00   7.84375000e+00 ...,   9.06250000e+00
   -4.59899902e-02   5.31250000e+00]
 [ -4.48226929e-03  -6.82421875e+00   7.97656250e+00 ...,   9.46093750e+00
   -4.29992676e-02   5.62109375e+00]
 [ -4.47845459e-03  -6.82812500e+00   7.98437500e+00 ...,   9.46093750e+00
   -4.19311523e-02   5.63281250e+00]]
After layer decoder_rnn_l0_t0_i_output (20, 512) <class 'numpy.float16'> [[ 0.02880859  0.88916016  0.98632812 ...,  0.85058594  0.99023438
   0.94189453]
 [ 0.02880859  0.88916016  0.98632812 ...,  0.85058594  0.99023438
   0.94189453]
 [ 0.02876282  0.88916016  0.98632812 ...,  0.85107422  0.99023438
   0.94189453]
 ...,
 [ 0.02865601  0.89013672  0.98632812 ...,  0.8515625   0.99023438
   0.94140625]
 [ 0.02876282  0.88916016  0.98632812 ...,  0.85058594  0.99023438
   0.94140625]
 [ 0.02876282  0.88916016  0.98632812 ...,  0.85058594  0.99023438
   0.94140625]]
After layer decoder_rnn_l0_t0_c_output (20, 512) <class 'numpy.float16'> [[-0.99267578 -0.99609375  0.99316406 ...,  0.99951172 -0.08209229
   0.97363281]
 [-0.99267578 -0.99609375  0.99316406 ...,  0.99951172 -0.08209229
   0.97363281]
 [-0.99267578 -0.99609375  0.99365234 ...,  0.99951172 -0.08477783
   0.97363281]
 ...,
 [-0.99316406 -0.99609375  0.99365234 ...,  0.99951172 -0.08935547
   0.97363281]
 [-0.99267578 -0.99609375  0.99365234 ...,  0.99951172 -0.08502197
   0.97363281]
 [-0.99267578 -0.99609375  0.99316406 ...,  0.99951172 -0.08380127
   0.97363281]]
After layer _mul2125_0 (20, 512) <class 'numpy.float16'> [[-0.02859497 -0.88574219  0.97949219 ...,  0.85009766 -0.08129883
   0.91699219]
 [-0.02859497 -0.88574219  0.97949219 ...,  0.85009766 -0.08129883
   0.91699219]
 [-0.02854919 -0.88574219  0.97998047 ...,  0.85058594 -0.08392334
   0.91699219]
 ...,
 [-0.02845764 -0.88671875  0.97998047 ...,  0.85107422 -0.08850098
   0.91650391]
 [-0.02854919 -0.88574219  0.97998047 ...,  0.85009766 -0.08416748
   0.91650391]
 [-0.02854919 -0.88574219  0.97949219 ...,  0.85009766 -0.08300781
   0.91650391]]
After layer decoder_rnn_l0_t0_state_0 (20, 512) <class 'numpy.float16'> [[ -0.03308105  -7.71484375   8.9921875  ...,  10.421875    -0.12219238
    6.59765625]
 [ -0.03308105  -7.7109375    8.9609375  ...,  10.3671875   -0.12231445
    6.57421875]
 [ -0.03302002  -7.68359375   8.9921875  ...,  10.265625    -0.1262207
    6.53125   ]
 ...,
 [ -0.03286743  -7.515625     8.8203125  ...,   9.9140625   -0.13452148
    6.23046875]
 [ -0.03302002  -7.7109375    8.953125   ...,  10.3125      -0.12719727
    6.5390625 ]
 [ -0.03302002  -7.71484375   8.9609375  ...,  10.3125      -0.12493896
    6.55078125]]
After layer activation1062_output (20, 512) <class 'numpy.float16'> [[-0.03308105 -1.          1.         ...,  1.         -0.12158203  1.        ]
 [-0.03308105 -1.          1.         ...,  1.         -0.1217041   1.        ]
 [-0.03302002 -1.          1.         ...,  1.         -0.12561035  1.        ]
 ...,
 [-0.03286743 -1.          1.         ...,  1.         -0.13366699  1.        ]
 [-0.03302002 -1.          1.         ...,  1.         -0.12646484  1.        ]
 [-0.03302002 -1.          1.         ...,  1.         -0.12426758  1.        ]]
After layer decoder_rnn_l0_t0_out_0 (20, 512) <class 'numpy.float16'> [[-0.00120258 -0.91845703  0.19763184 ...,  0.65380859 -0.12084961
   0.68408203]
 [-0.00120258 -0.91845703  0.19775391 ...,  0.65380859 -0.12097168
   0.68408203]
 [-0.00120544 -0.91894531  0.19714355 ...,  0.65380859 -0.12487793
   0.68408203]
 ...,
 [-0.00120354 -0.91943359  0.19641113 ...,  0.65380859 -0.13293457
   0.68310547]
 [-0.00119972 -0.91894531  0.19714355 ...,  0.65380859 -0.12573242
   0.68359375]
 [-0.00119972 -0.91894531  0.1973877  ...,  0.65380859 -0.12353516
   0.68408203]]
After layer expand_dims1071_0 (20, 512, 1) <class 'numpy.float16'> [[[-0.00120258]
  [-0.91845703]
  [ 0.19763184]
  ...,
  [ 0.65380859]
  [-0.12084961]
  [ 0.68408203]]

 [[-0.00120258]
  [-0.91845703]
  [ 0.19775391]
  ...,
  [ 0.65380859]
  [-0.12097168]
  [ 0.68408203]]

 [[-0.00120544]
  [-0.91894531]
  [ 0.19714355]
  ...,
  [ 0.65380859]
  [-0.12487793]
  [ 0.68408203]]

 ...,
 [[-0.00120354]
  [-0.91943359]
  [ 0.19641113]
  ...,
  [ 0.65380859]
  [-0.13293457]
  [ 0.68310547]]

 [[-0.00119972]
  [-0.91894531]
  [ 0.19714355]
  ...,
  [ 0.65380859]
  [-0.12573242]
  [ 0.68359375]]

 [[-0.00119972]
  [-0.91894531]
  [ 0.1973877 ]
  ...,
  [ 0.65380859]
  [-0.12353516]
  [ 0.68408203]]]
After layer att_batch_dot_0 (20, 10, 1) <class 'numpy.float16'> [[[ 0.53125   ]
  [ 0.92431641]
  [ 1.63769531]
  [ 2.60742188]
  [ 2.52734375]
  [ 0.27905273]
  [-2.96289062]
  [-5.8125    ]
  [-7.94921875]
  [-9.5546875 ]]

 [[ 0.53125   ]
  [ 0.92431641]
  [ 1.63769531]
  [ 2.609375  ]
  [ 2.52929688]
  [ 0.28125   ]
  [-2.95898438]
  [-5.80859375]
  [-7.9453125 ]
  [-9.5546875 ]]

 [[ 0.53027344]
  [ 0.92236328]
  [ 1.63183594]
  [ 2.59765625]
  [ 2.50585938]
  [ 0.24475098]
  [-3.00976562]
  [-5.87109375]
  [-8.015625  ]
  [-9.6328125 ]]

 [[ 0.53076172]
  [ 0.92382812]
  [ 1.63671875]
  [ 2.60742188]
  [ 2.52539062]
  [ 0.27294922]
  [-2.97070312]
  [-5.82421875]
  [-7.96484375]
  [-9.578125  ]]

 [[ 0.53076172]
  [ 0.92285156]
  [ 1.63085938]
  [ 2.59375   ]
  [ 2.49804688]
  [ 0.22521973]
  [-3.04101562]
  [-5.9140625 ]
  [-8.0703125 ]
  [-9.6875    ]]

 [[ 0.53125   ]
  [ 0.92431641]
  [ 1.63769531]
  [ 2.60742188]
  [ 2.52734375]
  [ 0.27734375]
  [-2.96484375]
  [-5.81640625]
  [-7.95703125]
  [-9.5625    ]]

 [[ 0.52929688]
  [ 0.92236328]
  [ 1.62890625]
  [ 2.58984375]
  [ 2.4921875 ]
  [ 0.21728516]
  [-3.05078125]
  [-5.92578125]
  [-8.0859375 ]
  [-9.703125  ]]

 [[ 0.53125   ]
  [ 0.92431641]
  [ 1.63867188]
  [ 2.609375  ]
  [ 2.53125   ]
  [ 0.28344727]
  [-2.95507812]
  [-5.80078125]
  [-7.94140625]
  [-9.546875  ]]

 [[ 0.53320312]
  [ 0.92431641]
  [ 1.63574219]
  [ 2.60351562]
  [ 2.515625  ]
  [ 0.25268555]
  [-3.00390625]
  [-5.8671875 ]
  [-8.015625  ]
  [-9.625     ]]

 [[ 0.52929688]
  [ 0.92089844]
  [ 1.625     ]
  [ 2.58203125]
  [ 2.4765625 ]
  [ 0.19311523]
  [-3.08398438]
  [-5.96484375]
  [-8.125     ]
  [-9.75      ]]

 [[ 0.53125   ]
  [ 0.92285156]
  [ 1.63378906]
  [ 2.59960938]
  [ 2.51171875]
  [ 0.25463867]
  [-2.99414062]
  [-5.8515625 ]
  [-7.99609375]
  [-9.609375  ]]

 [[ 0.53027344]
  [ 0.92089844]
  [ 1.62597656]
  [ 2.58203125]
  [ 2.4765625 ]
  [ 0.19152832]
  [-3.08789062]
  [-5.96875   ]
  [-8.1328125 ]
  [-9.7578125 ]]

 [[ 0.53125   ]
  [ 0.92089844]
  [ 1.62597656]
  [ 2.58398438]
  [ 2.48046875]
  [ 0.19555664]
  [-3.08203125]
  [-5.9609375 ]
  [-8.125     ]
  [-9.75      ]]

 [[ 0.53125   ]
  [ 0.92431641]
  [ 1.63769531]
  [ 2.609375  ]
  [ 2.52929688]
  [ 0.28027344]
  [-2.9609375 ]
  [-5.80859375]
  [-7.94921875]
  [-9.5546875 ]]

 [[ 0.53125   ]
  [ 0.92431641]
  [ 1.63769531]
  [ 2.609375  ]
  [ 2.52929688]
  [ 0.28100586]
  [-2.9609375 ]
  [-5.80859375]
  [-7.94921875]
  [-9.5546875 ]]

 [[ 0.53125   ]
  [ 0.92431641]
  [ 1.63769531]
  [ 2.60742188]
  [ 2.52734375]
  [ 0.27734375]
  [-2.96484375]
  [-5.81640625]
  [-7.95703125]
  [-9.5625    ]]

 [[ 0.53076172]
  [ 0.92382812]
  [ 1.63671875]
  [ 2.60546875]
  [ 2.5234375 ]
  [ 0.27026367]
  [-2.9765625 ]
  [-5.828125  ]
  [-7.97265625]
  [-9.5859375 ]]

 [[ 0.52978516]
  [ 0.92138672]
  [ 1.62695312]
  [ 2.5859375 ]
  [ 2.48242188]
  [ 0.19726562]
  [-3.08203125]
  [-5.9609375 ]
  [-8.125     ]
  [-9.75      ]]

 [[ 0.53076172]
  [ 0.92431641]
  [ 1.63671875]
  [ 2.60546875]
  [ 2.52148438]
  [ 0.26538086]
  [-2.984375  ]
  [-5.83984375]
  [-7.98828125]
  [-9.6015625 ]]

 [[ 0.53076172]
  [ 0.92382812]
  [ 1.63671875]
  [ 2.60742188]
  [ 2.52539062]
  [ 0.27246094]
  [-2.97265625]
  [-5.82421875]
  [-7.96875   ]
  [-9.578125  ]]]
After layer swapaxes45_output (10, 20, 1) <class 'numpy.float16'> [[[ 0.53125   ]
  [ 0.53125   ]
  [ 0.53027344]
  [ 0.53076172]
  [ 0.53076172]
  [ 0.53125   ]
  [ 0.52929688]
  [ 0.53125   ]
  [ 0.53320312]
  [ 0.52929688]
  [ 0.53125   ]
  [ 0.53027344]
  [ 0.53125   ]
  [ 0.53125   ]
  [ 0.53125   ]
  [ 0.53125   ]
  [ 0.53076172]
  [ 0.52978516]
  [ 0.53076172]
  [ 0.53076172]]

 [[ 0.92431641]
  [ 0.92431641]
  [ 0.92236328]
  [ 0.92382812]
  [ 0.92285156]
  [ 0.92431641]
  [ 0.92236328]
  [ 0.92431641]
  [ 0.92431641]
  [ 0.92089844]
  [ 0.92285156]
  [ 0.92089844]
  [ 0.92089844]
  [ 0.92431641]
  [ 0.92431641]
  [ 0.92431641]
  [ 0.92382812]
  [ 0.92138672]
  [ 0.92431641]
  [ 0.92382812]]

 [[ 1.63769531]
  [ 1.63769531]
  [ 1.63183594]
  [ 1.63671875]
  [ 1.63085938]
  [ 1.63769531]
  [ 1.62890625]
  [ 1.63867188]
  [ 1.63574219]
  [ 1.625     ]
  [ 1.63378906]
  [ 1.62597656]
  [ 1.62597656]
  [ 1.63769531]
  [ 1.63769531]
  [ 1.63769531]
  [ 1.63671875]
  [ 1.62695312]
  [ 1.63671875]
  [ 1.63671875]]

 [[ 2.60742188]
  [ 2.609375  ]
  [ 2.59765625]
  [ 2.60742188]
  [ 2.59375   ]
  [ 2.60742188]
  [ 2.58984375]
  [ 2.609375  ]
  [ 2.60351562]
  [ 2.58203125]
  [ 2.59960938]
  [ 2.58203125]
  [ 2.58398438]
  [ 2.609375  ]
  [ 2.609375  ]
  [ 2.60742188]
  [ 2.60546875]
  [ 2.5859375 ]
  [ 2.60546875]
  [ 2.60742188]]

 [[ 2.52734375]
  [ 2.52929688]
  [ 2.50585938]
  [ 2.52539062]
  [ 2.49804688]
  [ 2.52734375]
  [ 2.4921875 ]
  [ 2.53125   ]
  [ 2.515625  ]
  [ 2.4765625 ]
  [ 2.51171875]
  [ 2.4765625 ]
  [ 2.48046875]
  [ 2.52929688]
  [ 2.52929688]
  [ 2.52734375]
  [ 2.5234375 ]
  [ 2.48242188]
  [ 2.52148438]
  [ 2.52539062]]

 [[ 0.27905273]
  [ 0.28125   ]
  [ 0.24475098]
  [ 0.27294922]
  [ 0.22521973]
  [ 0.27734375]
  [ 0.21728516]
  [ 0.28344727]
  [ 0.25268555]
  [ 0.19311523]
  [ 0.25463867]
  [ 0.19152832]
  [ 0.19555664]
  [ 0.28027344]
  [ 0.28100586]
  [ 0.27734375]
  [ 0.27026367]
  [ 0.19726562]
  [ 0.26538086]
  [ 0.27246094]]

 [[-2.96289062]
  [-2.95898438]
  [-3.00976562]
  [-2.97070312]
  [-3.04101562]
  [-2.96484375]
  [-3.05078125]
  [-2.95507812]
  [-3.00390625]
  [-3.08398438]
  [-2.99414062]
  [-3.08789062]
  [-3.08203125]
  [-2.9609375 ]
  [-2.9609375 ]
  [-2.96484375]
  [-2.9765625 ]
  [-3.08203125]
  [-2.984375  ]
  [-2.97265625]]

 [[-5.8125    ]
  [-5.80859375]
  [-5.87109375]
  [-5.82421875]
  [-5.9140625 ]
  [-5.81640625]
  [-5.92578125]
  [-5.80078125]
  [-5.8671875 ]
  [-5.96484375]
  [-5.8515625 ]
  [-5.96875   ]
  [-5.9609375 ]
  [-5.80859375]
  [-5.80859375]
  [-5.81640625]
  [-5.828125  ]
  [-5.9609375 ]
  [-5.83984375]
  [-5.82421875]]

 [[-7.94921875]
  [-7.9453125 ]
  [-8.015625  ]
  [-7.96484375]
  [-8.0703125 ]
  [-7.95703125]
  [-8.0859375 ]
  [-7.94140625]
  [-8.015625  ]
  [-8.125     ]
  [-7.99609375]
  [-8.1328125 ]
  [-8.125     ]
  [-7.94921875]
  [-7.94921875]
  [-7.95703125]
  [-7.97265625]
  [-8.125     ]
  [-7.98828125]
  [-7.96875   ]]

 [[-9.5546875 ]
  [-9.5546875 ]
  [-9.6328125 ]
  [-9.578125  ]
  [-9.6875    ]
  [-9.5625    ]
  [-9.703125  ]
  [-9.546875  ]
  [-9.625     ]
  [-9.75      ]
  [-9.609375  ]
  [-9.7578125 ]
  [-9.75      ]
  [-9.5546875 ]
  [-9.5546875 ]
  [-9.5625    ]
  [-9.5859375 ]
  [-9.75      ]
  [-9.6015625 ]
  [-9.578125  ]]]
After layer sequencemask18_output (10, 20, 1) <class 'numpy.float16'> [[[  5.31250000e-01]
  [  5.31250000e-01]
  [  5.30273438e-01]
  [  5.30761719e-01]
  [  5.30761719e-01]
  [  5.31250000e-01]
  [  5.29296875e-01]
  [  5.31250000e-01]
  [  5.33203125e-01]
  [  5.29296875e-01]
  [  5.31250000e-01]
  [  5.30273438e-01]
  [  5.31250000e-01]
  [  5.31250000e-01]
  [  5.31250000e-01]
  [  5.31250000e-01]
  [  5.30761719e-01]
  [  5.29785156e-01]
  [  5.30761719e-01]
  [  5.30761719e-01]]

 [[  9.24316406e-01]
  [  9.24316406e-01]
  [  9.22363281e-01]
  [  9.23828125e-01]
  [  9.22851562e-01]
  [  9.24316406e-01]
  [  9.22363281e-01]
  [  9.24316406e-01]
  [  9.24316406e-01]
  [  9.20898438e-01]
  [  9.22851562e-01]
  [  9.20898438e-01]
  [  9.20898438e-01]
  [  9.24316406e-01]
  [  9.24316406e-01]
  [  9.24316406e-01]
  [  9.23828125e-01]
  [  9.21386719e-01]
  [  9.24316406e-01]
  [  9.23828125e-01]]

 [[ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]]
After layer swapaxes46_output (20, 10, 1) <class 'numpy.float16'> [[[  5.31250000e-01]
  [  9.24316406e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  5.31250000e-01]
  [  9.24316406e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  5.30273438e-01]
  [  9.22363281e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  5.30761719e-01]
  [  9.23828125e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  5.30761719e-01]
  [  9.22851562e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  5.31250000e-01]
  [  9.24316406e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  5.29296875e-01]
  [  9.22363281e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  5.31250000e-01]
  [  9.24316406e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  5.33203125e-01]
  [  9.24316406e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  5.29296875e-01]
  [  9.20898438e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  5.31250000e-01]
  [  9.22851562e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  5.30273438e-01]
  [  9.20898438e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  5.31250000e-01]
  [  9.20898438e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  5.31250000e-01]
  [  9.24316406e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  5.31250000e-01]
  [  9.24316406e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  5.31250000e-01]
  [  9.24316406e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  5.30761719e-01]
  [  9.23828125e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  5.29785156e-01]
  [  9.21386719e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  5.30761719e-01]
  [  9.24316406e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  5.30761719e-01]
  [  9.23828125e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]]
After layer attention_softmax_0 (20, 10, 1) <class 'numpy.float16'> [[[ 0.40307617]
  [ 0.59716797]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40307617]
  [ 0.59716797]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40307617]
  [ 0.59667969]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40307617]
  [ 0.59716797]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40307617]
  [ 0.59667969]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40307617]
  [ 0.59716797]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40307617]
  [ 0.59716797]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40307617]
  [ 0.59716797]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40356445]
  [ 0.59667969]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40332031]
  [ 0.59667969]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40332031]
  [ 0.59667969]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40356445]
  [ 0.59619141]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40380859]
  [ 0.59619141]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40307617]
  [ 0.59716797]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40307617]
  [ 0.59716797]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40307617]
  [ 0.59716797]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40307617]
  [ 0.59716797]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40332031]
  [ 0.59667969]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40283203]
  [ 0.59716797]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40307617]
  [ 0.59716797]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]]
After layer batch_dot18_0 (20, 512, 1) <class 'numpy.float16'> [[[ 0.01786804]
  [ 0.03945923]
  [-0.03341675]
  ...,
  [-0.0109787 ]
  [ 0.00999451]
  [-0.02462769]]

 [[ 0.01786804]
  [ 0.03945923]
  [-0.03341675]
  ...,
  [-0.0109787 ]
  [ 0.00999451]
  [-0.02462769]]

 [[ 0.01785278]
  [ 0.03942871]
  [-0.03341675]
  ...,
  [-0.01097107]
  [ 0.00998688]
  [-0.02461243]]

 ...,
 [[ 0.01785278]
  [ 0.03945923]
  [-0.03341675]
  ...,
  [-0.01097107]
  [ 0.00999451]
  [-0.02462769]]

 [[ 0.01786804]
  [ 0.03945923]
  [-0.03341675]
  ...,
  [-0.01097107]
  [ 0.00999451]
  [-0.02461243]]

 [[ 0.01786804]
  [ 0.03945923]
  [-0.03341675]
  ...,
  [-0.0109787 ]
  [ 0.00999451]
  [-0.02462769]]]
After layer reshape36_0 (20, 512) <class 'numpy.float16'> [[ 0.01786804  0.03945923 -0.03341675 ..., -0.0109787   0.00999451
  -0.02462769]
 [ 0.01786804  0.03945923 -0.03341675 ..., -0.0109787   0.00999451
  -0.02462769]
 [ 0.01785278  0.03942871 -0.03341675 ..., -0.01097107  0.00998688
  -0.02461243]
 ...,
 [ 0.01785278  0.03945923 -0.03341675 ..., -0.01097107  0.00999451
  -0.02462769]
 [ 0.01786804  0.03945923 -0.03341675 ..., -0.01097107  0.00999451
  -0.02461243]
 [ 0.01786804  0.03945923 -0.03341675 ..., -0.0109787   0.00999451
  -0.02462769]]
After layer decoder_rnn_hidden_concat_t0_output (20, 1024) <class 'numpy.float16'> [[-0.00120258 -0.91845703  0.19763184 ..., -0.0109787   0.00999451
  -0.02462769]
 [-0.00120258 -0.91845703  0.19775391 ..., -0.0109787   0.00999451
  -0.02462769]
 [-0.00120544 -0.91894531  0.19714355 ..., -0.01097107  0.00998688
  -0.02461243]
 ...,
 [-0.00120354 -0.91943359  0.19641113 ..., -0.01097107  0.00999451
  -0.02462769]
 [-0.00119972 -0.91894531  0.19714355 ..., -0.01097107  0.00999451
  -0.02461243]
 [-0.00119972 -0.91894531  0.1973877  ..., -0.0109787   0.00999451
  -0.02462769]]
After layer decoder_rnn_hidden_fc_t0_output (20, 512) <class 'numpy.float16'> [[-1.97460938  0.21411133 -0.81884766 ...,  1.984375    2.11914062
  -1.60449219]
 [-1.97460938  0.21362305 -0.81835938 ...,  1.984375    2.11914062
  -1.60449219]
 [-1.97363281  0.21606445 -0.82226562 ...,  1.98242188  2.1171875
  -1.60644531]
 ...,
 [-1.97167969  0.21972656 -0.82861328 ...,  1.97753906  2.1171875
  -1.61230469]
 [-1.9765625   0.21704102 -0.82226562 ...,  1.984375    2.11914062
  -1.60546875]
 [-1.97460938  0.21496582 -0.8203125  ...,  1.984375    2.11914062
  -1.60449219]]
After layer decoder_rnn_next_hidden_t0_output (20, 512) <class 'numpy.float16'> [[-0.96240234  0.2109375  -0.67431641 ...,  0.96289062  0.97167969
  -0.92236328]
 [-0.96240234  0.21044922 -0.67431641 ...,  0.96289062  0.97167969
  -0.92236328]
 [-0.96191406  0.21276855 -0.67626953 ...,  0.96289062  0.97167969
  -0.92285156]
 ...,
 [-0.96191406  0.21630859 -0.6796875  ...,  0.96240234  0.97167969
  -0.92333984]
 [-0.96240234  0.21374512 -0.67626953 ...,  0.96289062  0.97167969
  -0.92236328]
 [-0.96240234  0.21166992 -0.67529297 ...,  0.96289062  0.97167969
  -0.92236328]]
After layer logits_output (20, 16743) <class 'numpy.float16'> [[-2.01367188 -2.82421875 -2.40820312 ..., -2.09375    -3.50195312
  -2.58789062]
 [-2.015625   -2.82421875 -2.40820312 ..., -2.09375    -3.50195312
  -2.58789062]
 [-2.01171875 -2.82617188 -2.40625    ..., -2.09375    -3.50195312
  -2.58984375]
 ...,
 [-2.01171875 -2.82617188 -2.40625    ..., -2.09570312 -3.5        -2.59179688]
 [-2.01367188 -2.82421875 -2.40820312 ..., -2.09375    -3.50195312
  -2.58984375]
 [-2.01367188 -2.82421875 -2.40820312 ..., -2.09375    -3.50195312
  -2.58789062]]
After layer softmax_0 (20, 16743) <class 'numpy.float16'> [[  8.34465027e-07   3.57627869e-07   5.36441803e-07 ...,   7.74860382e-07
    1.78813934e-07   4.76837158e-07]
 [  8.34465027e-07   3.57627869e-07   5.36441803e-07 ...,   7.74860382e-07
    1.78813934e-07   4.76837158e-07]
 [  8.34465027e-07   3.57627869e-07   5.96046448e-07 ...,   7.74860382e-07
    1.78813934e-07   4.76837158e-07]
 ...,
 [  8.34465027e-07   3.57627869e-07   5.96046448e-07 ...,   7.74860382e-07
    1.78813934e-07   4.76837158e-07]
 [  8.34465027e-07   3.57627869e-07   5.96046448e-07 ...,   7.74860382e-07
    1.78813934e-07   4.76837158e-07]
 [  8.34465027e-07   3.57627869e-07   5.96046448e-07 ...,   7.74860382e-07
    1.78813934e-07   4.76837158e-07]]
After layer reshape37_0 (20, 10) <class 'numpy.float16'> [[ 0.40307617  0.59716797  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40307617  0.59716797  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40307617  0.59667969  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40307617  0.59716797  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40307617  0.59667969  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40307617  0.59716797  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40307617  0.59716797  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40307617  0.59716797  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40356445  0.59667969  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40332031  0.59667969  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40332031  0.59667969  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40356445  0.59619141  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40380859  0.59619141  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40307617  0.59716797  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40307617  0.59716797  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40307617  0.59716797  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40307617  0.59716797  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40332031  0.59667969  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40283203  0.59716797  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40307617  0.59716797  0.          0.          0.          0.          0.
   0.          0.          0.        ]]
After layer target_embed_embed_0 (20, 256) <class 'numpy.float16'> [[-0.05505371 -0.0300293  -0.03598022 ...,  0.08459473 -0.05288696
  -0.01667786]
 [-0.05505371 -0.0300293  -0.03598022 ...,  0.08459473 -0.05288696
  -0.01667786]
 [-0.05505371 -0.0300293  -0.03598022 ...,  0.08459473 -0.05288696
  -0.01667786]
 ...,
 [-0.05505371 -0.0300293  -0.03598022 ...,  0.08459473 -0.05288696
  -0.01667786]
 [-0.05505371 -0.0300293  -0.03598022 ...,  0.08459473 -0.05288696
  -0.01667786]
 [-0.05505371 -0.0300293  -0.03598022 ...,  0.08459473 -0.05288696
  -0.01667786]]
After layer decoder_rnn_concat_target_context_t0_output (20, 768) <class 'numpy.float16'> [[-0.05505371 -0.0300293  -0.03598022 ...,  0.96289062  0.97167969
  -0.92236328]
 [-0.05505371 -0.0300293  -0.03598022 ...,  0.96289062  0.97167969
  -0.92236328]
 [-0.05505371 -0.0300293  -0.03598022 ...,  0.96289062  0.97167969
  -0.92285156]
 ...,
 [-0.05505371 -0.0300293  -0.03598022 ...,  0.96240234  0.97167969
  -0.92333984]
 [-0.05505371 -0.0300293  -0.03598022 ...,  0.96289062  0.97167969
  -0.92236328]
 [-0.05505371 -0.0300293  -0.03598022 ...,  0.96289062  0.97167969
  -0.92236328]]
After layer decoder_rnn_l0_t0_i2h_output (20, 2048) <class 'numpy.float16'> [[-3.19726562  1.60742188  2.44140625 ..., -0.0770874   3.86523438
   0.59570312]
 [-3.19726562  1.60742188  2.44140625 ..., -0.07720947  3.86523438
   0.59570312]
 [-3.1953125   1.60644531  2.44335938 ..., -0.07684326  3.8671875
   0.59814453]
 ...,
 [-3.1953125   1.60546875  2.44335938 ..., -0.07635498  3.8671875
   0.60205078]
 [-3.1953125   1.60644531  2.44335938 ..., -0.07653809  3.86523438
   0.59619141]
 [-3.19726562  1.60742188  2.44335938 ..., -0.0769043   3.86523438
   0.59619141]]
After layer decoder_rnn_l0_t0_h2h_output (20, 2048) <class 'numpy.float16'> [[-0.32275391  0.47241211  1.859375   ...,  0.71337891  1.29492188
   0.17687988]
 [-0.32324219  0.47216797  1.859375   ...,  0.71289062  1.29492188
   0.17675781]
 [-0.32446289  0.4765625   1.85644531 ...,  0.71289062  1.29882812
   0.17321777]
 ...,
 [-0.32910156  0.48413086  1.85644531 ...,  0.71240234  1.30371094
   0.16711426]
 [-0.32324219  0.47558594  1.85839844 ...,  0.71240234  1.29785156
   0.1739502 ]
 [-0.32373047  0.47387695  1.85839844 ...,  0.71289062  1.29589844
   0.17529297]]
After layer _plus1063_0 (20, 2048) <class 'numpy.float16'> [[-3.51953125  2.08007812  4.30078125 ...,  0.63623047  5.16015625
   0.77246094]
 [-3.51953125  2.08007812  4.30078125 ...,  0.63574219  5.16015625
   0.77246094]
 [-3.51953125  2.08203125  4.30078125 ...,  0.63623047  5.1640625
   0.77148438]
 ...,
 [-3.5234375   2.08984375  4.30078125 ...,  0.63623047  5.171875
   0.76904297]
 [-3.51953125  2.08203125  4.30078125 ...,  0.63574219  5.1640625
   0.77001953]
 [-3.52148438  2.08203125  4.30078125 ...,  0.63574219  5.16015625
   0.77148438]]
After layer decoder_rnn_l0_t0_slice_output0 (20, 512) <class 'numpy.float16'> [[-3.51953125  2.08007812  4.30078125 ...,  1.73828125  4.62109375  2.78125   ]
 [-3.51953125  2.08007812  4.30078125 ...,  1.73828125  4.62109375  2.78125   ]
 [-3.51953125  2.08203125  4.30078125 ...,  1.74121094  4.6171875   2.78125   ]
 ...,
 [-3.5234375   2.08984375  4.30078125 ...,  1.74609375  4.61328125
   2.77734375]
 [-3.51953125  2.08203125  4.30078125 ...,  1.73828125  4.6171875
   2.77734375]
 [-3.52148438  2.08203125  4.30078125 ...,  1.73828125  4.6171875
   2.77929688]]
After layer decoder_rnn_l0_t0_slice_output1 (20, 512) <class 'numpy.float16'> [[-1.85351562  2.32226562  2.44335938 ...,  3.16796875 -0.68652344
   1.99023438]
 [-1.85351562  2.32226562  2.44335938 ...,  3.16796875 -0.68652344
   1.99023438]
 [-1.85839844  2.3203125   2.44726562 ...,  3.16796875 -0.68847656
   1.98828125]
 ...,
 [-1.86328125  2.31640625  2.453125   ...,  3.1640625  -0.68847656
   1.98828125]
 [-1.85546875  2.3203125   2.4453125  ...,  3.16601562 -0.68701172
   1.99023438]
 [-1.85449219  2.32226562  2.4453125  ...,  3.16796875 -0.68652344
   1.99023438]]
After layer decoder_rnn_l0_t0_slice_output2 (20, 512) <class 'numpy.float16'> [[-2.81640625 -3.09765625  2.85546875 ...,  4.265625   -0.08203125
   2.16015625]
 [-2.81640625 -3.09765625  2.85546875 ...,  4.265625   -0.08203125
   2.15820312]
 [-2.8203125  -3.1015625   2.86328125 ...,  4.2578125  -0.08447266
   2.15820312]
 ...,
 [-2.82226562 -3.10546875  2.87890625 ...,  4.25       -0.08862305  2.15625   ]
 [-2.81835938 -3.1015625   2.859375   ...,  4.2578125  -0.0847168
   2.15820312]
 [-2.81835938 -3.09960938  2.85742188 ...,  4.26171875 -0.08349609
   2.16015625]]
After layer decoder_rnn_l0_t0_slice_output3 (20, 512) <class 'numpy.float16'> [[-3.27734375  2.42382812 -1.40136719 ...,  0.63623047  5.16015625
   0.77246094]
 [-3.27734375  2.42382812 -1.40039062 ...,  0.63574219  5.16015625
   0.77246094]
 [-3.27539062  2.42773438 -1.40429688 ...,  0.63623047  5.1640625
   0.77148438]
 ...,
 [-3.26953125  2.43164062 -1.40820312 ...,  0.63623047  5.171875
   0.76904297]
 [-3.27539062  2.42382812 -1.40429688 ...,  0.63574219  5.1640625
   0.77001953]
 [-3.27539062  2.42382812 -1.40234375 ...,  0.63574219  5.16015625
   0.77148438]]
After layer decoder_rnn_l0_t0_o_output (20, 512) <class 'numpy.float16'> [[ 0.03634644  0.91845703  0.19763184 ...,  0.65380859  0.99414062
   0.68408203]
 [ 0.03634644  0.91845703  0.19775391 ...,  0.65380859  0.99414062
   0.68408203]
 [ 0.03643799  0.91894531  0.19714355 ...,  0.65380859  0.99414062
   0.68408203]
 ...,
 [ 0.03662109  0.91943359  0.1965332  ...,  0.65380859  0.99414062
   0.68310547]
 [ 0.03643799  0.91845703  0.19714355 ...,  0.65380859  0.99414062
   0.68359375]
 [ 0.03643799  0.91845703  0.1973877  ...,  0.65380859  0.99414062
   0.68408203]]
After layer decoder_rnn_l0_t0_f_output (20, 512) <class 'numpy.float16'> [[ 0.13549805  0.91064453  0.91992188 ...,  0.95947266  0.3347168
   0.87988281]
 [ 0.13549805  0.91064453  0.91992188 ...,  0.95947266  0.3347168
   0.87988281]
 [ 0.1348877   0.91064453  0.92041016 ...,  0.95947266  0.33447266
   0.87939453]
 ...,
 [ 0.13427734  0.91015625  0.92089844 ...,  0.95947266  0.33447266
   0.87939453]
 [ 0.13525391  0.91064453  0.92041016 ...,  0.95947266  0.3347168
   0.87988281]
 [ 0.13537598  0.91064453  0.92041016 ...,  0.95947266  0.3347168
   0.87988281]]
After layer _mul2126_0 (20, 512) <class 'numpy.float16'> [[ -4.48226929e-03  -7.02734375e+00   8.27343750e+00 ...,   1.00000000e+01
   -4.08935547e-02   5.80468750e+00]
 [ -4.48226929e-03  -7.02343750e+00   8.24218750e+00 ...,   9.94531250e+00
   -4.09545898e-02   5.78515625e+00]
 [ -4.45556641e-03  -6.99609375e+00   8.27343750e+00 ...,   9.85156250e+00
   -4.22058105e-02   5.74218750e+00]
 ...,
 [ -4.41360474e-03  -6.83984375e+00   8.12500000e+00 ...,   9.51562500e+00
   -4.49829102e-02   5.48046875e+00]
 [ -4.46701050e-03  -7.02343750e+00   8.24218750e+00 ...,   9.89843750e+00
   -4.25720215e-02   5.75390625e+00]
 [ -4.47082520e-03  -7.02734375e+00   8.25000000e+00 ...,   9.89843750e+00
   -4.18090820e-02   5.76562500e+00]]
After layer decoder_rnn_l0_t0_i_output (20, 512) <class 'numpy.float16'> [[ 0.02876282  0.88916016  0.98681641 ...,  0.85058594  0.99023438
   0.94189453]
 [ 0.02876282  0.88916016  0.98681641 ...,  0.85058594  0.99023438
   0.94189453]
 [ 0.02876282  0.88916016  0.98681641 ...,  0.85107422  0.99023438
   0.94189453]
 ...,
 [ 0.02865601  0.89013672  0.98681641 ...,  0.8515625   0.99023438
   0.94140625]
 [ 0.02876282  0.88916016  0.98681641 ...,  0.85058594  0.99023438
   0.94140625]
 [ 0.02870178  0.88916016  0.98681641 ...,  0.85058594  0.99023438
   0.94140625]]
After layer decoder_rnn_l0_t0_c_output (20, 512) <class 'numpy.float16'> [[-0.99267578 -0.99609375  0.99316406 ...,  0.99951172 -0.08184814
   0.97363281]
 [-0.99267578 -0.99609375  0.99316406 ...,  0.99951172 -0.08184814
   0.97363281]
 [-0.99316406 -0.99609375  0.99365234 ...,  0.99951172 -0.08428955
   0.97363281]
 ...,
 [-0.99316406 -0.99609375  0.99365234 ...,  0.99951172 -0.08837891
   0.97363281]
 [-0.99267578 -0.99609375  0.99365234 ...,  0.99951172 -0.08453369
   0.97363281]
 [-0.99267578 -0.99609375  0.99365234 ...,  0.99951172 -0.08331299
   0.97363281]]
After layer _mul2127_0 (20, 512) <class 'numpy.float16'> [[-0.02854919 -0.88574219  0.97998047 ...,  0.85009766 -0.08105469
   0.91699219]
 [-0.02854919 -0.88574219  0.97998047 ...,  0.85009766 -0.08105469
   0.91699219]
 [-0.02856445 -0.88574219  0.98046875 ...,  0.85058594 -0.08349609
   0.91699219]
 ...,
 [-0.02845764 -0.88671875  0.98046875 ...,  0.85107422 -0.08752441
   0.91650391]
 [-0.02854919 -0.88574219  0.98046875 ...,  0.85009766 -0.0836792
   0.91650391]
 [-0.02848816 -0.88574219  0.98046875 ...,  0.85009766 -0.08251953
   0.91650391]]
After layer decoder_rnn_l0_t0_state_0 (20, 512) <class 'numpy.float16'> [[ -0.03302002  -7.9140625    9.25       ...,  10.8515625   -0.12194824
    6.72265625]
 [ -0.03302002  -7.91015625   9.21875    ...,  10.796875    -0.12200928
    6.703125  ]
 [ -0.03302002  -7.8828125    9.25       ...,  10.703125    -0.12573242
    6.66015625]
 ...,
 [ -0.03286743  -7.7265625    9.109375   ...,  10.3671875   -0.13256836
    6.3984375 ]
 [ -0.03302002  -7.91015625   9.21875    ...,  10.75        -0.1262207
    6.671875  ]
 [ -0.03295898  -7.9140625    9.234375   ...,  10.75        -0.12432861
    6.68359375]]
After layer activation1063_output (20, 512) <class 'numpy.float16'> [[-0.03302002 -1.          1.         ...,  1.         -0.12133789  1.        ]
 [-0.03302002 -1.          1.         ...,  1.         -0.12139893  1.        ]
 [-0.03302002 -1.          1.         ...,  1.         -0.12512207  1.        ]
 ...,
 [-0.03286743 -1.          1.         ...,  1.         -0.13183594  1.        ]
 [-0.03302002 -1.          1.         ...,  1.         -0.12561035  1.        ]
 [-0.03295898 -1.          1.         ...,  1.         -0.12371826  1.        ]]
After layer decoder_rnn_l0_t0_out_0 (20, 512) <class 'numpy.float16'> [[-0.00119972 -0.91845703  0.19763184 ...,  0.65380859 -0.12060547
   0.68408203]
 [-0.00119972 -0.91845703  0.19775391 ...,  0.65380859 -0.1206665
   0.68408203]
 [-0.00120354 -0.91894531  0.19714355 ...,  0.65380859 -0.12438965
   0.68408203]
 ...,
 [-0.00120354 -0.91943359  0.1965332  ...,  0.65380859 -0.13110352
   0.68310547]
 [-0.00120354 -0.91845703  0.19714355 ...,  0.65380859 -0.12487793
   0.68359375]
 [-0.00120068 -0.91845703  0.1973877  ...,  0.65380859 -0.12298584
   0.68408203]]
After layer expand_dims1072_0 (20, 512, 1) <class 'numpy.float16'> [[[-0.00119972]
  [-0.91845703]
  [ 0.19763184]
  ...,
  [ 0.65380859]
  [-0.12060547]
  [ 0.68408203]]

 [[-0.00119972]
  [-0.91845703]
  [ 0.19775391]
  ...,
  [ 0.65380859]
  [-0.1206665 ]
  [ 0.68408203]]

 [[-0.00120354]
  [-0.91894531]
  [ 0.19714355]
  ...,
  [ 0.65380859]
  [-0.12438965]
  [ 0.68408203]]

 ...,
 [[-0.00120354]
  [-0.91943359]
  [ 0.1965332 ]
  ...,
  [ 0.65380859]
  [-0.13110352]
  [ 0.68310547]]

 [[-0.00120354]
  [-0.91845703]
  [ 0.19714355]
  ...,
  [ 0.65380859]
  [-0.12487793]
  [ 0.68359375]]

 [[-0.00120068]
  [-0.91845703]
  [ 0.1973877 ]
  ...,
  [ 0.65380859]
  [-0.12298584]
  [ 0.68408203]]]
After layer att_batch_dot_0 (20, 10, 1) <class 'numpy.float16'> [[[ 0.53125   ]
  [ 0.92480469]
  [ 1.63867188]
  [ 2.609375  ]
  [ 2.52929688]
  [ 0.28027344]
  [-2.96289062]
  [-5.8125    ]
  [-7.953125  ]
  [-9.5625    ]]

 [[ 0.53125   ]
  [ 0.92431641]
  [ 1.63867188]
  [ 2.609375  ]
  [ 2.52929688]
  [ 0.27954102]
  [-2.96289062]
  [-5.8125    ]
  [-7.953125  ]
  [-9.5625    ]]

 [[ 0.53076172]
  [ 0.92333984]
  [ 1.63378906]
  [ 2.59960938]
  [ 2.51171875]
  [ 0.25      ]
  [-3.00390625]
  [-5.86328125]
  [-8.015625  ]
  [-9.625     ]]

 [[ 0.53125   ]
  [ 0.92480469]
  [ 1.63867188]
  [ 2.609375  ]
  [ 2.52929688]
  [ 0.27661133]
  [-2.96875   ]
  [-5.8203125 ]
  [-7.96484375]
  [-9.5703125 ]]

 [[ 0.53076172]
  [ 0.92382812]
  [ 1.6328125 ]
  [ 2.59765625]
  [ 2.50195312]
  [ 0.23083496]
  [-3.03515625]
  [-5.90625   ]
  [-8.0625    ]
  [-9.6875    ]]

 [[ 0.52929688]
  [ 0.92285156]
  [ 1.63085938]
  [ 2.59375   ]
  [ 2.49804688]
  [ 0.22363281]
  [-3.04492188]
  [-5.91796875]
  [-8.078125  ]
  [-9.6953125 ]]

 [[ 0.53125   ]
  [ 0.92480469]
  [ 1.63964844]
  [ 2.61132812]
  [ 2.53125   ]
  [ 0.2800293 ]
  [-2.96289062]
  [-5.81640625]
  [-7.95703125]
  [-9.5625    ]]

 [[ 0.53125   ]
  [ 0.92480469]
  [ 1.63964844]
  [ 2.61132812]
  [ 2.53125   ]
  [ 0.2824707 ]
  [-2.95898438]
  [-5.80859375]
  [-7.94921875]
  [-9.5546875 ]]

 [[ 0.53320312]
  [ 0.92480469]
  [ 1.63769531]
  [ 2.60546875]
  [ 2.51953125]
  [ 0.25756836]
  [-2.99804688]
  [-5.859375  ]
  [-8.0078125 ]
  [-9.625     ]]

 [[ 0.52978516]
  [ 0.921875  ]
  [ 1.62695312]
  [ 2.5859375 ]
  [ 2.48242188]
  [ 0.20007324]
  [-3.07617188]
  [-5.953125  ]
  [-8.1171875 ]
  [-9.7421875 ]]

 [[ 0.53125   ]
  [ 0.92333984]
  [ 1.63476562]
  [ 2.6015625 ]
  [ 2.515625  ]
  [ 0.25805664]
  [-2.9921875 ]
  [-5.84765625]
  [-7.9921875 ]
  [-9.6015625 ]]

 [[ 0.53076172]
  [ 0.921875  ]
  [ 1.62792969]
  [ 2.5859375 ]
  [ 2.48242188]
  [ 0.19934082]
  [-3.078125  ]
  [-5.95703125]
  [-8.125     ]
  [-9.75      ]]

 [[ 0.53125   ]
  [ 0.92480469]
  [ 1.63867188]
  [ 2.61132812]
  [ 2.53125   ]
  [ 0.28100586]
  [-2.9609375 ]
  [-5.8125    ]
  [-7.953125  ]
  [-9.5625    ]]

 [[ 0.53173828]
  [ 0.921875  ]
  [ 1.62890625]
  [ 2.58789062]
  [ 2.48632812]
  [ 0.20495605]
  [-3.0703125 ]
  [-5.94921875]
  [-8.109375  ]
  [-9.734375  ]]

 [[ 0.53125   ]
  [ 0.92480469]
  [ 1.63964844]
  [ 2.61132812]
  [ 2.53125   ]
  [ 0.28100586]
  [-2.9609375 ]
  [-5.8125    ]
  [-7.953125  ]
  [-9.5625    ]]

 [[ 0.53125   ]
  [ 0.92480469]
  [ 1.63964844]
  [ 2.61132812]
  [ 2.53125   ]
  [ 0.28076172]
  [-2.96289062]
  [-5.8125    ]
  [-7.953125  ]
  [-9.5625    ]]

 [[ 0.53125   ]
  [ 0.92480469]
  [ 1.63867188]
  [ 2.609375  ]
  [ 2.52734375]
  [ 0.27368164]
  [-2.97265625]
  [-5.828125  ]
  [-7.96875   ]
  [-9.578125  ]]

 [[ 0.53027344]
  [ 0.92236328]
  [ 1.62890625]
  [ 2.58984375]
  [ 2.48828125]
  [ 0.20532227]
  [-3.07226562]
  [-5.953125  ]
  [-8.1171875 ]
  [-9.7421875 ]]

 [[ 0.53076172]
  [ 0.92480469]
  [ 1.63769531]
  [ 2.60742188]
  [ 2.5234375 ]
  [ 0.26782227]
  [-2.98242188]
  [-5.83984375]
  [-7.984375  ]
  [-9.6015625 ]]

 [[ 0.53125   ]
  [ 0.92431641]
  [ 1.63867188]
  [ 2.609375  ]
  [ 2.52734375]
  [ 0.27416992]
  [-2.97070312]
  [-5.82421875]
  [-7.96875   ]
  [-9.578125  ]]]
After layer swapaxes47_output (10, 20, 1) <class 'numpy.float16'> [[[ 0.53125   ]
  [ 0.53125   ]
  [ 0.53076172]
  [ 0.53125   ]
  [ 0.53076172]
  [ 0.52929688]
  [ 0.53125   ]
  [ 0.53125   ]
  [ 0.53320312]
  [ 0.52978516]
  [ 0.53125   ]
  [ 0.53076172]
  [ 0.53125   ]
  [ 0.53173828]
  [ 0.53125   ]
  [ 0.53125   ]
  [ 0.53125   ]
  [ 0.53027344]
  [ 0.53076172]
  [ 0.53125   ]]

 [[ 0.92480469]
  [ 0.92431641]
  [ 0.92333984]
  [ 0.92480469]
  [ 0.92382812]
  [ 0.92285156]
  [ 0.92480469]
  [ 0.92480469]
  [ 0.92480469]
  [ 0.921875  ]
  [ 0.92333984]
  [ 0.921875  ]
  [ 0.92480469]
  [ 0.921875  ]
  [ 0.92480469]
  [ 0.92480469]
  [ 0.92480469]
  [ 0.92236328]
  [ 0.92480469]
  [ 0.92431641]]

 [[ 1.63867188]
  [ 1.63867188]
  [ 1.63378906]
  [ 1.63867188]
  [ 1.6328125 ]
  [ 1.63085938]
  [ 1.63964844]
  [ 1.63964844]
  [ 1.63769531]
  [ 1.62695312]
  [ 1.63476562]
  [ 1.62792969]
  [ 1.63867188]
  [ 1.62890625]
  [ 1.63964844]
  [ 1.63964844]
  [ 1.63867188]
  [ 1.62890625]
  [ 1.63769531]
  [ 1.63867188]]

 [[ 2.609375  ]
  [ 2.609375  ]
  [ 2.59960938]
  [ 2.609375  ]
  [ 2.59765625]
  [ 2.59375   ]
  [ 2.61132812]
  [ 2.61132812]
  [ 2.60546875]
  [ 2.5859375 ]
  [ 2.6015625 ]
  [ 2.5859375 ]
  [ 2.61132812]
  [ 2.58789062]
  [ 2.61132812]
  [ 2.61132812]
  [ 2.609375  ]
  [ 2.58984375]
  [ 2.60742188]
  [ 2.609375  ]]

 [[ 2.52929688]
  [ 2.52929688]
  [ 2.51171875]
  [ 2.52929688]
  [ 2.50195312]
  [ 2.49804688]
  [ 2.53125   ]
  [ 2.53125   ]
  [ 2.51953125]
  [ 2.48242188]
  [ 2.515625  ]
  [ 2.48242188]
  [ 2.53125   ]
  [ 2.48632812]
  [ 2.53125   ]
  [ 2.53125   ]
  [ 2.52734375]
  [ 2.48828125]
  [ 2.5234375 ]
  [ 2.52734375]]

 [[ 0.28027344]
  [ 0.27954102]
  [ 0.25      ]
  [ 0.27661133]
  [ 0.23083496]
  [ 0.22363281]
  [ 0.2800293 ]
  [ 0.2824707 ]
  [ 0.25756836]
  [ 0.20007324]
  [ 0.25805664]
  [ 0.19934082]
  [ 0.28100586]
  [ 0.20495605]
  [ 0.28100586]
  [ 0.28076172]
  [ 0.27368164]
  [ 0.20532227]
  [ 0.26782227]
  [ 0.27416992]]

 [[-2.96289062]
  [-2.96289062]
  [-3.00390625]
  [-2.96875   ]
  [-3.03515625]
  [-3.04492188]
  [-2.96289062]
  [-2.95898438]
  [-2.99804688]
  [-3.07617188]
  [-2.9921875 ]
  [-3.078125  ]
  [-2.9609375 ]
  [-3.0703125 ]
  [-2.9609375 ]
  [-2.96289062]
  [-2.97265625]
  [-3.07226562]
  [-2.98242188]
  [-2.97070312]]

 [[-5.8125    ]
  [-5.8125    ]
  [-5.86328125]
  [-5.8203125 ]
  [-5.90625   ]
  [-5.91796875]
  [-5.81640625]
  [-5.80859375]
  [-5.859375  ]
  [-5.953125  ]
  [-5.84765625]
  [-5.95703125]
  [-5.8125    ]
  [-5.94921875]
  [-5.8125    ]
  [-5.8125    ]
  [-5.828125  ]
  [-5.953125  ]
  [-5.83984375]
  [-5.82421875]]

 [[-7.953125  ]
  [-7.953125  ]
  [-8.015625  ]
  [-7.96484375]
  [-8.0625    ]
  [-8.078125  ]
  [-7.95703125]
  [-7.94921875]
  [-8.0078125 ]
  [-8.1171875 ]
  [-7.9921875 ]
  [-8.125     ]
  [-7.953125  ]
  [-8.109375  ]
  [-7.953125  ]
  [-7.953125  ]
  [-7.96875   ]
  [-8.1171875 ]
  [-7.984375  ]
  [-7.96875   ]]

 [[-9.5625    ]
  [-9.5625    ]
  [-9.625     ]
  [-9.5703125 ]
  [-9.6875    ]
  [-9.6953125 ]
  [-9.5625    ]
  [-9.5546875 ]
  [-9.625     ]
  [-9.7421875 ]
  [-9.6015625 ]
  [-9.75      ]
  [-9.5625    ]
  [-9.734375  ]
  [-9.5625    ]
  [-9.5625    ]
  [-9.578125  ]
  [-9.7421875 ]
  [-9.6015625 ]
  [-9.578125  ]]]
After layer sequencemask19_output (10, 20, 1) <class 'numpy.float16'> [[[  5.31250000e-01]
  [  5.31250000e-01]
  [  5.30761719e-01]
  [  5.31250000e-01]
  [  5.30761719e-01]
  [  5.29296875e-01]
  [  5.31250000e-01]
  [  5.31250000e-01]
  [  5.33203125e-01]
  [  5.29785156e-01]
  [  5.31250000e-01]
  [  5.30761719e-01]
  [  5.31250000e-01]
  [  5.31738281e-01]
  [  5.31250000e-01]
  [  5.31250000e-01]
  [  5.31250000e-01]
  [  5.30273438e-01]
  [  5.30761719e-01]
  [  5.31250000e-01]]

 [[  9.24804688e-01]
  [  9.24316406e-01]
  [  9.23339844e-01]
  [  9.24804688e-01]
  [  9.23828125e-01]
  [  9.22851562e-01]
  [  9.24804688e-01]
  [  9.24804688e-01]
  [  9.24804688e-01]
  [  9.21875000e-01]
  [  9.23339844e-01]
  [  9.21875000e-01]
  [  9.24804688e-01]
  [  9.21875000e-01]
  [  9.24804688e-01]
  [  9.24804688e-01]
  [  9.24804688e-01]
  [  9.22363281e-01]
  [  9.24804688e-01]
  [  9.24316406e-01]]

 [[ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]]
After layer swapaxes48_output (20, 10, 1) <class 'numpy.float16'> [[[  5.31250000e-01]
  [  9.24804688e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  5.31250000e-01]
  [  9.24316406e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  5.30761719e-01]
  [  9.23339844e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  5.31250000e-01]
  [  9.24804688e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  5.30761719e-01]
  [  9.23828125e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  5.29296875e-01]
  [  9.22851562e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  5.31250000e-01]
  [  9.24804688e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  5.31250000e-01]
  [  9.24804688e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  5.33203125e-01]
  [  9.24804688e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  5.29785156e-01]
  [  9.21875000e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  5.31250000e-01]
  [  9.23339844e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  5.30761719e-01]
  [  9.21875000e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  5.31250000e-01]
  [  9.24804688e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  5.31738281e-01]
  [  9.21875000e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  5.31250000e-01]
  [  9.24804688e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  5.31250000e-01]
  [  9.24804688e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  5.31250000e-01]
  [  9.24804688e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  5.30273438e-01]
  [  9.22363281e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  5.30761719e-01]
  [  9.24804688e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  5.31250000e-01]
  [  9.24316406e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]]
After layer attention_softmax_0 (20, 10, 1) <class 'numpy.float16'> [[[ 0.40283203]
  [ 0.59716797]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40307617]
  [ 0.59716797]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40307617]
  [ 0.59667969]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40283203]
  [ 0.59716797]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40307617]
  [ 0.59716797]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40283203]
  [ 0.59716797]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40283203]
  [ 0.59716797]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40283203]
  [ 0.59716797]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40332031]
  [ 0.59667969]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40307617]
  [ 0.59667969]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40307617]
  [ 0.59667969]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40356445]
  [ 0.59667969]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40283203]
  [ 0.59716797]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40380859]
  [ 0.59619141]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40283203]
  [ 0.59716797]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40283203]
  [ 0.59716797]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40283203]
  [ 0.59716797]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40307617]
  [ 0.59667969]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40283203]
  [ 0.59765625]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40307617]
  [ 0.59716797]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]]
After layer batch_dot19_0 (20, 512, 1) <class 'numpy.float16'> [[[ 0.01786804]
  [ 0.03945923]
  [-0.03341675]
  ...,
  [-0.01097107]
  [ 0.00999451]
  [-0.02461243]]

 [[ 0.01786804]
  [ 0.03945923]
  [-0.03341675]
  ...,
  [-0.0109787 ]
  [ 0.00999451]
  [-0.02462769]]

 [[ 0.01785278]
  [ 0.03942871]
  [-0.03341675]
  ...,
  [-0.01097107]
  [ 0.00998688]
  [-0.02461243]]

 ...,
 [[ 0.01785278]
  [ 0.03942871]
  [-0.03341675]
  ...,
  [-0.01097107]
  [ 0.00998688]
  [-0.02461243]]

 [[ 0.0178833 ]
  [ 0.03948975]
  [-0.03344727]
  ...,
  [-0.0109787 ]
  [ 0.00999451]
  [-0.02462769]]

 [[ 0.01786804]
  [ 0.03945923]
  [-0.03341675]
  ...,
  [-0.0109787 ]
  [ 0.00999451]
  [-0.02462769]]]
After layer reshape38_0 (20, 512) <class 'numpy.float16'> [[ 0.01786804  0.03945923 -0.03341675 ..., -0.01097107  0.00999451
  -0.02461243]
 [ 0.01786804  0.03945923 -0.03341675 ..., -0.0109787   0.00999451
  -0.02462769]
 [ 0.01785278  0.03942871 -0.03341675 ..., -0.01097107  0.00998688
  -0.02461243]
 ...,
 [ 0.01785278  0.03942871 -0.03341675 ..., -0.01097107  0.00998688
  -0.02461243]
 [ 0.0178833   0.03948975 -0.03344727 ..., -0.0109787   0.00999451
  -0.02462769]
 [ 0.01786804  0.03945923 -0.03341675 ..., -0.0109787   0.00999451
  -0.02462769]]
After layer decoder_rnn_hidden_concat_t0_output (20, 1024) <class 'numpy.float16'> [[-0.00119972 -0.91845703  0.19763184 ..., -0.01097107  0.00999451
  -0.02461243]
 [-0.00119972 -0.91845703  0.19775391 ..., -0.0109787   0.00999451
  -0.02462769]
 [-0.00120354 -0.91894531  0.19714355 ..., -0.01097107  0.00998688
  -0.02461243]
 ...,
 [-0.00120354 -0.91943359  0.1965332  ..., -0.01097107  0.00998688
  -0.02461243]
 [-0.00120354 -0.91845703  0.19714355 ..., -0.0109787   0.00999451
  -0.02462769]
 [-0.00120068 -0.91845703  0.1973877  ..., -0.0109787   0.00999451
  -0.02462769]]
After layer decoder_rnn_hidden_fc_t0_output (20, 512) <class 'numpy.float16'> [[-1.97558594  0.21508789 -0.81982422 ...,  1.984375    2.12109375
  -1.60546875]
 [-1.97558594  0.2142334  -0.81933594 ...,  1.984375    2.12109375
  -1.60546875]
 [-1.97460938  0.21655273 -0.82275391 ...,  1.98242188  2.11914062
  -1.60742188]
 ...,
 [-1.97265625  0.22045898 -0.82910156 ...,  1.97851562  2.1171875
  -1.61328125]
 [-1.9765625   0.21777344 -0.82324219 ...,  1.984375    2.11914062
  -1.60742188]
 [-1.97558594  0.21569824 -0.82128906 ...,  1.984375    2.12109375
  -1.60644531]]
After layer decoder_rnn_next_hidden_t0_output (20, 512) <class 'numpy.float16'> [[-0.96240234  0.21179199 -0.67480469 ...,  0.96289062  0.97167969
  -0.92236328]
 [-0.96240234  0.21105957 -0.67480469 ...,  0.96289062  0.97167969
  -0.92236328]
 [-0.96240234  0.21325684 -0.67675781 ...,  0.96289062  0.97167969
  -0.92285156]
 ...,
 [-0.96191406  0.21691895 -0.68017578 ...,  0.96240234  0.97167969
  -0.92382812]
 [-0.96240234  0.21435547 -0.67675781 ...,  0.96289062  0.97167969
  -0.92285156]
 [-0.96240234  0.21240234 -0.67578125 ...,  0.96289062  0.97167969
  -0.92285156]]
After layer logits_output (20, 16743) <class 'numpy.float16'> [[-2.015625   -2.82421875 -2.40820312 ..., -2.09375    -3.50390625
  -2.58789062]
 [-2.015625   -2.82617188 -2.40820312 ..., -2.09375    -3.50195312
  -2.58789062]
 [-2.01367188 -2.82617188 -2.40820312 ..., -2.09375    -3.50195312
  -2.58984375]
 ...,
 [-2.01367188 -2.82617188 -2.40625    ..., -2.09570312 -3.5        -2.59375   ]
 [-2.015625   -2.82421875 -2.40820312 ..., -2.09375    -3.50195312
  -2.58984375]
 [-2.015625   -2.82421875 -2.40820312 ..., -2.09375    -3.50195312
  -2.58984375]]
After layer softmax_0 (20, 16743) <class 'numpy.float16'> [[  8.34465027e-07   3.57627869e-07   5.36441803e-07 ...,   7.74860382e-07
    1.78813934e-07   4.76837158e-07]
 [  8.34465027e-07   3.57627869e-07   5.36441803e-07 ...,   7.74860382e-07
    1.78813934e-07   4.76837158e-07]
 [  8.34465027e-07   3.57627869e-07   5.96046448e-07 ...,   7.74860382e-07
    1.78813934e-07   4.76837158e-07]
 ...,
 [  8.34465027e-07   3.57627869e-07   5.96046448e-07 ...,   7.74860382e-07
    1.78813934e-07   4.76837158e-07]
 [  8.34465027e-07   3.57627869e-07   5.96046448e-07 ...,   7.74860382e-07
    1.78813934e-07   4.76837158e-07]
 [  8.34465027e-07   3.57627869e-07   5.96046448e-07 ...,   7.74860382e-07
    1.78813934e-07   4.76837158e-07]]
After layer reshape39_0 (20, 10) <class 'numpy.float16'> [[ 0.40283203  0.59716797  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40307617  0.59716797  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40307617  0.59667969  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40283203  0.59716797  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40307617  0.59716797  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40283203  0.59716797  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40283203  0.59716797  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40283203  0.59716797  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40332031  0.59667969  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40307617  0.59667969  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40307617  0.59667969  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40356445  0.59667969  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40283203  0.59716797  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40380859  0.59619141  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40283203  0.59716797  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40283203  0.59716797  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40283203  0.59716797  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40307617  0.59667969  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40283203  0.59765625  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40307617  0.59716797  0.          0.          0.          0.          0.
   0.          0.          0.        ]]
After layer target_embed_embed_0 (20, 256) <class 'numpy.float16'> [[-0.05505371 -0.0300293  -0.03598022 ...,  0.08459473 -0.05288696
  -0.01667786]
 [-0.05505371 -0.0300293  -0.03598022 ...,  0.08459473 -0.05288696
  -0.01667786]
 [-0.05505371 -0.0300293  -0.03598022 ...,  0.08459473 -0.05288696
  -0.01667786]
 ...,
 [-0.05505371 -0.0300293  -0.03598022 ...,  0.08459473 -0.05288696
  -0.01667786]
 [-0.05505371 -0.0300293  -0.03598022 ...,  0.08459473 -0.05288696
  -0.01667786]
 [-0.05505371 -0.0300293  -0.03598022 ...,  0.08459473 -0.05288696
  -0.01667786]]
After layer decoder_rnn_concat_target_context_t0_output (20, 768) <class 'numpy.float16'> [[-0.05505371 -0.0300293  -0.03598022 ...,  0.96289062  0.97167969
  -0.92236328]
 [-0.05505371 -0.0300293  -0.03598022 ...,  0.96289062  0.97167969
  -0.92236328]
 [-0.05505371 -0.0300293  -0.03598022 ...,  0.96289062  0.97167969
  -0.92285156]
 ...,
 [-0.05505371 -0.0300293  -0.03598022 ...,  0.96240234  0.97167969
  -0.92382812]
 [-0.05505371 -0.0300293  -0.03598022 ...,  0.96289062  0.97167969
  -0.92285156]
 [-0.05505371 -0.0300293  -0.03598022 ...,  0.96289062  0.97167969
  -0.92285156]]
After layer decoder_rnn_l0_t0_i2h_output (20, 2048) <class 'numpy.float16'> [[-3.19726562  1.60742188  2.44335938 ..., -0.07714844  3.8671875
   0.59521484]
 [-3.19726562  1.60742188  2.44335938 ..., -0.07720947  3.8671875
   0.59570312]
 [-3.19726562  1.60644531  2.44335938 ..., -0.07696533  3.8671875
   0.59765625]
 ...,
 [-3.1953125   1.60644531  2.4453125  ..., -0.07623291  3.8671875
   0.60107422]
 [-3.19726562  1.60644531  2.44335938 ..., -0.07659912  3.8671875
   0.59570312]
 [-3.19726562  1.60742188  2.44335938 ..., -0.07702637  3.8671875
   0.59570312]]
After layer decoder_rnn_l0_t0_h2h_output (20, 2048) <class 'numpy.float16'> [[-0.32324219  0.47241211  1.86035156 ...,  0.71337891  1.29492188
   0.17687988]
 [-0.32348633  0.47241211  1.86035156 ...,  0.71386719  1.29394531
   0.17700195]
 [-0.32470703  0.4765625   1.85839844 ...,  0.71386719  1.29882812
   0.17321777]
 ...,
 [-0.32885742  0.48339844  1.85742188 ...,  0.71386719  1.30273438
   0.16809082]
 [-0.32373047  0.4753418   1.859375   ...,  0.71337891  1.29785156
   0.17431641]
 [-0.32373047  0.47363281  1.859375   ...,  0.71337891  1.29589844
   0.17541504]]
After layer _plus1064_0 (20, 2048) <class 'numpy.float16'> [[-3.51953125  2.08007812  4.3046875  ...,  0.63623047  5.1640625
   0.77197266]
 [-3.52148438  2.08007812  4.3046875  ...,  0.63671875  5.16015625
   0.77246094]
 [-3.52148438  2.08203125  4.30078125 ...,  0.63671875  5.1640625
   0.77099609]
 ...,
 [-3.5234375   2.08984375  4.3046875  ...,  0.63769531  5.171875
   0.76904297]
 [-3.52148438  2.08203125  4.3046875  ...,  0.63671875  5.1640625
   0.77001953]
 [-3.52148438  2.08203125  4.3046875  ...,  0.63623047  5.1640625
   0.77099609]]
After layer decoder_rnn_l0_t0_slice_output0 (20, 512) <class 'numpy.float16'> [[-3.51953125  2.08007812  4.3046875  ...,  1.73828125  4.62109375
   2.77929688]
 [-3.52148438  2.08007812  4.3046875  ...,  1.73828125  4.625       2.77929688]
 [-3.52148438  2.08203125  4.30078125 ...,  1.74121094  4.6171875
   2.77929688]
 ...,
 [-3.5234375   2.08984375  4.3046875  ...,  1.74609375  4.61328125
   2.77734375]
 [-3.52148438  2.08203125  4.3046875  ...,  1.73828125  4.6171875
   2.77734375]
 [-3.52148438  2.08203125  4.3046875  ...,  1.73828125  4.62109375
   2.77929688]]
After layer decoder_rnn_l0_t0_slice_output1 (20, 512) <class 'numpy.float16'> [[-1.85351562  2.32226562  2.4453125  ...,  3.16796875 -0.68603516
   1.99121094]
 [-1.85351562  2.32226562  2.4453125  ...,  3.16992188 -0.68554688
   1.9921875 ]
 [-1.85546875  2.3203125   2.44921875 ...,  3.16796875 -0.6875      1.99023438]
 ...,
 [-1.86328125  2.31640625  2.45507812 ...,  3.1640625  -0.6875      1.98925781]
 [-1.85546875  2.3203125   2.44726562 ...,  3.16796875 -0.68603516
   1.9921875 ]
 [-1.85449219  2.3203125   2.4453125  ...,  3.16796875 -0.68603516
   1.99121094]]
After layer decoder_rnn_l0_t0_slice_output2 (20, 512) <class 'numpy.float16'> [[-2.81640625 -3.09960938  2.85546875 ...,  4.265625   -0.08203125
   2.16015625]
 [-2.81640625 -3.1015625   2.85546875 ...,  4.265625   -0.08203125
   2.16015625]
 [-2.8203125  -3.1015625   2.86328125 ...,  4.2578125  -0.08398438
   2.15820312]
 ...,
 [-2.8203125  -3.109375    2.87890625 ...,  4.25       -0.08764648  2.15625   ]
 [-2.81640625 -3.1015625   2.859375   ...,  4.2578125  -0.08422852  2.15625   ]
 [-2.81640625 -3.1015625   2.859375   ...,  4.26171875 -0.08276367
   2.15820312]]
After layer decoder_rnn_l0_t0_slice_output3 (20, 512) <class 'numpy.float16'> [[-3.27734375  2.421875   -1.40136719 ...,  0.63623047  5.1640625
   0.77197266]
 [-3.27734375  2.421875   -1.40039062 ...,  0.63671875  5.16015625
   0.77246094]
 [-3.27539062  2.42578125 -1.40332031 ...,  0.63671875  5.1640625
   0.77099609]
 ...,
 [-3.26953125  2.4296875  -1.40820312 ...,  0.63769531  5.171875
   0.76904297]
 [-3.27734375  2.421875   -1.40332031 ...,  0.63671875  5.1640625
   0.77001953]
 [-3.27734375  2.42382812 -1.40234375 ...,  0.63623047  5.1640625
   0.77099609]]
After layer decoder_rnn_l0_t0_o_output (20, 512) <class 'numpy.float16'> [[ 0.03634644  0.91845703  0.19763184 ...,  0.65380859  0.99414062
   0.68408203]
 [ 0.03634644  0.91845703  0.19775391 ...,  0.65380859  0.99414062
   0.68408203]
 [ 0.03643799  0.91894531  0.19726562 ...,  0.65380859  0.99414062
   0.68359375]
 ...,
 [ 0.03662109  0.91894531  0.1965332  ...,  0.65429688  0.99414062
   0.68310547]
 [ 0.03634644  0.91845703  0.19726562 ...,  0.65380859  0.99414062
   0.68359375]
 [ 0.03634644  0.91845703  0.1973877  ...,  0.65380859  0.99414062
   0.68359375]]
After layer decoder_rnn_l0_t0_f_output (20, 512) <class 'numpy.float16'> [[ 0.13549805  0.91064453  0.92041016 ...,  0.95947266  0.33496094
   0.87988281]
 [ 0.13549805  0.91064453  0.92041016 ...,  0.95947266  0.33496094
   0.87988281]
 [ 0.13525391  0.91064453  0.92041016 ...,  0.95947266  0.33447266
   0.87988281]
 ...,
 [ 0.13427734  0.91015625  0.92089844 ...,  0.95947266  0.33447266
   0.87988281]
 [ 0.13525391  0.91064453  0.92041016 ...,  0.95947266  0.33496094
   0.87988281]
 [ 0.13537598  0.91064453  0.92041016 ...,  0.95947266  0.33496094
   0.87988281]]
After layer _mul2128_0 (20, 512) <class 'numpy.float16'> [[ -4.47463989e-03  -7.20703125e+00   8.51562500e+00 ...,   1.04140625e+01
   -4.08630371e-02   5.91406250e+00]
 [ -4.47463989e-03  -7.20312500e+00   8.48437500e+00 ...,   1.03593750e+01
   -4.08630371e-02   5.89843750e+00]
 [ -4.46701050e-03  -7.17968750e+00   8.51562500e+00 ...,   1.02656250e+01
   -4.20532227e-02   5.85937500e+00]
 ...,
 [ -4.41360474e-03  -7.03125000e+00   8.39062500e+00 ...,   9.94531250e+00
   -4.43420410e-02   5.62890625e+00]
 [ -4.46701050e-03  -7.20312500e+00   8.48437500e+00 ...,   1.03125000e+01
   -4.22668457e-02   5.87109375e+00]
 [ -4.46319580e-03  -7.20703125e+00   8.50000000e+00 ...,   1.03125000e+01
   -4.16564941e-02   5.87890625e+00]]
After layer decoder_rnn_l0_t0_i_output (20, 512) <class 'numpy.float16'> [[ 0.02876282  0.88916016  0.98681641 ...,  0.85058594  0.99023438
   0.94140625]
 [ 0.02870178  0.88916016  0.98681641 ...,  0.85058594  0.99023438
   0.94140625]
 [ 0.02870178  0.88916016  0.98681641 ...,  0.85107422  0.99023438
   0.94140625]
 ...,
 [ 0.02865601  0.89013672  0.98681641 ...,  0.8515625   0.99023438
   0.94140625]
 [ 0.02870178  0.88916016  0.98681641 ...,  0.85058594  0.99023438
   0.94140625]
 [ 0.02870178  0.88916016  0.98681641 ...,  0.85058594  0.99023438
   0.94140625]]
After layer decoder_rnn_l0_t0_c_output (20, 512) <class 'numpy.float16'> [[-0.99267578 -0.99609375  0.99316406 ...,  0.99951172 -0.08184814
   0.97363281]
 [-0.99267578 -0.99609375  0.99316406 ...,  0.99951172 -0.08184814
   0.97363281]
 [-0.99316406 -0.99609375  0.99365234 ...,  0.99951172 -0.08380127
   0.97363281]
 ...,
 [-0.99316406 -0.99609375  0.99365234 ...,  0.99951172 -0.08740234
   0.97363281]
 [-0.99267578 -0.99609375  0.99365234 ...,  0.99951172 -0.08404541
   0.97363281]
 [-0.99267578 -0.99609375  0.99365234 ...,  0.99951172 -0.08258057
   0.97363281]]
After layer _mul2129_0 (20, 512) <class 'numpy.float16'> [[-0.02854919 -0.88574219  0.97998047 ...,  0.85009766 -0.08105469
   0.91650391]
 [-0.02848816 -0.88574219  0.97998047 ...,  0.85009766 -0.08105469
   0.91650391]
 [-0.02850342 -0.88574219  0.98046875 ...,  0.85058594 -0.08300781
   0.91650391]
 ...,
 [-0.02845764 -0.88671875  0.98046875 ...,  0.85107422 -0.08654785
   0.91650391]
 [-0.02848816 -0.88574219  0.98046875 ...,  0.85009766 -0.08325195
   0.91650391]
 [-0.02848816 -0.88574219  0.98046875 ...,  0.85009766 -0.08178711
   0.91650391]]
After layer decoder_rnn_l0_t0_state_0 (20, 512) <class 'numpy.float16'> [[ -0.03302002  -8.09375      9.4921875  ...,  11.265625    -0.12194824
    6.83203125]
 [ -0.03295898  -8.0859375    9.4609375  ...,  11.2109375   -0.12194824
    6.81640625]
 [ -0.03295898  -8.0625       9.5        ...,  11.1171875   -0.125
    6.77734375]
 ...,
 [ -0.03286743  -7.91796875   9.375      ...,  10.796875    -0.13085938
    6.546875  ]
 [ -0.03295898  -8.0859375    9.46875    ...,  11.1640625   -0.12548828
    6.7890625 ]
 [ -0.03295898  -8.09375      9.484375   ...,  11.1640625   -0.12341309
    6.796875  ]]
After layer activation1064_output (20, 512) <class 'numpy.float16'> [[-0.03302002 -1.          1.         ...,  1.         -0.12133789  1.        ]
 [-0.03295898 -1.          1.         ...,  1.         -0.12133789  1.        ]
 [-0.03295898 -1.          1.         ...,  1.         -0.12432861  1.        ]
 ...,
 [-0.03286743 -1.          1.         ...,  1.         -0.13012695  1.        ]
 [-0.03295898 -1.          1.         ...,  1.         -0.12481689  1.        ]
 [-0.03295898 -1.          1.         ...,  1.         -0.12280273  1.        ]]
After layer decoder_rnn_l0_t0_out_0 (20, 512) <class 'numpy.float16'> [[-0.00119972 -0.91845703  0.19763184 ...,  0.65380859 -0.12060547
   0.68408203]
 [-0.00119781 -0.91845703  0.19775391 ...,  0.65380859 -0.12060547
   0.68408203]
 [-0.00120068 -0.91894531  0.19726562 ...,  0.65380859 -0.12359619
   0.68359375]
 ...,
 [-0.00120354 -0.91894531  0.1965332  ...,  0.65429688 -0.12939453
   0.68310547]
 [-0.00119781 -0.91845703  0.19726562 ...,  0.65380859 -0.12408447
   0.68359375]
 [-0.00119781 -0.91845703  0.1973877  ...,  0.65380859 -0.12207031
   0.68359375]]
After layer expand_dims1073_0 (20, 512, 1) <class 'numpy.float16'> [[[-0.00119972]
  [-0.91845703]
  [ 0.19763184]
  ...,
  [ 0.65380859]
  [-0.12060547]
  [ 0.68408203]]

 [[-0.00119781]
  [-0.91845703]
  [ 0.19775391]
  ...,
  [ 0.65380859]
  [-0.12060547]
  [ 0.68408203]]

 [[-0.00120068]
  [-0.91894531]
  [ 0.19726562]
  ...,
  [ 0.65380859]
  [-0.12359619]
  [ 0.68359375]]

 ...,
 [[-0.00120354]
  [-0.91894531]
  [ 0.1965332 ]
  ...,
  [ 0.65429688]
  [-0.12939453]
  [ 0.68310547]]

 [[-0.00119781]
  [-0.91845703]
  [ 0.19726562]
  ...,
  [ 0.65380859]
  [-0.12408447]
  [ 0.68359375]]

 [[-0.00119781]
  [-0.91845703]
  [ 0.1973877 ]
  ...,
  [ 0.65380859]
  [-0.12207031]
  [ 0.68359375]]]
After layer att_batch_dot_0 (20, 10, 1) <class 'numpy.float16'> [[[ 0.53173828]
  [ 0.92529297]
  [ 1.640625  ]
  [ 2.61328125]
  [ 2.53320312]
  [ 0.28344727]
  [-2.95898438]
  [-5.80859375]
  [-7.953125  ]
  [-9.5625    ]]

 [[ 0.53173828]
  [ 0.92529297]
  [ 1.640625  ]
  [ 2.61328125]
  [ 2.53320312]
  [ 0.28393555]
  [-2.95898438]
  [-5.80859375]
  [-7.94921875]
  [-9.5625    ]]

 [[ 0.53076172]
  [ 0.92382812]
  [ 1.63574219]
  [ 2.60351562]
  [ 2.515625  ]
  [ 0.25415039]
  [-3.        ]
  [-5.86328125]
  [-8.0078125 ]
  [-9.625     ]]

 [[ 0.53125   ]
  [ 0.92529297]
  [ 1.63964844]
  [ 2.61132812]
  [ 2.53125   ]
  [ 0.27807617]
  [-2.96875   ]
  [-5.8203125 ]
  [-7.96484375]
  [-9.578125  ]]

 [[ 0.53125   ]
  [ 0.92431641]
  [ 1.63574219]
  [ 2.6015625 ]
  [ 2.5078125 ]
  [ 0.23803711]
  [-3.02734375]
  [-5.8984375 ]
  [-8.0546875 ]
  [-9.671875  ]]

 [[ 0.53125   ]
  [ 0.92578125]
  [ 1.640625  ]
  [ 2.61328125]
  [ 2.53320312]
  [ 0.28271484]
  [-2.9609375 ]
  [-5.8125    ]
  [-7.95703125]
  [-9.5625    ]]

 [[ 0.52978516]
  [ 0.92382812]
  [ 1.6328125 ]
  [ 2.59765625]
  [ 2.50195312]
  [ 0.22973633]
  [-3.03710938]
  [-5.91015625]
  [-8.0703125 ]
  [-9.6875    ]]

 [[ 0.53173828]
  [ 0.92529297]
  [ 1.640625  ]
  [ 2.61328125]
  [ 2.53515625]
  [ 0.28564453]
  [-2.95703125]
  [-5.8046875 ]
  [-7.9453125 ]
  [-9.5546875 ]]

 [[ 0.53369141]
  [ 0.92578125]
  [ 1.63964844]
  [ 2.609375  ]
  [ 2.5234375 ]
  [ 0.26342773]
  [-2.9921875 ]
  [-5.85546875]
  [-8.        ]
  [-9.6171875 ]]

 [[ 0.53027344]
  [ 0.92236328]
  [ 1.62988281]
  [ 2.58984375]
  [ 2.48828125]
  [ 0.20739746]
  [-3.06640625]
  [-5.9453125 ]
  [-8.109375  ]
  [-9.734375  ]]

 [[ 0.53173828]
  [ 0.92431641]
  [ 1.63671875]
  [ 2.60546875]
  [ 2.51953125]
  [ 0.26220703]
  [-2.98828125]
  [-5.84375   ]
  [-7.9921875 ]
  [-9.6015625 ]]

 [[ 0.53076172]
  [ 0.92285156]
  [ 1.62988281]
  [ 2.58984375]
  [ 2.48828125]
  [ 0.20666504]
  [-3.06835938]
  [-5.94921875]
  [-8.109375  ]
  [-9.734375  ]]

 [[ 0.53173828]
  [ 0.92333984]
  [ 1.63085938]
  [ 2.59375   ]
  [ 2.49414062]
  [ 0.21398926]
  [-3.05859375]
  [-5.9375    ]
  [-8.1015625 ]
  [-9.71875   ]]

 [[ 0.53173828]
  [ 0.92529297]
  [ 1.640625  ]
  [ 2.61328125]
  [ 2.53320312]
  [ 0.28369141]
  [-2.95898438]
  [-5.80859375]
  [-7.953125  ]
  [-9.5625    ]]

 [[ 0.53173828]
  [ 0.92529297]
  [ 1.640625  ]
  [ 2.61328125]
  [ 2.53320312]
  [ 0.28271484]
  [-2.9609375 ]
  [-5.8125    ]
  [-7.953125  ]
  [-9.5625    ]]

 [[ 0.53173828]
  [ 0.92529297]
  [ 1.640625  ]
  [ 2.61328125]
  [ 2.53320312]
  [ 0.28222656]
  [-2.96289062]
  [-5.8125    ]
  [-7.95703125]
  [-9.5625    ]]

 [[ 0.53125   ]
  [ 0.92529297]
  [ 1.63964844]
  [ 2.61132812]
  [ 2.52929688]
  [ 0.27612305]
  [-2.97070312]
  [-5.82421875]
  [-7.96875   ]
  [-9.578125  ]]

 [[ 0.53076172]
  [ 0.92333984]
  [ 1.63085938]
  [ 2.59375   ]
  [ 2.4921875 ]
  [ 0.21252441]
  [-3.0625    ]
  [-5.94140625]
  [-8.109375  ]
  [-9.734375  ]]

 [[ 0.53076172]
  [ 0.92480469]
  [ 1.63867188]
  [ 2.609375  ]
  [ 2.52539062]
  [ 0.26879883]
  [-2.98242188]
  [-5.83984375]
  [-7.98828125]
  [-9.6015625 ]]

 [[ 0.53125   ]
  [ 0.92529297]
  [ 1.63964844]
  [ 2.61132812]
  [ 2.52929688]
  [ 0.27661133]
  [-2.97070312]
  [-5.82421875]
  [-7.96875   ]
  [-9.578125  ]]]
After layer swapaxes49_output (10, 20, 1) <class 'numpy.float16'> [[[ 0.53173828]
  [ 0.53173828]
  [ 0.53076172]
  [ 0.53125   ]
  [ 0.53125   ]
  [ 0.53125   ]
  [ 0.52978516]
  [ 0.53173828]
  [ 0.53369141]
  [ 0.53027344]
  [ 0.53173828]
  [ 0.53076172]
  [ 0.53173828]
  [ 0.53173828]
  [ 0.53173828]
  [ 0.53173828]
  [ 0.53125   ]
  [ 0.53076172]
  [ 0.53076172]
  [ 0.53125   ]]

 [[ 0.92529297]
  [ 0.92529297]
  [ 0.92382812]
  [ 0.92529297]
  [ 0.92431641]
  [ 0.92578125]
  [ 0.92382812]
  [ 0.92529297]
  [ 0.92578125]
  [ 0.92236328]
  [ 0.92431641]
  [ 0.92285156]
  [ 0.92333984]
  [ 0.92529297]
  [ 0.92529297]
  [ 0.92529297]
  [ 0.92529297]
  [ 0.92333984]
  [ 0.92480469]
  [ 0.92529297]]

 [[ 1.640625  ]
  [ 1.640625  ]
  [ 1.63574219]
  [ 1.63964844]
  [ 1.63574219]
  [ 1.640625  ]
  [ 1.6328125 ]
  [ 1.640625  ]
  [ 1.63964844]
  [ 1.62988281]
  [ 1.63671875]
  [ 1.62988281]
  [ 1.63085938]
  [ 1.640625  ]
  [ 1.640625  ]
  [ 1.640625  ]
  [ 1.63964844]
  [ 1.63085938]
  [ 1.63867188]
  [ 1.63964844]]

 [[ 2.61328125]
  [ 2.61328125]
  [ 2.60351562]
  [ 2.61132812]
  [ 2.6015625 ]
  [ 2.61328125]
  [ 2.59765625]
  [ 2.61328125]
  [ 2.609375  ]
  [ 2.58984375]
  [ 2.60546875]
  [ 2.58984375]
  [ 2.59375   ]
  [ 2.61328125]
  [ 2.61328125]
  [ 2.61328125]
  [ 2.61132812]
  [ 2.59375   ]
  [ 2.609375  ]
  [ 2.61132812]]

 [[ 2.53320312]
  [ 2.53320312]
  [ 2.515625  ]
  [ 2.53125   ]
  [ 2.5078125 ]
  [ 2.53320312]
  [ 2.50195312]
  [ 2.53515625]
  [ 2.5234375 ]
  [ 2.48828125]
  [ 2.51953125]
  [ 2.48828125]
  [ 2.49414062]
  [ 2.53320312]
  [ 2.53320312]
  [ 2.53320312]
  [ 2.52929688]
  [ 2.4921875 ]
  [ 2.52539062]
  [ 2.52929688]]

 [[ 0.28344727]
  [ 0.28393555]
  [ 0.25415039]
  [ 0.27807617]
  [ 0.23803711]
  [ 0.28271484]
  [ 0.22973633]
  [ 0.28564453]
  [ 0.26342773]
  [ 0.20739746]
  [ 0.26220703]
  [ 0.20666504]
  [ 0.21398926]
  [ 0.28369141]
  [ 0.28271484]
  [ 0.28222656]
  [ 0.27612305]
  [ 0.21252441]
  [ 0.26879883]
  [ 0.27661133]]

 [[-2.95898438]
  [-2.95898438]
  [-3.        ]
  [-2.96875   ]
  [-3.02734375]
  [-2.9609375 ]
  [-3.03710938]
  [-2.95703125]
  [-2.9921875 ]
  [-3.06640625]
  [-2.98828125]
  [-3.06835938]
  [-3.05859375]
  [-2.95898438]
  [-2.9609375 ]
  [-2.96289062]
  [-2.97070312]
  [-3.0625    ]
  [-2.98242188]
  [-2.97070312]]

 [[-5.80859375]
  [-5.80859375]
  [-5.86328125]
  [-5.8203125 ]
  [-5.8984375 ]
  [-5.8125    ]
  [-5.91015625]
  [-5.8046875 ]
  [-5.85546875]
  [-5.9453125 ]
  [-5.84375   ]
  [-5.94921875]
  [-5.9375    ]
  [-5.80859375]
  [-5.8125    ]
  [-5.8125    ]
  [-5.82421875]
  [-5.94140625]
  [-5.83984375]
  [-5.82421875]]

 [[-7.953125  ]
  [-7.94921875]
  [-8.0078125 ]
  [-7.96484375]
  [-8.0546875 ]
  [-7.95703125]
  [-8.0703125 ]
  [-7.9453125 ]
  [-8.        ]
  [-8.109375  ]
  [-7.9921875 ]
  [-8.109375  ]
  [-8.1015625 ]
  [-7.953125  ]
  [-7.953125  ]
  [-7.95703125]
  [-7.96875   ]
  [-8.109375  ]
  [-7.98828125]
  [-7.96875   ]]

 [[-9.5625    ]
  [-9.5625    ]
  [-9.625     ]
  [-9.578125  ]
  [-9.671875  ]
  [-9.5625    ]
  [-9.6875    ]
  [-9.5546875 ]
  [-9.6171875 ]
  [-9.734375  ]
  [-9.6015625 ]
  [-9.734375  ]
  [-9.71875   ]
  [-9.5625    ]
  [-9.5625    ]
  [-9.5625    ]
  [-9.578125  ]
  [-9.734375  ]
  [-9.6015625 ]
  [-9.578125  ]]]
After layer sequencemask20_output (10, 20, 1) <class 'numpy.float16'> [[[  5.31738281e-01]
  [  5.31738281e-01]
  [  5.30761719e-01]
  [  5.31250000e-01]
  [  5.31250000e-01]
  [  5.31250000e-01]
  [  5.29785156e-01]
  [  5.31738281e-01]
  [  5.33691406e-01]
  [  5.30273438e-01]
  [  5.31738281e-01]
  [  5.30761719e-01]
  [  5.31738281e-01]
  [  5.31738281e-01]
  [  5.31738281e-01]
  [  5.31738281e-01]
  [  5.31250000e-01]
  [  5.30761719e-01]
  [  5.30761719e-01]
  [  5.31250000e-01]]

 [[  9.25292969e-01]
  [  9.25292969e-01]
  [  9.23828125e-01]
  [  9.25292969e-01]
  [  9.24316406e-01]
  [  9.25781250e-01]
  [  9.23828125e-01]
  [  9.25292969e-01]
  [  9.25781250e-01]
  [  9.22363281e-01]
  [  9.24316406e-01]
  [  9.22851562e-01]
  [  9.23339844e-01]
  [  9.25292969e-01]
  [  9.25292969e-01]
  [  9.25292969e-01]
  [  9.25292969e-01]
  [  9.23339844e-01]
  [  9.24804688e-01]
  [  9.25292969e-01]]

 [[ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]]
After layer swapaxes50_output (20, 10, 1) <class 'numpy.float16'> [[[  5.31738281e-01]
  [  9.25292969e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  5.31738281e-01]
  [  9.25292969e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  5.30761719e-01]
  [  9.23828125e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  5.31250000e-01]
  [  9.25292969e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  5.31250000e-01]
  [  9.24316406e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  5.31250000e-01]
  [  9.25781250e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  5.29785156e-01]
  [  9.23828125e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  5.31738281e-01]
  [  9.25292969e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  5.33691406e-01]
  [  9.25781250e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  5.30273438e-01]
  [  9.22363281e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  5.31738281e-01]
  [  9.24316406e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  5.30761719e-01]
  [  9.22851562e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  5.31738281e-01]
  [  9.23339844e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  5.31738281e-01]
  [  9.25292969e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  5.31738281e-01]
  [  9.25292969e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  5.31738281e-01]
  [  9.25292969e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  5.31250000e-01]
  [  9.25292969e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  5.30761719e-01]
  [  9.23339844e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  5.30761719e-01]
  [  9.24804688e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  5.31250000e-01]
  [  9.25292969e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]]
After layer attention_softmax_0 (20, 10, 1) <class 'numpy.float16'> [[[ 0.40283203]
  [ 0.59716797]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40283203]
  [ 0.59716797]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40307617]
  [ 0.59716797]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40283203]
  [ 0.59765625]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40307617]
  [ 0.59716797]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40258789]
  [ 0.59765625]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40283203]
  [ 0.59765625]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40283203]
  [ 0.59716797]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40307617]
  [ 0.59667969]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40307617]
  [ 0.59667969]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40307617]
  [ 0.59667969]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40307617]
  [ 0.59667969]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40332031]
  [ 0.59667969]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40283203]
  [ 0.59716797]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40283203]
  [ 0.59716797]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40283203]
  [ 0.59716797]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40283203]
  [ 0.59765625]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40307617]
  [ 0.59667969]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40283203]
  [ 0.59765625]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40283203]
  [ 0.59765625]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]]
After layer batch_dot20_0 (20, 512, 1) <class 'numpy.float16'> [[[ 0.01786804]
  [ 0.03945923]
  [-0.03341675]
  ...,
  [-0.01097107]
  [ 0.00999451]
  [-0.02461243]]

 [[ 0.01786804]
  [ 0.03945923]
  [-0.03341675]
  ...,
  [-0.01097107]
  [ 0.00999451]
  [-0.02461243]]

 [[ 0.01786804]
  [ 0.03945923]
  [-0.03341675]
  ...,
  [-0.0109787 ]
  [ 0.00999451]
  [-0.02462769]]

 ...,
 [[ 0.01785278]
  [ 0.03942871]
  [-0.03341675]
  ...,
  [-0.01097107]
  [ 0.00998688]
  [-0.02461243]]

 [[ 0.0178833 ]
  [ 0.03948975]
  [-0.03344727]
  ...,
  [-0.0109787 ]
  [ 0.00999451]
  [-0.02462769]]

 [[ 0.0178833 ]
  [ 0.03948975]
  [-0.03344727]
  ...,
  [-0.0109787 ]
  [ 0.00999451]
  [-0.02462769]]]
After layer reshape40_0 (20, 512) <class 'numpy.float16'> [[ 0.01786804  0.03945923 -0.03341675 ..., -0.01097107  0.00999451
  -0.02461243]
 [ 0.01786804  0.03945923 -0.03341675 ..., -0.01097107  0.00999451
  -0.02461243]
 [ 0.01786804  0.03945923 -0.03341675 ..., -0.0109787   0.00999451
  -0.02462769]
 ...,
 [ 0.01785278  0.03942871 -0.03341675 ..., -0.01097107  0.00998688
  -0.02461243]
 [ 0.0178833   0.03948975 -0.03344727 ..., -0.0109787   0.00999451
  -0.02462769]
 [ 0.0178833   0.03948975 -0.03344727 ..., -0.0109787   0.00999451
  -0.02462769]]
After layer decoder_rnn_hidden_concat_t0_output (20, 1024) <class 'numpy.float16'> [[-0.00119972 -0.91845703  0.19763184 ..., -0.01097107  0.00999451
  -0.02461243]
 [-0.00119781 -0.91845703  0.19775391 ..., -0.01097107  0.00999451
  -0.02461243]
 [-0.00120068 -0.91894531  0.19726562 ..., -0.0109787   0.00999451
  -0.02462769]
 ...,
 [-0.00120354 -0.91894531  0.1965332  ..., -0.01097107  0.00998688
  -0.02461243]
 [-0.00119781 -0.91845703  0.19726562 ..., -0.0109787   0.00999451
  -0.02462769]
 [-0.00119781 -0.91845703  0.1973877  ..., -0.0109787   0.00999451
  -0.02462769]]
After layer decoder_rnn_hidden_fc_t0_output (20, 512) <class 'numpy.float16'> [[-1.97558594  0.21569824 -0.82080078 ...,  1.984375    2.12109375
  -1.60742188]
 [-1.97558594  0.21520996 -0.8203125  ...,  1.984375    2.12304688
  -1.60742188]
 [-1.97460938  0.21740723 -0.82373047 ...,  1.98242188  2.12109375
  -1.60839844]
 ...,
 [-1.97363281  0.22094727 -0.82958984 ...,  1.97949219  2.11914062
  -1.61328125]
 [-1.97753906  0.21826172 -0.82373047 ...,  1.984375    2.12109375
  -1.60839844]
 [-1.9765625   0.21655273 -0.82177734 ...,  1.984375    2.12109375
  -1.60742188]]
After layer decoder_rnn_next_hidden_t0_output (20, 512) <class 'numpy.float16'> [[-0.96240234  0.21240234 -0.67529297 ...,  0.96289062  0.97167969
  -0.92285156]
 [-0.96240234  0.21191406 -0.67529297 ...,  0.96289062  0.97167969
  -0.92285156]
 [-0.96240234  0.21398926 -0.67724609 ...,  0.96289062  0.97167969
  -0.92285156]
 ...,
 [-0.96191406  0.21740723 -0.68017578 ...,  0.96240234  0.97167969
  -0.92382812]
 [-0.96240234  0.21484375 -0.67724609 ...,  0.96289062  0.97167969
  -0.92285156]
 [-0.96240234  0.21325684 -0.67626953 ...,  0.96289062  0.97167969
  -0.92285156]]
After layer logits_output (20, 16743) <class 'numpy.float16'> [[-2.015625   -2.82617188 -2.40820312 ..., -2.09375    -3.50390625
  -2.58984375]
 [-2.015625   -2.82617188 -2.40820312 ..., -2.09375    -3.50390625
  -2.58984375]
 [-2.015625   -2.82617188 -2.40820312 ..., -2.09375    -3.50195312
  -2.58984375]
 ...,
 [-2.01367188 -2.828125   -2.40820312 ..., -2.09570312 -3.50195312 -2.59375   ]
 [-2.015625   -2.82617188 -2.40820312 ..., -2.09375    -3.50195312
  -2.59179688]
 [-2.015625   -2.82617188 -2.40820312 ..., -2.09375    -3.50195312
  -2.58984375]]
After layer softmax_0 (20, 16743) <class 'numpy.float16'> [[  8.34465027e-07   3.57627869e-07   5.96046448e-07 ...,   7.74860382e-07
    1.78813934e-07   4.76837158e-07]
 [  8.34465027e-07   3.57627869e-07   5.96046448e-07 ...,   7.74860382e-07
    1.78813934e-07   4.76837158e-07]
 [  8.34465027e-07   3.57627869e-07   5.96046448e-07 ...,   7.74860382e-07
    1.78813934e-07   4.76837158e-07]
 ...,
 [  8.34465027e-07   3.57627869e-07   5.96046448e-07 ...,   7.74860382e-07
    1.78813934e-07   4.76837158e-07]
 [  8.34465027e-07   3.57627869e-07   5.96046448e-07 ...,   7.74860382e-07
    1.78813934e-07   4.76837158e-07]
 [  8.34465027e-07   3.57627869e-07   5.96046448e-07 ...,   7.74860382e-07
    1.78813934e-07   4.76837158e-07]]
After layer reshape41_0 (20, 10) <class 'numpy.float16'> [[ 0.40283203  0.59716797  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40283203  0.59716797  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40307617  0.59716797  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40283203  0.59765625  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40307617  0.59716797  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40258789  0.59765625  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40283203  0.59765625  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40283203  0.59716797  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40307617  0.59667969  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40307617  0.59667969  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40307617  0.59667969  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40307617  0.59667969  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40332031  0.59667969  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40283203  0.59716797  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40283203  0.59716797  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40283203  0.59716797  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40283203  0.59765625  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40307617  0.59667969  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40283203  0.59765625  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40283203  0.59765625  0.          0.          0.          0.          0.
   0.          0.          0.        ]]
After layer target_embed_embed_0 (20, 256) <class 'numpy.float16'> [[-0.05505371 -0.0300293  -0.03598022 ...,  0.08459473 -0.05288696
  -0.01667786]
 [-0.05505371 -0.0300293  -0.03598022 ...,  0.08459473 -0.05288696
  -0.01667786]
 [-0.05505371 -0.0300293  -0.03598022 ...,  0.08459473 -0.05288696
  -0.01667786]
 ...,
 [-0.05505371 -0.0300293  -0.03598022 ...,  0.08459473 -0.05288696
  -0.01667786]
 [-0.05505371 -0.0300293  -0.03598022 ...,  0.08459473 -0.05288696
  -0.01667786]
 [-0.05505371 -0.0300293  -0.03598022 ...,  0.08459473 -0.05288696
  -0.01667786]]
After layer decoder_rnn_concat_target_context_t0_output (20, 768) <class 'numpy.float16'> [[-0.05505371 -0.0300293  -0.03598022 ...,  0.96289062  0.97167969
  -0.92285156]
 [-0.05505371 -0.0300293  -0.03598022 ...,  0.96289062  0.97167969
  -0.92285156]
 [-0.05505371 -0.0300293  -0.03598022 ...,  0.96289062  0.97167969
  -0.92285156]
 ...,
 [-0.05505371 -0.0300293  -0.03598022 ...,  0.96240234  0.97167969
  -0.92382812]
 [-0.05505371 -0.0300293  -0.03598022 ...,  0.96289062  0.97167969
  -0.92285156]
 [-0.05505371 -0.0300293  -0.03598022 ...,  0.96289062  0.97167969
  -0.92285156]]
After layer decoder_rnn_l0_t0_i2h_output (20, 2048) <class 'numpy.float16'> [[-3.19726562  1.60742188  2.44335938 ..., -0.07714844  3.8671875
   0.59521484]
 [-3.19726562  1.60742188  2.44335938 ..., -0.07720947  3.8671875
   0.59521484]
 [-3.19726562  1.60644531  2.44335938 ..., -0.07672119  3.8671875
   0.59716797]
 ...,
 [-3.1953125   1.60644531  2.4453125  ..., -0.07623291  3.8671875
   0.60058594]
 [-3.19726562  1.60742188  2.4453125  ..., -0.07672119  3.8671875
   0.59521484]
 [-3.19726562  1.60742188  2.44335938 ..., -0.07696533  3.8671875
   0.59521484]]
After layer decoder_rnn_l0_t0_h2h_output (20, 2048) <class 'numpy.float16'> [[-0.32373047  0.47265625  1.86132812 ...,  0.71435547  1.29492188
   0.17700195]
 [-0.32397461  0.47265625  1.86132812 ...,  0.71386719  1.29394531
   0.17712402]
 [-0.32495117  0.47607422  1.859375   ...,  0.71435547  1.29785156
   0.17370605]
 ...,
 [-0.32861328  0.48266602  1.859375   ...,  0.71435547  1.30273438
   0.1685791 ]
 [-0.32397461  0.4753418   1.86035156 ...,  0.71386719  1.296875
   0.17480469]
 [-0.32373047  0.47363281  1.86035156 ...,  0.71386719  1.29589844
   0.17590332]]
After layer _plus1065_0 (20, 2048) <class 'numpy.float16'> [[-3.52148438  2.08007812  4.3046875  ...,  0.63720703  5.1640625
   0.77246094]
 [-3.52148438  2.08007812  4.3046875  ...,  0.63671875  5.16015625
   0.77246094]
 [-3.52148438  2.08203125  4.3046875  ...,  0.63769531  5.1640625
   0.77099609]
 ...,
 [-3.5234375   2.08984375  4.3046875  ...,  0.63818359  5.171875
   0.76904297]
 [-3.52148438  2.08203125  4.3046875  ...,  0.63720703  5.1640625
   0.77001953]
 [-3.52148438  2.08203125  4.3046875  ...,  0.63671875  5.1640625
   0.77099609]]
After layer decoder_rnn_l0_t0_slice_output0 (20, 512) <class 'numpy.float16'> [[-3.52148438  2.08007812  4.3046875  ...,  1.74023438  4.62109375
   2.77929688]
 [-3.52148438  2.08007812  4.3046875  ...,  1.74023438  4.625       2.77929688]
 [-3.52148438  2.08203125  4.3046875  ...,  1.7421875   4.62109375
   2.77734375]
 ...,
 [-3.5234375   2.08984375  4.3046875  ...,  1.74511719  4.6171875
   2.77734375]
 [-3.52148438  2.08203125  4.3046875  ...,  1.73925781  4.62109375
   2.77734375]
 [-3.52148438  2.08203125  4.3046875  ...,  1.73925781  4.625       2.77734375]]
After layer decoder_rnn_l0_t0_slice_output1 (20, 512) <class 'numpy.float16'> [[-1.85351562  2.32226562  2.44726562 ...,  3.16992188 -0.68554688
   1.99316406]
 [-1.85351562  2.32226562  2.44726562 ...,  3.16992188 -0.68505859
   1.99316406]
 [-1.85546875  2.3203125   2.44921875 ...,  3.16796875 -0.68652344
   1.99121094]
 ...,
 [-1.86328125  2.31835938  2.45703125 ...,  3.1640625  -0.68652344
   1.99121094]
 [-1.85546875  2.3203125   2.44921875 ...,  3.16796875 -0.68554688
   1.9921875 ]
 [-1.85449219  2.3203125   2.44921875 ...,  3.16796875 -0.68554688
   1.9921875 ]]
After layer decoder_rnn_l0_t0_slice_output2 (20, 512) <class 'numpy.float16'> [[-2.81640625 -3.1015625   2.859375   ...,  4.265625   -0.08129883
   2.15820312]
 [-2.81640625 -3.1015625   2.859375   ...,  4.265625   -0.08154297  2.15625   ]
 [-2.81835938 -3.10351562  2.86328125 ...,  4.2578125  -0.08349609
   2.15820312]
 ...,
 [-2.8203125  -3.109375    2.87890625 ...,  4.25390625 -0.08618164
   2.15429688]
 [-2.81640625 -3.10351562  2.86132812 ...,  4.2578125  -0.08374023  2.15625   ]
 [-2.81640625 -3.10546875  2.859375   ...,  4.26171875 -0.08227539  2.15625   ]]
After layer decoder_rnn_l0_t0_slice_output3 (20, 512) <class 'numpy.float16'> [[-3.27734375  2.41992188 -1.40234375 ...,  0.63720703  5.1640625
   0.77246094]
 [-3.27734375  2.41992188 -1.40136719 ...,  0.63671875  5.16015625
   0.77246094]
 [-3.27539062  2.42382812 -1.40332031 ...,  0.63769531  5.1640625
   0.77099609]
 ...,
 [-3.27148438  2.42773438 -1.40722656 ...,  0.63818359  5.171875
   0.76904297]
 [-3.27734375  2.421875   -1.40429688 ...,  0.63720703  5.1640625
   0.77001953]
 [-3.27734375  2.421875   -1.40234375 ...,  0.63671875  5.1640625
   0.77099609]]
After layer decoder_rnn_l0_t0_o_output (20, 512) <class 'numpy.float16'> [[ 0.03634644  0.91845703  0.1973877  ...,  0.65429688  0.99414062
   0.68408203]
 [ 0.03634644  0.91845703  0.19763184 ...,  0.65380859  0.99414062
   0.68408203]
 [ 0.03643799  0.91845703  0.19726562 ...,  0.65429688  0.99414062
   0.68359375]
 ...,
 [ 0.03656006  0.91894531  0.19665527 ...,  0.65429688  0.99414062
   0.68310547]
 [ 0.03634644  0.91845703  0.19714355 ...,  0.65429688  0.99414062
   0.68359375]
 [ 0.03634644  0.91845703  0.1973877  ...,  0.65380859  0.99414062
   0.68359375]]
After layer decoder_rnn_l0_t0_f_output (20, 512) <class 'numpy.float16'> [[ 0.13549805  0.91064453  0.92041016 ...,  0.95947266  0.33496094
   0.87988281]
 [ 0.13549805  0.91064453  0.92041016 ...,  0.95947266  0.33520508
   0.87988281]
 [ 0.13525391  0.91064453  0.92041016 ...,  0.95947266  0.3347168
   0.87988281]
 ...,
 [ 0.13427734  0.91015625  0.92089844 ...,  0.95947266  0.3347168
   0.87988281]
 [ 0.13525391  0.91064453  0.92041016 ...,  0.95947266  0.33496094
   0.87988281]
 [ 0.13537598  0.91064453  0.92041016 ...,  0.95947266  0.33496094
   0.87988281]]
After layer _mul2130_0 (20, 512) <class 'numpy.float16'> [[ -4.47463989e-03  -7.37109375e+00   8.73437500e+00 ...,   1.08125000e+01
   -4.08630371e-02   6.01171875e+00]
 [ -4.46701050e-03  -7.36328125e+00   8.71093750e+00 ...,   1.07578125e+01
   -4.08630371e-02   5.99609375e+00]
 [ -4.45938110e-03  -7.34375000e+00   8.74218750e+00 ...,   1.06640625e+01
   -4.18395996e-02   5.96484375e+00]
 ...,
 [ -4.41360474e-03  -7.20703125e+00   8.63281250e+00 ...,   1.03593750e+01
   -4.37927246e-02   5.76171875e+00]
 [ -4.45938110e-03  -7.36328125e+00   8.71875000e+00 ...,   1.07109375e+01
   -4.20227051e-02   5.97265625e+00]
 [ -4.46319580e-03  -7.37109375e+00   8.72656250e+00 ...,   1.07109375e+01
   -4.13513184e-02   5.98046875e+00]]
After layer decoder_rnn_l0_t0_i_output (20, 512) <class 'numpy.float16'> [[ 0.02870178  0.88916016  0.98681641 ...,  0.85058594  0.99023438
   0.94140625]
 [ 0.02870178  0.88916016  0.98681641 ...,  0.85058594  0.99023438
   0.94140625]
 [ 0.02870178  0.88916016  0.98681641 ...,  0.85107422  0.99023438
   0.94140625]
 ...,
 [ 0.02865601  0.89013672  0.98681641 ...,  0.8515625   0.99023438
   0.94140625]
 [ 0.02870178  0.88916016  0.98681641 ...,  0.85058594  0.99023438
   0.94140625]
 [ 0.02870178  0.88916016  0.98681641 ...,  0.85058594  0.99023438
   0.94140625]]
After layer decoder_rnn_l0_t0_c_output (20, 512) <class 'numpy.float16'> [[-0.99267578 -0.99609375  0.99365234 ...,  0.99951172 -0.08111572
   0.97363281]
 [-0.99267578 -0.99609375  0.99365234 ...,  0.99951172 -0.08135986
   0.97363281]
 [-0.99267578 -0.99609375  0.99365234 ...,  0.99951172 -0.08331299
   0.97363281]
 ...,
 [-0.99316406 -0.99609375  0.99365234 ...,  0.99951172 -0.08599854
   0.97363281]
 [-0.99267578 -0.99609375  0.99365234 ...,  0.99951172 -0.08355713
   0.97363281]
 [-0.99267578 -0.99609375  0.99365234 ...,  0.99951172 -0.08209229
   0.97363281]]
After layer _mul2131_0 (20, 512) <class 'numpy.float16'> [[-0.02848816 -0.88574219  0.98046875 ...,  0.85009766 -0.08032227
   0.91650391]
 [-0.02848816 -0.88574219  0.98046875 ...,  0.85009766 -0.08056641
   0.91650391]
 [-0.02848816 -0.88574219  0.98046875 ...,  0.85058594 -0.08251953
   0.91650391]
 ...,
 [-0.02845764 -0.88671875  0.98046875 ...,  0.85107422 -0.08514404
   0.91650391]
 [-0.02848816 -0.88574219  0.98046875 ...,  0.85009766 -0.08276367
   0.91650391]
 [-0.02848816 -0.88574219  0.98046875 ...,  0.85009766 -0.08129883
   0.91650391]]
After layer decoder_rnn_l0_t0_state_0 (20, 512) <class 'numpy.float16'> [[ -0.03295898  -8.2578125    9.71875    ...,  11.6640625   -0.12121582
    6.9296875 ]
 [ -0.03295898  -8.25         9.6875     ...,  11.609375    -0.12145996
    6.9140625 ]
 [ -0.03295898  -8.2265625    9.71875    ...,  11.515625    -0.12438965
    6.8828125 ]
 ...,
 [ -0.03286743  -8.09375      9.609375   ...,  11.2109375   -0.12890625
    6.6796875 ]
 [ -0.03295898  -8.25         9.703125   ...,  11.5625      -0.12475586
    6.890625  ]
 [ -0.03295898  -8.2578125    9.703125   ...,  11.5625      -0.12268066
    6.8984375 ]]
After layer activation1065_output (20, 512) <class 'numpy.float16'> [[-0.03295898 -1.          1.         ...,  1.         -0.12060547  1.        ]
 [-0.03295898 -1.          1.         ...,  1.         -0.12084961  1.        ]
 [-0.03295898 -1.          1.         ...,  1.         -0.1237793   1.        ]
 ...,
 [-0.03286743 -1.          1.         ...,  1.         -0.12817383  1.        ]
 [-0.03295898 -1.          1.         ...,  1.         -0.12408447  1.        ]
 [-0.03295898 -1.          1.         ...,  1.         -0.12207031  1.        ]]
After layer decoder_rnn_l0_t0_out_0 (20, 512) <class 'numpy.float16'> [[-0.00119781 -0.91845703  0.1973877  ...,  0.65429688 -0.11987305
   0.68408203]
 [-0.00119781 -0.91845703  0.19763184 ...,  0.65380859 -0.12011719
   0.68408203]
 [-0.00120068 -0.91845703  0.19726562 ...,  0.65429688 -0.12304688
   0.68359375]
 ...,
 [-0.00120163 -0.91894531  0.19665527 ...,  0.65429688 -0.12744141
   0.68310547]
 [-0.00119781 -0.91845703  0.19714355 ...,  0.65429688 -0.12335205
   0.68359375]
 [-0.00119781 -0.91845703  0.1973877  ...,  0.65380859 -0.12133789
   0.68359375]]
After layer expand_dims1074_0 (20, 512, 1) <class 'numpy.float16'> [[[-0.00119781]
  [-0.91845703]
  [ 0.1973877 ]
  ...,
  [ 0.65429688]
  [-0.11987305]
  [ 0.68408203]]

 [[-0.00119781]
  [-0.91845703]
  [ 0.19763184]
  ...,
  [ 0.65380859]
  [-0.12011719]
  [ 0.68408203]]

 [[-0.00120068]
  [-0.91845703]
  [ 0.19726562]
  ...,
  [ 0.65429688]
  [-0.12304688]
  [ 0.68359375]]

 ...,
 [[-0.00120163]
  [-0.91894531]
  [ 0.19665527]
  ...,
  [ 0.65429688]
  [-0.12744141]
  [ 0.68310547]]

 [[-0.00119781]
  [-0.91845703]
  [ 0.19714355]
  ...,
  [ 0.65429688]
  [-0.12335205]
  [ 0.68359375]]

 [[-0.00119781]
  [-0.91845703]
  [ 0.1973877 ]
  ...,
  [ 0.65380859]
  [-0.12133789]
  [ 0.68359375]]]
After layer att_batch_dot_0 (20, 10, 1) <class 'numpy.float16'> [[[ 0.53173828]
  [ 0.92578125]
  [ 1.64160156]
  [ 2.61523438]
  [ 2.53515625]
  [ 0.28417969]
  [-2.9609375 ]
  [-5.8125    ]
  [-7.953125  ]
  [-9.5625    ]]

 [[ 0.53173828]
  [ 0.92578125]
  [ 1.64160156]
  [ 2.61523438]
  [ 2.53515625]
  [ 0.28540039]
  [-2.95898438]
  [-5.80859375]
  [-7.953125  ]
  [-9.5625    ]]

 [[ 0.53125   ]
  [ 0.92480469]
  [ 1.63769531]
  [ 2.60546875]
  [ 2.51953125]
  [ 0.2578125 ]
  [-2.99609375]
  [-5.859375  ]
  [-8.0078125 ]
  [-9.625     ]]

 [[ 0.53173828]
  [ 0.92578125]
  [ 1.64160156]
  [ 2.61328125]
  [ 2.53320312]
  [ 0.28173828]
  [-2.96484375]
  [-5.8203125 ]
  [-7.9609375 ]
  [-9.5703125 ]]

 [[ 0.53125   ]
  [ 0.92529297]
  [ 1.63671875]
  [ 2.60351562]
  [ 2.51171875]
  [ 0.24194336]
  [-3.0234375 ]
  [-5.89453125]
  [-8.046875  ]
  [-9.671875  ]]

 [[ 0.53027344]
  [ 0.92431641]
  [ 1.63476562]
  [ 2.59960938]
  [ 2.50585938]
  [ 0.23461914]
  [-3.03125   ]
  [-5.90234375]
  [-8.0625    ]
  [-9.6875    ]]

 [[ 0.53173828]
  [ 0.92626953]
  [ 1.64257812]
  [ 2.61523438]
  [ 2.53710938]
  [ 0.28515625]
  [-2.95898438]
  [-5.8125    ]
  [-7.95703125]
  [-9.5625    ]]

 [[ 0.53173828]
  [ 0.92578125]
  [ 1.64160156]
  [ 2.61523438]
  [ 2.53515625]
  [ 0.28613281]
  [-2.95703125]
  [-5.80859375]
  [-7.94921875]
  [-9.5625    ]]

 [[ 0.53369141]
  [ 0.92626953]
  [ 1.640625  ]
  [ 2.61132812]
  [ 2.52734375]
  [ 0.26757812]
  [-2.98828125]
  [-5.84765625]
  [-8.        ]
  [-9.609375  ]]

 [[ 0.53027344]
  [ 0.92382812]
  [ 1.63183594]
  [ 2.59375   ]
  [ 2.49609375]
  [ 0.2175293 ]
  [-3.0546875 ]
  [-5.9296875 ]
  [-8.09375   ]
  [-9.71875   ]]

 [[ 0.53173828]
  [ 0.92480469]
  [ 1.63867188]
  [ 2.609375  ]
  [ 2.5234375 ]
  [ 0.26708984]
  [-2.984375  ]
  [-5.83984375]
  [-7.98828125]
  [-9.6015625 ]]

 [[ 0.53076172]
  [ 0.92333984]
  [ 1.63183594]
  [ 2.59375   ]
  [ 2.49414062]
  [ 0.21398926]
  [-3.06054688]
  [-5.9375    ]
  [-8.1015625 ]
  [-9.7265625 ]]

 [[ 0.53173828]
  [ 0.92578125]
  [ 1.64160156]
  [ 2.61523438]
  [ 2.53515625]
  [ 0.28466797]
  [-2.95898438]
  [-5.8125    ]
  [-7.953125  ]
  [-9.5625    ]]

 [[ 0.53222656]
  [ 0.92382812]
  [ 1.6328125 ]
  [ 2.59570312]
  [ 2.49609375]
  [ 0.21887207]
  [-3.0546875 ]
  [-5.9296875 ]
  [-8.09375   ]
  [-9.7109375 ]]

 [[ 0.53173828]
  [ 0.92578125]
  [ 1.64160156]
  [ 2.61523438]
  [ 2.53515625]
  [ 0.28466797]
  [-2.95898438]
  [-5.8125    ]
  [-7.953125  ]
  [-9.5625    ]]

 [[ 0.53173828]
  [ 0.92578125]
  [ 1.64160156]
  [ 2.61328125]
  [ 2.53515625]
  [ 0.28271484]
  [-2.96289062]
  [-5.81640625]
  [-7.9609375 ]
  [-9.5703125 ]]

 [[ 0.53173828]
  [ 0.92578125]
  [ 1.64160156]
  [ 2.61328125]
  [ 2.53320312]
  [ 0.27856445]
  [-2.96875   ]
  [-5.82421875]
  [-7.96875   ]
  [-9.578125  ]]

 [[ 0.53076172]
  [ 0.92431641]
  [ 1.6328125 ]
  [ 2.59570312]
  [ 2.49804688]
  [ 0.21862793]
  [-3.05664062]
  [-5.93359375]
  [-8.1015625 ]
  [-9.7265625 ]]

 [[ 0.53125   ]
  [ 0.92578125]
  [ 1.640625  ]
  [ 2.61132812]
  [ 2.52929688]
  [ 0.27246094]
  [-2.97851562]
  [-5.8359375 ]
  [-7.984375  ]
  [-9.59375   ]]

 [[ 0.53173828]
  [ 0.92578125]
  [ 1.64160156]
  [ 2.61328125]
  [ 2.53320312]
  [ 0.27929688]
  [-2.96679688]
  [-5.8203125 ]
  [-7.96484375]
  [-9.578125  ]]]
After layer swapaxes51_output (10, 20, 1) <class 'numpy.float16'> [[[ 0.53173828]
  [ 0.53173828]
  [ 0.53125   ]
  [ 0.53173828]
  [ 0.53125   ]
  [ 0.53027344]
  [ 0.53173828]
  [ 0.53173828]
  [ 0.53369141]
  [ 0.53027344]
  [ 0.53173828]
  [ 0.53076172]
  [ 0.53173828]
  [ 0.53222656]
  [ 0.53173828]
  [ 0.53173828]
  [ 0.53173828]
  [ 0.53076172]
  [ 0.53125   ]
  [ 0.53173828]]

 [[ 0.92578125]
  [ 0.92578125]
  [ 0.92480469]
  [ 0.92578125]
  [ 0.92529297]
  [ 0.92431641]
  [ 0.92626953]
  [ 0.92578125]
  [ 0.92626953]
  [ 0.92382812]
  [ 0.92480469]
  [ 0.92333984]
  [ 0.92578125]
  [ 0.92382812]
  [ 0.92578125]
  [ 0.92578125]
  [ 0.92578125]
  [ 0.92431641]
  [ 0.92578125]
  [ 0.92578125]]

 [[ 1.64160156]
  [ 1.64160156]
  [ 1.63769531]
  [ 1.64160156]
  [ 1.63671875]
  [ 1.63476562]
  [ 1.64257812]
  [ 1.64160156]
  [ 1.640625  ]
  [ 1.63183594]
  [ 1.63867188]
  [ 1.63183594]
  [ 1.64160156]
  [ 1.6328125 ]
  [ 1.64160156]
  [ 1.64160156]
  [ 1.64160156]
  [ 1.6328125 ]
  [ 1.640625  ]
  [ 1.64160156]]

 [[ 2.61523438]
  [ 2.61523438]
  [ 2.60546875]
  [ 2.61328125]
  [ 2.60351562]
  [ 2.59960938]
  [ 2.61523438]
  [ 2.61523438]
  [ 2.61132812]
  [ 2.59375   ]
  [ 2.609375  ]
  [ 2.59375   ]
  [ 2.61523438]
  [ 2.59570312]
  [ 2.61523438]
  [ 2.61328125]
  [ 2.61328125]
  [ 2.59570312]
  [ 2.61132812]
  [ 2.61328125]]

 [[ 2.53515625]
  [ 2.53515625]
  [ 2.51953125]
  [ 2.53320312]
  [ 2.51171875]
  [ 2.50585938]
  [ 2.53710938]
  [ 2.53515625]
  [ 2.52734375]
  [ 2.49609375]
  [ 2.5234375 ]
  [ 2.49414062]
  [ 2.53515625]
  [ 2.49609375]
  [ 2.53515625]
  [ 2.53515625]
  [ 2.53320312]
  [ 2.49804688]
  [ 2.52929688]
  [ 2.53320312]]

 [[ 0.28417969]
  [ 0.28540039]
  [ 0.2578125 ]
  [ 0.28173828]
  [ 0.24194336]
  [ 0.23461914]
  [ 0.28515625]
  [ 0.28613281]
  [ 0.26757812]
  [ 0.2175293 ]
  [ 0.26708984]
  [ 0.21398926]
  [ 0.28466797]
  [ 0.21887207]
  [ 0.28466797]
  [ 0.28271484]
  [ 0.27856445]
  [ 0.21862793]
  [ 0.27246094]
  [ 0.27929688]]

 [[-2.9609375 ]
  [-2.95898438]
  [-2.99609375]
  [-2.96484375]
  [-3.0234375 ]
  [-3.03125   ]
  [-2.95898438]
  [-2.95703125]
  [-2.98828125]
  [-3.0546875 ]
  [-2.984375  ]
  [-3.06054688]
  [-2.95898438]
  [-3.0546875 ]
  [-2.95898438]
  [-2.96289062]
  [-2.96875   ]
  [-3.05664062]
  [-2.97851562]
  [-2.96679688]]

 [[-5.8125    ]
  [-5.80859375]
  [-5.859375  ]
  [-5.8203125 ]
  [-5.89453125]
  [-5.90234375]
  [-5.8125    ]
  [-5.80859375]
  [-5.84765625]
  [-5.9296875 ]
  [-5.83984375]
  [-5.9375    ]
  [-5.8125    ]
  [-5.9296875 ]
  [-5.8125    ]
  [-5.81640625]
  [-5.82421875]
  [-5.93359375]
  [-5.8359375 ]
  [-5.8203125 ]]

 [[-7.953125  ]
  [-7.953125  ]
  [-8.0078125 ]
  [-7.9609375 ]
  [-8.046875  ]
  [-8.0625    ]
  [-7.95703125]
  [-7.94921875]
  [-8.        ]
  [-8.09375   ]
  [-7.98828125]
  [-8.1015625 ]
  [-7.953125  ]
  [-8.09375   ]
  [-7.953125  ]
  [-7.9609375 ]
  [-7.96875   ]
  [-8.1015625 ]
  [-7.984375  ]
  [-7.96484375]]

 [[-9.5625    ]
  [-9.5625    ]
  [-9.625     ]
  [-9.5703125 ]
  [-9.671875  ]
  [-9.6875    ]
  [-9.5625    ]
  [-9.5625    ]
  [-9.609375  ]
  [-9.71875   ]
  [-9.6015625 ]
  [-9.7265625 ]
  [-9.5625    ]
  [-9.7109375 ]
  [-9.5625    ]
  [-9.5703125 ]
  [-9.578125  ]
  [-9.7265625 ]
  [-9.59375   ]
  [-9.578125  ]]]
After layer sequencemask21_output (10, 20, 1) <class 'numpy.float16'> [[[  5.31738281e-01]
  [  5.31738281e-01]
  [  5.31250000e-01]
  [  5.31738281e-01]
  [  5.31250000e-01]
  [  5.30273438e-01]
  [  5.31738281e-01]
  [  5.31738281e-01]
  [  5.33691406e-01]
  [  5.30273438e-01]
  [  5.31738281e-01]
  [  5.30761719e-01]
  [  5.31738281e-01]
  [  5.32226562e-01]
  [  5.31738281e-01]
  [  5.31738281e-01]
  [  5.31738281e-01]
  [  5.30761719e-01]
  [  5.31250000e-01]
  [  5.31738281e-01]]

 [[  9.25781250e-01]
  [  9.25781250e-01]
  [  9.24804688e-01]
  [  9.25781250e-01]
  [  9.25292969e-01]
  [  9.24316406e-01]
  [  9.26269531e-01]
  [  9.25781250e-01]
  [  9.26269531e-01]
  [  9.23828125e-01]
  [  9.24804688e-01]
  [  9.23339844e-01]
  [  9.25781250e-01]
  [  9.23828125e-01]
  [  9.25781250e-01]
  [  9.25781250e-01]
  [  9.25781250e-01]
  [  9.24316406e-01]
  [  9.25781250e-01]
  [  9.25781250e-01]]

 [[ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]]
After layer swapaxes52_output (20, 10, 1) <class 'numpy.float16'> [[[  5.31738281e-01]
  [  9.25781250e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  5.31738281e-01]
  [  9.25781250e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  5.31250000e-01]
  [  9.24804688e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  5.31738281e-01]
  [  9.25781250e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  5.31250000e-01]
  [  9.25292969e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  5.30273438e-01]
  [  9.24316406e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  5.31738281e-01]
  [  9.26269531e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  5.31738281e-01]
  [  9.25781250e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  5.33691406e-01]
  [  9.26269531e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  5.30273438e-01]
  [  9.23828125e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  5.31738281e-01]
  [  9.24804688e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  5.30761719e-01]
  [  9.23339844e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  5.31738281e-01]
  [  9.25781250e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  5.32226562e-01]
  [  9.23828125e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  5.31738281e-01]
  [  9.25781250e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  5.31738281e-01]
  [  9.25781250e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  5.31738281e-01]
  [  9.25781250e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  5.30761719e-01]
  [  9.24316406e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  5.31250000e-01]
  [  9.25781250e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]

 [[  5.31738281e-01]
  [  9.25781250e-01]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]
  [ -6.55040000e+04]]]
After layer attention_softmax_0 (20, 10, 1) <class 'numpy.float16'> [[[ 0.40283203]
  [ 0.59765625]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40283203]
  [ 0.59765625]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40283203]
  [ 0.59716797]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40283203]
  [ 0.59765625]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40283203]
  [ 0.59765625]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40283203]
  [ 0.59765625]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40258789]
  [ 0.59765625]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40283203]
  [ 0.59765625]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40307617]
  [ 0.59667969]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40283203]
  [ 0.59716797]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40307617]
  [ 0.59716797]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40307617]
  [ 0.59667969]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40283203]
  [ 0.59765625]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40332031]
  [ 0.59667969]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40283203]
  [ 0.59765625]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40283203]
  [ 0.59765625]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40283203]
  [ 0.59765625]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40283203]
  [ 0.59716797]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40258789]
  [ 0.59765625]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]

 [[ 0.40283203]
  [ 0.59765625]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]
  [ 0.        ]]]
After layer batch_dot21_0 (20, 512, 1) <class 'numpy.float16'> [[[ 0.0178833 ]
  [ 0.03948975]
  [-0.03344727]
  ...,
  [-0.0109787 ]
  [ 0.00999451]
  [-0.02462769]]

 [[ 0.0178833 ]
  [ 0.03948975]
  [-0.03344727]
  ...,
  [-0.0109787 ]
  [ 0.00999451]
  [-0.02462769]]

 [[ 0.01786804]
  [ 0.03945923]
  [-0.03341675]
  ...,
  [-0.01097107]
  [ 0.00999451]
  [-0.02461243]]

 ...,
 [[ 0.01786804]
  [ 0.03945923]
  [-0.03341675]
  ...,
  [-0.01097107]
  [ 0.00999451]
  [-0.02461243]]

 [[ 0.01786804]
  [ 0.03948975]
  [-0.03344727]
  ...,
  [-0.0109787 ]
  [ 0.00999451]
  [-0.02461243]]

 [[ 0.0178833 ]
  [ 0.03948975]
  [-0.03344727]
  ...,
  [-0.0109787 ]
  [ 0.00999451]
  [-0.02462769]]]
After layer reshape42_0 (20, 512) <class 'numpy.float16'> [[ 0.0178833   0.03948975 -0.03344727 ..., -0.0109787   0.00999451
  -0.02462769]
 [ 0.0178833   0.03948975 -0.03344727 ..., -0.0109787   0.00999451
  -0.02462769]
 [ 0.01786804  0.03945923 -0.03341675 ..., -0.01097107  0.00999451
  -0.02461243]
 ...,
 [ 0.01786804  0.03945923 -0.03341675 ..., -0.01097107  0.00999451
  -0.02461243]
 [ 0.01786804  0.03948975 -0.03344727 ..., -0.0109787   0.00999451
  -0.02461243]
 [ 0.0178833   0.03948975 -0.03344727 ..., -0.0109787   0.00999451
  -0.02462769]]
After layer decoder_rnn_hidden_concat_t0_output (20, 1024) <class 'numpy.float16'> [[-0.00119781 -0.91845703  0.1973877  ..., -0.0109787   0.00999451
  -0.02462769]
 [-0.00119781 -0.91845703  0.19763184 ..., -0.0109787   0.00999451
  -0.02462769]
 [-0.00120068 -0.91845703  0.19726562 ..., -0.01097107  0.00999451
  -0.02461243]
 ...,
 [-0.00120163 -0.91894531  0.19665527 ..., -0.01097107  0.00999451
  -0.02461243]
 [-0.00119781 -0.91845703  0.19714355 ..., -0.0109787   0.00999451
  -0.02461243]
 [-0.00119781 -0.91845703  0.1973877  ..., -0.0109787   0.00999451
  -0.02462769]]
After layer decoder_rnn_hidden_fc_t0_output (20, 512) <class 'numpy.float16'> [[-1.9765625   0.21655273 -0.82177734 ...,  1.984375    2.12304688
  -1.60839844]
 [-1.97558594  0.21606445 -0.82177734 ...,  1.984375    2.12304688
  -1.60839844]
 [-1.97558594  0.21789551 -0.82421875 ...,  1.98339844  2.12109375
  -1.609375  ]
 ...,
 [-1.97460938  0.22106934 -0.83007812 ...,  1.97949219  2.11914062
  -1.61425781]
 [-1.97753906  0.21875    -0.82470703 ...,  1.984375    2.12109375
  -1.609375  ]
 [-1.9765625   0.21679688 -0.82275391 ...,  1.984375    2.12304688
  -1.60839844]]
After layer decoder_rnn_next_hidden_t0_output (20, 512) <class 'numpy.float16'> [[-0.96240234  0.21325684 -0.67626953 ...,  0.96289062  0.97167969
  -0.92285156]
 [-0.96240234  0.21276855 -0.67626953 ...,  0.96289062  0.97167969
  -0.92285156]
 [-0.96240234  0.21447754 -0.67724609 ...,  0.96289062  0.97167969
  -0.92285156]
 ...,
 [-0.96240234  0.2175293  -0.68066406 ...,  0.96240234  0.97167969
  -0.92382812]
 [-0.96240234  0.21533203 -0.67773438 ...,  0.96289062  0.97167969
  -0.92285156]
 [-0.96240234  0.21350098 -0.67675781 ...,  0.96289062  0.97167969
  -0.92285156]]
After layer logits_output (20, 16743) <class 'numpy.float16'> [[-2.01757812 -2.82617188 -2.40820312 ..., -2.09375    -3.50195312
  -2.58984375]
 [-2.01757812 -2.82617188 -2.40820312 ..., -2.09375    -3.50195312
  -2.58984375]
 [-2.015625   -2.82617188 -2.40820312 ..., -2.09375    -3.50195312
  -2.59179688]
 ...,
 [-2.015625   -2.828125   -2.40820312 ..., -2.09570312 -3.50195312 -2.59375   ]
 [-2.015625   -2.82617188 -2.40820312 ..., -2.09375    -3.50195312
  -2.59179688]
 [-2.015625   -2.82617188 -2.40820312 ..., -2.09375    -3.50195312
  -2.58984375]]
After layer softmax_0 (20, 16743) <class 'numpy.float16'> [[  8.34465027e-07   3.57627869e-07   5.96046448e-07 ...,   7.74860382e-07
    1.78813934e-07   4.76837158e-07]
 [  8.34465027e-07   3.57627869e-07   5.96046448e-07 ...,   7.74860382e-07
    1.78813934e-07   4.76837158e-07]
 [  8.34465027e-07   3.57627869e-07   5.96046448e-07 ...,   7.74860382e-07
    1.78813934e-07   4.76837158e-07]
 ...,
 [  8.34465027e-07   3.57627869e-07   5.96046448e-07 ...,   7.74860382e-07
    1.78813934e-07   4.76837158e-07]
 [  8.34465027e-07   3.57627869e-07   5.96046448e-07 ...,   7.74860382e-07
    1.78813934e-07   4.76837158e-07]
 [  8.34465027e-07   3.57627869e-07   5.96046448e-07 ...,   7.74860382e-07
    1.78813934e-07   4.76837158e-07]]
After layer reshape43_0 (20, 10) <class 'numpy.float16'> [[ 0.40283203  0.59765625  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40283203  0.59765625  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40283203  0.59716797  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40283203  0.59765625  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40283203  0.59765625  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40283203  0.59765625  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40258789  0.59765625  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40283203  0.59765625  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40307617  0.59667969  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40283203  0.59716797  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40307617  0.59716797  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40307617  0.59667969  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40283203  0.59765625  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40332031  0.59667969  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40283203  0.59765625  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40283203  0.59765625  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40283203  0.59765625  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40283203  0.59716797  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40258789  0.59765625  0.          0.          0.          0.          0.
   0.          0.          0.        ]
 [ 0.40283203  0.59765625  0.          0.          0.          0.          0.
   0.          0.          0.        ]]
1.989	conclusion
[14:31:48] /home/ec2-user/danchenk/incubator-mxnet/src/engine/naive_engine.cc:55: Engine shutdown

Process finished with exit code 0
